{"authors": "Jiaao Chen; Diyi Yang", "pub_date": "", "title": "Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs", "abstract": "Abstractive conversation summarization has received much attention recently. However, these generated summaries often suffer from insufficient, redundant, or incorrect content, largely due to the unstructured and complex characteristics of human-human interactions. To this end, we propose to explicitly model the rich structures in conversations for more precise and accurate conversation summarization, by first incorporating discourse relations between utterances and action triples (\"WHO-DOING-WHAT\") in utterances through structured graphs to better encode conversations, and then designing a multi-granularity decoder to generate summaries by combining all levels of information. Experiments show that our proposed models outperform state-of-theart methods and generalize well in other domains in terms of both automatic evaluations and human judgments. We have publicly released our code at https://github.com/ GT-SALT/Structure-Aware-BART.", "sections": [{"heading": "Introduction", "text": "Online interaction has become an indispensable component of everyday life and people are increasingly using textual conversations to exchange ideas, make plans, and share information. However, it is time-consuming to recap and grasp all the core content within every complex conversation (Gao et al., 2020;Feng et al., 2020). As a result, how to organize massive everyday interactions into natural, concise, and informative text, i.e., abstractive conversation summarization, starts to gain importance.\nSignificant progress has been made on abstractive summarization for structured document via pointer generator (See et al., 2017), reinforcement methods (Paulus et al., 2018; and pre-trained models (Liu and Lapata, 2019;Lewis et al., 2020;. Despite the huge success, it is challenging to directly apply document models to summarize conversations, due to  (Gliwa et al., 2019). The annotated summary is Simon was on the phone before, so he didn't here Helen calling. Simon will fetch Helen some tissues.\na set of inherent differences between conversations and documents (Gliwa et al., 2019). First, speaker interruptions like repetitions, false-starts, and hesitations are frequent in conversations (Sacks et al., 1978), and key information resides in different portions of a conversation. These unstructured properties pose challenges for models to focus on salient contents that are necessary for generating both abstractive and informative summaries. Second, there is more than one speaker in conversations and people interact with each other in different language styles . The complex interactions among multiple speakers make it harder for mod-els to identify and associate speakers with correct actions so as to generate factual summaries.\nIn order to summarize the unstructured and complex conversations, a growing body of research has been conducted, such as transferring document summarization methods to conversation settings (Shang et al., 2018;Gliwa et al., 2019), adopting hierarchical models , or incorporating conversation structures like topic segmentation (Liu et al., 2019b;Chen and Yang, 2020), dialogue acts (Goo and Chen, 2018), and conversation stages (Chen and Yang, 2020). However, current approaches still face challenges in terms of succinctness and faithfulness, as most prior studies (i) fail to explicitly model dependencies between utterances which can help identify salient portions of conversations (Bui et al., 2009), and (ii) lack structured representations  to learn the associations between speakers, actions and events. We argue that these rich linguistic structures associated with conversations are key components towards generating abstractive and factual conversation summaries.\nTo this end, we present a structure-aware sequence-to-sequence model, in which we equip abstractive conversation summarization models with rich conversation structures through two types of graphs: discourse relation graph and action graph. Discourse relation graphs are constructed based on dependency-based discourse relations (Kirschner et al., 2012;Stone et al., 2013;Asher et al., 2016;Qin et al., 2017) between intertwined utterances, where each Elementary Discourse Unit (EDU) is one single utterance and they are linked through 16 different types of relations (Asher et al., 2016). As shown in Figure 1(a), highly related utterances are linked based on discourse relations like Question Answer Pairs, Comment and Explanation. Explicitly modeling these utterances relations in conversations can aid models in recognizing key content for succinct and informative summarization. Action graphs are constructed as the \"WHO-DOING-WHAT\" triplets in conversations which express socially situated identities and activities (Gee, 2014). For instance, in Figure 1(b), the action graph provides explicit information between Simon, fetch, and tissues for the utterance it is Simon who will fetch the tissues, making models less likely to generate summaries with wrong references (e.g., Helen will fetch the tissues).\nTo sum up, our contributions are: (1) We pro-pose to utilize discourse relation graphs and action graphs to better encode conversations for conversation summarization. (2) We design structureaware sequence-to-sequence models to combine these structured graphs and generate summaries with the help of a novel multi-granularity decoder.\n(3) We demonstrate the effectiveness of our proposed methods through experiments on a largescale conversation summarization dataset, SAM-Sum (Gliwa et al., 2019). (4) We further show that our structure-aware models can generalize well in new domains such as debate summarization.", "n_publication_ref": 23, "n_figure_ref": 2}, {"heading": "Related Work", "text": "Document Summarization Compared to extractive document summarization (Gupta and Lehal, 2010;Narayan et al., 2018;Liu and Lapata, 2019), abstractive document summarization is generally considered more challenging and has received more attention. Various methods have been designed to tackle abstractive document summarization like sequence-to-sequence models (Rush et al., 2015), pointer generators (See et al., 2017), reinforcement learning methods (Paulus et al., 2018; and pre-trained models (Lewis et al., 2020;. To generate faithful abstractive document summaries (Maynez et al., 2020), graphbased models were introduced recently such as extracting entity types (Fernandes et al., 2018;, leveraging knowledge graphs Zhu et al., 2020a) or designing extra fact correction modules . Inspired by these graph-based methods, we also construct action graphs for generating more factual conversation summaries.\nConversation Summarization Extractive dialogue summarization (Murray et al., 2005) has been studied extensively via statistical machine learning methods such as skip-chain CRFs (Galley, 2006), SVM with LDA models (Wang and Cardie, 2013), and multi-sentence compression algorithms (Shang et al., 2018). Such methods struggled with generating succinct, fluent, and natural summaries, especially when the key information needs to be aggregated from multiple first-person point-of-view utterances (Song et al., 2020). Abstractive conversation summarization overcomes these issues by designing hierarchical models , incorporating commonsense knowledge (Feng et al., 2020), or leveraging conversational structures like dialogue acts (Goo and Chen, 2018), key point sequences (Liu et al., 2019a), topic segments (Liu et al., 2019b; and stage developments (Chen and Yang, 2020). Some recent research has also utilized discourse relations as input features in classifiers to detect important content in conversations (Murray et al., 2006;Bui et al., 2009;Qin et al., 2017). However, current models still have not explicitly utilized the dependencies between different utterances, making models hard to leverage long-range dependencies and utilize these salient utterances. Moreover, less attention has been paid to identify the actions of different speakers and how they interact with or refer to each other, leading to unfaithful summarization with incorrect references or wrong reasoning (Gliwa et al., 2019). To fill these gaps, we propose to explicitly model actions within utterances, and relations between utterances in conversations in a structured way, by using discourse relation graphs and action graphs and further combining these through relational graph encoders and multigranularity decoders for abstractive conversation summarization.", "n_publication_ref": 23, "n_figure_ref": 0}, {"heading": "Methods", "text": "To generate abstractive and factual summaries from unstructured conversations, we propose to model structural signals in conversations by first constructing discourse relation graphs and action graphs (Section 3.1), and then encoding the graphs together with conversations (Section 3.2) as well as incorporating these different levels of information in the decoding stage through a multi-granularity decoder (Section 3.3) to summarize given conversations. The overall architecture is shown in Figure 2.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Structured Graph Construction", "text": "This section describes how to construct the discourse relation graphs and action graphs. Formally, for a given conversation C = {u 0 , ..., u m } with m utterances, we construct discourse relation graph G D = (V D , E D ), where V D is the set of nodes representing Elementary Discourse Units (EDUs), and E D is the adjacent matrix that describes the relations between EDUs, and action graph G A = (V A , E A ), where V A is the set of nodes representing \"WHO\", \"DOING\" and \"WHAT\" arguments, and E A is the adjacent matrix to link \"WHO-DOING-WHAT\" triples.\nDiscourse Relation Graph Utterances from different speakers do not occur in isolation; instead, they are related within the context of discourse (Murray et al., 2006;Qin et al., 2017), which has been shown effective for dialogue understanding like identifying the decisions in multi-party dialogues (Bui et al., 2009) and detecting salient content in email conversations (McKeown et al., 2007). Although current attention-based neural models are supposed to, or might implicitly, learn certain relations between utterances, they often struggle to focus on many informative utterances (Chen and Yang, 2020;Song et al., 2020) and fail to address long-range dependencies (Xu et al., 2020), especially when there are frequent interruptions. As a result, explicitly incorporating the discourse relations will help neural summarization models better encode the unstructured conversations and concentrate on the most salient utterances to generate more informative and less redundant summaries.\nTo do so, we view each utterance as an EDU and use the discourse relation types defined in Asher et al. (2016). We first pre-train a discourse parsing model (Shi and Huang, 2019) on a humanannotated multiparty dialogue corpus (Asher et al., 2016), with 0.775 F1 score on link predictions and 0.557 F1 score on relation classifications, which are comparable to the state-of-the-art results (Shi and Huang, 2019). We then utilize this pre-trained parser to predict the discourse relations within conversations in our SAMSum corpus (Gliwa et al., 2019).\nAfter predictions, there are 138,554 edges identified in total and 8.48 edges per conversation. The distribution of these predicted discourse relation types is: Comment (19.3%), Clarification Question (15.2%), Elaboration (2.3%), Acknowledgement(8.4%), Continuation (10.1%), Explanation (2.8%), Conditional (0.2 %), Question Answer Pair (21.5%), Alternation (0.3%), Q-Elab (2.5%), Result (5.5%), Background (0.4%), Narration (0.4%), Correction (0.4%), Parallel (0.9%), and Contrast (1.0%). Then for each conversation, we construct a discourse relation graph\nG D = (V D , E D ), where V D [k] represents the k-th utterance. E D [i][j] = r\nif there is a link from the i-th utterance to the j-th one with discourse relation r.", "n_publication_ref": 12, "n_figure_ref": 0}, {"heading": "Action Graph", "text": "The \"who-doing-what\" triples from utterances can provide explicit visualizations of speakers and their actions, the key to understanding concrete details happened in conversations (Moser, 2001;Gee, 2014;Sacks et al., 1978). Simply relying on neural models to identify this information from conversations often fail to produce factual characterizations of concrete details happened (Cao et al., 2018;. To this end, we extract \"WHO-DOING-WHAT\" triples from utterances and construct action graphs for conversation summarization Huang et al., 2020b,a). Specifically, we first transform the first-person point-of-view utterances to its thirdperson point-of-view forms based on simple rules: (i) substituting first/second-person pronouns with the names of current speaker or surrounding speakers and (ii) replacing third-person pronouns based on coreference clusters in conversations detected by the Stanford CoreNLP (Manning et al., 2014). For example, an utterance \"I'll bring it to you to-morrow\" from Amanda to Jerry will be transformed into \"Amanda'll bring cakes to Jerry tomorrow\". Then we extract \"WHO-DOING-WHAT\" (subjectpredicate-object) triples from transformed conversations using the open information extraction (Ope-nIE) systems 1 (Angeli et al., 2015). We then construct the Action Graph G A = (V A , E A ) from the extracted triples by taking arguments (\"WHO\", \"DOING\", or \"WHAT\" ) as nodes in V A , and connect them with edge E A [i][j] = 1 if they are adjacent in one \"WHO-DOING-WHAT\" triple.", "n_publication_ref": 7, "n_figure_ref": 0}, {"heading": "Encoder", "text": "Given a conversation and its corresponding discourse relation graph and action graph, we utilize an utterance encoder and two graph encoders, to obtain its hidden representations shown in Figure 2(a).", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Utterance Encoder", "text": "We initialize our utterance encoder F U (.) with a pre-trained encoder, i.e., BART-base (Lewis et al., 2020), and encode tokens {x i,0 , ..., x i,l } in an utterance u i into its hidden representation:\n{h U i,0 , ..., h U i,l } = F U ({x i,0 , ..., x i,l }) (1)\nHere we add a special token x i,0 =<S> at the beginning of each utterance to represent it.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Graph Encoder", "text": "Node Initialization For discourse relation graph, we employ the output embeddings of the special tokens x i,0 from the utterance encoder, i.e., h U i,0 , to initialize the i-th node v D i in G D . We use a one-hot embedding layer to encode the relations E D [i][j] = e D i,j between utterance i and j. For action graph, we first utilize F U (.) to encode each token in nodes v A i and then average their output embeddings as their initial representations.\nStructured Graph Attention Network Based on Graph Attention Network (Veli\u010dkovi\u0107 et al., 2018), we utilize these relations between nodes to encode each node  W, W e and a are trainable parameters. [. .] denotes the concatenation of two vectors. \u03c3 is the activation function, N i is the set containing nodei's neighbours in G.\nv D i in G D or v A i in G A through: \u03b1 ij = exp \u03c3 a T [Wv i Wv j W e e i,j]\nk\u2208N i exp (\u03c3 (a T [Wv i Wv k W e e i,k ])) h i = \u03c3( j\u2208N i \u03b1 ij Wv j ) Dataset Split #\nThrough two graph encoders F D (., .) and F A (., .), we then obtain the hidden representations of these nodes as:\n{h D 0 , ..., h D m } = F D ({v D 0 , ..., v D m }, E D ) (2) {h A 0 , ..., h A n } = F A ({x A 0 , ..., x A n }, E A ) (3)", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Multi-Granularity Decoder", "text": "Different levels of encoded representations are then aggregated via our multi-granularity decoder to generate summaries as shown in Figure 2(b). With s \u2212 1 previously generated tokens y 1 , ..., y s\u22121 , our decoder G(.) predicts the l-th token via:\ny = G(y 1:s\u22121 , F U (C), F D (G D ), F A (G A )) (4) P (\u1ef9 s |y <s , C, G D , G A ) = Softmax(W p\u0177 ) (5)\nTo better incorporate the information in constructed graphs, different from the traditional pretrained BART model (Lewis et al., 2020), we improve the BART transformer decoder with two extra cross attentions (Discourse Attention and Action Attention) added to each decoder layer, which attends to the encoded node representations in discourse relation graphs and action graphs.\nIn each decoder layer, after performing the original cross attentions over every token in utterances {h U i,0:l } and getting the utterance-attended representation x U , multi-granularity decoder then conducts cross attentions over nodes {h D 0:m } and {h A 0:n } that are encoded from graph encoders in parallel, to obtain the discourse-attended representation x D and action-attended representation x A . These two attended vectors are then combined into a structureaware representation x S , through a feed-forward network for further forward passing in the decoder.\nTo alleviate the negative impact of randomly initialized graph encoders and cross attentions over graphs on pre-trained BART decoders at early stages and accelerate the learning of newlyintroduced modules during training, we apply ReZero (Bachlechner et al., 2020) to the residual connection after attending to graphs in each decoder layer:\nx S = x U + \u03b1x S (6\n)\nwhere \u03b1 is one trainable parameter instead of a fixed value 1, which modulates updates from cross attentions over graphs.\nTraining During training, we seek to minimize the cross entropy and use the teacher-forcing strategy (Bengio et al., 2015):\nL = \u2212 log P (\u1ef9 l |y <l , C, G D , G A ) (7)\n4 Experiments", "n_publication_ref": 3, "n_figure_ref": 1}, {"heading": "Datasets", "text": "We trained and evaluated our models on a conversation summarization dataset SAMSum (Gliwa et al., 2019) covering messenger-like conversations about daily topics, such as arranging meetings and discussing events. We also showed the generalizability of our models on the Argumentative Dialogue Summary Corpus (ADSC) (Misra et al., 2015), a debate summarization corpus. The data statistics of two datasets were shown in Table 1, with the discourse relation types distributions in the Appendix.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Baselines", "text": "We compare our methods with several baselines:\n\u2022 Pointer Generator (See et al., 2017): We followed the settings in Gliwa et al. (2019) and used special tokens to separate each utterance.\n\u2022 Transformer (Vaswani et al., 2017): We trained transformer seq2seq models following the OpenNMT (Klein et al., 2017).\n\u2022 D-HGN (Feng et al., 2020) incorporated commonsense knowledge from ConceptNet (Liu and Singh, 2004) for dialogue summarization.   (Dror et al., 2018) and found that S-BART w. Discourse& Action significantly outperformed the base BART (p < 0.05).  \u2022 BART (Lewis et al., 2020): We utilized BART 2 , and separated utterances by a special token.\n\u2022 Multi-View Seq2Seq (Chen and Yang, 2020) utilized topic and stage views on top of BART for summarizing conversations. Here we implemented it based on BART-base models.", "n_publication_ref": 8, "n_figure_ref": 0}, {"heading": "Implementation Details", "text": "We used the BART-base model to initialize our sequence-to-sequence model for training in all experiments. For parameters in the original BART encoder/decoder, we followed the default settings and set the learning rate 3e-5 with 120 warm-up steps. For graph encoders, we set the number of hidden dimensions as 768, the number of attention heads as 2, the number of layers as 2, and the dropout rate as 0.2. For graph cross attentions added to BART decoder layers, we set the number of attention heads as 2. The weights \u03b1 in ReZero residual connections were initialized with 1. The learning rate for parameters in newly added modules was 3e-4 with 60 warm-up steps. All experiments were performed on GeForce RTX 2080Ti (11GB memory).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Results on In-Domain Corpus", "text": "Automatic Evaluation We evaluated all the models with the widely used automatic metric,  All model variants of S-BART received significantly higher ratings than BART (student t-test, p < 0.05).\nROUGE scores (Lin and Och, 2004) 3 , and reported ROUGE-1, ROUGE-2, and ROUGE-L in Table 2. We found that, compared to simple sequence-to-sequence models (Pointer Generator and Transformer), incorporating extra information such as commonsense knowledge from ConceptNet (D-HGN) increased the ROUGE metrics. When equipped with pre-trained models and simple conversation structures such as topics and conversation stages, Multi-View Seq2Seq boosted ROUGE scores. Incorporating discourse relation graphs or action graphs helped the performances of summarization, suggesting the effectiveness of explicitly modeling relations between utterances and the associations between speakers and actions within utterances. Combining two different structured graphs produced better ROUGE scores compared to previous state-of-the-art methods and our base models, with an increase of 2.0% on ROUGE-1, 4.3% on ROUGE-2, and 1.2% on ROUGE-L compared to our base model, BART. This indicates that, our structure-aware models with discourse and action graphs could help abstractive conversation summarization, and these two graphs complemented each other in generating better summaries.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Human Evaluation", "text": "We conducted human evaluation to qualitatively evaluate the generated summaries. Specifically, we asked annotators from Amazon Mechanical Turk to score a set of randomly sampled 100 generated summaries from ground-truth, BART and our structured models, using a Likert scale from 1 (worst) to 5 (best) in terms of factualness (e.g., associates actions with the right actors) , succinctness (e.g., does not contain redundant information), and informativeness (e.g., covers the most important content) (Feng et al., 2020;. To increase annotation quality, we required turkers to have a 98% approval rate and at least 10,000 approved tasks for their previous work. Each message was rated by three workers. The scores for each summary were averaged. The Intra-Class Correlation was 0.543, showing moderate agreement (Koo and Li, 2016).\nAs shown in Table 4, S-BART that utilized structured information from discourse relation graphs and action graphs generated significantly better summaries with respect to factualness, succinctness, and informativeness. This might because that the incorporation of structured information such as discourse relations helped S-BART to recognize the salient parts in conversations, and thus improve the succinctness and informativeness over BART. Modeling the connections between speakers and actions greatly helped generate more factual summaries than the baselines, e.g., with an increase of 0.27 from BART to S-BART w. Action.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Results on Out-Of-Domain Corpus", "text": "To investigate the generalizability of our structureaware models, we then tested the S-BART model trained on SAMSum corpus directly on the debate summarization domain (ADSC Corpus (Misra et al., 2015)) in a zero-shot setting. Besides the differences in topics, utterances in debate conversations were generally longer and include more action triples (37.20 vs 6.81 as shown in Table 1) and fewer participants. The distribution of discourse relation types also differed a lot across different   domains 4 (e.g., more Contrast in debates (19.5%) than in daily conversations (1.0%)).\nAs shown in Table 3, our single graph models S-BART w. Discourse and S-BART w. Action boosted ROUGE scores compared to BART, suggesting that utilizing structures can also increase the generalizability of conversation summarization methods. However, contrary to in-domain results in Table 2, action graphs led to much more gains than discourse graphs. This indicated that when domain shifts, action triples were most robust in terms of zero-shot setups; differences in discourse relation distributions could limit such generalization. Consistent with in-domain scenarios, our S-BART w. Discourse&Action achieved better results, with an increase of 66.2% on ROUGE-1, 373.4% on ROUGE-2, and 82.2% on ROUGE-L over BART.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Ablation Studies", "text": "This part conducted ablation studies to show the effectiveness of structured graphs in our S-BART.\nThe Quality of Discourse Relation Graphs We showed how the quality of discourse relation graphs affected the performances of conversation summarization in Table 5. Specifically, we compared the ROUGE scores of S-BART using our constructed discourse relation graphs (S-BART w. Discourse Graph) and S-BART using randomly generated discourse relation graphs S-BART w. Random Graph where both connections between nodes and relation types were randomized. The number of edges in two graphs was kept the same. We found that S-BART with our discourse graphs outperformed  6. Here, parallel strategy performed cross attentions on different graphs separately and then combined the attended results with feed-forward networks as discussed in Section 3.3; sequential strategy performed cross attentions on two graphs in a specific order (from discourse relation graphs to actions graphs, or vice versa). We found that the parallel strategy showed better performances and the sequential ones did not introduce gains compared to S-BART with single graphs. This demonstrates that discourse relation graphs and action graphs were both important and provided different signals for abstractive conversation summarization.\nVisualizing ReZero Weights We further tested our structure-aware BART with two ReZero settings: (i) initializing \u03b1 from 0, (ii) initializing \u03b1 from 1, and found initializing \u03b1 from 1 would bring in more performance gains (see Appendix). We then visualized the average \u03b1 over different decoder layers after training in Figure 3, and observed that (i) when \u03b1 was initialized with 1, the final \u03b1 was much larger than the setting where \u03b1 was initialized with 0, which might because randomly initialized modules barely received supervisions at early stages and therefore contributes less to BART. (ii) Compared to discourse graphs, action graphs received higher \u03b1 weights after training in both initializing settings, suggesting that the information from structured action graphs might be harder for the end-to-end BART models to capture. (iii) Utilizing both graphs spontaneously led to higher  ReZero weights, further validating the effectiveness of combining discourse relation graphs and action graphs and their complementary properties.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Error Analyses", "text": "To inspect when our summarization models could help the conversations summarization, we visualized the average number of discourse edges and the average number of action triples in three sets of conversations in examples where both S-BART and BART showed low ROUGE scores (ROUGE-1 < 20.0, ROUGE-2 < 10.0, ROUGE-L < 10.0). When the structures in conversations were simpler (fewer discourse edges and fewer action triples than the average), BART showed similar performance as S-BART. As the structures of conversations become more complex with more discourse relations and more action mentions, S-BART outperformed BART as it explicitly incorporated these structured graphs. However, both BART and S-BART struggled when there were much more interactions beyond certain thresholds, calling for better mechanisms to model structures in conversations for generating better summaries.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Conclusion", "text": "In this work, we introduced a structure-aware sequence-to-sequence model for abstractive conversation summarization by incorporating discourse relations between utterances, and the connections between speakers and actions within utterances. Experiments and ablation studies on SAMSum corpus showed the effectiveness of these structured graphs in aiding the task of conversation summarization via both quantitative and qualitative eval-uation metrics. Results in zero-shot settings on ADCS Corpus further demonstrated the generalizability of our structure-aware models. In the future, we plan to extend our current conversation summarization models for various application domains such as emails, debates, and podcasts, and in conversations that might involve longer utterances and more participants in an unsynchronized way.    (Asher et al., 2016) with default settings 5 to get the link prediction and relation classification models to label discourse relations in SAMSum and ADSC corpus. The distribution of the relation types in two datasets were shown in Table 9. The major discourse relations in daily conversations are Comment, Clarification and QA pairs, while the main discourse relations in debate are Comment, Contrast, Clarification and QA pairs.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "B Impact of Different ReZero Weight Initializations", "text": "We tested our structure-aware BART (S-BART w. Discourse/Action) within two ReZero settings: (i) initializing \u03b1 from 0, (ii) initializing \u03b1 from 1. And the results were shown in Table 8. S-BART with 1 as the initialized ReZero weight outperformed", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgement", "text": "We would like to thank the anonymous reviewers for their helpful comments, and the members of Georgia Tech SALT group for their feedback. This work is supported in part by grants from Google, Amazon and Salesforce.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Leveraging linguistic structure for open domain information extraction", "journal": "Long Papers", "year": "2015", "authors": "Gabor Angeli; Melvin Jose Johnson Premkumar; Christopher D Manning"}, {"title": "Discourse structure and dialogue acts in multiparty dialogue: the stac corpus", "journal": "", "year": "2016", "authors": "Nicholas Asher; Julie Hunter; Mathieu Morey; Benamara Farah; Stergos Afantenos"}, {"title": "Rezero is all you need: Fast convergence at large depth", "journal": "", "year": "2020", "authors": "Thomas Bachlechner; Prasad Bodhisattwa; Huanru Henry Majumder;  Mao; W Garrison; Julian Cottrell;  Mcauley"}, {"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "journal": "", "year": "2015", "authors": "Samy Bengio; Oriol Vinyals; Navdeep Jaitly; Noam Shazeer"}, {"title": "Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity", "journal": "Association for Computational Linguistics", "year": "2009", "authors": "Trung Bui; Matthew Frampton; John Dowding; Stanley Peters"}, {"title": "Faithful to the original: Fact aware neural abstractive summarization", "journal": "", "year": "2018", "authors": "Ziqiang Cao; W Wei; Sujian Li;  Li"}, {"title": "Incorporating structured commonsense knowledge in story completion", "journal": "", "year": "2019", "authors": "Jiaao Chen; Jianshu Chen; Zhou Yu"}, {"title": "Multi-view sequenceto-sequence models with conversational structure for abstractive dialogue summarization", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Jiaao Chen; Diyi Yang"}, {"title": "Multi-fact correction in abstractive text summarization", "journal": "", "year": "2020", "authors": "Yue Dong; Shuohang Wang; Zhe Gan; Yu Cheng; Jackie Chi Kit Cheung; Jingjing Liu"}, {"title": "The hitchhiker's guide to testing statistical significance in natural language processing", "journal": "Long Papers", "year": "2018", "authors": "Rotem Dror; Gili Baumer; Segev Shlomov; Roi Reichart"}, {"title": "Using local knowledge graph construction to scale seq2seq models to multi-document inputs", "journal": "", "year": "2019", "authors": "Angela Fan; Claire Gardent; Chlo\u00e9 Braud; Antoine Bordes"}, {"title": "Incorporating commonsense knowledge into abstractive dialogue summarization via heterogeneous graph networks", "journal": "", "year": "2020", "authors": "Xiachong Feng; Xiaocheng Feng; Bing Qin; Ting Liu"}, {"title": "Structured neural summarization", "journal": "", "year": "2018", "authors": "Patrick Fernandes; Miltiadis Allamanis; Marc Brockschmidt"}, {"title": "A skip-chain conditional random field for ranking meeting utterances by importance", "journal": "", "year": "2006", "authors": "Michel Galley"}, {"title": "From standard summarization to new tasks and beyond: Summarization with manifold information", "journal": "", "year": "2020", "authors": "Shen Gao; Xiuying Chen; Zhaochun Ren; Dongyan Zhao; Rui Yan"}, {"title": "An introduction to discourse analysis: Theory and method", "journal": "", "year": "2014", "authors": "James Paul Gee"}, {"title": "SAMSum corpus: A human-annotated dialogue dataset for abstractive summarization", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Bogdan Gliwa; Iwona Mochol; Maciej Biesek; Aleksander Wawer"}, {"title": "Abstractive dialogue summarization with sentence-gated modeling optimized by dialogue acts", "journal": "", "year": "2018", "authors": "Chih-Wen Goo; Yun-Nung Chen"}, {"title": "A survey of text summarization extractive techniques", "journal": "", "year": "2010", "authors": "Vishal Gupta; Gurpreet Singh Lehal"}, {"title": "Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward", "journal": "", "year": "2020", "authors": "Luyang Huang; Lingfei Wu; Lu Wang"}, {"title": "Enhanced story representation by conceptnet for predicting story endings", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Shanshan Huang; Kenny Q Zhu; Qianzi Liao; Libin Shen; Yinggong Zhao"}, {"title": "Visualizing argumentation: Software tools for collaborative and educational sensemaking", "journal": "Springer Science & Business Media", "year": "2012", "authors": "A Paul;  Kirschner; J Simon; Chad S Buckingham-Shum;  Carr"}, {"title": "Opennmt: Open-source toolkit for neural machine translation", "journal": "", "year": "2017", "authors": "Guillaume Klein; Yoon Kim; Yuntian Deng; Jean Senellart; Alexander M Rush"}, {"title": "A guideline of selecting and reporting intraclass correlation coefficients for reliability research", "journal": "Journal of chiropractic medicine", "year": "2016", "authors": "K Terry; Mae Y Koo;  Li"}, {"title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension", "journal": "", "year": "2020", "authors": "Mike Lewis; Yinhan Liu; Naman Goyal ; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"}, {"title": "Keep meeting summaries on topic: Abstractive multi-modal meeting summarization", "journal": "", "year": "2019", "authors": "Manling Li; Lingyu Zhang; Ji Heng; Richard J Radke"}, {"title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics", "journal": "", "year": "2004", "authors": "Chin-Yew Lin; Franz Josef Och"}, {"title": "Automatic dialogue summary generation for customer service", "journal": "Association for Computing Machinery", "year": "2019", "authors": "Chunyi Liu; Peng Wang; Jiang Xu; Zang Li; Jieping Ye"}, {"title": "Conceptnet -a practical commonsense reasoning tool-kit", "journal": "BT Technology Journal", "year": "2004", "authors": "H Liu; P Singh"}, {"title": "Text summarization with pretrained encoders", "journal": "", "year": "2019", "authors": "Yang Liu; Mirella Lapata"}, {"title": "Topic-aware pointergenerator networks for summarizing spoken conversations", "journal": "", "year": "2019", "authors": "Zhengyuan Liu; Angela Ng; Sheldon Lee; Ai Ti Aw; Nancy F Chen"}, {"title": "The Stanford CoreNLP natural language processing toolkit", "journal": "Association for Computational Linguistics", "year": "2014", "authors": "Christopher Manning; Mihai Surdeanu; John Bauer; Jenny Finkel; Steven Bethard; David Mcclosky"}, {"title": "On faithfulness and factuality in abstractive summarization", "journal": "Association for Computational Linguistics", "year": "2020", "authors": "Joshua Maynez; Shashi Narayan; Bernd Bohnet; Ryan Mcdonald"}, {"title": "Using question-answer pairs in extractive summarization of email conversations", "journal": "", "year": "2007", "authors": "K Mckeown; Lokesh Shrestha; Owen Rambow"}, {"title": "Using summarization to discover argument facets in online idealogical dialog", "journal": "Association for Computational Linguistics", "year": "2015", "authors": "Amita Misra; Pranav Anand; Jean E Fox Tree; Marilyn Walker"}, {"title": "An introduction to discourse analysis. theory and method", "journal": "", "year": "2001", "authors": "Beverly Moser"}, {"title": "Extractive summarization of meeting recordings", "journal": "", "year": "2005", "authors": "Gabriel Murray; S Renals; J Carletta"}, {"title": "Incorporating speaker and discourse features into speech summarization", "journal": "", "year": "2006", "authors": "Gabriel Murray; Steve Renals; Jean Carletta; Johanna Moore"}, {"title": "Ranking sentences for extractive summarization with reinforcement learning", "journal": "", "year": "2018", "authors": "Shashi Narayan; B Shay; Mirella Cohen;  Lapata"}, {"title": "A deep reinforced model for abstractive summarization", "journal": "", "year": "2018", "authors": "Romain Paulus; Caiming Xiong; Richard Socher"}, {"title": "Joint modeling of content and discourse relations in dialogues", "journal": "Long Papers", "year": "2017", "authors": "Kechen Qin; Lu Wang; Joseph Kim"}, {"title": "A neural attention model for abstractive sentence summarization", "journal": "Association for Computational Linguistics", "year": "2015", "authors": "Alexander M Rush; Sumit Chopra; Jason Weston"}, {"title": "A simplest systematics for the organization of turn taking for conversation", "journal": "Elsevier", "year": "1978", "authors": "Harvey Sacks; A Emanuel; Gail Schegloff;  Jefferson"}, {"title": "Get to the point: Summarization with pointergenerator networks", "journal": "Long Papers", "year": "2017", "authors": "Abigail See; J Peter; Christopher D Liu;  Manning"}, {"title": "Unsupervised abstractive meeting summarization with multisentence compression and budgeted submodular maximization", "journal": "Long Papers", "year": "2018", "authors": "Guokan Shang; Wensi Ding; Zekun Zhang; Antoine Tixier; Polykarpos Meladianos; Michalis Vazirgiannis; Jean-Pierre Lorr\u00e9"}, {"title": "A deep sequential model for discourse parsing on multi-party dialogues", "journal": "", "year": "2019", "authors": "Zhouxing Shi; Minlie Huang"}, {"title": "The ucf podcast summarization system at trec 2020", "journal": "", "year": "2020", "authors": "Kaiqiang Song; Chen Li; Xiaoyang Wang; Dong Yu; Fei Liu"}, {"title": "Situated utterances and discourse relations", "journal": "", "year": "2013", "authors": "Matthew Stone; Una Stojnic; Ernest Lepore"}, {"title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"}, {"title": "Graph attention networks", "journal": "", "year": "2018", "authors": "Petar Veli\u010dkovi\u0107; Guillem Cucurull; Arantxa Casanova; Adriana Romero; Pietro Li\u00f2; Yoshua Bengio"}, {"title": "Domainindependent abstract generation for focused meeting summarization", "journal": "Long Papers", "year": "2013", "authors": "Lu Wang; Claire Cardie"}, {"title": "Discourse-aware neural extractive text summarization", "journal": "", "year": "2020", "authors": "Jiacheng Xu; Zhe Gan; Yu Cheng; Jingjing Liu"}, {"title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization", "journal": "", "year": "2019", "authors": "Jingqing Zhang; Yao Zhao; Mohammad Saleh; Peter J Liu"}, {"title": "Abstractive meeting summarization via hierarchical adaptive segmental network learning", "journal": "", "year": "2019", "authors": "Zhou Zhao; Haojie Pan; Changjie Fan; Yan Liu; Linlin Li; Min Yang; Deng Cai"}, {"title": "Boosting factual correctness of abstractive summarization with knowledge graph", "journal": "ArXiv", "year": "2003", "authors": "Chenguang Zhu; William Hinthorn; Ruochen Xu; Michael Qing Kai Zeng; Xuedong Zeng; Meng Huang;  Jiang"}, {"title": "A hierarchical network for abstractive meeting summarization with cross-domain pretraining", "journal": "", "year": "2020", "authors": "Chenguang Zhu; Ruochen Xu; Michael Zeng; Xuedong Huang"}, {"title": "A Discourse Relation Distributions We pre-trained a deep sequential model", "journal": "2019) on STAC Corpus", "year": "", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: An example of discourse relation graph (a) and action graph (b) from one conversation in SAM-Sum(Gliwa et al., 2019). The annotated summary is Simon was on the phone before, so he didn't here Helen calling. Simon will fetch Helen some tissues.", "figure_data": ""}, {"figure_label": "2", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Model architecture. Each utterance is encoded via transformer encoder; discourse relation graphs and action graphs are encoded through Graph Attention Networks (a). The multi-granularity decoder (b) then generates summaries based on all levels of encoded information including utterances, action graphs, and discourse graphs.", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Averaged \u03b1 over decoder layers in the trained S-BART models using different graphs", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Conv # Participants # Turns # Discourse Edges # Action Triples", "figure_data": "Train 147322.4011.178.476.72SAMSumVal8182.3910.838.346.48Test8192.3611.258.636.81ADSCFull452.007.516.5137.20"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Statistics of the used datasets, including the total number of conversations (# Conv), the average number of participants, turns, discourse edges and action triples per conversation.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Chen and Yang, 2020) 45.56 52.13 44.68 22.30 25.58 22.03 44.70 50.82 43.29 BART (Lewis et al., 2020) 45.15 49.58 45.97 21.66 23.95 22.16 44.46 48.92 44.26 S-BART w. Discourse \u2020 45.89 51.34 45.87 22.50 25.26 22.33 44.83 49.93 44.17 S-BART w. Action \u2020 45.67 50.25 46.44 22.39 24.70 22.96 44.86 49.29 44.75 S-BART w. Discourse&Action \u2020 46.07 51.13 46.24 22.60 25.11 22.81 45.00 49.82 44.47", "figure_data": "ModelFROUGE-1 PRFROUGE-2 PRFROUGE-L PRPointer Generator (See et al., 2017)40.08--15.28--36.63--Transformer (Vaswani et al., 2017)37.27--10.76--32.73--D-HGN (Feng et al., 2020)42.03--18.07--39.56--Multi-view Seq2Seq ("}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "ROUGE-1, ROUGE-2 and ROUGE-L scores for different models on the SAMSum Corpus test set. Results are averaged over three random runs. \u2020 means our methods. We performed Pitman's permutation test", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "", "figure_data": ":Human evaluation on Factualness,Succinctness, Informativeness."}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "ROUGE-1, ROUGE-2 and ROUGE-L scores of S-BART with either the constructed discourse relation graphs or random graphs. Results are averaged over three random runs.", "figure_data": "Combination StrategyR-1R-2R-LParallel46.07 22.60 45.00Sequential (discourse, action)45.40 22.14 44.67Sequential (action, discourse) 45.62 22.41 44.62"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "", "figure_data": ": ROUGE-1, ROUGE-2 and ROUGE-L scoresof S-BART models using different ways to combine dis-course relation graphs and action graphs. Results areaveraged over three random runs."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Conversations # Num # Dis. # Act.", "figure_data": "Test Set8198.636.81Similar3738.316.36Increase2089.137.40Challenging1609.587.85"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "The total number of examples, average number of Discourse edges and Action triples in different set of conversations in the SAMSUM test set.", "figure_data": ""}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "", "figure_data": ": (i) Similar: examples whereS-BART generated similar ROUGE scores (the dif-ferences were less than 0.1) compared to BART;(ii) Increase: examples where S-BART resulted inhigher ROUGE scores (the differences were largerthan 1.0) compared to BART; (iii) Challenging:"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "Lewis et al., 2020)  45.15 49.58 45.97 21.66 23.95 22.16 44.46 48.92  44.26 S-BART w. Discourse \u03b1 = 0 \u2020 45.40 50.22 45.86 21.96 24.49 22.25 44.56 49.32 44.13 S-BART w. Action \u03b1 = 0 \u2020 45.47 50.82 45.42 22.23 24.96 22.34 44.55 49.69 43.75 S-BART w. Discourse&Action \u03b1 = 0 \u2020 45.59 51.47 45.09 22.42 25.51 22.27 44.67 50.24 43.52 S-BART w. Discourse \u03b1 = 1 \u2020 45.89 51.34 45.87 22.50 25.26 22.33 44.83 49.93 44.17 S-BART w. Action \u03b1 = 1 \u2020 45.67 50.25 46.44 22.39 24.70 22.96 44.86 49.29 44.75 S-BART w. Discourse&Action \u03b1 = 1 \u2020 46.07 51.13 46.24 22.60 25.11 22.81 45.00 49.82 44.47", "figure_data": "ModelFROUGE-1 PRFROUGE-2 PRFROUGE-L PRBART ("}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "Results on SAMSum Corpus. ROUGE-1, ROUGE-2 and ROUGE-L scores for different models on the test set. Results are averaged over three random runs. \u2020 means our methods.", "figure_data": "Discourse Type SAMSum ADSCComment19.3%42.7%Clarification15.2%13.3%Elaboration2.3%0.1%Acknowlegement8.4%0.9%Explanation2.8%0.3%Conditional0.2%0%QA pair21.5%12.3%Alternation0.3%0.6%Result5.5%0.2%Backgraound0.4%0%Narration0.4%0%Correction0.4%1.1%Continuation0.9%7.5%Q-Elab2.5%0%Parallel0.9%0%Contrast1.0%19.5%"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "The distribution of predicted discourse relation types on SAMSum Corpus and ADSC Corpus.", "figure_data": ""}], "doi": "10.3115/v1/P15-1034"}