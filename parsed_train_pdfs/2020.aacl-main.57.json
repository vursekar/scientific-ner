{"authors": "Jack G M Fitzgerald", "pub_date": "", "title": "STIL -Simultaneous Slot Filling, Translation, Intent Classification, and Language Identification: Initial Results using mBART on MultiATIS++", "abstract": "Slot-filling, Translation, Intent classification, and Language identification, or STIL, is a newly-proposed task for multilingual Natural Language Understanding (NLU). By performing simultaneous slot filling and translation into a single output language (English in this case), some portion of downstream system components can be monolingual, reducing development and maintenance cost. Results are given using the multilingual BART model (Liu et al., 2020) fine-tuned on 7 languages using the MultiATIS++ dataset. When no translation is performed, mBART's performance is comparable to the current state of the art system (Cross-Lingual BERT by Xu et al. ( 2020)) for the languages tested, with better average intent classification accuracy (96.07% versus 95.50%) but worse average slot F1 (89.87% versus 90.81%). When simultaneous translation is performed, average intent classification accuracy degrades by only 1.7% relative and average slot F1 degrades by only 1.2% relative.", "sections": [{"heading": "Introduction", "text": "Multilingual Natural Language Understanding (NLU), also called cross-lingual NLU, is a technique by which an NLU-based system can scale to multiple languages. A single model is trained on more than one language, and it can accept input from more than one language during inference. In most recent high-performing systems, a model is first pre-trained using unlabeled data for all supported languages and then fine tuned for a specific task using a small set of labeled data (Conneau and Lample, 2019;Pires et al., 2019).\nTwo typical tasks for goal-based systems, such as virtual assistants and chatbots, are intent classification and slot filling (Gupta et al., 2006). Though intent classification creates a language agnostic output (the intent of the user), slot filling does not.  Instead, a slot-filling model outputs the labels for each of input tokens from the user. Suppose the slot-filling model can handle L languages. Downstream components must therefore handle all L languages for the full system to be multilingual across L languages. Machine translation could be performed before the slot filling model at system runtime, though the latency would be fully additive, and some amount of information useful to the slotfilling model may be lost. Similarly, translation could occur after the slot-filling model at runtime, but slot alignment between the source and target language is a non-trivial task (Jain et al., 2019;Xu et al., 2020). Instead, the goal of this work was to build a single model that can simultaneously translate the input, output slotted text in a single language (English), classify the intent, and classify the input language (See Table 1). The STIL task is defined such that the input language tag is not given to the model as input. Thus, language identification is necessary so that the system can communicate back to the user in the correct language.  In all STIL cases, the output is in English. Each token is followed by its BIO-tagged slot label. The sequence of tokens and slots are followed by the intent and then the language.\nsification, and Language identification (STIL); (2) both non-translated and STIL results using the mBART model (Liu et al., 2020) trained using a fully text-to-text data format; and (3) public release of source code used in this study, with a goal toward reproducibility and future work on the STIL task 1 .", "n_publication_ref": 6, "n_figure_ref": 0}, {"heading": "Dataset", "text": "The Airline Travel Information System (ATIS) dataset is a classic benchmark for goal-oriented NLU (Price, 1990;Tur et al., 2010). It contains utterances focused on airline travel, such as how much is the cheapest flight from Boston to New York tomorrow morning? The dataset is annotated with 17 intents, though the distribution is skewed, with 70% of intents being the flight intent. Slots are labeled using the Beginning Inside Outside (BIO) format. ATIS was localized to Turkish and Hindi in 2018, forming MultiATIS (Upadhyay et al., 2018), and then to Spanish, Portuguese, German, French, Chinese, and Japanese in 2020, forming Multi-ATIS++ (Xu et al., 2020). In this work, Portuguese was excluded due to a lack of Portuguese pretraining in the publicly available mBART model, and Japanese was excluded due to a current lack of alignment between Japanese and English samples in MultiATIS++. Hindi and Turkish data were taken from Multi-ATIS, and the training data were upsampled by 3x for Hindi and 7x for Turkish. Prior to any upsampling, there were 4,488 training samples for English, Spanish, German, French, and Chinese. The test sets contained 893 samples for all languages except Turkish, which had 715 samples.\nFor English, Spanish, German, French, and Chinese, validation sets of 490 samples were used in all cases. Given the smaller data quantities for Hindi and Turkish, two training and validation set configurations were considered. The first configuration", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Related Work", "text": "Previous approaches for intent classification and slot filling have used either (1) separate models for slot filling, including support vector machines (Moschitti et al., 2007), conditional random fields (Xu and Sarikaya, 2014), and recurrent neural networks of various types (Kurata et al., 2016) or (2) joint models that diverge into separate decoders or layers for intent classification and slot filling (Xu and Sarikaya, 2013;Guo et al., 2014;Liu and Lane, 2016;Hakkani-T\u00fcr et al., 2016) or that share hidden states (Wang et al., 2018). In this work, a fully text-to-text approach similar to that of the T5 model was used, such that the model would have maximum information sharing across the four STIL sub-tasks.\nEncoder-decoder models, first introduced in 2014 (Sutskever et al., 2014), are a mainstay of neural machine translation. The original transformer model included both an encoder and a decoder (Vaswani et al., 2017). Since then, much of the work on transformers focuses on models with only an encoder pretrained with autoencoding techniques (e.g. BERT by Devlin et al. (2018)) or auto-regressive models with only a decoder (e.g.\nGPT by Radford (2018)). In this work, it was assumed that encoder-decoder models, such as BART (Lewis et al., 2019) and T5 (Raffel et al., 2019), are the best architectural candidates given the translation component of the STIL task, as well as past state of the art advancement by encoder-decoder models on ATIS, cited above. Rigorous architectural comparisons are left to future work.", "n_publication_ref": 14, "n_figure_ref": 0}, {"heading": "The Model", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "The Pretrained mBART Model", "text": "The multilingual BART (mBART) model architecture was used (Liu et al., 2020), as well as the pretrained mBART.cc25 model described in the same paper. The model consists of 12 encoder layers, 12 decoder layers, a hidden layer size of 1,024, and 16 attention heads, yielding a parameter count of 680M. The mBART.cc25 model was trained on 25 languages for 500k steps using a 1.4 TB corpus of scraped website data taken from Common Crawl (Wenzek et al., 2019). The model was trained to reconstruct masked tokens and to rearrange scrambled sentences. SentencePiece tokenization (Kudo and Richardson, 2018) was used for mBART.cc25 with a sub-word vocabulary size of 250k.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "This Work", "text": "The same vocabulary as that of the pretrained model was used for this work, and SentencePiece tokenization was performed on the full sequence, including the slot tags, intent tags, and language tags. For all mBART experiments and datasets, data from all languages were shuffled together. The fairseq library was used for all experimentation (Ott et al., 2019).\nTraining was performed on 8 Nvidia V100 GPUs (16 GB) using a batch size of 32, layer normalization for both the encoder and the decoder (Xu et al., 2019); label smoothed cross entropy with = 0.2 (Szegedy et al., 2016); the ADAM optimizer with \u03b2 1 = 0.9 and \u03b2 2 = 0.999 (Kingma and Ba, 2014); an initial learning rate of 3 \u00d7 10 \u22125 with polynomial decay over 20,000 updates after 1 epoch of warmup; attention dropout of 0.1 and dropout of 0.2 elsewhere; and FP16 type for weights. Each model was trained for 19 epochs, which took 5-6 hours.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Results and Discussion", "text": "Results from the models are given in Table 3. Statistical significance was evaluated using the Wilson method (Wilson, 1927) with 95% confidence. Xu et al. (2020) Examining the first training configuration (1,496 samples for Hindi and 626 for Turkish), the nontranslated mBART's macro-averaged intent classification (96.07%) outperforms Cross-Lingual BERT by Xu et al. (2020) (95.50%), but slot F1 is worse (89.87% for non-translated mBART and 90.81% for Cross-Lingual BERT). The differences are statistically significant in both cases.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Comparing to", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "With and Without Translation", "text": "When translation is performed (the STIL task), intent classification accuracy degrades by 1.7% relative from 96.07% to 94.40%, and slot F1 degrades by 1.2% relative from 89.87% to 88.79%. The greatest degradation occurred for utterances involving flight number, airfare, and airport name (in that order).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Additional Hindi and Turkish Training Data", "text": "Adding 105 more Hindi and 12 more Turkish training examples results in improved performance for the translated, STIL mBART model. Macro-averaged intent classification improves from 94.40% to 95.94%, and slot F1 improves from 88.79% to 90.10%, both of which are statistically significant. By adding these 117 samples, the STIL mBART model matches the performance (within confidence intervals) of the non-translated mBART model. This finding suggests that the STIL models may require more training data than traditional, non-translated slot filling models. Additionally, by adding more Hindi and Turkish data, both the intent accuracy and the slot filling F1 improves for every individual language of the translated, STIL models, suggesting that some portion of the internal, learned representation is language agnostic.\nFinally, the results suggest that there is a trainingsize-dependent performance advantage in using a single output language, as contrasted with the nontranslated mBART model, for which the intent classification accuracy and slot F1 does not improve (with statistical significance) when using the additional Hindi and Turkish training samples.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Language Identification", "text": "Language identification F1 is above 99.7% for all languages, with perfect performance in many cases.  (Qin et al., 2019) 97.5 Joint BERT + CRF (Chen et al., 2019) 97.9\nNon-translated mBART, with  Perfect performance on Chinese and Hindi is unsurprising given their unique scripts versus the other languages tested.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Conclusion", "text": "This preliminary work demonstrates that a single NLU model can perform simultaneous slot filling, translation, intent classification, and language identification across 7 languages using MultiATIS++. Such an NLU model would negate the need for multiple-language support in some portion of downstream system components. Performance is not irreconcilably worse than traditional slot-filling models, and performance is statistically equivalent with a small amount of additional training data. Looking forward, a more challenging dataset is needed to further develop the translation compo-nent of the STIL task. The English MultiATIS++ test set only contains 455 unique entity-slot pairs. An ideal future dataset would include freeform and varied content, such as text messages, song titles, or open-domain questions. Until then, work remains to achieve parity with English-only ATIS models.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgments", "text": "The author would like to thank Saleh Soltan, Gokhan Tur, Saab Mansour, and Batool Haider for reviewing this work and providing valuable feedback.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Bert for joint intent classification and slot filling", "journal": "ArXiv", "year": "2019", "authors": "Qian Chen; Zhu Zhuo; Wen Wang"}, {"title": "Crosslingual language model pretraining", "journal": "Curran Associates, Inc", "year": "2019", "authors": "Alexis Conneau; Guillaume Lample"}, {"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2018", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"title": "Joint semantic utterance classification and slot filling with recursive neural networks", "journal": "IEEE Spoken Language Technology Workshop", "year": "2014", "authors": "Gokhan Daniel (zhaohan) Guo; Scott Tur; Yih Wen-Tau; Geoffrey Zweig"}, {"title": "The at t spoken language understanding system", "journal": "", "year": "2006", "authors": "N Gupta; G Tur; D Hakkani-Tur; S Bangalore; G Riccardi; M Gilbert"}, {"title": "Multi-domain joint semantic frame parsing using bi-directional rnn-lstm", "journal": "", "year": "2016", "authors": "Dilek Hakkani-T\u00fcr; Gokhan Tur; Asli Celikyilmaz; Yun-Nung Vivian Chen; Jianfeng Gao; Li Deng; Ye-Yi Wang"}, {"title": "Entity projection via machine translation for cross-lingual NER", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Alankar Jain; Bhargavi Paranjape; Zachary C "}, {"title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"title": "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing", "journal": "", "year": "2018", "authors": "Taku Kudo; John Richardson"}, {"title": "Leveraging sentence-level information with encoder lstm for semantic slot filling", "journal": "", "year": "2016", "authors": "Gakuto Kurata; Bing Xiang; Bowen Zhou; Mo Yu"}, {"title": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", "journal": "", "year": "2019", "authors": "Mike Lewis; Yinhan Liu; Naman Goyal ; Abdelrahman Mohamed; Omer Levy; Ves Stoyanov; Luke Zettlemoyer"}, {"title": "Attention-based recurrent neural network models for joint intent detection and slot filling", "journal": "", "year": "2016", "authors": "Bing Liu; Ian Lane"}, {"title": "Multilingual denoising pre-training for neural machine translation", "journal": "", "year": "2020", "authors": "Yinhan Liu; Jiatao Gu; Naman Goyal; Xian Li; Sergey Edunov; Marjan Ghazvininejad; Mike Lewis; Luke Zettlemoyer"}, {"title": "Spoken language understanding with kernels for syntactic/semantic structures", "journal": "", "year": "2007", "authors": "Alessandro Moschitti; Giuseppe Riccardi; Christian Raymond"}, {"title": "fairseq: A fast, extensible toolkit for sequence modeling", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Myle Ott; Sergey Edunov; Alexei Baevski; Angela Fan; Sam Gross; Nathan Ng; David Grangier; Michael Auli"}, {"title": "How multilingual is multilingual BERT?", "journal": "", "year": "2019", "authors": "Telmo Pires; Eva Schlinger; Dan Garrette"}, {"title": "Evaluation of spoken language systems: the ATIS domain", "journal": "", "year": "1990-06-24", "authors": "P J Price"}, {"title": "A stack-propagation framework with token-level intent detection for spoken language understanding", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Libo Qin; Wanxiang Che; Yangming Li; Haoyang Wen; Ting Liu"}, {"title": "Improving language understanding by generative pre-training", "journal": "", "year": "2018", "authors": "Alec Radford"}, {"title": "Exploring the limits of transfer learning with a unified text-to", "journal": "", "year": "2019", "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"}, {"title": "Don't parse, generate! a sequence to sequence architecture for task-oriented semantic parsing", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Subendhu Rongali; Luca Soldaini; Emilio Monti; Wael Hamza"}, {"title": "Sequence to sequence learning with neural networks", "journal": "MIT Press", "year": "2014", "authors": "Ilya Sutskever; Oriol Vinyals; V Quoc;  Le"}, {"title": "Rethinking the inception architecture for computer vision", "journal": "", "year": "2016", "authors": "Christian Szegedy; Vincent Vanhoucke; Sergey Ioffe; Jon Shlens; Zbigniew Wojna"}, {"title": "What is left to be understood in atis?", "journal": "", "year": "2010", "authors": "Gokhan Tur; Z Dilek; Larry Hakkani-T\u00fcr;  Heck"}, {"title": "2018. (almost) zeroshot cross-lingual spoken language understanding", "journal": "", "year": "", "authors": "Shyam Upadhyay; Manaal Faruqui; Gokhan Tur; Dilek Hakkani-T\u00fcr; Larry Heck"}, {"title": "Attention is all you need", "journal": "Curran Associates Inc", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Kaiser ; Illia Polosukhin"}, {"title": "A bimodel based RNN semantic frame parsing model for intent detection and slot filling", "journal": "", "year": "2018", "authors": "Yu Wang; Yilin Shen; Hongxia Jin"}, {"title": "Ccnet: Extracting high quality monolingual datasets from web crawl data", "journal": "", "year": "2019", "authors": "Guillaume Wenzek; Marie-Anne Lachaux; Alexis Conneau; Vishrav Chaudhary; Francisco Guzm\u00e1n; Armand Joulin; Edouard Grave"}, {"title": "Probable inference, the law of succession, and statistical inference", "journal": "Journal of the American Statistical Association", "year": "1927", "authors": "Edwin B Wilson"}, {"title": "Understanding and improving layer normalization", "journal": "Curran Associates, Inc", "year": "2019", "authors": "Jingjing Xu; Xu Sun; Zhiyuan Zhang; Guangxiang Zhao; Junyang Lin"}, {"title": "Convolutional neural network based triangular crf for joint intent detection and slot filling", "journal": "IEEE Workshop on Automatic Speech Recognition and Understanding", "year": "2013", "authors": "P Xu; R Sarikaya"}, {"title": "Targeted feature dropout for robust slot filling in natural language understanding", "journal": "", "year": "2014", "authors": "Puyang Xu; Ruhi Sarikaya"}, {"title": "End-to-end slot alignment and recognition for crosslingual nlu", "journal": "", "year": "2020", "authors": "Weijia Xu; Batool Haider; Saab Mansour"}], "figures": [{"figure_label": "", "figure_type": "", "figure_id": "fig_0", "figure_caption": "slots: (salt lake city, fromloc.cityname), . . . (oakland, toloc.cityname), . . . (california, toloc.statename) lang: zh", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "<B-fromloc.city name> lake <I-fromloc.city name> city <I-fromloc.city name> oakland <B-toloc.city name> california <B-toloc.state name> <intent-flight> <lang-de> \u4ece\u76d0\u6e56\u57ce\u5230\u52a0\u5dde\u5965\u514b\u5170 \u7684\u822a\u73ed salt <B-fromloc.city name> lake <I-fromloc.city name> city <I-fromloc.city name> oakland <B-toloc.city name> california <B-toloc.state name> <intent-flight> <lang-zh>", "figure_data": "Example InputExample Outputfl\u00fcge von salt lake citysaltnach oakland kalifornienContributions of this work include (1) the intro-duction of a new task for multilingual NLU, namelysimultaneous Slot filling, Translation, Intent clas-"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Two text-to-text STIL examples.", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Results are shown for intent accuracy, slot F1 score, and language identification F1 score. For English, Spanish, German, Chinese, and French in all of the models shown above (including other work), training sets were between 4,478 and 4,488 samples, and validation sets were between 490 and 500 samples. In this work, two training set sizes were used for Hindi and Turkish, denoted by \"tr=\" and \"with hi-tr val[idation set]\" or \"no hi-tr val[idation set]\". Across all work shown above, the tests sets contained 893 samples for all languages except Turkish, for which the test set was 715 samples.", "figure_data": ""}], "doi": "10.18653/v1/D19-1100"}