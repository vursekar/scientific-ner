{"authors": "Guy Tevet; Jonathan Berant", "pub_date": "", "title": "Evaluating the Evaluation of Diversity in Natural Language Generation", "abstract": "Despite growing interest in natural language generation (NLG) models that produce diverse outputs, there is currently no principled method for evaluating the diversity of an NLG system. In this work, we propose a framework for evaluating diversity metrics. The framework measures the correlation between a proposed diversity metric and a diversity parameter, a single parameter that controls some aspect of diversity in generated text. For example, a diversity parameter might be a binary variable used to instruct crowdsourcing workers to generate text with either low or high content diversity. We demonstrate the utility of our framework by: (a) establishing best practices for eliciting diversity judgments from humans, (b) showing that humans substantially outperform automatic metrics in estimating content diversity, and (c) demonstrating that existing methods for controlling diversity by tuning a \"decoding parameter\" mostly affect form but not meaning. Our framework can advance the understanding of different diversity metrics, an essential step on the road towards better NLG systems.", "sections": [{"heading": "Introduction", "text": "An important desideratum of natural language generation (NLG) systems is to produce outputs that are not only correct, but also diverse. For example, a dialog system (Adiwardana et al., 2020) should permit many responses for the prompt \"How are you today?\". Similarly, we expect diverse responses in tasks such as story generation (Li et al., 2018), question generation (Pan et al., 2019) and question answering (Fan et al., 2019).\nDespite growing effort to produce more diverse models (Li et al., 2016c,a;Holtzman et al., 2019;Du and Black, 2019), there is no standard evaluation metric for measuring diversity. Thus, different papers evaluate diversity differently (if at Set A \u2022 Pretty much everything.\n\u2022 Nothing, really.\n\u2022 You won't believe what happened! \u2022 Why do you even care?\n\u2022 What were you doing that was more important than this?", "n_publication_ref": 7, "n_figure_ref": 0}, {"heading": "Set B", "text": "\u2022 Not much.\n\u2022 It was pretty dull.\n\u2022 Blah, you didn't miss anything.\n\u2022 Not anything that important.\n\u2022 Very little, it was uneventful.\nFigure 1: Diversity metric evaluation: we show two sets of responses to the same question, generated by crowdsourcing workers. While both sets are diverse in terms of form, only set A is diverse in terms of content. Each graph presents the distribution over a diversity metric for sets with high content diversity (blue) and low content diversity (orange). Distributions are approximated over 200 sets. We observe that the human score metric (absDHS) separates the two distributions, while an n-gram based metric (distinct-n) fails, illustrating that it does not capture content diversity. The dotted lines correspond to the specific sets A and B presented above. all), making it difficult to compare competing approaches (Hashimoto et al., 2019). Having a principled and consensual diversity evaluation metric is hence fundamental for the field of NLG.\nA key challenge in developing diversity evaluation metrics, is the difficulty in determining their efficacy. Unlike metrics for evaluating the quality of generated text, where one can measure correlation between a metric (such as BLEU (Papineni et al., 2002)) and human judgement (Zhang et al., 2019a;Sagarkar et al., 2018), it is unknown if hu-mans can reliably estimate diversity.\nIn this paper, we propose a framework for evaluating diversity metrics (Figure 2). We assume that a tester (human or model) is generating sets of sentences, conditioned on some diversity parameter that controls the diversity of the output sentences. We evaluate the diversity of the sentences using a proposed metric, and measure correlation between the metric and the diversity parameter. High correlation indicates that the metric captures how the diversity parameter affects the model output.\nWe instantiate this framework with two tests. As a preliminary step, we introduce the decoding test: the tester is a neural generation model and the diversity parameter is a decoding parameter, such as softmax temperature (Ackley et al., 1985). This parameter controls the skewness of the distribution in every generated token, and has been shown to affect model diversity (Holtzman et al., 2019;Caccia et al., 2018). Then, we turn the focus to content diversity, introducing the content test (Figure 1). Here, the tester is a human, and the diversity parameter is a binary variable, where the human is instructed to generate sets of sentences with either high or low diversity in content.\nWe evaluate three families of popular diversity metrics with these tests: (a) n-gram-based metrics that estimate diversity based on surface patterns in a set of generated sentences, (b) neural metrics: we propose a reduction from evaluating sentence similarity to evaluating diversity, then evaluate diversity using state-of-the-art sentence similarity models, and (c) human evaluation: we explore multiple ways in which humans can be asked to estimate diversity, resulting in multiple Human Diversity Score (HDS) variations.\nApplying our tests leads to several findings: (i) In the decoding test, n-gram-based metrics correlate well with decoding parameters, such as softmax temperature. While the goal of our framework is to evaluate diversity metrics, this result lets us reflect back on the tester itself and conclude that decoding parameters predominantly control the form of text rather than content. (ii) Conversely, n-gram-based metrics perform poorly in the content test. While neural metrics outperform n-gram-based metrics, humans are substantially better than any automatic metric at detecting content diversity. This is illustrated in Figure 1, where a human clearly distinguishes between sets that have high (blue) and low (orange) content diver-sity, while n-gram-based metrics fail to do so.\nDue to this gap, we construct a large dataset focused on content-diversity metrics. We release the Metrics for content Diversity (McDiv) benchmark, a challenge for research in diversity evaluation.\nTo conclude, our main contributions are: \u2022 A framework for evaluating diversity metrics.\n\u2022 Tests instantiating this framework, measuring the sensitivity of metrics to diversity, with a focus on content diversity. \u2022 Best practices for obtaining diversity evaluations from crowdsourcing workers. \u2022 Establishing that humans outperform current automatic metrics in detecting content diversity. \u2022 The McDiv dataset -a benchmark for content diversity aware metrics. \u2022 The collected data, test scores and code are publicly available, 1 and can be used to easily compare new diversity metrics to existing results in our framework.", "n_publication_ref": 7, "n_figure_ref": 4}, {"heading": "Background: Diversity Evaluation", "text": "Recently, interest in diversity has increased (Du and Black, 2019;Holtzman et al., 2019), resulting in multiple proposals for its evaluation. We describe recent approaches, highlighting the need for a standard way to evaluate metrics.\nPerplexity is the standard metric in language modeling, measuring the proximity of a language model (LM), P LM , to the true distribution, P ref , by approximating the cross-entropy H(P ref , P LM ) with held-out data from P ref . Thus, perplexity captures to some extent diversity. For example, a dialog model that puts all probability mass on the output \"I don't know\" for any given context will obtain infinite perplexity once it encounters any other response. This property makes perplexity popular in LM-based NLG models, and often it is the only reported measure for diversity (Lewis et al., 2017;Fan et al., 2018;Wang et al., 2019;. However, perplexity does not purely measure diversity, and high perplexity does not entail low diversity. For example, a LM with a uniform distribution over the vocabulary for each decoded token has high diversity, but its perplexity will be extremely high, due to its low quality. Moreover, perplexity evaluates a LM, while the diversity of a NLG system is also strongly affected by the decoding procedure. For example, Top-k and nucleus sampling are popular decoding schemes that tradeoff quality and diversity by ignoring some of the LM probability mass (Holtzman et al., 2019).\nLast, some NLG models, such as Generative Adversarial Networks (GANs) (Yu et al., 2017) are not language models. While one can approximate perplexity for such models (Tevet et al., 2019), ideally, a metric should not be tied to a model. N-gram-based metrics A popular metric is distinct n-grams (Li et al., 2016b), which computes the proportion of unique n-grams out of the total number of n-grams in a set of generated sentences. Du\u0161ek et al. (2020) calculated Shannon entropy (Manning et al., 1999) based on different n-grams as a measure of lexical diversity. Self-BLEU (Zhu et al., 2018;Shu et al., 2019) measures the BLEU score of a generated sentence with respect to another generated sentence (rather than a gold reference). High average Self-BLEU indicates high similarity between generated sentences and low diversity. In \u00a75 we expand this idea and suggest a reduction from any similarity metric to a diversity metric. By design, n-gram based metrics are sensitive to diversity in the form of language, rather than its meaning.\nEmbedding-based metrics A new line of metrics suggests to embed generated sentences in latent space, then evaluate them in this space. Du and Black (2019) suggest to cluster the embedded sentences with k-means, then use its inertia as a measure for diversity. Recently, Lai et al. (2020) suggested to consider the volume induced by the embedded sentences as a diversity metric.  asked humans to evaluate the internal diversity of a generated essay. Ghandeharioun et al. (2019) let crowdsourcing workers interact with a dialog chat-bot, then asked them to evaluate the diversity of a single conversation. In contrast, this paper focuses on the diversity of different responses given a context, as in Zhang et al. (2019b).", "n_publication_ref": 17, "n_figure_ref": 0}, {"heading": "Human evaluation", "text": "To conclude, increasing interest in diversity resulted in multiple proposed diversity metrics. However, there is no consensus on how to evaluate diversity and what each metric actually measures.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Evaluating Diversity Metrics", "text": "We now describe our framework for evaluating diversity metrics. Diversity has many facets: for in-  stance, a set of sentences can be diverse in terms of their content, while another may have similar content, but diverse form (Figure 1). Our framework provides a way to evaluate metrics for different aspects of diversity under moderate assumptions.\nWe define a diversity metric m div (S c ) \u2208 R as a function that takes a set of generated responses S c as an input, and outputs a diversity score. Each response s \u2208 S c is generated for the same input context c, hence S c is a sample from a generative distribution P gen (s | c). The overall diversity score of a generative model can be obtained by averaging m div over sets S c sampled from the model given multiple contexts c \u2208 C.\nTo evaluate m div (\u2022), we assume access to some deterministic diversity parameter d that controls an aspect of diversity in S c . We test the relation between m div and the parameter d. By varying d and measuring m div , we can compute the correlation \u03c1 between m div and an aspect of diversity represented by d. Because our goal is to have metrics that rank the diversity of generated texts, we use Spearman's \u03c1 rank correlation as our test score. Figure 2 illustrates the flow of a test in our framework.\nIn practice, to control the diversity level of S c using d, we use a tester: a generative model that takes a context c and a diversity parameter d as input, and outputs a response set S c,d . We stress that the tester can be either a neural model or a human. A good tester should reliably represent the diversity level quantified by d.\nAs a hypothetical example, c can be a movie name and d represent sentiment diversity, that is, the number of different sentiments in a collection of reviews S c . A human tester can observe c and d, and produce reviews accordingly (such data can be easily mined from IMDB). A collection of such (d, S c,d ) makes a test, in which the correlation between m div (S c,d ) and d measures the sensitivity of m div to sentiment diversity.\nWe now describe two tests that instantiate this framework, roughly corresponding to the two main aspects of diversity: form diversity and content diversity.", "n_publication_ref": 0, "n_figure_ref": 2}, {"heading": "Decoding Test", "text": "The diversity of a NLG system constructed from a LM depends on both the LM but also the decoding algorithm on top of it. For example, beam search approximates the most probable output, and dramatically reduces diversity. Conversely, sampling from the LM leads to high diversity, but low quality output (Holtzman et al., 2019).\nA popular method to control diversity in NLG systems is to vary some decoding parameter. Variations include (a) softmax temperature (Ackley et al., 1985), where a parameter \u03c4 controls the skewness of the softmax distribution at each step, (b) Nucleus (Top-p) sampling (Holtzman et al., 2019), where one samples at each step from the minimal set of most probable tokens whose cumulative probability is at least p, and (c) Top-k sampling, which samples from the top-k most probable tokens at each step. All methods skew the LM distribution in a way that avoids low-probability tokens and leads to higher quality (Holtzman et al., 2019), providing a decoding parameter that trades off quality and diversity (Caccia et al., 2018).\nIn the decoding test (decTest), we define the tester to be a LM, such as GPT-2 (Radford et al., 2019), and the diversity parameter d to be a decoding parameter such as temperature. We check how different diversity metrics m div correlate with decoding parameters. This can shed light on the quality of the metrics, but also on how decoding parameters affect the output of a NLG system. The decoding test uses automatically-generated data that is cheap to produce, and decoding parameters that are well-known to control diversity. Thus, we view this test as a warm-up test to explore the strengths of our framework.", "n_publication_ref": 6, "n_figure_ref": 0}, {"heading": "Content Test", "text": "In the content test (conTest), our goal is to evaluate how different diversity metrics capture the notion of content diversity. Measuring content diversity requires deep understanding of the semantics of responses in S c .\nTo isolate content from form diversity, we aim to generate response sets with a similar level of form diversity, but where the level of content diversity is controlled by the diversity parameter d. In \u00a76, we will focus on whether automatic diversity metrics can perform as well as humans on the task of estimating content diversity.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Human Diversity Score", "text": "One of the core questions we tackle is: Can humans evaluate diversity reliably? Although a few papers (Ghandeharioun et al., 2019;Zhang et al., 2019b) asked humans to evaluate diversity, to the best of our knowledge no work thoroughly investigated this question. The importance of this question is clear when comparing to quality evaluation. There, human judgment is the gold standard, and automatic quality metrics are established by showing high correlation with human score. Thus, understanding if humans can judge diversity is important for improving diversity metrics. We use crowdsourcing workers 2 to compute a human diversity score: we show workers a context followed by a set of responses, and ask them to rate the diversity of the set.\nTo establish best practices, we experiment with multiple variations of HDS (detailed in \u00a76.2), asking humans to rate the diversity of a response set, and evaluating each practice with our framework. We focus on the following questions: \u2022 Should humans rate diversity of a set or similarity between pairs in the set, from which diversity can be inferred? (tl;dr: diversity) \u2022 Can humans evaluate different aspects of diversity well? (tl;dr: not effectively) \u2022 Should humans rate the absolute diversity score of a set of sentences or rank whether one set is more diverse than another? Here, we did not reach a conclusive result, and describe this experiment in the Appendix C. As a preliminary step, we conducted pilot experiments among a group of NLP graduate students. The main insights were: (a) humans are biased by quality: if a generated set has high diversity but low quality, humans will rate diversity low. To neutralize this, we explicitly ask workers to evaluate the quality of one of the responses in the set S c , and then instruct them to ignore quality in diversity questions; (b) To make sure a worker reads the context c, we ask them to generate a sentence s before they rate diversity; (c) It is difficult for workers to evaluate the diversity of a set with more than 10 responses. Our crowdsourcing tasks are provided in Appendix A.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Diversity to Similarity Reduction", "text": "We expand the idea from Zhu et al. (2018) and suggest a method to construct a diversity metric from any 2-sentence similarity metric. Given m sim (s 1 , s 2 ) \u2208 R, a symmetric similarity metric that gets a pair of input sentences (s 1 , s 2 ) and returns a similarity score, we can define a diversity metricm div as the negation of the mean similarity score across all (unordered) pairs of S c :\nm div (S c ) = \u2212 1 |Sc| 2 s i ,s j \u2208Sc,i>j m sim (s i , s j ).\nThis reduction allows us to easily define new diversity metrics based on past work on sentence similarity (Gomaa et al., 2013;Devlin et al., 2019;Zhang et al., 2019a;Reimers and Gurevych, 2019). In \u00a76 we show that both n-gram-based similarity metrics and neural semantic similarity metrics provide useful diversity metrics.\n6 Experiments", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "NLG Tasks", "text": "We apply our evaluation procedure on three different English NLG tasks that require diversity.\n\u2022 Story completion (storyGen); We use the ROC Stories dataset (Mostafazadeh et al., 2016), in which the context c is the first four sentences of a story, and the response s is a single sentence that ends the story. We use the contexts C from this data and generate response sets S c for each context using our testers. The long contexts characterizing this data narrow down the space of possible responses, making this a \"low-entropy\" generation task, where the output is constrained, but diversity is still essential. \u2022 Dialog response generation (respGen); A comment-response pairs dataset extracted from the website reddit.com and pre-processed by Hashimoto et al. (2019). We use the comments from their data as contexts C and generate response sets S c for each context using our testers. Since comments are single sentences the response is less constrained, making this a \"medium-entropy\" generation task. \u2022 3-words prompt completion (promptGen);\nContexts C are 3-words prompts, extracted from the Cornell Movie-Dialogs Corpus (Danescu-Niculescu-Mizil and Lee, 2011) by taking the first three words from each original context. The response sets S c are completions of the prompts, generated by our testers. This context provides minimal constraints, making this a \"highentropy\" generation task. Samples of the contexts extracted for each task, along with generated response sets, are presented in Appendix B. We intentionally avoid NLG tasks where diversity is not necessarily desired, such as summarization and machine translation.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Evaluated Metrics", "text": "N-gram-based metrics We evaluate distinct ngrams (distinct-n), as described in \u00a72. We also evaluate n-grams cosine similarity (cos-sim): a similarity measure computing the cosine between the vectors representing two sentences, where each vector is a count vector over the n-grams that appear in the response. We use the reduction from \u00a75 to convert this to a diversity measure. In both metrics, rather than choosing the order of the ngrams, we average over n \u2208 {1, . . . , 5}, which we found to outperform any single choice of n.\nNeural metrics We exploit existing BERT-based models (Devlin et al., 2019) fine-tuned for estimating similarity between two sentences (applying the reduction from \u00a75). BERT-STS; A BERT model fine-tuned on Semantic Textual Similarity (Cer et al., 2017): a collection of sentence pairs annotated with scores from 1-5 denoting their semantic similarity. 3 BERT-Score (Zhang et al., 2019a); Originally a quality metric, BERT-Score uses BERT's embeddings to measure similarity between two sen-tences. We used RoBERTa-large , as suggested by the authors. 4 Sentence-BERT (sent-BERT) (Reimers and Gurevych, 2019) is a sentence-level embedding model based on BERT. We use the cosine similarity between the embeddings of two responses as a similarity metric. In our experiments we used bert-large-nli-stsb-mean-tokens. 5 Human Metrics We examine four methods for evaluating diversity with humans (see \u00a74), to investigate best practices for obtaining diversity judgment from humans. In all metrics (except ranking), ratings are from 5 (highest diversity/similarity) to 1 (lowest). The original tasks presented to workers are in Appendix A.\nAbsolute HDS (absHDS); Given a context c and a set of generated responses S c , rate the level of diversity of S c . Ranking HDS (rnkHDS); Given a context c and two sets S c,d 1 , S c,d 2 generated with different values of the diversity parameter d, rate which set is more diverse. Since this metric did not clearly outperform absHDS, we provide results in Appendix C only. Similarity HDS (simHDS); Given a context c and a set of generated responses S c , rate the similarity of each two sentences in S c , and then apply the reduction from \u00a75. Aspect HDS (aspHDS); Identical to absHDS, except we explicitly ask about a specific aspect of diversity, namely form and content. 6", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "Decoding Test", "text": "In decTest we measure the correlation between diversity metrics (m div ) and the softmax temperature decoding parameter (d). The tester generating the response sets (S c ) is a neural NLG model. Response set (\u03c4 = 0.25)\n\u2022 It was a minor fire and they put it out.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\nResponse set (\u03c4 = 0.8)\n\u2022 They arrived and put out the fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It turned out to be a fire.\n\u2022 It was a minor fire night.\nResponse set (\u03c4 = 1.1)\n\u2022 It turned out to be a mechanic.\n\u2022 Before the fire was put out it was a fire.\n\u2022 It was a fire.\n\u2022 They co-worker matter how bad the fire was.\n\u2022 Several shells, the fire department came just in time. deviation. HDS metrics are computed over one experiment of 200 sets, due to their high cost. Data for storyGen and respGen was generated by the MASS model , fine-tuned on each dataset. Data for promptGen was generated by GPT-2-large (Radford et al., 2019) without fine-tuning. We provide examples for how story endings change as a function of temperature in Table 1. Examples for all tasks along with additional reproducibility details are in the Appendix B. For each HDS metric, we collected 10 ratings per query from Amazon Mechanical Turk (AMT) workers. While absHDS demands one query per response set, in order to perform simHDS at a reasonable cost, we chose |S c | = 5, resulting in 5 2 = 10 crowdsourcing queries instead of 10 2 = 45 per set. We evaluate simHDS only for respGen due to the metric's high cost and low performance.\nResults Table 2 presents results of absHDS, simHDS, and all automatic metrics. In general, ngram based metrics capture the diversity induced by a temperature sweep, beating HDS and neural metrics. Figure 3 provides a more detailed analysis. Each point represents a single set of responses generated at some temperature. While rank correlation for cosine similarity is high, it is  While our framework is meant to evaluate diversity metrics, the results of the test let us reflect on the decoding parameters themselves. This result shows that humans perform worse than automatic metrics in this experimental setup, hinting that temperature mostly controls superficial changes to the generated text. Additionally, simHDS performs worse than absHDS although it is 3x more expensive, showing that rating the entire set rather than averaging over pairs is useful.\nOther decoding parameters To compare the robustness of our conclusions to other decoding parameters, we repeat it with two additional decoding methods: (a) in Nucleus (Top-p) sampling we swept linearly over 100 values of p in the range [0.1, 1.0]; (b) In Top-k sampling we swept k in logarithmic scale over 100 values in the range [1, 30K] and present the correlation between the  metrics and log 10 (k). While softmax temperature enables skewing P LM to a more diverse P gen using \u03c4 > 1, both Top-p and Top-k enable only skewing P LM to a more sharp (hence less diverse) P gen . Table 3 presents results for all automatic metrics using the three decoding methods over prompt-Gen. Results for other tasks are in Appendix C. We find that Top-p correlates well with temperature along all three generation tasks, whereas Topk does not correlate with any of them.", "n_publication_ref": 2, "n_figure_ref": 1}, {"heading": "Content Test", "text": "In conTest, we measure the correlation between diversity metrics (m div ) and content diversity, represented by a binary parameter d \u2208 {0, 1}. The testers are AMT workers, guided to create sets with high level of form diversity and high or low content diversity according to d.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Data and settings", "text": "For each task, we collected 200 sets of 5 responses each (100 sets per class). For high content diversity class, we asked workers to give 5 responses per context, with as different content and structure as possible. Then we asked the same workers to choose a single response they wrote, and rephrase it 5 times such that the original content will be preserved, while changing the form -this set is used for the low content diversity class. A sample from this data is in Figure 1 and more samples in Appendix B. For each HDS metric, we collected 10 ratings from crowdsourcing workers, different than the ones who composed the sets.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Results", "text": "In addition to Spearman's \u03c1, we report the optimal single-threshold classifier accuracy (OCA), i.e., the best achievable accuracy in predicting the class of a response set (high or low content diversity) for any threshold \u03b7 on m div , such that if m div (S c ) > \u03b7 the classifier predicts high diversity, and otherwise predicts low diversity.\nTable 4 shows the results. N-gram-based metrics perform poorly, indicating they do not measure content diversity well. Neural models perform better than n-gram-based metrics (especially sent-BERT), but there is still a clear gap between automatic metrics and humans. Figure 4 illustrates the typical distributions of n-gram, neural and human metrics. Clearly, HDS separates high and low content diversity better than neural metrics. In addition, n-gram-based metrics saturate both classes to near maximal values, similarly to decTest.\nSince conTest isolates content diversity, we used aspHDS to directly rate content and form diversity. Content aspHDS gets similar scores to ab-sHDS, suggesting little gain in asking directly on the tested aspect. Form aspHDS gets low scores compared to absHDS, validating that the form diversity of the two classes is similar.   sets and 10 ratings per set for all experimentsthe minimal values in which results are confidently stable. Results are presented in Figure 5.", "n_publication_ref": 0, "n_figure_ref": 2}, {"heading": "Aspects of Diversity", "text": "In this work, we focused on the two primary aspects of diversity: content diversity (What to say?) and form diversity (How to say it?). In Figure 1, Both sets are diverse, but Set B is only form diverse, as all answers deliver the same massage, whereas Set A is diverse in both form and content.\nFurthermore, we can observe aspects of diversity as having a tree-like structure, where both content and form diversity can be divided to subaspects: Content diversity (e.g. answering the question \"How are you today?\") can be expressed by using different sentiment (\"I'm doing good.\" vs. \"I'm so glad you asked! I'm really doing good.\"), different relevance (\"I'm fine\" vs. \"Did you watch the game last night?\"), and more. Form diversity can be divided into sub-aspects as well: syntactic diversity (\"Someone took it from me.\" vs. \"It was taken from me.\") or lexical diversity (\"I feel fine.\" vs. \"I feel very well.\"). Even those sub-aspects can be further divided. For example, a sub-aspect of lexical diversity is register diversity (\"How are you?\" vs. \"Sup bro?\").\nAnother observation is that different aspects are not orthogonal, that is, changing one aspect may lead to changes in other aspects. Specifically, we observe that while it is relatively easy to produce high form diversity with low content diversity (Set B in Figure 1), it is almost impossible to diversify content without changing form. This observation was important during the design of conTest.", "n_publication_ref": 0, "n_figure_ref": 2}, {"heading": "Conclusions", "text": "This work presents a framework for evaluating diversity metrics as a step toward standardized evaluation. We limit the scope of this work to differ-ences between form and content diversity, which are key towards understanding different aspects of diversity. Future work can explore other aspects of diversity, e.g. testing sentiment diversity, as proposed in \u00a73. We urge researchers to use this framework as a platform for developing new diversity metrics and establishing their efficiency.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "A HDS Questionnaires", "text": "All Human scores for HDS metrics were collected using Amazon Mechanical Turk (AMT) crowdsourcing platform by English native-speaking workers that were specifically qualified for this task. Figure 7 presents the warm-up part, common for all HDS questionnaires. Before asking workers to rate the diversity of each set, we first asked them to generate a response for the context themselves, to make sure they read it. To neutralize the effect of the responses' quality on the workers, we also asked the workers to rate the quality of the first response in the set, then explicitly instructed them to ignore quality when rating diversity.\nFigures 8 to 11 present the diversity questions of absHDS, aspHDS, rnkHDS and simHDS as appeared in the AMT questionnaires.\nCosts For HDS metrics that require one query per response set (i.e. absHDS, rnkHDS, aspDHS), the cost for a single rating was 0.18$. We collected 10 ratings per response set, and conduct each experiment with 200 sets, hence the total cost for an experiment was 360$. In the case of simHDS, the response set size was 5, and the number of queries needed per set is 5 2 = 10. The cost of a single rating for this task was 0.056$, and with the same multipliers, the total cost for an experiment was 1120$, three times more expensive.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "B Data Samples", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "B.1 Decoding Test (decTest)", "text": "Tables 11 to 19 present data samples from sto-ryGen, respGen and promptGen with the neural testers of decTest, as detailed in \u00a76. Each table presents two contexts and three response sets per context. Each response set was generated with a different value of decoding parameter for the three decoding methods: softmax temperature, Nucleus sampling, and Top-k.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "B.2 Content Test (conTest)", "text": "Tables 20 to 22 present data samples from sto-ryGen, respGen and promptGen with the human testers of conTest, as detailed in \u00a76. Each table presents two contexts and two response sets per context -one for the low content diversity class and one for the high content diversity class.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "C Additional Experiments", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "C.1 Decoding Test (decTest)", "text": "Comparing decTest results of storyGen to other tasks (Table 2), this task is characterised with noisier scores for all metrics (Figures 3 and 6), hence lower \u03c1 values and higher variance. A possible explanation is larger effect of c on the distribution P gen (s|c) in this task.\nTables 3, 6 and 7, present decTest absolute scoring experiment using temperature, nucleus sampling and Top-k decoding parameters as d. Top-k consistently yields lower \u03c1 compared to other decoding parameters, especially for storyGen task. This implies that Top-k represents diversity less reliably than other methods.\nRanking experiment To examine whether we can improve correlation by asking humans to rank diversity, rather than providing an absolute score, we designed a ranking version of decTest. Each context is given along with two sets (5 samples each), produced with different temperature values. We sweep over temperature differences instead of the absolute temperature values. The human metric in this setting is rnkHDS (see \u00a76.2), and the automatic metrics are the difference between the scores each of the two sets got.\nWe report two measures; The first is Spearman's \u03c1 between the metric and the temperature difference. The second is accuracy, i.e., whether the metric can predict which set has higher temperature (e.g., in automatic metrics this is whether the sign of the temperature difference and the sign of metric score difference agree). 7 Table 5 summarizes the ranking test results. We observe that humans are better at ranking compared to giving absolute scores (Table 2), and are doing as well as automatic metrics. However, the scores of all automatic metrics also improve, making it difficult to separate between the different metrics.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "C.2 Metrics for Content Diversity (McDiv)", "text": "As elaborated in \u00a7 6.  tion between temperature differences and each metric score. Accuracy (acc) of classifying which set has the higher temperature. Standard deviation is up to 0.02 for all automatic metrics for both Spearman's correlation and accuracy.\nmetric to score zero correlation in conTest over this subset. The method of sub-sampling was meant to approximately equalize the distributions of the two classes, low and high content diversity, over the scores of distinct-n metric, and was performed as follows:\n\u2022 Sort all collected samples (from both low and high content diversity classes) according to their distinct-n score.\n\u2022 Divide the sorted samples to groups with fixed size (40 samples each in our case).\n\u2022 From each such group, randomly sample the same amount of samples for each of the two classes. For example, if a group contains 5 low content diversity samples and 35 high content diversity samples, we can sample at most 5 samples for each class.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Resutls", "text": "We applied conTest for all the collected data for each of the three NLG tasks (see Tables 8 and 9 10). Compared to Table 4, The gap between the best performing neural metrics (sent-BERT) and absHDS was increased in favor to HDS (0.04 compared to 0.1 difference in Spearman's \u03c1).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "D Additional Reproducibility Details", "text": "Collected data and code All the collected data, metric scores per samples for each of decTest and conTest, as well as code for running and visualizing the tests, are publicly available 8 . The collection methods are elaborated in Section 6.\nOriginal data We provide additional data for the original three datasets used in Section 6.\n\u2022 ROC Stories dataset 9 (Mostafazadeh et al., 2016) used for storyGen task contains 96K/1K/1K train/validation/test titles and five-sentence stories. We used the samples without pre-processing for both fine-tuning MASS model and generate samples for our tests.\n\u2022 Reddit comment-response dataset used for respGen task contains 37M /1M /1M train/validation/test comment -response pairs, extracted from the social website reddit.com scraped by pushshift.io followed by the pre-process described in (Hashimoto et al., 2019). We used the samples without further processing for both fine-tuning MASS model and generate samples for our tests. To the best of our knowledge, this dataset is not publicly available at the moment.\n\u2022 CMDC dataset 10 (Danescu-Niculescu-Mizil and Lee, 2011) contains 108K/30K train/test sentence-response pairs extracted from movie scripts. We extracted the first three words from the sentences (used as contexts for the original task) to be the context of our task. We did not use this data for training since we used GPT-2 without fine-tuning for promptGen.\nAuto-generated data For decTest, we used two pre-trained generative models for generating responses given the contexts:\n\u2022 For storyGen and respGen tasks, we used MASS 11        \u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He did not get to the meeting anymore.\n\u2022 He missed his meeting.\n\u2022 He passed out and failing the meeting \u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting.\n\u2022 He passed out and was kicked out of the meeting.\n\u2022 He missed his meeting.\n\u2022 He missed his meeting. Family Night Food. Tonight, my mom ordered Mexican food for family night. She got it from my favorite Mexican place in town. When it arrived, it was hot and smelled wonderful. We devoured it with gusto.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of eating everyone was satisfied.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of eating everyone was satisfied.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of take it home we all enjoyed its night.\n\u2022 After a few hours of eating everyone was satisfied.\n\u2022 After dinner, we all went home to cook Mexican food.\n\u2022 After a few hours of cooking she was tired and ready to eat.\n\u2022 After dinner, I always put got ready for Christmas.\n\u2022 After dinner, I helped her do the dishes.\n\u2022 After a few hours of dinner, the food was amazing.\n\u2022 After a few hours of take it home we all enjoyed margaria.\n\u2022 After dinner, I was ready to take on work the next day of \u2022 After dinner, I was sad to say goodbye to her \u2022 After a few hours of take it home we all enjoyed one bite.\n\u2022 After a few hours of eating everyone was satisfied.\n\u2022 Even though my stomach was gone, I was sad it was finally pockets \u2022 After dinner, I alone.\n\u2022 All in all the family while my mom finished the food.\n\u2022 After a few hours of dancing, she pianed.\n\u2022 Afterwards I'd never finish single night a week.\n\u2022 Afterwards we all went to sleep in my woods.\n\u2022 Afterwards I helped her do much better than my wife.\n\u2022 Afterwards my mom helped me finish my dinner.\n\u2022 After a few hours we all enjoyed storm blood from the Italy.\n\u2022 After dinner, we all enjoyed some good food together.   The worker is asked to generate response of hers/his own and rate the quality of the tester's response. \u2022 So that's the first time you want to punch somebody, not miss before.\" The Seahawks would! \u2022 So that's the science behind the Broadwell-E processors from Intel that Intel launched last fall! \u2022 So that's the instinct from other teams, that they're a headache. -Ramsay MacDonald,! \u2022 So that's the white whale right there about too much debt. And then what you! \u2022 So that's the end of our discussion about the causes. What happens when we look at the! \u2022 So that's the cover of inhibition against \"chronic\" or \"adaptive\" stimulants! \u2022 So that's the way the story goes, but exactly how is cloud providers going to restrict Their! \u2022 So that's the beginning, the beginning of the show, I guess five minutes.\" ! \u2022 So that's the Indie Mobile Game Week Honoring Winners!!!!!!!!! \u2022 So that's the reason I'm writing, that's why you don't understand why people know!\n\u2022 do you listen to the music?\" \"I don't know. I don't listen! \u2022 do you listen to them?\" \"I do,\" he said. \"I'm not! \u2022 do you listen to the voices of the people?\" \"I do,\" said the king! \u2022 do you listen to the song?\" \"I don't know . I don't know! \u2022 do you listen to the music?\" \"I do.\" \"You're not! \u2022 do you listen to the news? I do. I'm a big fan of the! \u2022 do you listen to me?\" \"Yes, I do.\" \"I'm! \u2022 do you listen to the other side?\" \"I don't know. I don't! \u2022 do you listen to the other side?\" \"I do,\" said the boy. \"! \u2022 do you listen to the news? No, I don't. I don't listen!\n\u2022 do you listen to the current draft? I listen to the current draft. I'm! \u2022 do you listen to it?\" It's easy to hear the \"why?\" but when! \u2022 do you listen to the people that come here?\" \"No, I'm too busy! \u2022 do you listen to the thing?\" \"Of course I do.   ", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Response set (high content diversity)", "text": "Response set (low content diversity) \u2022 Suppose there's an escape plan we haven't thought of yet.\n\u2022 Suppose there's an omelet that is the most amazing ever.\n\u2022 Suppose there's an airplane ticket that's even cheaper.\n\u2022 Suppose there's an actual deadline for this paper.\n\u2022 Suppose there's an event that we can go to this weekend.\n\u2022 Suppose there's an airline that costs less.\n\u2022 Suppose there's an flight that isn't as expensive.\n\u2022 Suppose there's an air travel fare, but doesn't cost as much.\n\u2022 Suppose there's an way to fly there that is low cost.\n\u2022 Suppose there's an flight going there and it's not a lot of money \u2022 Nothing remotely like eating a big breakfast.\n\u2022 Nothing remotely like dancing with your wife at the wedding.\n\u2022 Nothing remotely like singing Justin Bieber's greatest hits \u2022 Nothing remotely like falling down a hill \u2022 Nothing remotely like getting yelled at\n\u2022 Nothing remotely like being super full and satisfied.\n\u2022 Nothing remotely like getting to taste many different foods.\n\u2022 Nothing remotely like starting the day off right.\n\u2022 Nothing remotely like doing exactly what I want to do.\n\u2022 Nothing remotely like feeding myself with great food.    ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgements", "text": "We thank Aya Meltzer-Asscher for linguistic advice, and Or Nachmias, Ben Bogin, Mor Geva, Omer Goldman and Ohad Rubin for their useful suggestions and references. This research was partially supported by The Israel Science Foundation grant 942/16, The Yandex Initiative for Machine Learning and the European Research Council (ERC) under the European Union Horizons 2020 research and innovation programme (grant ERC DELPHI 802800).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Context", "text": "Response set (\u03c4 = 0.25) Response set (\u03c4 = 0.8) Response set (\u03c4 = 1.1) Fire next door. John woke up smelling like something was burning. He went outside. He saw the fire next door. He called the authorities.\n\u2022 It was a minor fire and they put it out.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a minor fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It was a minor fire and they put it out.\n\u2022 They arrived and put out the fire.\n\u2022 It was a fire.\n\u2022 It was a fire.\n\u2022 It turned out to be a fire.\n\u2022 It was a minor fire night.\n\u2022 They arrived and put it out.\n\u2022 It was a scary but beautiful fire next time he went in.\n\u2022 It was a fire.\n\u2022 It was a put out and John was able to put it out.\n\u2022 It was a scary place to live.\n\u2022 It turned out to be a mechanic.\n\u2022 Before the fire was put out it was a fire.\n\u2022 It was a fire.\n\u2022 They co-worker matter how bad the fire was.\n\u2022 Several shells, the fire department came just in time.\n\u2022 They arrived and put out the fire.\n\u2022 It turned out to be a clear, fact.\n\u2022 It was a fire.\n\u2022 It was a scary meal for wet clothes.\n\u2022 It was a scary stealing from him. Charles Shaves His Chest. Charles decides he no longer wants chest hair. He shaves his chest hair with a razor. Although his skin is irritated, he hair is now gone. Charles is satisfied.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is very happy to have a chest hair.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is very happy to have a chest hair.\n\u2022 He is glad that he finally shaved.\n\u2022 He is very happy that he no longer has chest hair.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that his chest hair is no longer shaved.\n\u2022 He is glad that he finally shaved \u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally of shaving.\n\u2022 He is glad that he finally shashock his chest hair.\n\u2022 He is glad that he finally peaceful his voice again.\n\u2022 He is glad that he finally shaavoided his chest hair.\n\u2022 He is glad that he finally downcome.\n\u2022 He is ready to start better cooperation his fireplace.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he no longer has chest hair.\n\u2022 He is happy to finally be shaved.\n\u2022 He is very happy to have ster good ride of his life.\n\u2022 He is glad that he finally shaved.\n\u2022 He is glad that he finally has chest hair. ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Context", "text": "Response set (k = 3) Response set (k = 32) Response set (k = 318) Loud Noise. Jane was trying to take a nap. She heard a loud bang in the kitchen. It woke her up. A dish had fallen off the counter.\n\u2022 Jane pulled over and started to clean herself.\n\u2022 Jane was horrified and dropped her favorite food.\n\u2022 Jane was able to finish her car and take a nap.\n\u2022 Jane was able to finish her nap .\n\u2022 Jane was able to finish her nap .\n\u2022 Jane stopped at the store to buy a new one.\n\u2022 Jane was able to grab a nap afterwards.\n\u2022 Jane was unable to finish her nap since it was lost.\n\u2022 Jane pulled over and started to clean up.\n\u2022 Jane was able to finish her nap .\n\u2022 Jane was able to catch a car using the seat.\n\u2022 Jane stopped at the store to buy a new book.\n\u2022 Jane was sad her cat dropped out of the kitchen.\n\u2022 Jane screamed.\n\u2022 Jane was horrified to find her car broken down on the floor.\n\u2022 Jane was horrified and dropped her pay phone.\n\u2022 Jane was easily able to grab a nap.\n\u2022 Jane pulled over and started to cry.\n\u2022 Jane pulled over and started to cry.\n\u2022 Jane stopped at the store to buy a new dish from the store.\n\u2022 Jane comes, noticed a lot of food left under it.\n\u2022 Jane was horrified and dropped her book.\n\u2022 Jane remembered to take a nap.\n\u2022 Jane was since she took a nap while she waited for the refun \u2022 Jane knew she had no time to finish her book.\n\u2022 Jane was glad.\n\u2022 Jane was annoyed and began to cry.\n\u2022 Jane stopped at the store to buy a new one.\n\u2022 Jane wanted to have her car back.\n\u2022 Jane was monthed.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Headache.", "text": "Kate was wearing big over the ear headphones. But they were tight and squeezing her head. She tried to adjust them to relieve the tension. But nothing really worked.\n\u2022 Kate decided to go to the store and buy some ear phones.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to the store and buy some ear phones.\n\u2022 She decided to go buy a pair of headphones instead.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to the doctor and have some rest.\n\u2022 Kate decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to the store and buy some ear phones.\n\u2022 She decided to go buy some ear plugs.\n\u2022 She decided to go buy a hat so she could enjoy the the long lin \u2022 Kate decided to go to the store to buy some candy since she was ti \u2022 Kate decided to go outside to rest.\n\u2022 Kate decided to go to the store and buy some ran phones.\n\u2022 Kate decided to go to the store and buy some headphones instead.\n\u2022 Kate decided to go back to her old dishes.\n\u2022 She decided to go buy a big pair of headphones instead.\n\u2022 Kate decided to go to the store and wearing some headphones.\n\u2022 She was forced to go to the store to buy some cash.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to a ess instead.\n\u2022 Kate decided to go to the store and buy some fake headphones.\n\u2022 She decided to go to the store and buy some ear phones.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go to the store and buy some headphones instead.\n\u2022 She decided to go buy some ear phones.\n\u2022 Kate decided to go to the gym and use some saw no more watching T \u2022 Kate decided to go to the store and buy some cute phones.\n\u2022 She decided to go buy a fake headphones instead.\n\u2022 She decided to go to the store and buy some concert.   ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Context", "text": "Response set (k = 3) Response set (k = 32) Response set (k = 318) watching curry play in his prime is truly a privilege\n\u2022 i know i just dont want him to play for us \u2022 he has to be a good center for that \u2022 he is a great center of football in his prime \u2022 hes been playing in his prime for a long time \u2022 he was a great back in the day \u2022 hes been playing for a while now \u2022 i dont know about that he was pretty damn good at that \u2022 i dont think he was ever in his prime \u2022 i dont think he is a prime minister \u2022 i dont know why but i think he is a very good player and \u2022 and his career as well \u2022 agreed the way hes playing is awesome \u2022 it has to be \u2022 this is just called a job \u2022 and then being on the field for the first time \u2022 i dont see him doing that often enough \u2022 he just likes to party in the kitchen \u2022 at this point hes going to be a great star for the rest of the \u2022 only if he pays well \u2022 the only thing that can make that kind of difference is how much time you\n\u2022 yeah my feeling i mean we dont like it but it happens all the \u2022 you are one for real \u2022 they still have a rule saying they might not be injured yet \u2022 it really is a necessary thing to do \u2022 finally some reason to continue watching him at some point \u2022 yet that would be epic \u2022 not to mention eating curry dinner is a privilege \u2022 i just dont want to turn over for this goal like he does in \u2022 gt playing in his prime is truly a privilege ftfy \u2022 so is saying he is in high school im going this evening when she usually works\n\u2022 i think you accidentally a word \u2022 you are a good man \u2022 i hope she works \u2022 im going to the same time as you when she usually works \u2022 i am so sorry to hear that \u2022 i hope she works for you \u2022 i am so jealous of your work i am so jealous \u2022 i hope you have fun \u2022 i hope you get a job at a local bar \u2022 i hope she works for you  Response set (\u03c4 = 0.25)\nResponse set (\u03c4 = 0.8) Response set (\u03c4 = 1.1) \u2022 Not the hacking. The hacking is the fact that the DNC was hacked. ! \u2022 Not the hacking. The hacking is the real problem. The hacking is the! \u2022 Not the hacking of the DNC, but the leaks of the emails of the Democratic National Committee.! \u2022 Not the hacking, but the way it was done. The FBI's investigation into the! \u2022 Not the hacking of the DNC, but the hacking of the emails of the Democratic National Committee.! \u2022 Not the hacking of the DNC, but the leaking of the emails. The DNC's! \u2022 Not the hacking of the DNC. The hacking of the DNC was a \"false flag! \u2022 Not the hacking of the DNC. But the hacking of the RNC. The DNC hack! \u2022 Not the hacking. The hacking is the problem. The hacking is the problem! \u2022 Not the hacking of the DNC, but the leaking of the emails. The DNC was hacked,!\n\u2022 Not the hacking after all? I'm sure the nation-states that are involved in! \u2022 Not the hacking that happened on the internal networks of the Energy Department. In fact, according to! \u2022 Not the hacking of the American public but rather the fraudulent Heisenberg principle that seemed to be! \u2022 Not the hacking that took place in the DNC last year or the release of hacked emails during the! \u2022 Not the hacking futurists Cardboard inventor and self-described tinkerer Dennis! \u2022 Not the hacking alone. In the first half of the report, the hackers tried to create fake!   (Top-k). Bold text is the 3-words prompt context.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Context", "text": "Response set (high content diversity) Response set (low content diversity) Sold Out Jane wanted to watch a big new action movie. She had been waiting a long time for it to come out. When tickets became available she was too busy. By the time she had a chance to buy some it was sold out.\n\u2022 Jane cried over the fact that she couldn't watch it and just gave up looking for a ticket.\n\u2022 Jane decided to look for a scalper that would sell her the ticket for the movie that she really wanted to see.\n\u2022 Jane thought it was okay since she can still have a chance to watch it once it gets uploaded in video and movie streaming applications.\n\u2022 Jane posted a status on her social media accounts asking her friends for any spare ticket that she is willing to buy.\n\u2022 Jane resorted to contacting her old friend who is working at a huge movie theater hoping she can help her get a ticket.\n\u2022 Jane remembered that she has an old friend who is a manager at a big movie theater so she contacted that friend in the hopes that she can buy any spare ticket.\n\u2022 Desperate to watch the movie, Jane called her friend, who works at a movie theater, asking for a ticket to that movie.\n\u2022 Jane recalled that her friend works at a movie theater and hoped that she can help get a ticket for that movie.\n\u2022 Jane decided to look for her friend who could possibly have access to tickets for that movie since that friend currently works at a movie theater.\n\u2022 Jane realized that her friend might have spare tickets since she is a manager of a movie theater showing that film.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Beavers.", "text": "My friend has some beavers in his backyard. They come up from the creek by his house. He invites my over and we watch them. We take pictures of them and send them to our friends.\n\u2022 They are fascinating animals.\n\u2022 Our friends love getting the pictures.\n\u2022 Sometimes his dogs chase them.\n\u2022 They are building a dam on the creek.\n\u2022 They won't let us get too close to them.\n\u2022 They are busy gathering sticks to make a dam.\n\u2022 The dam they are building is almost complete. \u2022 It's fascinating to see their workmanship building a dam.\n\u2022 They are turning the creek into a pond by building a dam.\n\u2022 They all work together with careful engineering to build a dam. \u2022 I just got into this show and can't stop watching places apple slices in a bowl so they'll stay fresh\n\u2022 Oh boy, I love apples.\n\u2022 I don't need you telling me how to keep things fresh, take a hike.\n\u2022 Girl, you're the fresh one around here.\n\u2022 This post might be better in the life hacks section.\n\u2022 This is actually a useful bit of advice.\n\u2022 I find merit in this input.\n\u2022 That information will serve me well.\n\u2022 Thanks, that's really good to know! \u2022 Such knowledge is certainly beneficial.\n\u2022 Wise words, I will heed them. ", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "A learning algorithm for boltzmann machines", "journal": "Cognitive science", "year": "1985", "authors": "H David; Geoffrey E Ackley; Terrence J Hinton;  Sejnowski"}, {"title": "Towards a human-like opendomain chatbot", "journal": "", "year": "2020", "authors": "Daniel Adiwardana; Minh-Thang Luong; David R So; Jamie Hall; Noah Fiedel; Romal Thoppilan; Zi Yang; Apoorv Kulshreshtha; Gaurav Nemade; Yifeng Lu"}, {"title": "Language gans falling short", "journal": "", "year": "2018", "authors": "Massimo Caccia; Lucas Caccia; William Fedus; Hugo Larochelle; Joelle Pineau; Laurent Charlin"}, {"title": "Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation", "journal": "", "year": "2017", "authors": "Daniel Cer; Mona Diab; Eneko Agirre; I\u00f1igo Lopez-Gazpio; Lucia Specia"}, {"title": "Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs", "journal": "", "year": "2011", "authors": "Cristian Danescu-Niculescu-Mizil; Lillian Lee"}, {"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"title": "Boosting dialog response generation", "journal": "", "year": "2019", "authors": "Wenchao Du; Alan W Black"}, {"title": "Evaluating the state-of-the-art of end-to-end natural language generation: The e2e nlg challenge", "journal": "Computer Speech & Language", "year": "2020", "authors": "Ond\u0159ej Du\u0161ek; Jekaterina Novikova; Verena Rieser"}, {"title": "Eli5: Long form question answering", "journal": "", "year": "2019", "authors": "Angela Fan; Yacine Jernite; Ethan Perez; David Grangier; Jason Weston; Michael Auli"}, {"title": "Hierarchical neural story generation", "journal": "", "year": "2018", "authors": "Angela Fan; Mike Lewis; Yann Dauphin"}, {"title": "Approximating interactive human evaluation with self-play for open-domain dialog systems", "journal": "", "year": "2019", "authors": "Asma Ghandeharioun; Judy Hanwen Shen; Natasha Jaques; Craig Ferguson; Noah Jones; Agata Lapedriza; Rosalind Picard"}, {"title": "A survey of text similarity approaches", "journal": "International Journal of Computer Applications", "year": "2013", "authors": "H Wael;  Gomaa; A Aly;  Fahmy"}, {"title": "Unifying human and statistical evaluation for natural language generation", "journal": "", "year": "2019", "authors": "Tatsunori Hashimoto; Hugh Zhang; Percy Liang"}, {"title": "The curious case of neural text degeneration", "journal": "", "year": "2019", "authors": "Ari Holtzman; Jan Buys; Maxwell Forbes; Yejin Choi"}, {"title": "Diversity, density, and homogeneity: Quantitative characteristic metrics for text collections", "journal": "", "year": "2020", "authors": "Yi-An Lai; Xuan Zhu; Yi Zhang; Mona Diab"}, {"title": "Deal or no deal? end-to-end learning of negotiation dialogues", "journal": "", "year": "2017", "authors": "Mike Lewis; Denis Yarats; Yann Dauphin; Devi Parikh; Dhruv Batra"}, {"title": "A diversity-promoting objective function for neural conversation models", "journal": "", "year": "2016", "authors": "Jiwei Li; Michel Galley; Chris Brockett; Jianfeng Gao; Bill Dolan"}, {"title": "A diversity-promoting objective function for neural conversation models", "journal": "Association for Computational Linguistics", "year": "2016", "authors": "Jiwei Li; Michel Galley; Chris Brockett; Jianfeng Gao; Bill Dolan"}, {"title": "A simple, fast diverse decoding algorithm for neural generation", "journal": "", "year": "2016", "authors": "Jiwei Li; Will Monroe; Dan Jurafsky"}, {"title": "Generating long and informative reviews with aspect-aware coarse-to-fine decoding", "journal": "", "year": "2019", "authors": "Junyi Li; Wayne Xin Zhao; Ji-Rong Wen; Yang Song"}, {"title": "Generating reasonable and diversified story ending using sequence to sequence model with adversarial training", "journal": "", "year": "2018", "authors": "Zhongyang Li; Xiao Ding; Ting Liu"}, {"title": "Roberta: A robustly optimized bert pretraining approach", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"title": "Foundations of statistical natural language processing", "journal": "MIT press", "year": "1999", "authors": "D Christopher;  Manning; D Christopher; Hinrich Manning;  Sch\u00fctze"}, {"title": "A corpus and cloze evaluation for deeper understanding of commonsense stories", "journal": "", "year": "2016", "authors": "Nasrin Mostafazadeh; Nathanael Chambers; Xiaodong He; Devi Parikh; Dhruv Batra; Lucy Vanderwende; Pushmeet Kohli; James Allen"}, {"title": "Recent advances in neural question generation", "journal": "", "year": "2019", "authors": "Liangming Pan; Wenqiang Lei; Tat-Seng Chua; Min-Yen Kan"}, {"title": "Bleu: a method for automatic evaluation of machine translation", "journal": "Association for Computational Linguistics", "year": "2002", "authors": "Kishore Papineni; Salim Roukos; Todd Ward; Wei-Jing Zhu"}, {"title": "Language models are unsupervised multitask learners", "journal": "", "year": "2019", "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"}, {"title": "Sentencebert: Sentence embeddings using siamese bertnetworks", "journal": "", "year": "2019", "authors": "Nils Reimers; Iryna Gurevych"}, {"title": "Quality signals in generated stories", "journal": "", "year": "2018", "authors": "Manasvi Sagarkar; John Wieting; Lifu Tu; Kevin Gimpel"}, {"title": "Generating diverse translations with sentence codes", "journal": "", "year": "2019", "authors": "Raphael Shu; Hideki Nakayama; Kyunghyun Cho"}, {"title": "Mass: Masked sequence to sequence pre-training for language generation", "journal": "", "year": "2019", "authors": "Kaitao Song; Xu Tan; Tao Qin; Jianfeng Lu; Tie-Yan Liu"}, {"title": "Evaluating text gans as language models", "journal": "", "year": "2019", "authors": "Guy Tevet; Gavriel Habib; Vered Shwartz; Jonathan Berant"}, {"title": "Paperrobot: Incremental draft generation of scientific ideas", "journal": "", "year": "2019", "authors": "Qingyun Wang; Lifu Huang; Zhiying Jiang; Kevin Knight; Heng Ji; Mohit Bansal; Yi Luan"}, {"title": "Enhancing topic-to-essay generation with external commonsense knowledge", "journal": "", "year": "2019", "authors": "Pengcheng Yang; Lei Li; Fuli Luo; Tianyu Liu; Xu Sun"}, {"title": "Seqgan: Sequence generative adversarial nets with policy gradient", "journal": "", "year": "2017", "authors": "Lantao Yu; Weinan Zhang; Jun Wang; Yong Yu"}, {"title": "Bertscore: Evaluating text generation with bert", "journal": "", "year": "2019", "authors": "Tianyi Zhang; Varsha Kishore; Felix Wu; Q Kilian; Yoav Weinberger;  Artzi"}, {"title": "Syntax-infused variational autoencoder for text generation", "journal": "", "year": "2019", "authors": "Xinyuan Zhang; Yi Yang; Siyang Yuan; Dinghan Shen; Lawrence Carin"}, {"title": "Texygen: A benchmarking platform for text generation models", "journal": "", "year": "2018", "authors": "Yaoming Zhu; Sidi Lu; Lei Zheng; Jiaxian Guo; Weinan Zhang; Jun Wang; Yong Yu"}], "figures": [{"figure_label": "", "figure_type": "", "figure_id": "fig_0", "figure_caption": "So what did I miss in the first 20 minutes?", "figure_data": ""}, {"figure_label": "2", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: An overview of our diversity metrics evaluation framework. The tester (machine or human) generates a response set (S c,d ) given a diversity parameter (d) and a context (c). The test score of a metric mdiv is the correlation between the metric score for S c,d and d.", "figure_data": ""}, {"figure_label": "", "figure_type": "", "figure_id": "fig_2", "figure_caption": "Thus, we use crowdsourcing workers as testers, and a binary parameter d \u2208 {0, 1}, corresponding to low or high content diversity. A worker observes a context c and produces a set of responses S c based on the value of d. We encourage workers to use different words and phrases in different responses regardless of the value of d, such that form diversity is high in all examples. Examples from this data are in Figure 1 and Appendix B.", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: decTest: Scatter plot of n-gram-based (cosine similarity), neural (BERT-STS) and human (absHDS) metrics as a function of temperature for respGen. Each point corresponds to a single generated set. Error bars of HDS represent the standard deviation over 10 annotator ratings.", "figure_data": ""}, {"figure_label": "4", "figure_type": "", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: conTest: histograms of metric values of n-gram (distinct n-grams), neural (BERT-Score) and human (absHDS) metrics for promptGen. The orange histogram represents the distribution of the low content diversity class, the blue histogram represents the distribution of the high content diversity class and brown is the intersection between the two. Pointing down triangles represent the threshold \u03b7 of the optimal classifiers. The histograms show how each metric separates the two classes.", "figure_data": ""}, {"figure_label": "5", "figure_type": "", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: conTest absHDS results depends on the number of ratings per set and the number of sets.", "figure_data": ""}, {"figure_label": "", "figure_type": "", "figure_id": "fig_6", "figure_caption": "Figure 6: decTest: Scatter plot of n-gram-based (cosine similarity), neural (BERT-STS) and human (absHDS) metrics as a function of temperature for storyGen. Each point corresponds to a single generated set. Error bars of HDS represent the standard deviation over 10 annotator ratings.", "figure_data": ""}, {"figure_label": "7", "figure_type": "", "figure_id": "fig_7", "figure_caption": "Figure 7 :7Figure 7: Warm-up part, starting each AMT HDS task. It includes the context, and a single response generated by the tester.", "figure_data": ""}, {"figure_label": "8", "figure_type": "", "figure_id": "fig_8", "figure_caption": "Figure 8 :8Figure 8: absHDS question along with the evaluated response set (conTest in this case).", "figure_data": ""}, {"figure_label": "9", "figure_type": "", "figure_id": "fig_9", "figure_caption": "Figure 9 :9Figure9: aspHDS question (content in this case). The response set is the same as presented for absHDS question.", "figure_data": ""}, {"figure_label": "10", "figure_type": "", "figure_id": "fig_10", "figure_caption": "Figure 10 :10Figure 10: rnkHDS question along with the two evaluated response sets.", "figure_data": ""}, {"figure_label": "11", "figure_type": "", "figure_id": "fig_11", "figure_caption": "Figure 11 :11Figure 11: simHDS question along with the two evaluated responses.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Data and settings For each task, we generated sets of 10 responses per context, using a linear temperature sweep with 100 values in the range [0.2, 1.2](Caccia et al., 2018). We generated 1K sets in total for each of 1K contexts (10 per temperature) and evaluated 200 (2 random sets per temperature). For automatic metrics, we repeat this 100 times (randomly sampling 200 out of 1K sets each time), to present the mean and standard Context Fire next door. John woke up smelling like something was burning. He went outside. He saw the fire next door. He called the authorities.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "An example of the effect of temperature on the response set Sc for a context c from ROC Stories.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Content Diversity Benchmark We construct the Metrics for content Diversity (McDiv) benchmark, focusing on metrics for content diversity.McDiv is a dataset containing 6K {c, S c } pairs, (2K for each storyGen, respGen and prompt-Gen) collected as described in this section.Mc-   ", "figure_data": "storyGenrespGenpromptGen\u03c1OCA\u03c1OCA\u03c1OCAdistinct-n0.570.770.340.670.330.68cos-sim0.560.770.330.660.360.67BERT-STS0.60.780.460.720.650.82sent-BERT0.770.900.590.790.680.81BERT-score0.590.770.490.740.40.69absHDS0.850.950.630.810.780.89aspHDSform0.350.650.560.790.40.68aspHDScontent 0.840.940.670.830.750.88"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "", "figure_data": ": conTest results: Spearman's (\u03c1) correlation betweena set's class and each metric score.Div contains a subset of 3K examples, termedMcDiv nuggets , in which form diversity was neutral-ized, providing a difficult meta-evaluation chal-lenge. McDiv nuggets was sampled to ensure thatthe correlation of distinct-n (a form diversity met-ric) is zero over this subset. Applying conTestover the data shows that n-gram based metricsobtain near-zero values on McDiv nuggets as ex-pected, and all neural metrics perform substan-tially worse on McDiv nuggets than on McDiv. OnconTest, we obtain absHDS annotations for morethan 200 random samples from McDiv nuggets andobtain 0.7 Spearman's \u03c1 for the respGen task, sub-stantially higher than the best performing neuralmetric (sent-BERT) score at 0.6. Details and con-Test results can be found in Appendix C.HDS Stability: Picking Parameter ValuesHDS experiments demand expensive human labor.Thus, we need to carefully choose the number ofsets and different ratings we ask per set, to get re-"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "", "figure_data": ""}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "", "figure_data": ": decTest results for different decoding parameters:Spearman's \u03c1 (mean and standard deviation) of automaticmetrics for storyGen.TemperatureTop-pTop-kdistinct-n0.89 (0.01)0.84 (0.02) 0.64 (0.04)cos-sim0.89 (0.01)0.78 (0.03) 0.62 (0.05)BERT-STS0.81 (0.02)0.74 (0.03) 0.56 (0.04)sent-BERT0.80 (0.02)0.63 (0.05) 0.51 (0.04)BERT-score0.87 (0.01)0.77 (0.03)0.6 (0.05)"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "", "figure_data": ": decTest results for different decoding parameters:Spearman's \u03c1 (mean and standard deviation) of automaticmetrics for respGen.storyGenrespGenpromptGen\u03c1OCA\u03c1OCA\u03c1OCAdistinct-n0.530.740.520.740.480.75cos-sim0.530.740.520.740.600.77BERT-STS0.570.740.610.780.780.89sent-BERT0.750.870.680.830.80.9BERT-score 0.600.770.560.780.540.74"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "conTest results for McDiv; Results for automatic metrics over all the samples (2K per task).", "figure_data": "storyGenrespGenpromptGen\u03c1OCA\u03c1OCA\u03c1OCAdistinct-n-0.0020.49-0.0020.49-0.0030.49cos-sim0.040.530.080.550.220.60BERT-STS0.340.640.390.680.680.83sent-BERT0.630.800.530.760.730.85BERT-score0.350.660.330.650.350.65"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "conTest results for McDivnuggets subset; Results for automatic metrics over all the samples (1K per task).", "figure_data": "storyGenrespGenpromptGen\u03c1OCA\u03c1OCA\u03c1OCAdistinct-n0.040.57-0.010.460.120.56cos-sim0.050.540.040.540.280.62BERT-STS0.340.680.390.690.720.9sent-BERT0.680.850.60.790.750.88BERT-score 0.370.690.340.680.380.69absHDS0.780.90.70.850.840.94"}, {"figure_label": "10", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "", "figure_data": ": conTest results for 200 random samples fromMcDivnuggets including HDS."}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_16", "figure_caption": "decTest data samples for storyGen task and different p values (nucleus sampling). How is our mentioning application related to a related method (#five with two in queue) page such! \u2022 How is our having to resort to roundabout hypotheticals to argue that Stewart may secretly want! \u2022 How is our blood working out for you?\" a statewide voter got an outpouring of rename and!", "figure_data": "\u2022 How is our Internet even even connected with ourcorporate tracks? Every cell phone on the planetknows!\u2022 How is our developer name attached to the icon?Since the Planetside icon is use internally!\u2022 How is our food paradise created? Artificialchemical fertilizers. So these aren't GMOs, but!\u2022 How is our acquisition* worth -BOARD ROLL(Least Significant Equivalents)!\u2022 How is our transit plan addressing thisproblem? Under our old plans, Burlington Buses!\u2022 How is our mind different than any other partof the body?\" A Broader View!\u2022 How is our campaign working? Bitcoin launchesalongside psychological research showing thatpeople pay a lot!"}, {"figure_label": "17", "figure_type": "table", "figure_id": "tab_17", "figure_caption": "decTest data samples for promptGen task and different temperatures. Bold text is the 3-words prompt context.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_18", "figure_caption": "So that's the story of the last few years. The current political climate is not! \u2022 So that's the end of the first part of this series. I hope you enjoyed it.! \u2022 So that's the first thing I want to say. I'm not going to be the guy! \u2022 So that's the thing about being a professional. You have to be able to handle the criticism! \u2022 So that's the way it is. I don't think there's any way to change it! \u2022 So that's the problem. It's not just that the government is failing to protect! \u2022 So that's the thing about this. It's not just about the money. It's about! \u2022 So that's the end of the story.So that's the state of the campaign. Now, what I do want to talk about is! \u2022 So that's the thing: For as much as I love TLC, it's hard to! \u2022 So that's the idea, anyway. The last two seasons have been about doing that. It! \u2022 So that's the end of the half-hour segment. The next half-hour! \u2022 So that's the situation we're in,\" he said.", "figure_data": "Response set (p = 0.208)Response set (p = 0.64)Response set (p = 1)\"We're in the!\u2022 So that's the thing, I don't know if you know,but in general it's!\u2022 So that's the difference between the kinds ofthings that people will be talking about onThe next stepWednesday,!is to create a custom!\u2022 So that's the $2.3 billion. Here's the issue:\u2022 So that's the case. So, what's the problem?You're!Well,!\u2022 So that's the standard for using memcpy(). It's\u2022 So that's the first time I've ever seen a realfine to use memc!one. I'm not!\u2022 So that's the next step, and the next step is totry to figure out what's!"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_19", "figure_caption": "do you listen to those who are opposing it, who want to create a situation in which a! \u2022 do you listen to music or watch TV? How often do you cook or clean? How much! \u2022 do you listen to them? It's like the first time you got into something and it just! \u2022 do you listen to your father? We'll leave it to the gods to decide.\" ! \u2022 do you listen to music? I like to listen to music, but I don't really know! \u2022 do you listen to my story and see if you like it?\" \"I think you! \u2022 do you listen to Human Fly?, which YouTuber Nico Perri collaborated on, and Google! \u2022 do you listen to the acapella lyrics out of context and express the feeling?\" It's! \u2022 do you listen to Michael Kiwanuka-Smith who writes, \"The American Journalism Review discern! \u2022 do you listen to my songs as I said,\" Ramckhalter said. \"You feel! \u2022 do you listen to U.S. 90 night at this time of the year? ! \u2022 do you listen to that as well?\" \"The question was not, 'Who is! \u2022 do you listen?\" He asks, leaning forward as he woodenly talks to him. \"Listen! \u2022 do you listen to those books and sway him so much? No. He was deeply brainwashed! \u2022 do you listen?' Simon(lol).I feel like i'm in a Kurdish Genocide. I! \u2022 do you listen to value authenticated queries from your menu when running count? And if not, then!", "figure_data": "I'vebeen reading!"}, {"figure_label": "18", "figure_type": "table", "figure_id": "tab_20", "figure_caption": "decTest data samples for promptGen task and different p values (nucleus sampling). Bold text is the 3-words prompt context.", "figure_data": ""}, {"figure_label": "22", "figure_type": "table", "figure_id": "tab_21", "figure_caption": "conTest data samples for promptGen task. Bold text is the 3-words prompt context.", "figure_data": ""}], "doi": "10.18653/v1/N16-1014"}