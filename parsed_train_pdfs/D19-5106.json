{"authors": "Deli Chen; Shuming Ma; Keiko Harimoto; Ruihan Bao; Qi Su; Xu Sun", "pub_date": "", "title": "Group, Extract and Aggregate: Summarizing a Large Amount of Finance News for Forex Movement Prediction", "abstract": "Incorporating related text information has proven successful in stock market prediction. However, it is a huge challenge to utilize texts in the enormous forex (foreign currency exchange) market because the associated texts are too redundant. In this work, we propose a BERT-based Hierarchical Aggregation Model to summarize a large amount of finance news to predict forex movement. We firstly group news from different aspects: time, topic and category. Then we extract the most crucial news in each group by the SOTA extractive summarization method. Finally, we conduct interaction between the news and the trade data with attention to predict the forex movement. The experimental results show that the category based method performs best among three grouping methods and outperforms all the baselines. Besides, we study the influence of essential news attributes (category and region) by statistical analysis and summarize the influence patterns for different currency pairs. * This work is done when Deli Chen is a intern at Mizuho Securities.", "sections": [{"heading": "Introduction", "text": "Deep learning and Natural Language Processing technologies have been widely applied in market prediction tasks (Strau\u00df et al., 2018;Alostad and Davulcu, 2017;Li et al., 2015;Ni et al., 2019), and the market related finance news has proven very useful for the prediction (Ding et al., 2016;Xu and Cohen, 2018). However, the studies of prediction in forex market, which is the largest market in the world with the highest daily trading volume, is much less than that in the stock market. Figure 1 shows the average numbers per hour of forex related news. There is a large amount of finance news related to forex trading with different influence, so it is a huge challenge to extract the useful semantic information from news. Most of previous works (Bakhach et al., 2016; Shen and Liang, 2016; Pradeepkumar and Ravi, 2016;Contreras et al., 2018;Weeraddana et al., 2018) on forex prediction ignore related text totally and focus on the forex trade data only, which loses the important semantic information. Yet existing works (Seifollahi and Shajari, 2019;Nassirtoussi et al., 2015) applying finance news in forex prediction mainly rely on manual rules to build feature vectors, which can hardly access the semantic information effectively.\nTo make better use of finance news, we propose a novel neural model: Bert-based Hierarchical Aggregation Model (BHAM) to summarize a large amount of finance news for forex movement prediction. We suppose that the finance news is redundant and only a small amount of news plays a crucial role in forex trading. So the key point is how to extract the most important news. In BHAM, we design a hierarchical structure to extract essential news at the group level first and then aggregate the semantic information across all groups. We expect the news is more related intragroup and less related inter-groups to make the extraction more effective. We design three grouping methods from different aspects: time, topic or category. At the group level, we concatenate news headlines in the same group and regard news extraction in each group as an extractive summarization task. We modify the SOTA extractive summarization model proposed in (Liu, 2019) to select the most important news. The connection process can let the selected news both content aware and context aware. Followingly, we conduct multimodal interaction between news data and trade data through attention mechanism to predict the forex prediction. The trade data represents the history movement of the forex, and the news data represents the environment variable. These two types of information are highly related.\nWe conduct experiments on four major currency pairs (USD-EUR, USD-JPY, USD-RMB, USD-GBP), and the experimental results show that the category-based BHAM performs best among all the baselines and proposed methods in all currency pairs. Based on this method, we analyze the influence of input time and prediction time on forex trading. We also analyze the influence of news category and news region and find various influence patterns for different currency pairs, which may be enlightening to the forex investors. The main contributions of this works are summarized as follows:\n\u2022 We design a novel neural model to incorporate finance news in forex movement prediction. To the best of our knowledge, this is the first work to use the neural model to summarize a large amount of news for forex movement prediction.\n\u2022 We propose three news grouping methods from different aspects: time, topic and category. Experiments show that the category based method performs best and outperforms all the baselines.\n\u2022 Based on our experiments, we study the effect of time parameters on forex trading. We also analyze and summarize different influence patterns of finance news (both category and region) on different currency pairs.", "n_publication_ref": 13, "n_figure_ref": 1}, {"heading": "Related Work", "text": "BERT (Devlin et al., 2018) is a potent pretrained contextualized sentence representation and has proven obvious improvement for many NLP tasks (Sun et al., 2019;Xu et al., 2019). Liu (2019) proposes a modified BERT for extractive summarization and achieve the state-of-the-art result in extractive document summarization task.\nThere have been many studies applying the related text in market prediction tasks. Moreover, the text assisted stock movement prediction has attracted many researchers' interest. Most of these works predict stock movement based on single news: Si et al. (2014) utilize the sentiment analysis to help the prediction. Duan et al. (2018) adopt the summarization of news body instead of headline to predict. Ding et al. (2016) propose the knowledgedriven event embedding method to make the forecast. Yet some others choose multi-news: Hu et al. (2018) propose a hybrid attention network to combine news in different days. However, the number of combined news is still limited and much smaller than that of forex news.\nCompared to stock prediction, works about forex prediction is much scarce, and most of these works (Carapu\u00e7o et al., 2018;Bakhach et al., 2016;Yong et al., 2018;Roledene et al., 2016;Contreras et al., 2018;Weeraddana et al., 2018) do not consider the text information. Shen and Liang (2016) employ stacked autoencoder to get the trade data representation and adopt support vector regression to predict. de Almeida et al. (2018) combine SVM with genetic algorithms to optimize investments in Forex markets based on history price. Tsai et al. (2018) choose the convolutional neural network to process the trading data. Besides, only limited works utilize the forex related text in the prediction process. Nassirtoussi et al. (2015) adopt the WordNet (Miller, 1995) and SentiWordNet (Baccianella et al., 2010) to extract the text semantic and sentiment information and build the text feature vector to forecast forex movement. Following this work, Seifollahi and Shajari (2019) add word sense disambiguation in the sentiment analysis of news headlines. Vijayan and Potey (2016) apply the J48 algorithm in analyzing text. This kind of method pays more attention to access a fixed feature vector from news and can only represent news on a shallow level. In this work, we propose a selection and aggregation neural framework to process the larger amount of finance news and employ the powerful pre-trained BERT as text encoder, which can learn the deep semantic information effectively.", "n_publication_ref": 21, "n_figure_ref": 0}, {"heading": "Approach", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Problem Formulation", "text": "Each sample in the dataset (x, y, f ) contains the set of news text x, the forex trade data y, and the forex movement label f . x and y happen in the same input time window. To be more specific, x is a list of news groups\nx = C 1 , C 2 , \u2022 \u2022 \u2022 , C L .\nL is the number of groups. The methods for  dividing groups are introduced in Section 3.5. Each news group is a sequence of finance news [news 1 , news 2 , \u2022 \u2022 \u2022 , news K ] in chronological order. y is the trade data embedding accessed by the method introduced in Section 3.6. And f \u2208 {1, 0} is the forex movement label telling whether the forex trade price is up or down after a certain time (we call it prediction delay). The forex movement prediction task can be defined as assigning movement label for the news input and trade data input.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Model Overview", "text": "The overview of the Bert-based Hierarchical Aggregation Model (BHAM) is displayed in Figure 2. The model can be generally divided into two steps: (1)Intra-group extraction and (2)Intergroups aggregation. In the Intra-group extraction step, news in the same group is connected as a continuous paragraph, and we conduct extractive summarization on this paragraph to select the most important news. Specifically, we employ BERT as the encoder to get the contextualized paragraph representation and compute the importance score for each news. Then we select and aggregate the top-k (k is a hyper-parameters) news to get the final group representation. In the Inter-groups aggregation step, we first access the trade data representation by a 3-layer perceptron and then employ the trade data representation as a query to calculate the attention scores of all the news group and obtain the final news representation. Finally, we fuse the final news representation and the trade data representation to predict the forex movement.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Intra-group Extraction", "text": "There will be lots of news in the same group, and we suppose that only a small amount of news has the greatest influence on the forex movement. The purpose of this step is to select the essential news from all news in group, which is redundant and full of noise. Inspired by the BERT-based extractive summarization model proposed in (Liu, 2019), we modify this method to select the most crucial news in each group. All the news in the same group is related to the subject of this group, and the connection of them in chronological order can be regarded as the continuous description of the group subject. The connection can make the news representations realize the context information of this group by passing information among different news. We suppose the context information can help select better news in group.\nThe form of group news input for BERT encoder is illustrated in Figure 3. We insert a [CLS] token before each news and a [SEP] token after each news. For the segment embedding, we use the loop of [E A , E B ] to extend the raw segment embedding of BERT to multi-sentences. After the BERT encoding, all the [CLS] tokens cls are regarded as the semantic representations of the corresponding news. The importance score for each news is calculated base on these [CLS] tokens:\nscore i = sigmoid(W 0 * cls i + b 0 ) (1) t i = TOP k (score i ) (2) s i = softmax(t i )(3)\nWhere i \u2208 {1, 2, \u2022 \u2022 \u2022 , L}, L is the number of groups. cls i is the list of [CLS] tokens in the ith group. W 0 and b 0 are the trainable parameters. score i is a list of values indicating the important scores of news. TOP k is an operation to select the top-k pieces of news with the highest scores.\nThen the group representation is calculated by the weighted sum of the top-k [CLS] tokens:\nG i = k j=1 cls i j * s i j (4)\nThe G i is the final representation of the i-th news group which contains the semantic information from the most important news in this group.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "Inter-groups Aggregation", "text": "The purpose of this step is to aggregate semantic information at the inter-groups level. The forex trade data and the finance news are highly relevant: the trade data represents the history movement of forex, and the finance news represents the environmental variable. So the combination of them can help us model the forex movement better. In a certain input time, news groups have different impacts on forex movement. So we employ the trade data as a query to calculate the attention weights of news groups. Then the weighted sum of news groups and the trade data representation are finally fused to predict the forex movement. For forex trade data y, we apply a 3-layer perceptron to access the trade data representation R t , and each layer is a non-linear transform with Relu activation function. Then we calculate the attention weight between R t and G i :\ng(i) = Relu(R t * W a * G i ) (5) att i = e g(i) L i=1 e g(i)(6)\nWhere att(i) is the i-th news group's attention weight to trade data. Then we sum the news groups representations up to get the final news semantic representation R s :\nR s = L i=1 G i * att i (7)\nTo fuse the news semantic and trade data representations effectively, we choose the fusion function used in Mou et al., 2016) to fuse R s and R t and predict the movement:\nR = [R t ; R s ; R t \u2212 R s ; R t \u2022 R s ] (8) p(f |x, y) = softmax(W p * R + b p ) (9)\n\u2022 means element-wise multiplication.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Methods of Grouping News", "text": "In this part, we introduce the three news grouping methods. The ideal division enables news groups to be high cohesion and low coupling, which means the semantic information of finance news should be highly related intra-group and less related inter-groups. We suppose that extracting news by groups can reduce the extraction difficulty compared to extracting from all news directly because news in the same group is close to each other and has less noise. Moreover, this method can help us analyze the contributions of different groups.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Grouping by Time", "text": "In this method, finance news is divided into groups according to the time when news happens. We set the time unit to 5 minutes and news released in the same time unit will be divided into the same group. This method supposes that news happened closely is highly correlated.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Grouping by Topic", "text": "In this method, finance news is divided into groups by news topic. The news topics are generated by unsupervised news clustering. In this work, we choose the affinity propagation algorithm (Frey and Dueck, 2007) to generate news clusters without setting the number of clusters subjectively. Moreover, we choose the tf-idf of 2-gram features from news headlines. This method supposes that finance news focuses on several finance event topics at a particular time. News in the same topic describes this topic from different aspects and has a high correlation.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Grouping by Category", "text": "In this method, news is divided into groups by category.\nThe news categories 1 are {Business Sectors, Business General, Business Assets, Business Commodities, Business Organizations, Politics&International Affairs, Arts&Culture&Entertainment&Sports, Science &Technology, Other}. This method supposes that news in the same category is close to each other.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Trade Data Embedding", "text": "The raw record of forex data includes the open/ close/high/low trade prices for each minute. In order to extract all the possible features, we build the trade data embedding y containing multi aspects:\n\u2022 Raw Number: open/close/high/low trade price for each trade minute.\n\u2022 Change Rate: change rate of open/close/ high/low price compared to last trade minute.\n\u2022 Trade Statistics: mean value, max value, min value, median, variance of all the trade prices in input minutes.\nThe min-max scale is applied for each currency pair's samples to scale the raw numbers in y to [0, 1] according to the maximum and minimum value of each feature.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Training Objective", "text": "The loss function of the proposed model includes two parts: the negative log-likelihood training loss and the L 2 regularization item:\nLoss = \u2212f * log p(f |x, y, \u03b8) + \u03bb 2 \u03b8 2 2 (10)\n\u03b8 is the model parameters. Experiments show that the performance improves after adding L 2 regularization. We train three models with different news grouping methods: time, topic and category, and we call them BHAM-Time, BHAM-Topic, BHAM-Category, respectively.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Experiment", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Dataset", "text": "The experiment dataset is accessed from the professional finance news providers Reuters 2 . We collect forex trade data of four major currency pairs (USD-EUR, USD-JPY, USD-RMB, USD-GBP) from 2013 to 2017.\nWe collect the open/close/high/low trade price for each trade minute. As for the finance news data, we collect all the English news happened in trade time released by Reuters and match the news with target currency pairs according to news region. For example, we match USD-EUR with news related to US, Europe or both of them. The raw data contains both news headline and body, and we utilize the headline only since the headline contains the most valuable information and has less noise. The forex movement label f is decided by the comparison of prediction time price and the input window ending price. We design the symbol USD-EUR(20-10) to represent the prediction for the USD-EUR exchange rate with 20 minutes input time and 10 minutes prediction delay. To access more data for training, we overlap the input time of samples. For example, when overlap-rate is 50%, two consecutive samples' input time will be 8:00-8:20 am and 8:10-8:30 am. Then the data samples will be twice as large as no overlap condition (In the USD-EUR(20-10) dataset, the number of samples will increase from 31k to 62k). We reserve 5k samples for developing and 5k samples for testing. All the rest of samples are applied for training.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Experiment Setting", "text": "We choose the pytorch-pretrained-BERT 3 as BERT implement and choose the bert-baseuncased version in which there are 12 layers, 768 hidden states and 12 attention heads in the transformer. We truncate the BERT input to 256 tokens and fine-tune the BERT parameters during training. We adopt the Adam (Kingma and Ba, 2014) optimizer with the initial learning rate of 0.001. We apply the dropout (Srivastava et al., 2014) regularization with the dropout probability of 0.2 to reduce over-fitting. The batch size is 32. The training epoch is 60 with early stop. The weight of L 2 regularization is 0.015. The learning rate begins to decay after 10 epoch. The overlap rate of data samples is 50%, and the number of selected news in each group is 3. When splitting the dataset, we guarantee that the samples in train set are previous to samples in valid set and test set to avoid the possible information leakage. We tune the hyper-parameters on the development set and test model on the test set. The forex prediction is conducted as a binary classification task (up or down). The evaluation metrics are macro-F1 and Matthews Correlation Coefficient (MCC). MCC is often reported in stock movement forecast (Xu and Cohen, 2018;Ding et al., 2016) because it can overcome the data imbalance issue.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Results and Analysis", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Comparison with Baselines", "text": "Here, we introduce the baselines in this work. Since there are few existing works, we modify two advanced models from stock prediction field which adopt multi-news as input for this task. Besides, we design some ablation variations of the proposed model to check the effects of different modules. The baselines are shown below:\n\u2022 NoNews: This method considers the forex trade data only and use a 3-layer perceptron (the setting is same as full model) to encode the trade data and make prediction. This is a baseline to check the improvement by adding text information.\n\u2022 SVM: This method chooses the support vector machine to predict the result based on the feature vectors extracted by the method introduced in (Seifollahi and Shajari, 2019).\n\u2022 HAN: This method is proposed in (Hu et al., 2018) for stock movement prediction. It includes a hybrid attention mechanism and Gated Recurrent Unit to combine multi-day's stock news to predict movement. We use every 5 minutes instead of each day as time unit for this method and the StockNet method because there is too much news for forex trading and the experiments show that the latest news has the most influence.\n\u2022 StockNet: This method is proposed in (Xu and Cohen, 2018). It treats the prediction task as a generation task and designs a modified variational auto encoder to process multidays' tweets to predict stock movement.\n\u2022 NoGroup: This method does not group news and select key news directly from all news.\n\u2022 NoConnect: This method does not connect news in the same group. Instead, it gets the representation for each news independently using BERT. This method groups news by category.\n\u2022 LSTM+Attention: This method uses the bidirectional LSTM and self-attention to replace the BERT as text encoder. The number of LSTM hidden states is 256, and the hidden-layer is 3. This method groups news by category.  methods perform well, and both BHAM-Topic and BHAM-Category methods outperform all the baselines. The BHAM-Category performs best among these methods, which shows that the semantic information of finance news is mostly aggregated by category. All the methods get improved after introducing the text information, which proves the related finance news is helpful for the prediction. The performance of NoGroup method decreases by a large margin compared to BHAM-Category, which demonstrates that the hierarchical structure works well. Without hierarchical structure, selecting essential news directly from all news has more noise and requires the model to have a stronger fitting ability for a longer paragraph. After removing the news connection, the performance of NoConnect method drops sharply compared to BHAM-Category. Accessing the news representation from the connected paragraph helps the news representation realize the context information in the group. The LSTM+Attention method performs worse than the BERT-based method, which proves that BERT has stronger power of sentence encoding. The two methods borrowed from stock movement prediction are designed to consider all news's information, but the forex related news is redundant, which can explain the poor performance of these two methods.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "As shown in", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Effect of Time Parameters", "text": "In this section, we analyze the influence of two crucial time parameters on model performance, which are input time and predic- tion delay.\nWe choose the input time \u2208 {10, 20, 30, 40, 50, 60} (minutes), the prediction delay \u2208 {5, 10, 15, 20, 25, 30} (minutes) and experiment all combinations. We take the USD-JPY for example to analyze the time effect of forex trading, and we observe similar results in other currency pairs. The Figure 4 shows BHAM-Category model's performances (macro-F1%) on USD-JPY pair under different combinations of input time and prediction delay. We can observe that with the increase of input time from 10 minutes to 40 minutes, the model performance improves too. However, when we increase the input time continuously, the model performance begins to decrease. Too less text is not enough to support the prediction, but too many texts may bring much noise. The ideal input time is around 40 minutes. Besides, at all input time conditions, the model's performances decline with the increase of prediction delay because events happened in the prediction delay time may also influence the forex movement. We can also conclude that forex movement pays more attention to the latest news because when masking the latest news input (such as USD-JPY(40-05) and USD-JPY(30-15), the latter one can be seen as the former one masking the lastest 10 minutes input), the model performance declines obviously at almost all conditions.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Influence of News Attributes", "text": "In this section, we analyze the influence of finance news's attributes (category and region) on prediction results and summarize the influence patterns for different currency pairs. We conduct the experiments based on BHAM-Category.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Effect of News Category", "text": "The forex trading data's attention weights over news categories are calculated by Equation 6. We sum up all the attention weights of test samples and calculate the proportions each category contributes. As shown in Figure 5, we display the influence patterns of news category for different currency pairs. We observe that there are obvious differences among currency pairs. USD-EUR trading pays more attention to the Business Sectors and Politics/International Affairs news. USD-JPY trading is mostly influenced by Business Sectors and Science/Technology news. Politics/International Affairs news has the most significant impact on USD-RMB trading and Business Commodities news effects USD-GBP trading most. The summarized influence patterns can serve as decision-making reference for forex traders when facing news from various categories.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Effect of News Region", "text": "The trading data's attention weight for selected news att ij is calculated by the following formula:\natt ij = att i * s i j (11)\nWhere att i is the trade data's attention on the i-th category in Equation 6 and s i j in Equation 4 is the weight of selected news in group. We sum up all the selected news's attention according to their regions and access the region influence weight. The results are shown in Figure 6. For each currency pair, the news are divided into three classes: news related to region A only, news related to region B only and news related to both region A and B. And we observe that the news related to both region A and B has the least influence on all currency  pairs. News related to the US has the largest influence weight on USD-JPY and USD-GBP trading. Yet news related to China/Europe has a larger influence weight than news related to US in USD-RMB/USD-EUP trading. We can intuitively observe the influence weights of different regions for forex trading, which is helpful for the analysis and forecast of forex movement.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Impact of Selection Number", "text": "The selection number in each group is an essential hyper-parameter to control the amount of extracted information. As shown in Table 2, the BHAM-Category performs best when the selection number is 3 in all currency pairs. When the selection number is small (1,2), the model is too strict so that some crucial information will be missed. When the selection number is large (4,5), some less influential news will be selected and interfere model's decision. When we keep all news in the group, the model's performance declines by a large margin. This experiment demonstrates that the selection mechanism plays an important role in the proposed model.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Conclusion", "text": "In this work, we propose a BERT-based Hierarchical Aggregation Model to summarize a large amount of finance news for forex movement prediction. Experiments show that our model outperforms all the baselines by a large margin, which proves the effectiveness of the proposed framework. We design three grouping news methods: time, topic and category and experiments show that the category-based method performs best, which shows that the semantic information of forex related news is mostly aggregated by category. Experiments about time effect prove that the proper input time is about 40 minutes and the prediction accuracy declines with the increase of prediction delay. Besides, we analyze the influence of news attributes on forex trading and observe some interesting conclusions: Business Sectors news has the most influence on USD-EUR trading and Politics/International Affairs news effects USD-RMB trading most. Besides, both USD-JPY trading and USD-GBP trading pay most attention to news from US. All these influence patterns can help forex traders handle different news more wisely and make better decisions.\nTo our knowledge, this is the first work to utilize the advanced NLP pre-train technology in the enormous forex market and the results show the potential of this research area. Promising future studies may include designing more suitable grouping methods or combining news grouping and market predicting in an end2end model.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgement", "text": "This work is supported by a Research Grant from Mizuho Securities Co., Ltd. Mizuho Securities also provide experiment data and valuable domain experts suggestions.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Combining support vector machine with genetic algorithms to optimize investments in forex markets with high leverage", "journal": "Applied Soft Computing", "year": "2018", "authors": "Bernardo Jubert De Almeida; Rui Ferreira Neves; Nuno Horta"}, {"title": "Directional prediction of stock prices using breaking news on twitter", "journal": "Web Intelligence", "year": "2017", "authors": "Hana Alostad; Hasan Davulcu"}, {"title": "Sentiwordnet 3.0: an enhanced lexical resource for sentiment analysis and opinion mining", "journal": "", "year": "2010", "authors": "Stefano Baccianella; Andrea Esuli; Fabrizio Sebastiani"}, {"title": "Forecasting directional changes in the fx markets", "journal": "IEEE", "year": "2016", "authors": "Amer Bakhach; P K Edward; Hamid Tsang;  Jalalian"}, {"title": "Reinforcement learning applied to forex trading", "journal": "Applied Soft Computing", "year": "2018", "authors": "Jo\u00e3o Carapu\u00e7o; Rui Neves; Nuno Horta"}, {"title": "Enmx: An elastic network model to predict the forex market evolution", "journal": "", "year": "2018", "authors": "V Antonio; Antonio Contreras; Alberto Llanes; Sergio P\u00e9rez-Bernabeu; Horacio Navarro; Jose J P\u00e9rez-S\u00e1nchez; Jos\u00e9 M L\u00f3pez-Esp\u00edn;  Cecilia"}, {"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2018", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"title": "Knowledge-driven event embedding for stock prediction", "journal": "", "year": "2016-12-11", "authors": "Xiao Ding; Yue Zhang; Ting Liu; Junwen Duan"}, {"title": "Learning target-specific representations of financial news documents for cumulative abnormal return prediction", "journal": "", "year": "2018-08-20", "authors": "Junwen Duan; Yue Zhang; Xiao Ding; Ching-Yun Chang; Ting Liu"}, {"title": "Clustering by passing messages between data points. science", "journal": "", "year": "2007", "authors": "J Brendan; Delbert Frey;  Dueck"}, {"title": "Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction", "journal": "", "year": "2018-02-05", "authors": "Ziniu Hu; Weiqing Liu; Jiang Bian; Xuanzhe Liu; Tie-Yan Liu"}, {"title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"title": "Tensor-based learning for predicting stock movements", "journal": "", "year": "2015-01-25", "authors": "Qing Li; Liling Jiang; Ping Li; Hsinchun Chen"}, {"title": "Fine-tune bert for extractive summarization", "journal": "", "year": "2019", "authors": "Yang Liu"}, {"title": "Wordnet: a lexical database for english", "journal": "Communications of the ACM", "year": "1995", "authors": "A George;  Miller"}, {"title": "Natural language inference by tree-based convolution and heuristic matching", "journal": "Short Papers", "year": "2016-08-07", "authors": "Lili Mou; Rui Men; Ge Li; Yan Xu; Lu Zhang; Rui Yan; Zhi Jin"}, {"title": "Text mining of news-headlines for forex market prediction: A multi-layer dimension reduction algorithm with semantics and sentiment", "journal": "Expert Systems with Applications", "year": "2015", "authors": "Saeed Arman Khadjeh Nassirtoussi;  Aghabozorgi; Ying Teh; David Chek Ling Wah;  Ngo"}, {"title": "Forecasting of forex time series data based on deep learning", "journal": "Procedia computer science", "year": "2019", "authors": "Lina Ni; Yujie Li; Xiao Wang; Jinquan Zhang; Jiguo Yu; Chengming Qi"}, {"title": "Forex rate prediction using chaos and quantile regression random forest", "journal": "IEEE", "year": "2016", "authors": "Dadabada Pradeepkumar; Vadlamani Ravi"}, {"title": "Genibux-event based intelligent forex trading strategy enhancer", "journal": "IEEE", "year": "2016", "authors": "Lakna Sasika Roledene; Nadun Ariyathilaka; Prasad Liyanage; Jeewanee Lakmal;  Bamunusinghe"}, {"title": "Word sense disambiguation application in sentiment analysis of news headlines: an applied approach to forex market prediction", "journal": "Journal of Intelligent Information Systems", "year": "2019", "authors": "Saeed Seifollahi; Mehdi Shajari"}, {"title": "A time series forecasting model based on deep learning integrated algorithm with stacked autoencoders and svr for fx prediction", "journal": "Springer", "year": "2016", "authors": "Hua Shen; Xun Liang"}, {"title": "Exploiting social relations and sentiment for stock prediction", "journal": "", "year": "2014-10-25", "authors": "Jianfeng Si; Arjun Mukherjee; Bing Liu; Qing Sinno Jialin Pan; Huayi Li;  Li"}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "journal": "Journal of Machine Learning Research", "year": "2014", "authors": "Nitish Srivastava; Geoffrey E Hinton; Alex Krizhevsky; Ilya Sutskever; Ruslan Salakhutdinov"}, {"title": "Intraday news trading: The reciprocal relationships between the stock market and economic news", "journal": "Communication Research", "year": "2018", "authors": "Nadine Strau\u00df; Rens Vliegenthart; Piet Verhoeven"}, {"title": "Utilizing bert for aspect-based sentiment analysis via constructing auxiliary sentence", "journal": "", "year": "2019", "authors": "Chi Sun; Luyao Huang; Xipeng Qiu"}, {"title": "Predict forex trend via convolutional neural networks", "journal": "Journal of Intelligent Systems", "year": "2018", "authors": "Yun-Cheng Tsai; Jun-Hao Chen; Jun-Jie Wang"}, {"title": "Improved accuracy of forex intraday trend prediction through text mining of news headlines using j48", "journal": "International Journal of Advanced Research in Computer Engineering & Technology (IJARCET)", "year": "2016", "authors": " Mrs Remya Vijayan; M A Mrs;  Potey"}, {"title": "Multigranularity hierarchical attention fusion networks for reading comprehension and question answering", "journal": "Long Papers", "year": "2018-07-15", "authors": "Wei Wang; Chen Wu; Ming Yan"}, {"title": "Detection of black regions in the forex market by analyzing high-frequency intraday data", "journal": "IEEE", "year": "2018", "authors": " Nr Weeraddana;  Silva"}, {"title": "Bert post-training for review reading comprehension and aspect-based sentiment analysis", "journal": "", "year": "2019", "authors": "Hu Xu; Bing Liu; Lei Shu; Philip S Yu"}, {"title": "Stock movement prediction from tweets and historical prices", "journal": "Long Papers", "year": "2018-07-15", "authors": "Yumo Xu; Shay B Cohen"}, {"title": "Foreign currency exchange rate prediction using neuro-fuzzy systems", "journal": "Procedia computer science", "year": "2018", "authors": "Yunli Yoke Leng Yong; Xiaowei Lee;  Gu; P Plamen; David Chek Ling Angelov; Elnaz Ngo;  Shafipour"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Average numbers per hour of forex related news from Reuters in 2013-2017. US EU represents news related to US, Europe or both of them.", "figure_data": ""}, {"figure_label": "4", "figure_type": "", "figure_id": "fig_2", "figure_caption": "Figure 4 :4Figure 4: The BHAM-Category model's performances (macro-F1%) on USD-JPY pair under different conditions of input time and prediction delay. The dark colour means low performance and light colour means high performance.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": ", all the three proposed", "figure_data": "PLQPLQ,QSXW7LPHPLQ PLQPLQPLQPLQ PLQ PLQ PLQ PLQ PLQ3UHG'HOD\\"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Results of baselines and proposed methods on the test set (input time window is 40 minutes, and prediction delay is 5 minutes, we observe similar result in other time settings). All the experiment results have proven significant with p < 0.05 by student t-test.", "figure_data": "USD-EURUSD-JPYUSD-RMBUSD-GBPMethodF1 MCC F1 MCC F1 MCC F1 MCCNoNews63.0 0.266 64.8 0.295 65.4 0.304 64.7 0.301SVM64.8 0.297 65.7 0.314 66.2 0.324 65.1 0.310HAN65.2 0.305 67.0 0.341 66.7 0.334 66.9 0.346StockNet65.4 0.309 66.8 0.336 67.2 0.343 66.5 0.339NoGroup66.7 0.335 67.5 0.350 68.0 0.361 68.3 0.375NoConnect68.8 0.377 70.9 0.418 69.6 0.392 68.7 0.383LSTM+Attention 69.8 0.397 71.2 0.422 71.8 0.434 69.7 0.403BHAM-Time70.7 0.414 70.5 0.409 71.4 0.426 69.2 0.392BHAM-Topic71.8 0.436 72.6 0.451 72.3 0.445 71.3 0.435BHAM-Category 72.5 0.450 73.4 0.466 73.5 0.468 71.6 0.441Table 1:"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "The attention distributions over categories for different currency pairs.", "figure_data": "USD-EURUSD-JPYUSD-RMBUSD-GBP6% 10%4%30%18%3%21%6%15%2%15%15%7%5%12%10%21%5%8%5%11%11% 8%8%16%10% 5%31%3%17% 5% 6%6%16%21%8%BUSINESS_SECTORSBUSINESS_GENERAL NEWSBUSINESS_ASSETSBUSINESS_COMMODITIESBUSINESS_ORGANIZATIONSPOLITICS/INTERNATIONAL_AFFAIRSARTS/CULTURE/ENTERTAINMENT/SPOTRSSCIENCE/TECHNOLOGYOTHER36% Figure 5: US US&CN 20% 43% US US&JP 22% US 32% US&EU 26% USD-RMB USD-JPY USD-EUR49% US USD-GBP US&G B 18%EU 42%JP 35%CN 44%GB 33%Figure 6: The attention distributions over regions for different currency pairs.USD-EUR USD-JPY USD-RMB USD-GBP167.668.869.367.3271.473.172.270.8372.573.473.571.6472.272.873.170.7570.870.371.968.4\u221e64.164.565.763.6"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Impact of selection number in each group in BHAM-Category. \u221e means keeping all news. The results have proven statistic significant.", "figure_data": ""}], "doi": "10.3233/WEB-170349"}