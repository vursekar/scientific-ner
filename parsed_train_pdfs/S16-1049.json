{"authors": "Tamara\u00e1lvarez -L\u00f3pez; Jonathan Juncal-Mart\u00ednez; Milagros Fern\u00e1ndez-Gavilanes; Enrique Costa-Montenegro; Francisco Javier Gonz\u00e1lez-Casta\u00f1o", "pub_date": "", "title": "GTI at SemEval-2016 Task 5: SVM and CRF for Aspect Detection and Unsupervised Aspect-Based Sentiment Analysis", "abstract": "This paper describes in detail the approach carried out by the GTI research group for Se-mEval 2016 Task 5: Aspect-Based Sentiment Analysis, for the different subtasks proposed, as well as languages and dataset contexts. In particular, we developed a system for category detection based on SVM. Then for the opinion target detection task we developed a system based on CRFs. Both are built for restaurants domain in English and Spanish languages. Finally for aspect-based sentiment analysis we carried out an unsupervised approach based on lexicons and syntactic dependencies, in English language for laptops and restaurants domains.", "sections": [{"heading": "Introduction", "text": "In the last years, with the growth of Internet, people use it as a means of expressing their opinions and experiences about several subjects. That is the reason why there is a great amount of user generated information available online, through many different platforms, such as blogs, social networks, etc. This information became very valuable for companies, politicians, etc., who are interested in what users say about them or their products. Due to this, Sentiment Analysis (SA) techniques have attracted the interest of researches, trying to process all this amount of information by means of usually supervised methods based on classifiers.\nMost of these researches focus on extracting the sentiment of a whole review or text (Liu, 2012). This is enough for many applications and purposes. However, sometimes there is a need for analysing the text in a deeper way, at entity or aspect level. For example, a review in the restaurants domain can include different opinions about different aspects, such as the service or the food quality, so it is interesting to distinguish the different opinions for each of these aspects. This is the reason why some studies emerged about the so-called aspect-based sentiment analysis (Marcheggiani et al., 2014;Lu et al., 2011).\nHence this is the subject of the task 5 of the Se-mEval 2016 (Pontiki et al., 2016), divided into different subtasks. Groups are asked to detect aspect categories in a review or sentence, which are predefined for each domain and formed by an entity and an attribute. Then, there is a subtask which consists of detecting the opinion target expression, which are related to the categories found. Finally, aspect-based sentiment analysis is required for one of the subtasks, associating a polarity, which can be positive, negative or neutral, to each of the categories found in the sentence or review. Datasets in different languages and domains are available for proving the approaches.\nThe remainder of this paper is structured as follows. In Section 2 we make a description of the system developed for all the subtasks. Section 3 contains the results of all the different subtasks, as well as detailed scores for each slot. Finally, in section 4 we summarize the main aspects of our system and extract some final conclusions.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "System Overview", "text": "In this section we make a brief description of the system submitted for the different subtasks. We presented our submission for English restaurants dataset for subtask 1, slots 1, 2 and 3, and subtask 2, slots 1 and 3. For English laptops dataset we sent a submission for subtasks 1 and 2 only in slot 3. Then, the system was also developed for Spanish language and restaurants dataset in subtasks 1, slots 1 and 2 and subtask 2, slot 1. In the next subsections we describe the different stages carried out for obtaining all the different results.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Preprocessing", "text": "As a first step for all the subtasks, each preprocessed social media review must first be broken into tokens, in order to derive the syntactic context. Partof-speech (POS) tagging and lemmatization are performed to ensure that all the inflected forms of a word are covered. In the case of English, Stanford Tagger is applied due to its better results, however it does not provide lemmatization. That is why using the resulting form and tag, lemma is extracted by means of Freeling Tagger (Atserias et al., 2006;Padr\u00f3 and Stanilovsky, 2012). On the other hand, for Spanish language only Freeling Tagger is used. Freeling is a library that provides multiple languages among which are English and Spanish. Food and drinks recognition is also performed, based on dictionaries 1 , in order to identify words referring to those topics for the subsequent processing of the sentences.\nPOS tagging allows the identification of lexical items that can contribute to the correct recognition of targets in a message. These items are namely adjectives, adverbs, verbs and nouns. The lemmatized and POS-annotated messages are fed to a parser that transforms the output of the tagger into a full parse tree. Finally, the tree is converted to dependencies, and the functions are annotated. The entire process is performed by means of Freeling Parser (Padr\u00f3 and Stanilovsky, 2012).", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Subtask 1: Sentence-level Aspect-Based", "text": "Sentiment Analysis (ABSA)\nThis subtask contains different slots, having participated in three of them, which are slot 1, slot 2 and slot 3. The system for Spanish and English language is exactly the same for both slots 1 and 2.\n1 Taken from the lists available at https://es.speaklanguages.com/ingl\u00e9s/vocabulario/comidas", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Slot 1 Aspect category detection", "text": "The aim of this task is to assign to each sentence a category, which is a tuple (entity, attribute), from a given set of 12 different predefined categories. To do this, we used a linear SVM classifier combined with word lists. These word lists are created from the training file provided by the organization, which was composed of 2000 sentences, grouped in 350 reviews. Different datasets were provided for several languages and topics. Our system was developed for restaurants dataset, both in English and Spanish.\nThe library libsvm (Chang and Lin, 2011) was used to implement the SVM classifier, using the following features for each sentence:\n\u2022 Words: those words appearing in the sentence, which are nouns, verbs or adjectives are extracted.\n\u2022 Lemmas: lemmas from nouns, verbs and adjectives are selected.\n\u2022 POS tags: part of speech from nouns, verbs and adjectives in the sentence.\n\u2022 Bigrams: all the bigrams found in the sentence.\nWe developed 12 different binary classifiers, one for each possible category. If the output of one classifier for a particular sentence is \"1\", then we add the related category to the sentence. If more than one category is found for the same sentence, we add all of them to the list of categories. After this, the outputs are improved by means of our word lists, as we can see in Algorithm 1, executed for each sentence. The word lists were created automatically from the training file, extracting all the nouns and adjectives appearing in sentences from the same category, and manually filtered later in order to remove noisy items. Six different lists are composed, containing terms related to: ambience, service, prices, quality, style options and location.\nThe inputs defined for the following algorithm are the list of categories obtained from SVM for each sentence (CList(s)) and the six word lists created previously. The output is the new list per sentence, containing the old categories from SVM and the new ones added. ", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Slot 2 Opinion target expression", "text": "For this slot, teams were asked to extract the exact expressions or words in the sentence, in which an opinion is expressed. The implementation for this slot is made by means of CRFs, using CRF++ tool (Kudo, 2005) and the training file provided for building the model. A training file is needed to build as input for the CRF, whose structure is as follows.\nIn the first column, all the words for every sentence are written, then in the second column, the corresponding lemma. The third column represents the tag and the last one represents if the word is an aspect or not or if it is included in a multiword aspect.\nThen for creating the model we take into account all these features, as well as all the possible bigrams in each sentence. In the output, if no target is found, no opinion is returned for that sentence.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Slot 3 Sentiment polarity", "text": "This slot is implemented only for English language, both restaurants and laptops datasets. Our system is fully unsupervised, this can explain the low results obtained for this slot. An adjustment was made to the system already implemented for sentiment analysis in the whole sentence, which was presented in Semeval 2015, task 10: sentiment analysis in Twitter (Fern\u00e1ndez-Gavilanes et al., 2015), which was also unsupervised. For this dataset, a new polarity lexicon was generated automatically from the training dataset, applying a polarity rank algorithm, as explained in the mentioned article. Then, it was merged with SOCAL (Taboada et al., 2011) and AFINN (Nielsen, 2011) lexicons, which are general context ones, by applying an average for those words which appeared in more than one of them.\nOur system for the restaurant dataset implements the following syntactic rules:\n\u2022 If there is no opinion or only one target expression in the sentence, the system automatically takes the polarity of the whole sentence and assign it to all the categories which appear in this sentence.\n\u2022 If there is only one different target expression but appearing more than once, we check if there is an adversative clause in the sentence built with \"but\" particle. If not, we also take the polarity of the whole sentence for all the opinions. If the previous condition is fulfilled, we will take the polarity of the first clause of the sentence, which is the piece of sentence placed before the \"but\" and then apply a polarity linear system, which consists of summing up all the polarities found in the dictionary created. For the next opinions which have the same target, we will follow the same procedure but with the piece of sentence after the \"but\". For this linear approach, we take negations in account only for adjectives, flipping the polarity of the adjectives which come inmediately after a negation particle, as \"no\" or \"not\".\n\u2022 When there are several different opinion targets, we split the sentence to detect the scope of each target and apply the same linear polarity algorithm explained in the previous point.\nTo detect the scope of the target, we take the words which appear before and after the target, splitting by punctuation marks (\";\", \",\", \".\", \"?\", \"!\", \"-\").\nFor the laptops dataset, since there are no opinion target expressions, we take the polarity of the whole sentence to assign the polarity of each category.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Subtask 2: Text-level ABSA", "text": "Subtask 2 is similar to subtask 1, but instead of implementing aspect detection at sentence-level, it is performed at text-level. Participants are asked to implement slots 1 and 3 for this subtask. We participate in slot 1 for Spanish and English language, following the same procedure for both. Slot 3 is just implemented for English language for restaurants and laptops datasets.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Slot 1 Aspect category detection", "text": "Once we performed aspect category detection at sentence-level, we use this output as input for textlevel detection. All the categories found are grouped at sentence-level and added all of them at reviewlevel. Besides this, if RESTAURANT#GENERAL is not explicitly assigned to any sentence of the review, we add it anyway.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Slot 3 Sentiment polarity", "text": "Similarly to slot 1, we use the output from subtask 1 slot 3 as input for this slot. All the polarities found are again grouped for all the sentences contained in the review and added them to text-level. If there are different polarities for the same category, some rules are applied: if polarities are negative and neutral, negative is finally assigned; if there are positive and neutral opinions, positive polarity is assigned; if there are positive and negative opinions for the same category, the tag \"conflict\" is assigned to that category at review-level.\nMoreover, as RESTAURANT#GENERAL is compulsory for every review, if no sentence has this category assigned, we take into account all the polarities of the other categories found and then assign the polarity for this category. Again, if there are different polarities containing positive and negative, \"conflict\" tag is assigned. The same process is followed for laptops dataset, with the LAPTOPS#GENERAL category.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Experimental Results", "text": "In this section, we describe the experiments carried out for the different subtasks and slots and the datasets provided by the organization. These datasets are composed of several reviews, splitted in sentences, for restaurants and laptops topics. The performance of slots 1 and 2, for both subtasks, are measured by means of the F-score, while slot 3 is evaluated by means of the accuracy.\nTable 1 represents the precision, recall and Fscore obtained for restaurants datasets and all the slots submitted. For English language, an unconstrained system was presented, while for Spanish language both constrained and unconstrained systems were submitted. The constrained approaches do not need any external resources, but only the training files provided, while in the unconstrained ones, food and drinks lexicon was used in the preprocessing step for identifying different foods and drinks.\nIt can be seen that there is not much difference between constrained and unconstrained systems for Spanish language, so we can assume that the recognition of different names of foods or drinks does not increase the knowledge of the classifiers, perform-  ing almost equally. Moreover, we can state that our system perfoms as well for English as for Spanish language.\nIn Table 2, the detailed scores for slot 3 are shown in English language, for restaurants dataset, likewise in Table 3    As it can be seen in Table 2 and Table 3, the results obtained for the sentiment slot are not quite competitive with the other teams. This can be due to the fact that our system is fully unsupervised, while the others are usually supervised systems, based on training. Moreover, we performed a simple adaptation from our original system, made for sentiment analysis in Twitter, presented to SemEval 2015, so there is still a lot of improvement on this field.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Conclusions", "text": "This paper describes the participation of the GTI group, AtlantTIC Research Center, University of Vigo, in the SemEval 2016, Task 5: Aspect-Based Sentiment Analysis. We developed a supervised system based on SVM classifiers for category detection, and CRFs for opinion target detection. Then, for the aspect-based sentiment analysis we submitted a fully unsupervised system, based on syntactic dependencies and context-based polarity lexicons.  As we can see in Table 4, competitive results were obtained for aspect and category detection, being in first position for Spanish language, both in subtask 1 and subtask 2. Moreover, in subtask 2, which is aspect detection at review level, we also achieved the first position for English language in restaurants datasets. However, our system did not perform as well as expected in slot 3, maybe due to the fact of the lack of supervision for our model. It results not competitive against other supervised approaches, although its main advantage is that there is no need of training sets, which is time and resource consuming in order to manually tag them.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgments", "text": "This work was supported by the Spanish Government, co-financed by the European Regional Development Fund (ERDF) under project TACTICA.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "", "journal": "", "year": "", "authors": "Jordi Atserias; Bernardino Casas; Elisabet Comelles; Meritxell Gonz\u00e1lez; Llu\u00eds Padr\u00f3; Muntsa Padr\u00f3"}, {"title": "Freeling 1.3: Syntactic and semantic services in an open-source nlp library", "journal": "", "year": "", "authors": ""}, {"title": "Libsvm: a library for support vector machines", "journal": "ACM Transactions on Intelligent Systems and Technology", "year": "2011", "authors": "Chih-Chung Chang; Chih-Jen Lin"}, {"title": "GTI: An Unsupervised Approach for Sentiment Analysis in Twitter", "journal": "Association for Computational Linguistics", "year": "2015-06", "authors": "Milagros Fern\u00e1ndez-Gavilanes; Tamara\u00e1lvarez L\u00f3pez; Jonathan Juncal-Mart\u00ednez; Enrique Costa-Montenegro; Francisco Javier Gonz\u00e1lez-Casta\u00f1o"}, {"title": "Crf++: Yet another crf toolkit", "journal": "", "year": "2005", "authors": "Taku Kudo"}, {"title": "Sentiment analysis and opinion mining. Synthesis lectures on human language technologies", "journal": "", "year": "2012", "authors": "Bing Liu"}, {"title": "Multi-aspect sentiment analysis with topic models", "journal": "IEEE", "year": "2011", "authors": "Bin Lu; Myle Ott; Claire Cardie; Benjamin K Tsou"}, {"title": "Hierarchical multilabel conditional random fields for aspect-oriented opinion mining", "journal": "Springer", "year": "2014", "authors": "Diego Marcheggiani; Oscar T\u00e4ckstr\u00f6m; Andrea Esuli; Fabrizio Sebastiani"}, {"title": "A new anew: Evaluation of a word list for sentiment analysis in microblogs", "journal": "", "year": "2011", "authors": "Finn\u00e5rup Nielsen"}, {"title": "Freeling 3.0: Towards wider multilinguality", "journal": "", "year": "2012", "authors": "Llu\u00eds Padr\u00f3; Evgeny Stanilovsky"}, {"title": "SemEval-2016 Task 5: Aspect Based Sentiment Analysis", "journal": "Association for Computational Linguistics", "year": "2016-06", "authors": "Maria Pontiki; Dimitrios Galanis; Haris Papageorgiou; Ion Androutsopoulos; Suresh Manandhar; Al- Mohammad; Mahmoud Smadi; Yanyan Al-Ayyoub; Bing Zhao; Orph\u00e9e Qin; V\u00e9ronique De Clercq; Marianna Hoste; Xavier Apidianaki; Natalia Tannier; Evgeny Loukachevitch;  Kotelnikov"}, {"title": "Lexicon-based methods for sentiment analysis", "journal": "Computational linguistics", "year": "2011", "authors": "Maite Taboada; Julian Brooke; Milan Tofiloski; Kimberly Voll; Manfred Stede"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Algorithm 1 :1Combining SVM outputs with word lists for a sentence s. Input: CList(s), ambienceL, serviceL, locationL, pricesL, qualityL, styleL Output: newList(s) 1 newList(s) = CList(s); 2 foreach unigram(s) do 3 if unigram(s) \u2208 ambienceL then 4 newList(s) = newList(s) \u222a {AMBIENCEs) \u2208 locationL then 10 newList(s) = newList(s) \u222a {LOCATION#GENERAL} 11 end 12 if unigram(s) \u2208 pricesL then 13 if FOOD#A \u2208 CList(s) then 14 newList(s) = newList(s)", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Measures for restaurants dataset, slots 1 and 2.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "for laptops dataset.", "figure_data": "Subt1P N NEUPrec. Rec. 84.66 76.76 80.52 F 60.5 59.31 59.9 10.48 25.00 14.77Acc. 69.96Subt2P N NEU CONFL. 7.61 63.64 13.59 87.2 76.22 81.34 62.75 38.1 47.41 18.18 8.7 11.7664.11"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Detailed scores for slot 3, restaurants dataset in English language.", "figure_data": "Subt1P N NEUPrec. Rec. 68.78 87.94 77.19 F 63.39 42.34 50.77 0 0 0Acc. 67.29Subt2P N NEU CONFL. 10.99 71.43 19.05 74.64 76.63 75.62 60.81 27.78 38.14 12.12 12.9 12.558.35"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Detailed scores for slot 3, laptops dataset in English language.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Position of our approach in the different datasets and subtasks submitted, according to the results published by the organisation.", "figure_data": ""}], "doi": ""}