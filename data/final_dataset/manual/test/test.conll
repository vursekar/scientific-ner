-DOCSTART- -X- O
All -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
hyperparameters -X- _ O
: -X- _ O
both -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
one -X- _ O
layer -X- _ O
with -X- _ O
GRU -X- _ O
cells -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
state -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
GRU -X- _ O
is -X- _ O
256 -X- _ B-HyperparameterValue
; -X- _ O
the -X- _ O
utterance -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
limited -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
; -X- _ O
the -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
50 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
000 -X- _ I-HyperparameterValue
and -X- _ O
the -X- _ O
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
is -X- _ O
256 -X- _ B-HyperparameterValue
; -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
shared -X- _ O
by -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
; -X- _ O
all -X- _ O
trainable -X- _ O
parameters -X- _ O
are -X- _ O
initialized -X- _ O
from -X- _ O
a -X- _ B-HyperparameterValue
uniform -X- _ I-HyperparameterValue
distribution -X- _ I-HyperparameterValue
[ -X- _ O
- -X- _ O
0.08 -X- _ O
, -X- _ O
0.08 -X- _ O
] -X- _ O
; -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
for -X- _ O
optimization -X- _ O
with -X- _ O
a -X- _ O
mini -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
128 -X- _ B-HyperparameterValue
and -X- _ O
initialized -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.001 -X- _ B-HyperparameterValue
; -X- _ O
the -X- _ O
gradient -X- _ O
clipping -X- _ O
strategy -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
avoid -X- _ O
gradient -X- _ O
explosion -X- _ O
, -X- _ O
where -X- _ O
the -X- _ B-HyperparameterName
gradient -X- _ I-HyperparameterName
clipping -X- _ I-HyperparameterName
value -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
dimensional -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
256 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
component -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
mixture -X- _ O
Gaussian -X- _ O
for -X- _ O
prior -X- _ O
networks -X- _ O
in -X- _ O
WAE -X- _ B-MethodName
is -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
As -X- _ O
to -X- _ O
the -X- _ O
discriminator -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
initialized -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
0.0002 -X- _ B-HyperparameterValue
and -X- _ O
use -X- _ O
128 -X- _ B-HyperparameterValue
different -X- _ O
kernels -X- _ O
for -X- _ O
each -X- _ B-HyperparameterName
kernel -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
in -X- _ O
{ -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
3 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
} -X- _ O
. -X- _ O
The -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
response -X- _ I-HyperparameterName
bag -X- _ I-HyperparameterName
is -X- _ O
limited -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
where -X- _ O
the -X- _ O
instances -X- _ O
inside -X- _ O
are -X- _ O
randomly -X- _ O
sampled -X- _ O
for -X- _ O
each -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
implemented -X- _ O
with -X- _ O
Pytorch -X- _ O
0.4.1 -X- _ O
4 -X- _ O
. -X- _ O

To -X- _ O
comprehensively -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
response -X- _ O
utterances -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
both -X- _ O
automatic -X- _ O
and -X- _ O
human -X- _ O
evaluation -X- _ O
metrics -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
: -X- _ O
In -X- _ O
dialogue -X- _ O
generation -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
is -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
previous -X- _ O
studies -X- _ O
( -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Shang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
multiple -X- _ O
valid -X- _ O
responses -X- _ O
exist -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
multi -X- _ O
- -X- _ O
reference -X- _ O
BLEU -X- _ B-MetricName
where -X- _ O
the -X- _ O
evaluated -X- _ O
utterance -X- _ O
is -X- _ O
compared -X- _ O
to -X- _ O
provided -X- _ O
multiple -X- _ O
references -X- _ O
simultaneously -X- _ O
. -X- _ O
Distinctness -X- _ O
: -X- _ O
To -X- _ O
distinguish -X- _ O
safe -X- _ O
and -X- _ O
commonplace -X- _ O
responses -X- _ O
, -X- _ O
the -X- _ O
distinctness -X- _ O
score -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
measure -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
diversity -X- _ O
by -X- _ O
counting -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
distinctive -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
] -X- _ O
- -X- _ O
grams -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
both -X- _ O
Intra -X- _ O
- -X- _ O
Dist -X- _ O
: -X- _ O
the -X- _ O
distinctness -X- _ O
scores -X- _ O
of -X- _ O
multiple -X- _ O
responses -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
query -X- _ O
and -X- _ O
Inter -X- _ O
- -X- _ O
Dist -X- _ O
: -X- _ O
the -X- _ O
distinctness -X- _ O
scores -X- _ O
of -X- _ O
generated -X- _ O
responses -X- _ O
of -X- _ O
the -X- _ O
whole -X- _ O
testing -X- _ O
set -X- _ O
. -X- _ O
Embedding -X- _ O
Similarity -X- _ O
: -X- _ O
Embedding -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
compute -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
sentence -X- _ O
embedding -X- _ O
of -X- _ O
a -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
response -X- _ O
and -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
one -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
various -X- _ O
ways -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
embedding -X- _ O
from -X- _ O
the -X- _ O
constituent -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
three -X- _ O
most -X- _ O
commonly -X- _ O
used -X- _ O
strategies -X- _ O
: -X- _ O
Greedy -X- _ O
matches -X- _ O
each -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
with -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
evaluated -X- _ O
sentence -X- _ O
; -X- _ O
Average -X- _ O
uses -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
word -X- _ O
embed -X- _ O
- -X- _ O
Input -X- _ O
火山喷发瞬间的一些壮观景象 -X- _ O
。 -X- _ O
再过十分钟就进入win8时代，我是系统升级控 -X- _ O
。 -X- _ O
Query -X- _ O
These -X- _ O
are -X- _ O
some -X- _ O
magnificent -X- _ O
sights -X- _ O
at -X- _ O
the -X- _ O
moment -X- _ O
of -X- _ O
the -X- _ O
volcanic -X- _ O
eruption -X- _ O
. -X- _ O
There -X- _ O
remain -X- _ O
ten -X- _ O
minutes -X- _ O
before -X- _ O
we -X- _ O
entering -X- _ O
the -X- _ O
era -X- _ O
of -X- _ O
win8 -X- _ O
. -X- _ O
I -X- _ O
am -X- _ O
a -X- _ O
geek -X- _ O
of -X- _ O
system -X- _ O
updating -X- _ O
. -X- _ O
What -X- _ O
application -X- _ O
is -X- _ O
this -X- _ O
. -X- _ O
如此这般这般淼小 -X- _ O
。 -X- _ O
我觉得这样的界面更像windows8 -X- _ O
。 -X- _ O
It -X- _ O
is -X- _ O
so -X- _ O
so -X- _ O
imperceptible -X- _ O
. -X- _ O
I -X- _ O
think -X- _ O
interface -X- _ O
like -X- _ O
this -X- _ O
looks -X- _ O
more -X- _ O
like -X- _ O
windows8 -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Case -X- _ O
study -X- _ O
for -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
from -X- _ O
the -X- _ O
testing -X- _ O
set -X- _ O
of -X- _ O
Weibo -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
Chinese -X- _ O
utterances -X- _ O
are -X- _ O
translated -X- _ O
into -X- _ O
English -X- _ O
for -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
readability -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
input -X- _ O
query -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
four -X- _ O
responses -X- _ O
generated -X- _ O
by -X- _ O
each -X- _ O
method -X- _ O
and -X- _ O
an -X- _ O
additional -X- _ O
intermediate -X- _ O
utterance -X- _ O
( -X- _ O
marked -X- _ O
with -X- _ O
underline -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
dings -X- _ O
; -X- _ O
and -X- _ O
Extreme -X- _ O
takes -X- _ O
the -X- _ O
most -X- _ O
extreme -X- _ O
value -X- _ O
among -X- _ O
all -X- _ O
words -X- _ O
for -X- _ O
each -X- _ O
dimension -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O
Since -X- _ O
multiple -X- _ O
references -X- _ O
exist -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
utterance -X- _ O
to -X- _ O
be -X- _ O
evaluated -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
its -X- _ O
score -X- _ O
with -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
reference -X- _ O
. -X- _ O
Human -X- _ O
Evaluation -X- _ O
with -X- _ O
Case -X- _ O
Analysis -X- _ O
: -X- _ O
As -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
lose -X- _ O
sight -X- _ O
of -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
response -X- _ O
( -X- _ O
Tao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
adopt -X- _ O
human -X- _ O
evaluation -X- _ O
on -X- _ O
100 -X- _ O
random -X- _ O
samples -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
generation -X- _ O
quality -X- _ O
with -X- _ O
three -X- _ O
independent -X- _ O
aspects -X- _ O
considered -X- _ O
: -X- _ O
relevance -X- _ O
( -X- _ O
whether -X- _ O
the -X- _ O
reply -X- _ O
is -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
) -X- _ O
, -X- _ O
diversity -X- _ O
( -X- _ O
whether -X- _ O
the -X- _ O
reply -X- _ O
narrates -X- _ O
with -X- _ O
diverse -X- _ O
words -X- _ O
) -X- _ O
and -X- _ O
readability -X- _ O
( -X- _ O
whether -X- _ O
the -X- _ O
utterance -X- _ O
is -X- _ O
grammatically -X- _ O
formed -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
property -X- _ O
is -X- _ O
assessed -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
from -X- _ O
1 -X- _ O
( -X- _ O
worst -X- _ O
) -X- _ O
to -X- _ O
5 -X- _ O
( -X- _ O
best -X- _ O
) -X- _ O
by -X- _ O
three -X- _ O
annotators -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
is -X- _ O
conducted -X- _ O
in -X- _ O
a -X- _ O
blind -X- _ O
process -X- _ O
with -X- _ O
the -X- _ O
utterance -X- _ O
belonging -X- _ O
unknown -X- _ O
to -X- _ O
the -X- _ O
reviewers -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
representative -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
approaches -X- _ O
as -X- _ O
listed -X- _ O
below -X- _ O
: -X- _ O
S2S -X- _ O
: -X- _ O
the -X- _ O
vanilla -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
with -X- _ O
attention -X- _ O
mechanism -X- _ O
where -X- _ O
standard -X- _ O
beam -X- _ O
search -X- _ O
is -X- _ O
applied -X- _ O
in -X- _ O
testing -X- _ O
to -X- _ O
generate -X- _ O
multiple -X- _ O
different -X- _ O
responses -X- _ O
. -X- _ O
Method -X- _ O
Multi -X- _ B-MetricName
- -X- _ I-MetricName
BLEU -X- _ I-MetricName
EMBEDDING -X- _ I-MetricName
Intra -X- _ I-MetricName
- -X- _ I-MetricName
Dist -X- _ I-MetricName
Inter -X- _ I-MetricName
- -X- _ O
Dist -X- _ B-MetricName
BLEU -X- _ I-MetricName
- -X- _ O
1 -X- _ O
BLEU -X- _ O
- -X- _ O
2 -X- _ O
G -X- _ B-MetricName
A -X- _ I-MetricName
E -X- _ I-MetricName
Dist -X- _ I-MetricName
- -X- _ O
1 -X- _ O
Dist -X- _ O
- -X- _ O
2 -X- _ O
S2S+DB -X- _ B-MetricName
: -X- _ O
the -X- _ O
vanilla -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
modified -X- _ O
diversity -X- _ O
- -X- _ O
promoting -X- _ O
beam -X- _ B-TaskName
search -X- _ I-TaskName
method -X- _ I-TaskName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016b -X- _ O
) -X- _ O
where -X- _ O
a -X- _ O
fixed -X- _ O
diversity -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.5 -X- _ B-HyperparameterValue
is -X- _ O
used -X- _ O
. -X- _ O
MMS -X- _ O
: -X- _ O
the -X- _ O
modified -X- _ O
multiple -X- _ O
responding -X- _ O
mechanisms -X- _ O
enhanced -X- _ O
dialogue -X- _ O
model -X- _ O
proposed -X- _ O
by -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
which -X- _ O
introduces -X- _ O
responding -X- _ O
mechanism -X- _ O
embeddings -X- _ O
for -X- _ O
diverse -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
CVAE -X- _ B-MethodName
: -X- _ O
the -X- _ O
vanilla -X- _ O
CVAE -X- _ B-MethodName
model -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
BOW -X- _ B-MetricName
( -X- _ I-MetricName
bag -X- _ I-MetricName
- -X- _ I-MetricName
of -X- _ I-MetricName
- -X- _ I-MetricName
word -X- _ I-MetricName
) -X- _ I-MetricName
loss -X- _ I-MetricName
( -X- _ I-MetricName
CVAE+BOW -X- _ B-MethodName
and -X- _ O
CVAE -X- _ B-MethodName
) -X- _ O
. -X- _ O
WAE -X- _ B-MethodName
: -X- _ O
the -X- _ O
conditional -X- _ B-MethodName
Wasserstein -X- _ I-MethodName
autoencoder -X- _ I-MethodName
model -X- _ O
for -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
models -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
data -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
GAN -X- _ B-MethodName
within -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
space -X- _ O
. -X- _ O
Ours -X- _ O
: -X- _ O
we -X- _ O
explore -X- _ O
our -X- _ O
model -X- _ O
Ours -X- _ O
and -X- _ O
conduct -X- _ O
various -X- _ O
ablation -X- _ O
studies -X- _ O
: -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
only -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
generation -X- _ O
( -X- _ O
Ours -X- _ O
- -X- _ O
First -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
the -X- _ O
discriminator -X- _ O
( -X- _ O
Ours -X- _ O
- -X- _ O
Disc -X- _ O
) -X- _ O
and -X- _ O
multireference -X- _ B-MetricName
BOW -X- _ I-MetricName
loss -X- _ I-MetricName
( -X- _ O
Ours -X- _ O
- -X- _ O
MBOW -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
GMM -X- _ O
prior -X- _ O
networks -X- _ O
( -X- _ O
Ours+GMP -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
whole -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
fashion -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
using -X- _ O
Glove -X- _ O
( -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
) -X- _ O
1 -X- _ O
. -X- _ O
Then -X- _ O
modules -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
are -X- _ O
jointly -X- _ O
trained -X- _ O
by -X- _ O
optimizing -X- _ O
the -X- _ O
losses -X- _ O
L -X- _ O
f -X- _ O
irst -X- _ O
and -X- _ O
L -X- _ O
second -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
phases -X- _ O
respectively -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
vanishing -X- _ O
latent -X- _ O
variable -X- _ O
problem -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
of -X- _ O
CVAE -X- _ B-MethodName
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
KL -X- _ B-MethodName
annealing -X- _ I-MethodName
strategy -X- _ I-MethodName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
term -X- _ O
is -X- _ O
gradually -X- _ O
increased -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
other -X- _ O
technique -X- _ O
employed -X- _ O
is -X- _ O
the -X- _ O
MBOW -X- _ B-MetricName
loss -X- _ O
which -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
sharpen -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
for -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
and -X- _ O
alleviate -X- _ O
the -X- _ O
vanishing -X- _ O
problem -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
. -X- _ O
During -X- _ O
testing -X- _ O
, -X- _ O
diverse -X- _ O
responses -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
phases -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
distinctive -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
is -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
prior -X- _ O
probability -X- _ O
network -X- _ O
. -X- _ O
This -X- _ O
process -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Capable -X- _ O
of -X- _ O
capturing -X- _ O
the -X- _ O
common -X- _ O
feature -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
, -X- _ O
the -X- _ O
variable -X- _ O
c -X- _ O
is -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
mapping -X- _ O
network -X- _ O
and -X- _ O
no -X- _ O
intermediate -X- _ O
utterance -X- _ O
is -X- _ O
required -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
reducing -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
decoding -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
generation -X- _ O
phase -X- _ O
aims -X- _ O
to -X- _ O
model -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
in -X- _ O
a -X- _ O
response -X- _ O
bag -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
CVAE -X- _ B-MethodName
architecture -X- _ O
, -X- _ O
while -X- _ O
two -X- _ O
prominent -X- _ O
modifications -X- _ O
remain -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
modeling -X- _ O
each -X- _ O
response -X- _ O
with -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
approximates -X- _ O
each -X- _ O
response -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
bag -X- _ O
representation -X- _ O
c -X- _ O
with -X- _ O
only -X- _ O
the -X- _ O
distinctive -X- _ O
feature -X- _ O
of -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
remaining -X- _ O
to -X- _ O
be -X- _ O
captured -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
the -X- _ O
prior -X- _ O
common -X- _ O
feature -X- _ O
c -X- _ O
can -X- _ O
provide -X- _ O
extra -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
sampling -X- _ O
network -X- _ O
which -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
decrease -X- _ O
the -X- _ O
latent -X- _ O
searching -X- _ O
space -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
CVAE -X- _ B-MethodName
architecture -X- _ O
, -X- _ O
the -X- _ O
overall -X- _ O
objective -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
generation -X- _ O
phase -X- _ O
is -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
L -X- _ O
cvae -X- _ O
= -X- _ O
E -X- _ O
q -X- _ O
φ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
c -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
[ -X- _ O
log -X- _ O
p -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
c -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
] -X- _ O
− -X- _ O
D -X- _ O
[ -X- _ O
q -X- _ O
φ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
| -X- _ O
| -X- _ O
p -X- _ O
ϕ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
where -X- _ O
q -X- _ O
φ -X- _ O
represents -X- _ O
the -X- _ O
recognition -X- _ O
network -X- _ O
and -X- _ O
p -X- _ O
ϕ -X- _ O
is -X- _ O
the -X- _ O
prior -X- _ O
network -X- _ O
with -X- _ O
φ -X- _ O
and -X- _ O
ϕ -X- _ O
as -X- _ O
the -X- _ O
trainable -X- _ O
parameters -X- _ O
; -X- _ O
D -X- _ O
( -X- _ O
| -X- _ O
| -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
regularization -X- _ O
term -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
distributions -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
the -X- _ O
recognition -X- _ O
networks -X- _ O
are -X- _ O
implemented -X- _ O
with -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
that -X- _ O
µ -X- _ O
log -X- _ O
σ -X- _ O
2 -X- _ O
= -X- _ O
W -X- _ O
q -X- _ O
 -X- _ O
 -X- _ O
h -X- _ O
x -X- _ O
h -X- _ O
y -X- _ O
c -X- _ O
 -X- _ O
 -X- _ O
+ -X- _ O
b -X- _ O
q -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
h -X- _ O
x -X- _ O
and -X- _ O
h -X- _ O
y -X- _ O
are -X- _ O
the -X- _ O
utterance -X- _ O
representations -X- _ O
of -X- _ O
query -X- _ O
and -X- _ O
response -X- _ O
got -X- _ O
by -X- _ O
GRU -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
∼ -X- _ O
N -X- _ O
( -X- _ O
µ -X- _ O
, -X- _ O
σ -X- _ O
2 -X- _ O
I -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
prior -X- _ O
networks -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
implements -X- _ O
. -X- _ O
One -X- _ O
is -X- _ O
the -X- _ O
vanilla -X- _ O
CVAE -X- _ B-MethodName
model -X- _ O
where -X- _ O
the -X- _ O
prior -X- _ O
p -X- _ O
ϕ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
another -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
representations -X- _ O
h -X- _ O
x -X- _ O
and -X- _ O
c -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
µ -X- _ O
log -X- _ O
σ -X- _ O
2 -X- _ O
= -X- _ O
W -X- _ O
p -X- _ O
h -X- _ O
x -X- _ O
c -X- _ O
+ -X- _ O
b -X- _ O
p -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
distance -X- _ O
D -X- _ O
( -X- _ O
| -X- _ O
| -X- _ O
) -X- _ O
here -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
KL -X- _ B-MetricName
divergence -X- _ I-MetricName
. -X- _ O
For -X- _ O
the -X- _ O
other -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
WAE -X- _ B-MethodName
model -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
prior -X- _ O
p -X- _ O
ϕ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
Gaussian -X- _ O
distributions -X- _ O
GMM -X- _ O
( -X- _ O
π -X- _ O
k -X- _ O
, -X- _ O
µ -X- _ O
k -X- _ O
, -X- _ O
σ -X- _ O
k -X- _ O
2 -X- _ O
I -X- _ O
) -X- _ O
K -X- _ O
k=1 -X- _ O
, -X- _ O
where -X- _ O
K -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
Gaussian -X- _ O
distributions -X- _ O
and -X- _ O
π -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
mixture -X- _ O
coefficient -X- _ O
of -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
th -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
GMM -X- _ O
module -X- _ O
as -X- _ O
computed -X- _ O
: -X- _ O
π -X- _ O
k -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
e -X- _ O
k -X- _ O
) -X- _ O
K -X- _ O
i=1 -X- _ O
exp -X- _ O
( -X- _ O
e -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
and -X- _ O
 -X- _ O
 -X- _ O
e -X- _ O
k -X- _ O
µ -X- _ O
k -X- _ O
log -X- _ O
σ -X- _ O
2 -X- _ O
k -X- _ O
 -X- _ O
 -X- _ O
= -X- _ O
W -X- _ O
p -X- _ O
, -X- _ O
k -X- _ O
h -X- _ O
x -X- _ O
c -X- _ O
+ -X- _ O
b -X- _ O
p -X- _ O
, -X- _ O
k -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
To -X- _ O
sample -X- _ O
an -X- _ O
instance -X- _ O
, -X- _ O
Gumble -X- _ O
- -X- _ O
Softmax -X- _ O
reparametrization -X- _ O
trick -X- _ O
( -X- _ O
Kusner -X- _ O
and -X- _ O
Hernández -X- _ O
- -X- _ O
Lobato -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
normalize -X- _ O
the -X- _ O
coefficients -X- _ O
. -X- _ O
The -X- _ O
distance -X- _ O
here -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
Wasserstein -X- _ O
distance -X- _ O
which -X- _ O
is -X- _ O
implemented -X- _ O
with -X- _ O
an -X- _ O
adversarial -X- _ O
discriminator -X- _ O
. -X- _ O
Recap -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
generation -X- _ O
phase -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
only -X- _ O
capture -X- _ O
the -X- _ O
distinctive -X- _ O
feature -X- _ O
of -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
. -X- _ O
Hence -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
for -X- _ O
each -X- _ O
separate -X- _ O
response -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
introduce -X- _ O
a -X- _ O
multireference -X- _ B-MetricName
bag -X- _ I-MetricName
- -X- _ I-MetricName
of -X- _ I-MetricName
- -X- _ I-MetricName
word -X- _ I-MetricName
loss -X- _ I-MetricName
( -X- _ I-MetricName
MBOW -X- _ I-MetricName
) -X- _ I-MetricName
which -X- _ O
requires -X- _ O
the -X- _ O
network -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
current -X- _ O
response -X- _ O
y -X- _ O
against -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
: -X- _ O
L -X- _ O
mbow -X- _ O
= -X- _ O
E -X- _ O
q -X- _ O
φ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
[ -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
bow -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
+ -X- _ O
λ -X- _ O
log -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
( -X- _ O
{ -X- _ O
ȳ -X- _ O
} -X- _ O
bow -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
probability -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
a -X- _ O
feedforward -X- _ O
network -X- _ O
f -X- _ O
as -X- _ O
the -X- _ O
vanilla -X- _ O
bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
word -X- _ O
loss -X- _ O
does -X- _ O
; -X- _ O
{ -X- _ O
ȳ -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
complementary -X- _ O
response -X- _ O
bag -X- _ O
of -X- _ O
y -X- _ O
and -X- _ O
its -X- _ O
probability -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
probability -X- _ O
of -X- _ O
responses -X- _ O
in -X- _ O
the -X- _ O
bag -X- _ O
; -X- _ O
and -X- _ O
λ -X- _ O
is -X- _ O
a -X- _ O
scaling -X- _ O
factor -X- _ O
accounting -X- _ O
for -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
magnitude -X- _ O
. -X- _ O
As -X- _ O
it -X- _ O
shows -X- _ O
, -X- _ O
the -X- _ O
MBOW -X- _ O
loss -X- _ O
penalizes -X- _ O
the -X- _ O
recognition -X- _ O
networks -X- _ O
if -X- _ O
other -X- _ O
complementary -X- _ O
responses -X- _ O
can -X- _ O
be -X- _ O
predicted -X- _ O
from -X- _ O
the -X- _ O
distinctive -X- _ O
variable -X- _ O
z. -X- _ O
Besides -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
complementary -X- _ O
term -X- _ O
may -X- _ O
approach -X- _ O
zero -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
optimize -X- _ O
, -X- _ O
we -X- _ O
actually -X- _ O
adopt -X- _ O
its -X- _ O
lower -X- _ O
bound -X- _ O
in -X- _ O
practice -X- _ O
: -X- _ O
log -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
bow -X- _ O
| -X- _ O
x -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
log -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
| -X- _ O
y -X- _ O
| -X- _ O
t=1 -X- _ O
e -X- _ O
fy -X- _ O
t -X- _ O
| -X- _ O
V -X- _ O
| -X- _ O
j -X- _ O
e -X- _ O
f -X- _ O
j -X- _ O
) -X- _ O
≥ -X- _ O
log -X- _ O
( -X- _ O
| -X- _ O
y -X- _ O
| -X- _ O
t=1 -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
e -X- _ O
fy -X- _ O
t -X- _ O
| -X- _ O
V -X- _ O
| -X- _ O
j -X- _ O
e -X- _ O
f -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
where -X- _ O
| -X- _ O
V -X- _ O
| -X- _ O
is -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
Totally -X- _ O
, -X- _ O
the -X- _ O
whole -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
step -X- _ O
- -X- _ O
two -X- _ O
generation -X- _ O
is -X- _ O
then -X- _ O
: -X- _ O
L -X- _ O
second -X- _ O
= -X- _ O
L -X- _ O
cvae -X- _ O
+ -X- _ O
L -X- _ O
mbow -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
optimized -X- _ O
in -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
way -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
generation -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
map -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
query -X- _ O
x -X- _ O
to -X- _ O
the -X- _ O
common -X- _ O
feature -X- _ O
c -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ B-TaskName
multi -X- _ I-TaskName
- -X- _ I-TaskName
instance -X- _ I-TaskName
learning -X- _ I-TaskName
( -X- _ O
Zhou -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
from -X- _ O
the -X- _ O
simple -X- _ O
intuition -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
much -X- _ O
easier -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
fit -X- _ O
multiple -X- _ O
instances -X- _ O
from -X- _ O
their -X- _ O
mid -X- _ O
- -X- _ O
point -X- _ O
than -X- _ O
a -X- _ O
random -X- _ O
start -X- _ O
- -X- _ O
point -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
To -X- _ O
obtain -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
common -X- _ O
feature -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
as -X- _ O
the -X- _ O
mid -X- _ O
- -X- _ O
point -X- _ O
of -X- _ O
embeddings -X- _ O
of -X- _ O
multiple -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
encode -X- _ O
the -X- _ O
input -X- _ O
x -X- _ O
with -X- _ O
a -X- _ O
bidirectional -X- _ O
gated -X- _ O
recurrent -X- _ O
units -X- _ O
( -X- _ O
GRU -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
input -X- _ O
representation -X- _ O
h -X- _ O
x -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
common -X- _ O
feature -X- _ O
c -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
a -X- _ O
mapping -X- _ O
network -X- _ O
which -X- _ O
is -X- _ O
implemented -X- _ O
by -X- _ O
a -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
whose -X- _ O
trainable -X- _ O
parameter -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
θ -X- _ O
. -X- _ O
The -X- _ O
feature -X- _ O
c -X- _ O
is -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
response -X- _ O
decoder -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
intermediate -X- _ O
response -X- _ O
y -X- _ O
c -X- _ O
which -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
approximate -X- _ O
all -X- _ O
valid -X- _ O
responses -X- _ O
. -X- _ O
Mathematically -X- _ O
, -X- _ O
the -X- _ O
objective -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
L -X- _ O
avg -X- _ O
= -X- _ O
1 -X- _ O
| -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
| -X- _ O
y -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
log -X- _ O
p -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
c -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
| -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
| -X- _ O
is -X- _ O
the -X- _ O
cardinality -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
and -X- _ O
p -X- _ O
ψ -X- _ O
represents -X- _ O
the -X- _ O
response -X- _ O
decoder -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
to -X- _ O
measure -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
intermediate -X- _ O
response -X- _ O
y -X- _ O
c -X- _ O
approximates -X- _ O
the -X- _ O
mid -X- _ O
- -X- _ O
point -X- _ O
response -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
up -X- _ O
an -X- _ O
individual -X- _ O
discriminator -X- _ O
and -X- _ O
derive -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
to -X- _ O
produce -X- _ O
better -X- _ O
results -X- _ O
. -X- _ O
As -X- _ O
to -X- _ O
the -X- _ O
discriminator -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
project -X- _ O
each -X- _ O
utterance -X- _ O
to -X- _ O
an -X- _ O
embedding -X- _ O
space -X- _ O
with -X- _ O
fixed -X- _ O
dimensionality -X- _ O
via -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
CNNs -X- _ O
) -X- _ O
with -X- _ O
different -X- _ O
kernels -X- _ O
as -X- _ O
the -X- _ O
process -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
of -X- _ O
the -X- _ O
query -X- _ O
and -X- _ O
response -X- _ O
embeddings -X- _ O
is -X- _ O
computed -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
D -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
θ -X- _ O
represents -X- _ O
trainable -X- _ O
parameter -X- _ O
in -X- _ O
the -X- _ O
discriminator -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
response -X- _ O
bag -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
response -X- _ O
embedding -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
matching -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O
The -X- _ O
objective -X- _ O
of -X- _ O
intermediate -X- _ O
response -X- _ O
y -X- _ O
c -X- _ O
is -X- _ O
then -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
D -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
c -X- _ O
) -X- _ O
and -X- _ O
D -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
) -X- _ O
: -X- _ O
L -X- _ O
disc -X- _ O
= -X- _ O
E -X- _ O
x -X- _ O
, -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
, -X- _ O
y -X- _ O
c -X- _ O
[ -X- _ O
D -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
c -X- _ O
) -X- _ O
− -X- _ O
D -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
where -X- _ O
y -X- _ O
c -X- _ O
denotes -X- _ O
the -X- _ O
utterance -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
decoder -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
variable -X- _ O
c. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
discrete -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
breaks -X- _ O
down -X- _ O
gradient -X- _ O
propagation -X- _ O
from -X- _ O
the -X- _ O
discriminator -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
" -X- _ O
soft -X- _ O
" -X- _ O
continuous -X- _ O
approximation -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
: -X- _ O
y -X- _ O
ct -X- _ O
∼ -X- _ O
softmax -X- _ O
( -X- _ O
o -X- _ O
t -X- _ O
/τ -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
o -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
logit -X- _ O
vector -X- _ O
as -X- _ O
the -X- _ O
inputs -X- _ O
to -X- _ O
the -X- _ O
softmax -X- _ O
function -X- _ O
at -X- _ O
time -X- _ O
- -X- _ O
step -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
temperature -X- _ O
τ -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
τ -X- _ O
0 -X- _ O
as -X- _ O
training -X- _ O
proceeds -X- _ O
for -X- _ O
increasingly -X- _ O
peaked -X- _ O
distributions -X- _ O
. -X- _ O
The -X- _ O
whole -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
step -X- _ O
- -X- _ O
one -X- _ O
generation -X- _ O
is -X- _ O
then -X- _ O
L -X- _ O
f -X- _ O
irst -X- _ O
= -X- _ O
L -X- _ O
avg -X- _ O
+ -X- _ O
L -X- _ O
disc -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
optimized -X- _ O
by -X- _ O
a -X- _ O
minimax -X- _ O
game -X- _ O
with -X- _ O
adversarial -X- _ B-TaskName
training -X- _ I-TaskName
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

Along -X- _ O
with -X- _ O
the -X- _ O
flourishing -X- _ O
development -X- _ O
of -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
the -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
framework -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
for -X- _ O
conversation -X- _ B-TaskName
response -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
Shang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sordoni -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
mapping -X- _ O
from -X- _ O
a -X- _ O
query -X- _ O
x -X- _ O
to -X- _ O
a -X- _ O
reply -X- _ O
y -X- _ O
is -X- _ O
learned -X- _ O
with -X- _ O
the -X- _ O
negative -X- _ O
log -X- _ O
likelihood -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
" -X- _ O
safe -X- _ O
" -X- _ O
response -X- _ O
problem -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
various -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016a -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
diversity -X- _ O
- -X- _ O
promoting -X- _ O
objective -X- _ O
function -X- _ O
to -X- _ O
encourage -X- _ O
diverse -X- _ O
responses -X- _ O
during -X- _ O
decoding -X- _ O
. -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
, -X- _ O
2018a -X- _ O
introduce -X- _ O
a -X- _ O
responding -X- _ O
mechanism -X- _ O
between -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
to -X- _ O
generate -X- _ O
various -X- _ O
responses -X- _ O
. -X- _ O
incorporate -X- _ O
topic -X- _ O
information -X- _ O
to -X- _ O
generate -X- _ O
informative -X- _ O
responses -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
deterministic -X- _ O
structure -X- _ O
when -X- _ O
generating -X- _ O
multiple -X- _ O
diverse -X- _ O
responses -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
response -X- _ O
utterances -X- _ O
are -X- _ O
only -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
and -X- _ O
ignored -X- _ O
when -X- _ O
forward -X- _ O
computing -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
confuse -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
pursuing -X- _ O
multiple -X- _ O
objectives -X- _ O
simultaneously -X- _ O
. -X- _ O
A -X- _ O
few -X- _ O
works -X- _ O
explore -X- _ O
to -X- _ O
change -X- _ O
the -X- _ O
deterministic -X- _ O
structure -X- _ O
of -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
by -X- _ O
introducing -X- _ O
stochastic -X- _ O
latent -X- _ O
variables -X- _ O
. -X- _ O
VAE -X- _ B-MethodName
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
popular -X- _ O
methods -X- _ O
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Serban -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Cao -X- _ O
and -X- _ O
Clark -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
discourse -X- _ O
- -X- _ O
level -X- _ O
diversity -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
Gaussian -X- _ O
distribution -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
observed -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
CVAE -X- _ B-MethodName
with -X- _ O
a -X- _ O
fixed -X- _ O
Gaussian -X- _ O
prior -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
conditional -X- _ O
posteriors -X- _ O
tend -X- _ O
to -X- _ O
collapse -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
mode -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
relatively -X- _ O
simple -X- _ O
scope -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
, -X- _ O
WAE -X- _ B-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
adopts -X- _ O
a -X- _ O
Gaussian -X- _ O
mixture -X- _ O
prior -X- _ O
network -X- _ O
with -X- _ O
Wasserstein -X- _ B-MetricName
distance -X- _ I-MetricName
and -X- _ O
VAD -X- _ B-MetricName
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
sequentially -X- _ O
introduces -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
latent -X- _ O
variables -X- _ O
to -X- _ O
condition -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
response -X- _ O
sequence -X- _ O
are -X- _ O
proposed -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
models -X- _ O
overcome -X- _ O
the -X- _ O
deterministic -X- _ O
structure -X- _ O
of -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
, -X- _ O
they -X- _ O
still -X- _ O
ignore -X- _ O
the -X- _ O
correlation -X- _ O
of -X- _ O
multiple -X- _ O
valid -X- _ O
responses -X- _ O
and -X- _ O
each -X- _ O
case -X- _ O
is -X- _ O
trained -X- _ O
separately -X- _ O
. -X- _ O
To -X- _ O
consider -X- _ O
the -X- _ O
multiple -X- _ O
responses -X- _ O
jointly -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
likelihood -X- _ O
strategy -X- _ O
is -X- _ O
explored -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
propose -X- _ O
the -X- _ O
maximum -X- _ O
generated -X- _ O
likelihood -X- _ O
criteria -X- _ O
which -X- _ O
model -X- _ O
a -X- _ O
query -X- _ O
with -X- _ O
its -X- _ O
multiple -X- _ O
responses -X- _ O
as -X- _ O
a -X- _ O
bag -X- _ O
of -X- _ O
instances -X- _ O
and -X- _ O
proposes -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
model -X- _ O
towards -X- _ O
the -X- _ O
most -X- _ O
likely -X- _ O
answer -X- _ O
rather -X- _ O
than -X- _ O
all -X- _ O
possible -X- _ O
responses -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Rajendran -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
reward -X- _ O
the -X- _ O
dialogue -X- _ O
system -X- _ O
if -X- _ O
any -X- _ O
valid -X- _ O
answer -X- _ O
is -X- _ O
produced -X- _ O
in -X- _ O
the -X- _ O
reinforcement -X- _ O
learning -X- _ O
phase -X- _ O
. -X- _ O
Though -X- _ O
considering -X- _ O
multiple -X- _ O
responses -X- _ O
jointly -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
likelihood -X- _ O
strategy -X- _ O
fails -X- _ O
to -X- _ O
utilize -X- _ O
all -X- _ O
the -X- _ O
references -X- _ O
during -X- _ O
training -X- _ O
with -X- _ O
some -X- _ O
cases -X- _ O
ig -X- _ O
- -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
dialogue -X- _ O
system -X- _ O
where -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
steps -X- _ O
and -X- _ O
testing -X- _ O
process -X- _ O
are -X- _ O
illustrated -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
query -X- _ O
x -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
aims -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
multiple -X- _ O
responses -X- _ O
in -X- _ O
a -X- _ O
bag -X- _ O
{ -X- _ O
y -X- _ O
} -X- _ O
simultaneously -X- _ O
with -X- _ O
the -X- _ O
continuous -X- _ O
common -X- _ O
and -X- _ O
distinctive -X- _ O
features -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
latent -X- _ O
variables -X- _ O
c -X- _ O
and -X- _ O
z -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
phases -X- _ O
respectively -X- _ O
. -X- _ O
nored -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
multiple -X- _ O
responses -X- _ O
jointly -X- _ O
and -X- _ O
model -X- _ O
each -X- _ O
specific -X- _ O
response -X- _ O
separately -X- _ O
by -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
generation -X- _ O
architecture -X- _ O
. -X- _ O

We -X- _ O
tested -X- _ O
our -X- _ O
framework -X- _ O
on -X- _ O
another -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
distantly -X- _ O
supervised -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
DS -X- _ B-TaskName
- -X- _ I-TaskName
QA -X- _ I-TaskName
) -X- _ O
task -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
check -X- _ O
its -X- _ O
generalizability -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
statistics -X- _ O
for -X- _ O
the -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
three -X- _ O
, -X- _ O
Quasar -X- _ B-DatasetName
- -X- _ I-DatasetName
T -X- _ I-DatasetName
, -X- _ O
SearchQA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
TriviaQA -X- _ B-DatasetName
provided -X- _ O
by -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
were -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
evaluating -X- _ O
DS -X- _ B-TaskName
- -X- _ I-TaskName
QA -X- _ I-TaskName
methods -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
data -X- _ O
of -X- _ B-DatasetName
SQuAD -X- _ I-DatasetName
v1.1 -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
was -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
our -X- _ O
AGR -X- _ O
. -X- _ O
The -X- _ B-DatasetName
SQuAD -X- _ I-DatasetName
dataset -X- _ I-DatasetName
consisted -X- _ O
of -X- _ O
the -X- _ O
triples -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
paragraph -X- _ O
that -X- _ O
includes -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
answers -X- _ O
are -X- _ O
our -X- _ O
compact -X- _ O
answers -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
are -X- _ O
consecutive -X- _ O
short -X- _ O
word -X- _ O
sequences -X- _ O
( -X- _ O
2.8 -X- _ O
words -X- _ O
on -X- _ O
average -X- _ O
) -X- _ O
, -X- _ O
whose -X- _ O
majority -X- _ O
are -X- _ O
noun -X- _ O
phrases -X- _ O
, -X- _ O
unlike -X- _ O
the -X- _ O
compact -X- _ O
answers -X- _ O
for -X- _ O
our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
experiment -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
sentences -X- _ O
or -X- _ O
phrases -X- _ O
( -X- _ O
8.3 -X- _ O
words -X- _ O
on -X- _ O
average -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
trained -X- _ O
our -X- _ O
AGR -X- _ O
with -X- _ O
all -X- _ O
the -X- _ O
triples -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
paragraph -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
SQuAD -X- _ B-DatasetName
- -X- _ I-DatasetName
v1.1 -X- _ I-DatasetName
under -X- _ O
the -X- _ O
same -X- _ O
settings -X- _ O
for -X- _ O
the -X- _ O
AGR -X- _ O
's -X- _ O
hyperparameters -X- _ O
as -X- _ O
in -X- _ O
our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
experiment -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
neither -X- _ O
causal -X- _ O
word -X- _ O
embeddings -X- _ O
nor -X- _ O
causality -X- _ O
- -X- _ O
attention -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
AGR -X- _ O
training -X- _ O
schemes -X- _ O
for -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ O
) -X- _ O
and -X- _ O
Ours -X- _ O
( -X- _ O
RV -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
300 -X- _ O
- -X- _ O
dimensional -X- _ O
GloVe -X- _ O
word -X- _ O
embeddings -X- _ O
learned -X- _ O
from -X- _ O
840 -X- _ O
billion -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
web -X- _ O
crawl -X- _ O
data -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
general -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
combined -X- _ O
the -X- _ O
resulting -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
F -X- _ O
in -X- _ O
the -X- _ O
AGR -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
DS -X- _ B-TaskName
- -X- _ I-TaskName
QA -X- _ I-TaskName
method -X- _ I-TaskName
, -X- _ O
OpenQA -X- _ B-TaskName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
used -X- _ O
the -X- _ O
hyperparameters -X- _ O
presented -X- _ O
in -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
OpenQA -X- _ B-TaskName
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
components -X- _ O
: -X- _ O
a -X- _ O
paragraph -X- _ O
selector -X- _ O
to -X- _ O
choose -X- _ O
relevant -X- _ O
paragraphs -X- _ O
( -X- _ O
or -X- _ O
answer -X- _ O
passages -X- _ O
in -X- _ O
our -X- _ O
terms -X- _ O
) -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
paragraphs -X- _ O
and -X- _ O
a -X- _ O
paragraph -X- _ O
reader -X- _ O
to -X- _ O
extract -X- _ O
answers -X- _ O
from -X- _ O
the -X- _ O
selected -X- _ O
paragraphs -X- _ O
. -X- _ O
For -X- _ O
identifying -X- _ O
answer -X- _ O
a -X- _ O
to -X- _ O
given -X- _ O
question -X- _ O
q -X- _ O
from -X- _ O
set -X- _ O
of -X- _ O
paragraphs -X- _ O
P -X- _ O
= -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
paragraph -X- _ O
selector -X- _ O
and -X- _ O
the -X- _ O
paragraph -X- _ O
reader -X- _ O
respectively -X- _ O
compute -X- _ O
probabilities -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
a -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
final -X- _ O
output -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
a -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
probabilities -X- _ O
. -X- _ O
We -X- _ O
introduced -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
representation -X- _ O
generated -X- _ O
by -X- _ O
fakerepresentation -X- _ O
generator -X- _ O
F -X- _ O
with -X- _ O
question -X- _ O
q -X- _ O
and -X- _ O
paragraph -X- _ O
p -X- _ O
i -X- _ O
as -X- _ O
its -X- _ O
input -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
the -X- _ O
probabilities -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
a -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
P -X- _ O
, -X- _ O
C -X- _ O
) -X- _ O
= -X- _ O
i -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
a -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
P -X- _ O
r -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
P -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
In -X- _ O
the -X- _ O
original -X- _ O
OpenQA -X- _ O
, -X- _ O
the -X- _ O
paragraph -X- _ O
selector -X- _ O
and -X- _ O
the -X- _ O
reader -X- _ O
use -X- _ O
bidirectional -X- _ O
stacked -X- _ O
RNNs -X- _ O
for -X- _ O
encoding -X- _ O
paragraphs -X- _ O
, -X- _ O
where -X- _ O
word -X- _ O
embeddings -X- _ O
p -X- _ O
i -X- _ O
of -X- _ O
a -X- _ O
paragraph -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
implementation -X- _ O
, -X- _ O
we -X- _ O
computed -X- _ O
attention -X- _ O
- -X- _ O
weighted -X- _ O
embeddingp -X- _ O
i -X- _ O
of -X- _ O
a -X- _ O
paragraph -X- _ O
by -X- _ O
using -X- _ O
compactanswer -X- _ O
representation -X- _ O
c -X- _ O
i -X- _ O
. -X- _ O
Given -X- _ O
word -X- _ O
embedding -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
for -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
in -X- _ O
paragraph -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
its -X- _ O
attentionweighted -X- _ O
embeddingp -X- _ O
j -X- _ O
i -X- _ O
was -X- _ O
computed -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
bilinear -X- _ O
function -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
: -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
= -X- _ O
softmax -X- _ O
j -X- _ O
( -X- _ O
p -X- _ O
T -X- _ O
i -X- _ O
Mc -X- _ O
i -X- _ O
) -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
, -X- _ O
where -X- _ O
M -X- _ O
R -X- _ O
d×d -X- _ O
is -X- _ O
a -X- _ O
trainable -X- _ O
matrix -X- _ O
, -X- _ O
softmax -X- _ O
j -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
element -X- _ O
of -X- _ O
the -X- _ O
softmaxed -X- _ O
vector -X- _ O
of -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
d -X- _ O
= -X- _ O
300 -X- _ O
. -X- _ O
We -X- _ O
gave -X- _ O
[ -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
; -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
] -X- _ O
, -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
p -X- _ O
j -X- _ O
i -X- _ O
andp -X- _ O
j -X- _ O
i -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
in -X- _ O
paragraph -X- _ O
p -X- _ O
i -X- _ O
to -X- _ O
the -X- _ O
bidirectional -X- _ O
stacked -X- _ O
RNNs -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
DS -X- _ O
- -X- _ O
QA -X- _ O
methods -X- _ O
: -X- _ O
R -X- _ B-MethodName
3 -X- _ I-MethodName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
OpenQA -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
Ours -X- _ O
( -X- _ O
RV -X- _ B-MethodName
) -X- _ O
evaluated -X- _ O
against -X- _ O
the -X- _ O
Quasar -X- _ B-DatasetName
- -X- _ I-DatasetName
T -X- _ I-DatasetName
, -X- _ O
SearchQA -X- _ B-DatasetName
and -X- _ O
TriviaQA -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
methods -X- _ O
were -X- _ O
evaluated -X- _ O
with -X- _ O
EM -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
, -X- _ O
following -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
EM -X- _ B-MetricName
measures -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
predictions -X- _ O
that -X- _ O
exactly -X- _ O
match -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answers -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
is -X- _ O
a -X- _ O
metric -X- _ O
that -X- _ O
loosely -X- _ O
measures -X- _ O
the -X- _ O
average -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
prediction -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answer -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
both -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ B-MethodName
) -X- _ O
and -X- _ O
Ours -X- _ O
( -X- _ O
RV -X- _ B-MethodName
) -X- _ O
outperformed -X- _ O
both -X- _ O
previous -X- _ O
methods -X- _ O
, -X- _ O
R -X- _ B-MethodName
3 -X- _ I-MethodName
and -X- _ O
OpenQA -X- _ B-MethodName
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
for -X- _ O
the -X- _ O
TriviaQA -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Some -X- _ O
of -X- _ O
the -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
method -X- _ O
, -X- _ O
OpenQA -X- _ B-MethodName
, -X- _ O
were -X- _ O
statistically -X- _ O
significant -X- _ O
. -X- _ O
These -X- _ O
findings -X- _ O
suggest -X- _ O
that -X- _ O
our -X- _ O
framework -X- _ O
can -X- _ O
be -X- _ O
effective -X- _ O
for -X- _ O
tasks -X- _ O
other -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O

Another -X- _ O
interesting -X- _ O
point -X- _ O
is -X- _ O
that -X- _ O
Ours -X- _ O
( -X- _ O
RV -X- _ B-MethodName
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
F -X- _ O
RV -X- _ O
was -X- _ O
trained -X- _ O
using -X- _ O
random -X- _ O
vectors -X- _ O
, -X- _ O
achieved -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
performance -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
was -X- _ O
puzzling -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
first -X- _ O
checked -X- _ O
whether -X- _ O
F -X- _ O
RV -X- _ B-MethodName
's -X- _ O
output -X- _ O
was -X- _ O
not -X- _ O
just -X- _ O
random -X- _ O
noise -X- _ O
( -X- _ O
which -X- _ O
could -X- _ O
prevent -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
model -X- _ O
from -X- _ O
overfitting -X- _ O
) -X- _ O
by -X- _ O
replacing -X- _ O
in -X- _ O
Ours -X- _ O
( -X- _ O
RV -X- _ B-MethodName
) -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
F -X- _ O
RV -X- _ B-MethodName
by -X- _ O
random -X- _ O
vectors -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
sampled -X- _ O
the -X- _ O
random -X- _ O
vectors -X- _ O
from -X- _ O
different -X- _ O
distribution -X- _ O
types -X- _ O
with -X- _ O
various -X- _ O
ranges -X- _ O
, -X- _ O
we -X- _ O
obtained -X- _ O
at -X- _ O
best -X- _ O
similar -X- _ O
performance -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
BASE -X- _ B-MethodName
: -X- _ O
51.6 -X- _ B-MetricValue
in -X- _ O
P@1 -X- _ B-MetricName
. -X- _ O
This -X- _ O
result -X- _ O
confirms -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
trivial -X- _ O
to -X- _ O
mimic -X- _ O
F -X- _ O
RV -X- _ B-MethodName
using -X- _ O
random -X- _ O
vectors -X- _ O
at -X- _ O
least -X- _ O
. -X- _ O
We -X- _ O
investigated -X- _ O
the -X- _ O
F -X- _ O
RV -X- _ B-MethodName
's -X- _ O
output -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
it -X- _ O
actually -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
compact -X- _ O
answer -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
passage -X- _ O
. -X- _ O
We -X- _ O
computed -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
representation -X- _ O
sets -X- _ O
from -X- _ O
a -X- _ O
gold -X- _ O
set -X- _ O
of -X- _ O
3 -X- _ O
, -X- _ O
608 -X- _ O
triples -X- _ O
of -X- _ O
why -X- _ O
- -X- _ O
questions -X- _ O
, -X- _ O
answer -X- _ O
passages -X- _ O
and -X- _ O
manually -X- _ O
created -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
overlap -X- _ O
with -X- _ O
CmpAns -X- _ O
: -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
: -X- _ O
F -X- _ B-MethodName
RV -X- _ I-MethodName
's -X- _ O
output -X- _ O
with -X- _ O
the -X- _ O
pairs -X- _ O
of -X- _ O
a -X- _ O
whyquestion -X- _ O
and -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
set -X- _ O
as -X- _ O
its -X- _ O
input -X- _ O
; -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
: -X- _ O
F -X- _ O
RV -X- _ B-MethodName
's -X- _ O
output -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
as -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
replaced -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
content -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
passages -X- _ O
that -X- _ O
also -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
associated -X- _ O
gold -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
with -X- _ O
random -X- _ O
vectors -X- _ O
; -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
: -X- _ O
F -X- _ O
RV -X- _ O
's -X- _ O
output -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
as -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
replaced -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
content -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
passages -X- _ O
that -X- _ O
did -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
associated -X- _ O
gold -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
with -X- _ O
random -X- _ O
vectors -X- _ O
6 -X- _ O
. -X- _ O
If -X- _ O
F -X- _ B-MethodName
RV -X- _ I-MethodName
perfectly -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
- -X- _ O
passage -X- _ O
pair -X- _ O
, -X- _ O
6 -X- _ O
For -X- _ O
both -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
and -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
never -X- _ O
replaced -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
also -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
should -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
and -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
should -X- _ O
significantly -X- _ O
differ -X- _ O
from -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
. -X- _ O
Next -X- _ O
we -X- _ O
computed -X- _ O
the -X- _ O
average -X- _ O
Euclidian -X- _ O
distance -X- _ O
among -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
distance -X- _ O
( -X- _ O
2.67 -X- _ O
) -X- _ O
between -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
was -X- _ O
much -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
average -X- _ O
distance -X- _ O
( -X- _ O
13.3 -X- _ O
) -X- _ O
between -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
replaced -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
much -X- _ O
more -X- _ O
words -X- _ O
with -X- _ O
random -X- _ O
vectors -X- _ O
in -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
than -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
( -X- _ O
38.1 -X- _ O
words -X- _ O
vs. -X- _ O
5.6 -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
might -X- _ O
be -X- _ O
much -X- _ O
larger -X- _ O
than -X- _ O
that -X- _ O
between -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
if -X- _ O
F -X- _ O
RV -X- _ B-MethodName
focused -X- _ O
equally -X- _ O
on -X- _ O
every -X- _ O
answer -X- _ O
passage -X- _ O
word -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
actual -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
case -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
draw -X- _ O
decisive -X- _ O
conclusions -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
complex -X- _ O
nature -X- _ O
of -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
that -X- _ O
F -X- _ B-MethodName
RV -X- _ I-MethodName
does -X- _ O
actually -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
compact -X- _ O
answer -X- _ O
than -X- _ O
on -X- _ O
other -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
computed -X- _ O
{ -X- _ O
r -X- _ O
org -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
{ -X- _ O
r -X- _ O
in -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
{ -X- _ O
r -X- _ O
out -X- _ O
i -X- _ O
} -X- _ O
with -X- _ O
fakerepresentation -X- _ O
generator -X- _ O
F -X- _ O
OP -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
and -X- _ O
observed -X- _ O
the -X- _ O
same -X- _ O
tendency -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
methods -X- _ O
in -X- _ O
the -X- _ O
Precision -X- _ B-MetricValue
of -X- _ O
the -X- _ O
top -X- _ O
answer -X- _ O
( -X- _ O
P@1 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Mean -X- _ B-MetricValue
Average -X- _ I-MetricValue
Precision -X- _ I-MetricValue
( -X- _ O
MAP -X- _ B-MetricValue
) -X- _ O
( -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
Oracle -X- _ O
method -X- _ O
indicates -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
fictional -X- _ O
method -X- _ O
that -X- _ O
ranks -X- _ O
the -X- _ O
answer -X- _ O
passages -X- _ O
perfectly -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
it -X- _ O
locates -X- _ O
all -X- _ O
the -X- _ O
m -X- _ O
correct -X- _ O
answers -X- _ O
to -X- _ O
a -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
m -X- _ O
ranks -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
- -X- _ O
standard -X- _ O
labels -X- _ O
. -X- _ O
This -X- _ O
performance -X- _ O
is -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
those -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
implementable -X- _ O
methods -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ O
) -X- _ O
, -X- _ O
outperformed -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
methods -X- _ O
. -X- _ O
Our -X- _ O
starting -X- _ O
point -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
BASE -X- _ B-MethodName
, -X- _ O
was -X- _ O
already -X- _ O
superior -X- _ O
to -X- _ O
the -X- _ O
methods -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
BASE -X- _ B-MethodName
and -X- _ O
BASE+AddTr -X- _ B-MethodName
, -X- _ O
neither -X- _ O
of -X- _ O
which -X- _ O
used -X- _ O
compactanswer -X- _ O
representations -X- _ O
or -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
F -X- _ O
, -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ O
) -X- _ O
gave -X- _ O
3.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ B-MetricValue
2.8 -X- _ I-MetricValue
% -X- _ I-MetricValue
improvement -X- _ O
in -X- _ B-MetricName
P@1 -X- _ I-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
outperformed -X- _ O
BASE+CAns -X- _ B-MethodName
and -X- _ O
BASE+CEnc -X- _ B-MethodName
, -X- _ O
which -X- _ O
generated -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
representations -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
BASE+Enc -X- _ O
, -X- _ O
which -X- _ O
trained -X- _ O
the -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
without -X- _ O
adversarial -X- _ O
learning -X- _ O
. -X- _ O
These -X- _ O
performance -X- _ O
differences -X- _ O
were -X- _ O
statistically -X- _ O
significant -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
by -X- _ O
the -X- _ O
McNemar -X- _ O
's -X- _ O
test -X- _ O
) -X- _ O
. -X- _ O
Ours -X- _ O
( -X- _ O
OP -X- _ O
) -X- _ O
also -X- _ O
outperformed -X- _ O
all -X- _ O
the -X- _ O
BERTbased -X- _ B-MethodName
models -X- _ O
but -X- _ O
an -X- _ O
interesting -X- _ O
point -X- _ O
is -X- _ O
that -X- _ O
fakerepresentation -X- _ O
generator -X- _ O
F -X- _ O
boosted -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
statistically -X- _ O
significant -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
by -X- _ O
the -X- _ O
McNemar -X- _ O
's -X- _ O
test -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
AGR -X- _ B-MethodName
is -X- _ O
effective -X- _ O
in -X- _ O
both -X- _ O
our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
model -X- _ O
and -X- _ O
our -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O

Same -X- _ O
as -X- _ O
BERT+FOP -X- _ B-MethodName
except -X- _ O
that -X- _ O
it -X- _ O
used -X- _ O
FRV -X- _ B-MethodName
instead -X- _ O
of -X- _ O
FOP -X- _ B-MethodName
for -X- _ O
producing -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
representation -X- _ O
. -X- _ O
To -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
Japanese -X- _ O
Wikipedia -X- _ O
articles -X- _ O
( -X- _ O
August -X- _ O
2018 -X- _ O
version -X- _ O
) -X- _ O
and -X- _ O
causality -X- _ O
expressions -X- _ O
automatically -X- _ O
recognized -X- _ O
from -X- _ O
a -X- _ O
causality -X- _ O
recognizer -X- _ O
( -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
data -X- _ O
mix -X- _ O
consists -X- _ O
of -X- _ O
75 -X- _ O
% -X- _ O
of -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
Wikipedia -X- _ O
( -X- _ O
14 -X- _ O
, -X- _ O
675 -X- _ O
, -X- _ O
535 -X- _ O
sentences -X- _ O
taken -X- _ O
out -X- _ O
of -X- _ O
784 -X- _ O
, -X- _ O
869 -X- _ O
articles -X- _ O
randomly -X- _ O
sampled -X- _ O
) -X- _ O
and -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
cause -X- _ O
and -X- _ O
effect -X- _ O
phrases -X- _ O
taken -X- _ O
from -X- _ O
causality -X- _ O
expressions -X- _ O
( -X- _ O
4 -X- _ O
, -X- _ O
891 -X- _ O
, -X- _ O
846 -X- _ O
phrases -X- _ O
from -X- _ O
2 -X- _ O
, -X- _ O
445 -X- _ O
, -X- _ O
923 -X- _ O
causal -X- _ O
relations -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
ratio -X- _ O
was -X- _ O
determined -X- _ O
through -X- _ O
preliminary -X- _ O
experiments -X- _ O
using -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
parameters -X- _ O
, -X- _ O
we -X- _ O
followed -X- _ O
the -X- _ O
settings -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ O
in -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
3 -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
50 -X- _ O
. -X- _ O
We -X- _ O
ran -X- _ O
3 -X- _ O
epochs -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
for -X- _ O
finetuning -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
4 -X- _ O
. -X- _ O
+ -X- _ O
+ -X- _ O
+ -X- _ O
+ -X- _ O
+ -X- _ O
+ -X- _ O
E -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
E -X- _ O
' -X- _ O
E -X- _ O
′ -X- _ O
) -X- _ O
E -X- _ O
Q -X- _ O
E -X- _ O
Q -X- _ O
E -X- _ O
P -X- _ O
E -X- _ O
0 -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
N+M+1 -X- _ O
E -X- _ O
[ -X- _ O
A -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
takes -X- _ O
a -X- _ O
questionpassage -X- _ O
pair -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
computes -X- _ O
the -X- _ O
input -X- _ O
representation -X- _ O
using -X- _ O
token -X- _ O
, -X- _ O
segment -X- _ O
, -X- _ O
position -X- _ O
, -X- _ O
and -X- _ O
attention -X- _ O
feature -X- _ O
embeddings -X- _ O
( -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
input -X- _ O
representation -X- _ O
computation -X- _ O
, -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ O
only -X- _ O
used -X- _ O
the -X- _ O
token -X- _ O
, -X- _ O
segment -X- _ O
, -X- _ O
and -X- _ O
position -X- _ O
embeddings -X- _ O
, -X- _ O
while -X- _ O
BERT -X- _ O
additionally -X- _ O
used -X- _ O
the -X- _ O
attention -X- _ O
feature -X- _ O
embeddings -X- _ O
5 -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
same -X- _ O
similarity -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
causalityattention -X- _ O
features -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
attention -X- _ O
feature -X- _ O
embeddings -X- _ O
during -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
testing -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
during -X- _ O
the -X- _ O
pretraining -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
feature -X- _ O
embeddings -X- _ O
for -X- _ O
answer -X- _ O
passages -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
E -X- _ O
sim -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
E -X- _ O
sim -X- _ O
w -X- _ O
M -X- _ O
, -X- _ O
and -X- _ O
E -X- _ O
caus -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
E -X- _ O
caus -X- _ O
w -X- _ O
M -X- _ O
) -X- _ O
were -X- _ O
computed -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
attention -X- _ O
feature -X- _ O
vectors -X- _ O
, -X- _ O
a -X- _ O
s -X- _ O
and -X- _ O
a -X- _ O
c -X- _ O
, -X- _ O
as -X- _ O
those -X- _ O
in -X- _ O
our -X- _ O
proposed -X- _ O
methods -X- _ O
; -X- _ O
those -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
parts -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
questions -X- _ O
, -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
were -X- _ O
computed -X- _ O
from -X- _ O
a -X- _ O
zero -X- _ O
vector -X- _ O
( -X- _ O
indicating -X- _ O
no -X- _ O
attention -X- _ O
feature -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
transformer -X- _ O
encoder -X- _ O
processed -X- _ O
the -X- _ O
input -X- _ O
representation -X- _ O
to -X- _ O
gen -X- _ O
- -X- _ O
3 -X- _ O
12 -X- _ O
- -X- _ O
layers -X- _ O
, -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
states -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
and -X- _ O
training -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
million -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
warmup -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
using -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
. -X- _ O
4 -X- _ O
We -X- _ O
tested -X- _ O
all -X- _ O
the -X- _ O
combinations -X- _ O
of -X- _ O
epochs -X- _ B-HyperparameterName
{ -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
2 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
3 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
} -X- _ O
and -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
of -X- _ O
{ -X- _ O
1e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
2e -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
3e -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
} -X- _ O
and -X- _ O
chose -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
maximized -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
in -X- _ O
W -X- _ O
hySet -X- _ O
. -X- _ O
5 -X- _ O
We -X- _ O
also -X- _ O
evaluated -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
that -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
the -X- _ O
attention -X- _ O
feature -X- _ O
embeddings -X- _ O
, -X- _ O
but -X- _ O
its -X- _ O
P@1 -X- _ B-MetricName
( -X- _ O
41.4 -X- _ B-MetricValue
) -X- _ O
was -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
51.2 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
P@1 -X- _ B-MetricName
MAP -X- _ I-MetricName
Oh -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
41.8 -X- _ O
41.0 -X- _ O
Sharp -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O

In -X- _ O
our -X- _ O
proposed -X- _ O
methods -X- _ O
and -X- _ O
their -X- _ O
variants -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
weights -X- _ O
in -X- _ O
the -X- _ O
CNNs -X- _ O
were -X- _ O
initialized -X- _ B-HyperparameterName
using -X- _ O
He -X- _ B-HyperparameterValue
's -X- _ I-HyperparameterValue
method -X- _ I-HyperparameterValue
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
weights -X- _ O
in -X- _ O
our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
model -X- _ O
were -X- _ O
initialized -X- _ B-HyperparameterName
randomly -X- _ O
with -X- _ O
a -X- _ O
uniform -X- _ B-HyperparameterValue
distribution -X- _ I-HyperparameterValue
in -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
range -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
( -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
0.01 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
0.01 -X- _ I-HyperparameterValue
) -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
the -X- _ O
CNN -X- _ O
- -X- _ O
based -X- _ O
components -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
window -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
filters -X- _ O
to -X- _ O
" -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
" -X- _ O
with -X- _ O
100 -X- _ O
filters -X- _ O
each -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
dropout -X- _ B-HyperparameterName
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
probability -X- _ O
0.5 -X- _ B-HyperparameterValue
on -X- _ O
the -X- _ O
final -X- _ O
logistic -X- _ O
regression -X- _ O
layer -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
these -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
were -X- _ O
chosen -X- _ O
with -X- _ O
our -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
optimized -X- _ O
the -X- _ O
learned -X- _ O
parameters -X- _ O
with -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
stochastic -X- _ I-HyperparameterValue
gradient -X- _ I-HyperparameterValue
descent -X- _ I-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
0.001 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
for -X- _ O
each -X- _ O
iteration -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O

att -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
CNNs -X- _ O
to -X- _ O
generate -X- _ O
final -X- _ O
representation -X- _ O
r -X- _ O
t -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
passage -X- _ O
/ -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
t. -X- _ O
The -X- _ O
CNNs -X- _ O
resembles -X- _ O
those -X- _ O
in -X- _ O
Kim -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Convolutions -X- _ O
are -X- _ O
performed -X- _ O
over -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
using -X- _ O
both -X- _ O
multiple -X- _ O
filters -X- _ O
and -X- _ O
multiple -X- _ O
filter -X- _ O
windows -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
sliding -X- _ O
over -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
or -X- _ O
3 -X- _ O
word -X- _ O
windows -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
and -X- _ O
100 -X- _ O
filters -X- _ O
for -X- _ O
each -X- _ O
window -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
average -X- _ O
pooling -X- _ O
operation -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
convolution -X- _ O
results -X- _ O
to -X- _ O
generate -X- _ O
representation -X- _ O
r -X- _ O
t -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
/ -X- _ O
value -X- _ O
of -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
; -X- _ O
r -X- _ O
t -X- _ O
= -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
representation -X- _ O
r -X- _ O
t -X- _ O
to -X- _ O
300 -X- _ O
. -X- _ O
4 -X- _ O
Why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
Experiments -X- _ O

The -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
used -X- _ O
in -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
were -X- _ O
obtained -X- _ O
by -X- _ O
concatenating -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
d -X- _ O
- -X- _ O
dimensional -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
300 -X- _ B-HyperparameterValue
in -X- _ O
this -X- _ O
work -X- _ O
) -X- _ O
: -X- _ O
general -X- _ O
word -X- _ O
embeddings -X- _ O
and -X- _ O
causal -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
General -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
widely -X- _ O
used -X- _ O
embedding -X- _ O
vectors -X- _ O
( -X- _ O
300 -X- _ B-HyperparameterValue
dimensions -X- _ B-HyperparameterName
) -X- _ O
that -X- _ O
were -X- _ O
pretrained -X- _ O
for -X- _ O
about -X- _ O
1.65 -X- _ O
million -X- _ O
words -X- _ O
by -X- _ O
applying -X- _ O
word2vec -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
to -X- _ O
about -X- _ O
35 -X- _ O
million -X- _ O
sentences -X- _ O
from -X- _ O
Japanese -X- _ B-TaskName
Wikipedia -X- _ I-TaskName
( -X- _ O
January -X- _ O
2015 -X- _ O
version -X- _ O
) -X- _ O
. -X- _ O
Causal -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Sharp -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
were -X- _ O
proposed -X- _ O
for -X- _ O
representing -X- _ B-MetricValue
the -X- _ I-MetricValue
causal -X- _ I-MetricValue
associations -X- _ I-MetricValue
between -X- _ I-MetricValue
words -X- _ I-MetricValue
. -X- _ O
Sharp -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
cre -X- _ O
- -X- _ O
ated -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
cause -X- _ O
- -X- _ O
effect -X- _ O
word -X- _ O
pairs -X- _ O
by -X- _ O
paring -X- _ O
each -X- _ O
content -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
cause -X- _ O
part -X- _ O
with -X- _ O
each -X- _ O
content -X- _ O
word -X- _ O
in -X- _ O
an -X- _ O
effect -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
causality -X- _ O
expression -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
Volcanoes -X- _ O
erupt -X- _ O
because -X- _ O
magma -X- _ O
pushes -X- _ O
through -X- _ O
vents -X- _ O
and -X- _ O
fissures -X- _ O
. -X- _ O
" -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
extracted -X- _ O
100 -X- _ O
million -X- _ O
causality -X- _ O
expressions -X- _ O
from -X- _ O
4 -X- _ O
- -X- _ O
billion -X- _ O
Japanese -X- _ O
web -X- _ O
pages -X- _ O
using -X- _ O
the -X- _ O
causality -X- _ O
recognizer -X- _ O
of -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
following -X- _ O
Sharp -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
300dimensional -X- _ O
causal -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
about -X- _ O
1.85 -X- _ O
million -X- _ O
words -X- _ O
by -X- _ O
applying -X- _ O
the -X- _ O
generalized -X- _ O
skip -X- _ B-MethodName
- -X- _ I-MethodName
gram -X- _ I-MethodName
embedding -X- _ I-MethodName
model -X- _ I-MethodName
of -X- _ O
Levy -X- _ O
and -X- _ O
Goldberg -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
causality -X- _ O
expressions -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
architecture -X- _ O
shared -X- _ O
by -X- _ O
our -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
F -X- _ O
and -X- _ O
real -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
R -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
θ -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
q -X- _ O
is -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
t -X- _ O
is -X- _ O
either -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
or -X- _ O
a -X- _ O
manually -X- _ O
created -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
. -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
first -X- _ O
represents -X- _ O
question -X- _ O
q -X- _ O
and -X- _ O
passage -X- _ O
/ -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
t -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
supplemented -X- _ O
with -X- _ O
attention -X- _ O
mechanisms -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
attention -X- _ O
- -X- _ O
weighted -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
given -X- _ O
to -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
( -X- _ O
CNNs -X- _ O
) -X- _ O
that -X- _ O
generate -X- _ O
a -X- _ O
single -X- _ O
feature -X- _ O
vector -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
output -X- _ O
/ -X- _ O
value -X- _ O
of -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
mechanisms -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
CNNs -X- _ O
used -X- _ O
in -X- _ O
Encoder -X- _ O
( -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
were -X- _ O
proposed -X- _ O
by -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O
Further -X- _ O
details -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Section -X- _ O
B -X- _ O
of -X- _ O
the -X- _ O
supplementary -X- _ O
materials -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
implementation -X- _ O
, -X- _ O
both -X- _ O
F -X- _ O
and -X- _ O
R -X- _ O
are -X- _ O
networks -X- _ O
with -X- _ O
identical -X- _ O
structure -X- _ O
called -X- _ O
Encoder -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
where -X- _ O
p -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
and -X- _ O
q -X- _ O
are -X- _ O
respectively -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
manually -X- _ O
created -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
: -X- _ O
F -X- _ O
( -X- _ O
p -X- _ O
| -X- _ O
q -X- _ O
) -X- _ O
= -X- _ O
Encoder -X- _ O
( -X- _ O
p -X- _ O
; -X- _ O
θ -X- _ O
F -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
R -X- _ O
( -X- _ O
c -X- _ O
| -X- _ O
q -X- _ O
) -X- _ O
= -X- _ O
Encoder -X- _ O
( -X- _ O
c -X- _ O
; -X- _ O
θ -X- _ O
R -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
Here -X- _ O
θ -X- _ O
F -X- _ O
and -X- _ O
θ -X- _ O
R -X- _ O
represent -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
networks -X- _ O
F -X- _ O
and -X- _ O
R. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
Encoder -X- _ O
are -X- _ O
described -X- _ O
below -X- _ O
. -X- _ O
Discriminator -X- _ O
D -X- _ O
( -X- _ O
r -X- _ O
) -X- _ O
takes -X- _ O
as -X- _ O
input -X- _ O
r -X- _ O
, -X- _ O
either -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
F -X- _ O
( -X- _ O
p -X- _ O
| -X- _ O
q -X- _ O
) -X- _ O
or -X- _ O
that -X- _ O
of -X- _ O
R -X- _ O
( -X- _ O
c -X- _ O
| -X- _ O
q -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computes -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
given -X- _ O
representation -X- _ O
r -X- _ O
comes -X- _ O
from -X- _ O
a -X- _ O
real -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
using -X- _ O
a -X- _ O
feedforward -X- _ O
network -X- _ O
with -X- _ O
two -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
( -X- _ O
100 -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
layer -X- _ O
and -X- _ O
50 -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
layer -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
layer -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
sigmoid -X- _ O
outputs -X- _ O
by -X- _ O
the -X- _ O
logistic -X- _ O
regression -X- _ O
layer -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
probability -X- _ O
. -X- _ O

Why -X- _ O
- -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
) -X- _ O
tasks -X- _ O
retrieve -X- _ O
from -X- _ O
a -X- _ O
text -X- _ O
archive -X- _ O
answers -X- _ O
to -X- _ O
such -X- _ O
why -X- _ O
- -X- _ O
questions -X- _ O
as -X- _ O
" -X- _ O
Why -X- _ O
does -X- _ O
honey -X- _ O
last -X- _ O
such -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
? -X- _ O
" -X- _ O
Previous -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
methods -X- _ O
retrieve -X- _ O
from -X- _ O
a -X- _ O
text -X- _ O
archive -X- _ O
answer -X- _ O
passages -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
several -X- _ O
sentences -X- _ O
, -X- _ O
like -X- _ O
A -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
( -X- _ O
Girju -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Higashinaka -X- _ O
and -X- _ O
Isozaki -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
, -X- _ O
2013Sharp -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Verberne -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
passages -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
A -X- _ O
proper -X- _ O
answer -X- _ O
passage -X- _ O
must -X- _ O
contain -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
paraphrase -X- _ O
of -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
underlined -X- _ O
texts -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
reasons -X- _ O
or -X- _ O
the -X- _ O
causes -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
bold -X- _ O
texts -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
of -X- _ O
Q -X- _ O
Why -X- _ O
does -X- _ O
honey -X- _ O
last -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
? -X- _ O
A -X- _ O
While -X- _ O
excavating -X- _ O
Egypt -X- _ O
's -X- _ O
pyramids -X- _ O
, -X- _ O
archaeologists -X- _ O
have -X- _ O
found -X- _ O
pots -X- _ O
of -X- _ O
honey -X- _ O
in -X- _ O
an -X- _ O
ancient -X- _ O
tomb -X- _ O
: -X- _ O
thousands -X- _ O
of -X- _ O
years -X- _ O
old -X- _ O
and -X- _ O
still -X- _ O
preserved -X- _ O
. -X- _ O
Honey -X- _ O
can -X- _ O
last -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
due -X- _ O
to -X- _ O
three -X- _ O
special -X- _ O
properties -X- _ O
. -X- _ O
Its -X- _ O
average -X- _ O
pH -X- _ O
is -X- _ O
3.9 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
quite -X- _ O
acidic -X- _ O
. -X- _ O
Such -X- _ O
high -X- _ O
level -X- _ O
of -X- _ O
acidity -X- _ O
is -X- _ O
certainly -X- _ O
hostile -X- _ O
and -X- _ O
hinders -X- _ O
the -X- _ O
growth -X- _ O
of -X- _ O
many -X- _ O
microbes -X- _ O
. -X- _ O
Though -X- _ O
honey -X- _ O
contains -X- _ O
around -X- _ O
17 -X- _ O
- -X- _ O
18 -X- _ O
% -X- _ O
water -X- _ O
, -X- _ O
its -X- _ O
water -X- _ O
activity -X- _ O
is -X- _ O
too -X- _ O
low -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
growth -X- _ O
of -X- _ O
microbes -X- _ O
. -X- _ O
Moreover -X- _ O
honey -X- _ O
contains -X- _ O
hydrogen -X- _ O
peroxide -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
thought -X- _ O
to -X- _ O
help -X- _ O
prevent -X- _ O
the -X- _ O
growth -X- _ O
of -X- _ O
microbes -X- _ O
in -X- _ O
honey -X- _ O
. -X- _ O
Despite -X- _ O
these -X- _ O
properties -X- _ O
, -X- _ O
honey -X- _ O
can -X- _ O
be -X- _ O
contaminated -X- _ O
under -X- _ O
certain -X- _ O
circumstances -X- _ O
. -X- _ O
C -X- _ O
Because -X- _ O
its -X- _ O
acidity -X- _ O
, -X- _ O
low -X- _ O
water -X- _ O
activity -X- _ O
, -X- _ O
and -X- _ O
hydrogen -X- _ O
peroxide -X- _ O
together -X- _ O
hinder -X- _ O
the -X- _ O
growth -X- _ O
of -X- _ O
microbes -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Answer -X- _ O
passage -X- _ O
A -X- _ O
to -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
Q -X- _ O
and -X- _ O
its -X- _ O
compact -X- _ O
answer -X- _ O
C -X- _ O
the -X- _ O
events -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
often -X- _ O
written -X- _ O
in -X- _ O
multiple -X- _ O
non -X- _ O
- -X- _ O
adjacent -X- _ O
sentences -X- _ O
. -X- _ O
This -X- _ O
multi -X- _ O
- -X- _ O
sentenceness -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
answer -X- _ O
passages -X- _ O
often -X- _ O
contain -X- _ O
redundant -X- _ O
parts -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
directly -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
or -X- _ O
its -X- _ O
reason -X- _ O
/ -X- _ O
cause -X- _ O
and -X- _ O
whose -X- _ O
presence -X- _ O
complicates -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
task -X- _ O
. -X- _ O
Highly -X- _ O
accurate -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
methods -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
exact -X- _ O
reason -X- _ O
sought -X- _ O
by -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
in -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
without -X- _ O
being -X- _ O
distracted -X- _ O
by -X- _ O
redundancy -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
( -X- _ O
NN -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
, -X- _ O
from -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
vector -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
redundant -X- _ O
reason -X- _ O
asked -X- _ O
by -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
exploit -X- _ O
the -X- _ O
generated -X- _ O
vector -X- _ O
representation -X- _ O
as -X- _ O
evidence -X- _ O
for -X- _ O
judging -X- _ O
whether -X- _ O
the -X- _ O
passage -X- _ O
answers -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
. -X- _ O
This -X- _ O
idea -X- _ O
was -X- _ O
inspired -X- _ O
by -X- _ O
Ishida -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
used -X- _ O
a -X- _ O
seq2seq -X- _ O
model -X- _ O
to -X- _ O
automatically -X- _ O
generate -X- _ O
such -X- _ O
compact -X- _ O
answers -X- _ O
as -X- _ O
C -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
from -X- _ O
the -X- _ O
answer -X- _ O
passages -X- _ O
retrieved -X- _ O
by -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
method -X- _ O
. -X- _ O
Compact -X- _ O
answers -X- _ O
are -X- _ O
sentences -X- _ O
or -X- _ O
phrases -X- _ O
that -X- _ O
express -X- _ O
the -X- _ O
reasons -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
without -X- _ O
redundancy -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
such -X- _ O
automatically -X- _ O
generated -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
to -X- _ O
support -X- _ O
a -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
method -X- _ O
in -X- _ O
finding -X- _ O
the -X- _ O
exact -X- _ O
reason -X- _ O
of -X- _ O
a -X- _ O
whyquestion -X- _ O
in -X- _ O
these -X- _ O
passages -X- _ O
, -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
accuracy -X- _ O
may -X- _ O
be -X- _ O
improved -X- _ O
. -X- _ O
We -X- _ O
actually -X- _ O
tried -X- _ O
this -X- _ O
idea -X- _ O
in -X- _ O
a -X- _ O
preliminary -X- _ O
study -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
generated -X- _ O
a -X- _ O
compact -X- _ O
answer -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
- -X- _ O
passage -X- _ O
pair -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
generation -X- _ O
method -X- _ O
of -X- _ O
Iida -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
used -X- _ O
the -X- _ O
generated -X- _ O
compactanswer -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
- -X- _ O
passage -X- _ O
pair -X- _ O
to -X- _ O
find -X- _ O
proper -X- _ O
answer -X- _ O
passages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
disappointed -X- _ O
by -X- _ O
the -X- _ O
small -X- _ O
performance -X- _ O
improvement -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
generating -X- _ O
a -X- _ O
compact -X- _ O
answer -X- _ O
of -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
as -X- _ O
word -X- _ O
sequences -X- _ O
, -X- _ O
we -X- _ O
devised -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
representation -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
representation -X- _ O
for -X- _ O
a -X- _ O
compact -X- _ O
answer -X- _ O
, -X- _ O
from -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
generative -X- _ B-MethodName
adversarial -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ I-MethodName
GAN -X- _ I-MethodName
) -X- _ I-MethodName
approach -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
developed -X- _ O
an -X- _ O
adversarial -X- _ O
network -X- _ O
called -X- _ O
the -X- _ O
Adversarial -X- _ O
networks -X- _ O
for -X- _ O
Generating -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
Representation -X- _ O
( -X- _ O
AGR -X- _ O
) -X- _ O
. -X- _ O
Like -X- _ O
the -X- _ O
original -X- _ O
GAN -X- _ B-MethodName
, -X- _ O
an -X- _ O
AGR -X- _ B-MethodName
is -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
generator -X- _ O
and -X- _ O
a -X- _ O
discriminator -X- _ O
: -X- _ O
the -X- _ O
generator -X- _ O
network -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
generating -X- _ O
( -X- _ O
from -X- _ O
answer -X- _ O
passages -X- _ O
) -X- _ O
fake -X- _ O
representations -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
hard -X- _ O
for -X- _ O
the -X- _ O
discriminator -X- _ O
network -X- _ O
to -X- _ O
distinguish -X- _ O
these -X- _ O
fake -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
true -X- _ O
representations -X- _ O
derived -X- _ O
from -X- _ O
manually -X- _ O
created -X- _ O
compact -X- _ O
- -X- _ O
answers -X- _ O
. -X- _ O
We -X- _ O
combined -X- _ O
the -X- _ O
generator -X- _ O
network -X- _ O
in -X- _ O
the -X- _ O
AGR -X- _ B-MethodName
with -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
method -X- _ O
. -X- _ O
Our -X- _ O
evaluation -X- _ O
against -X- _ O
a -X- _ O
Japanese -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
dataset -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
created -X- _ O
using -X- _ O
general -X- _ O
web -X- _ O
texts -X- _ O
as -X- _ O
a -X- _ O
source -X- _ O
of -X- _ O
answer -X- _ O
passages -X- _ O
, -X- _ O
revealed -X- _ O
that -X- _ O
the -X- _ O
generator -X- _ O
network -X- _ O
significantly -X- _ O
improved -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ranked -X- _ O
answer -X- _ O
passages -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
combination -X- _ O
significantly -X- _ O
outperformed -X- _ O
several -X- _ O
strong -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
a -X- _ O
generator -X- _ O
network -X- _ O
and -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
combination -X- _ O
also -X- _ O
outperformed -X- _ O
a -X- _ O
vanilla -X- _ O
BERT -X- _ O
model -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
generator -X- _ O
network -X- _ O
in -X- _ O
our -X- _ O
AGR -X- _ B-MethodName
may -X- _ O
be -X- _ O
effective -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
combined -X- _ O
with -X- _ O
many -X- _ O
types -X- _ O
of -X- _ O
NN -X- _ O
architectures -X- _ O
. -X- _ O
Another -X- _ O
interesting -X- _ O
point -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
improved -X- _ O
even -X- _ O
when -X- _ O
we -X- _ O
replaced -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
inputs -X- _ O
to -X- _ O
AGR -X- _ B-MethodName
, -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
vectors -X- _ O
that -X- _ O
represent -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
vector -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
warrants -X- _ O
further -X- _ O
exploration -X- _ O
in -X- _ O
our -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
applied -X- _ O
our -X- _ O
AGR -X- _ O
to -X- _ O
a -X- _ O
distantly -X- _ O
su -X- _ O
- -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
a -X- _ O
machinereading -X- _ O
task -X- _ O
, -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
applicable -X- _ O
to -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
combined -X- _ O
our -X- _ O
generator -X- _ O
network -X- _ O
with -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
DS -X- _ B-TaskName
- -X- _ I-TaskName
QA -X- _ I-TaskName
method -X- _ O
, -X- _ O
OpenQA -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
used -X- _ O
a -X- _ O
generated -X- _ O
compact -X- _ O
- -X- _ O
answer -X- _ O
representation -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
passage -X- _ O
as -X- _ O
evidence -X- _ O
to -X- _ O
1 -X- _ O
) -X- _ O
select -X- _ O
relevant -X- _ O
passages -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
ones -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
find -X- _ O
an -X- _ O
answer -X- _ O
from -X- _ O
the -X- _ O
selected -X- _ O
passages -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
task -X- _ O
was -X- _ O
not -X- _ O
our -X- _ O
initial -X- _ O
target -X- _ O
( -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
DS -X- _ B-TaskName
- -X- _ I-TaskName
QA -X- _ I-TaskName
task -X- _ O
were -X- _ O
considerably -X- _ O
shorter -X- _ O
than -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
, -X- _ O
experiments -X- _ O
using -X- _ O
three -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
( -X- _ O
Quasar -X- _ B-DatasetName
- -X- _ I-DatasetName
T -X- _ I-DatasetName
( -X- _ O
Dhingra -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
SearchQA -X- _ B-DatasetName
( -X- _ O
Dunn -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Triv -X- _ B-DatasetName
- -X- _ I-DatasetName
iaQA -X- _ I-DatasetName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
) -X- _ O
revealed -X- _ O
that -X- _ O
the -X- _ O
generator -X- _ O
network -X- _ O
improved -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
AGR -X- _ B-MethodName
may -X- _ O
be -X- _ O
applicable -X- _ O
to -X- _ O
many -X- _ O
QA -X- _ B-TaskName
- -X- _ O
like -X- _ O
tasks -X- _ O
. -X- _ O
2 -X- _ O
Why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
Model -X- _ O
Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
AGR -X- _ O
. -X- _ O
Our -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ O
model -X- _ O
computes -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
a -X- _ O
given -X- _ O
answer -X- _ O
passage -X- _ O
describes -X- _ O
a -X- _ O
proper -X- _ O
answer -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
why -X- _ O
- -X- _ O
question -X- _ O
using -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
an -X- _ O
answer -X- _ O
passage -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
compact -X- _ O
answer -X- _ O
. -X- _ O
The -X- _ O
probability -X- _ O
( -X- _ O
the -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
model -X- _ O
's -X- _ O
final -X- _ O
output -X- _ O
) -X- _ O
is -X- _ O
computed -X- _ O
from -X- _ O
these -X- _ O
representations -X- _ O
by -X- _ O
our -X- _ O
answer -X- _ O
selection -X- _ O
module -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
layer -X- _ O
with -X- _ O
dropout -X- _ O
and -X- _ O
softmax -X- _ O
output -X- _ O
. -X- _ O
The -X- _ O
representations -X- _ O
of -X- _ O
why -X- _ O
- -X- _ O
questions -X- _ O
and -X- _ O
answer -X- _ O
passages -X- _ O
are -X- _ O
generated -X- _ O
by -X- _ O
Convolutional -X- _ O
Neural -X- _ O
Networks -X- _ O
( -X- _ O
CNNs -X- _ O
) -X- _ O
( -X- _ O
Collobert -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
LeCun -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
that -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
are -X- _ O
augmented -X- _ O
by -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
attention -X- _ O
mechanisms -X- _ O
, -X- _ O
similarityattention -X- _ O
and -X- _ O
causality -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
are -X- _ O
given -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
general -X- _ O
word -X- _ O
embeddings -X- _ O
computed -X- _ O
by -X- _ O
word2vec -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
using -X- _ O
Wikipedia -X- _ O
and -X- _ O
causal -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Sharp -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
computing -X- _ O
a -X- _ O
question -X- _ O
's -X- _ O
representation -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
passage -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
encoder -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
computation -X- _ O
. -X- _ O
Likewise -X- _ O
the -X- _ O
passage -X- _ O
encoder -X- _ O
is -X- _ O
given -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
compact -X- _ O
answer -X- _ O
. -X- _ O
We -X- _ O
represent -X- _ O
these -X- _ O
information -X- _ O
flows -X- _ O
with -X- _ O
dotted -X- _ O
arrows -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
representations -X- _ O
of -X- _ O
compact -X- _ O
answers -X- _ O
are -X- _ O
created -X- _ O
by -X- _ O
a -X- _ O
generator -X- _ O
network -X- _ O
called -X- _ O
a -X- _ O
fakerepresentation -X- _ O
generator -X- _ O
( -X- _ O
F -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
adversarial -X- _ O
learning -X- _ O
manner -X- _ O
( -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
whole -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
model -X- _ O
, -X- _ O
the -X- _ O
generator -X- _ O
's -X- _ O
parameters -X- _ O
are -X- _ O
fixed -X- _ O
and -X- _ O
no -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
conducted -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
main -X- _ O
contribution -X- _ O
: -X- _ O
the -X- _ O
AGR -X- _ O
and -X- _ O
the -X- _ O
fake -X- _ O
- -X- _ O
representation -X- _ O
generator -X- _ O
. -X- _ O
The -X- _ O
entire -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
model -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
why -X- _ O
- -X- _ O
QA -X- _ B-TaskName
method -X- _ O
. -X- _ O
Its -X- _ O
details -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
A -X- _ O
of -X- _ O
the -X- _ O
supplementary -X- _ O
materials -X- _ O
. -X- _ O

We -X- _ O
analyzed -X- _ O
examples -X- _ O
for -X- _ O
which -X- _ O
ASR -X- _ O
is -X- _ O
correct -X- _ O
and -X- _ O
PR -X- _ O
is -X- _ O
not -X- _ O
. -X- _ O
Tab -X- _ O
. -X- _ O
7 -X- _ O
shows -X- _ O
that -X- _ O
, -X- _ O
given -X- _ O
q -X- _ B-HyperparameterName
and -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
3 -X- _ B-HyperparameterValue
candidates -X- _ O
, -X- _ O
PR -X- _ B-MethodName
chooses -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
suitable -X- _ O
but -X- _ O
wrong -X- _ O
answer -X- _ O
. -X- _ O
This -X- _ O
probably -X- _ O
happens -X- _ O
since -X- _ O
the -X- _ O
answer -X- _ O
best -X- _ O
matches -X- _ O
the -X- _ O
syntactic -X- _ O
/ -X- _ O
semantic -X- _ O
pattern -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
which -X- _ O
asks -X- _ O
for -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
color -X- _ O
, -X- _ O
indeed -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
offers -X- _ O
such -X- _ O
type -X- _ O
, -X- _ O
primary -X- _ O
colors -X- _ O
. -X- _ O
PR -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
background -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
support -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
colors -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
ASR -X- _ B-MethodName
selects -X- _ O
c -X- _ O
2 -X- _ O
as -X- _ O
it -X- _ O
can -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
other -X- _ O
answers -X- _ O
. -X- _ O
Its -X- _ O
ASC -X- _ O
provides -X- _ O
an -X- _ O
average -X- _ O
score -X- _ O
for -X- _ O
the -X- _ O
category -X- _ O
0 -X- _ O
( -X- _ O
both -X- _ O
members -X- _ O
are -X- _ O
correct -X- _ O
) -X- _ O
of -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
1 -X- _ O
k -X- _ O
i -X- _ O
= -X- _ O
2 -X- _ O
ASC -X- _ O
( -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
0.653 -X- _ O
, -X- _ O
while -X- _ O
for -X- _ O
c -X- _ O
1 -X- _ O
the -X- _ O
average -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O
significant -X- _ O
lower -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
0.522 -X- _ B-MetricValue
. -X- _ O
This -X- _ O
provides -X- _ O
higher -X- _ O
support -X- _ O
for -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
ASR -X- _ B-MethodName
to -X- _ O
rerank -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
PR -X- _ O
. -X- _ O
Tab -X- _ O
. -X- _ O
8 -X- _ O
shows -X- _ O
an -X- _ O
interesting -X- _ O
case -X- _ O
where -X- _ O
all -X- _ O
the -X- _ O
sentences -X- _ O
contain -X- _ O
the -X- _ O
required -X- _ O
information -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
February -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
PR -X- _ B-MethodName
and -X- _ O
ASR -X- _ B-MethodName
both -X- _ O
choose -X- _ O
answer -X- _ O
c -X- _ O
0 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
correct -X- _ O
but -X- _ O
not -X- _ O
natural -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
provides -X- _ O
the -X- _ O
requested -X- _ O
information -X- _ O
indirectly -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
it -X- _ O
contains -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
ancillary -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
MASR -X- _ B-MetricName
is -X- _ O
able -X- _ O
to -X- _ O
rerank -X- _ O
the -X- _ O
best -X- _ O
answer -X- _ O
, -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
position -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
AS2 -X- _ O
is -X- _ O
obtained -X- _ O
using -X- _ O
RoBERTa -X- _ B-MethodName
Large -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
KGAT -X- _ B-MethodName
and -X- _ O
ASR -X- _ O
using -X- _ O
this -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
also -X- _ O
reports -X- _ O
the -X- _ O
comparison -X- _ O
with -X- _ O
PR -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
official -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
our -X- _ O
PR -X- _ O
replicates -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
obtaining -X- _ O
slightly -X- _ O
lower -X- _ O
performance -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
but -X- _ O
higher -X- _ O
on -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
KGAT -X- _ B-MethodName
performs -X- _ O
lower -X- _ O
than -X- _ O
PR -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
ASR -X- _ O
establishes -X- _ O
the -X- _ O
new -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
with -X- _ O
an -X- _ O
MAP -X- _ B-MetricName
of -X- _ O
92.80 -X- _ O
vs. -X- _ O
92.00 -X- _ O
. -X- _ O
The -X- _ O
P@1 -X- _ O
also -X- _ O
significantly -X- _ O
improves -X- _ O
by -X- _ O
2 -X- _ O
% -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
achieving -X- _ O
89.71 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
impressively -X- _ O
high -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
on -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
ASR -X- _ O
outperforms -X- _ O
all -X- _ O
models -X- _ O
, -X- _ O
being -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
PR -X- _ O
regarding -X- _ B-MetricName
P@1 -X- _ I-MetricName
. -X- _ O
The -X- _ O
latter -X- _ O
is -X- _ O
97.06 -X- _ O
, -X- _ O
which -X- _ O
corresponds -X- _ O
to -X- _ O
mistaking -X- _ O
the -X- _ O
answers -X- _ O
of -X- _ O
only -X- _ O
two -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
manually -X- _ O
checked -X- _ O
these -X- _ O
and -X- _ O
found -X- _ O
out -X- _ O
that -X- _ O
these -X- _ O
were -X- _ O
two -X- _ O
annotation -X- _ O
errors -X- _ O
: -X- _ O
ASR -X- _ O
achieves -X- _ O
perfect -X- _ O
accuracy -X- _ B-MetricName
while -X- _ O
PR -X- _ O
only -X- _ O
mistakes -X- _ O
one -X- _ O
answer -X- _ O
. -X- _ O
Of -X- _ O
course -X- _ O
, -X- _ O
this -X- _ O
just -X- _ O
provides -X- _ O
evidence -X- _ O
that -X- _ O
PR -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Large -X- _ O
solves -X- _ O
the -X- _ O
task -X- _ O
of -X- _ B-TaskName
selecting -X- _ I-TaskName
the -X- _ I-TaskName
best -X- _ I-TaskName
answers -X- _ I-TaskName
( -X- _ O
i.e. -X- _ O
, -X- _ O
measuring -X- _ O
P@1 -X- _ B-MetricName
on -X- _ O
this -X- _ O
dataset -X- _ O
is -X- _ O
not -X- _ O
meaningful -X- _ O
anymore -X- _ O
) -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
4.1 -X- _ O
) -X- _ O
. -X- _ O
ACC -X- _ O
is -X- _ O
the -X- _ O
overall -X- _ B-MetricName
accuracy -X- _ I-MetricName
while -X- _ O
F1 -X- _ B-MetricName
refers -X- _ O
to -X- _ O
the -X- _ O
category -X- _ O
0 -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
ASC -X- _ O
in -X- _ O
MASR -X- _ B-MetricName
- -X- _ I-MetricName
FP -X- _ I-MetricName
achieves -X- _ O
the -X- _ O
highest -X- _ O
accuracy -X- _ B-MetricName
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
This -X- _ O
happens -X- _ O
since -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
FEVER -X- _ B-DatasetName
data -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
reports -X- _ O
the -X- _ O
P@1 -X- _ O
, -X- _ O
MAP -X- _ B-MetricName
and -X- _ O
MRR -X- _ B-MetricName
of -X- _ O
the -X- _ O
rerankers -X- _ O
, -X- _ O
and -X- _ O
different -X- _ O
answer -X- _ O
supporting -X- _ O
models -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
, -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
WQA -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
As -X- _ O
WQA -X- _ B-DatasetName
is -X- _ O
an -X- _ O
internal -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
the -X- _ O
improvement -X- _ O
over -X- _ O
PR -X- _ O
in -X- _ O
the -X- _ O
tables -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
use -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Base -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
checkpoint -X- _ O
and -X- _ O
start -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
k -X- _ O
candidates -X- _ O
reranked -X- _ O
by -X- _ O
PR -X- _ O
( -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
table -X- _ O
shows -X- _ O
that -X- _ O
: -X- _ O
PR -X- _ O
replicates -X- _ O
the -X- _ O
MAP -X- _ B-MetricName
and -X- _ O
MRR -X- _ B-MetricName
of -X- _ O
the -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
reranker -X- _ O
by -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
. -X- _ O
Joint -X- _ O
Model -X- _ O
Multi -X- _ O
- -X- _ O
classifier -X- _ O
performs -X- _ O
lower -X- _ O
than -X- _ O
PR -X- _ O
for -X- _ O
all -X- _ O
measures -X- _ O
and -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
findings -X- _ O
of -X- _ O
Bonadiman -X- _ O
and -X- _ O
Moschitti -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
also -X- _ O
did -X- _ O
not -X- _ O
obtain -X- _ O
improvement -X- _ O
when -X- _ O
jointly -X- _ O
used -X- _ O
all -X- _ O
the -X- _ O
candidates -X- _ O
altogether -X- _ O
in -X- _ O
a -X- _ O
representation -X- _ O
. -X- _ O
Joint -X- _ O
Model -X- _ O
Pairwise -X- _ O
differs -X- _ O
from -X- _ O
ASR -X- _ O
as -X- _ O
it -X- _ O
concatenates -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
, -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
use -X- _ O
any -X- _ O
Answer -X- _ O
Support -X- _ O
Classifier -X- _ O
( -X- _ O
ASC -X- _ O
) -X- _ O
. -X- _ O
Still -X- _ O
, -X- _ O
it -X- _ O
exploits -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
aggregating -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
all -X- _ O
pairs -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
answer -X- _ O
t -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
improves -X- _ O
on -X- _ O
PR -X- _ O
over -X- _ O
all -X- _ O
measures -X- _ O
and -X- _ O
datasets -X- _ O
. -X- _ O
Our -X- _ O
KGAT -X- _ B-MethodName
version -X- _ O
for -X- _ O
AS2 -X- _ O
also -X- _ O
improves -X- _ O
PR -X- _ O
over -X- _ O
all -X- _ O
datasets -X- _ O
and -X- _ O
almost -X- _ O
all -X- _ O
measures -X- _ O
, -X- _ O
confirming -X- _ O
that -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
using -X- _ O
candidates -X- _ O
as -X- _ O
support -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
is -X- _ O
generally -X- _ O
valid -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
superior -X- _ O
to -X- _ O
Joint -X- _ O
Model -X- _ O
Pairwise -X- _ O
. -X- _ O
ASR -X- _ O
achieves -X- _ O
the -X- _ O
highest -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
models -X- _ O
( -X- _ O
but -X- _ O
MASR -X- _ B-MethodName
- -X- _ I-MethodName
FP -X- _ I-MethodName
on -X- _ O
WQA -X- _ B-DatasetName
) -X- _ O
, -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
measures -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
outperforms -X- _ O
PR -X- _ O
by -X- _ O
almost -X- _ O
3 -X- _ O
absolute -X- _ O
percent -X- _ O
points -X- _ O
in -X- _ O
P@1 -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
by -X- _ O
almost -X- _ O
6 -X- _ O
points -X- _ O
on -X- _ O
TREC -X- _ B-DatasetName
from -X- _ O
91.18 -X- _ O
% -X- _ O
to -X- _ O
97.06 -X- _ O
% -X- _ O
, -X- _ O
which -X- _ O
corresponds -X- _ O
to -X- _ O
an -X- _ O
error -X- _ B-MetricName
reduction -X- _ I-MetricName
of -X- _ B-MetricValue
60 -X- _ I-MetricValue
% -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
randomization -X- _ O
test -X- _ O
( -X- _ O
Yeh -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
to -X- _ O
verify -X- _ O
if -X- _ O
the -X- _ O
models -X- _ O
significantly -X- _ O
differ -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
prediction -X- _ O
outcome -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
100 -X- _ O
, -X- _ O
000 -X- _ O
trials -X- _ O
for -X- _ O
each -X- _ O
calculation -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
confirm -X- _ O
the -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
between -X- _ O
ASR -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
for -X- _ O
WikiQA -X- _ O
, -X- _ O
and -X- _ O
between -X- _ O
ASR -X- _ O
and -X- _ O
all -X- _ O
models -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
including -X- _ O
also -X- _ O
KGAT -X- _ B-MethodName
) -X- _ O
on -X- _ O
WQA -X- _ B-DatasetName
. -X- _ O

Metrics -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
QA -X- _ O
systems -X- _ O
is -X- _ O
typically -X- _ O
measured -X- _ O
with -X- _ O
Accuracy -X- _ B-MetricName
in -X- _ O
providing -X- _ O
correct -X- _ O
answers -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
percentage -X- _ B-MetricName
of -X- _ I-MetricName
correct -X- _ I-MetricName
responses -X- _ I-MetricName
. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
referred -X- _ O
to -X- _ O
Precision -X- _ B-MetricName
- -X- _ O
at -X- _ O
- -X- _ O
1 -X- _ O
( -X- _ O
P@1 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
reranking -X- _ O
, -X- _ O
while -X- _ O
standard -X- _ O
Precision -X- _ B-MetricName
and -X- _ O
Recall -X- _ B-MetricName
are -X- _ O
not -X- _ O
essential -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
as -X- _ O
we -X- _ O
assume -X- _ O
the -X- _ O
system -X- _ O
does -X- _ O
not -X- _ O
abstain -X- _ O
from -X- _ O
providing -X- _ O
answers -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
Mean -X- _ B-MetricName
Average -X- _ I-MetricName
Precision -X- _ I-MetricName
( -X- _ I-MetricName
MAP -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
Mean -X- _ B-MetricName
Reciprocal -X- _ I-MetricName
Recall -X- _ I-MetricName
( -X- _ I-MetricName
MRR -X- _ I-MetricName
) -X- _ I-MetricName
evaluated -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
entire -X- _ O
set -X- _ O
of -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
, -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
WQA -X- _ B-DatasetName
, -X- _ O
using -X- _ O
RoBERTa -X- _ B-MethodName
base -X- _ O
Transformer -X- _ O
. -X- _ O
† -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
P@1 -X- _ O
between -X- _ O
ASR -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
marked -X- _ O
systems -X- _ O
is -X- _ O
statistically -X- _ O
significant -X- _ O
at -X- _ O
95 -X- _ O
% -X- _ O
. -X- _ O
JOINT -X- _ O
- -X- _ O
MULTICLASSIFER -X- _ O
JOINT -X- _ O
- -X- _ O
PAIR -X- _ O
KGAT -X- _ O
ASR -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
4 -X- _ O
5 -X- _ O
−3 -X- _ O
−2 -X- _ O
−1 -X- _ O
0 -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
4 -X- _ O
5 -X- _ O
k -X- _ O
Improvement -X- _ O
( -X- _ O
% -X- _ O
) -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Impact -X- _ O
of -X- _ O
k -X- _ O
on -X- _ O
the -X- _ O
WQA -X- _ B-DatasetName
dev -X- _ O
. -X- _ O
set -X- _ O
question -X- _ O
( -X- _ O
this -X- _ O
varies -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
dataset -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
direct -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O
Models -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Base -X- _ O
( -X- _ O
12 -X- _ O
layer -X- _ O
) -X- _ O
and -X- _ O
RoBERTa -X- _ O
- -X- _ O
Large -X- _ O
- -X- _ O
MNLI -X- _ O
( -X- _ O
24 -X- _ O
layer -X- _ O
) -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
released -X- _ O
as -X- _ O
checkpoints -X- _ O
for -X- _ O
use -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
4 -X- _ O
. -X- _ O
Reranker -X- _ O
training -X- _ O
We -X- _ O
adopt -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
transfer -X- _ O
step -X- _ O
on -X- _ O
the -X- _ O
ASNQ -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
adapt -X- _ O
step -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
early -X- _ B-HyperparameterName
stopping -X- _ I-HyperparameterName
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
corpus -X- _ O
for -X- _ O
both -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
steps -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
highest -X- _ O
MAP -X- _ B-MetricName
score -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
equal -X- _ O
to -X- _ O
3 -X- _ B-HyperparameterValue
and -X- _ O
9 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
adapt -X- _ O
and -X- _ O
transfer -X- _ O
steps -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
for -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
128 -X- _ B-HyperparameterValue
tokens -X- _ O
. -X- _ O
KGAT -X- _ B-MethodName
and -X- _ O
ASR -X- _ B-MethodName
training -X- _ O
Again -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
a -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
for -X- _ O
training -X- _ O
the -X- _ O
ASR -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
utilize -X- _ O
1 -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPU -X- _ O
with -X- _ O
32 -X- _ O
GB -X- _ O
memory -X- _ O
and -X- _ O
a -X- _ O
train -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
eight -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
for -X- _ O
RoBERTa -X- _ B-MethodName
Base -X- _ O
/ -X- _ O
Large -X- _ O
to -X- _ O
130 -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ B-HyperparameterName
epochs -X- _ I-HyperparameterName
to -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
other -X- _ O
training -X- _ O
configurations -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
KGAT -X- _ B-MethodName
model -X- _ O
from -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
transformer -X- _ O
models -X- _ O
for -X- _ O
ASR -X- _ O
: -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
4 -X- _ O
https://github.com/pytorch/fairseq -X- _ O
Base -X- _ O
/ -X- _ O
Large -X- _ O
for -X- _ O
PR -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
for -X- _ O
ASC -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ B-HyperparameterName
maximum -X- _ I-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
for -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
128 -X- _ B-HyperparameterValue
tokens -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
to -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
goal -X- _ O
of -X- _ O
MASR -X- _ B-MethodName
is -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
target -X- _ O
answers -X- _ O
, -X- _ O
t -X- _ O
0 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
t -X- _ O
k -X- _ O
. -X- _ O
The -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
target -X- _ O
answer -X- _ O
is -X- _ O
the -X- _ O
embedding -X- _ O
V -X- _ O
R -X- _ O
2d -X- _ O
from -X- _ O
Equation -X- _ O
1 -X- _ O
in -X- _ O
ASR -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
hidden -X- _ O
vectors -X- _ O
of -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
target -X- _ O
answers -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
matrix -X- _ O
V -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
k+1 -X- _ O
) -X- _ O
R -X- _ O
( -X- _ O
k+1 -X- _ O
) -X- _ O
×2d -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
matrix -X- _ O
and -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
weights -X- _ O
W -X- _ O
R -X- _ O
2d -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
a -X- _ O
standard -X- _ O
multi -X- _ B-MetricName
- -X- _ I-MetricName
class -X- _ I-MetricName
classification -X- _ I-MetricName
loss -X- _ I-MetricName
: -X- _ O
L -X- _ O
M -X- _ O
ASR -X- _ O
= -X- _ O
y -X- _ O
* -X- _ O
log -X- _ O
( -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
V -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
k+1 -X- _ O
) -X- _ O
W -X- _ O
T -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
where -X- _ O
y -X- _ O
is -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
- -X- _ O
vector -X- _ O
, -X- _ O
and -X- _ O
| -X- _ O
y -X- _ O
| -X- _ O
= -X- _ O
| -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
| -X- _ O
. -X- _ O

We -X- _ O
developed -X- _ O
ASR -X- _ O
architecture -X- _ O
described -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
the -X- _ O
noise -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
introduced -X- _ O
by -X- _ O
irrelevant -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Answer -X- _ B-MethodName
Support -X- _ I-MethodName
Classifier -X- _ I-MethodName
( -X- _ I-MethodName
ASC -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
which -X- _ O
classifies -X- _ O
each -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
four -X- _ O
classes -X- _ O
: -X- _ O
0 -X- _ O
: -X- _ O
t -X- _ O
and -X- _ O
c -X- _ O
i -X- _ O
are -X- _ O
both -X- _ O
correct -X- _ O
, -X- _ O
1 -X- _ O
: -X- _ O
t -X- _ O
is -X- _ O
correct -X- _ O
while -X- _ O
c -X- _ O
i -X- _ O
is -X- _ O
not -X- _ O
, -X- _ O
2 -X- _ O
: -X- _ O
vice -X- _ O
versa -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
: -X- _ O
both -X- _ O
incorrect -X- _ O
. -X- _ O
This -X- _ O
multi -X- _ O
- -X- _ O
classifier -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
Figure -X- _ O
1b -X- _ O
, -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
top -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
Transformer -X- _ O
, -X- _ O
which -X- _ O
produced -X- _ O
a -X- _ O
PairWise -X- _ O
Representation -X- _ O
( -X- _ O
PWR -X- _ O
) -X- _ O
. -X- _ O
ASC -X- _ O
is -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
fashion -X- _ O
, -X- _ O
using -X- _ O
its -X- _ O
specific -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
, -X- _ O
computed -X- _ O
with -X- _ O
the -X- _ O
labels -X- _ O
above -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
ASR -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1c -X- _ O
) -X- _ O
uses -X- _ O
the -X- _ O
joint -X- _ O
representation -X- _ O
of -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
with -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
k -X- _ O
, -X- _ O
where -X- _ O
t -X- _ O
and -X- _ O
c -X- _ O
i -X- _ O
are -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
candidates -X- _ O
reranked -X- _ O
by -X- _ O
PR -X- _ O
. -X- _ O
The -X- _ O
k -X- _ O
representations -X- _ O
are -X- _ O
summarized -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
operation -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
aggregate -X- _ O
all -X- _ O
the -X- _ O
supporting -X- _ O
or -X- _ O
not -X- _ O
supporting -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
candidates -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
. -X- _ O
The -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
PR -X- _ O
embedding -X- _ O
with -X- _ O
the -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
embedding -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
classification -X- _ O
layer -X- _ O
, -X- _ O
which -X- _ O
scores -X- _ O
t -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
q -X- _ O
, -X- _ O
also -X- _ O
using -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
candidates -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
t -X- _ O
from -X- _ O
the -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
candidates -X- _ O
of -X- _ O
q -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
its -X- _ O
score -X- _ O
. -X- _ O
This -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
rerank -X- _ O
all -X- _ O
the -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
candidates -X- _ O
with -X- _ O
their -X- _ O
scores -X- _ O
. -X- _ O
Implementation -X- _ O
details -X- _ O
: -X- _ O
ASR -X- _ O
is -X- _ O
a -X- _ O
PR -X- _ O
that -X- _ O
also -X- _ O
exploits -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
t -X- _ O
and -X- _ O
A -X- _ O
\ -X- _ O
{ -X- _ O
t -X- _ O
} -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
generate -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
R -X- _ O
d -X- _ O
embedding -X- _ O
of -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O
E -X- _ O
t -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
withÊ -X- _ O
j -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
output -X- _ O
by -X- _ O
another -X- _ O
RoBERTa -X- _ B-MethodName
Transformer -X- _ O
applied -X- _ O
to -X- _ O
answer -X- _ O
pairs -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
j -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
E -X- _ O
t -X- _ O
to -X- _ O
the -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
tensor -X- _ O
fromÊ -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
Ê -X- _ O
k -X- _ O
: -X- _ O
V -X- _ O
= -X- _ O
[ -X- _ O
E -X- _ O
t -X- _ O
: -X- _ O
Maxpool -X- _ O
( -X- _ O
[ -X- _ O
Ê -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
Ê -X- _ O
k -X- _ O
] -X- _ O
) -X- _ O
] -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
V -X- _ O
R -X- _ O
2d -X- _ O
is -X- _ O
the -X- _ O
final -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
t. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
standard -X- _ O
feedforward -X- _ O
network -X- _ O
to -X- _ O
implement -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
layer -X- _ O
: -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
| -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
, -X- _ O
C -X- _ O
k -X- _ O
) -X- _ O
= -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
V -X- _ O
W -X- _ O
T -X- _ O
+ -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
W -X- _ O
R -X- _ O
2×2d -X- _ O
and -X- _ O
B -X- _ O
are -X- _ O
parameters -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
t -X- _ O
from -X- _ O
dimension -X- _ O
2d -X- _ O
to -X- _ O
dimension -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
correct -X- _ O
or -X- _ O
incorrect -X- _ O
labels -X- _ O
. -X- _ O
ASC -X- _ B-MethodName
labels -X- _ O
There -X- _ O
can -X- _ O
be -X- _ O
different -X- _ O
interpretations -X- _ O
when -X- _ O
attempting -X- _ O
to -X- _ O
define -X- _ O
labels -X- _ O
for -X- _ O
answer -X- _ O
pairs -X- _ O
. -X- _ O
An -X- _ O
alternative -X- _ O
to -X- _ O
the -X- _ O
definition -X- _ O
illustrated -X- _ O
above -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
FEVER -X- _ B-MethodName
compatible -X- _ O
encoding -X- _ O
: -X- _ O
0 -X- _ O
: -X- _ O
t -X- _ O
is -X- _ O
correct -X- _ O
, -X- _ O
while -X- _ O
c -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
any -X- _ O
value -X- _ O
, -X- _ O
as -X- _ O
also -X- _ O
an -X- _ O
incorrect -X- _ O
c -X- _ O
i -X- _ O
may -X- _ O
provide -X- _ O
important -X- _ O
context -X- _ O
( -X- _ O
corresponding -X- _ O
to -X- _ O
FEVER -X- _ B-MethodName
Support -X- _ O
label -X- _ O
) -X- _ O
; -X- _ O
1 -X- _ O
: -X- _ O
t -X- _ O
is -X- _ O
incorrect -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
correct -X- _ O
, -X- _ O
since -X- _ O
c -X- _ O
i -X- _ O
can -X- _ O
provide -X- _ O
evidence -X- _ O
that -X- _ O
t -X- _ O
is -X- _ O
not -X- _ O
similar -X- _ O
to -X- _ O
a -X- _ O
correct -X- _ O
answer -X- _ O
( -X- _ O
corresponding -X- _ O
to -X- _ O
FEVER -X- _ B-MethodName
Refutal -X- _ O
label -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
: -X- _ O
both -X- _ O
are -X- _ O
incorrect -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
nothing -X- _ O
can -X- _ O
be -X- _ O
told -X- _ O
( -X- _ O
corresponding -X- _ O
to -X- _ O
FEVER -X- _ B-MethodName
Neutral -X- _ O
label -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
baseline -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
architecture -X- _ O
: -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
question -X- _ O
with -X- _ O
the -X- _ O
top -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
answer -X- _ O
can -X- _ O
- -X- _ O
didates -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
c -X- _ O
1 -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
c -X- _ O
2 -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
c -X- _ O
k+1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
provide -X- _ O
this -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
Transformer -X- _ O
model -X- _ O
used -X- _ O
for -X- _ O
pointwise -X- _ O
reranking -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
E -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
Transformer -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
with -X- _ O
weights -X- _ O
W -X- _ O
R -X- _ O
( -X- _ O
k+1 -X- _ O
) -X- _ O
× -X- _ O
| -X- _ O
E -X- _ O
| -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
classification -X- _ I-MetricName
loss -X- _ I-MetricName
: -X- _ O
y -X- _ O
× -X- _ O
log -X- _ O
( -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
EW -X- _ O
T -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
y -X- _ O
is -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vector -X- _ O
representing -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
candidates -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
| -X- _ O
y -X- _ O
| -X- _ O
= -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
transformer -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
TANDA -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ O
base -X- _ O
or -X- _ O
large -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
ASNQ -X- _ B-TaskName
( -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
candidate -X- _ O
answers -X- _ O
are -X- _ O
calculated -X- _ O
as -X- _ O
p -X- _ O
( -X- _ O
c -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
c -X- _ O
k+1 -X- _ O
) -X- _ O
= -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
EW -X- _ O
T -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
rerank -X- _ O
c -X- _ O
i -X- _ O
according -X- _ O
their -X- _ O
probability -X- _ O
. -X- _ O
Joint -X- _ O
Model -X- _ O
Pairwise -X- _ O
Our -X- _ O
second -X- _ O
baseline -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
. -X- _ O
We -X- _ O
concatenate -X- _ O
the -X- _ O
question -X- _ O
with -X- _ O
each -X- _ O
c -X- _ O
i -X- _ O
to -X- _ O
constitute -X- _ O
the -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
pairs -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
Transformer -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
as -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
pair -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
pair -X- _ O
containing -X- _ O
the -X- _ O
target -X- _ O
candidate -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
candidates -X- _ O
' -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
. -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
is -X- _ O
always -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
position -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
classification -X- _ O
loss -X- _ O
. -X- _ O
At -X- _ O
classification -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
one -X- _ O
target -X- _ O
candidate -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
set -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
position -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
all -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
We -X- _ O
classify -X- _ O
all -X- _ O
k -X- _ O
+ -X- _ O
1 -X- _ O
candidates -X- _ O
and -X- _ O
use -X- _ O
their -X- _ O
score -X- _ O
for -X- _ O
reranking -X- _ O
them -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
to -X- _ O
qualify -X- _ O
for -X- _ O
a -X- _ O
pairwise -X- _ O
approach -X- _ O
, -X- _ O
Joint -X- _ O
Model -X- _ O
Pairwise -X- _ O
should -X- _ O
use -X- _ O
a -X- _ O
ranking -X- _ O
loss -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
use -X- _ O
standard -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
efficient -X- _ O
and -X- _ O
the -X- _ O
different -X- _ O
is -X- _ O
performance -X- _ O
is -X- _ O
negligible -X- _ O
. -X- _ O
Joint -X- _ O
Model -X- _ O
with -X- _ O
KGAT -X- _ B-MethodName
Liu -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
presented -X- _ O
an -X- _ O
interesting -X- _ O
model -X- _ O
, -X- _ O
Kernel -X- _ B-MethodName
Graph -X- _ I-MethodName
Attention -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
KGAT -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
for -X- _ O
fact -X- _ B-TaskName
verification -X- _ I-TaskName
: -X- _ O
given -X- _ O
a -X- _ O
claimed -X- _ O
fact -X- _ O
f -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
evidences -X- _ O
Ev -X- _ O
= -X- _ O
{ -X- _ O
ev -X- _ O
1 -X- _ O
, -X- _ O
ev -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
ev -X- _ O
m -X- _ O
} -X- _ O
, -X- _ O
their -X- _ O
model -X- _ O
carries -X- _ O
out -X- _ O
joint -X- _ O
reasoning -X- _ O
over -X- _ O
Ev -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
aggregating -X- _ O
information -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
f -X- _ O
to -X- _ O
be -X- _ O
true -X- _ O
or -X- _ O
false -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
y -X- _ O
{ -X- _ O
true -X- _ O
, -X- _ O
false -X- _ O
} -X- _ O
. -X- _ O
The -X- _ O
approach -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
graph -X- _ O
, -X- _ O
G -X- _ O
, -X- _ O
whose -X- _ O
nodes -X- _ O
are -X- _ O
the -X- _ O
n -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
f -X- _ O
, -X- _ O
ev -X- _ O
i -X- _ O
) -X- _ O
pairs -X- _ O
, -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
ev -X- _ O
i -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
ev -X- _ O
i -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
ev -X- _ O
i -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
n -X- _ O
i -X- _ O
, -X- _ O
G -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
label -X- _ O
probability -X- _ O
in -X- _ O
each -X- _ O
node -X- _ O
i -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
p -X- _ O
( -X- _ O
ev -X- _ O
i -X- _ O
| -X- _ O
f -X- _ O
, -X- _ O
Ev -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
n -X- _ O
i -X- _ O
| -X- _ O
G -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
selecting -X- _ O
the -X- _ O
most -X- _ O
informative -X- _ O
evidence -X- _ O
. -X- _ O
KGAT -X- _ B-MethodName
uses -X- _ O
an -X- _ O
edge -X- _ O
kernel -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
hierarchi -X- _ O
- -X- _ O
cal -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
propagates -X- _ O
information -X- _ O
between -X- _ O
nodes -X- _ O
and -X- _ O
aggregate -X- _ O
evidences -X- _ O
. -X- _ O
We -X- _ O
built -X- _ O
a -X- _ O
KGAT -X- _ B-MethodName
model -X- _ O
for -X- _ O
AS2 -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
we -X- _ O
replace -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
ev -X- _ O
i -X- _ O
with -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
candidate -X- _ O
answers -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
the -X- _ O
claim -X- _ O
f -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
target -X- _ O
answer -X- _ O
pair -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
. -X- _ O
KGAT -X- _ B-MethodName
constructs -X- _ O
the -X- _ O
evidence -X- _ O
graph -X- _ O
G -X- _ O
by -X- _ O
using -X- _ O
each -X- _ O
claim -X- _ O
- -X- _ O
evidence -X- _ O
pair -X- _ O
as -X- _ O
a -X- _ O
node -X- _ O
, -X- _ O
which -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
is -X- _ O
( -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
connects -X- _ O
all -X- _ O
node -X- _ O
pairs -X- _ O
with -X- _ O
edges -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
evidence -X- _ O
graph -X- _ O
. -X- _ O
This -X- _ O
way -X- _ O
, -X- _ O
sentence -X- _ O
and -X- _ O
token -X- _ O
attention -X- _ O
operate -X- _ O
over -X- _ O
the -X- _ O
triplets -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
establishing -X- _ O
semantic -X- _ O
links -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
help -X- _ O
to -X- _ O
support -X- _ O
or -X- _ O
undermine -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
t. -X- _ O
The -X- _ O
original -X- _ O
KGAT -X- _ B-MethodName
aggregates -X- _ O
all -X- _ O
the -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
we -X- _ O
built -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
relevance -X- _ O
, -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
t. -X- _ O
As -X- _ O
we -X- _ O
use -X- _ O
AS2 -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
will -X- _ O
be -X- _ O
about -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
t. -X- _ O
More -X- _ O
in -X- _ O
detail -X- _ O
, -X- _ O
we -X- _ O
initialize -X- _ O
the -X- _ O
node -X- _ O
representation -X- _ O
using -X- _ O
the -X- _ O
contextual -X- _ O
embeddings -X- _ O
obtained -X- _ O
with -X- _ O
two -X- _ O
TANDA -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ O
base -X- _ O
models -X- _ O
1 -X- _ O
: -X- _ O
the -X- _ O
first -X- _ O
produces -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
second -X- _ O
outputs -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
operation -X- _ O
on -X- _ O
these -X- _ O
two -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
final -X- _ O
node -X- _ O
representation -X- _ O
. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
architecture -X- _ O
is -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
KGAT -X- _ B-MethodName
. -X- _ O
Finally -X- _ O
, -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
one -X- _ O
c -X- _ O
i -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
t -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
its -X- _ O
probability -X- _ O
, -X- _ O
which -X- _ O
ranks -X- _ O
c -X- _ O
i -X- _ O
. -X- _ O

One -X- _ O
simple -X- _ O
and -X- _ O
effective -X- _ O
method -X- _ O
to -X- _ O
build -X- _ O
an -X- _ O
answer -X- _ O
selector -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
model -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
simple -X- _ O
classification -X- _ O
layer -X- _ O
to -X- _ O
it -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
AS2 -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O
Specifically -X- _ O
, -X- _ O
q -X- _ O
= -X- _ O
Tok -X- _ O
q -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
Tok -X- _ O
, -X- _ O
inserted -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
, -X- _ O
as -X- _ O
separator -X- _ O
, -X- _ O
and -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
This -X- _ O
input -X- _ O
is -X- _ O
encoded -X- _ O
as -X- _ O
three -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
tokens -X- _ O
, -X- _ O
segments -X- _ O
and -X- _ O
their -X- _ O
positions -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
several -X- _ O
layers -X- _ O
( -X- _ O
up -X- _ O
to -X- _ O
24 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
them -X- _ O
contains -X- _ O
sublayers -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
, -X- _ O
normalization -X- _ O
and -X- _ O
feed -X- _ O
forward -X- _ O
processing -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
of -X- _ O
this -X- _ O
transformation -X- _ O
is -X- _ O
an -X- _ O
embedding -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
representing -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
models -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
words -X- _ O
and -X- _ O
segments -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
E -X- _ O
is -X- _ O
fed -X- _ O
( -X- _ O
after -X- _ O
applying -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linearity -X- _ O
function -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
layer -X- _ O
having -X- _ O
weights -X- _ O
: -X- _ O
W -X- _ O
and -X- _ O
B. -X- _ O
The -X- _ O
output -X- _ O
layer -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
implement -X- _ O
the -X- _ O
task -X- _ O
function -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
softmax -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
/ -X- _ O
candidate -X- _ O
pair -X- _ O
classification -X- _ O
, -X- _ O
as -X- _ O
: -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
= -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
W -X- _ O
× -X- _ O
tanh -X- _ O
( -X- _ O
E -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
with -X- _ B-MetricName
log -X- _ I-MetricName
cross -X- _ I-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
: -X- _ I-MetricName
L -X- _ I-MetricName
= -X- _ I-MetricName
− -X- _ I-MetricName
l -X- _ I-MetricName
{ -X- _ I-MetricName
0 -X- _ I-MetricName
, -X- _ I-MetricName
1 -X- _ I-MetricName
} -X- _ I-MetricName
y -X- _ I-MetricName
l -X- _ I-MetricName
× -X- _ I-MetricName
log -X- _ I-MetricName
( -X- _ I-MetricName
ŷ -X- _ I-MetricName
l -X- _ I-MetricName
) -X- _ I-MetricName
on -X- _ O
pairs -X- _ O
of -X- _ O
texts -X- _ O
, -X- _ O
where -X- _ O
y -X- _ O
l -X- _ O
is -X- _ O
the -X- _ O
correct -X- _ O
and -X- _ O
incorrect -X- _ O
answer -X- _ O
label -X- _ O
, -X- _ O
ŷ -X- _ O
1 -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
andŷ -X- _ O
0 -X- _ O
= -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
Training -X- _ O
the -X- _ O
Transformer -X- _ O
from -X- _ O
scratch -X- _ O
requires -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
tasks -X- _ I-TaskName
, -X- _ O
for -X- _ O
which -X- _ O
labels -X- _ O
can -X- _ O
be -X- _ O
automatically -X- _ O
generated -X- _ O
. -X- _ O
Several -X- _ O
methods -X- _ O
for -X- _ O
pretraining -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
AlBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
of -X- _ O
reranking -X- _ B-TaskName
answer -X- _ I-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
candidates -X- _ I-TaskName
provided -X- _ O
by -X- _ O
a -X- _ O
retrieval -X- _ O
engine -X- _ O
can -X- _ O
be -X- _ O
modeled -X- _ O
with -X- _ O
a -X- _ O
classifier -X- _ O
scoring -X- _ O
the -X- _ O
candidates -X- _ O
. -X- _ O
Let -X- _ O
q -X- _ O
be -X- _ O
an -X- _ O
element -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
set -X- _ O
, -X- _ O
Q -X- _ O
, -X- _ O
and -X- _ O
A -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
c -X- _ O
n -X- _ O
} -X- _ O
be -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
candidates -X- _ O
for -X- _ O
q -X- _ O
, -X- _ O
a -X- _ O
reranker -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
R -X- _ O
: -X- _ O
Q -X- _ O
× -X- _ O
Π -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
Π -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
Π -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
permutations -X- _ O
of -X- _ O
A. -X- _ O
Previous -X- _ O
work -X- _ O
targeting -X- _ O
ranking -X- _ O
problems -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
domain -X- _ O
has -X- _ O
classified -X- _ O
reranking -X- _ O
functions -X- _ O
into -X- _ O
three -X- _ O
buckets -X- _ O
: -X- _ O
pointwise -X- _ O
, -X- _ O
pairwise -X- _ O
, -X- _ O
and -X- _ O
listwise -X- _ O
methods -X- _ O
. -X- _ O
Pointwise -X- _ B-TaskName
reranking -X- _ I-TaskName
: -X- _ O
This -X- _ O
approach -X- _ O
learns -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
c -X- _ O
i -X- _ O
correctly -X- _ O
answering -X- _ O
q -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
binary -X- _ O
classification -X- _ O
setting -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
rank -X- _ O
is -X- _ O
simply -X- _ O
obtained -X- _ O
sorting -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
estimates -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
with -X- _ O
neural -X- _ O
models -X- _ O
( -X- _ O
Severyn -X- _ O
and -X- _ O
Moschitti -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
also -X- _ O
using -X- _ O
attention -X- _ O
mechanisms -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Compare -X- _ O
- -X- _ O
Aggregate -X- _ O
( -X- _ O
Yoon -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
inter -X- _ O
- -X- _ O
weighted -X- _ O
alignment -X- _ O
networks -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
TANDA -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
current -X- _ O
most -X- _ O
accurate -X- _ O
model -X- _ O
on -X- _ O
WikiQA -X- _ B-DatasetName
and -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
Pairwise -X- _ O
reranking -X- _ O
: -X- _ O
The -X- _ O
method -X- _ O
considers -X- _ O
binary -X- _ O
classifiers -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
χ -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
j -X- _ O
) -X- _ O
for -X- _ O
determining -X- _ O
the -X- _ O
partial -X- _ O
rank -X- _ O
between -X- _ O
c -X- _ O
i -X- _ O
and -X- _ O
c -X- _ O
j -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
scoring -X- _ O
function -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
summing -X- _ O
up -X- _ O
all -X- _ O
the -X- _ O
contributions -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
candidate -X- _ O
t -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
j -X- _ O
χ -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
j -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
large -X- _ O
body -X- _ O
of -X- _ O
work -X- _ O
preceding -X- _ O
Transformer -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
Laskar -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Tayyar -X- _ O
Madabushi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
are -X- _ O
largely -X- _ O
outperformed -X- _ O
by -X- _ O
the -X- _ O
pointwise -X- _ O
TANDA -X- _ B-MethodName
model -X- _ O
. -X- _ O
Listwise -X- _ O
reranking -X- _ O
: -X- _ O
This -X- _ O
approach -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
Bian -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Ai -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
aims -X- _ O
at -X- _ O
learning -X- _ O
p -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
π -X- _ O
) -X- _ O
, -X- _ O
π -X- _ O
Π -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
information -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
set -X- _ O
of -X- _ O
candidates -X- _ O
. -X- _ O
The -X- _ O
loss -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
for -X- _ O
training -X- _ O
such -X- _ O
networks -X- _ O
is -X- _ O
constituted -X- _ O
by -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
all -X- _ O
elements -X- _ O
of -X- _ O
its -X- _ O
ranked -X- _ O
items -X- _ O
. -X- _ O
The -X- _ O
closest -X- _ O
work -X- _ O
to -X- _ O
our -X- _ O
research -X- _ O
is -X- _ O
by -X- _ O
Bonadiman -X- _ O
and -X- _ O
Moschitti -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
designed -X- _ O
several -X- _ O
joint -X- _ O
models -X- _ O
. -X- _ O
These -X- _ O
improved -X- _ O
early -X- _ O
neural -X- _ O
networks -X- _ O
based -X- _ O
on -X- _ O
CNN -X- _ O
and -X- _ O
LSTM -X- _ O
for -X- _ O
AS2 -X- _ O
, -X- _ O
but -X- _ O
failed -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
models -X- _ O
. -X- _ O

A -X- _ O
more -X- _ O
structured -X- _ O
approach -X- _ O
to -X- _ O
building -X- _ B-TaskName
joint -X- _ I-TaskName
models -X- _ I-TaskName
over -X- _ O
sentences -X- _ O
can -X- _ O
instead -X- _ O
be -X- _ O
observed -X- _ O
in -X- _ O
Fact -X- _ O
Verification -X- _ O
Systems -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
methods -X- _ O
developed -X- _ O
in -X- _ O
the -X- _ O
FEVER -X- _ B-DatasetName
challenge -X- _ O
( -X- _ O
Thorne -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
systems -X- _ O
take -X- _ O
a -X- _ O
claim -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Joe -X- _ O
Walsh -X- _ O
was -X- _ O
inducted -X- _ O
in -X- _ O
2001 -X- _ O
, -X- _ O
as -X- _ O
input -X- _ O
( -X- _ O
see -X- _ O
Tab -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
verify -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
valid -X- _ O
, -X- _ O
using -X- _ O
related -X- _ O
sentences -X- _ O
called -X- _ O
evidences -X- _ O
( -X- _ O
typically -X- _ O
retrieved -X- _ O
by -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Ev -X- _ O
1 -X- _ O
, -X- _ O
As -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
Eagles -X- _ O
, -X- _ O
Walsh -X- _ O
was -X- _ O
inducted -X- _ O
into -X- _ O
the -X- _ O
Rock -X- _ O
and -X- _ O
Roll -X- _ O
Hall -X- _ O
of -X- _ O
Fame -X- _ O
in -X- _ O
1998 -X- _ O
, -X- _ O
and -X- _ O
into -X- _ O
the -X- _ O
Vocal -X- _ O
Group -X- _ O
Hall -X- _ O
of -X- _ O
Fame -X- _ O
in -X- _ O
2001 -X- _ O
, -X- _ O
and -X- _ O
Ev -X- _ O
3 -X- _ O
, -X- _ O
Walsh -X- _ O
was -X- _ O
awarded -X- _ O
with -X- _ O
the -X- _ O
Vocal -X- _ O
Group -X- _ O
Hall -X- _ O
of -X- _ O
Fame -X- _ O
in -X- _ O
2001 -X- _ O
, -X- _ O
support -X- _ O
the -X- _ O
veracity -X- _ O
of -X- _ O
the -X- _ O
claim -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
Ev -X- _ O
2 -X- _ O
is -X- _ O
neutral -X- _ O
as -X- _ O
it -X- _ O
describes -X- _ O
who -X- _ O
Joe -X- _ O
Walsh -X- _ O
is -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
contribute -X- _ O
to -X- _ O
establish -X- _ O
the -X- _ O
induction -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
supporting -X- _ O
evidence -X- _ O
for -X- _ O
answer -X- _ O
correctness -X- _ O
in -X- _ O
AS2 -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
modeled -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
rationale -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
joint -X- _ O
models -X- _ O
for -X- _ O
AS2 -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
, -X- _ O
given -X- _ O
q -X- _ O
and -X- _ O
a -X- _ O
target -X- _ O
answer -X- _ O
candidate -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
answer -X- _ O
candidates -X- _ O
, -X- _ O
( -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
.. -X- _ O
c -X- _ O
k -X- _ O
) -X- _ O
can -X- _ O
provide -X- _ O
positive -X- _ O
, -X- _ O
negative -X- _ O
, -X- _ O
or -X- _ O
neutral -X- _ O
support -X- _ O
to -X- _ O
decide -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
t. -X- _ O
Our -X- _ O
first -X- _ O
approach -X- _ O
exploits -X- _ O
Fact -X- _ B-TaskName
Checking -X- _ I-TaskName
research -X- _ I-TaskName
: -X- _ O
we -X- _ O
adapted -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
FEVER -X- _ B-DatasetName
system -X- _ O
, -X- _ O
KGAT -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
AS2 -X- _ O
. -X- _ O
We -X- _ O
defined -X- _ O
a -X- _ O
claim -X- _ O
as -X- _ O
a -X- _ O
pair -X- _ O
constituted -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
one -X- _ O
target -X- _ O
answer -X- _ O
, -X- _ O
while -X- _ O
considering -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
answers -X- _ O
as -X- _ O
evidences -X- _ O
. -X- _ O
We -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
and -X- _ O
rebuilt -X- _ O
all -X- _ O
its -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
AS2 -X- _ O
task -X- _ O
. -X- _ O
Our -X- _ O
second -X- _ O
method -X- _ O
, -X- _ O
Answer -X- _ B-MethodName
Support -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
Reranker -X- _ I-MethodName
( -X- _ I-MethodName
ASR -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
is -X- _ O
completely -X- _ O
new -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
pair -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
generated -X- _ O
by -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
AS2 -X- _ O
models -X- _ O
, -X- _ O
concatenated -X- _ O
with -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
pairs -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
latter -X- _ O
summarizes -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
each -X- _ O
c -X- _ O
i -X- _ O
to -X- _ O
t -X- _ O
using -X- _ O
a -X- _ O
maxpooling -X- _ O
operation -X- _ O
. -X- _ O
c -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
unrelated -X- _ O
to -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
since -X- _ O
the -X- _ O
candidates -X- _ O
are -X- _ O
automatically -X- _ O
retrieved -X- _ O
, -X- _ O
thus -X- _ O
it -X- _ O
may -X- _ O
introduce -X- _ O
just -X- _ O
noise -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ B-MethodName
Answer -X- _ I-MethodName
Support -X- _ I-MethodName
Classifier -X- _ I-MethodName
( -X- _ I-MethodName
ASC -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
learn -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
t -X- _ O
and -X- _ O
c -X- _ O
i -X- _ O
by -X- _ O
classifying -X- _ O
their -X- _ O
embedding -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
obtain -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
transformer -X- _ O
network -X- _ O
to -X- _ O
their -X- _ O
concatenated -X- _ O
text -X- _ O
. -X- _ O
ASC -X- _ B-MethodName
tunes -X- _ O
the -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
embedding -X- _ O
parameters -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
evidence -X- _ O
that -X- _ O
c -X- _ O
i -X- _ O
provides -X- _ O
to -X- _ O
t. -X- _ O
Our -X- _ O
Answer -X- _ O
Support -X- _ O
- -X- _ O
based -X- _ O
Reranker -X- _ O
( -X- _ O
ASR -X- _ O
) -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
also -X- _ O
simpler -X- _ O
than -X- _ O
our -X- _ O
approach -X- _ O
based -X- _ O
on -X- _ O
KGAT -X- _ B-MethodName
. -X- _ O
Our -X- _ O
third -X- _ O
method -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
ASR -X- _ B-MethodName
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
, -X- _ O
although -X- _ O
ASR -X- _ B-MethodName
exploits -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
k -X- _ O
candidates -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
produces -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
target -X- _ O
t -X- _ O
without -X- _ O
knowing -X- _ O
the -X- _ O
scores -X- _ O
produced -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
target -X- _ O
answers -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
jointly -X- _ O
model -X- _ O
the -X- _ O
representation -X- _ O
obtained -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
ASR -X- _ O
( -X- _ O
MASR -X- _ O
) -X- _ O
architecture -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
then -X- _ O
carry -X- _ O
out -X- _ O
a -X- _ O
complete -X- _ O
global -X- _ O
reasoning -X- _ O
over -X- _ O
all -X- _ O
target -X- _ O
answers -X- _ O
. -X- _ O
We -X- _ O
experimented -X- _ O
with -X- _ O
our -X- _ O
models -X- _ O
over -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
WikiQA -X- _ B-DatasetName
, -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
WQA -X- _ B-DatasetName
, -X- _ O
where -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
an -X- _ O
internal -X- _ O
dataset -X- _ O
built -X- _ O
on -X- _ O
anonymized -X- _ O
customer -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
: -X- _ O
ASR -X- _ B-MethodName
improves -X- _ O
the -X- _ O
best -X- _ O
current -X- _ O
model -X- _ O
for -X- _ O
AS2 -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
TANDA -X- _ O
by -X- _ O
∼3 -X- _ O
% -X- _ O
, -X- _ O
corresponding -X- _ O
to -X- _ O
an -X- _ O
error -X- _ B-MetricName
reduction -X- _ I-MetricName
of -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
Accuracy -X- _ B-MetricName
, -X- _ O
on -X- _ O
both -X- _ O
Wik -X- _ B-DatasetName
- -X- _ I-DatasetName
iQA -X- _ I-DatasetName
and -X- _ O
TREC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
We -X- _ O
also -X- _ O
obtain -X- _ O
a -X- _ O
relative -X- _ O
improvement -X- _ O
of -X- _ O
∼3 -X- _ O
% -X- _ O
over -X- _ O
TANDA -X- _ B-MethodName
on -X- _ O
WQA -X- _ B-DatasetName
, -X- _ O
confirming -X- _ O
that -X- _ O
ASR -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
solution -X- _ O
to -X- _ O
design -X- _ B-TaskName
accurate -X- _ I-TaskName
QA -X- _ I-TaskName
systems -X- _ I-TaskName
. -X- _ O
Most -X- _ O
interestingly -X- _ O
, -X- _ O
MASR -X- _ B-MethodName
improves -X- _ O
ASR -X- _ B-MethodName
by -X- _ O
additional -X- _ O
2 -X- _ O
% -X- _ O
, -X- _ O
confirming -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
joint -X- _ O
modeling -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
mention -X- _ O
that -X- _ O
MASR -X- _ O
improvement -X- _ O
is -X- _ O
also -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
FEVER -X- _ B-DatasetName
data -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
ASC -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
fact -X- _ B-TaskName
verification -X- _ I-TaskName
inference -X- _ I-TaskName
and -X- _ O
the -X- _ O
answer -X- _ B-TaskName
support -X- _ I-TaskName
inference -X- _ I-TaskName
are -X- _ O
similar -X- _ O
. -X- _ O

Recall -X- _ O
that -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
GBMT -X- _ B-MethodName
, -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
contains -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
rules -X- _ O
: -X- _ O
basic -X- _ O
rules -X- _ O
, -X- _ O
segmenting -X- _ O
rules -X- _ O
, -X- _ O
and -X- _ O
selecting -X- _ O
rules -X- _ O
. -X- _ O
While -X- _ O
basic -X- _ O
rules -X- _ O
exist -X- _ O
in -X- _ O
both -X- _ O
systems -X- _ O
, -X- _ O
segmenting -X- _ O
and -X- _ O
selecting -X- _ O
rules -X- _ O
make -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
context -X- _ O
- -X- _ O
aware -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
rules -X- _ O
in -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
types -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
on -X- _ O
both -X- _ O
language -X- _ O
pairs -X- _ O
35 -X- _ O
% -X- _ O
- -X- _ O
36 -X- _ O
% -X- _ O
of -X- _ O
rules -X- _ O
are -X- _ O
basic -X- _ O
rules -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
segmenting -X- _ O
rules -X- _ O
is -X- _ O
∼53 -X- _ O
% -X- _ O
, -X- _ O
selecting -X- _ O
rules -X- _ O
only -X- _ O
account -X- _ O
for -X- _ O
11 -X- _ O
% -X- _ O
- -X- _ O
12 -X- _ O
% -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
segmenting -X- _ O
rules -X- _ O
contain -X- _ O
richer -X- _ O
contextual -X- _ O
information -X- _ O
than -X- _ O
selecting -X- _ O
rules -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
of -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
when -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
rules -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
when -X- _ O
only -X- _ O
basic -X- _ O
rules -X- _ O
are -X- _ O
allowed -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
degrades -X- _ O
to -X- _ O
the -X- _ O
conventional -X- _ O
GBMT -X- _ B-MethodName
system -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
suggest -X- _ O
that -X- _ O
both -X- _ O
segmenting -X- _ O
and -X- _ O
selecting -X- _ O
rules -X- _ O
consistently -X- _ O
improve -X- _ O
GBMT -X- _ O
on -X- _ O
both -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
segmenting -X- _ O
rules -X- _ O
are -X- _ O
more -X- _ O
useful -X- _ O
than -X- _ O
selecting -X- _ O
rules -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
reasonable -X- _ O
since -X- _ O
( -X- _ O
hong -X- _ O
kong -X- _ O
macao -X- _ O
taiwan -X- _ O
) -X- _ O
hong -X- _ O
kong -X- _ O
spring -X- _ O
festival -X- _ O
retail -X- _ O
business -X- _ O
rise -X- _ O
10 -X- _ O
% -X- _ O
( -X- _ O
Gang -X- _ O
Ao -X- _ O
Tai -X- _ O
) -X- _ O
XiangGang -X- _ O
XinChun -X- _ O
LingShou -X- _ O
ShengYi -X- _ O
ShangSheng -X- _ O
YiCheng -X- _ O
Ref -X- _ O
: -X- _ O
GBMT -X- _ B-MethodName
: -X- _ O
GBMTctx -X- _ B-MethodName
: -X- _ O
( -X- _ O
hong -X- _ O
kong -X- _ O
, -X- _ O
macao -X- _ O
and -X- _ O
taiwan -X- _ O
) -X- _ O
hong -X- _ O
kong -X- _ O
's -X- _ O
retail -X- _ O
sales -X- _ O
up -X- _ O
10 -X- _ O
% -X- _ O
during -X- _ O
spring -X- _ O
festival -X- _ O
( -X- _ O
the -X- _ O
spring -X- _ O
festival -X- _ O
) -X- _ O
hong -X- _ O
kong -X- _ O
retail -X- _ O
business -X- _ O
in -X- _ O
hong -X- _ O
kong -X- _ O
, -X- _ O
macao -X- _ O
and -X- _ O
taiwan -X- _ O
rose -X- _ O
by -X- _ O
10 -X- _ O
% -X- _ O
( -X- _ O
hong -X- _ O
kong -X- _ O
, -X- _ O
macao -X- _ O
and -X- _ O
taiwan -X- _ O
) -X- _ O
hong -X- _ O
kong -X- _ O
spring -X- _ O
retail -X- _ O
business -X- _ O
will -X- _ O
increase -X- _ O
by -X- _ O
10 -X- _ O
% -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
subgraph -X- _ O
selection -X- _ O
we -X- _ O
also -X- _ O
dedicate -X- _ O
protect -X- _ O
and -X- _ O
improve -X- _ O
living -X- _ O
emvironment -X- _ O
. -X- _ O

The -X- _ O
1 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
of -X- _ O
all -X- _ O
systems -X- _ O
. -X- _ O
Bold -X- _ O
figures -X- _ O
mean -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
GBMT -X- _ B-MethodName
at -X- _ O
p -X- _ O
≤ -X- _ O
0.01 -X- _ O
. -X- _ O
* -X- _ O
means -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
PBMT -X- _ B-MethodName
at -X- _ O
p -X- _ O
≤ -X- _ O
0.01 -X- _ O
. -X- _ O
+ -X- _ O
means -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
TBMT -X- _ B-MethodName
at -X- _ O
p -X- _ O
≤ -X- _ O
0.01 -X- _ O
. -X- _ O
Following -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Chinese -X- _ O
and -X- _ O
German -X- _ O
sentences -X- _ O
are -X- _ O
parsed -X- _ O
into -X- _ O
projective -X- _ O
dependency -X- _ O
trees -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
converted -X- _ O
to -X- _ O
graphs -X- _ O
by -X- _ O
adding -X- _ O
bigram -X- _ O
edges -X- _ O
. -X- _ O
Word -X- _ O
alignment -X- _ O
is -X- _ O
performed -X- _ O
by -X- _ O
GIZA++ -X- _ O
( -X- _ O
Och -X- _ O
and -X- _ O
Ney -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
heuristic -X- _ O
function -X- _ O
grow -X- _ O
- -X- _ O
diag -X- _ O
- -X- _ O
final -X- _ O
- -X- _ O
and -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
SRILM -X- _ B-MethodName
( -X- _ O
Stolcke -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
gram -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Xinhua -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
English -X- _ O
Gigaword -X- _ O
corpus -X- _ O
5th -X- _ O
edition -X- _ O
with -X- _ O
modified -X- _ O
Kneser -X- _ O
- -X- _ O
Ney -X- _ O
discounting -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Goodman -X- _ O
, -X- _ O
1996 -X- _ O
) -X- _ O
. -X- _ O
Batch -X- _ O
MIRA -X- _ B-MethodName
( -X- _ O
Cherry -X- _ O
and -X- _ O
Foster -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
tune -X- _ O
feature -X- _ O
weights -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
scores -X- _ O
averaged -X- _ O
on -X- _ O
three -X- _ O
runs -X- _ O
of -X- _ O
MIRA -X- _ B-DatasetName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
system -X- _ O
GBMT -X- _ B-MethodName
ctx -X- _ O
with -X- _ O
several -X- _ O
other -X- _ O
systems -X- _ O
. -X- _ O
A -X- _ O
system -X- _ O
PBMT -X- _ B-MethodName
is -X- _ O
built -X- _ O
using -X- _ O
the -X- _ O
phrase -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
in -X- _ O
Moses -X- _ O
( -X- _ O
Koehn -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
GBMT -X- _ O
is -X- _ O
the -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
translation -X- _ O
system -X- _ O
described -X- _ O
in -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
examine -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
bigram -X- _ O
links -X- _ O
, -X- _ O
GBMT -X- _ O
is -X- _ O
also -X- _ O
used -X- _ O
to -X- _ O
translate -X- _ B-TaskName
dependency -X- _ I-TaskName
trees -X- _ I-TaskName
where -X- _ O
treelets -X- _ O
Xiong -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
basic -X- _ O
translation -X- _ O
units -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
we -X- _ O
name -X- _ O
the -X- _ O
system -X- _ O
TBMT -X- _ B-MethodName
. -X- _ O
All -X- _ O
systems -X- _ O
are -X- _ O
implemented -X- _ O
in -X- _ O
Moses -X- _ O
. -X- _ O

