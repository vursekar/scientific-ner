-DOCSTART-	O
BERT	B-MethodName
1415	B-MetricValue
-	I-MetricValue
29	I-MetricValue
30	I-MetricValue
-	I-MetricValue
44	I-MetricValue
45	I-MetricValue
-	I-MetricValue
59	I-MetricValue
6060708090100	O
BiLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT	I-MethodName
DGLSTM	I-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
ELMO	I-MethodName
Syn	I-MethodName
-	I-MethodName
LSTM	I-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT	I-MethodName
Figure	O
5	O
:	O
Left	O
:	O
Catalan	O
,	O
Right	O
:	O
Spanish	O
.	O
In	O
Proceedings	O
of	O
the	O
15th	O
International	O
Workshop	O
on	O
Semantic	O
Evaluation	O
(	O
SemEval-2021	O
)	O
,	O
pages	O
317326	O
,	O
Online	O
.	O
In	O
Proceedings	O
of	O
the	O
2019	O
Conference	O
of	O
the	O
North	O
American	O
Chapter	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
:	O
Human	O
Language	O
Technologies	O
,	O
Volume	O
1	O
(	O
Long	O
and	O
Short	O
Papers	O
)	O
,	O
pages	O
32073215	O
,	O
Minneapolis	O
,	O
Minnesota	O
.	O
Nancy	O
X.	O
R.	O
Wang	O
,	O
Diwakar	O
Mahajan	O
,	O
Marina	O
Danilevsky	O
,	O
and	O
Sara	O
Rosenthal	O
.	O
We	O
use	O
the	O
ofcial	O
test	O
set	O
for	O
evaluation	O
.	O
Jia	O
et	O
al	O
.	O
,	O
2019	O
;	O
Huang	O
et	O
al	O
.	O
,	O
2019	O
;	O
Zhou	O
et	O
1	O
Introduction	O
For	O
our	O
work	O
in	O
our	O
lab	O
(	O
Orange	O
-	O
Deski	O
n	O
)	O
we	O
needed	O
a	O
robust	O
dependency	O
analysis	O
for	O
written	O
French	O
with	O
the	O
highest	O
Labeled	B-MetricName
Attachment	I-MetricName
Score	I-MetricName
(	I-MetricName
LAS)1possible	I-MetricName
,	O
using	O
a	O
wide	O
range	O
of	O
dependency	O
relations	O
.	O
(	O
2018	O
)	O
or	O
Lichtarge	O
et	O
Scott	O
M.	O
Lundberg	O
,	O
Gabriel	O
G.	O
Erion	O
,	O
and	O
Su	O
-	O
In	O
Lee	O
.	O
2018	O
.	O
Kis	B-HyperparameterName
a	O
hyperparameter	O
to	O
tune	O
.	O
A	O
left	O
table	O
shows	O
the	O
context	O
and	O
its	O
fact	O
,	O
and	O
a	O
right	O
gure	O
shows	O
a	O
visualization	O
of	O
token	O
representations	O
.	O
From	O
these	O
results	O
,	O
it	O
can	O
be	O
con	O
-	O
cluded	O
that	O
the	O
pseudo	O
labels	O
are	O
benecial	O
and	O
they	O
can	O
help	O
us	O
train	B-TaskName
DST	I-TaskName
models	O
more	O
robustly	O
.	O
(	O
2018	O
)	O
,	O
who	O
used	O
a	O
seq2seq	O
model	O
to	O
automatically	O
generate	O
such	O
compact	O
answers	O
as	O
C	O
in	O
Table	O
Besim	O
Avci	O
Google	O
ffrederickliu	O
,	O
besim	O
g@google.com	O
With	O
this	O
graphical	O
representation	O
,	O
they	O
applied	O
graph	O
neural	O
networks	O
to	O
predict	O
ternary	O
relations	O
in	O
the	O
medical	O
domain	O
.	O
In	O
Proceedings	O
of	O
SIGDIAL	O
.	O
Currently	O
,	O
the	O
vocabulary	O
list	O
for	O
adult	O
learners	O
includes	O
about	O
12	O
500	O
words	O
for	O
levels	O
A1C1	O
.	O
This	O
is	O
valuable	O
,	O
since	O
the	O
more	O
we	O
know	O
about	O
the	O
way	O
examinees	O
think	O
about	O
the	O
problem	O
presented	O
in	O
an	O
item	O
,	O
the	O
better	O
we	O
can	O
evaluate	O
exam	O
validity	O
.	O
All	O
unsupervised	O
systems	O
benet	O
from	O
domainadaptation	O
via	O
ne	O
-	O
tuning	O
on	O
authentic	O
labelled	O
data	O
(	O
Miceli	O
Barone	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Other	O
Systems	O
QuBot	B-MethodName
,	O
a	O
chatbot	O
from	O
Pohang	O
University	O
and	O
CMU	O
,	O
is	O
used	O
for	O
out	O
-	O
of	O
-	O
domain	O
handling	O
.	O
This	O
issue	O
becomes	O
more	O
prominent	O
in	O
the	O
era	O
of	O
deep	O
learning	O
,	O
as	O
training	O
deep	O
models	O
generally	O
requires	O
a	O
lot	O
of	O
well	O
-	O
labelled	O
data	O
,	O
but	O
it	O
is	O
expensive	O
and	O
time	O
-	O
consuming	O
to	O
collect	O
large	O
-	O
scale	O
datasets	O
with	O
completely	O
clean	O
annotations	O
.	O
The	O
results	O
show	O
that	O
:	O
ASR	B-MethodName
improves	O
the	O
best	O
current	O
model	O
for	O
AS2	B-MethodName
,	O
i.e.	O
,	O
T	O
AND	O
A	O
by3	O
%	O
,	O
corresponding	O
to	O
an	O
error	O
reduction	O
of	O
10	B-MetricValue
%	I-MetricValue
in	B-MetricName
Accuracy	I-MetricName
,	O
on	O
both	O
WikiQA	B-DatasetName
and	O
TREC	B-DatasetName
-	I-DatasetName
QA	I-DatasetName
.	O
Daniel	O
Tse	O
and	O
James	O
R.	O
Curran	O
.	O
2010	O
.	O
Classication	O
in	O
the	O
presence	O
of	O
label	O
noise	O
:	O
a	O
survey	O
.	O
The	O
number	O
of	O
parameters	O
in	O
the	O
model	O
are	O
approximately	O
248	O
Million	O
and	O
it	O
takes26	O
hours	O
on	O
4	O
Nvidia	O
V100	O
(	O
32	O
GB	O
)	O
GPUs	O
.	O
Patrick	O
Ernst	O
,	O
Amy	O
Siu	O
,	O
and	O
Gerhard	O
Weikum	O
.	O
Next	O
,	O
we	O
plot	O
the	O
model	O
errors	O
across	O
the	O
two	O
classes	O
of	O
low	O
-	O
complexity	O
and	O
high	O
-	O
complexity	O
items	O
,	O
as	O
shown	O
in	O
Figure	O
3	O
.	O
In	O
Word	O
Journal	O
Of	O
The	O
International	O
Linguistic	O
Association	O
,	O
pages	O
18	O
,	O
Tokyo	O
,	O
Japan	O
,	O
sep	O
.	O
Wikipedia2vec	B-MethodName
:	O
The	O
system	O
employed	O
a	O
frame	O
-	O
based	O
information	O
retrieval	O
approach	O
to	O
select	O
Wikipedia	O
sentences	O
providing	O
evidence	O
and	O
used	O
a	O
two	O
-	O
layer	O
multilayer	O
perceptron	O
(	O
MLP	O
)	O
for	O
classication	O
.	O
Denition	O
1	O
(	O
Entity	O
and	O
Mention	O
)	O
.	O
5	O
Conclusion	O
This	O
paper	O
has	O
presented	O
a	O
novel	O
portal	O
that	O
collects	O
spoken	O
dialog	O
data	O
for	O
connected	O
systems	O
.	O
Tsung	O
-	O
Yi	O
Lin	O
,	O
Priya	O
Goyal	O
,	O
Ross	O
Girshick	O
,	O
Kaiming	O
He	O
,	O
and	O
Piotr	O
Doll	O
ar	O
.	O
2017	O
.	O
Nikola	O
Mrk	O
sic	O
,	O
Diarmuid	O
O	O
Seaghdha	O
,	O
Tsung	O
-	O
Hsien	O
Wen	O
,	O
Blaise	O
Thomson	O
,	O
and	O
Steve	O
Young	O
.	O
In	O
Proceedings	O
of	O
ACL	O
2018	O
(	O
Volume	O
2	O
:	O
Short	O
Papers	O
)	O
,	O
pages	O
2530	O
.	O
For	O
instance	O
,	O
Figure	O
1	O
(	O
top	O
)	O
shows	O
one	O
type	O
of	O
structured	O
information	O
in	O
NER	B-TaskName
.	O
(	O
pets	O
)	O
,	O
family	O
information	O
,	O
hobbies	O
,	O
jobs	O
,	O
personal	O
information	O
and	O
music	O
tastes	O
respectively	O
.	O
InterlocutorLiteral	O
Agent	O
:	O
!	O
In	O
our	O
Distractor	B-MethodName
Memorynetwork	I-MethodName
,	O
training	O
corresponds	O
to	O
updating	O
the	O
memory	O
and	O
the	O
parameters	O
of	O
the	O
query	O
network	O
.	O
The	O
focus	O
nodes	O
(	O
US	O
,	O
river	O
,	O
2nd	O
)	O
are	O
extracted	O
from	O
the	O
mentions	O
of	O
the	O
question	O
,	O
and	O
they	O
constrain	O
the	O
answer	O
node	O
via	O
predicate	O
sequences	O
in	O
the	O
knowledge	O
base	O
.	O
Our	O
KGAT	B-MethodName
version	O
for	O
AS2	B-MethodName
also	O
improves	O
PR	B-MetricName
over	O
all	O
datasets	O
and	O
almost	O
all	O
measures	O
,	O
conrming	O
that	O
the	O
idea	O
of	O
using	O
candidates	O
as	O
support	O
of	O
the	O
target	O
answer	O
is	O
generally	O
valid	O
.	O
In	O
Proceedings	O
of	O
the	O
Third	O
Conference	O
on	B-TaskName
Machine	I-TaskName
Translation	I-TaskName
:	O
Shared	O
Task	O
Papers	O
,	O
pages	O
272303	O
,	O
Belgium	O
,	O
Brussels	O
.	O
Association	O
for	O
Computational	O
Linguistics	O
.	O
A	O
baseline	O
that	O
further	O
pre	O
-	O
trains	O
the	O
PLM	B-MethodName
on	O
taskspecic	O
corpus	O
as	O
in	O
Gururangan	O
et	O
al	O
.	O
V	B-MethodName
-	I-MethodName
net	I-MethodName
:	O
Fully	O
convolutional	O
neural	O
networks	O
for	O
volumetric	O
medical	O
image	B-TaskName
segmentation	I-TaskName
.	O
Given	O
that	O
the	O
vanilla	O
noisy	O
labels	O
are	O
regarded	O
as	O
the	O
true	O
labels	O
,	O
we	O
can	O
conjecture	O
that	O
the	O
true	O
performance	O
is	O
actually	O
higher	O
.	O
Conduct	O
Chinese	O
word	B-TaskName
segmentation	I-TaskName
with	O
HanLP(v_1.5.3)3	B-MethodName
.	O
Improving	O
machine	B-TaskName
translation	I-TaskName
quality	O
with	O
automatic	O
named	B-TaskName
entity	I-TaskName
recognition	I-TaskName
.	O
2015	O
.	O
Paraphrasing	O
is	O
the	O
most	O
frequent	O
error	O
category	O
observed	O
for	O
DrQA	B-MethodName
,	O
which	O
makes	O
sense	O
if	O
we	O
con	O
-	O
sider	O
the	O
features	O
used	O
to	O
represent	O
each	O
passage	O
,	O
such	O
as	O
exact	O
match	O
with	O
a	O
question	O
word	O
,	O
which	O
depend	O
on	O
lexical	O
overlap	O
between	O
the	O
question	O
and	O
passage	O
.	O
(	O
2019)88.39	B-MetricValue
90.29	I-MetricValue
89.33	I-MetricValue
BiLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
ELMOy89.14	I-MethodName
88.59	B-MetricValue
88.87	I-MetricValue
BiLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT89.32	I-MethodName
90.02	B-MetricValue
89.67	I-MetricValue
BiLSTM	B-MethodName
-	I-MethodName
GCN	I-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
ELMOy89.40	I-MethodName
89.71	B-MetricValue
89.55	I-MetricValue
GCN	B-MethodName
-	I-MethodName
BiLSTM	I-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT89.34	I-MethodName
91.26	B-MetricValue
90.29	I-MetricValue
DGLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
(	O
2019	O
)	O
+	B-MethodName
ELMO	I-MethodName
89.59	B-MetricValue
90.17	I-MetricValue
89.88	I-MetricValue
DGLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT89.63	I-MethodName
89.87	B-MetricValue
89.75	I-MetricValue
Luo	O
et	O
al	O
.	O
(	O
2020	O
)	O
+	O
BERT	B-MethodName
-	O
-	O
90.30	B-MetricValue
Syn	B-MethodName
-	I-MethodName
LSTM	I-MethodName
-	I-MethodName
CRF	I-MethodName
+	I-MethodName
BERT	I-MethodName
(	O
Ours	O
)	O
90.14	B-MetricValue
91.58	I-MetricValue
90.85	I-MetricValue
Table	O
3	O
:	O
Experimental	O
results	O
Figure	O
1	O
shows	O
the	O
class	O
assignment	O
,	O
p	O
-	O
value	O
,	O
and	O
mean	O
response	O
time	O
for	O
each	O
item	O
.	O
Discretestate	B-MethodName
variational	I-MethodName
autoencoders	I-MethodName
for	O
joint	B-TaskName
discovery	I-TaskName
andfactorization	I-TaskName
of	I-TaskName
relations	I-TaskName
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
use	O
dice	B-MetricName
loss	I-MetricName
in	O
replacement	O
of	O
the	O
standard	O
cross	B-MetricName
-	I-MetricName
entropy	I-MetricName
objective	O
for	O
data	O
-	O
imbalanced	O
NLP	O
tasks	O
.	O
We	O
used	O
almost	O
the	O
same	O
59	O
pairs	O
for	O
which	O
morphological	O
analysis	O
failed	O
were	O
removed	O
.	O
Though	O
the	O
average	B-MetricName
time	I-MetricName
per	I-MetricName
task	I-MetricName
and	O
fscore	B-MetricName
for	O
the	O
endpointed	B-MethodName
variant	I-MethodName
are	O
better	O
than	O
those	O
of	O
the248	O
Lattice	B-MethodName
-	I-MethodName
LSTM	I-MethodName
:	O
c3	O
:	O
Every	O
year	O
,	O
Valentines	O
day	O
is	O
celebrated	O
on	O
February	O
14	O
in	O
many	O
countries	O
around	O
the	O
world	O
.	O
The	O
fact	O
is	O
represented	O
as	O
the	O
format	O
of	O
(	O
head	O
,	O
relation	O
,	O
tail).5167	O
This	O
approach	O
also	O
uses	O
a	O
POS	O
-	O
tagging	O
step	O
in	O
order	O
to	O
obtain	O
the	O
initial	O
set	O
of	O
entities	O
to	O
process	O
.	O
In	O
Proceedings	O
of	O
the	O
Thirteenth	O
International	O
Conference	O
on	O
Articial	O
Intelligence	O
and	O
Statistics	O
,	O
volume	O
9	O
of	O
Proceedings	O
of	O
Machine	O
Learning	O
Research	O
,	O
pages	O
249256	O
,	O
Chia	O
Laguna	O
Resort	O
,	O
Sardinia	O
,	O
Italy	O
.	O
Specially	O
,	O
for	O
+	O
positive	O
,	O
DSC	B-MethodName
achieves	O
minor	O
improvements	O
(	O
+0.05	B-MetricValue
F1	B-MetricName
)	O
over	O
DL	B-MethodName
.	O
A	O
plausible	O
explanation	O
is	O
that	B-MetricName
KL	I-MetricName
loss	I-MetricName
confuses	O
the	O
persona	O
predictor	O
and	O
indirectly	O
increases	O
the	O
uncertainty	O
of	O
the	O
GPT-2	B-MethodName
.	O
Roth	O
(	O
2019	O
)	O
for	O
their	O
systems	O
that	O
use	O
authentic	O
error	O
-	O
annotated	O
data	O
for	O
training	O
(	O
Table	O
4b	O
and	O
4c	O
)	O
.	O
Diederik	O
P.	O
Kingma	O
and	O
Jimmy	O
Ba	O
.	O
2014	O
.	O
(	O
1.0	O
)	O
Why	O
am	O
I	O
getting	O
headaches	O
out	O
of	O
no	O
whero	O
never	O
get	O
them	O
:(	O
Mikhail	O
Khodak	O
,	O
Nikunj	O
Saunshi	O
,	O
Yingyu	O
Liang	O
,	O
Tengyu	O
Ma	O
,	O
Brandon	O
Stewart	O
,	O
and	O
Sanjeev	O
Arora	O
.	O
Le	O
,	O
and	O
Christopher	O
D.	O
Manning	O
.	O
Attention	O
is	O
all	O
you	O
need	O
.	O
2018	O
.	O
This	O
was	O
further	O
examined	O
by	O
one	O
of	O
the	O
authors	O
,	O
who	O
is	O
uent	O
in	O
both	O
English	O
and	O
Korean	O
.	O
IEEE	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12(10):993	O
1001	O
.	O
This	O
bias	O
may	O
affect	O
a	O
downstream	O
ML	O
model	O
,	O
but	O
the	O
vector	O
space	O
has	O
no	O
absolute	O
interpretable	O
meaning	O
,	O
especially	O
when	O
it	O
comes	O
to	O
whether	O
this	O
embedding	O
model	O
will	O
lead	O
to	O
a	O
unfairly	O
discriminative	O
algorithm	O
.	O
Six	O
challenges	O
for	B-TaskName
neural	I-TaskName
machine	I-TaskName
translation	I-TaskName
.	O
The	O
evaluation	O
is	O
conducted	O
in	O
a	O
blind	O
process	O
with	O
the	O
utterance	O
belonging	O
unknown	O
to	O
the	O
reviewers	O
.	O
International	O
World	O
Wide	O
Web	O
Conferences	O
Steering	O
Committee	O
.	O
Association	O
for	O
Computational	O
Linguistics	O
.	O
We	O
mainly	O
focus	O
on	O
negative	O
emotions	O
,	O
relevant	O
to	O
people	O
in	O
psychological	O
distress	O
.	O
Answer	O
4	O
his	O
father	O
Context	O
(	O
CNN	O
)	O
unseeded	O
Frenchwoman	O
Aravane	O
Rezai	O
produced	O
one	O
of	O
the	O
shocks	O
of	O
the	O
year	O
on	O
Sunday	O
by	O
defeating	O
favorite	O
Venus	O
Williams	O
in	O
straight	O
setsto	O
win	O
the	O
final	O
of	O
the	O
Madrid	O
Open	O
.	O
Generating	O
multiple	O
-	O
choice	O
test	O
items	O
from	O
medical	O
text	O
:	O
A	O
pilot	O
study	O
.	O
The	O
recommendation	O
policy	O
has	O
been	O
improved	O
in	O
two	O
ways	O
:	O
1)All	O
participating	O
system	O
developers	O
agreed	O
that	O
Skylar	B-MethodName
should	O
give	O
ES	O
recommendations	O
on	O
a	O
rotating	O
basis	O
so	O
that	O
all	O
systems	O
are	O
recommended	O
equally	O
.	O
For	O
the	O
last	O
dialogue	O
snippet	O
,	O
the	O
vanilla	O
labels	O
are	O
correct	O
.	O
Finally	O
,	O
we	O
also	O
include	O
the	O
Year	O
the	O
item	O
was	O
administered	O
as	O
a	O
predictor	O
(	O
2010	O
-	O
2015	O
)	O
to	O
account	O
for	O
potential	O
changes	O
in	O
response	O
process	O
complexity	O
and	O
examinee	O
samples	O
over	O
time	O
.	O
Eline	O
Zenner	O
,	O
Dirk	O
Speelman	O
,	O
and	O
Dirk	O
Geeraerts	O
.	O
916	O
P1s	O
PersonaIve	O
5	O
cats	O
.	O
Bert	B-MethodName
-	I-MethodName
Tagger	I-MethodName
:	O
Devlin	O
et	O
3466Acknowledgements	O
We	O
would	O
like	O
to	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
comments	O
.	O
44.23	B-MetricValue
56.18	I-MetricValue
MAGEC	B-DatasetName
Fine	B-MethodName
-	I-MethodName
tuned	I-MethodName
(	O
34	O
K	O
real	O
data	O
)	O
56.54	B-MetricValue
60.01	I-MetricValue
Table	O
5	O
:	O
Comparison	O
with	O
LM	B-MethodName
-	I-MethodName
based	I-MethodName
GEC	I-MethodName
on	O
the	O
CoNLL	B-DatasetName
(	I-DatasetName
M2	I-DatasetName
)	I-DatasetName
and	B-DatasetName
JFLEG	I-DatasetName
(	I-DatasetName
GLEU	I-DatasetName
)	I-DatasetName
test	O
sets	O
for	O
unsupervised	O
(	O
?	O
)	O
and	O
supervised	O
systems	O
trained	O
or	O
ne	O
-	O
tuned	O
on	O
different	O
amounts	O
of	O
labelled	O
data	O
.	O
=	O
S	O
x2X	O
testNeighbork(x	O
)	O
denotes	O
the	O
union	O
of	O
neighborhood	O
examples	O
(	O
of	O
distancek	O
)	O
around	O
the	O
test	O
set	O
,	O
and	O
Fsoft(x;p	O
)	O
:	O
In	O
Proceedings	O
of	O
the	O
54th	O
Annual	O
Meeting	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
,	O
ACL	O
2016	O
,	O
August	O
7	O
-	O
12	O
,	O
2016	O
,	O
Berlin	O
,	O
Germany	O
,	O
Volume	O
1	O
:	O
Long	O
Papers	O
.	O
Information	O
,	O
11:74	O
.	O
In	O
Advances	O
in	O
Neural	O
Information	O
Processing	O
Systems	O
.	O
In	O
this	O
paper	O
,	O
we	O
consider	O
two	O
POS	O
taggers	O
:	O
a	O
symbol	O
-	O
rened	O
generative	O
HMM	O
tagger	O
(	O
SR	B-MethodName
-	I-MethodName
HMM	I-MethodName
)	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2009	O
)	O
and	O
a	O
BiLSTMCRF	B-MethodName
model	O
when	O
assisting	O
Chinese	B-MethodName
SDG	I-MethodName
.	O
The	O
arc	O
labels	O
encode	O
linguisticallymotivated	O
,	O
broadly	O
-	O
applicable	O
semantic	O
relations	O
that	O
are	O
grounded	O
under	O
the	O
type	O
-	O
driven	O
semantics	O
.	O
InProceedings	O
of	O
the	O
57th	O
Conference	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
,	O
ACL	O
2019	O
,	O
Florence	O
,	O
Italy	O
,	O
July	O
28-	O
August	O
2	O
,	O
2019	O
,	O
Volume	O
1	O
:	O
Long	O
Papers	O
,	O
pages	O
23462357	O
.	O
Zhiguo	O
Wang	O
,	O
Haitao	O
Mi	O
,	O
Wael	O
Hamza	O
,	O
and	O
Radu	O
Florian	O
.	O
2016	O
.	O
In	O
Proceedings	O
of	O
the	O
54th	O
Annual	O
Meeting	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
(	O
Volume	O
1	O
:	O
Long	O
Papers	O
)	O
,	O
pages	O
10641074	O
.	O
However	O
,	O
when	O
the	O
amount	O
of	O
training	O
is	O
relatively	O
small	O
,	O
the	O
large	O
-	O
scale	O
model	O
may	O
not	O
be	O
able	O
to	O
achieve	O
good	O
results	O
,	O
so	O
solving	O
the	O
problem	O
of	O
model	O
training	O
under	O
the	O
condition	O
of	O
a	O
small	O
amount	O
of	O
target	O
data	O
has	O
become	O
a	O
research	O
hotspot	O
.	O
2017	O
.	O
Still	O
,	O
the	O
Max	B-MetricName
-	I-MetricName
Ratio	I-MetricName
of	O
58.15	B-MetricValue
%	I-MetricValue
accounts	O
for	O
a	O
much	O
larger	O
fraction	O
than	O
other	O
predictions	O
.	O
Linguist	O
.	O
,	O
37:197230	O
.	O
According	O
to	O
the	O
Wilcoxon	O
test	O
,	O
these	O
differences	O
are	O
statistically	O
signicant	O
,	O
at	O
a	O
0.05	O
level	O
,	O
only	O
for	O
the	O
s2s	O
(	O
BLEU	B-MetricName
score	O
)	O
and	O
the	O
transformer	B-MethodName
model	O
(	O
both	O
BLEU	B-MetricName
and	O
NIST	B-MetricName
scores	O
)	O
.	O
2020	O
.	O
5	O
Future	O
Directions	O
Improving	O
content	O
diversity	O
in	O
NLG	B-TaskName
.	O
In	O
contrast	O
,	O
Ev2is	B-MethodName
neutral	O
as	O
it	O
describes	O
who	O
Joe	O
Walsh	O
is	O
but	O
does	O
not	O
contribute	O
to	O
establish	O
the	O
induction	O
.	O
2016	O
.	O
38Question	O
Siamese	O
BERT	B-MethodName
XLNet	B-MethodName
Is	O
it	O
single	O
core	O
or	O
multi	O
core?processor	O
name	O
core	O
i3	O
internal	O
mic	O
single	O
digital	O
microphonenumber	O
of	O
cores	O
2	O
processor	O
variant	O
7100u	O
processor	O
name	O
core	O
i3	O
processor	O
name	O
core	O
i3	O
os	O
architecture	O
64	O
bit	O
number	O
of	O
cores	O
2	O
processor	O
brand	O
intel	O
Does	O
16	O
inch	O
laptop	O
t	O
in	O
to	O
it?depth	O
13	O
inch	O
compatible	O
laptop	O
size	O
15.4	O
inchcompatible	O
laptop	O
size	O
15.4	O
inch	O
width	O
9	O
inch	O
laptop	O
sleeve	O
al	O
.	O
98	B-MetricValue
%	B-MetricName
Negative	I-MetricName
(	O
98	B-MetricValue
%	B-MetricName
Negative	I-MetricName
)	O
These	O
extra	O
annotations	O
were	O
performed	O
by	O
volunteers	O
from	O
the	O
teams	O
participating	O
in	O
the	O
shared	O
task	O
and	O
three	O
of	O
the	O
organizers	O
.	O
All	O
the	O
speakers	O
are	O
anonymized	O
and	O
no	O
identifiable	O
personal	O
information	O
is	O
included	O
.	O
Blue	O
x0	O
is	O
a	O
robust	O
input	O
example	O
(	O
the	O
entire	O
diamond	O
is	O
green	O
)	O
.	O
In	O
our	O
evaluation	O
,	O
we	O
consider	O
a	O
model	O
biased	O
if	O
substituting	O
tokens	O
associated	O
with	O
protected	O
attributes	O
changes	O
theexpected	O
prediction	O
,	O
which	O
is	O
the	O
average	O
prediction	O
among	O
all	O
examples	O
within	O
the	O
neighborhood	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
MoKGE	B-MethodName
,	O
a	O
novel	O
method	O
that	O
diversifies	O
the	O
generative	O
reasoning	O
by	O
a	O
mixture	O
of	O
expert	O
(	O
MoE	O
)	O
strategy	O
on	O
commonsense	O
knowledge	O
graphs	O
(	O
KG	O
)	O
.	O
Marta	O
R.	O
Costa	O
-	O
juss	O
`	O
a	O
and	O
Jos	O
e	O
A.	O
R.	O
Fonollosa	O
.	O
2.1	O
Test	O
data	O
To	O
evaluate	O
and	O
compare	O
our	O
models	O
,	O
we	O
use	O
the	O
Spanish	O
-	O
English	O
(	O
SPA	O
-	O
EN	O
)	O
part	O
of	O
the	O
LinCE	B-DatasetName
benchmark	O
(	O
a	O
total	O
of	O
32,651	O
posts	O
equivalent	O
to	O
390,953	O
tokens	O
)	O
(	O
Aguilar	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
2018	O
Association	O
for	O
Computational	O
Linguistics89Comparative	O
Analysis	O
of	O
Neural	O
QA	B-TaskName
models	O
on	O
SQuAD	B-DatasetName
Soumya	O
Wadhwa	O
Khyathi	O
Raghavi	O
Chandu	O
Eric	O
Nyberg	O
Language	O
Technologies	O
Institute	O
,	O
Carnegie	O
Mellon	O
University	O
fsoumyaw	O
,	O
kchandu	O
,	O
en09	O
g@andrew.cmu.edu	O
Suppose	O
a	O
product	O
PhasSspecications	O
and	O
Qquestions	O
.	O
In	O
fact	O
,	O
it	O
is	O
the	O
most	O
frequent	O
prediction	O
for	O
LM+KL+MI	B-MethodName
over	O
4,332	O
persona	O
labels	O
.	O
Tsdae	O
:	O
Using	O
transformer	B-MethodName
-	O
based	O
sequential	O
denoising	O
auto	O
-	O
encoderfor	O
unsupervised	B-TaskName
sentence	I-TaskName
embedding	I-TaskName
learning	I-TaskName
.	O
Ashish	O
Vaswani	O
,	O
Noam	O
Shazeer	O
,	O
Niki	O
Parmar	O
,	O
Jakob	O
Uszkoreit	O
,	O
Llion	O
Jones	O
,	O
Aidan	O
N	O
Gomez	O
,	O
ukasz	O
Kaiser	O
,	O
and	O
Illia	O
Polosukhin	O
.	O
2017	O
.	O
These	O
models	O
are	O
believed	O
to	O
be	O
reasoning	O
in	O
some	O
way	O
;	O
however	O
,	O
it	O
has	O
been	O
shown	O
that	O
these	O
same	O
results	O
,	O
or	O
better	O
,	O
can	O
be	O
achieved	O
without	O
considering	O
the	O
claim	O
at	O
all	O
only	O
the	O
evidence	O
.	O
As	O
pointed	O
out	O
by	O
Meng	O
et	O
al	O
.	O
Our	O
model	O
can	O
be	O
seen	O
as	O
an	O
extension	O
of	O
the	O
model	O
by	O
Jolly	O
et	O
al	O
.	O
Finally	O
,	O
we	O
showed	O
that	O
by	O
using	O
only	O
extracted	O
evidence	O
as	O
the	O
premise	O
,	O
our	O
approach	O
outperforms	O
previous	O
baselines	O
on	O
the	O
downstream	B-TaskName
tabular	I-TaskName
inference	I-TaskName
task	O
.	O
2016	O
Association	O
for	O
Computational	O
Linguistics	O
X575	O
:	O
writing	O
rengas	O
with	O
web	O
services	O
Daniel	O
Winterstein	O
Winterwell	O
Associates	O
daniel@winterwell.comJoseph	O
Corneli	O
Goldsmiths	O
College	O
,	O
University	O
of	O
London	O
j.corneli@gold.ac.uk	O
Abstract	O
Our	O
software	O
system	O
simulates	O
the	O
classical	O
collaborative	O
Japanese	O
poetry	O
form	O
,	O
renga	O
,	O
made	O
of	O
linked	O
haikus	O
.	O
359System	O
P	O
R	O
F	O
0:5	O
Random	B-MethodName
32.8	B-MetricValue
6.7	I-MetricValue
18.49	I-MetricValue
Edit	B-MethodName
distance	I-MethodName
39.9	B-MetricValue
9.5	I-MetricValue
24.27	I-MetricValue
Word	B-MethodName
embeddings	I-MethodName
39.7	B-MetricValue
9.0	I-MetricValue
23.56	I-MetricValue
Spell	B-MethodName
-	I-MethodName
breaking	I-MethodName
43.1	B-MetricValue
10.6	I-MetricValue
26.66	I-MetricValue
+	O
OOV	B-MethodName
+	I-MethodName
Case	I-MethodName
44.9	B-MetricValue
10.9	I-MetricValue
27.70	I-MetricValue
!	O
Evaluating	O
text	B-TaskName
generation	I-TaskName
with	O
bert	B-MethodName
.	O
However	O
,	O
many	O
popular	O
pre	O
-	O
trained	O
sets	O
of	O
word	O
embeddings	O
assume	O
xed	O
nite	O
-	O
size	O
vocabularies1	O
,	O
2	O
,	O
which	O
hinders	O
their	O
ability	O
to	O
provide	O
useful	O
word	O
representations	O
for	O
out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	O
)	O
words	O
.	O
[	O
%	O
]	O
based	O
on	O
entity	O
length	O
on	O
Catalan	O
,	O
Spanish	O
,	O
English	O
and	O
Chinese	O
datasets	O
.	O
Being	O
limited	O
only	O
by	O
the	O
amount	O
of	O
clean	O
monolingual	O
data	O
,	O
this	O
large	O
-	O
scale	O
unsupervised	O
approach	O
can	O
perform	O
better	O
than	O
training	O
on	O
small	O
authentic	O
error	O
corpora	O
.	O
Javid	O
Ebrahimi	O
,	O
Anyi	O
Rao	O
,	O
Daniel	O
Lowd	O
,	O
and	O
2008	O
.	O
automatically	O
answering	O
yes	O
/	O
no	O
questions	O
using	O
customer	O
reviews	O
.	O
That	O
s	O
cool	O
!	O
942,854	B-MetricValue
2,490	I-MetricValue
5,010	I-MetricValue
#	B-MetricName
Words	I-MetricName
(	I-MetricName
P	I-MetricName
)	I-MetricName
13.6	B-MetricValue
13.6	I-MetricValue
13.0	I-MetricValue
13.1	I-MetricValue
#	B-MetricName
Words	I-MetricName
(	I-MetricName
H	I-MetricName
)	I-MetricName
7.1	B-MetricValue
7.2	I-MetricValue
6.8	I-MetricValue
6.8	I-MetricValue
Table	O
1	O
:	O
Statistics	O
of	O
KorNLI	O
dataset	O
.	O
ConceptNet	B-MethodName
.	O
However	O
,	O
are	O
these	O
evaluations	O
robust	O
?	O
For	O
attention	O
in	O
our	O
GNN	B-MethodName
,	O
we	O
mask	O
the	O
nodes	O
of	O
the	O
null	O
entity	O
,	O
so	O
that	O
the	O
attention	O
score	O
becomes	O
zero	O
for	O
them	O
.	O
In	O
Proceedings	O
of	O
the	O
2013	O
Conference	O
on	O
Empirical	O
Methods	O
in	O
Natural	O
Language	O
Processing	O
,	O
pages	O
16311642	O
,	O
Seattle	O
,	O
Washington	O
,	O
USA	O
.	O
Association	O
for	O
Computational	O
Linguistics	O
.	O
Right	O
:	O
A	O
biased	O
model	O
where	O
the	O
predictions	O
for	O
xp	O
(	O
red	O
)	O
are	O
usually	O
more	O
negative	O
(	O
gray	O
)	O
than	O
x(yellow	O
)	O
.	O
2014	O
.	O
The	O
generation	O
of	O
the	O
rst	O
distractor	O
continues	O
by	O
appending	O
a	O
[	O
MASK	O
]	O
token	O
after	O
each	O
forward	O
pass	O
until	O
the	O
network	O
generates	O
a	O
separator	O
token	O
Before	O
describing	O
our	O
interleaving	O
method	O
in	O
detail	O
,	O
we	O
rst	O
describe	O
the	O
Transformer	B-MethodName
architecture	O
.	O
Human	O
B	B-MethodName
LM	B-MethodName
LM+KL+MII	B-MethodName
ride	O
around	O
the	O
town	O
on	O
my	O
cool	O
bicycle	O
.	O
E	O
Effect	O
of	O
Sentence	O
Length	O
The	O
models	O
withy	O
symbol	O
are	O
retrieved	O
from	O
Jie	O
and	O
Lu	O
(	O
2019	O
)	O
.	O
al	O
.	O
,	O
2019	O
;	O
Liu	O
et	O
al	O
.	O
,	O
2019b	O
)	O
.	O
The	O
specific	O
sentence	O
model	O
we	O
used	O
was	O
Swedish	B-MethodName
sentence	I-MethodName
-	I-MethodName
Bert	I-MethodName
(	O
Rekathati	O
,	O
2021	O
)	O
.	O
Reasonet	B-MethodName
:	O
Learning	O
to	O
stop	O
reading	O
in	O
machine	O
comprehension	O
.	O
In	O
the	O
experiments	O
that	O
follow	O
,	O
we	O
report	O
objective	O
and	O
subjective	O
measures	O
to	O
determine	O
the	O
settings	O
that	O
produced	O
superior	O
results	O
.	O
My	O
favorite	O
music	O
is	O
hip	O
hop	O
.	O
Assuming	O
our	O
coded	O
samples	O
are	O
representative	O
of	O
the	O
real	O
distribution	O
of	O
relevant	O
/	O
irrelevant	O
tweets	O
that	O
occur	O
with	O
each	O
query	O
word	O
,	O
it	O
makes	O
sense	O
to	O
also	O
discard	O
the	O
39	O
noisy	O
query	O
words	O
from	O
our	O
Original	O
Dataset	O
.	O
As	O
we	O
can	O
see	O
from	O
Figure	O
4	O
,	O
RSN	B-MethodName
is	O
able	O
to	O
roughly	O
distinguish	O
different	O
relations	O
,	O
andSemi	B-MethodName
-	I-MethodName
supervised	I-MethodName
RSN	I-MethodName
further	O
facilitated	O
knowl	O
-	O
edge	O
transfer	O
by	O
optimizing	O
the	O
margin	O
betweenpotential	O
relation	O
clusters	O
during	O
training	O
.	O
Harish	O
Tayyar	O
Madabushi	O
,	O
Mark	O
Lee	O
,	O
and	O
John	O
Barnden	O
.	O
1998	O
.	O
From	O
the	O
perspective	O
of	O
both	O
the	O
e	O
-	O
commerce	O
service	O
provider	O
as	O
well	O
as	O
the	O
customers	O
,	O
there	O
must	O
be	O
an	O
effective	O
question	B-TaskName
answering	I-TaskName
system	O
to	O
provide	O
immediate	O
answers	O
to	O
the	O
user	O
queries	O
.	O
In	O
other	O
words	O
,	O
they	O
have	O
similar	O
semantics	O
to	O
the	O
GT	O
utterance	O
and	O
follow	O
the	O
While	O
the	O
approach	O
taken	O
in	O
this	O
paper	O
has	O
a	O
higher	O
ecological	O
validity	O
,	O
studying	O
such	O
cases	O
in	O
the	O
future	O
may	O
lead	O
to	O
a	O
greater	O
understanding	O
of	O
various	O
aspects	O
of	O
response	O
process	O
complexity	O
and	O
their	O
relationship	O
to	O
item	O
text	O
.	O
Similar	O
tools	O
have	O
also	O
been	O
developed	O
for	O
many	O
other	O
languages	O
(	O
see	O
e.g.	O
Alfter	O
,	O
2021	O
)	O
.	O
Association	O
for	O
Computational	O
Linguistics	O
.	O
They	O
collect	O
entailing	O
and	O
contradictory	O
utterances	O
to	O
the	O
given	O
persona	O
,	O
and	O
release	O
an	O
evaluation	O
set	O
comprised	O
of	O
dialogues	O
each	O
with	O
31	O
utterance	O
candidates	O
:	O
10	O
entailing	O
,	O
10	O
neutral	O
,	O
and	O
10	O
contradictory	O
utterances	O
with	O
1	O
ground	O
-	O
truth	O
(	O
GT	O
)	O
utterance	O
.	O
In	O
Advances	O
in	O
neural	O
information	O
processing	O
systems	O
,	O
pages	O
3483	O
3491	O
.	O
In	O
Journal	O
of	O
the	O
Royal	O
Statistical	O
Society	O
(	O
Methodological	O
)	O
.	O
CoNLL2003	B-DatasetName
is	O
an	O
English	O
dataset	O
with	O
4	O
entity	O
types	O
:	O
Location	O
,	O
Organization	O
,	O
Person	O
and	O
Miscellaneous	O
.	O
PRESEMT	B-MethodName
was	O
designed	O
to	O
create	O
MT	B-TaskName
systems	O
requiring	O
only	O
very	O
limited	O
amounts	O
of	O
specialized	O
,	O
expensive	O
linguistic	O
resources	O
.	O
JournalNature	O
Communications	O
,	O
10(1	O
)	O
.	O
Mehdi	O
Mirza	O
and	O
Simon	O
Osindero	O
.	O
BPu	O
measures	O
the	O
KL	B-MetricName
divergence	I-MetricName
DKL(F0||A(f(u	O
)	O
)	O
)	O
where	O
F0refers	O
to	O
uniform	O
distribution	O
.	O
The	O
item	O
The	O
interface	O
was	O
useful	O
and	O
easy	O
to	O
understand	O
with	O
the	O
answer	O
of	O
Both	O
was	O
signicant	O
(	O
2(4	O
,	O
N	O
=	O
12	O
)	O
=	O
9.0	O
,	O
p	B-MetricName
<	B-MetricValue
.005	I-MetricValue
)	O
,	O
as	O
was	O
The	O
assistant	O
was	O
easy	O
and	O
intuitive	O
to	O
use	O
also	O
with	O
the	O
answer	O
Both	O
(	O
2(4	O
,	O
N	O
=	O
12	O
)	O
=	O
9.0	O
,	O
p	B-MetricName
<	B-MetricValue
.005	I-MetricValue
)	O
.	O
6	O
Related	O
Work	O
In	O
this	O
section	O
,	O
we	O
briey	O
review	O
related	O
work	O
on	O
DST	B-TaskName
and	O
noisy	B-TaskName
label	I-TaskName
learning	I-TaskName
.	O
A	O
AB	O
Pre	O
.	O
an	O
empirical	O
comparison	O
of	O
direct	O
,	O
PCFG	B-MethodName
-	O
based	O
,	O
and	O
HPSG	B-MethodName
-	O
based	O
parsers	O
.	O
Proceedings	O
of	O
the	O
VLDB	O
Endowment	O
,	O
10(5):565576	O
.	O
Bleurt	B-MethodName
:	O
Learning	O
robust	O
metrics	O
for	O
text	B-TaskName
generation	I-TaskName
.	O
The	O
actual	O
weight	O
values	O
must	O
reward	O
the	O
establishment	O
of	O
alignments	O
at	O
an	O
earlier	O
rather	O
than	O
a	O
later	O
stage	O
.	O
With	O
recent	O
progress	O
in	O
large	O
pretrained	O
language	O
models	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
;	O
Yang	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
some	O
attempts	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2019	O
;	O
Zhang	O
et	O
al	O
.	O
,	O
2020	O
;	O
Ham	O
et	O
al	O
.	O
,	O
2020	O
;	O
Shen	O
et	O
al	O
.	O
,	O
2021	O
;	O
In	O
Proceedings	O
of	O
the	O
First	O
Conference	O
on	O
Machine	O
Translation	O
:	O
Volume	O
2	O
,	O
Shared	O
Task	O
Papers	O
,	O
pages	O
131198	O
,	O
Berlin	O
,	O
Germany	O
.	O
We	O
explore	O
a	O
range	O
of	O
hyperparameter	O
congurations	O
of	O
two	O
models	O
:	O
a	O
contextcounting	O
model	O
involving	O
a	B-MethodName
PPMI	I-MethodName
matrix	O
compressed	O
with	O
Singular	B-MethodName
Value	I-MethodName
Decomposition	I-MethodName
(	I-MethodName
SVD	I-MethodName
)	I-MethodName
,	O
and	O
the	O
Skipgram	B-MethodName
with	I-MethodName
Negative	I-MethodName
Sampling	I-MethodName
(	I-MethodName
SGNS	I-MethodName
)	I-MethodName
1We	O
share	O
the	O
code	O
for	O
these	O
methods	O
at	O
https://	O
github.com/rgalhama/wordrep_cmcl2020	O
In	O
the	O
end	O
,	O
we	O
hope	O
to	O
build	O
a	O
generic	O
end	O
-	O
to	O
-	O
end	O
classier	O
,	O
which	O
can	O
be	O
used	O
in	O
a	O
domain	O
outside	O
the	O
one	O
in	O
which	O
it	O
was	O
trained	O
,	O
with	O
no	O
or	O
minimal	O
re	O
-	O
training	O
.	O
Given	O
a	O
text	O
,	O
your	O
task	O
is	O
to	O
create	O
one	O
or	O
more	O
multiple	O
choice	O
questions	O
based	O
on	O
the	O
text	O
,	O
i.e.	O
:	O
1	O
.	O
formulate	O
a	O
question	O
with	O
the	O
correct	O
answer	O
in	O
the	O
text	O
;	O
2	O
.	O
mark	O
the	O
correct	O
answer	O
in	O
the	O
text	O
;	O
3	O
.	O
mark	O
some	O
wrong	O
,	O
but	O
plausible	O
options	O
in	O
the	O
text	O
.	O
English	O
Language	O
&	O
Linguistics	O
,	O
21(1):99127	O
.	O
2018	O
.	O
In	O
Proceedings	O
of	O
the	O
2019	O
Conference	O
of	O
the	O
North	O
American	O
Chapter	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
:	O
Human	O
Language	O
Technologies	O
,	O
NAACL	O
-	O
HLT	O
2019	O
,	O
Minneapolis	O
,	O
MN	O
,	O
USA	O
,	O
June	O
2	O
-	O
7	O
,	O
2019	O
,	O
Volume	O
1	O
(	O
Long	O
and	O
Short	O
Papers	O
)	O
,	O
pages	O
41714186	O
.	O
False	B-HyperparameterValue
Trainingepochs	B-HyperparameterName
50	B-HyperparameterValue
50	I-HyperparameterValue
50	I-HyperparameterValue
lr	B-HyperparameterName
1.0	B-HyperparameterValue
1.0	I-HyperparameterValue
1.0	I-HyperparameterValue
lrdecay	B-HyperparameterName
True	B-HyperparameterValue
True	I-HyperparameterValue
True	I-HyperparameterValue
normalize	B-HyperparameterName
semb	I-HyperparameterName
False	B-HyperparameterValue
False	I-HyperparameterValue
True	I-HyperparameterValue
prob	B-HyperparameterName
eps	I-HyperparameterName
0.01	B-HyperparameterValue
0.01	I-HyperparameterValue
0.01	I-HyperparameterValue
Table	O
6	O
:	O
Training	O
settings	O
used	O
in	O
word	O
similarity	O
experiment	O
for	O
BoS	B-MethodName
,	O
PBoS	B-MethodName
,	O
and	O
Hello	O
,	O
how	O
are	O
you	O
today?[P1	O
]	O
Ideally	O
,	O
each	O
row	O
is	O
independent	O
and	O
,	O
its	O
relevance	O
to	O
the	O
hypothesis	O
can	O
be	O
determined	O
on	O
its	O
own	O
.	O
KorNLI	B-MethodName
scores	O
are	O
accuracy	B-MetricName
(	O
%	O
)	O
and	O
KorSTS	B-MethodName
scores	O
are	O
100	B-MetricValue
Spearman	B-MetricName
correlation.yTo	I-MetricName
ensure	O
comparability	O
with	O
XNLI	B-DatasetName
,	O
we	O
only	O
use	O
the	O
MNLI	B-DatasetName
portion	O
of	O
the	O
KorNLI	B-DatasetName
dataset	O
.	O
We	O
computed	O
an	O
inter	B-MetricName
-	I-MetricName
rater	I-MetricName
reliability	I-MetricName
score	I-MetricName
for	O
our	O
two	O
coders	O
,	O
based	O
on	O
a	O
random	O
sample	O
of	O
200	O
tweets	O
.	O
Then	O
for	O
a	O
set	O
,	O
K	O
=	O
fk1;:::;k	O
tg	O
,	O
oftdemographic	O
identity	O
word	O
vectors	O
from	O
a	O
particular	O
protected	O
group	O
(	O
i.e.	O
national	O
origin	O
,	O
religion	O
,	O
etc	O
.	O
)	O
,	O
we	O
dene	O
a	O
set	O
,	O
P	O
,	O
containing	O
the	O
predicted	O
negative	O
sentiment	O
probability	O
via	O
minimizer	O
,	O
f	O
,	O
normalized	O
to	O
be	O
one	O
probability	O
mass	O
.	O
Comparing	O
to	O
BoS	B-MethodName
,	O
we	O
assign	O
different	O
importance	O
asjw	O
,	O
instead	O
of	O
a	O
uniform	O
weight	O
,	O
to	O
each	O
subword	O
.	O
KFM	B-MethodName
Parameters	O
2014	O
.	O
Truncated	O
samplingk=5	B-HyperparameterName
4.37	B-MetricValue
0.0	I-MetricValue
71.38	I-MetricValue
0.7	I-MetricValue
74.20	I-MetricValue
0.2	I-MetricValue
71.38	I-MetricValue
0.2	I-MetricValue
31.32	I-MetricValue
0.4	I-MetricValue
9.18	I-MetricValue
0.1	I-MetricValue
16.44	I-MetricValue
0.2	I-MetricValue
40.99	I-MetricValue
0.2	I-MetricValue
k=20	B-HyperparameterName
4.60	B-MetricValue
0.0	I-MetricValue
63.42	I-MetricValue
1.2	I-MetricValue
64.47	I-MetricValue
2.1	I-MetricValue
60.33	I-MetricValue
2.4	I-MetricValue
33.69	I-MetricValue
0.6	I-MetricValue
9.26	I-MetricValue
0.1	I-MetricValue
17.70	I-MetricValue
0.2	I-MetricValue
42.58	I-MetricValue
0.5	I-MetricValue
k=50	B-HyperparameterName
4.68	B-MetricValue
0.1	I-MetricValue
60.98	I-MetricValue
1.8	I-MetricValue
61.39	I-MetricValue
2.4	I-MetricValue
56.93	I-MetricValue
2.8	I-MetricValue
34.80	I-MetricValue
0.3	I-MetricValue
9.29	I-MetricValue
0.1	I-MetricValue
17.48	I-MetricValue
0.4	I-MetricValue
42.44	I-MetricValue
0.5	I-MetricValue
Nucleus	B-HyperparameterName
samplingp=.5	I-HyperparameterName
4.19	B-MetricValue
0.1	B-MetricValue
72.78	I-MetricValue
1.0	I-MetricValue
77.66	I-MetricValue
0.8	I-MetricValue
75.14	I-MetricValue
0.9	I-MetricValue
28.36	I-MetricValue
0.6	I-MetricValue
9.05	I-MetricValue
0.3	I-MetricValue
16.09	I-MetricValue
0.6	I-MetricValue
40.95	I-MetricValue
0.5	I-MetricValue
p=.75	B-HyperparameterName
4.41	B-MetricValue
0.1	I-MetricValue
67.01	I-MetricValue
1.7	I-MetricValue
71.41	I-MetricValue
2.5	I-MetricValue
68.22	I-MetricValue
2.9	I-MetricValue
31.21	I-MetricValue
0.3	I-MetricValue
9.16	I-MetricValue
0.1	I-MetricValue
17.07	I-MetricValue
0.5	I-MetricValue
41.88	I-MetricValue
0.7	I-MetricValue
p=.95	B-HyperparameterName
4.70	B-MetricValue
0.1	I-MetricValue
61.92	I-MetricValue
2.6	I-MetricValue
63.43	I-MetricValue
3.4	I-MetricValue
59.23	I-MetricValue
3.8	I-MetricValue
34.17	I-MetricValue
0.3	I-MetricValue
9.27	I-MetricValue
0.2	I-MetricValue
17.68	I-MetricValue
0.4	I-MetricValue
42.60	I-MetricValue
0.8	I-MetricValue
MoEembed	O
5.41	B-MetricValue
0.0	I-MetricValue
47.55	I-MetricValue
0.5	I-MetricValue
Second	O
,	O
since	B-MethodName
DialPort	I-MethodName
has	O
multiple	O
users	O
in	O
parallel	O
,	O
Mr.	B-MethodName
Clue	I-MethodName
was	O
updated	O
to	O
launch	O
a	O
new	O
agent	O
instance	O
for	O
each	O
new	O
HTTP	O
session	O
(	O
user	O
)	O
that	O
is	O
directed	O
to	O
the	O
game	O
from	O
the	O
main	O
DialPort	B-MethodName
system	O
.	O
al	O
.	O
There	O
are	O
sev	O
-	O
eral	O
criteria	O
to	O
evaluate	O
the	O
distance	O
between	O
twoclusters	O
.	O
5String	O
concatenation	O
is	O
denoted	O
with	O
.27	O
European	O
union	O
regulations	O
on	O
algorithmic	O
decision	O
-	O
making	O
and	O
a	O
right	O
to	O
explanation	O
.	O
Multi	O
-	O
task	O
learning	O
Following	O
Ueda	O
et	O
al	O
.	O
#	O
.	O
For	O
the	O
few	O
shot	O
setup	O
,	O
we	O
added	O
all	O
the	O
translated	O
utterances	O
except	O
the	O
ones	O
that	O
correspond	O
to	O
those	O
utterances	O
we	O
already	O
picked	O
as	O
the	O
few	O
shot	O
samples	O
.	O
Parsing	O
to	O
1	O
-	O
endpoint	O
-	O
crossing	O
,	O
pagenumber-2	O
graphs	O
.	O
19	O
of	O
these	O
teams	O
scored	O
higher	O
than	O
the	O
baseline	O
presented	O
in	O
Thorne	O
et	O
al	O
.	O
Davide	O
Chicco	O
.	O
2021	O
.	O
In	O
Proceedings	O
of	O
the	O
2015	O
conference	O
on	O
empirical	O
methods	O
in	O
natural	O
language	O
processing	O
,	O
pages	O
20132018	O
.	O
We	O
expect	O
the	O
knowledge	O
gained	O
during	O
MT	B-MethodName
training	O
to	O
be	O
transferred	O
to	O
ZAR	B-MethodName
.	O
The	O
fact	O
is	O
represented	O
as	O
the	O
format	O
of	O
(	O
head	O
,	O
relation	O
,	O
tail).5166	O
Furthermore	O
,	O
the	O
timing	O
demands	O
of	O
items	O
should	O
be	O
such	O
that	O
different	O
exam	O
forms	O
seen	O
by	O
different	O
test	O
-	O
takers	O
should	O
entail	O
similar	O
times	O
to	O
complete	O
.	O
w.	O
Each	O
edge	O
(	O
i;j)is	O
associated	O
with	O
a	O
weight	O
pw[i	O
:	O
j	O
]	O
how	O
likely	O
w[i	O
:	O
j]itself	O
is	O
a	O
meaningful	O
subword	O
.	O
Since	O
the	O
original	O
emrQA	B-DatasetName
is	O
automatically	O
generated	O
based	O
on	O
templates	O
,	O
the	O
quality	O
is	O
poor	O
it	O
means	O
that	O
the	O
original	O
emrQA	B-DatasetName
dataset	O
was	O
inappropriate	O
to	O
evaluate	O
the	O
ability	O
of	O
the	O
model	O
to	O
reason	O
over	O
the	O
clinical	O
text	O
since	O
the	O
most	O
of	O
questions	O
can	O
be	O
9https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/5158	O
We	O
use	O
Dialogue	B-DatasetName
NLI	I-DatasetName
(	O
Welleck	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
PersonaChat	B-DatasetName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2018	O
)	O
datasets	O
from	O
the	O
ParlAI	O
framework	O
as	O
is	O
.	O
Tags	O
are	O
added	O
to	O
the	O
data	O
as	O
a	O
preprocessing	O
step	O
.	O
Molecular	O
Psychiatry	O
,	O
11(1):11	O
-	O
17	O
.	O
Stem	O
Vilka	O
kan	O
utf	O
arda	O
medicinska	O
rapporter	O
f	O
or	O
kabinbes	O
attning	O
?	O
an	O
100k	O
vocabulary	O
for	O
each	O
language	O
and	O
are	O
used	O
as	O
target	O
vectors	O
for	O
each	O
of	O
the	O
subword	O
-	O
level	O
embedding	O
models	O
in	O
this	O
experiment	O
.	O
Jun	O
Quan	O
,	O
Shian	O
Zhang	O
,	O
Qian	O
Cao	O
,	O
Zizhong	O
Li	O
,	O
and	O
Deyi	O
Xiong	O
.	O
This	O
also	O
reveals	O
the	O
limitation	O
of	O
our	O
method	O
on	O
polysemous	O
words	O
.	O
4232for	O
each	O
iteration	O
was	O
set	O
to	O
20	B-HyperparameterValue
.	O
An	O
illustrative	O
stimulus	O
example	O
would	O
be	O
the	O
following	O
:	O
"	O
The	O
Swedish	O
unions	O
are	O
controlled	O
by	O
globalists	O
"	O
.	O
;	O
(	O
1	O
)	O
where	O
P(wjEN)andP(wjSPA	O
)	O
are	O
probabilities	O
given	O
by	O
the	O
dictionaries	O
described	O
in	O
section	O
3.1	O
.	O
arXiv	O
preprint	O
arXiv:2012.14610	O
.	O
H	O
:}	O
We	O
assess	O
their	O
similarity	O
as	O
0.5	O
if	O
they	O
share	O
any	O
synset	O
.	O
For	O
KVQ	O
-	O
FH	O
,	O
we	O
use	O
the	O
implementation	O
given	O
in	O
the	O
paper	O
.	O
We	O
use	O
Moses	O
(	O
Koehn	O
et	O
al	O
.	O
,	O
2007	O
)	O
for	O
all	O
tokenization	O
/	O
detokenization	O
scripts	O
.	O
In	O
Proceedings	O
of	O
EMNLP	O
2018	O
,	O
pages	O
1121	O
.	O
CA_translated	O
CA8	O
Cap	O
.	O
The	O
results	O
demonstrate	O
that	O
the	O
proposed	O
model	O
achieves	O
better	O
performance	O
than	O
previous	O
approaches	O
while	O
requiring	O
fewer	O
parameters	O
.	O
Cognitive	O
Behavioural	O
Therapy	O
is	O
derived	O
from	O
Cognitive	O
Therapy	O
model	O
theory	O
(	O
Beck	O
,	O
1976	O
;	O
Beck	O
et	O
al	O
.	O
,	O
1979	O
)	O
,	O
which	O
postulates	O
that	O
our	O
emotions	O
and	O
behaviour	O
are	O
inuenced	O
by	O
the	O
way	O
we	O
think	O
and	O
by	O
how	O
we	O
make	O
sense	O
of	O
the	O
world	O
.	O
First	O
,	O
they	O
divide	O
the	O
question	O
templates	O
into	O
easy	O
and	O
hard	O
versions	O
and	O
then	O
use	O
the	O
hard	O
question	O
only	O
.	O
Yes	O
/	O
No	O
What	O
was	O
your	O
general	O
impression	O
of	O
our	O
personal	O
assistants	O
?	O
The	O
Art	O
of	O
Renga	O
.	O
2018	O
.	O
In	O
order	O
to	O
improve	O
service	O
an	O
audio	O
server	O
is	O
under	O
construction	O
as	O
are	O
smartphone	O
and	O
tablet	O
versions	O
.	O
5.7	O
Error	O
Analysis	O
We	O
further	O
investigate	O
the	O
error	B-MetricName
rate	I-MetricName
with	O
respect	O
to	O
each	O
slot	O
.	O
Andreea	O
Simona	O
Calude	O
,	O
Steven	O
Miller	O
,	O
and	O
Mark	O
Pagel	O
.	O
2017	O
.	O
Transactions	O
of	O
the	O
Association	O
for	O
Computational	O
Linguistics	O
,	O
3:211225	O
.	O
Of	O
course	O
,	O
this	O
issue	O
leads	O
to	O
questions	O
of	O
censorship	O
.	O
arXiv	O
preprint	O
arXiv:1607.04606	O
.	O
From	O
a	O
further	O
comparison	O
between	O
the	O
input	O
query	O
and	O
the	O
mid	O
,	O
we	O
also	O
observe	O
that	O
the	O
intermediate	O
utterance	O
is	O
more	O
similar	O
to	O
nal	O
responses	O
than	O
the	O
input	O
query	O
,	O
which	O
correlates	O
well	O
with	O
our	O
original	O
intention	O
shown	O
in	O
Figure	O
1	O
.	O
6	O
Conclusion	O
and	O
future	O
work	O
In	O
this	O
paper	O
,	O
we	O
tackle	O
the	O
one	B-TaskName
-	I-TaskName
to	I-TaskName
-	I-TaskName
many	I-TaskName
queryresponse	I-TaskName
mapping	I-TaskName
problem	O
in	O
open	O
-	O
domain	O
conversation	O
and	O
propose	O
a	O
novel	O
two	O
-	O
step	O
generation	O
architecture	O
with	O
the	O
correlation	O
of	O
multiple	O
valid	O
responses	O
considered	O
.	O
The	O
ne	B-HyperparameterName
-	I-HyperparameterName
tuned	I-HyperparameterName
model	O
also	O
outperforms	O
the	O
baseline	O
for	O
mitigating	O
the	O
bias	O
.	O
The	O
emphasis	O
is	O
on	O
early	O
evidence	O
-	O
based	O
non	O
-	O
pharmacological	O
intervention	O
,	O
avoiding	O
institutionalisation	O
and	O
medicalisation	O
.	O
To	O
bridge	O
the	O
gap	O
,	O
we	O
proposeRelational	B-MethodName
Siamese	I-MethodName
Networks	I-MethodName
(	O
RSNs	B-MethodName
)	O
to	O
learn	O
transferable	O
relational	O
knowledge	O
from	O
superviseddata	O
for	O
OpenRE	B-TaskName
.	O
Perhaps	O
a	O
cause	O
may	O
be	O
the	O
fact	O
that	O
the	O
XPOS	B-MethodName
we	O
use	O
(	O
predicted	O
by	O
UDpipe	B-MethodName
)	O
contain	O
more	O
errors	O
than	O
average	O
for	O
the	O
Chinese	B-DatasetName
,	I-DatasetName
Ukrainian	I-DatasetName
or	I-DatasetName
Vietnamese	I-DatasetName
treebanks	I-DatasetName
than	O
for	O
languages	O
where	O
our	O
test	B-MetricName
score	I-MetricName
is	O
closer	O
to	O
the	O
development	B-MetricName
score	I-MetricName
.	O
Samuel	O
Humeau	O
,	O
Kurt	O
Shuster	O
,	O
Marie	O
-	O
Anne	O
Lachaux	O
,	O
and	O
Jason	O
Weston	O
.	O
Yinhan	O
Liu	O
,	O
Myle	O
Ott	O
,	O
Naman	O
Goyal	O
,	O
Jingfei	O
Du	O
,	O
Mandar	O
Joshi	O
,	O
Danqi	O
Chen	O
,	O
Omer	O
Levy	O
,	O
Mike	O
Lewis	O
,	O
Luke	O
Zettlemoyer	O
,	O
and	O
Veselin	O
Stoyanov	O
.	O
We	O
use	O
SRILM	B-MethodName
(	O
Stolcke	O
,	O
2002	O
)	O
to	O
train	O
a	O
5	B-HyperparameterValue
-	O
gram	B-HyperparameterName
language	O
model	O
on	O
the	O
Xinhua	B-DatasetName
portion	I-DatasetName
of	I-DatasetName
the	I-DatasetName
English	B-DatasetName
Gigaword	I-DatasetName
corpus	I-DatasetName
5th	I-DatasetName
edition	I-DatasetName
with	O
modied	B-MethodName
Kneser	I-MethodName
-	I-MethodName
Ney	I-MethodName
discounting	I-MethodName
(	O
Chen	O
and	O
Goodman	O
,	O
1996	O
)	O
.	O
Top-1	B-MetricName
Top-3	B-MetricName
Top-5	B-MetricName
Top-10	B-MetricName
Top-50	B-MetricName
Top-100	B-MetricName
Top-500	B-MetricName
Top-2000	B-MetricName
LM	B-MethodName
37.59	B-MetricValue
55.57	B-MetricValue
63.28	B-MetricValue
72.76	B-MetricValue
87.19	B-MetricValue
91.54	B-MetricValue
97.79	B-MetricValue
99.60	B-MetricValue
LM+KL+MI	B-MethodName
0.53	B-MetricValue
1.80	B-MetricValue
2.24	B-MetricValue
3.20	B-MetricValue
8.64	B-MetricValue
12.10	B-MetricValue
30.57	B-MetricValue
80.22	B-MetricValue
Table	O
5	O
:	O
Evaluation	O
on	O
the	B-MetricName
top	I-MetricName
-	I-MetricName
k	I-MetricName
accuracy	I-MetricName
over	O
4,332	O
clusters	O
.	O
These	O
claims	O
were	O
sampled	O
for	O
annotation	O
with	O
a	O
probability	O
proportional	O
to	O
the	O
number	O
of	O
systems	O
which	O
labeled	O
each	O
of	O
them	O
incorrectly	O
.	O
Irshad	O
Bhat	O
,	O
Riyaz	O
A.	O
Bhat	O
,	O
Manish	O
Shrivastava	O
,	O
and	O
Dipti	O
Sharma	O
.	O
Word	B-TaskName
embedding	I-TaskName
-	O
based	O
Part	B-TaskName
of	I-TaskName
Speech	I-TaskName
tagging	I-TaskName
in	O
Tamil	O
texts	O
.	O
Vivek	O
Gupta	O
,	O
Riyaz	O
A.	O
Bhat	O
,	O
Atreya	O
Ghosal	O
,	O
Manish	O
Srivastava	O
,	O
Maneesh	O
Singh	O
,	O
and	O
Vivek	O
Srikumar	O
.	O
2021	O
.	O
Brian	O
Hu	O
Zhang	O
,	O
Blake	O
Lemoine	O
,	O
and	O
Margaret	O
Mitchell	O
.	O
2018a	O
.	O
On	O
average	O
,	O
the	O
subjects	O
correctly	O
answered	O
a	O
signicantly	O
larger	O
number	O
of	O
questions	O
than	O
Nr(Ns=	B-MetricName
62:26	B-MetricValue
,	O
SE=	B-MetricName
1:09,t(53	B-MetricValue
)	O
Efciently	O
approximates	O
system	O
-	O
level	O
combination	O
.	O
In	O
fact	O
,	O
many	O
personas	O
share	O
similar	O
meanings	O
and	O
can	O
be	O
further	O
clustered	O
.	O
2019	O
.	O
Rico	O
Sennrich	O
and	O
Biao	O
Zhang	O
.	O
Transactions	O
of	O
the	O
Association	O
of	O
Computational	O
Linguistics	O
,	O
4:357370	O
.	O
We	O
also	O
provide	O
ablation	O
analyses	O
to	O
validate	O
each	O
component	O
of	O
our	O
model	O
.	O
However	O
,	O
we	O
always	O
use	O
standard	O
cross	B-MetricName
-	I-MetricName
entropy	I-MetricName
loss	I-MetricName
as	O
it	O
is	O
more	O
efcient	O
and	O
the	O
different	O
is	O
performance	O
is	O
negligible	O
.	O
Next	O
,	O
a	O
one	B-HyperparameterValue
-	I-HyperparameterValue
dimensional	I-HyperparameterValue
convolutional	B-HyperparameterValue
layer	B-HyperparameterName
and	O
a	O
maxpooling	B-HyperparameterValue
layer	I-HyperparameterValue
transform	B-HyperparameterName
the	O
vector	O
sequence	O
intofeatures	O
.	O
Higher	O
scores	O
denote	O
better	O
language	B-TaskName
generation	I-TaskName
.	O
In	O
Proceedings	O
of	O
the	O
First	O
Workshop	O
on	O
Neural	O
Machine	O
Translation	O
,	O
pages	O
69	O
79	O
,	O
Vancouver	O
.	O
Yael	O
Netzer	O
,	O
David	O
Gabay	O
,	O
Yoav	O
Goldberg	O
,	O
and	O
Michael	O
Elhadad	O
.	O
2009	O
.	O
Springer	O
US	O
,	O
New	O
York	O
,	O
NY	O
.	O
Derrick	O
Nguyen	O
and	O
Bernard	O
Widrow	O
.	O
Mandar	O
Joshi	O
,	O
Eunsol	O
Choi	O
,	O
Daniel	O
S	O
Weld	O
,	O
and	O
Luke	O
Zettlemoyer	O
.	O
2017	O
.	O
6	O
Acknowledgement	O
This	O
work	O
is	O
supported	O
by	O
the	O
National	O
Key	O
Re	O
-	O
search	O
and	O
Development	O
Program	O
of	O
China	O
(	O
No.2018YFB1004503	O
)	O
and	O
the	O
National	O
Natural	O
Sci	O
-	O
ence	O
Foundation	O
of	O
China	O
(	O
NSFC	O
No	O
.	O
61572273,61661146007	O
)	O
.	O
-DOCSTART-	O
We	O
initially	O
found	O
this	O
surprising	O
since	O
intra	O
-	O
sentence	O
ones	O
contain	O
arguments	O
with	O
less	O
information	O
than	O
their	O
(	O
full	O
-	O
sentence	O
)	O
intersentence	O
counterparts	O
.	O
However	O
,	O
one	O
explanation	O
for	O
this	O
is	O
that	O
,	O
while	O
looking	O
for	O
relations	O
within	O
sentence	O
boundaries	O
is	O
a	O
problem	O
that	O
has	O
been	O
very	O
explored	O
,	O
and	O
to	O
some	O
extent	O
solved	O
,	O
in	O
various	O
NLP	O
tasks	O
(	O
e.g.	O
syntactic	O
parsing	O
)	O
,	O
there	O
are	O
not	O
as	O
many	O
rules	O
regarding	O
relations	O
that	O
occur	O
across	O
sentence	O
boundaries	O
.	O
Regardless	O
of	O
the	O
cause	O
,	O
these	O
results	O
illustrate	O
that	O
future	O
shallow	O
discourse	O
parsers	O
may	O
benefit	O
from	O
accounting	O
for	O
such	O
linguistic	O
differences	O
explicitly	O
.	O
Parsers	O
struggle	O
to	O
identify	O
implicit	O
relations	O
from	O
less	O
frequent	O
classes	O
.	O
The	O
second	O
distributional	O
shift	O
we	O
examine	O
is	O
a	O
shift	O
in	O
vocabulary	O
.	O
=	O
m	O
c=1	O
log	O
P	O
(	O
tc	O
|	O
t1	O
:	O
c−1	O
,	O
X	O
)	O
(	O
1	O
)	O
We	O
calculate	O
a	O
score	O
f	O
(	O
T	O
a	O
i	O
,	O
p	O
k	O
)	O
for	O
each	O
possible	O
polarity	O
by	O
employing	O
the	O
pre	O
-	O
trained	O
generative	O
language	O
model	O
(	O
i.e.	O
,	O
BART	B-MethodName
)	O
to	O
score	O
the	O
templates	O
,	O
and	O
then	O
choose	O
the	O
polarity	O
of	O
category	O
a	O
i	O
with	O
the	O
largest	O
score	O
.	O
For	O
ACD	B-MethodName
,	O
we	O
first	O
create	O
templates	O
T	O
+	O
a	O
i	O
and	O
T	O
−	O
a	O
i	O
for	O
all	O
possible	O
categories	O
of	O
the	O
sentence	O
X	O
,	O
and	O
then	O
use	O
the	O
fine	O
-	O
tuned	O
pre	O
-	O
trained	O
generative	O
language	O
model	O
to	O
assign	O
a	O
score	O
for	O
each	O
template	O
T	O
a	O
i	O
=	O
{	O
t	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
m	O
}	O
,	O
in	O
a	O
similar	O
way	O
as	O
Equation	O
1	O
.	O
Also	O
,	O
we	O
decide	O
whether	O
the	O
a	O
i	O
category	O
is	O
discussed	O
or	O
not	O
in	O
the	O
input	O
sentence	O
according	O
to	O
the	O
higher	O
score	O
between	O
T	O
+	O
a	O
i	O
and	O
T	O
−	O
a	O
i	O
.	O
GE	B-MethodName
:	O
a	O
logistic	O
regression	O
classifier	O
trained	O
using	O
generalized	O
expectation	O
criteria	O
(	O
Druck	O
et	O
al	O
,	O
2008	O
)	O
.	O
Class	O
labels	O
are	O
used	O
as	O
labeled	O
features	O
.	O
sLDA	B-MethodName
:	O
a	O
supervised	O
topic	O
model	O
trained	O
using	O
seeded	O
LDA	B-MethodName
(	O
Jagarlamudi	O
et	O
al	O
,	O
2012	O
)	O
.	O
Besides	O
k	O
seeded	O
topics	O
(	O
k	O
is	O
the	O
number	O
of	O
classes	O
)	O
,	O
we	O
use	O
an	O
extra	O
topic	O
to	O
account	O
for	O
other	O
content	O
in	O
the	O
corpus	O
.	O
Word	O
embedding	O
-	O
based	O
methods	O
.	O
The	O
best	O
performing	O
combination	O
for	O
our	O
approach	O
performs	O
as	O
well	O
as	O
classical	O
topic	O
models	O
,	O
but	O
with	O
lower	O
runtime	O
and	O
computational	O
complexity	O
.	O
Topic	O
models	O
are	O
the	O
standard	O
approach	O
for	O
exploratory	O
document	O
analysis	O
(	O
Boyd	O
-	O
Graber	O
et	O
al	O
,	O
2017	O
)	O
,	O
which	O
aims	O
to	O
uncover	O
main	O
themes	O
and	O
underlying	O
narratives	O
within	O
a	O
corpus	O
.	O
But	O
in	O
times	O
of	O
distributed	O
and	O
even	O
contextualized	O
embeddings	O
,	O
are	O
they	O
the	O
only	O
option	O
?	O
This	O
work	O
explores	O
an	O
alternative	O
to	O
topic	O
modeling	O
by	O
casting	O
'	O
key	O
themes	O
'	O
or	O
'	O
topics	O
'	O
as	O
clusters	O
of	O
word	O
types	O
under	O
the	O
modern	O
distributed	O
representation	O
learning	O
paradigm	O
:	O
unsupervised	O
pre	O
-	O
trained	O
word	O
embeddings	O
provide	O
a	O
representation	O
for	O
each	O
word	O
type	O
as	O
a	O
vector	O
,	O
allowing	O
us	O
to	O
cluster	O
them	O
based	O
on	O
their	O
distance	O
in	O
high	O
-	O
dimensional	O
space	O
.	O
The	O
goal	O
of	O
this	O
work	O
is	O
not	O
to	O
strictly	O
outperform	O
,	O
but	O
rather	O
to	O
benchmark	O
standard	O
clustering	O
of	O
modern	O
embedding	O
methods	O
against	O
the	O
classical	O
approach	O
of	O
Latent	B-MethodName
Dirichlet	I-MethodName
Allocation	I-MethodName
(	O
LDA	O
;	O
Blei	O
et	O
al	O
,	O
2003	O
)	O
.	O
Dropout	O
is	O
then	O
applied	O
to	O
these	O
encoded	O
representations	O
h	O
(	O
t	O
)	O
(	O
Equation	O
4represents	O
general	O
formulation	O
for	O
both	O
the	O
tasks	O
)	O
.	O
These	O
are	O
then	O
passed	O
to	O
a	O
BiLSTM	O
decoder	O
,	O
followed	O
by	O
a	O
dropout	O
layer	O
and	O
then	O
a	O
linear	O
output	O
layer	O
to	O
get	O
output	O
o	O
(	O
p	O
)	O
(	O
p	O
representing	O
primary	O
task	O
)	O
or	O
o	O
(	O
a	O
)	O
(	O
a	O
representing	O
auxiliary	O
task	O
)	O
.	O
−	O
−	O
h	O
(	O
f	O
)	O
t	O
=	O
BiLST	O
M	O
(	O
f	O
)	O
(	O
e	O
t	O
,	O
h	O
(	O
f	O
)	O
t−1	O
)	O
(	O
2	O
)	O
−	O
−	O
h	O
(	O
b	O
)	O
t	O
=	O
BiLST	O
M	O
(	O
b	O
)	O
(	O
e	O
t	O
,	O
h	O
(	O
b	O
)	O
t+1	O
)	O
(	O
3	O
)	O
h	O
t	O
=	O
[	O
−	O
−	O
h	O
(	O
f	O
)	O
t	O
,	O
−−	O
h	O
(	O
b	O
)	O
T	O
−t	O
]	O
This	O
indicates	O
that	O
the	O
potential	O
upper	O
limit	O
of	O
performance	O
on	O
this	O
task	O
is	O
quite	O
high	O
,	O
since	O
there	O
exists	O
a	O
near	O
-	O
perfect	O
ranking	O
of	O
tokens	O
in	O
the	O
TEST	O
set	O
based	O
only	O
on	O
predictions	O
from	O
these	O
15	O
diverse	O
participating	O
teams	O
.	O
The	O
stacking	O
classifier	O
produces	O
significantly	O
better	O
rankings	O
than	O
any	O
of	O
the	O
constituent	O
systems	O
alone	O
,	O
while	O
the	O
average	O
(	O
over	O
all	O
teams	O
)	O
ranked	O
between	O
the	O
3rd	O
and	O
4th	O
best	O
system	O
in	O
all	O
three	O
tracks	O
.	O
Inspection	O
of	O
stacking	O
model	O
weights	O
revealed	O
that	O
it	O
largely	O
learned	O
to	O
trust	O
the	O
topperforming	O
systems	O
,	O
so	O
we	O
also	O
tried	O
simply	O
averaging	O
the	O
top	O
3	O
systems	O
for	O
each	O
track	O
,	O
and	O
this	O
method	O
was	O
statistically	O
tied	O
with	O
stacking	O
for	O
the	O
English	O
and	O
French	O
tracks	O
(	O
p	O
=	O
0.002	O
for	O
Spanish	O
)	O
.	O
Interestingly	O
,	O
the	O
highest	O
-	O
weighted	O
team	O
in	O
each	O
track	O
's	O
stacking	O
model	O
was	O
singsound	O
(	O
+2.417	O
on	O
average	O
across	O
the	O
three	O
models	O
)	O
,	O
followed	O
teams	O
and	O
learning	O
algorithms	O
.	O
It	O
would	O
be	O
interesting	O
to	O
revisit	O
these	O
ideas	O
using	O
a	O
more	O
diverse	O
and	O
longitudinal	O
data	O
set	O
in	O
the	O
future	O
.	O
U	O
F	O
l	O
s	O
e	O
R	O
i	O
w	O
k	O
f	O
Y	O
d	O
6	O
h	O
5	O
j	O
j	O
a	O
e	O
L	O
c	O
e	O
c	O
s	O
3	O
P	O
n	O
p	O
C	O
w	O
r	O
j	O
D	O
u	O
a	O
2	O
N	O
L	O
9	O
+	O
W	O
L	O
G	O
c	O
2	O
u	O
n	O
e	O
e	O
J	O
u	O
5	O
p	O
z	O
G	O
9	O
m	O
+	O
2	O
M	O
P	O
/	O
L	O
+	O
h	O
V	O
l	O
1	O
/	O
F	O
M	O
6	O
r	O
I	O
i	O
1	O
G	O
L	O
1	O
U	O
V	O
Y	O
p	O
R	O
g	O
V	O
b	O
7	O
M	O
x	O
S	O
a	O
V	O
C	O
Q	O
m	O
j	O
r	O
g	O
w	O
k	O
g	O
3	O
K	O
x	O
N	O
j	O
b	O
r	O
g	O
g	O
1	O
4	O
z	O
v	O
=	O
0	O
d	O
and	O
use	O
the	O
residual	O
connections	O
to	O
set	O
p	O
(	O
1	O
)	O
t	O
=	O
y	O
t	O
.	O
At	O
the	O
t	O
-	O
th	O
step	O
in	O
the	O
decoder	O
-	O
encoder	O
attention	O
block	O
of	O
layer	O
1	O
we	O
have	O
where	O
(	O
α	O
t	O
,	O
k	O
ē	O
t	O
=	O
hardmax	O
(	O
0	O
,	O
.	O
.	O
.	O
,	O
0	O
)	O
where	O
In	O
Lemma	O
D.2	O
we	O
construct	O
feed	O
-	O
forward	O
network	O
Layer	O
2	O
.	O
In	O
the	O
first	O
block	O
of	O
layer	O
2	O
,	O
we	O
set	O
the	O
value	O
transformation	O
function	O
to	O
identically	O
zero	O
similar	O
to	O
Lemma	O
C.3	O
,	O
i.e.	O
V	O
(	O
2	O
)	O
(	O
)	O
=	O
0	O
which	O
leads	O
to	O
the	O
output	O
of	O
Att	O
(	O
)	O
to	O
be	O
0	O
and	O
then	O
using	O
the	O
residual	O
connection	O
we	O
get	O
p	O
In	O
the	O
final	O
block	O
of	O
the	O
decoder	O
in	O
the	O
second	O
layer	O
,	O
the	O
computation	O
for	O
RNN	O
takes	O
place	O
.	O
To	O
further	O
verify	O
that	O
every	O
mono	O
-	O
lingual	O
RE	B-TaskName
models	O
can	O
benefit	O
from	O
our	O
proposed	O
framework	O
,	O
which	O
explicitly	O
consider	O
language	O
-	O
consistent	O
relation	O
patterns	O
,	O
we	O
train	O
models	O
with	O
multi	O
-	O
lingual	O
data	O
and	O
evaluate	O
the	O
performance	O
of	O
these	O
models	O
in	O
the	O
mono	O
-	O
lingual	O
RE	B-TaskName
scenario	O
.	O
To	O
show	O
the	O
results	O
clearly	O
,	O
we	O
report	O
the	O
precision	O
-	O
recall	O
curves	O
in	O
Figure	O
3	O
and	O
the	O
AUC	O
results	O
in	O
Table	O
4	O
.	O
From	O
the	O
results	O
,	O
we	O
can	O
observe	O
that	O
:	O
(	O
1	O
)	O
As	O
compared	O
with	O
the	O
models	O
directly	O
learned	O
with	O
the	O
mono	O
-	O
lingual	O
data	O
,	O
the	O
models	O
exploiting	O
the	O
multi	O
-	O
lingual	O
information	O
perform	O
better	O
in	O
the	O
mono	O
-	O
lingual	O
scenario	O
.	O
This	O
demonstrates	O
that	O
there	O
is	O
latent	O
consistency	O
among	O
languages	O
,	O
and	O
grasping	O
this	O
consistency	O
from	O
multi	O
-	O
lingual	O
data	O
can	O
provide	O
additional	O
information	O
for	O
models	O
in	O
each	O
language	O
to	O
enhance	O
their	O
results	O
in	O
the	O
mono	O
-	O
lingual	O
scenario	O
.	O
(	O
2	O
)	O
Our	O
proposed	O
models	O
achieve	O
the	O
best	O
precision	O
over	O
the	O
entire	O
range	O
of	O
recall	O
and	O
also	O
significantly	O
improve	O
the	O
AUC	O
results	O
as	O
compared	O
with	O
both	O
MNRE	B-TaskName
and	O
mono	B-TaskName
-	I-TaskName
lingual	I-TaskName
RE	I-TaskName
models	O
.	O
It	O
indicates	O
that	O
due	O
to	O
the	O
consistent	O
semantic	O
space	O
in	O
our	O
framework	O
,	O
language	O
-	O
consistent	O
information	O
lying	O
in	O
the	O
multi	O
-	O
lingual	O
data	O
is	O
better	O
mined	O
and	O
serve	O
the	O
mono	O
-	O
lingual	O
scenario	O
.	O
Some	O
statistics	O
for	O
the	O
texts	O
of	O
the	O
two	O
datasets	O
have	O
been	O
extracted	O
with	O
the	O
TEXTSTAT	O
Python	O
package	O
and	O
reported	O
reported	O
in	O
Table	O
A	O
:	O
we	O
extracted	O
the	O
counts	O
of	O
syllables	O
,	O
lexicon	O
(	O
how	O
many	O
different	O
word	O
types	O
are	O
being	O
used	O
)	O
,	O
sentences	O
and	O
characters	O
.	O
Difficult	O
words	O
refers	O
to	O
the	O
number	O
of	O
polysyllabic	O
words	O
with	O
Syllable	O
Count	O
>	O
2	O
that	O
are	O
not	O
included	O
in	O
the	O
list	O
of	O
words	O
of	O
common	O
usage	O
in	O
English	O
.	O
Table	O
5	O
is	O
a	O
summary	O
of	O
the	O
information	O
about	O
the	O
version	O
of	O
all	O
Transformer	O
-	O
based	O
models	O
used	O
and	O
their	O
pretraining	O
methods	O
.	O
D	O
Detailed	O
metrics	O
of	O
all	O
the	O
models	O
(	O
Weissenbacher	O
et	O
al	O
,	O
2019	O
)	O
and	O
take	O
into	O
account	O
"	O
partial"matches	O
,	O
in	O
which	O
it	O
is	O
sufficient	O
for	O
a	O
system	O
prediction	O
to	O
partially	O
overlap	O
with	O
the	O
gold	O
annotation	O
to	O
be	O
considered	O
as	O
a	O
true	O
match	O
.	O
Then	O
,	O
a	O
response	O
sentence	O
is	O
generated	O
by	O
replacing	O
{	O
Object	O
-	O
Name	O
}	O
with	O
the	O
value	O
'	O
pasta	O
'	O
.	O
Table	O
4	O
presents	O
the	O
sequence	O
of	O
five	O
context	O
utterances	O
and	O
the	O
interviewer	O
's	O
utterance	O
which	O
follows	O
the	O
context	O
.	O
"	O
Human	O
"	O
is	O
the	O
real	O
interviewer	O
utterance	O
(	O
ground	O
truth	O
)	O
.	O
"	O
Retrieval	O
,	O
"	O
"	O
Text	O
Generation	O
,	O
"	O
and	O
"	O
Proposed	O
"	O
are	O
the	O
outputs	O
by	O
the	O
methods	O
examined	O
in	O
our	O
experiment	O
.	O
In	O
Dialogue	O
-	O
1	O
in	O
Table	O
4	O
,	O
the	O
interviewer	O
utterance	O
generated	O
by	O
the	O
retrieval	O
model	O
asks	O
whether	O
the	O
user	O
eats	O
vegetables	O
.	O
For	O
example	O
,	O
in	O
Arabic	O
,	O
the	O
distributions	O
of	O
predicted	O
tags	O
with	O
respect	O
to	O
case	O
,	O
possession	O
,	O
part	O
-	O
of	O
-	O
speech	O
,	O
and	O
several	O
other	O
classes	O
differ	O
significantly	O
from	O
the	O
original	O
training	O
data	O
.	O
Such	O
difference	O
suggests	O
that	O
either	O
the	O
words	O
in	O
the	O
unlabeled	O
Wiki	O
Data	O
have	O
very	O
different	O
characteristics	O
than	O
our	O
training	O
set	O
,	O
or	O
our	O
tag	O
classifier	O
is	O
not	O
functioning	O
properly	O
to	O
identify	O
the	O
tags	O
.	O
Either	O
case	O
would	O
be	O
detrimental	O
to	O
semi	O
-	O
supervised	O
learning	O
.	O
The	O
problem	O
is	O
even	O
more	O
stark	O
for	O
Persian	O
:	O
in	O
Persian	O
the	O
only	O
labeled	O
words	O
in	O
the	O
training	O
data	O
are	O
verbs	O
,	O
so	O
all	O
nonverb	O
words	O
in	O
the	O
Wiki	O
Data	O
will	O
receive	O
an	O
incorrect	O
analysis	O
,	O
which	O
is	O
obviously	O
not	O
conducive	O
to	O
learning	O
anything	O
useful	O
.	O
As	O
a	O
recommendation	O
for	O
the	O
future	O
,	O
when	O
performing	O
semi	O
-	O
supervised	O
learning	O
for	O
morphology	O
where	O
the	O
labeled	O
data	O
only	O
represents	O
a	O
subset	O
of	O
the	O
phenomena	O
in	O
the	O
language	O
,	O
it	O
is	O
likely	O
necessary	O
to	O
first	O
identify	O
which	O
of	O
the	O
available	O
unlabeled	O
data	O
is	O
appropriate	O
for	O
semi	O
-	O
supervised	O
learning	O
before	O
applying	O
such	O
methods	O
.	O
To	O
achieve	O
this	O
,	O
during	O
training	O
,	O
we	O
manually	O
append	O
two	O
consecutive	O
[	O
eos	O
]	O
tokens	O
to	O
the	O
end	O
of	O
the	O
target	O
sequence	O
,	O
as	O
shown	O
in	O
the	O
top	O
left	O
part	O
of	O
Figure	O
2	O
.	O
In	O
this	O
way	O
,	O
the	O
model	O
can	O
learn	O
a	O
deterministic	O
transition	O
behaviour	O
between	O
two	O
[	O
eos	O
]	O
states	O
,	O
meaning	O
that	O
t	O
(	O
[	O
eos	O
]	O
,	O
[	O
eos	O
]	O
)	O
=	O
max	O
v	O
V	O
t	O
(	O
[	O
eos	O
]	O
,	O
v	O
)	O
.	O
This	O
is	O
because	O
,	O
during	O
training	O
,	O
the	O
model	O
never	O
sees	O
a	O
transition	O
(	O
[	O
eos	O
]	O
,	O
v	O
)	O
,	O
where	O
v	O
=	O
[	O
eos	O
]	O
.	O
During	O
inference	O
,	O
the	O
resultỸ	O
is	O
acquired	O
as	O
Y	O
=	O
arg	O
max	O
Y	O
S	O
(	O
X	O
,	O
Y	O
)	O
,	O
where	O
the	O
CRF	O
scoring	O
function	O
S	O
(	O
X	O
,	O
Y	O
)	O
in	O
Equation	O
(	O
8	O
)	O
can	O
be	O
decomposed	O
as	O
:	O
S	O
(	O
X	O
,	O
Y	O
)	O
The	O
specification	O
of	O
each	O
task	O
is	O
shown	O
in	O
Table	O
1	O
.	O
We	O
covered	O
news	O
and	O
review	O
texts	O
that	O
are	O
similar	O
to	O
the	O
pretraining	O
corpus	O
of	O
RoBERTa	B-MethodName
as	O
well	O
as	O
scientific	O
domains	O
in	O
which	O
text	O
corpora	O
can	O
have	O
largely	O
different	O
distributions	O
from	O
those	O
of	O
RoBERTa	B-MethodName
.	O
Furthermore	O
,	O
the	O
pretraining	O
corpora	O
of	O
the	O
target	O
tasks	O
include	O
both	O
large	O
and	O
small	O
cases	O
to	O
determine	O
whether	O
the	O
adapter	O
-	O
based	O
approach	O
can	O
be	O
applicable	O
in	O
both	O
low	O
and	O
high	O
-	O
resource	O
settings	O
.	O
1	O
https://github.com/Adapter	O
-	O
Hub/	O
adapter	O
-	O
transformers	O
2	O
Downloadble	O
link	O
for	O
task	O
dataset	O
:	O
https://github	O
.	O
com	O
/	O
allenai	O
/	O
dont	O
-	O
stop	O
-	O
pretraining	O
Our	O
implementation	O
is	O
based	O
on	O
HuggingFace	O
since	O
we	O
found	O
AllenNLP	O
(	O
Gardner	O
et	O
al	O
,	O
2018	O
)	O
used	O
in	O
Gururangan	O
et	O
al	O
,	O
2020	O
is	O
incompatible	O
with	O
adapter	O
-	O
transformer	O
(	O
Pfeiffer	O
et	O
al	O
,	O
2020b	O
)	O
.	O
al	O
,	O
2013a	O
,	O
b	O
)	O
to	O
further	O
capture	O
semantically	O
similar	O
words	O
to	O
the	O
ones	O
belonging	O
to	O
each	O
label	O
dictionary	O
.	O
We	O
first	O
proceed	O
with	O
pre	O
-	O
trained	O
models	O
which	O
enable	O
to	O
identify	O
semantically	O
similar	O
words	O
used	O
in	O
the	O
general	O
domain	O
.	O
In	O
our	O
case	O
,	O
we	O
used	O
Glove	B-MethodName
1	I-MethodName
(	O
Pennington	O
et	O
al	O
,	O
2014	O
)	O
,	O
The	O
model	O
is	O
pre	O
-	O
trained	O
on	O
a	O
corpus	O
using	O
Wikipedia2014	B-DatasetName
and	O
Gigaword5	B-DatasetName
,	O
with	O
a	O
330	O
vocabulary	O
of	O
the	O
top	O
400	O
,	O
000	O
most	O
frequent	O
words	O
and	O
a	O
context	O
window	O
size	O
of	O
10	O
.	O
Furthermore	O
,	O
we	O
also	O
seek	O
to	O
obtain	O
similar	O
words	O
as	O
used	O
in	O
the	O
specific	O
domain	O
of	O
the	O
corpus	O
.	O
W	O
illiam	O
Shockley	O
are	O
its	O
auxiliary	O
descriptions	O
.	O
Actually	O
,	O
in	O
YAGO	B-MethodName
(	O
Suchanek	O
et	O
al	O
,	O
2007	O
)	O
and	O
Wikidata	B-MethodName
(	O
Vrandečić	O
and	O
Krötzsch	O
,	O
2014	O
)	O
,	O
a	O
primary	O
triple	O
is	O
identified	O
for	O
each	O
n	O
-	O
ary	O
fact	O
.	O
The	O
above	O
5	O
-	O
ary	O
fact	O
is	O
a	O
relatively	O
complete	O
example	O
.	O
In	O
the	O
real	O
-	O
world	O
scenario	O
,	O
many	O
n	O
-	O
ary	O
facts	O
appear	O
as	O
only	O
partial	O
ones	O
,	O
each	O
consisting	O
of	O
a	O
primary	O
triple	O
and	O
a	O
subset	O
of	O
its	O
auxiliary	O
description	O
(	O
s	O
)	O
,	O
due	O
to	O
incomplete	O
knowledge	O
acquisition	O
.	O
For	O
example	O
,	O
(	O
John	O
Bardeen	O
,	O
awardreceived	O
,	O
N	O
obel	O
P	O
rize	O
in	O
P	O
hysics	O
)	O
with	O
pointin	O
-	O
time	O
:	O
1956	O
and	O
it	O
with	O
{	O
together	O
-	O
with	O
:	O
W	O
alter	O
Houser	O
Brattain	O
,	O
together	O
-	O
with	O
:	O
W	O
illiam	O
Shockley	O
}	O
are	O
two	O
typical	O
partial	O
facts	O
corresponding	O
to	O
the	O
above	O
5	O
-	O
ary	O
fact	O
.	O
AE	B-MethodName
-	I-MethodName
LSTM	I-MethodName
first	O
models	O
the	O
words	O
in	O
sentence	O
via	O
LSTM	O
network	O
and	O
concatenate	O
the	O
aspect	O
embedding	O
to	O
the	O
hidden	O
contextual	O
representation	O
for	O
calculating	O
the	O
attention	O
weights	O
,	O
which	O
are	O
employed	O
to	O
produce	O
the	O
final	O
representation	O
for	O
the	O
input	O
sentence	O
to	O
judge	O
the	O
sentiment	O
polarity	O
.	O
ATAE	B-MethodName
-	I-MethodName
LSTM	I-MethodName
:	I-MethodName
ATAE	I-MethodName
-	I-MethodName
LSTM	I-MethodName
extended	B-MethodName
AE	I-MethodName
-	I-MethodName
LSTM	I-MethodName
by	O
appending	O
the	O
aspect	O
embedding	O
to	O
each	O
word	O
embedding	O
so	O
as	O
to	O
represent	O
the	O
input	O
sentence	O
,	O
which	O
highlights	O
the	O
role	O
of	O
aspect	O
embedding	O
.	O
The	O
other	O
design	O
of	O
ATAE	B-MethodName
-	I-MethodName
LSTM	I-MethodName
is	O
the	O
same	O
as	O
AE	B-MethodName
-	I-MethodName
LSTM	I-MethodName
.	O
IAN	B-MethodName
:	I-MethodName
IAN	I-MethodName
considers	O
the	O
separate	O
modeling	O
of	O
aspect	O
terms	O
and	O
sentences	O
respectively	O
.	O
For	O
the	O
En	B-TaskName
De	I-TaskName
task	O
,	O
we	O
employ	O
the	O
popular	O
WMT14	B-DatasetName
dataset	O
,	O
which	O
consists	O
of	O
approximately	O
4.5	O
M	O
sentence	O
pairs	O
for	O
training	O
.	O
We	O
select	O
newstest2013	B-DatasetName
as	O
the	O
validation	O
set	O
and	O
newstest2014	B-DatasetName
as	O
the	O
test	O
set	O
.	O
All	O
sentences	O
had	O
been	O
jointly	O
byte	O
-	O
pair	O
-	O
encoded	O
with	O
32	O
K	O
merge	O
operations	O
,	O
which	O
results	O
in	O
a	O
shared	O
source	O
-	O
target	O
vocabulary	O
of	O
about	O
37	O
K	O
tokens	O
.	O
For	O
the	O
En	B-TaskName
Fr	I-TaskName
task	O
,	O
we	O
use	O
the	O
significantly	O
larger	B-DatasetName
WMT14	I-DatasetName
dataset	O
consisting	O
of	O
36	O
M	O
sentence	O
pairs	O
.	O
The	O
combination	O
of	O
{	O
newstest2012	B-DatasetName
,	I-DatasetName
2013	I-DatasetName
}	O
was	O
used	O
for	O
model	O
selection	O
and	O
the	O
experimental	O
results	O
were	O
reported	O
on	O
newstest2014	B-DatasetName
.	O
To	O
extend	O
the	O
single	O
-	O
dimensional	O
style	O
transfer	O
setup	O
above	O
to	O
multi	O
-	O
dimensional	O
setting	O
,	O
we	O
use	O
language	O
models	O
as	O
discriminators	O
to	O
provide	O
the	O
feedback	O
to	O
the	O
model	O
for	O
partially	O
annotated	O
nature	O
of	O
input	O
data	O
.	O
As	O
opposed	O
to	O
a	O
classifier	O
-	O
based	O
discriminator	O
,	O
the	O
language	O
model	O
as	O
discriminator	O
takes	O
into	O
account	O
the	O
wider	O
language	O
distribution	O
of	O
the	O
target	O
style	O
.	O
Additionally	O
,	O
such	O
a	O
setup	O
allows	O
us	O
to	O
use	O
only	O
the	O
target	O
style	O
corpus	O
for	O
training	O
the	O
transfer	O
model	O
,	O
whereas	O
the	O
classifier	O
would	O
require	O
both	O
source	O
and	O
target	O
style	O
corpus	O
to	O
distinguish	O
between	O
a	O
sentence	O
as	O
being	O
from	O
one	O
style	O
or	O
another	O
.	O
Inspired	O
by	O
Yang	O
et	O
al	O
(	O
2018	O
)	O
,	O
we	O
fine	O
-	O
tune	O
a	O
language	O
model	O
on	O
the	O
target	O
style	O
s	O
i	O
,	O
so	O
that	O
the	O
language	O
model	O
is	O
equipped	O
with	O
language	O
distribution	O
of	O
target	O
domain	O
data	O
.	O
This	O
entails	O
generating	O
the	O
probability	O
of	O
next	O
token	O
,	O
given	O
the	O
previous	O
tokens	O
-	O
also	O
known	O
as	O
Causal	B-TaskName
Language	I-TaskName
Modeling	I-TaskName
objective	O
(	O
Conneau	O
and	O
Lample	O
,	O
2019	O
)	O
.	O
By	O
using	O
principled	O
statistical	O
techniques	O
and	O
considering	O
evidence	O
at	O
a	O
larger	O
scale	O
,	O
we	O
offer	O
a	O
more	O
robust	O
approach	O
to	O
compositor	O
identification	O
than	O
has	O
previously	O
been	O
possible	O
.	O
The	O
fact	O
that	O
our	O
system	O
works	O
well	O
on	O
OCR	O
texts	O
means	O
that	O
we	O
are	O
not	O
restricted	O
to	O
only	O
those	O
documents	O
for	O
which	O
we	O
have	O
manually	O
produced	O
transcriptions	O
,	O
opening	O
up	O
the	O
possibility	O
for	O
bibliographic	O
study	O
on	O
a	O
much	O
larger	O
class	O
of	O
texts	O
.	O
Though	O
we	O
are	O
unable	O
to	O
incorporate	O
the	O
kinds	O
of	O
world	O
knowledge	O
used	O
by	O
bibliographers	O
,	O
our	O
ability	O
to	O
include	O
more	O
information	O
and	O
more	O
finegrained	O
information	O
allows	O
us	O
to	O
recreate	O
their	O
results	O
.	O
Having	O
validated	O
these	O
techniques	O
on	O
the	O
First	B-DatasetName
Folio	I-DatasetName
,	O
where	O
historical	O
claims	O
are	O
well	O
established	O
,	O
we	O
hope	O
future	O
work	O
can	O
extend	O
these	O
methods	O
and	O
their	O
application	O
.	O
We	O
thank	O
the	O
three	O
anonymous	O
reviewers	O
for	O
their	O
valuable	O
feedback	O
.	O
The	O
average	O
provides	O
an	O
estimate	O
of	O
the	O
typical	O
memory	O
load	O
throughout	O
a	O
sentence	O
,	O
while	O
the	O
(	O
absolute	O
)	O
embedding	O
difference	O
is	O
a	O
measure	O
of	O
how	O
many	O
times	O
a	O
reader	O
needs	O
to	O
push	O
or	O
pop	O
a	O
connected	O
component	O
to	O
or	O
from	O
their	O
memory	O
store	O
.	O
These	O
features	O
comprise	O
the	O
EMBEDDING	B-MethodName
model	O
.	O
To	O
extract	O
the	O
remaining	O
features	O
,	O
we	O
first	O
ran	O
the	O
Stanford	O
dependency	O
parser	O
on	O
both	O
corpora	O
.	O
The	O
program	O
icy	O
-	O
parses	O
uses	O
part	O
-	O
of	O
-	O
speech	O
tags	O
and	O
head	O
-	O
dependent	O
relations	O
to	O
determine	O
the	O
total	O
,	O
average	O
,	O
and	O
maximum	O
integration	O
cost	O
across	O
a	O
sentence	O
.	O
Here	O
average	O
integration	O
cost	O
functions	O
as	O
another	O
kind	O
of	O
memory	O
load	O
estimate	O
while	O
the	O
maximum	O
value	O
models	O
the	O
most	O
-	O
Rank	O
Sentence	O
2	O
Gingerbread	O
was	O
brought	O
to	O
Europe	O
in	O
992	O
by	O
the	O
Armenian	O
monk	O
Gregory	O
of	O
Nicopolis	O
-	O
LRB	O
-	O
Gregory	O
Makar	O
-	O
RRB	O
-	O
-	O
LRB	O
-	O
Grégoire	O
de	O
Nicopolis	O
-	O
RRB	O
-	O
.	O
Therefore	O
,	O
we	O
design	O
such	O
a	O
reward	O
to	O
train	O
the	O
personas	O
generator	O
to	O
learn	O
to	O
generate	O
a	O
set	O
of	O
personas	O
that	O
is	O
more	O
helpful	O
for	O
the	O
downstream	O
dialogue	O
response	O
generation	O
.	O
Our	O
second	O
motivation	O
is	O
that	O
the	O
dialogue	O
response	O
generator	O
has	O
not	O
been	O
exposed	O
to	O
the	O
generated	O
partner	O
personas	O
.	O
We	O
would	O
like	O
to	O
fine	O
-	O
tune	O
the	O
response	O
generator	O
to	O
mitigate	O
the	O
potential	O
traininginference	O
discrepancy	O
.	O
Experimental	O
results	O
indicate	O
that	O
our	O
design	O
empirically	O
works	O
well	O
.	O
The	O
previous	O
work	O
from	O
Cai	O
et	O
al	O
(	O
2019a	O
)	O
employed	O
critic	O
network	O
for	O
RL	O
loss	O
backpropagation	O
.	O
As	O
described	O
above	O
,	O
we	O
compute	O
the	O
KL	B-MetricName
divergence	I-MetricName
on	O
a	O
per	O
-	O
item	O
basis	O
,	O
and	O
report	O
the	O
mean	O
over	O
all	O
items	O
in	O
the	O
test	O
set	O
.	O
Table	O
1	O
shows	O
the	O
performance	O
of	O
our	O
trained	O
model	O
on	O
unseen	O
test	O
data	O
.	O
The	O
full	O
test	O
data	O
consists	O
of	O
4.6	O
million	O
phrase	O
pairs	O
,	O
all	O
of	O
which	O
contain	O
at	O
least	O
one	O
phrase	O
that	O
was	O
not	O
observed	O
in	O
either	O
the	O
training	O
or	O
development	O
data	O
.	O
Our	O
model	O
does	O
reasonably	O
well	O
at	O
predicting	O
these	O
conditional	O
probabilities	O
,	O
reaching	O
a	O
correlation	B-MetricName
of	O
r	B-MetricName
=	O
0.949	B-MetricValue
with	O
P	O
(	O
x	O
|	O
y	O
)	O
on	O
the	O
complete	O
test	O
data	O
.	O
p	O
(	O
s	O
|	O
t	O
)	O
p	O
(	O
t	O
)	O
For	O
instance	O
,	O
(	O
Wubben	O
et	O
al	O
,	O
2010	O
)	O
constructed	O
a	O
large	O
-	O
scale	O
parallel	O
corpus	O
containing	O
paraphrases	O
collected	O
from	O
the	O
headlines	O
that	O
appeared	O
in	O
Google	O
News	O
.	O
Then	O
they	O
trained	O
a	O
Phrase	B-MethodName
-	I-MethodName
Based	I-MethodName
Machine	I-MethodName
Translation	I-MethodName
model	O
(	O
PBMT	O
)	O
(	O
Koehn	O
et	O
al	O
,	O
2007	O
)	O
on	O
their	O
parallel	O
corpus	O
using	O
the	O
MOSES	O
package	O
.	O
The	O
trained	O
PBMT	B-MethodName
is	O
finally	O
used	O
to	O
generate	O
paraphrases	O
.	O
Early	O
works	O
on	O
paraphrasing	O
mainly	O
focused	O
on	O
template	O
-	O
based	O
or	O
statistical	O
machine	O
translation	O
approaches	O
.	O
We	O
show	O
here	O
the	O
effect	O
of	O
the	O
pattern	O
on	O
the	O
head	O
number	O
reduction	O
:	O
using	O
block	B-HyperparameterValue
instead	O
of	B-HyperparameterValue
row	I-HyperparameterValue
/	I-HyperparameterValue
column	I-HyperparameterValue
pruning	B-HyperparameterName
leads	O
to	O
a	O
much	O
larger	O
number	O
of	O
pruned	O
heads	O
while	O
improving	O
accuracy	B-MetricName
,	O
here	O
on	O
the	O
SST	B-TaskName
-	I-TaskName
2	I-TaskName
task	O
.	O
We	O
are	O
using	O
Block	B-HyperparameterValue
Movement	I-HyperparameterValue
pruning	B-HyperparameterName
for	O
each	O
model	O
,	O
with	O
different	O
block	O
patterns	O
,	O
pruning	O
only	O
the	O
attention	O
layers	O
.	O
Compression	B-MetricName
measures	O
the	O
reduction	O
of	O
the	O
number	O
of	O
non	O
-	O
zero	O
parameters	O
in	O
attention	O
linear	O
layers	O
,	O
whereas	O
head	B-MetricName
compression	I-MetricName
measures	O
the	O
reduction	O
of	O
the	O
number	O
of	O
complete	O
non	O
-	O
zero	O
heads	O
.	O
We	O
select	O
speed	B-MetricName
as	O
our	O
main	O
metric	O
to	O
compare	O
with	O
other	O
techniques	O
,	O
as	O
it	O
is	O
the	O
major	O
practical	O
measure	O
of	O
inference	O
efficiency	O
.	O
On	O
this	O
metric	O
,	O
we	O
decided	O
to	O
compare	O
our	O
models	O
to	O
the	O
best	O
models	O
available	O
i.e.	O
the	O
distilled	O
models	O
(	O
MobileBERT	B-MethodName
,	O
TinyBERT	B-MethodName
)	O
,	O
even	O
though	O
the	O
method	O
is	O
different	O
,	O
as	O
they	O
are	O
the	O
strongest	O
"	O
speed	B-MetricName
/	I-MetricName
accuracy	I-MetricName
"	O
baseline	O
available	O
.	O
In	O
many	O
areas	O
of	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
it	O
is	O
important	O
that	O
systems	O
are	O
able	O
to	O
correctly	O
analyze	O
and	O
generate	O
different	O
morphological	O
forms	O
,	O
including	O
previously	O
unseen	O
forms	O
.	O
The	O
ability	O
to	O
accurately	O
analyze	O
and	O
generate	O
morphological	O
forms	O
is	O
crucial	O
to	O
creating	O
applications	O
such	O
as	O
machine	O
translation	O
(	O
Chahuneau	O
et	O
al	O
,	O
2013	O
)	O
and	O
information	O
retrieval	O
(	O
Darwish	O
and	O
Oard	O
,	O
2007	O
)	O
.	O
Accordingly	O
,	O
learning	O
morphological	O
reinflection	O
patterns	O
from	O
labeled	O
data	O
is	O
an	O
important	O
challenge	O
.	O
The	O
Universal	O
Morphological	O
Reinflection	O
task	O
at	O
SIGMORPHON	O
2017	O
(	O
Cotterell	O
and	O
Schütze	O
,	O
2017	O
)	O
is	O
an	O
evaluation	O
campaign	O
aimed	O
at	O
systems	O
that	O
tackle	O
the	O
task	O
of	O
morphological	O
inflection	O
.	O
It	O
extends	O
the	O
SIGMORPHON	O
2016	O
Morphological	O
Reinflection	O
by	O
conducting	O
tasks	O
in	O
52	O
languages	O
instead	O
of	O
10	O
Cotterell	O
et	O
al	O
(	O
2016	O
)	O
.	O
Mahabadi	O
et	O
al	O
(	O
2021	O
)	O
.	O
Related	O
to	O
our	O
work	O
are	O
also	O
other	O
few	O
-	O
shot	O
adaptation	O
techniques	O
like	O
PET	B-MethodName
(	O
Schick	O
and	O
Schütze	O
,	O
2021	O
)	O
.	O
Moreover	O
,	O
adapter	O
layers	O
have	O
also	O
been	O
explored	O
in	O
the	O
computer	O
vision	O
domain	O
(	O
Rebuffi	O
et	O
al	O
,	O
2017	O
;	O
de	O
Vries	O
et	O
al	O
,	O
2017	O
)	O
.	O
To	O
evaluate	O
low	O
-	O
resource	O
prompt	B-TaskName
tuning	I-TaskName
,	O
we	O
compare	O
against	O
fine	O
-	O
tuned	O
variants	O
of	O
the	O
same	O
model	O
on	O
two	O
semantic	O
parsing	O
datasets	O
with	O
canonical	O
representations	O
available	O
.	O
We	O
compare	O
both	O
large	O
and	O
small	O
variants	O
of	O
the	O
T5	B-MethodName
architecture	O
on	O
these	O
datasets	O
and	O
experiment	O
with	O
various	O
canonicalized	O
representations	O
.	O
In	O
this	O
section	O
,	O
we	O
motivate	O
and	O
introduce	O
of	O
multimodal	O
information	O
we	O
will	O
use	O
in	O
our	O
experiments	O
.	O
The	O
Lancaster	O
Sensorimotor	O
Norms	O
The	O
Lancaster	B-DatasetName
Sensorimotor	I-DatasetName
norms	I-DatasetName
(	O
Lynott	O
et	O
al	O
,	O
2019	O
)	O
provide	O
ratings	O
(	O
means	O
and	O
standard	O
deviations	O
)	O
for	O
40	O
,	O
000	O
English	O
words	O
along	O
dimensions	O
of	O
embodiment	O
which	O
capture	O
the	O
extent	O
to	O
which	O
a	O
concept	O
is	O
experienced	O
across	O
11	O
different	O
sensory	O
modalities	O
,	O
and	O
measures	O
derived	O
from	O
those	O
categories	O
,	O
listed	O
below	O
(	O
each	O
has	O
an	O
example	O
word	O
that	O
rates	O
highly	O
for	O
that	O
modalitiy	O
)	O
:	O
Auditory	O
-	O
sound	O
;	O
ping	O
Gustatory	O
-	O
having	O
to	O
do	O
with	O
eating	O
;	O
cream	O
Haptic	O
-	O
muscle	O
movement	O
;	O
handshake	O
Interoceptive	O
-	O
having	O
to	O
do	O
with	O
affect	O
or	O
emotion	O
;	O
headache	O
Olfactory	O
-	O
smell	O
;	O
incense	O
Visual	O
-	O
visual	O
;	O
barcode	O
Foot	O
-	O
leg	O
-	O
haptics	O
for	O
foot	O
/	O
leg	O
;	O
run	O
Hand	O
-	O
arm	O
-	O
haptics	O
for	O
hand	O
/	O
arm	O
;	O
pointing	O
Head	O
-	O
having	O
to	O
do	O
with	O
the	O
head	O
;	O
eye	O
Mouth	O
-	O
haptics	O
for	O
mouth	O
;	O
kiss	O
Torso	O
-	O
haptics	O
for	O
torso	O
;	O
breath	O
Max	O
-	O
strength.perceptual	O
-	O
the	O
highest	O
rating	O
across	O
the	O
11	O
sensorimotor	O
dimensions	O
Minkowski3.perceptual	O
-	O
treating	O
the	O
11	O
modalities	O
as	O
a	O
vector	O
,	O
this	O
represents	O
the	O
distance	O
of	O
the	O
vector	O
from	O
the	O
origin	O
with	O
influence	O
of	O
weaker	O
dimensions	O
attenuated	O
Exclusivity.perceptual	O
-	O
the	O
extent	O
to	O
which	O
a	O
concept	O
(	O
out	O
of	O
the	O
11	O
)	O
which	O
is	O
experienced	O
through	O
a	O
single	O
perceptual	O
modalitiy	O
The	O
last	O
three	O
can	O
be	O
seen	O
as	O
aggregates	O
from	O
the	O
11	O
modalities	O
;	O
they	O
also	O
have	O
.action	O
values	O
representing	O
the	O
extent	O
to	O
which	O
a	O
concept	O
is	O
experienced	O
as	O
an	O
action	O
(	O
as	O
opposed	O
to	O
.perceptual	O
)	O
,	O
and	O
.sensorimotor	O
values	O
representing	O
the	O
extent	O
a	O
concept	O
is	O
experience	O
as	O
sensorimotor	O
.	O
As	O
these	O
norms	O
were	O
derived	O
from	O
surveys	O
given	O
to	O
adults	O
,	O
these	O
norms	O
represent	O
the	O
degree	O
to	O
which	O
the	O
survey	O
participants	O
assigned	O
those	O
words	O
to	O
those	O
categories	O
.	O
Though	O
this	O
does	O
not	O
represent	O
a	O
neurophysiological	O
grounding	O
of	O
words	O
to	O
those	O
modalities	O
learned	O
through	O
interaction	O
and	O
embodiment	O
,	O
this	O
serves	O
as	O
a	O
useful	O
approximation	O
.	O
-DOCSTART-	O
String	B-MethodName
Kernels	I-MethodName
(	O
Lodhi	O
et	O
al	O
,	O
2001	O
)	O
provide	O
a	O
way	O
of	O
comparing	O
two	O
documents	O
,	O
based	O
on	O
the	O
inner	O
product	O
generated	O
by	O
all	O
substrings	O
of	O
length	O
n	O
,	O
typically	O
known	O
as	O
character	O
n	O
-	O
grams	O
.	O
Being	O
relatively	O
simple	O
to	O
use	O
and	O
implement	O
,	O
this	O
technique	O
has	O
many	O
applications	O
according	O
to	O
the	O
literature	O
(	O
Cozma	O
et	O
al	O
,	O
2018	O
;	O
Giménez	O
-	O
Pérez	O
et	O
al	O
,	O
2017	O
;	O
Masala	O
et	O
al	O
,	O
2017	O
;	O
Ionescu	O
et	O
al	O
,	O
2014Popescu	O
and	O
Ionescu	O
,	O
2013	O
)	O
,	O
with	O
emphasis	O
on	O
dialect	O
identification	O
and	O
the	O
good	O
results	O
obtained	O
for	O
this	O
task	O
in	O
previous	O
VarDial	O
evaluation	O
campaigns	O
(	O
Butnaru	O
and	O
Ionescu	O
,	O
2018b	O
;	O
Ionescu	O
and	O
Butnaru	O
,	O
2017	O
;	O
.	O
Similar	O
to	O
our	O
last	O
year	O
's	O
submission	O
for	O
the	O
SMG	B-TaskName
-	I-TaskName
CH	I-TaskName
subtask	O
(	O
Gȃman	O
and	O
Ionescu	O
,	O
2020	O
)	O
,	O
we	O
employ	O
the	O
string	O
kernels	O
computed	O
by	O
the	O
efficient	O
algorithm	O
introduced	O
by	O
Popescu	O
et	O
al	O
(	O
2017	O
)	O
.	O
This	O
gives	O
us	O
a	O
dual	O
representation	O
of	O
the	O
data	O
,	O
through	O
a	O
kernel	O
matrix	O
where	O
the	O
cell	O
on	O
row	O
i	O
and	O
column	O
j	O
represents	O
the	O
similarity	O
between	O
two	O
text	O
samples	O
x	O
i	O
and	O
x	O
j	O
.	O
In	O
our	O
experiments	O
,	O
we	O
consider	O
the	O
presence	O
bits	O
string	O
kernel	O
(	O
Popescu	O
and	O
Ionescu	O
,	O
2013	O
)	O
as	O
the	O
similarity	O
function	O
.	O
For	O
two	O
strings	O
x	O
i	O
and	O
x	O
j	O
over	O
a	O
set	O
of	O
characters	O
S	O
,	O
the	O
presence	O
bits	O
string	O
kernel	O
is	O
defined	O
as	O
follows	O
:	O
where	O
n	O
is	O
the	O
length	O
of	O
n	O
-	O
grams	O
and	O
#	O
(	O
x	O
,	O
g	O
)	O
is	O
a	O
function	O
that	O
returns	O
1	O
when	O
the	O
number	O
of	O
occurrences	O
of	O
n	O
-	O
gram	O
g	O
in	O
x	O
is	O
greater	O
than	O
1	O
,	O
and	O
0	O
otherwise	O
.	O
k	O
0/1	O
(	O
x	O
i	O
,	O
x	O
j	O
)	O
=	O
g	O
S	O
n	O
#	O
(	O
x	O
i	O
,	O
g	O
)	O
#	O
(	O
x	O
j	O
,	O
g	O
)	O
,	O
(	O
1	O
)	O
The	O
resulting	O
kernel	O
matrix	O
is	O
plugged	O
into	O
a	O
ν	B-MethodName
-	I-MethodName
Support	I-MethodName
Vector	I-MethodName
Regression	I-MethodName
(	O
ν	O
-	O
SVR	O
)	O
model	O
.	O
SVR	B-MethodName
(	O
Drucker	O
et	O
al	O
,	O
1997	O
)	O
is	O
a	O
modified	O
Support	O
Vector	O
Machines	O
(	O
SVM	O
)	O
(	O
Cortes	O
and	O
Vapnik	O
,	O
1995	O
)	O
model	O
that	O
is	O
repurposed	O
for	O
regression	O
.	O
Similar	O
to	O
SVM	O
,	O
SVR	O
uses	O
the	O
notion	O
of	O
support	O
vectors	O
and	O
margin	O
in	O
order	O
to	O
find	O
an	O
optimal	O
estimator	O
.	O
However	O
,	O
instead	O
of	O
a	O
separating	O
hyperplane	O
,	O
SVR	B-MethodName
aims	O
to	O
find	O
a	O
hyperplane	O
that	O
estimates	O
the	O
data	O
points	O
(	O
support	O
vectors	O
)	O
within	O
the	O
margin	O
with	O
minimal	O
error	O
.	O
In	O
our	O
experiments	O
,	O
we	O
employ	O
an	O
equivalent	O
SVR	B-MethodName
formulation	O
known	O
as	O
ν	B-MethodName
-	I-MethodName
SVR	I-MethodName
(	O
Chang	O
and	O
Lin	O
,	O
2002	O
)	O
,	O
where	O
ν	B-HyperparameterName
is	O
the	O
configurable	O
proportion	O
of	O
support	O
vectors	O
to	O
keep	O
with	O
respect	O
to	O
the	O
number	O
of	O
samples	O
in	O
the	O
data	O
set	O
.	O
Using	O
ν	B-MethodName
-	I-MethodName
SVR	I-MethodName
,	O
the	O
optimal	O
solution	O
can	O
converge	O
to	O
a	O
sparse	O
model	O
,	O
with	O
only	O
a	O
few	O
support	O
vectors	O
.	O
This	O
is	O
especially	O
useful	O
in	O
our	O
case	O
,	O
as	O
the	O
data	O
set	O
provided	O
for	O
the	O
SMG	B-TaskName
-	I-TaskName
CH	I-TaskName
subtask	O
does	O
not	O
contain	O
too	O
many	O
samples	O
.	O
Another	O
reason	O
to	O
employ	O
ν	B-MethodName
-	I-MethodName
SVR	I-MethodName
in	O
our	O
regression	O
task	O
is	O
that	O
it	O
was	O
found	O
to	O
surpass	O
other	O
regression	O
methods	O
for	O
other	O
use	O
cases	O
,	O
such	O
as	O
complex	O
word	O
identification	O
(	O
Butnaru	O
and	O
Ionescu	O
,	O
2018a	O
)	O
.	O
We	O
model	O
question	O
difficulty	O
as	O
defined	O
in	O
the	O
oneparameter	O
IRT	B-MethodName
model	O
(	O
also	O
named	O
Rasch	O
model	O
(	O
Rasch	O
,	O
1960	O
)	O
)	O
,	O
which	O
associates	O
a	O
skill	O
level	O
θ	O
to	O
each	O
student	O
and	O
a	O
difficulty	O
level	O
b	O
to	O
each	O
question	O
.	O
For	O
a	O
given	O
question	O
j	O
,	O
its	O
latent	O
trait	O
b	O
j	O
define	O
the	O
item	O
response	O
function	O
(	O
i.r.f	O
.	O
)	O
,	O
which	O
indicates	O
the	O
probability	O
(	O
P	O
C	O
)	O
that	O
a	O
student	O
i	O
with	O
skill	O
level	O
θ	O
i	O
correctly	O
answers	O
the	O
question	O
.	O
The	O
formula	O
of	O
the	O
i.r.f	O
.	O
is	O
as	O
follows	O
:	O
According	O
to	O
the	O
intuition	O
,	O
a	O
student	O
with	O
a	O
given	O
skill	O
θ	O
i	O
has	O
a	O
lower	O
probability	O
of	O
correctly	O
answering	O
more	O
difficult	O
questions	O
.	O
Also	O
,	O
if	O
a	O
question	O
is	O
too	O
difficult	O
or	O
too	O
easy	O
(	O
i.e.	O
b	O
j	O
or	O
b	O
j	O
−	O
)	O
,	O
all	O
the	O
students	O
will	O
answer	O
in	O
the	O
same	O
way	O
(	O
i.e.	O
P	O
C	O
0	O
or	O
P	O
C	O
1	O
)	O
regardless	O
of	O
θ	O
i	O
.	O
Given	O
some	O
students	O
'	O
answers	O
to	O
a	O
set	O
of	O
questions	O
,	O
with	O
IRT	B-MethodName
it	O
is	O
possible	O
to	O
estimate	O
both	O
the	O
For	O
each	O
task	O
,	O
2	O
additional	O
downstream	O
architectures	O
are	O
created	O
by	O
modifying	O
the	O
number	O
of	O
layers	O
and	O
the	O
hidden	O
dimensions	O
compared	O
to	O
our	O
default	O
setting	O
.	O
We	O
create	O
small	O
and	O
large	O
models	O
that	O
are	O
roughly	O
the	O
half	O
and	O
twice	O
of	O
default	O
in	O
terms	O
of	O
the	O
number	O
of	O
trainable	O
parameters	O
.	O
A	O
detailed	O
comparison	O
of	O
the	O
downstream	O
architectures	O
is	O
shown	O
in	O
Table	O
5	O
.	O
The	O
results	O
are	O
shown	O
in	O
Table	O
6	O
.	O
We	O
show	O
that	O
the	O
ranking	O
of	O
the	O
upstream	O
models	O
is	O
almost	O
fixed	O
when	O
the	O
model	O
sizes	O
are	O
varied	O
.	O
As	O
expected	O
,	O
the	O
small	O
architecture	O
has	O
worse	O
perfor	O
-	O
mance	O
than	O
default	O
,	O
while	O
large	O
has	O
better	O
.	O
Moreover	O
,	O
the	O
scores	O
causing	O
the	O
change	O
in	O
ranking	O
are	O
negligible	O
,	O
e.g.	O
,	O
TERA	B-MethodName
/	I-MethodName
CPC	I-MethodName
in	O
SS	B-MetricName
and	O
wav2vec	B-MethodName
2.0	I-MethodName
Base	I-MethodName
/	O
HuBERT	B-MethodName
Base	O
in	O
OOD	B-MetricName
-	I-MetricName
ASR	I-MetricName
with	O
large	O
.	O
The	O
results	O
show	O
that	O
the	O
relative	O
performance	O
achieved	O
by	O
different	O
upstream	O
models	O
is	O
agnostic	O
to	O
the	O
downstream	O
architecture	O
,	O
confirming	O
the	O
robustness	O
of	O
the	O
framework	O
used	O
in	B-MethodName
SUPERB	I-MethodName
-	I-MethodName
SG	I-MethodName
.	O
Machine	B-TaskName
translation	I-TaskName
aims	O
at	O
translating	O
text	O
from	O
the	O
source	O
language	O
to	O
the	O
target	O
language	O
.	O
In	O
this	O
task	O
,	O
we	O
use	O
the	O
IWSLT14	B-DatasetName
German	I-DatasetName
-	I-DatasetName
to	I-DatasetName
-	I-DatasetName
English	I-DatasetName
(	O
DE	O
-	O
EN	O
)	O
dataset	O
as	O
our	O
benchmark	O
.	O
Following	O
previous	O
works	O
,	O
we	O
use	O
the	O
sequence	O
-	O
level	O
knowledge	O
distillation	O
(	O
Gu	O
et	O
al	O
,	O
2018	O
)	O
during	O
training	O
.	O
For	O
evaluation	O
,	O
we	O
report	O
results	O
in	O
BLEU	B-MetricName
scores	O
(	O
Papineni	O
et	O
al	O
,	O
2002	O
)	O
.	O
In	O
this	O
experiment	O
,	O
we	O
use	O
the	O
BERT	O
model	O
in	O
German	O
language	O
.	O
We	O
compare	O
our	O
model	O
with	O
a	O
range	O
of	O
strong	O
NAG	B-MethodName
models	O
,	O
including	O
NAG	B-MethodName
-	I-MethodName
NMT	I-MethodName
(	O
Gu	O
et	O
al	O
,	O
2018	O
)	O
,	O
ENAG	B-MethodName
-	I-MethodName
E	I-MethodName
and	O
ENAG	B-MethodName
-	I-MethodName
P	I-MethodName
(	O
Guo	O
et	O
al	O
,	O
2019	O
)	O
,	O
NAG	B-MethodName
-	I-MethodName
REG	I-MethodName
(	O
Wang	O
et	O
al	O
,	O
2019b	O
)	O
,	O
NAG	B-MethodName
-	I-MethodName
CRF	I-MethodName
and	O
BNAG	B-MethodName
-	I-MethodName
CRF	I-MethodName
.	O
For	O
each	O
NAG	B-MethodName
baseline	O
,	O
we	O
also	O
report	O
the	O
results	O
using	O
LPD	O
-	O
9	O
decoding	O
.	O
In	O
addition	O
,	O
we	O
compare	O
our	O
model	O
with	O
several	O
strong	O
autoregressive	O
models	O
,	O
including	O
LSTM	B-MethodName
-	I-MethodName
based	I-MethodName
(	O
Wu	O
et	O
al	O
,	O
2016	O
)	O
,	O
CNN	B-MethodName
-	I-MethodName
based	I-MethodName
(	O
Gehring	O
et	O
al	O
,	O
2017	O
)	O
and	O
transformer	B-MethodName
model	O
.	O
The	O
results	O
are	O
shown	O
in	O
Table	O
3	O
,	O
from	O
which	O
we	O
see	O
that	O
our	O
model	O
outperforms	O
the	O
best	B-MethodName
NAG	I-MethodName
baseline	O
(	O
with	O
LPD	O
)	O
in	O
terms	O
of	O
both	O
the	O
generation	O
quality	O
and	O
inference	B-MetricName
speedup	I-MetricName
.	O
Additionally	O
,	O
we	O
also	O
report	O
the	O
results	O
using	O
the	O
ratio	O
-	O
first	O
decoding	O
.	O
By	O
setting	O
α	B-HyperparameterName
as	O
0.8	B-HyperparameterValue
,	O
the	O
inference	B-MetricName
speedup	I-MetricName
can	O
be	O
further	O
boosted	O
to	O
13.92×	B-MetricValue
while	O
the	O
generation	O
quality	O
is	O
still	O
higher	O
than	O
the	O
best	O
NAG	B-MethodName
baseline	O
.	O
We	O
now	O
turn	O
to	O
comparing	O
with	O
purely	O
handcrafted	O
approaches	O
.	O
To	O
do	O
this	O
,	O
we	O
obtained	O
logs	O
from	O
our	O
company	O
's	O
text	O
-	O
based	O
customer	O
support	O
dialog	O
system	O
,	O
which	O
uses	O
a	O
sophisticated	O
rulebased	O
dialog	O
manager	O
.	O
Data	O
from	O
this	O
system	O
is	O
attractive	O
for	O
evaluation	O
because	O
it	O
is	O
used	O
by	O
real	O
customers	O
-	O
not	O
usability	O
subjects	O
-	O
and	O
because	O
its	O
rule	O
-	O
based	O
dialog	O
manager	O
was	O
developed	O
by	O
customer	O
support	O
professionals	O
at	O
our	O
company	O
,	O
and	O
not	O
the	O
authors	O
.	O
This	O
data	O
is	O
not	O
publicly	O
available	O
,	O
but	O
we	O
are	O
unaware	O
of	O
suitable	O
humancomputer	O
dialog	O
data	O
in	O
the	O
public	O
domain	O
which	O
uses	O
rules	O
.	O
Customers	O
start	O
using	O
the	O
dialog	O
system	O
by	O
entering	O
a	O
brief	O
description	O
of	O
their	O
problem	O
,	O
such	O
as	O
"	O
I	O
need	O
to	O
update	O
my	O
operating	O
system	O
"	O
.	O
They	O
are	O
then	O
routed	O
to	O
one	O
of	O
several	O
hundred	O
domains	O
,	O
where	O
each	O
domain	O
attempts	O
to	O
resolve	O
a	O
particular	O
problem	O
.	O
In	O
this	O
study	O
,	O
we	O
collected	O
humancomputer	O
transcripts	O
for	O
the	O
high	O
-	O
traffic	O
domains	O
"	O
reset	O
password	O
"	O
and	O
"	O
can	O
not	O
access	O
account	O
"	O
.	O
We	O
labeled	O
the	O
dialog	O
data	O
as	O
follows	O
.	O
First	O
,	O
we	O
enumerated	O
unique	O
system	O
actions	O
observed	O
in	O
the	O
data	O
.	O
Then	O
,	O
for	O
each	O
dialog	O
,	O
starting	O
from	O
the	O
beginning	O
,	O
we	O
examined	O
each	O
system	O
action	O
,	O
and	O
determined	O
whether	O
it	O
was	O
"	O
correct	O
"	O
.	O
Here	O
,	O
correct	O
means	O
that	O
it	O
was	O
the	O
most	O
appropriate	O
action	O
among	O
the	O
set	O
of	O
existing	O
system	O
actions	O
,	O
given	O
the	O
history	O
of	O
that	O
dialog	O
.	O
If	O
multiple	O
actions	O
were	O
arguably	O
appropriate	O
,	O
we	O
broke	O
ties	O
in	O
favor	O
of	O
the	O
existing	O
rule	O
-	O
based	O
dialog	O
manager	O
.	O
Example	O
dialogs	O
are	O
provided	O
in	O
the	O
Appendix	O
Sections	O
A.5	O
and	O
A.6	O
.	O
If	O
a	O
system	O
action	O
was	O
labeled	O
as	O
correct	O
,	O
we	O
left	O
it	O
as	O
-	O
is	O
and	O
continued	O
to	O
the	O
next	O
system	O
action	O
.	O
If	O
the	O
system	O
action	O
was	O
not	O
correct	O
,	O
we	O
replaced	O
it	O
with	O
the	O
correct	O
system	O
action	O
,	O
and	O
discarded	O
the	O
rest	O
of	O
the	O
dialog	O
,	O
since	O
we	O
do	O
not	O
know	O
how	O
the	O
user	O
would	O
have	O
replied	O
to	O
this	O
new	O
system	O
action	O
.	O
The	O
resulting	O
dataset	O
contained	O
a	O
mixture	O
of	O
complete	O
and	O
partial	O
dialogs	O
,	O
containing	O
only	O
correct	O
system	O
actions	O
.	O
We	O
partitioned	O
this	O
set	O
into	O
training	O
and	O
test	O
dialogs	O
.	O
Basic	O
statistics	O
of	O
the	O
data	O
are	O
shown	O
in	O
Table	O
2	O
.	O
In	O
this	O
domain	O
,	O
no	O
entities	O
were	O
relevant	O
to	O
the	O
control	O
flow	O
,	O
and	O
there	O
was	O
no	O
obvious	O
mask	O
logic	O
since	O
any	O
question	O
could	O
follow	O
any	O
question	O
.	O
Therefore	O
,	O
we	O
wrote	O
no	O
domain	O
-	O
specific	O
software	O
for	O
this	O
instance	O
of	O
the	O
HCN	B-MethodName
,	O
and	O
relied	O
purely	O
on	O
the	O
recurrent	O
neural	O
network	O
to	O
drive	O
the	O
conversation	O
.	O
The	O
architecture	O
and	O
training	O
of	O
the	O
RNN	O
was	O
the	O
same	O
as	O
in	O
Section	O
4	O
,	O
except	O
that	O
here	O
we	O
did	O
not	O
have	O
enough	O
data	O
for	O
a	O
validation	O
set	O
,	O
so	O
we	O
instead	O
trained	O
until	O
we	O
either	O
achieved	O
100	B-MetricValue
%	I-MetricValue
accuracy	B-MetricName
on	O
the	O
training	O
set	O
or	O
reached	O
200	O
epochs	O
.	O
To	O
evaluate	O
,	O
we	O
observe	O
that	O
conventional	O
measures	O
like	O
average	O
dialog	O
accuracy	O
unfairly	O
penalize	O
the	O
system	O
used	O
to	O
collect	O
the	O
dialogs	O
-	O
in	O
our	O
case	O
,	O
the	O
rule	O
-	O
based	O
system	O
.	O
If	O
the	O
system	O
used	O
for	O
collection	O
makes	O
an	O
error	O
at	O
turn	O
t	O
,	O
the	O
labeled	O
dialog	O
only	O
includes	O
the	O
sub	O
-	O
dialog	O
up	O
to	O
turn	O
t	O
,	O
and	O
the	O
system	O
being	O
evaluated	O
off	O
-	O
line	O
is	O
only	O
evaluated	O
on	O
that	O
sub	O
-	O
dialog	O
.	O
In	O
other	O
words	O
,	O
in	O
our	O
case	O
,	O
reporting	O
dialog	O
accuracy	O
would	O
favor	O
the	O
HCN	B-MethodName
because	O
it	O
would	O
be	O
evaluated	O
on	O
fewer	O
turns	O
than	O
the	O
rule	O
-	O
based	O
system	O
.	O
We	O
therefore	O
,	O
where	O
C	O
(	O
HCN	B-MethodName
-	O
win	O
)	O
is	O
the	O
number	O
of	O
test	O
dialogs	O
where	O
the	O
rule	O
-	O
based	O
approach	O
output	O
a	O
wrong	O
action	O
before	O
the	O
HCN	B-MethodName
;	O
C	O
(	O
rule	O
-	O
win	O
)	O
is	O
the	O
number	O
of	O
test	O
dialogs	O
where	O
the	O
HCN	B-MethodName
output	O
a	O
wrong	O
action	O
before	O
the	O
rulebased	O
approach	O
;	O
and	O
C	O
(	O
all	O
)	O
is	O
the	O
number	O
of	O
dialogs	O
in	O
the	O
test	O
set	O
.	O
When	O
∆P	B-MetricName
>	O
0	O
,	O
there	O
are	O
more	O
dialogs	O
in	O
which	O
HCNs	O
produce	O
longer	O
continuous	O
sequences	O
of	O
correct	O
actions	O
starting	O
from	O
the	O
beginning	O
of	O
the	O
dialog	O
.	O
We	O
run	O
all	O
experiments	O
5	O
times	O
,	O
each	O
time	O
shuffling	O
the	O
order	O
of	O
the	O
training	O
set	O
.	O
Results	O
are	O
in	O
Figure	O
3	O
.	O
HCNs	B-MethodName
exceed	O
performance	O
of	O
the	O
existing	O
rule	O
-	O
based	O
system	O
after	O
about	O
30	O
dialogs	O
.	O
In	O
these	O
domains	O
,	O
we	O
have	O
a	O
further	O
source	O
of	O
knowledge	O
:	O
the	O
rule	O
-	O
based	O
dialog	O
managers	O
themselves	O
can	O
be	O
used	O
to	O
generate	O
example	O
"	O
sunnyday	O
"	O
dialogs	O
,	O
where	O
the	O
user	O
provides	O
purely	O
expected	O
inputs	O
.	O
From	O
each	O
rule	O
-	O
based	O
controller	O
,	O
synthetic	O
dialogs	O
were	O
sampled	O
to	O
cover	O
each	O
expected	O
user	O
response	O
at	O
least	O
once	O
,	O
and	O
added	O
to	O
the	O
set	O
of	O
labeled	O
real	O
dialogs	O
.	O
This	O
resulted	O
in	O
75	O
dialogs	O
for	O
the	O
"	O
Forgot	O
password	O
"	O
domain	O
,	O
and	O
325	O
for	O
the	O
"	O
Ca	O
n't	O
access	O
account	O
"	O
domain	O
.	O
Training	O
was	O
repeated	O
as	O
described	O
above	O
.	O
Results	O
are	O
also	O
included	O
in	O
Figure	O
3	O
,	O
with	O
the	O
suffix	O
"	O
sampled	O
"	O
.	O
In	O
the	O
"	O
Ca	O
n't	O
access	O
account	O
"	O
domain	O
,	O
the	O
sampled	O
dialogs	O
yield	O
a	O
large	O
improvement	O
,	O
probably	O
because	O
the	O
flow	O
chart	O
for	O
this	O
domain	O
is	O
large	O
,	O
so	O
the	O
sampled	O
dialogs	O
increase	O
coverage	O
.	O
The	O
gain	O
in	O
the	O
"	O
forgot	O
password	O
"	O
domain	O
is	O
present	O
but	O
smaller	O
.	O
In	O
summary	O
,	O
HCNs	B-MethodName
can	O
out	O
-	O
perform	O
Figure	O
3	O
:	O
Training	O
dialogs	O
vs.	O
∆P	B-MetricName
,	O
where	O
∆P	B-MetricName
is	O
the	O
fraction	O
of	O
test	O
dialogs	O
where	O
HCNs	B-MethodName
produced	O
longer	O
initial	O
correct	O
sequences	O
of	O
system	O
actions	O
than	O
the	O
rules	O
,	O
minus	O
the	O
fraction	O
where	O
rules	O
produced	O
longer	O
initial	O
correct	O
sequences	O
than	O
the	O
HCNs	B-MethodName
.	O
"	O
embed	O
"	O
indicates	O
whether	O
utterance	O
embeddings	O
were	O
included	O
;	O
"	O
sampled	O
"	O
indicates	O
whether	O
dialogs	O
sampled	O
from	O
the	O
rule	O
-	O
based	O
controller	O
were	O
included	O
in	O
the	O
training	O
set	O
.	O
production	O
-	O
grade	O
rule	O
-	O
based	O
systems	O
with	O
a	O
reasonable	O
number	O
of	O
labeled	O
dialogs	O
,	O
and	O
adding	O
synthetic	O
"	O
sunny	O
-	O
day	O
"	O
dialogs	O
improves	O
performance	O
further	O
.	O
Moreover	O
,	O
unlike	O
existing	O
pipelined	O
approaches	O
to	O
dialog	O
management	O
that	O
rely	O
on	O
an	O
explicit	O
state	O
tracker	O
,	O
this	O
HCN	B-MethodName
used	O
no	O
explicit	O
state	O
tracker	O
,	O
highlighting	O
an	O
advantage	O
of	O
the	O
model	O
.	O
The	O
experiment	O
dataset	O
is	O
accessed	O
from	O
the	O
professional	O
finance	O
news	O
providers	O
Reuters	O
2	O
.	O
We	O
collect	O
forex	O
trade	O
data	O
of	O
four	O
major	O
currency	O
pairs	O
(	O
USD	O
-	O
EUR	O
,	O
USD	O
-	O
JPY	O
,	O
USD	O
-	O
RMB	O
,	O
USD	O
-	O
GBP	O
)	O
from	O
2013	O
to	O
2017	O
.	O
We	O
collect	O
the	O
open	O
/	O
close	O
/	O
high	O
/	O
low	O
trade	O
price	O
for	O
each	O
trade	O
minute	O
.	O
As	O
for	O
the	O
finance	O
news	O
data	O
,	O
we	O
collect	O
all	O
the	O
English	O
news	O
happened	O
in	O
trade	O
time	O
released	O
by	O
Reuters	O
and	O
match	O
the	O
news	O
with	O
target	O
currency	O
pairs	O
according	O
to	O
news	O
region	O
.	O
For	O
example	O
,	O
we	O
match	O
USD	O
-	O
EUR	O
with	O
news	O
related	O
to	O
US	O
,	O
Europe	O
or	O
both	O
of	O
them	O
.	O
The	O
raw	O
data	O
contains	O
both	O
news	O
headline	O
and	O
body	O
,	O
and	O
we	O
utilize	O
the	O
headline	O
only	O
since	O
the	O
headline	O
contains	O
the	O
most	O
valuable	O
information	O
and	O
has	O
less	O
noise	O
.	O
The	O
forex	O
movement	O
label	O
f	O
is	O
decided	O
by	O
the	O
comparison	O
of	O
prediction	O
time	O
price	O
and	O
the	O
input	O
window	O
ending	O
price	O
.	O
We	O
design	O
the	O
symbol	O
USD	O
-	O
EUR	O
(	O
20	O
-	O
10	O
)	O
to	O
represent	O
the	O
prediction	O
for	O
the	O
USD	O
-	O
EUR	O
exchange	O
rate	O
with	O
20	B-HyperparameterValue
minutes	I-HyperparameterValue
input	B-HyperparameterName
time	I-HyperparameterName
and	O
10	B-HyperparameterValue
minutes	I-HyperparameterValue
prediction	B-HyperparameterName
delay	I-HyperparameterName
.	O
To	O
access	O
more	O
data	O
for	O
training	O
,	O
we	O
overlap	O
the	O
input	O
time	O
of	O
samples	O
.	O
For	O
example	O
,	O
when	O
overlap	O
-	O
rate	O
is	O
50	O
%	O
,	O
two	O
consecutive	O
samples	O
'	O
input	O
time	O
will	O
be	O
8:00	O
-	O
8:20	O
am	O
and	O
8:10	O
-	O
8:30	O
am	O
.	O
Then	O
the	O
data	O
samples	O
will	O
be	O
twice	O
as	O
large	O
as	O
no	O
overlap	O
condition	O
(	O
In	O
the	O
USD	O
-	O
EUR	O
(	O
20	O
-	O
10	O
)	O
dataset	O
,	O
the	O
number	O
of	O
samples	O
will	O
increase	O
from	O
31k	O
to	O
62k	O
)	O
.	O
We	O
reserve	O
5k	O
samples	O
for	O
developing	O
and	O
5k	O
samples	O
for	O
testing	O
.	O
All	O
the	O
rest	O
of	O
samples	O
are	O
applied	O
for	O
training	O
.	O
Classification	B-MetricName
accuracies	I-MetricName
are	O
shown	O
in	O
Table	O
3	O
5	O
.	O
It	O
is	O
apparent	O
that	O
in	O
both	O
training	O
data	O
settings	O
-	O
controlled	O
and	O
non	O
-	O
controlled	O
(	O
'	O
all	O
'	O
)	O
-	O
the	O
accuracy	O
of	O
aggression	O
identification	O
reduces	O
as	O
the	O
true	O
/	O
false	O
cut	B-HyperparameterName
-	I-HyperparameterName
off	I-HyperparameterName
threshold	I-HyperparameterName
t	B-HyperparameterName
increases	O
.	O
In	O
the	O
case	O
of	O
the	O
controlled	O
training	O
data	O
setting	O
there	O
is	O
at	O
first	O
a	O
small	O
increase	O
in	O
accuracy	B-MetricName
as	O
t	B-HyperparameterName
rises	O
from	O
1	B-HyperparameterValue
to	O
3	B-HyperparameterValue
.	O
This	O
result	O
suggests	O
that	O
the	O
levels	O
in	O
the	O
Wiki	O
-	O
Comments	O
Corpus	O
most	O
closely	O
matching	O
the	O
aggressive	O
posts	O
on	O
HackForums	O
are	O
those	O
in	O
the	O
attack	O
score	O
range	O
1	O
to	O
5	O
,	O
and	O
that	O
the	O
optimal	O
value	O
of	O
t	B-HyperparameterName
is	O
between	O
2	B-HyperparameterValue
and	O
3	B-HyperparameterValue
.	O
To	O
illustrate	O
the	O
rise	O
and	O
fall	O
in	O
classification	O
accuracy	B-MetricName
as	O
t	B-HyperparameterName
increases	O
,	O
we	O
plot	O
accuracies	O
as	O
boxplots	O
for	O
the	O
100	O
runs	O
in	O
the	O
controlled	O
training	O
data	O
setting	O
(	O
Figure	O
4.3	O
)	O
.	O
The	O
boxplots	O
show	O
medians	O
(	O
the	O
thick	O
horizontal	O
bars	O
)	O
,	O
first	O
and	O
third	O
quar	O
-	O
tiles	O
(	O
Q1	O
,	O
Q3	O
,	O
shown	O
by	O
the	O
hinges	O
)	O
,	O
and	O
whiskers	O
extending	O
as	O
far	O
as	O
1.5	O
*	O
IQR	O
where	O
IQR	O
is	O
the	O
inter	O
-	O
quartile	O
range	O
between	O
Q1	O
and	O
Q3	O
.	O
Datapoints	O
beyond	O
the	O
whiskers	O
are	O
outliers	O
and	O
are	O
plotted	O
individually	O
.	O
This	O
paper	O
presents	O
a	O
English	O
-	O
Korean	O
parallel	O
dataset	O
that	O
collects	O
381	O
K	O
news	O
articles	O
where	O
1	O
,	O
400	O
of	O
them	O
,	O
comprising	O
10	O
K	O
sentences	O
,	O
are	O
manually	O
labeled	O
for	O
crosslingual	O
named	B-TaskName
entity	I-TaskName
recognition	I-TaskName
(	O
NER	B-TaskName
)	O
.	O
The	O
annotation	O
guidelines	O
for	O
the	O
two	O
languages	O
are	O
developed	O
in	O
parallel	O
,	O
that	O
yield	O
the	O
inter	O
-	O
annotator	O
agreement	O
scores	O
of	O
91	O
and	O
88	O
%	O
for	O
English	O
and	O
Korean	O
respectively	O
,	O
indicating	O
sublime	O
quality	O
annotation	O
in	O
our	O
dataset	O
.	O
Three	O
types	O
of	O
crosslingual	O
learning	O
approaches	O
,	O
direct	O
model	O
transfer	O
,	O
embedding	O
projection	O
,	O
and	O
annotation	O
projection	O
,	O
are	O
used	O
to	O
develop	O
zero	O
-	O
shot	O
Korean	O
NER	B-TaskName
models	O
.	O
Our	O
best	O
model	O
gives	O
the	O
F1	B-MetricName
-	I-MetricName
score	I-MetricName
of	O
51	B-MetricValue
%	I-MetricValue
that	O
is	O
very	O
encouraging	O
,	O
considering	O
the	O
extremely	O
distinct	O
natures	O
of	O
these	O
two	O
languages	O
.	O
This	O
is	O
pioneering	O
work	O
that	O
explores	O
zero	B-TaskName
-	I-TaskName
shot	I-TaskName
crosslingual	I-TaskName
learning	I-TaskName
between	O
English	O
and	O
Korean	O
and	O
provides	O
rich	O
parallel	O
annotation	O
for	O
a	O
core	O
NLP	O
task	O
such	O
as	O
named	B-TaskName
entity	I-TaskName
recognition	I-TaskName
.	O
Ocular	O
OCR	O
Transcription	O
Hinman	O
Attr	O
Blayney	O
Attr	O
Hinman	O
Attr	O
Blayney	O
Attr	O
1	O
-	O
to	O
-	O
1	O
M	O
-	O
to	O
-	O
1	O
1	O
-	O
to	O
-	O
1	O
M	O
-	O
to	O
-	O
1	O
1	O
-	O
to	O
-	O
1	O
M	O
-	O
to	O
-	O
1	O
1	O
-	O
to	O
-	O
1	O
M	O
-	O
to	O
-	O
1	O
(	O
Hinman	O
,	O
1963	O
;	O
Howard	O
-	O
Hill	O
,	O
1973	O
,	O
1976	O
,	O
1980Taylor	O
,	O
1981	O
;	O
O'Connor	O
,	O
1975	O
;	O
Werstine	O
,	O
1982	O
)	O
.	O
We	O
also	O
evaluate	O
our	O
system	O
against	O
an	O
earlier	O
,	O
highly	O
influential	O
model	O
proposed	O
by	O
Hinman	O
(	O
1963	O
)	O
,	O
which	O
we	O
approximate	O
by	O
reverting	O
certain	O
compositor	O
divisions	O
in	O
Blayney	O
's	O
attribution	O
.	O
Hinman	O
's	O
attribution	O
posited	O
five	O
compositors	O
,	O
while	O
Blayney	O
's	O
posited	O
eight	O
.	O
In	O
experiments	O
,	O
we	O
set	O
the	O
model	O
's	O
maximum	B-HyperparameterName
number	I-HyperparameterName
of	I-HyperparameterName
compositors	I-HyperparameterName
to	B-HyperparameterName
C	I-HyperparameterName
=	O
5	B-HyperparameterValue
when	O
evaluating	O
on	O
Hinman	O
's	O
attribution	O
,	O
and	O
use	O
C	B-HyperparameterName
=	B-HyperparameterValue
8	I-HyperparameterValue
with	O
Blayney	O
's	O
.	O
We	O
compute	O
the	O
one	O
-	O
to	O
-	O
one	O
and	O
many	O
-	O
to	O
-	O
one	O
accuracy	O
,	O
mapping	O
the	O
recovered	O
page	O
groups	O
to	O
the	O
gold	O
compositors	O
to	O
maximize	O
accuracy	O
,	O
as	O
is	O
standard	O
for	O
many	O
unsupervised	O
clustering	O
tasks	O
,	O
e.g.	O
POS	O
induction	O
(	O
see	O
Christodoulopoulos	O
et	O
al	O
(	O
2010	O
)	O
)	O
.	O
BASIC	B-MethodName
model	O
variant	O
:	O
We	O
evaluate	O
a	O
simple	O
baseline	O
model	O
that	O
uses	O
a	O
multinomial	O
parameterization	O
for	O
generating	O
diplomatic	O
words	O
and	O
does	O
not	O
incorporate	O
spacing	O
information	O
.	O
We	O
use	O
two	O
different	O
options	O
for	O
selection	O
of	O
spelling	O
variants	O
to	O
be	O
considered	O
by	O
the	O
model	O
.	O
First	O
,	O
we	O
consider	O
only	O
the	O
three	O
words	O
selected	O
by	O
Hinman	O
:	O
do	O
,	O
go	O
and	O
here	O
(	O
referred	O
to	O
as	O
HINMAN	O
)	O
.	O
Second	O
,	O
we	O
use	O
a	O
larger	O
,	O
automatically	O
selected	O
,	O
word	O
list	O
(	O
referred	O
to	O
as	O
AUTO	O
)	O
.	O
Here	O
,	O
we	O
select	O
all	O
modern	O
words	O
with	O
frequency	O
greater	O
than	O
70	O
that	O
are	O
not	O
names	O
and	O
that	O
exhibit	O
sufficient	O
variance	O
in	O
diplomatic	O
spellings	O
(	O
most	O
common	O
diplomatic	O
spelling	O
occurs	O
in	O
less	O
than	O
80	O
%	O
of	O
aligned	O
tokens	O
)	O
.	O
For	O
our	O
full	O
model	O
,	O
described	O
in	O
the	O
next	O
section	O
,	O
we	O
always	O
use	O
the	O
larger	O
AUTO	O
word	O
list	O
.	O
FEAT	B-MethodName
model	O
variant	O
:	O
We	O
run	O
experiments	O
with	O
several	O
variants	O
of	O
our	O
full	O
model	O
,	O
described	O
in	O
Section	O
3	O
(	O
referred	O
to	O
as	O
FEAT	B-MethodName
since	O
they	O
use	O
a	O
feature	O
-	O
based	O
parameterization	O
of	O
diplomatic	O
word	O
generation	O
.	O
)	O
We	O
try	O
ablations	O
of	O
WORD	O
and	O
EDIT	O
features	O
,	O
as	O
well	O
as	O
model	O
variants	O
with	O
and	O
without	O
the	O
spacing	O
generation	O
component	O
(	O
referred	O
to	O
as	O
SPACE	B-MethodName
.	O
)	O
We	O
refer	O
to	O
the	O
full	O
model	O
that	O
includes	O
both	O
types	O
of	O
features	O
and	O
spacing	O
generation	O
as	O
ALL	O
.	O
Online	O
misogyny	O
is	O
a	O
pernicious	O
social	O
problem	O
that	O
risks	O
making	O
online	O
platforms	O
toxic	O
and	O
unwelcoming	O
to	O
women	O
.	O
We	O
present	O
a	O
new	O
hierarchical	O
taxonomy	O
for	O
online	O
misogyny	O
,	O
as	O
well	O
as	O
an	O
expert	O
labelled	O
dataset	O
to	O
enable	O
automatic	O
classification	O
of	O
misogynistic	O
content	O
.	O
The	O
dataset	O
consists	O
of	O
6	O
,	O
567	O
labels	O
for	O
Reddit	O
posts	O
and	O
comments	O
.	O
As	O
previous	O
research	O
has	O
found	O
untrained	O
crowdsourced	O
annotators	O
struggle	O
with	O
identifying	O
misogyny	O
,	O
we	O
hired	O
and	O
trained	O
annotators	O
and	O
provided	O
them	O
with	O
robust	O
annotation	O
guidelines	O
.	O
We	O
report	O
baseline	O
classification	O
performance	O
on	O
the	O
binary	O
classification	O
task	O
,	O
achieving	O
accuracy	B-MetricName
of	O
0.93	B-MetricValue
and	O
F1	B-MetricName
of	O
0.43	B-MetricValue
.	O
The	O
codebook	O
and	O
datasets	O
are	O
made	O
freely	O
available	O
for	O
future	O
researchers	O
.	O
We	O
represent	O
the	O
whole	O
corpus	O
D	O
with	O
an	O
undirected	O
graph	O
G	O
=	O
(	O
N	O
,	O
E	O
)	O
,	O
where	O
N	O
and	O
E	O
are	O
nodes	O
and	O
edges	O
in	O
the	O
graph	O
respectively	O
.	O
To	O
model	O
both	O
words	O
and	O
documents	O
,	O
each	O
of	O
them	O
is	O
represented	O
as	O
a	O
node	O
n	O
i	O
N	O
,	O
which	O
gives	O
rise	O
to	O
N	O
=	O
V	O
+	O
D	O
nodes	O
in	O
total	O
,	O
where	O
V	O
is	O
the	O
size	O
of	O
vocabulary	O
V	O
and	O
D	O
is	O
the	O
number	O
of	O
documents	O
in	O
corpus	O
D.	O
An	O
edge	O
(	O
n	O
i	O
,	O
n	O
j	O
)	O
indicates	O
the	O
relevance	O
of	O
node	O
n	O
i	O
and	O
n	O
j	O
,	O
whose	O
weight	O
is	O
determined	O
by	O
A	O
i	O
,	O
j	O
=	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
TF	O
-	O
IDF	O
ij	O
,	O
i	O
D	O
and	O
j	O
V	O
TF	O
-	O
IDF	O
ji	O
,	O
i	O
V	O
and	O
j	O
D	O
1	O
,	O
i	O
=	O
j	O
0	O
,	O
otherwise	O
(	O
1	O
)	O
where	O
A	O
is	O
the	O
adjacency	O
matrix	O
of	O
G	O
and	O
TF	O
-	O
IDF	O
ij	O
denotes	O
the	O
max	O
-	O
normalized	O
TF	O
-	O
IDF	O
(	O
Term	O
Frequency	O
-	O
Inverse	O
Document	O
Frequency	O
)	O
weight	O
of	O
word	O
j	O
in	O
document	O
i.	O
Besides	O
self	O
-	O
connections	O
,	O
we	O
only	O
apply	O
positive	O
weights	O
to	O
edges	O
between	O
documents	O
and	O
words	O
,	O
while	O
rely	O
on	O
the	O
model	O
to	O
capture	O
higher	O
-	O
order	O
relationships	O
,	O
e.g.	O
doc	O
-	O
doc	O
and	O
word	O
-	O
word	O
relationships	O
,	O
by	O
applying	O
graph	O
convolutions	O
on	O
graph	O
G.	O
I	O
X	O
X	O
T	O
I	O
	O
	O
	O
	O
EẐ	O
Z	O
Dirichlet	O
(	O
α	O
)	O
GX	O
L	O
rec	O
(	O
X	O
,	O
X	O
)	O
MMD	O
(	O
P	O
Z	O
,	O
QẐ	O
)	O
Figure	O
1	O
:	O
The	O
framework	O
of	O
GTM	O
.	O
Circles	O
denote	O
neural	O
networks	O
.	O
X	O
,	O
I	O
,	O
Ẑ	O
,	O
X	O
,	O
Z	O
are	O
the	O
TF	O
-	O
IDF	O
matrix	O
of	O
the	O
corpus	O
,	O
an	O
identity	O
matrix	O
,	O
latent	O
topics	O
of	O
all	O
documents	O
,	O
reconstructed	O
word	O
weights	O
and	O
topic	O
distributions	O
drawn	O
from	O
the	O
Dirichlet	O
prior	O
respectively	O
.	O
L	O
rec	O
(	O
X	O
,	O
X	O
)	O
and	O
MMD	O
(	O
P	O
Z	O
,	O
Q	O
Z	O
)	O
are	O
training	O
objectives	O
.	O
The	O
thesis	O
express	O
the	O
central	O
claim	O
of	O
an	O
author	O
with	O
respect	O
to	O
the	O
essay	O
's	O
topic	O
.	O
Main	O
Idea	O
The	O
ideas	O
establish	O
foundational	O
ideas	O
or	O
aspects	O
that	O
are	O
related	O
to	O
the	O
thesis	O
.	O
Evidence	O
The	O
evidence	O
elements	O
provide	O
examples	O
or	O
other	O
evidence	O
that	O
are	O
used	O
to	O
support	O
main	O
ideas	O
and	O
thesis	O
.	O
Elaboration	O
The	O
elaboration	O
elements	O
further	O
explain	O
main	O
ideas	O
or	O
provide	O
reasons	O
,	O
but	O
contain	O
no	O
examples	O
or	O
other	O
evidence	O
.	O
Conclusion	O
The	O
conclusion	O
sentence	O
is	O
the	O
extension	O
of	O
the	O
central	O
argument	O
,	O
summarizes	O
the	O
full	O
text	O
,	O
and	O
echos	O
the	O
thesis	O
of	O
the	O
essay	O
.	O
Other	O
Other	O
elements	O
refer	O
to	O
the	O
ones	O
that	O
do	O
not	O
match	O
the	O
above	O
classes	O
.	O
The	O
dataset	O
has	O
1	O
,	O
230	O
argumentative	O
essays	O
written	O
by	O
high	O
school	O
students	O
,	O
covering	O
diverse	O
topics	O
.	O
These	O
essays	O
were	O
collected	O
from	O
a	O
website	O
LeleKetang	O
.	O
1	O
We	O
asked	O
two	O
annotators	O
from	O
the	O
literal	O
arts	O
college	O
to	O
assign	O
discourse	O
elements	O
to	O
sentences	O
from	O
these	O
essays	O
according	O
to	O
a	O
manual	O
.	O
The	O
annotators	O
discussed	O
to	O
reach	O
a	O
consensus	O
and	O
refined	O
the	O
manual	O
for	O
several	O
rounds	O
.	O
We	O
use	O
one	O
annotator	O
's	O
annotation	O
as	O
the	O
gold	O
answer	O
,	O
and	O
the	O
other	O
's	O
annotation	O
as	O
the	O
prediction	O
,	O
and	O
compute	O
the	O
F1	B-MetricName
scores	O
to	O
measure	O
the	O
agreement	O
,	O
which	O
is	O
shown	O
in	O
Figure	O
3	O
.	O
Table	O
1	O
shows	O
the	O
basic	O
statistics	O
of	O
the	O
dataset	O
.	O
The	O
distribution	O
of	O
discourse	O
elements	O
is	O
imbalanced	O
.	O
Elaboration	O
and	O
evidence	O
sentences	O
are	O
[	O
To	O
conclude	O
,	O
art	O
could	O
play	O
an	O
active	O
role	O
in	O
improving	O
the	O
quality	O
of	O
people	O
's	O
lives	O
,	O
]	O
s	O
1	O
[	O
but	O
I	O
think	O
that	O
governments	O
should	O
attach	O
heavier	O
weight	O
to	O
other	O
social	O
issues	O
such	O
as	O
education	O
and	O
housing	O
needs	O
]	O
s	O
2	O
[	O
because	O
those	O
are	O
the	O
most	O
essential	O
ways	O
enable	O
to	O
make	O
people	O
a	O
decent	O
life	O
.	O
]	O
s	O
3	O
.	O
many	O
more	O
than	O
thesis	O
and	O
main	O
idea	O
sentences	O
.	O
The	O
type	O
of	O
other	O
sentence	O
accounts	O
for	O
a	O
very	O
small	O
percentage	O
of	O
the	O
dataset	O
.	O
The	O
test	O
dataset	O
is	O
10	O
%	O
of	O
the	O
whole	O
dataset	O
.	O
Our	O
next	O
model	O
leverages	O
the	O
negatively	O
perturbed	O
graphs	O
in	O
a	O
max	O
-	O
margin	O
formulation	O
.	O
During	O
training	O
,	O
given	O
a	O
(	O
belief	O
,	O
argument	O
,	O
stance	O
)	O
context	O
x	O
,	O
a	O
ground	O
truth	O
graph	O
G	O
(	O
g	O
)	O
and	O
a	O
negative	O
graph	O
G	O
(	O
n	O
)	O
,	O
linearized	O
into	O
a	O
sequence	O
of	O
words	O
{	O
y	O
(	O
g	O
)	O
i	O
}	O
k	O
i=1	O
and	O
{	O
y	O
(	O
n	O
)	O
i	O
}	O
l	O
i=1	O
respectively	O
,	O
we	O
define	O
the	O
loss	O
function	O
L	O
as	O
a	O
linear	O
combination	O
of	O
the	O
standard	O
crossentropy	B-MetricName
loss	I-MetricName
L	B-MetricName
CE	I-MetricName
and	O
a	O
max	B-MetricName
-	I-MetricName
margin	I-MetricName
loss	I-MetricName
L	B-MetricName
MM	I-MetricName
,	O
defined	O
between	O
a	O
word	O
y	O
(	O
g	O
)	O
i	O
of	O
the	O
positive	O
graph	O
and	O
a	O
word	O
y	O
(	O
n	O
)	O
i	O
of	O
the	O
negative	O
graph	O
.	O
L	B-MetricName
CE	I-MetricName
=	O
i	O
−logP	O
θ	O
(	O
y	O
(	O
g	O
)	O
i	O
|	O
y	O
(	O
g	O
)	O
<	O
i	O
,	O
x	O
)	O
L	B-MetricName
MM	I-MetricName
=	O
i	O
max	O
(	O
0	O
,	O
logP	O
θ	O
(	O
y	O
(	O
g	O
)	O
i	O
|	O
y	O
(	O
g	O
)	O
<	O
i	O
,	O
x	O
)	O
−	O
log	O
P	O
θ	O
(	O
y	O
(	O
n	O
)	O
i	O
|	O
y	O
(	O
n	O
)	O
<	O
i	O
,	O
x	O
)	O
+	O
β	O
)	O
L	O
=	O
L	B-MetricName
CE	I-MetricName
+	O
αL	B-MetricName
MM	I-MetricName
where	O
α	O
and	O
β	O
(	O
margin	O
)	O
are	O
hyperparameters	O
.	O
As	O
noted	O
earlier	O
,	O
the	O
baseline	O
model	O
often	O
makes	O
commonsense	O
mistakes	O
in	O
distinguishing	O
between	O
positive	O
and	O
negative	O
relations	O
(	O
"	O
causes	O
"	O
vs	O
"	O
not	O
causes	O
"	O
)	O
and	O
our	O
relation	O
perturbing	O
negative	O
graphs	O
and	O
the	O
max	B-MetricName
-	I-MetricName
margin	I-MetricName
loss	I-MetricName
component	O
facilitate	O
learning	O
a	O
better	O
boundary	O
between	O
them	O
.	O
Although	O
existing	O
reading	O
comprehension	O
tasks	O
focus	O
exclusively	O
on	O
finding	O
one	O
span	O
of	O
text	O
as	O
the	O
final	O
answer	O
,	O
DROP	B-MethodName
loosens	O
the	O
restriction	O
so	O
that	O
the	O
answer	O
to	O
the	O
question	O
may	O
be	O
several	O
text	O
spans	O
.	O
Therefore	O
,	O
specific	O
adaption	O
should	O
be	O
made	O
to	O
extend	O
previous	O
single	O
-	O
span	O
extraction	O
to	O
multi	O
-	O
span	O
scenario	O
.	O
To	O
do	O
this	O
,	O
we	O
propose	O
directly	O
predicting	O
the	O
number	O
of	O
spans	O
and	O
model	O
it	O
as	O
a	O
classification	O
problem	O
.	O
This	O
is	O
achieved	O
by	O
computing	O
a	O
probability	O
distribution	O
on	O
span	O
amount	O
as	O
p	O
span	O
=	O
softmax	O
(	O
FFN	O
(	O
[	O
h	O
Q	O
2	O
;	O
h	O
P	O
2	O
;	O
h	O
CLS	O
]	O
)	O
)	O
To	O
extract	O
non	O
-	O
overlapped	O
spans	O
to	O
the	O
specific	O
amount	O
,	O
we	O
adopt	O
the	O
non	O
-	O
maximum	O
suppression	O
(	O
NMS	O
)	O
algorithm	O
(	O
Rosenfeld	O
and	O
Thurston	O
,	O
1971	O
)	O
that	O
is	O
widely	O
used	O
in	O
computer	O
vision	O
for	O
pruning	O
redundant	O
bounding	O
boxes	O
,	O
as	O
shown	O
in	O
Algorithm	O
1	O
.	O
Concretely	O
,	O
the	O
model	O
first	O
proposes	O
a	O
set	O
of	O
top	O
-	O
K	O
spans	O
S	O
according	O
to	O
the	O
descending	O
order	O
of	O
the	O
span	O
score	O
,	O
which	O
is	O
computed	O
as	O
p	O
start	O
k	O
p	O
end	O
l	O
for	O
the	O
span	O
(	O
k	O
,	O
l	O
)	O
.	O
It	O
also	O
predicts	O
the	O
amount	O
of	O
extracted	O
spans	O
t	O
from	O
p	O
span	O
,	O
and	O
initializes	O
a	O
new	O
setS.	O
Next	O
,	O
we	O
add	O
the	O
span	O
s	O
i	O
that	O
possesses	O
the	O
maximum	O
span	O
score	O
to	O
the	O
setS	O
,	O
and	O
remove	O
it	O
from	O
S.	O
We	O
also	O
delete	O
any	O
remaining	O
span	O
s	O
j	O
that	O
overlaps	O
with	O
s	O
i	O
,	O
where	O
the	O
degree	O
of	O
overlap	O
is	O
measured	O
using	O
the	O
text	O
-	O
level	O
F1	O
function	O
.	O
This	O
process	O
is	O
repeated	O
for	O
remaining	O
spans	O
in	O
S	O
,	O
until	O
S	O
is	O
empty	O
or	O
the	O
size	O
ofS	O
reaches	O
t.	O
