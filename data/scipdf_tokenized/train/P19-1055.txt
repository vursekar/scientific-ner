Sentiment Tagging with Partial Labels using Modular Architectures
Many NLP learning tasks can be decomposed into several distinct sub - tasks , each associated with a partial label . In this paper we focus on a popular class of learning problems , sequence prediction applied to several sentiment analysis tasks , and suggest a modular learning approach in which different sub - tasks are learned using separate functional modules , combined to perform the final task while sharing information . Our experiments show this approach helps constrain the learning process and can alleviate some of the supervision efforts .
Many natural language processing tasks attempt to replicate complex human - level judgments , which often rely on a composition of several sub - tasks into a unified judgment . For example , consider the Targeted - Sentiment task ( Mitchell et al , 2013 ) , assigning a sentiment polarity score to entities depending on the context that they appear in . Given the sentence " according to a CNN poll , Green Book will win the best movie award " , the system has to identify both entities , and associate the relevant sentiment value with each one ( neutral with CNN , and positive with Green Book ) . This task can be viewed as a combination of two tasks , entity identification , locating contiguous spans of words corresponding to relevant entities , and sentiment prediction , specific to each entity based on the context it appears in . Despite the fact that this form of functional task decomposition is natural for many learning tasks , it is typically ignored and learning is defined as a monolithic process , combining the tasks into a single learning problem . Our goal in this paper is to take a step towards modular learning architectures that exploit the learning tasks ' inner structure , and as a result simplify the learning process and reduce the annotation effort . We introduce a novel task decomposition approach , learning with partial labels , in which the task output labels decompose hierarchically , into partial labels capturing different aspects , or sub - tasks , of the final task . We show that learning with partial labels can help support weakly - supervised learning when only some of the partial labels are available . Given the popularity of sequence labeling tasks in NLP , we demonstrate the strength of this approach over several sentiment analysis tasks , adapted for sequence prediction . These include target - sentiment prediction ( Mitchell et al , 2013 ) , aspect - sentiment prediction ( Pontiki et al , 2016 ) and subjective text span identification and polarity prediction . To ensure the broad applicability of our approach to other problems , we extend the popular LSTM - CRF ( Lample et al , 2016 ) model that was applied to many sequence labeling tasks 1 . The modular learning process corresponds to a task decomposition , in which the prediction label , y , is deconstructed into a set of partial labels { y 0 , .. , y k } , each defining a sub - task , capturing a different aspect of the original task . Intuitively , the individual sub - tasks are significantly easier to learn , suggesting that if their dependencies are modeled correctly when learning the final task , they can constrain the learning problem , leading to faster convergence and a better overall learning outcome . In addition , the modular approach helps alleviate the supervision problem , as often providing full supervision for the overall task is costly , while providing additional partial labels is significantly easier . For example , annotating entity segments syntactically is considerably easier than determining their associated sentiment , which requires understanding the nuances of the context they appear in semantically . By exploiting modularity , the entity segmentation partial labels can be used to help improve that specific aspect of the overall task . Our modular task decomposition approach is partially inspired by findings in cognitive neuroscience , namely the two - streams hypothesis , a widely accepted model for neural processing of cognitive information in vision and hearing ( Eysenck and Keane , 2005 ) , suggesting the brain processes information in a modular way , split between a " where " ( dorsal ) pathway , specialized for locating objects and a " what " ( ventral ) pathway , associated with object representation and recognition ( Mishkin et al , 1983 ; Geschwind and Galaburda , 1987 ; Kosslyn , 1987 ; Rueckl et al , 1989 ) . Jacobs et al ( 1991 ) provided a computational perspective , investigating the " what " and " where " decomposition on a computer vision task . We observe that this task decomposition naturally fits many NLP tasks and borrow the notation . In the target - sentiment tasks we address in this paper , the segmentation tagging task can be considered as a " where " - task ( i.e. , the location of entities ) , and the sentiment recognition as the " what " - task . Our approach is related to multi - task learning ( Caruana , 1997 ) , which has been extensively applied in NLP ( Toshniwal et al , 2017 ; Eriguchi et al , 2017 ; Collobert et al , 2011 ; Luong , 2016 ; Liu et al , 2018 ) . However , instead of simply aggregating the objective functions of several different tasks , we suggest to decompose a single task into multiple inter - connected sub - tasks and then integrate the representation learned into a single module for the final decision . We study several modular neural architectures , which differ in the way information is shared between tasks , the learning representation associated with each task and the way the dependency between decisions is modeled . Our experiments were designed to answer two questions . First , can the task structure be exploited to simplify a complex learning task by using a modular approach ? Second , can partial labels be used effectively to reduce the annotation effort ? To answer the first question , we conduct experiments over several sequence prediction tasks , and compare our approach to several recent models for deep structured prediction ( Lample et al , 2016 ; Ma and Hovy , 2016 ; Liu et al , 2018 ) , and when available , previously published results ( Mitchell et al , 2013 ; Zhang et al , 2015 ; Li and Lu , 2017 ; Ma et al , 2018 ) We show that modular learning indeed helps simplify the learning task compared to traditional monolithic approaches . To answer the second question , we evaluate our model 's ability to leverage partial labels in two ways . First , by restricting the amount of full labels , and observing the improvement when providing increasing amounts of partial labels for only one of the sub - tasks . Second , we learn the sub - tasks using completely disjoint datasets of partial labels , and show that the knowledge learned by the sub - task modules can be integrated into the final decision module using a small amount of full labels . Our contributions : ( 1 ) We provide a general modular framework for sequence learning tasks . While we focus on sentiment analysis task , the framework is broadly applicable to many other tagging tasks , for example , NER ( Carreras et al , 2002 ; Lample et al , 2016 ) and SRL ( Zhou and Xu , 2015 ) , to name a few . ( 2 ) We introduce a novel weakly supervised learning approach , learning with partial labels , that exploits the modular structure to reduce the supervision effort . ( 3 ) We evaluated our proposed model , in both the fullysupervised and weakly supervised scenarios , over several sentiment analysis tasks .
From a technical perspective , our task decomposition approach is related to multi - task learning ( Caruana , 1997 ) , specifically , when the tasks share information using a shared deep representation ( Collobert et al , 2011 ; Luong , 2016 ) . However , most prior works aggregate multiple losses on either different pre - defined tasks at the final layer ( Collobert et al , 2011 ; Luong , 2016 ) , or on a language model at the bottom level ( Liu et al , 2018 ) . This work suggests to decompose a given task into sub - tasks whose integration comprise the original task . To the best of our knowledge , Ma et al ( 2018 ) , focusing on targeted sentiment is most similar to our approach . They suggest a joint learning approach , modeling a sequential relationship between two tasks , entity identification and target sentiment . We take a different approach viewing each of the model components as a separate module , predicted independently and then integrated into the final decision module . As we demonstrate in our experiments , this approach leads to better performance and increased flexibil - ity , as it allows us to decouple the learning process and learn the tasks independently . Other modular neural architectures were recently studied for tasks combining vision and language analysis ( Andreas et al , 2016 ; Hu et al , 2017 ; Yu et al , 2018 ) , and were tailored for the grounded language setting . To help ensure the broad applicability of our framework , we provide a general modular network formulation for sequence labeling tasks by adapting a neural - CRF to capture the task structure . This family of models , combining structured prediction with deep learning showed promising results ( Gillick et al , 2015 ; Lample et al , 2016 ; Ma and Hovy , 2016 ; Zhang et al , 2015 ; Li and Lu , 2017 ) , by using rich representations through neural models to generate decision candidates , while utilizing an inference procedure to ensure coherent decisions . Our main observation is that modular learning can help alleviate some of the difficulty involved in training these powerful models .
Using neural networks to generate emission potentials in CRFs was applied successfully in several sequence prediction tasks , such as word segmentation ( Chen et al , 2017 ) , NER ( Ma and Hovy , 2016 ; Lample et al , 2016 ) , chunking and PoS tagging ( Liu et al , 2018 ; Zhang et al , 2017 ) . A sequence is represented as a sequence of L tokens : x = [ x 1 , x 2 , . . . , x L ] , each token corresponds to a label y Y , where Y is the set of all possible tags . An inference procedure is designed to find the most probable sequence y * = [ y 1 , y 2 , . . . , y L ] by solving , either exactly or approximately , the following optimization problem : y * = arg max y P ( y | x ) . Despite the difference in tasks , these models follow a similar general architecture : ( 1 ) Characterlevel information , such as prefix , suffix and capitalization , is represented through a character embedding layer learned using a bi - directional LSTM ( BiLSTM ) . ( 2 ) Word - level information is obtained through a word embedding layer . ( 3 ) The two representations are concatenated to represent an input token , used as input to a word - level BiLSTM which generates the emission potentials for a succeeding CRF . ( 4 ) The CRF is used as an inference layer to generate the globally - normalized probability of possible tag sequences .
A CRF model describes the probability of predicted labels y , given a sequence x as input , as , ỹ ) is the partition function that marginalize over all possible assignments to the predicted labels of the sequence , and Φ ( x , y ) is the scoring function , which is defined as : P Λ ( y | x ) = e Φ ( x , y ) Z , where Z = ỹ e Φ ( x Φ ( x , y ) = t φ ( x , y t ) + ψ ( y t−1 , y t ) . The partition function Z can be computed efficiently via the forward - backward algorithm . The term φ ( x , y t ) corresponds to the score of a particular tag y t at position t in the sequence , and ψ ( y t−1 , y t ) represents the score of transition from the tag at position t − 1 to the tag at position t. In the Neural CRF model , φ ( x , y t ) is generated by the aforementioned Bi - LSTM while ψ ( y t−1 , y t ) by a transition matrix .
To accommodate our task decomposition approach , we first define the notion of partial labels , and then discuss different neural architectures capturing the dependencies between the modules trained over the different partial labels . Partial Labels and Task Decomposition : Given a learning task , defined over an output space y Y , where Y is the set of all possible tags , each specific label y is decomposed into a set of partial labels , { y 0 , .. , y k } . We refer to y as the full label . According to this definition , a specific assignment to all k partial labels defines a single full label . Note the difference between partially labeled data ( Cour et al , 2011 ) , in which instances can have more than a single full label , and our setup in which the labels are partial . In all our experiments , the partial labels refer to two sub - tasks , ( 1 ) a segmentation task , identifying Beginning , Inside and Outside of an entity or aspect . ( 2 ) one or more type recognition tasks , recognizing the aspect type and/or the sentiment polarity associated with it . Hence , a tag y t at location t is divided into y seg t and y typ t , corresponding to segmentation and type ( sentiment type here ) respectively . Fig . 1 provides an example of the target - sentiment task . Note that the sentiment labels do not capture segmentation information . Text ABC News ' President Tag B - neu O O Christiane Amanpour Exclusive Interview with Seg Senti Mubarak E - neu B - neu E - neu B - neu E - neu O B O O E B E B E O neu O O neu neu neu neu neu O Figure 1 : Target - sentiment decomposition example . Modular Learning architectures : We propose three different models , in which information from the partial labels can be used . All the models have similar modules types , corresponding to the segmentation and type sub - tasks , and the decision module for predicting the final task . The modules are trained over the partial segmentation ( y seg ) and type ( y typ ) labels , and the full label y information , respectively . These three models differ in the way they share information . Model 1 , denoted Twofold Modular , LSTM - CRF - T , is similar in spirit to multi - task learning ( Collobert et al , 2011 ) with three separate modules . Model 2 , denoted Twofold modular Infusion , ( LSTM - CRF - TI ) and Model 3 , denoted Twofold modular Infusion with guided gating , ( LSTM - CRF - TI ( g ) ) both infuse information flow from two sub - task modules into the decision module . The difference is whether the infusion is direct or goes through a guided gating mechanism . The three models are depicted in Fig . 2 and described in details in the following paragraphs . In all of these models , underlying neural architecture are used for the emission potentials when CRF inference layers are applied on top .
The twofold modular model enhances the original monolithic model by using multi - task learning with shared underlying representations . The segmentation module and the type module are trained jointly with the decision module , and all the modules share information by using the same embedding level representation , as shown in Figure 2a . Since the information above the embedding level is independent , the LSTM layers in the different modules do not share information , so we refer to these layers of each module as private . The segmentation module predicts the segmentation BIO labels at position t of the sequence by using the representations extracted from its private word level bi - directional LSTM ( denoted as H seg ) as emission for a individual CRF : h seg t = H seg ( e t , − h seg t−1 , − h seg t+1 ) , φ ( x , y seg t ) = W seg h seg t + b seg , where W seg and b seg denote the parameters of the segmentation module emission layer , and H seg denotes its private LSTM layer . This formulation allows the model to forge the segmentation path privately through backpropagation by providing the segmentation information y seg individually , in addition to the complete tag information y. The type module , using y typ , is constructed in a similar way . By using representations from the its own private LSTM layers , the type module predicts the sentiment ( entity ) type at position t of the sequence : h typ t = H typ ( e t , − h typ t−1 , − h typ t+1 ) , φ ( x , y typ t ) = W typ h typ t + b typ . Both the segmentation information y seg and the type information y typ are provided together with the complete tag sequence y , enabling the model to learn segmentation and type recognition simultaneously using two different paths . Also , the decomposed tags naturally augment more training data to the model , avoiding over - fitting due to more complicated structure . The shared representation beneath the private LSTMs layers are updated via the back - propagated errors from all the three modules .
The twofold modular infusion model provides a stronger connection between the functionalities of the two sub - tasks modules and the final decision module , differing from multi - task leaning . In this model , instead of separating the pathways from the decision module as in the previous twofold modular model , the segmentation and the type representation are used as input to the final decision module . The model structure is shown in Figure 2b , and can be described formally as : I seg t = W seg h seg t + b seg , I typ t = W typ h typ t + b typ , S t = W [ h t ; I seg t ; I typ t ] + b , where S t is the shared final emission potential to the CRF layer in the decision module , and ; is the Figure 2 : Three modular models for task decomposition . In them , blue blocks are segmentation modules , detecting entity location and segmentation , and yellow blocks are the type modules , recognizing the entity type or sentiment polarity . Green blocks are the final decision modules , integrating all the decisions . ( G ) refers to " Guided Gating " concatenation operator , combining the representation from the decision module and that from the type module and the segmentation module . The term " Infusion " used for naming this module is intended to indicate that both modules actively participate in the final decision process , rather than merely form two independent paths as in the twofold modular model . This formulation provides an alternative way of integrating the auxiliary sub - tasks back into the major task in the neural structure to help improve learning .
In the previous section we described a way of infusing information from other modules naively by simply concatenating them . But intuitively , the hidden representation from the decision module plays an important role as it is directly related to the final task we are interested in . To effectively use the information from other modules forming sub - tasks , we design a gating mechanism to dynamically control the amount of information flowing from other modules by infusing the expedient part while excluding the irrelevant part , as shown in Figure 2c . This gating mechanism uses the information from the decision module to guide the information from other modules , thus we name it as guided gating infusion , which we describe formally as follows : I seg t = σ ( W 1 h t + b 1 ) ⊗ ( W seg h seg t + b seg ) , I typ t = σ ( W 2 h t + b 2 ) ⊗ ( W typ h typ t + b typ ) , S t = W [ h t ; I seg t ; I typ t ] + b , where σ is the logistic sigmoid function and ⊗ is the element - wise multiplication . The { W 1 , W 2 , b 1 , b 2 } are the parameters of these guided gating , which are updated during the training to maximize the overall sequence labeling performance .
Our objective naturally rises from the model we described in the text . Furthermore , as our experiments show , it is easy to generalize this objective , to a " semi - supervised " setting , in which the learner has access to only a few fully labeled examples and additional partially labeled examples . E.g. , if only segmentation is annotated but the type information is missing . The loss function is a linear combination of the negative log probability of each sub - tasks , together with the decision module : J = − N i log P ( y i | x i ) + α log P ( y seg ( i ) | x ( i ) ) + β log P ( y typ ( i ) | x ( i ) ) , ( 1 ) where N is the number of examples in the training set , y seg and y typ are the decomposed segmentation and type tags corresponding to the two sub - task modules , and α and β are the hyperparameters controlling the importance of the two modules contributions respectively . If the training example is fully labeled with both segmentation and type annotated , training is straightforward ; if the training example is partially labeled , e.g. , only with segmentation but without type , we can set the log probability of the type module and the decision module 0 and only train the segmentation module . This formulation provides extra flexibility of using partially annotated corpus together with fully annotated corpus to improve the overall performance .
Our experimental evaluation is designed to evaluate the two key aspects of our model : ( Q1 ) Can the modular architecture alleviate the difficulty of learning the final task ? To answer this question , we compare our modular architecture to the traditional neural - CRF model and several recent competitive models for sequence labeling combining inference and deep learning . The results are summarized in Tables 1 - 3 . ( Q2 ) Can partial labels be used effectively as a new form of weak - supervision ? To answer this question we compared the performance of the model when trained using disjoint sets of partial and full labels , and show that adding examples only associated with partial labels , can help boost performance on the final task . The results are summarized in Figures 3 - 5 .
We evaluated our models over three different sentiment analysis tasks adapted for sequence prediction . We included additional results for multilingual NER in the Appendix for reference . Target Sentiment Datasets We evaluated our models on the targeted sentiment dataset released by Mitchell et al ( 2013 ) , which consists of entity and sentiment annotations on both English and Spanish tweets . Similar to previous studies ( Mitchell et al , 2013 ; Zhang et al , 2015 ; Li and Lu , 2017 ) , our task focuses on people and organizations ( collapsed into volitional named entities tags ) and the sentiment associated with their description in tweets . After this processing , the labels of each tweets are composed of both segmentation ( entity spans ) and types ( sentiment tags ) . We used the original 10 - fold cross validation splits to calculate averaged F1 score , using 10 % of the training set for development . We used the same metrics in Zhang et al ( 2015 ) and Li and Lu ( 2017 ) for a fair comparison .
We used the Restaurants dataset provided by Se - mEval 2016 Task 5 subtask 1 , consisting of opinion target ( aspect ) expression segmentation , aspect classification and matching sentiment prediction . In the original task definition , the three tasks were designed as a pipeline , and assumed gold aspect labels when predicting the matching sentiment labels . Instead , our model deals with the challenging end - to - end setting by casting the problem as a sequence labeling task , labeling each aspect segment with the aspect label and sentiment polarity 2 .
We adapted the SemEval 2013 Task 2 subtask A as another task to evaluate our model . In this task , the system is given a marked phrase inside a longer text , and is asked to label its polarity . Unlike the original task , we did not assume the sequence is known , resulting in two decisions , identifying subjective expressions ( i.e. , a segmentation task ) and labeling their polarity , which can be modeled jointly as a sequence labeling task .
Following previous studies ( Ma and Hovy , 2016 ; Liu et al , 2018 ) showing that the word embedding choice can significantly influence performance , we used the pre - trained GloVe 100 dimension Twitter embeddings only for all tasks in the main text . All the words not contained in these embeddings ( OOV , out - of - vocabulary words ) are treated as an " unknown " word . Our models were deployed with minimal hyper parameters tuning , and can be briefly summarized as : the character embeddings has dimension 30 , the hidden layer dimension of the character level LSTM is 25 , and the hidden layer of the word level LSTM has dimension 300 . Similar to Liu et al ( 2018 ) , we also applied highway networks ( Srivastava et al , 2015 ) from the character level LSTM to the word level LSTM . In our pilot study , we shrank the number of parameters in our modular architectures to around one third such that the total number of parameter is similar as that in the LSTM - CRF model , but we did not observe a significant performance change so we kept them as denoted . The values of α and β in the objective function were always set to 1.0 .
We used BIOES tagging scheme but only during the training and convert them back to BIO2 for evaluation for all tasks 3 . Our model was implemented using pytorch ( Paszke et al , 2017 ) . To help improve performance we parallelized the for - ward algorithm and the Viterbi algorithm on the GPU . All the experiments were run on NVIDIA GPUs . We used the Stochastic Gradient Descent ( SGD ) optimization of batch size 10 , with a momentum 0.9 to update the model parameters , with the learning rate 0.01 , the decay rate 0.05 ; The learning rate decays over epochs by η/ ( 1 + e * ρ ) , where η is the learning rate , e is the epoch number , and ρ is the decay rate . We used gradient clip to force the absolute value of the gradient to be less than 5.0 . We used early - stop to prevent over - fitting , with a patience of 30 and at least 120 epochs . In addition to dropout , we used Adversarial Training ( AT ) ( Goodfellow et al , 2014 ) , to regularize our model as the parameter numbers increase with modules . AT improves robustness to small worst - case perturbations by computing the gradients of a loss function w.r.t . the input . In this study , α and β in Eq . 1 are both set to 1.0 , and we leave other tuning choices for future investigation .
Our first set of results are designed to compare our modular learning models , utilize partial labels decomposition , with traditional monolithic models , that learn directly over the full labels . In all three tasks , we compare with strong sequence prediction models , including LSTM - CRF ( Lample et al , 2016 ) , which is directly equivalent to our baseline model ( i.e. , final task decision without the modules ) , and LSTM - CNN - CRF ( Ma and Hovy , 2016 ) and LSTM - CRF - LM ( Liu et al , 2018 ) which use a richer latent representation for scoring the emission potentials . ( denoted E+A ) . The second adds a third module that predicts the sentiment polarity associated with the aspect ( denoted E+A+S ) . I.e. , for a given sentence , label its entity span , the aspect category of the entity and the sentiment polarity of the entity at the same time . The results over four languages are summarized in Tab . 2 . In all cases , our modular approach outperforms all monolithic approaches . Subjective Phrase Identification and Classification This dataset contains tweets annotated with sentiment phrases , used for training the models . As in the original SemEval task , it is tested in two settings , in - domain , where the test data also consists of tweets , and out - of - domain , where the test set consists of SMS text messages . We present the results of experiments on these data set in Table 3 .
Our modular architecture is a natural fit for learning with partial labels . Since the modular architecture decomposes the final task into sub - tasks , the absence of certain partial labels is permitted . In this case , only the module corresponding to the available partial labels will be updated while the other parts of the model stay fixed . This property can be exploited to reduce the supervision effort by defining semi - supervised learning protocols that use partial - labels when the full labels are not available , or too costly to annotate . E.g. , in the target sentiment task , segmentation labels are significantly easier to annotate . To demonstrate this property we conducted two sets of experiments . The first investigates how the decision module can effectively integrate the knowledge independently learned by sub - tasks modules using different partial labels . We quantify this ability by providing varying amounts of full labels to support the integration process . The second set studies the traditional semi - supervised settings , where we have a handful of full labels , but we have a larger amount of partial labels . Modular Knowledge Integration The modular architecture allows us to train each model using data obtained separately for each task , and only use a handful of examples annotated for the final task in order to integrate the knowledge learned by each module into a unified decision . We simulated these settings by dividing the training data into three folds . We associated each one of the first two folds with the two sub - task modules . Each one of the these folds only included the partial labels relevant for that sub - task . We then used gradually increasing amounts of the third fold , consisting of the full labels , for training the decision module . Fig . 3 describes the outcome for targetsentiment , comparing a non - modular model using only the full labels , with the modular approach , which uses the full labels for knowledge integration . Results show that even when very little full data is available results significantly improve . Additional results show the same pattern for subjective phrase identification and classification are included in the Appendix .
Partially - labeled data can be cheaper and easier to obtain , especially for low - resource languages . In this set of experiments , we model these settings over the target - sentiment task . The results are summarized in Fig . 4 . We fixed the amount of full labels to 20 % of the training set , and gradually increased the amount of partially labeled data . We studied adding segmentation and type separately . After the model is trained in this routine , it was tested on predicting the full labels jointly on the test set .
In our final analysis we considered a novel domain - adaptation settings , where we have a small amount of fully labeled in - domain data from aspect sentiment and more out - of - domain data from target sentiment . However unlike the traditional domain - adaptation settings , the out - ofdomain data is labeled for a different task , and only shares one module with the original task . In our experiments we fixed 20 % of the fully labeled data for the aspect sentiment task , and gradually added out - of - domain data , consisting of partial sentiment labels from the target sentiment task . Our model successfully utilized the out - ofdomain data and improved performance on the indomain task . The results are shown on Fig 5 .
We present and study several modular neural architectures designed for a novel learning scenario : learning from partial labels . We experiment with several sentiment analysis tasks . Our models , inspired by cognitive neuroscience findings ( Jacobs et al , 1991 ; Eysenck and Keane , 2005 ) and multitask learning , suggest a functional decomposition of the original task into two simpler sub - tasks . We evaluate different methods for sharing information and integrating the modules into the final decision , such that a better model can be learned , while converging faster 5 . As our experiments show , modular learning can be used with weak supervision , using examples annotated with partial labels only . The modular approach also provides interesting directions for future research , focusing on alleviating the supervision bottleneck by using large amount of partially labeled data that are cheaper and easy to obtain , together with only a handful amount of annotated data , a scenario especially suitable for low - resource languages .
In Figure 6 , we show an example of task decomposition for standard NER . In Figure 7 , we show another example of task decomposition for target sentiment , in addition to the one in the main text .
The complete results of our experiments on the target sentiment task are summarized in Tab . 4 . Our LSTM - CRF - TI ( g ) model outperforms all the other competing models in Precision , Recall and the F1 score .
NER datasets We evaluated our models on three NER datasets , the English , Dutch and Spanish parts of the 2002 and 2003 CoNLL shared tasks ( Sang and F. , 2002 ; Sang et al , 2003 ) . We used the original division of training , validation and test sets . The task is defined over four different entity types : PERSON , LOCATION , ORGANIZATION , MISC . We used the BIOES tagging scheme during the training , and convert them back to original tagging scheme in testing as previous studies show that using this tagging scheme instead of BIO2 can help improve performance ( Ratinov and Roth , 2009 ; Lample et al , 2016 ; Ma and Hovy , 2016 ; Liu et al , 2018 ) . As a result , the segmentation module had 5 output labels , and the entity module had 4 . The final decision task , consisted of the Cartesian product of the segmentation set ( BIES ) and the entity set , plus the " O " tag , resulting in 17 labels . Results on NER We compared our models with the state - of - the - art systems on English 6 , Dutch and Spanish . For Dutch and Spanish , we used cross - lingual embedding as a way to exploit lexical information . The results are shown in Tab . 5 and Tab . 6 7 . Our best - performing model outperform all the competing systems .
We conducted additional experiments on knowledge integration in the same setting as in the main text to investigate the properties of the modules . Figure 8 shows the results for Dutch and Spanish NER datasets , while Figure 9 shows the results for the Subjective Polarity Disambiguation Datasets using the in - domain data .
The proposed twofold modular infusion model ( with guided gating as an option ) breaks the complex learning problem into several sub - problems and then integrate them using joint training . The process defined by this formulation has more parameters and requires learning multiple objectives jointly . Our convergence analysis intends to evaluate whether the added complexity leads to a harder learning problem ( i.e. , slower to converge ) or whether the tasks constrain each other and as a result can be efficiently learned . We compare between our LSTM - CRF - TI ( g ) model and recent published top models on the English NER dataset in Figure 10 and on the subjec - tive polarity disambiguation datasets in Figure 11 . The curve compares convergence speed in terms of learning epochs . Our LSTM - CRF - TI ( g ) model has a much faster convergence rate compared to the other models . Figure 11 : Comparing convergence over the development set on the subjective polarity disambiguation datasets . The x - axis is number of epochs and the y - axis is the F1 - score .
We thank the reviewers for their insightful comments . We thank the NVIDIA Corporation for their GPU donation , used in this work . This work was partially funded by a Google Gift .
