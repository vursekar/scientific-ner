Exploring Statistical and Neural Models for Noun Ellipsis Detection and Resolution in English
Computational approaches to noun ellipsis resolution has been sparse , with only a naive rulebased approach that uses syntactic feature constraints for marking noun ellipsis licensors and selecting their antecedents . In this paper , we further the ellipsis research by exploring several statistical and neural models for both the subtasks involved in the ellipsis resolution process and addressing the representation and contribution of manual features proposed in previous research . Using the best performing models , we build an end - to - end supervised Machine Learning ( ML ) framework for this task that improves the existing F1 score by 16.55 % for the detection and 14.97 % for the resolution subtask . Our experiments demonstrate robust scores through pretrained BERT ( Bidirectional Encoder Representations from Transformers ) embeddings for word representation , and more so the importance of manual features - once again highlighting the syntactic and semantic characteristics of the ellipsis phenomenon . For the classification decision , we notice that a simple Multilayar Perceptron ( MLP ) works well for the detection of ellipsis ; however , Recurrent Neural Networks ( RNN ) are a better choice for the much harder resolution step .
Noun ellipsis is a linguistic phenomenon where the head noun of a noun phrase gets deleted , without making the sentence ungrammatical . For example in the sentence in ( 1 ) from ( Lobeck , 1995 ) , the noun presentation is elided at " [ e ] " . 1 . John 's presentation on urban development was virtually ignored because [ NP Mary 's [ e ] ] was so much more interesting . The elided information can be retrieved from the previous context as in ( 1 ) or with the knowledge of idiomatic usage of language as in I will be back in two [ e ] . where two means two minutes . It is also possible that the reference of the elided information comes from extra - linguistic , situational context . For example , consider a speaker pointing towards the roses in a shop and saying an utterance as in I will take two [ e ] . While human interlocutors resolve any such elided information by disambiguating from context , cognitive commonsense extension and reasoning ( Chen , 2016 ) , ellipsis resolution can be a hard task for Natural Language Processing ( NLP ) systems ( Hardt , 1999 ) . Resolution of ellipsis comprises two tasks - detection of the elided material and antecedent selection ( Liu et al , 2016b ; Nielsen , 2003 ) . Ellipses occur in the environment of certain syntactical structures or trigger words , also known as licensors or triggers of ellipses . They are useful syntactic cues for the detection of noun ellipsis . See Figure 1 for an example of the noun ellipsis resolution process .
Nominal ellipsis has been a topic of interest in theoretical linguistics for a very long time ( Halliday and Hasan , 1976 ; Dalrymple et al , 1991 ; Lobeck , 1995 ; Lappin , 1996 ; Hobbs and Kehler , 1997 ; Hardt , 1999 ; Johnson , 2001 ; Wijnen et al , 2003 ; Merchant , 2004 ; Frazier , 2008 ; Chung et al , 2010 ; Mer - chant , 2010 ; Goksun et al , 2010 ; Gunther , 2011 ; Rouveret , 2012 ; Lindenbergh et al , 2015 ; van Craenenbroeck and Merchant , 2013 ; Park , 2017 ; Hyams et al , 2017 ; Kim et al , 2019 ) . Computational approaches to the ellipsis phenomenon majorly focus on the Verb Phrase Ellipsis ( VPE ) along with a few related phenomenon such as gapping , sluicing and do - so anaphora , for instance , the detection of VPE in the Penn Treebank using pattern match ( Hardt , 1992 ) , a transformation learning - based approach to generated patterns for VPE resolution ( Hardt , 1998 ) , the domain independent VPE detection and resolution using machine learning ( Nielsen , 2003 ) , automatically parsed text ( Nielsen , 2004b ) , sentence trimming methods ( McShane et al , 2015 ) , linguistic principles ( McShane and Babkin , 2016 ) , improved parsing techniques that encode elided material dependencies for reconstruction of sentences containing gapping ( Schuster et al , 2018 ) , discriminative and margin infused algorithms ( Dean et al , 2016 ) , Multilayer Perceptrons ( MLP ) and Transformers ( Zhang et al , 2019 ) . In recent times , there has been a surge in the computational research on nominal ellipsis and closely related phenomena ( Khullar et al , 2020 ( Khullar et al , , 2019Lapshinova - Koltunski et al , 2018 ; Menzel , 2017 ; Menzel and Lapshinova - Koltunski , 2014 ) . For the resolution process , we previously proposed a rule based system ( Khullar et al , 2019 ) that detects noun ellipsis using syntactic constraints on licensors of ellipsis and resolves them by matching Part - of - Speech ( POS ) tag similarity between the licensor of ellipsis and the modifier of the antecedent . It later fine tunes these syntactic rules on a small curated dataset that contains 234 instances of noun ellipsis along with some negative samples ( Khullar et al , 2019 ) . For the present paper , we further the research on noun ellipses by using the NoEl corpus annotated by us previously ( Khullar et al , 2020 ) to experiment with state - ofthe - art ML models .
Following the VPE resolution framework presented by ( Zhang et al , 2019 ) , we investigate a similar framework for noun ellipsis resolution in English and present alternative choices of the models at each step as shown in Figure 2 . We use the NoEl corpus ( Khullar et al , 2020 ) that marks noun ellipsis instances as a separate layer ( using the stand - off annotation scheme ) on the Cornell Movie Dialogs corpus ( Danescu - Niculescu - Mizil and Lee , 2011 ) . The corpus marks a total of 946 annotations , of which 438 are described as endophoric , i.e. with a textual antecedent , and 508 exophoric , i.e. without a textual antecedent .
From a given sentence , we first select all words belonging to the syntactic categories that can license noun ellipsis in English , i.e. cardinal and ordinal numbers , determiners and adjectives ( Ross , 1967 ; Lobeck , 1995 ; Mitkov , 1999 ; Saito et al , 2008 ; Kim et al , 2019 ; Khullar et al , 2019 ) using a POS tag filter . The POS tags are obtained from state - ofthe - art spaCy parser ( Honnibal and Johnson , 2015 ) . For simplicity , we refer to words with these categories as noun modifiers ( although in strict linguistic terms , this might be problematic ) . For each of these selected noun modifiers , we follow the task specification for VPE detection used by ( Nielsen , 2004a ; Bos and Spenader , 2011 ; Liu et al , 2016a ; Dean et al , 2016 ) and present noun ellipsis detection as a binary classification task , where given a noun modifier and the sentence in which it occurs as the input , the goal of the classifier is to predict whether the noun modifier licenses a noun ellipsis or not . Formally , for a given licensor word l i is a licensor in a sentence s , the task is represented as follows : f ( l i , s ) − { 0 , 1 } where 1 denotes that l i is a licensor in s , and 0 otherwise . We experiment with both static and contextualised word embeddings for word and context representation . For the former , we choose pretrained fastText ( FT ) word embeddings ( Bojanowski et al , 2016 ) as they provide representations for rare and unknown words that might be frequent in the movie dialogues . For the latter , we use pretrained BERT embeddings from the BERT base uncased wordpiece model for English ( Devlin et al , 2019 ) , as these currently offer the most powerful embeddings taking into account a large left and right context . fastText We take pretrained FT word embeddings for the noun modifier and sentence in which it is present and sum pool to obtain a single vector that we use to train our classifiers . For the statistical models , we choose Naive Bayes and Linear Support Vector Machine ( SVM ) , and use scikit learn ( Pedregosa et al , 2011 ) with 5 - fold cross validation for training and testing . We choose a BERT We separate the sentence and the licensor with a [ SEP ] token and keep the sequence length to 300 as this is the maximum sentence length in the training data . After creating the concatenated set of tokens , if the number of tokens are greater than 300 , we clip it to 300 , otherwise we add [ PAD ] tokens which correspond to the embedding of 768 dimensional zero - vector . The [ CLS ] output of the BERT model ( Devlin et al , 2019 ) is then fed into Naive Bayes , Linear SVM , MLP and bi - LSTM networks as above . Manual Syntactic Features For each of these models , we additionally experiment with manual syntactic features . We use the lexical features proposed by ( Dean et al , 2016 ) and extended lexical features by ( Zhang et al , 2019 ) , and take the five syntactic constraints on licensors of ellipsis explored by ( Khullar et al , 2019 ) for their rulebased approach as our slot pattern features . We concatenate all these features to the embeddings from the previous step and check if they improve the classification decision .
We define noun ellipsis resolution as a binary classification task where given a licensor , antecedent candidate and their context , the goal of the classifier is to predict whether the antecedent candidate is the resolution of the ellipsis licensed by the licensor . Formally , given a sentence s , the licensor l i from the detection step , and the antecedent candidate a j ; the noun ellipsis resolution task can be defined as follows : f ( a j , l i , s ) − { 0 , 1 } where 1 denotes that the antecedent candidate a j is the actual resolution of the ellipsis licensed by l i , and 0 otherwise . Embeddings Similar to the detection step , we take pretrained fastText word embeddings for the licensor , antecedent candidate and context , and sum pool to obtain a single vector . In case of BERT , we separate the sentence , the licensor and the antecedent candidate with a [ SEP ] token and follow the same steps as in the detection step .
We use POS tags of the licensor and modifier of the antecedent as our syntactic features and cosine similarity between their POS tags as our semantic features , following ( Khullar et al , 2019 ) . We concatenate these features to the embeddings to explore the efficacy of adding manual features on resolution .
We detection task , we take the annotated 946 positive samples ( exophoric ) and randomly choose 946 negative samples . Similarly , for the resolution task , we take 438 positive samples ( endophoric ) and 438 randomly chosen negative samples . We perform a standard 70 - 10 - 20 split to obtain the train , development and test set respectively , and follow the 5 - fold cross validation procedure to capture both classes properly in each case . For MLP , we take a simple , two - layer feedforward network ( FFNN ) or two layers of multiple computational units interconnected in a feed - forward way without loops . We have a single hidden layer with 768 neurons and a sigmoid function . A unidirectional weight connection exists between the two successive layers . The classification decision is made by turning the input vector representations of a word with its context into a score . The network has a softmax output layer . For bi - LSTM , we have embedding layer , time - distributed translate layer , Bi - LSTM ( RNN ) layer , batch normalization layer , dropout layer and prediction layer . The activation used is Softmax . The loss function is calculated with cross entropy . We train in batch sizes of 16 and early stopping with max epochs of 100 . In early stopping the patience is kept to be 10 and the optimizer used is Adam . We use default values for the learning rate . We use Keras ( Chollet et al , 2015 ) for coding the models .
We evaluate the performance of our models in terms of F1 - score , computed by taking an average F1 - scores obtained from the 5 - folds results . We experiment with sixteen models each for the noun ellipsis detection and resolution . The results on the testset for Precision , Recall and F1 - Score values are presented in Table .2 . As expected , the neural models perform significantly better than the statistical ones for both the subtasks . Our experiments show that for the detection task , BERT embeddings with a simple MLP gives best scores . This is expected because , BERT currently provides the most powerful contextual word representations , using 12 separate attention mechanism for each layer , where , at each layer , each token can focus on 12 distinct aspects of other tokens . Since Transformers ( Vaswani et al , 2017 ) use many distinct attention heads ( 12 * 12=144 for the base BERT model ) , each head can focus on a different kind of constituent combinations , making BERT broadly attending over the whole sentence . In our task , the ( Khullar et al , 2019 ) and the neural model presented in this paper . input and output , but they are not innately designed to capture temporal relationships within a sentence . Hence , although they perform well for a task like detection that needs local information , they are outperformed by bi - LSTMs on the resolution task that requires capturing a deeper relationship between the antecedent and the elided noun . We also note that manual feature addition boosts results greatly for all models , highlighting that ellipsis is a syntactically constrained phenomenon . We finally integrate the best models for each subtask into an end - to - end pipeline , as in Figure 2 . Now , instead of the gold vectors ( from the annotations ) , the resolution model is fed the ouput licensor vector from the detection model . This obviously results into error propagation into the second model , and lowers the precision value to 82.52 % , recall to 78.66 % and consequently , the F1 - score to 80.55 % of the final system . The error in the final system comes from failing to detect actual licensors , wrongly identifying non - licensor words and correct licensor detection but failed antecedent resolution . We run our final system on the curated dataset prepared by ( Khullar et al , 2019 ) and compare the results with their rule - based approach . As expected , this model improves the F1 - score by 16.55 % for noun ellipsis detection and 14.97 % for noun ellipsis res - olution . See Table 3 . The even higher accuracy on the curated dataset can be explained by the nature of the sentences in this dataset which are from textbooks , and , hence , free of grammatical errors , etc . - resulting into improved parser performance in the pre - processing step . Although , the presented models achieve high scores on both the tasks separately and in the pipeline process , the results can be further improved with hyper - parameter tuning and additional regularization .
We explored statistical and neural models for noun ellipsis detection and resolution , presenting a strong results for this task . As expected , neural classifiers perform significantly better than the statistical with the same input representation . As with several other NLP tasks , the contextual nature of BERT is useful for noun ellipsis resolution too , making robust predictions with simple neural classifiers . Finally , addition of manual features boosts the performance of all classifiers including those that use BERT , highlighting that ellipsis is a syntactically constrained phenomenon .
