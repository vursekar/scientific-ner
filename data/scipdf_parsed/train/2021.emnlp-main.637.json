{"authors": "Jiawei Chen; Hongyu Lin; Xianpei Han;  Le Sun", "pub_date": "", "title": "Honey or Poison? Solving the Trigger Curse in Few-shot Event Detection via Causal Intervention", "abstract": "Event detection has long been troubled by the trigger curse: overfitting the trigger will harm the generalization ability while underfitting it will hurt the detection performance. This problem is even more severe in few-shot scenario. In this paper, we identify and solve the trigger curse problem in few-shot event detection (FSED) from a causal view. By formulating FSED with a structural causal model (SCM), we found that the trigger is a confounder of the context and the result, which makes previous FSED methods much easier to overfit triggers. To resolve this problem, we propose to intervene on the context via backdoor adjustment during training. Experiments show that our method significantly improves the FSED on ACE05, MAVEN and KBP17 datasets.", "sections": [{"heading": "Introduction", "text": "Event detection (ED) aims to identify and classify event triggers in a sentence, e.g., detecting an Attack event triggered by fire in \"They killed by hostile fire in Iraqi\". Recently, supervised ED approaches have achieved promising performance (Chen et al., 2015;Nguyen and Grishman, 2015;Nguyen et al., 2016;Lin et al., 2018Lin et al., , 2019bDu and Cardie, 2020;Liu et al., 2020a;Lu et al., 2021), but when adapting to new event types and domains, a large number of manually annotated event data is required which is expensive. By contrast, fewshot event detection (FSED) aims to build effective event detectors that are able to detect new events from instances (query) with a few labeled instances (support set). Due to their ability to classify novel types, many few-shot algorithms have been used in FSED, e.g., metric-based methods like Prototypical Network (Lai et al., 2020;Deng et al., 2020;Cong et al., 2021).\nUnfortunately, there has long been a \"trigger curse\" which troubles the learning of event detec-They were killed by hostile [MASK] in Iraqi.\nThey were killed by hostile fire in Iraqi.\n1 or 0 tion models, especially in few-shot scenario (Bronstein et al., 2015;Liu et al., 2017;Chen et al., 2018;Liu et al., 2019;Ji et al., 2019). For many event types, their triggers are dominated by several popular words, e.g., the Attack event type is dominated by war, attack, fight, fire, bomb in ACE05. And we found the top 5 triggers of each event type cover 78% of event occurrences in ACE05. Due to the trigger curse, event detection models nearly degenerate to a trigger matcher, ignore the majority of contextual information and mainly rely on whether the candidate word matches the dominant triggers. This problem is more severe in FSED: since the given support instances are very sparse and lack diversity, it is much easier to overfit the trigger of the support instances. An intuitive solution for the trigger curse is to erase the trigger information in instances and forces the model to focus more on the context. Unfortunately, due to the decisive role of triggers, directly wiping out the trigger information commonly hurts the performance (Lu et al., 2019;Liu et al., 2020b). Some previous approaches try to tackle this problem by introducing more di-versified context information like event argument information (Liu et al., 2017(Liu et al., , 2019Ji et al., 2019) and document-level information (Ji and Grishman, 2008;Liao and Grishman, 2010;Duan et al., 2017;Chen et al., 2018). However, rich context information is commonly not available for FSED, and therefore these methods can not be directly applied.\nQuery E T C S Y E C T S Y Q(\nIn this paper, we revisit the trigger curse in FSED from a causal view. Specifically, we formulate the data distribution of FSED using a trigger-centric structural causal model (SCM) (Pearl et al., 2016) shown in Figure 1(a). Such trigger-centric formulation is based on the fact that, given the event type, contexts have a much lower impact on triggers, compared with the impact of triggers on contexts. This results in the decisive role of triggers in event extraction, and therefore conventional event extraction approaches commonly follow the triggercentric procedure (i.e., identifying triggers first and then using triggers as an indicator to find arguments in contexts). Furthermore, the case grammar theory in linguistics (Fillmore, 1967) also formulate the language using such trigger/predicate-centric assumption, and have been widely exploited in many NLP tasks like semantic role labeling (Gildea and Jurafsky, 2002) and abstract meaning representation (Banarescu et al., 2013).\nFrom the SCM, we found that T (trigger set) is a confounder of the C(context set) and the Y (result), and therefore there exists a backdoor path C \u2190 T \u2192 Y . The backdoor path explains why previous FSED models disregard contextual information: it misleads the conventional learning procedure to mistakenly regard effects of triggers as the effects of contexts. Consequently, the learning criteria of conventional FSED methods are optimized towards spurious correlation, rather than capturing causality between C and Y . To address this issue, we propose to intervene on context to block the information from trigger to context. Specifically, we apply backdoor adjustment to estimate the interventional distribution that is used for optimizing causality. Furthermore, because backdoor adjustment relies on the unknown prior confounder (trigger) distribution, we also propose to estimate it based on contextualized word prediction.\nWe conducted experiments on ACE05 1 , MAVEN 2 and KBP17 3 datasets. Experiments show that causal intervention can significantly alleviate trigger curse, and therefore the proposed method significantly outperforms previous FSED methods.", "n_publication_ref": 30, "n_figure_ref": 1}, {"heading": "Structural Causal Model for FSED", "text": "This section describes the structural causal model (SCM) for FSED, illustrated in Figure 1(a). Note that, we omit the causal structure of the query for simplicity since it is the same as the support set. Concretely, the SCM formulates the data distribution of FSED: 1) Starting from an event E we want to describe (in Figure 1(a) is an Attack in Iraqi).\n2) The path E \u2192 T indicates the trigger decision process, i.e., selecting words or phrases (in Figure 1(a) is fire) which can almost clearly express the event occurrence (Doddington et al., 2004). 3) The path E \u2192 C \u2190 T indicates that a set of contexts are generated depending on both the event and the trigger, which provides background information and organizes this information depending on the trigger. For instance, the context \"They killed by hostile [fire] in Iraqi\" provides the place, the role and the consequences of the event, and this information is organized following the structure determined by fire. 4) an event instance is generated by combining one of the contexts in C and one of the triggers in T via the path C \u2192 S \u2190 T . 5) Finally, a matching between query and support set is generated through S \u2192 Y \u2190 Q.\nConventional learning criteria for FSED directly optimize towards the conditional distribution P (Y |S, Q). However, from the SCM, we found that the backdoor path C \u2190 T \u2192 Y pass on associations (Pearl et al., 2016) and mislead the learning with spurious correlation. Consequently, the learning procedure towards P (Y |S, Q) will mistakenly regard the effects of triggers as the effects of contexts, and therefore overfit the trigger information.", "n_publication_ref": 3, "n_figure_ref": 2}, {"heading": "Causal Intervention for Trigger Curse", "text": "Based on the SCM, this section describes how to resolve the trigger curse via causal intervention. Context Intervention. To block the backdoor path, we intervene on the context C and the new context-intervened SCM is shown in Figure 1(b). Given support set s, event set e of s, context set C of s and query instance q, we optimize the interventional distribution P (Y |do(C = C), E = e, Q = q) rather than P (Y |S = s, Q = q), where do(\u2022) denotes causal intervention operation. By interven-ing, the learning objective of models changes from optimizing correlation to optimizing causality. Backdoor Adjustment. Backdoor adjustment is used to estimate the interventional distribution 4 :\nP (Y |do(C=C), E=e, Q=q) = t\u2208T s\u2208S P (Y |s, q)P (s|C, t)P (t|e),(1)\nwhere P (s|C, t) denotes the generation of s from the trigger and contexts. P (s|C, t) = 1/|C| if and only if the context of s in C and the trigger of s is t. P (Y |s, q) \u221d \u03c6(s, q; \u03b8) is the matching model between q and s parametrized by \u03b8.\nEstimating P (t|e) via Contextualized Prediction. The confounder distribution P (t|e) is unknown because E is a hidden variable. Since the event argument information is contained in C, we argue that P (t|e) \u221d M (t|C) where M (\u2022|C) indicates a masked token prediction task (Taylor, 1953) which is constructed by masking triggers in the support set. In this paper, we use masked language model to calculate P (t|e) by first generating a set of candidate triggers through the context:\nT c = {t i |i = 1, 2, . . .} \u222a {t 0 }\n, where t i is the i-th predicted token and t 0 is the original trigger of the support set instance, then P (t|e) is estimated by averaging logit obtained from the MLM:\nP (ti|e) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03bb i = 0 (1 \u2212 \u03bb) exp(li) j exp(lj) i = 0 (2)\nwhere l i is the logit for the i th token. To reduce the noise introduced by MLM, we assign an additional hyperparameter \u03bb \u2208 (0, 1) to t 0 .\nOptimizing via Representation Learning. Given the interventional distribution, FSED model can be learned by minimizing the loss function on it:\nL(\u03b8) = \u2212 q\u2208Q f (P (Y |do(C), e, q; \u03b8)) = \u2212 q\u2208Q f ( t\u2208T s\u2208S P (Y |s, q; \u03b8)P (s|C, t)P (t|e))(3)\nwhere Q is training queries and f is a strict monotonically increasing function. However, the optimization of L(\u03b8) needs to calculate every P (Y |s, q; \u03b8), which is quite time-consuming. To this end, we propose a surrogate learning criteria L SG (\u03b8) to optimize the causal relation based on representation learning: 4 The proof is shown in Appendix LSG(\u03b8) = \u2212 q\u2208Q g(R(q; \u03b8), t\u2208T s\u2208S P (s|C, t)P (t|e)R(s; \u03b8))\nHere R is a representation model which inputs s or q and outputs a dense representation. g(\u2022, \u2022) is a distance metric measuring the similarity between two representations. Such loss function is widely used in many metric-based methods (e.g., Prototypical Networks and Relation Networks). In the Appendix, we prove L SG (\u03b8) is equivalent to L(\u03b8).  2) FS-ClusterLoss (Lai et al., 2020), which add two auxiliary loss functions when training. Furthermore, we compare our method with models finetuned with support set (Finetune) and pretrained using the training set (Pretrain). BERT base (uncased) is used as the encoder for all models and MLM for trigger collection.", "n_publication_ref": 2, "n_figure_ref": 1}, {"heading": "Experimental Results", "text": "The performance of our method and all baselines is shown in Table 1. We can see that: 1) By intervening on the context in SCM and using backdoor adjustment during training, our method can effectively learn FSED models. Compared with the original metric-based models, our method achieves 8.7% and 1.6% micro-F1 (average) improvement in prototypical network and relation network respectively.\n2) The causal theory is a promising technique for resolving the trigger cruse problem. Notice that FS-LexFree cannot achieve the competitive performance with the original FS models, which indicates that trigger information is import and underfitting triggers will hurt the detection performance. This verifies that trigger curse is very challenging and causal intervention can effectively resolve it.\n3) Our method can achieve state-of-the-art FSED performance. Compared with best score in baselines, our method gains 7.5%, 1.0%, and 2.0% micro-F1 improvements on ACE05, MAVEN and KBP17 datasets respectively.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Effect on Different Settings", "text": "To further demonstrate the effectiveness of the proposed method, we also conduct experiments under different FSED settings: 1) The primal episodebased settings (Episode), which is the 5+1-way 5-shot settings in Lai et al. (2020). 2) Episode + ambiguous instances (Ambiguity), which samples some additional negative query instances that include words same as triggers in support set to verify whether models overfit the triggers.\nThe performance of different models with different settings is shown in Figure 2. We can see that: 1) Generally speaking, all models can achieve better performance on Episode because correctly recognize high-frequent triggers can achieve good performance in this setting. Consequently, the performance under this setting can not well represent how FSED is influenced by trigger overfitting. 2) The performance of all models dropped on Ambiguity setting, which suggests that trigger overfitting has a significant impact on FSED. 3) Our method still maintains good performance on Ambiguity, which indicates that our method can alleviate the trigger curse problem by optimizing towards the underlying causality.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "Case Study", "text": "We select ambiguous cases (in Table 2) to better illustrate the effectiveness of our method. For Query 1, FS-Base wrongly detects the word run to be a trigger word. In Support set 1, run means nomi-  nating while run means managing in Query 1. FS-Base fails to recognize such different sense of word under context. For Query 2, FS-Base makes mistake again on the ambiguous word suspect. Even though suspect is the noun form of suspected in Support set 2, it does not trigger a Suspicion event in Query 2. In contract to FS-Base, our approach is able to handle both cases correctly, illustrating its effectiveness.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Related Work", "text": "Causal Inference. Causal inference aims to make reliable predictions using the causal effect between variables (Pearl, 2009). Many studies have used causal theory to improve model robustness (Wang et al., 2020a,b;Qi et al., 2020;Tang et al., 2020b;Zeng et al., 2020). Recently, backdoor adjustment has been used to remove the spurious association brought by the confounder (Tang et al., 2020a;Yue et al., 2020;Zhang et al., 2021). Few-shot Event Detection. Few-shot event detection has been studied in many different settings. Bronstein et al. (2015) collect some seed triggers, then detect unseen event with feature-based method. Deng et al. (2020) decompose FSED into two subtasks: trigger identification and few-shot classification. Feng et al. (2020) adopt a sentence-level few-shot classification without triggers. Lai et al.\n(2020) and Cong et al. (2021) adopt N+1-way fewshot setting that is closest to our setting.", "n_publication_ref": 12, "n_figure_ref": 0}, {"heading": "Conclusions", "text": "This paper proposes to revisit the trigger curse in FSED from a causal view. Specifically, we identify the cause of the trigger curse problem from a structural causal model, and then solve the problem through casual intervention via backdoor adjustment. Experimental results demonstrate the effectiveness and robustness of our methods. ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "A Proof of Backdoor Adjustment", "text": "We prove the backdoor adjustment for our SCM using the rules of do-calculus (Pearl, 1995). For a causal graph G, let G X denote the graph where all of the incoming edges to Node X are removed. let G X denote the graph where all of the outgoing edges from Node X are removed. \u22a5 \u22a5 G denotes d-separation in G.\nD-separation (Pearl, 2014): Two (sets of) nodes X and Y are d-separation by a set of nodes Z (i.e. X \u22a5 \u22a5 G Y |Z) if all of the paths between (any node in) X and (any node in) Y are blocked by Z.\nThe rules of do-calculus are:\nRule 1 P (y|do(t), z, w) = P (y|do(t), w) if Y \u22a5 \u22a5 G T Z|T, W Rule 2 P (y|do(t), do(z), w) = P (y|do(t), z, w) if Y \u22a5 \u22a5 G T Z Z|T, W Rule 3 P (y|do(t), do(z), w) = P (y|do(t), w) if Y \u22a5 \u22a5 G T Z(W ) Z|T, W(5)\nwhere Z(W ) denotes the set of nodes of Z that aren't ancestors of any node of W in G T .\nWe can prove our interventional distribution P (Y |do(C = C), E = e):\nStep 1 Using the law of total probability: Step 2 Using the law of conditional probability:\nP (Y |do(C = C), E = e, Q = q) =t\u2208T\nP (Y |do(C = C), E = e, Q = q) = t\u2208T s\u2208S\n[P (Y |do(C), e, t, s, q)\u00d7 P (s|do(C), e, t, q)P (t|do(C), e, q)]\nStep 3 Using the Rule 3:\nP (Y |do(C = C), E = e, Q = q) = t\u2208T s\u2208S\n[P (Y |e, t, s, q)\u00d7 P (s|do(C), e, t, q)P (t|e, q)]\nStep 4 Using the Rule 1:\nP (Y |do(C = C), E = e, Q = q) = t\u2208T s\u2208S\nP (Y |s, q)P (s|do(C), t)P (t|e)\nStep 5 Using the Rule 2:\nP (Y |do(C = C), E = e, Q = q) = t\u2208T s\u2208S\nP (Y |s, q)P (s|C, t)P (t|e)", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "B Detailed Task Settings", "text": "One-way K-Shot Settings. We adopt One-way K-shot setting in our experiments, in which the support set in an episode contains one event type (called concerned event) and the query can contain any event type. The model aims to detect triggers of the concerned event in query and all types will be evaluated by traversing each event type. The support set and query in an episode can be formulated as follows:\nS = {(S 1 , E, Y 1 ), . . . , (S K , E, Y K )}\nwhere S is the support set, E is the concerned event, S i = {s i 1 , s i 2 , . . . , s i n i } is the i-th sentence in support, s i j is the j-th token in S i , Y i = {y i 1 , y i 2 , . . . , y i n } is the labels of tokens in S i and y i j = 1 only if t i is the trigger (or part of trigger) of concerned event, otherwise y i j = 0.\nQ = {Q 1 , Q 2 , . . . , Q M }\nwhere Q is the set of query and Q i = {q i 1 , q i 2 , . . . , q i m i } is the i-th query sentence and q i j is the j-th token in Q i\nThe model is expected to output the concerned event in Q:\nO Q = {(Q 1 , E, T 1 1 ), . . . , (Q 1 , E, T 1 n 1 ), (Q 2 , E, T 2 1 ), . . . , (Q 2 , E, T 2 n 2 ), . . . , (Q M , E, T M 1 ), . . . , (Q M , E, T M n M )}\nwhere O Q is the set of triggers of concerned event detected in Q, T i k is the k-th trigger of concerned event in sentence Q i and n i \u2265 0 means the number of triggers of concerned event in Q i .\nEvaluation We improve the traditional episode evaluation setting by evaluating the full test set. For each event type in test set, we randomly sample K instances as support set and all other instances are used as query. Following previous event detection works (Chen et al., 2015), the predicted trigger is correct if its event type and offsets match those of a gold trigger. We evaluate all methods using macro-F1 and micro-F1 scores, and micro-F1 is taken as the primary measure.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "C Few-shot Event Detection Baselines", "text": "We use two metric-base methods in our experiments: Prototypical network (Snell et al., 2017) and Relation network (Sung et al., 2018), which contain an encoder component and a classifier component.\nEncoder We use BERT (Devlin et al., 2019) to encoder the support set and the query. Given a sentece X = {x 1 , x 2 , . . . , x n }, BERT encodes the sequence and output the represent of each token in X: R = {r 1 , r 2 , . . . , r n }. After obtaining the feature representation of the support set, we calculate the prototype of the categories (concerned event and other):\np i = 1 |R i | r\u2208R i r, i = 0, 1\nwhere p i is the prototype of category i, R i is the set of feature representation of tokens that labeled with y = i in support set.\nClassifier The models classify each token in query based on its similarity to the prototype.\nWe first calculate the similarity between prototype and token in query.\ns i,j,k = g(p k , q i j ), k = 0, 1(6)\nwhere g(x, y) measures the similarity between x and y, q i j is the represent of j-th token in i-th query sentence.\nThen we calculate the probability distribution of token q i j :\nP (Y |q i j , S) = Softmax(s i,j,0 , s i,j,1 )(7)\nDuring training, we use the Cross-Entropy loss on each token of query. And the support set and the query are randomly sampled from the training set.\nWhen evaluating, we treat the labels as IO tagging schemes, and adjacent I are considered to be the same trigger so that we can handle a trigger with multiple tokens.\nSimilarity Functions For prototypical network, the similarity in Equation 6 is Euclidean distance. For relation network, we calculate similarity using neural networks. Unlike the original paper, we find the following calculation to be more efficient:\ng(p k , q j i ) = F (p k \u2295 q j i \u2295 |p k \u2212 q j i |)\nwhere \u2295 means concatenation vectors and F is two-layer feed-forward neural networks with a ReLU function on the first layer.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "D Proof of Loss Function", "text": "We prove L SG (\u03b8) is equivalent to L(\u03b8), which indicates that minimizing L SG (\u03b8) is equivalent to minimizing L(\u03b8). At first , we define a function \u03c6(s, q) \u221d P (Y |s, q; \u03b8) and then we need to prove that g( t\u2208T s\u2208S P (t|e)p(s|C, t)r s , q) = f ( t\u2208T s\u2208S P (t|e)P (s|C, t)\u03c6(s, q)).\nFrom Appendix-A, we can obtain: ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "E Implementation Details", "text": "All of our experiments are implemented on one Nvidia TITAN RTX. Our implementation is based on HuggingFace's Transformers (Wolf et al., 2019) and Allennlp (Gardner et al., 2018). We tune the hyperparameters based on the dev performance. We train each model 5 times with different random seed, and when evaluating, we sample 4 different support sets.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Metric-based Methods", "text": "The hyperparameter is shown in Table 5. During training, the support set and the query is sampled in training set, the query contains 2 positive instances and 10 negative instances (5 times of positive instances). During validating, the support set and the query is sampled in dev set, the query contains 10 positive instances and 100 negative instances (10 times of positive", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Acknowledgments", "text": "We thank the reviewers for their insightful comments and helpful suggestions. This research work is supported by National Key R&D Program of China under Grant 2018YFB1005100, the National Natural Science Foundation of China under Grants no. 62106251 and 62076233, and in part by the Youth Innovation Promotion Association CAS(2018141).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "", "text": "instances). The results of dev set are shown in Table 3. For FS-Causal, we found that there is an impact on whether backdoor adjustment is applied separately to the support set and query, as shown in Table 4. Based on the best results of the dev set, we evaluate it on the test set.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Finetuning-based Methods", "text": "The hyperparameter is shown in Table 6. For pretraining, we train a supervised event detection model using the training set. For finetuning, we use the support set to finetune the parameters of the event detection model and then detect the event in query.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Abstract Meaning Representation for sembanking", "journal": "", "year": "2013", "authors": "Laura Banarescu; Claire Bonial; Shu Cai; Madalina Georgescu; Kira Griffitt; Ulf Hermjakob; Kevin Knight; Philipp Koehn; Martha Palmer; Nathan Schneider"}, {"title": "Few-Shot Event Detection with Prototypical Amortized Conditional Random Field", "journal": "", "year": "2021", "authors": "Xin Cong; Shiyao Cui; Bowen Yu; Tingwen Liu; Wang Yubin; Bin Wang"}, {"title": "Metalearning with dynamic-memory-based prototypical network for few-shot event detection", "journal": "", "year": "2020", "authors": "Shumin Deng; Ningyu Zhang; Jiaojian Kang; Yichi Zhang; Wei Zhang; Huajun Chen"}, {"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "journal": "Long and Short Papers", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"title": "The automatic content extraction (ace) program-tasks, data, and evaluation", "journal": "", "year": "2004", "authors": "Alexis George R Doddington;  Mitchell; A Mark;  Przybocki; A Lance; Stephanie M Ramshaw; Ralph M Strassel;  Weischedel"}, {"title": "Event extraction by answering (almost) natural questions", "journal": "", "year": "2020", "authors": "Xinya Du; Claire Cardie"}, {"title": "Exploiting document level information to improve event detection via recurrent neural networks", "journal": "Long Papers", "year": "2017", "authors": "Ruifang Shaoyang Duan; Wenli He;  Zhao"}, {"title": "Probing and fine-tuning reading comprehension models for few-shot event extraction. CoRR, abs", "journal": "", "year": "2010", "authors": "Rui Feng; Jie Yuan; Chao Zhang"}, {"title": "The case for case", "journal": "", "year": "1967", "authors": "Charles Fillmore"}, {"title": "Allennlp: A deep semantic natural language processing platform", "journal": "CoRR", "year": "2018", "authors": "Matt Gardner; Joel Grus; Mark Neumann; Oyvind Tafjord; Pradeep Dasigi; Nelson F Liu; Matthew E Peters; Michael Schmitz; Luke Zettlemoyer"}, {"title": "Automatic labeling of semantic roles", "journal": "Computational linguistics", "year": "2002", "authors": "Daniel Gildea; Daniel Jurafsky"}, {"title": "Refining event extraction through cross-document inference", "journal": "", "year": "2008", "authors": "Heng Ji; Ralph Grishman"}, {"title": "Exploiting the entity type sequence to benefit event detection", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Yuze Ji; Youfang Lin; Jianwei Gao; Huaiyu Wan"}, {"title": "Extensively matching for few-shot learning event detection", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": ""}, {"title": "Using document level cross-event inference to improve event extraction", "journal": "Association for Computational Linguistics", "year": "2010", "authors": "Shasha Liao; Ralph Grishman"}, {"title": "Nugget proposal networks for Chinese event detection", "journal": "Association for Computational Linguistics", "year": "2018", "authors": "Hongyu Lin; Yaojie Lu; Xianpei Han; Le Sun"}, {"title": "Cost-sensitive regularization for label confusion-aware event detection", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Hongyu Lin; Yaojie Lu; Xianpei Han; Le Sun"}, {"title": "Sequence-to-nuggets: Nested entity mention detection via anchor-region networks", "journal": "", "year": "2019", "authors": "Hongyu Lin; Yaojie Lu; Xianpei Han; Le Sun"}, {"title": "Element intervention for open relation extraction", "journal": "", "year": "2021", "authors": "Fangchao Liu; Lingyong Yan; Hongyu Lin; Xianpei Han; Le Sun"}, {"title": "Exploiting the ground-truth: An adversarial imitation based knowledge distillation approach for event detection", "journal": "", "year": "2019", "authors": "Jian Liu; Yubo Chen; Kang Liu"}, {"title": "Event extraction as machine reading comprehension", "journal": "", "year": "2020", "authors": "Jian Liu; Yubo Chen; Kang Liu; Wei Bi; Xiaojiang Liu"}, {"title": "How does context matter? on the robustness of event detection with contextselective mask generalization", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Jian Liu; Yubo Chen; Kang Liu; Yantao Jia; Zhicheng Sheng"}, {"title": "Exploiting argument information to improve event detection via supervised attention mechanisms", "journal": "Association for Computational Linguistics", "year": "2017", "authors": "Shulin Liu; Yubo Chen; Kang Liu"}, {"title": "Distilling discrimination and generalization knowledge for event detection via deltarepresentation learning", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Yaojie Lu; Hongyu Lin; Xianpei Han; Le Sun"}, {"title": "Text2Event: Controllable sequence-tostructure generation for end-to-end event extraction", "journal": "Long Papers", "year": "2021", "authors": "Yaojie Lu; Hongyu Lin; Jin Xu; Xianpei Han; Jialong Tang; Annan Li; Le Sun; Meng Liao; Shaoyi Chen"}, {"title": "Joint event extraction via recurrent neural networks", "journal": "", "year": "2016", "authors": "Kyunghyun Thien Huu Nguyen; Ralph Cho;  Grishman"}, {"title": "Event detection and domain adaptation with convolutional neural networks", "journal": "Short Papers", "year": "2015", "authors": "Huu Thien; Ralph Nguyen;  Grishman"}, {"title": "Causal diagrams for empirical research", "journal": "Biometrika", "year": "1995", "authors": "Judea Pearl"}, {"title": "Causality", "journal": "Cambridge university press", "year": "2009", "authors": "Judea Pearl"}, {"title": "Probabilistic reasoning in intelligent systems: networks of plausible inference", "journal": "Elsevier", "year": "2014", "authors": "Judea Pearl"}, {"title": "Causal inference in statistics: A primer", "journal": "John Wiley & Sons", "year": "2016", "authors": "Judea Pearl; Madelyn Glymour; Nicholas P Jewell"}, {"title": "Two causal principles for improving visual dialog", "journal": "", "year": "2020", "authors": "Jiaxin Qi; Yulei Niu; Jianqiang Huang; Hanwang Zhang"}, {"title": "Prototypical networks for few-shot learning", "journal": "", "year": "2017", "authors": "Jake Snell; Kevin Swersky; Richard Zemel"}, {"title": "Learning to compare: Relation network for few-shot learning", "journal": "", "year": "2018", "authors": "Flood Sung; Yongxin Yang; Li Zhang; Tao Xiang; H S Philip; Timothy M Torr;  Hospedales"}, {"title": "Long-tailed classification by keeping the good and removing the bad momentum causal effect", "journal": "", "year": "2020-12-06", "authors": "Kaihua Tang; Jianqiang Huang; Hanwang Zhang"}, {"title": "Unbiased scene graph generation from biased training", "journal": "", "year": "2020", "authors": "Kaihua Tang; Yulei Niu; Jianqiang Huang; Jiaxin Shi; Hanwang Zhang"}, {"title": "cloze procedure\": A new tool for measuring readability", "journal": "Journalism quarterly", "year": "1953", "authors": "L Wilson;  Taylor"}, {"title": "Visual commonsense r-cnn", "journal": "", "year": "2020", "authors": "Tan Wang; Jianqiang Huang; Hanwang Zhang; Qianru Sun"}, {"title": "Visual commonsense representation learning via causal inference", "journal": "", "year": "2020", "authors": "Tan Wang; Jianqiang Huang; Hanwang Zhang; Qianru Sun"}, {"title": "MAVEN: A Massive General Domain Event Detection Dataset", "journal": "", "year": "2020", "authors": "Xiaozhi Wang; Ziqi Wang; Xu Han; Wangyi Jiang; Rong Han; Zhiyuan Liu; Juanzi Li; Peng Li; Yankai Lin; Jie Zhou"}, {"title": "Huggingface's transformers: State-of-the-art natural language processing", "journal": "", "year": "1910", "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R\u00e9mi Louf"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure1: Illustration of the causal intervention strategy proposed in this paper. The graph includes the event E, the trigger set T , the context set C, the support instance S, the prediction Y and the query instance Q.", "figure_data": ""}, {"figure_label": "", "figure_type": "", "figure_id": "fig_1", "figure_caption": "s\u2208S [P (Y |do(C), e, t, s, q)\u00d7 P (s, t|do(C), e, q)]", "figure_data": ""}, {"figure_label": "", "figure_type": "", "figure_id": "fig_2", "figure_caption": "PPFor prototypical network, g(r, q) = (r \u2212 q) 2 . Let \u03c6(s, q) = |r s \u2212 q| and f (x) = x 2 , x > 0. g(t\u2208T s\u2208S P (t|e)p(s|C, t)r s , q) =[ t\u2208T s\u2208S P (t|e)p(s|C, t)r s \u2212 q] (t|e)P (s|C, t)\u03c6(s, q)] \u221df (P (Y |do(C = C), E = e, Q = q)) D.2 Relation Network Let g(r, q) = F [r \u2295 q \u2295 |r \u2212 q|]. Let \u03c6(s, q) = g(r s , q) and f (x) = x g( t\u2208T s\u2208S P (t|e)P (s|C, t)r s , q) (t|e)P (s|C, t)\u03c6(s, q)]\u221df (P (Y |do(C = C), E = e, Q = q))Here, we assume that the feature representations of the same event type in support are close to each other so that | s p s r s \u2212 s p s q| \u2248 s p s |r s \u2212 q|.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "We randomly sample few instances as support set and all other instances in the test set are used as queries. A support set corresponds to an event type and all types will be evaluated by traversing each event type. Models need to detection the span and type of triggers in a sentence. We also compared the results across settings in Section 4.3. We evaluate all methods using macro-F1 and micro-F1 scores, and micro-F1 is taken as the primary measure.Finetune 51.0\u00b11.4 58.2\u00b11.6 30.7\u00b11.5 31.6\u00b12.3 59.4\u00b11.9 62.7\u00b11.8 Finetune* 39.9\u00b11.1 45.5\u00b10.7 20.8\u00b11.0 20.6\u00b10.8 45.0\u00b10.7 47.3\u00b10.6 Pretrain+Finetune 22.9\u00b16.0 20.3\u00b14.3 20.9\u00b14.6 16.9\u00b15.2 35.1\u00b15.9 30.1\u00b15.5 Pretrain+Finetune* 14.6\u00b13.3 15.6\u00b13.4 12.5\u00b13.8 14.9\u00b14.0 23.4\u00b16.8 25.8\u00b16.3 9\u00b11.5 69.4\u00b12.0 44.2\u00b11.2 44.0\u00b11.2 65.5\u00b12.3 67.1\u00b12.4 FS-Causal (Ours) 73.0\u00b12.2 76.9\u00b11.4 52.1\u00b10.2 55.0\u00b10.4 70.9\u00b10.6 73.2\u00b10.9 Ours) 67.2\u00b11.4 71.8\u00b11.9 53.0\u00b10.5 57.0\u00b10.9 66.4\u00b10.4 72.0\u00b10.6", "figure_data": "ACE05MAVENKBP17ModelMacroMicroMacroMicroMacroMicroFinetuing-basedFS-Base63.8\u00b12.8 67.3\u00b12.7 44.7\u00b11.4 44.5\u00b12.0 65.5\u00b12.7 67.3\u00b13.1Prototypical NetFS-LexFree52.7\u00b12.9 53.9\u00b13.2 25.6\u00b11.0 21.8\u00b11.4 60.7\u00b12.5 61.4\u00b12.8FS-ClusterLoss FS-Base 64.Relation Net 65.7\u00b13.7 68.7\u00b14.5 52.4\u00b11.4 56.0\u00b11.4 67.2\u00b11.5 71.2\u00b11.4 FS-LexFree 59.3\u00b13.5 60.1\u00b13.9 43.8\u00b11.9 45.9\u00b12.4 61.9\u00b12.4 65.4\u00b12.8FS-ClusterLoss57.6\u00b12.3 60.2\u00b13.2 46.3\u00b11.1 51.8\u00b11.4 56.8\u00b13.0 62.1\u00b12.5FS-Causal (4 Experiments4.1 Experimental SettingsDatasets. 5 We conducted experiments onACE05, MAVEN (Wang et al., 2020c) and KBP17datasets. We split train/dev/test sets accordingto event types and we use event types with moreinstances for training, the other for dev/test. Toconduct 5-shot experiments, we filter event typesless than 6 instances. Finally, for ACE05, itstrain/dev/test set contains 3598/140/149 instancesand 20/10/10 types respectively, for MAVEN, thoseare 34651/1494/1505 instances and 120/45/45types, for KBP17, those are 15785/768/792instances and 25/13/13 types.Task Settings. Different from episode evaluationin Lai et al. (2020) and Cong et al. (2021), weemploy a more practical event detection settinginspired by Yang and Katiyar (2020) in Few-shotNER. Baselines. We conduct experiments on twometric-based methods: Prototypical Network(Snell et al., 2017) and Relation Network (Sunget al., 2018), which are referred as FS-Base. Basedon these models, we compare our causal interven-tion method (FS-Casual) with 1) FS-LexFree (Luet al., 2019), which address overfit triggers via ad-versarial learning, we use their lexical-free encoder;"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "F1 score of 5-shot FSED on test set. * means fixing the parameters of encoder when finetuning. \u00b1 is the standard deviation of 5 random training rounds.", "figure_data": "FS-BaseFS-ClusterFS-Causal807570656055EpisodeAmbiguityOurs"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Support set 1 I mean , I 'd like to --I 'd like to see the Greens [Nominate]run[/Nominate] David Cobb again. Query 1 Release a known terrorist to run the PLO and that will bring about peace FS-Base Release a known terrorist to [Nominate]run[/Nominate] the PLO and that will bring about peace FS-Causal Release a known terrorist to run the PLO and that will bring about peace Support set 2 They were [Suspicion]suspected[/Suspicion] of having facilitated the suicide bomber. Query 2 A fourth suspect, Osman Hussein, was arrested in Rome, Italy, and later extradited to the UK. FS-Base A fourth [Suspicion]suspect[/Suspicion], Osman Hussein, was arrested in Rome, Italy, and later extradited to the UK. FS-Causal A fourth suspect, Osman Hussein, was arrested in Rome, Italy, and later extradited to the UK.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Ambiguous cases from ACE05 and MAVEN test set. The results are based on prototypical network and Support set means one instance in the support set.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Yi Yang and Arzoo Katiyar. 2020. Simple and effective few-shot named entity recognition with structured nearest neighbor learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6365-6375, Online. Association for Computational Linguistics.", "figure_data": "Zhongqi Yue, Hanwang Zhang, Qianru Sun, and Xian-Sheng Hua. 2020. Interventional few-shot learning.In Advances in Neural Information Processing Sys-tems 33: Annual Conference on Neural InformationProcessing Systems 2020, NeurIPS 2020, December6-12, 2020, virtual.Xiangji Zeng, Yunliang Li, Yuchen Zhai, and YinZhang. 2020. Counterfactual generator: A weakly-supervised method for named entity recognition. InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 7270-7280, Online. Association for Computa-tional Linguistics.Dong Zhang, Hanwang Zhang, Jinhui Tang, Xian-Sheng Hua, and Qianru Sun. 2020. Causal interven-tion for weakly-supervised semantic segmentation.In Advances in Neural Information Processing Sys-tems 33: Annual Conference on Neural InformationProcessing Systems 2020, NeurIPS 2020, December6-12, 2020, virtual.Wenkai Zhang, Hongyu Lin, Xianpei Han, and Le Sun.2021. De-biasing distantly supervised named en-tity recognition via causal intervention. In Proceed-ings of the 59th Annual Meeting of the Associationfor Computational Linguistics and the 11th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 1: Long Papers), pages 4803-4813,Online. Association for Computational Linguistics.Ofer Bronstein, Ido Dagan, Qi Li, Heng Ji, and AnetteFrank. 2015. Seed-based event trigger labeling:How far can event descriptions get us? In Proceed-ings of the 53rd Annual Meeting of the Associationfor Computational Linguistics and the 7th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 2: Short Papers), pages 372-376,Beijing, China. Association for Computational Lin-guistics.Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, andJun Zhao. 2015. Event extraction via dynamic multi-pooling convolutional neural networks. In Proceed-ings of the 53rd Annual Meeting of the Associationfor Computational Linguistics and the 7th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 1: Long Papers), pages 167-176,Beijing, China. Association for Computational Lin-guistics.Yubo Chen, Hang Yang, Kang Liu, Jun Zhao, andYantao Jia. 2018. Collective event detection via ahierarchical and bias tagging networks with gatedmulti-level attention mechanisms. In Proceedings ofthe 2018 Conference on Empirical Methods in Nat-ural Language Processing, pages 1267-1276, Brus-sels, Belgium. Association for Computational Lin-guistics."}], "doi": "10.18653/v1/2021.findings-acl.3"}