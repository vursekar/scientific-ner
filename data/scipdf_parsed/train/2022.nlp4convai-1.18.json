{"authors": "Seungju Han; Beomsu Kim; Seokjun Seo; Enkhbayar Erdenee; Buru Chang;  Hyperconnect", "pub_date": "", "title": "Understanding and Improving the Exemplar-based Generation for Open-domain Conversation", "abstract": "Exemplar-based generative models for opendomain conversation produce responses based on the exemplars provided by the retriever, taking advantage of generative models and retrieval models. However, due to the oneto-many problem of the open-domain conversation, they often ignore the retrieved exemplars while generating responses or produce responses over-fitted to the retrieved exemplars. To address these advantages, we introduce a training method selecting exemplars that are semantically relevant to the gold response but lexically distanced from the gold response. In the training phase, our training method first uses the gold response instead of dialogue context as a query to select exemplars that are semantically relevant to the gold response. And then, it eliminates the exemplars that lexically resemble the gold responses to alleviate the dependency of the generative models on that exemplars. The remaining exemplars could be irrelevant to the given context since they are searched depending on the gold response. Thus, our training method further utilizes the relevance scores between the given context and the exemplars to penalize the irrelevant exemplars. Extensive experiments demonstrate that our proposed training method alleviates the drawbacks of the existing exemplar-based generative models and significantly improves the performance in terms of appropriateness and informativeness. \u2020 Equal contribution * Corresponding author Given context A: Do you ever feel like time is just going by way too fast? Retrieved exemplar B: It's hard to get anything done with coworkers around. Generated responses B: Do you have any hobbies that you like to do while you're at work? like gardening? (a) RetNRef (Weston et al, 2018) B: It's hard to get things done with coworkers when you're busy all the time. (c) RetNRef w/ CORGE (Ours) B: OMG! especially recently. a week seems like one day. A: Yes! Time especially goes by fast when I'm working at my job. I'm constantly busy. B: It's hard to get around. anything done with coworkers gets to get done with anything.", "sections": [{"heading": "Introduction", "text": "Exemplar-based generative models (Wu et al., 2019;Cai et al., 2019b;Gupta et al., 2021) for open-domain conversation combine a retrieval model (Humeau et al., 2019;Mazare et al., 2018;Kim et al., 2021) and a generative model (Adiwardana et al., 2020;Roller et al., 2021; Figure 1: Responses generated by the three exemplarbased generative models. RetNRef ignores the exemplar during response generation, RetNRef \u03b1 generates the response highly over-fitted to the exemplar, and RetNRef trained with our training method (CORGE) well utilizes the exemplar to produce a more fluent response than that of the others. Zhang et al., 2020;Brown et al., 2020) into a single framework to generate responses in two steps:\n(1) the retriever searches an exemplar using the given context as a query, and (2) the generator produces a response based on the given context and the retrieved exemplar. Exemplar-based generative models produce more specific responses than vanilla generative models while being more fluent than retrieval models.\nDespite their success, exemplar-based generative models have two major shortcomings. Primitive exemplar-based generative models Cai et al., 2019a) tend to entirely ignore the exemplars and produce responses similar to those of vanilla generative models. This is due to the one-to-many problem (Li et al., 2016) where there are many possible responses for each dialogue context. During the training phase, the retrieved exemplar is not helpful for generating the gold response when the exemplar retrieved for the given context is significantly different from the gold response. This leads exemplar-based generative models to ignore the exemplar while generating responses, as shown in Figure 1(a). To address this issue, recent exemplar-based generative models utilize the gold response (Roller et al., 2021) or the slightly perturbed gold response (Cai et al., 2019b) as an exemplar in the training phase. However, these training methods cause the generator to rely heavily on the retrieved exemplar, i.e. the generator resorts to copying the provided tokens, as shown in Figure 1(b). These two disadvantages of existing exemplar-based generative models can adversely affect the quality of the generated response.\nTherefore, we introduce CORGE (COnnecting Retriever and GEnerator), a simple training method of exemplar-based generative models considering the one-to-many problem of the open-domain conversation. As inspired by Wu et al. (2019), CORGE first utilizes the gold response instead of dialogue context as the query for the retriever to select exemplars that are similar to the gold response. The retrieved exemplars ensure that exemplar-based generative models utilize their semantics while generating the gold response at the training phase. Since the exemplars are retrieved by the gold response, some of them are lexically identical or too similar to the gold response. These exemplars lead exemplar-based generative models to be trained to depend on the exemplar heavily. Thus, CORGE then eliminates the exemplars based on the distance between the exemplars and the gold response to alleviate the dependency of the generative models on the exemplars. Here, we employ Jaccard similarity to measure the distance (Guu et al., 2018;Cai et al., 2019a;Wu et al., 2019). However, as the selected exemplars solely depend on the gold response, some of them may be irrelevant to the given context, which results in exemplar-based generative models still ignoring the retrieved exemplar. To solve this, CORGE utilizes the relevance scores between the context and the exemplar to weight the relevant exemplars and penalizes irrelevant exemplars to the given context. Extensive experiments show that CORGE is generally applicable to the existing exemplar-based generative models and improves the quality of generated responses regarding appropriateness and informativeness.", "n_publication_ref": 19, "n_figure_ref": 3}, {"heading": "Our main contributions:", "text": "(1) We analyze the shortcomings of existing exemplar-based generative models derived from the nature of the opendomain conversation, the one-to-many problem.\n(2) We introduce a training method (CORGE) to improve the quality of generated responses by selecting useful exemplars and weighting the exemplars by relevance scores assessed by the retriever.\n(3) Through the human evaluation, we demonstrate that CORGE significantly improves the performance of exemplar-based generative models in terms of appropriateness and informativeness.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Related Work", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Exemplar-based Generation", "text": "While generative models have shown remarkable performance on the open-domain conversation, it is well-known that generative models tend to yield uninformative and bland responses (Li et al., 2016;Liu et al., 2016;Serban et al., 2017;Li et al., 2020;Holtzman et al., 2019;Welleck et al., 2019). Exemplar-based generative models are introduced to overcome the aforementioned problem generative models suffer. Wu et al. (2019) introduce an exemplar-based generative model for open-domain conversation, which retrieves a context-exemplar pair conditioned by the input context and encodes the lexical difference between the input context and the retrieved context to the edit vector. The response is produced by feeding the exemplar and the edit vector to the generator. ; Roller et al. (2021) also retrieve the exemplar using the given context as a query and concatenate the exemplar with the context, then feed the concatenated exemplar into the generator to produce the final response for the open-domain conversation. Cai et al. (2019a,b) propose a method that removes the irrelevant information from the exemplar, then uses the masked exemplar to inform the generator to produce the response. Gupta et al. (2021) condition the generator with the retrieved exemplars and the extracted semantic frames of the exemplars, which improves the coherence of generated responses. We do not consider this model as a baseline because their model requires an additional semantic frame extractor, and it can be mutually complemented with our proposed training method.", "n_publication_ref": 10, "n_figure_ref": 0}, {"heading": "Knowledge-grounded Generation", "text": "Knowledge-grounded generation models that utilize retrieved results (e.g., relevant documents from Wikipedia) to generate informative responses have been proposed to perform knowledge-intensive NLP tasks (e.g., open-domain question answering). The knowledge-grounded generation has a similar form with the exemplar-based generation. However, the main difference is that knowledgegrounded generative models extract the knowledge from external resources to generate the informative response. Guu et al. (2020) show the effectiveness of pre-training a knowledge retriever with the largescale language model for open-domain question answering, and Lewis et al. (2020) demonstrate that knowledge-grounded generative models produce more informative and diverse sentences than vanilla generative models on a wide range of knowledgeintensive NLP tasks. Fan et al. (2021) similarly propose a knowledge-grounded generative model for response generation, but they do not focus on the open-domain conversation. In Method Section, we demonstrate the difference between our approach and knowledge-grounded generative models, and we show that existing knowledge-grounded generative models are not directly applicable to the open-domain conversation in Experiments Section.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Preliminaries", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Exemplar-based Generation", "text": "Let D = {(c i , r i ) | 1 \u2264 i \u2264 n} denote the dialogue dataset, which consists of n pairs of context c and response r. Exemplar-based generative models are composed of two components: a retriever R and a generator G. For a given context c i , the retriever finds the top-scoring exemplar based on the relevance score S R (z, c i ) of the exemplar z \u2208 R , where R is a pre-defined response set. The generator computes the probability of the response for the context c i while utilizing the exemplar z as P G (r|c i , z).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Drawbacks of Existing Exemplar-based Generative models", "text": "As mentioned in Roller et al. (2021), the primitive exemplar-based generative model  tends to ignore the retrieved exemplar dur-ing response generation due to the one-to-many problem in open-domain conversation (Li et al., 2016). Since its retriever searches an exemplar based on a given context, the retrieved exemplar is often significantly different from a gold response of the generator, although both of the retrieved exemplar and gold response are relevant to the given context, which is shown in Figure 2(a). As the retrieved exemplar is not helpful for generating the gold response, the generator is trained to ignore the retrieved exemplar and to produce a response using only the given context. To induce the generator to utilize retrieved exemplars more actively, Roller et al. ( 2021) make use of the gold response, and Cai et al. (2019b) use perturbed gold response as an exemplar rather than using retrieved exemplars during the model training. However, since the exemplar z i and the gold response r i are too similar (as shown in Figure 2(b)), the exemplar-based generative model learns to rely overly on the exemplar. Eventually, the generator produces a highly over-fitted response to the exemplar by directly copying the tokens of the exemplar.", "n_publication_ref": 4, "n_figure_ref": 1}, {"heading": "Method", "text": "We hypothesize that selecting semantically relevant but lexically distanced exemplars from the gold response could solve the drawbacks above. To validate this hypothesis, we introduce a training method of exemplar-based generative models, called CORGE. Our proposed training method is illustrated in Figure 3, and the illustrative examples about the exemplars selected by CORGE are described in Table 1.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Selecting Exemplars Semantically", "text": "Relevant but Lexically Distanced to the Gold Response\nWe describe how CORGE selects semantically relevant but lexically distanced exemplars to the gold response. Conventionally, the retriever selects the exemplars z based on the relevance score S R (z, c i ) for the given context c i . However, this searching process could return a significantly different exemplar z from the gold response r i , and it induces the generator G to ignore the retrieved exemplar during response generation. Therefore, we select exemplars based on the gold response r i to ensure that the generator G utilizes the exemplars inspired by Wu et al.. We select top-k scoring exemplars based on the score S R \u2032 (z, r i ), which we call k-Nearest Exemplars (kNE). 1 These kNE are more semantically related to the gold response r i than the exemplar obtained by using S R (z, c i ).\nHowever, some of the selected kNE are lexically identical or too close to the gold response r unintentionally since the retriever searches the exemplars based on the gold response. We observe that using these exemplars also causes the overfitting problem of generated responses; therefore, the generator excessively copies tokens from the exemplars. From this, we are motivated to filter out the exemplars which are lexically too close to the gold response and preserve the exemplars properly distanced to the gold response to mitigate the over-fitting problem. Here, we employ Jaccard similarity to measure the lexical similarity (Guu et al., 2018;Cai et al., 2019a;Wu et al., 2019) between the exemplar and the gold response. Exemplars are filtered out when their Jaccard distance with the gold response r is larger than 0.6, and we replace them with the randomly chosen responses from the pre-defined response set R. The threshold of filtering is empirically chosen as 0.6. The set of the final exemplars z obtained through these steps is referred to as\nZ i = {z i,1 , z i,2 , \u2022 \u2022 \u2022 , z i,k }.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Weighting the Selected Exemplars based on the Relevance Score", "text": "As we select the exemplar totally based on the gold response, some of kNE could be relevant to the gold response r i but irrelevant to the given context c i . Therefore, we condition the generator with the relevance score of kNE to reward the relevant exemplars and penalize irrelevant exemplars. Using the retriever R, we calculate the relevance score S R (z i,j , c i ) per each selected exemplar z i,j , then apply the softmax function to the relevance score to 1 Note that S R (z, c) and S R \u2032 (z, ri) use the same retriever, but they are computed differently. Please refer to how we calculate the score S R \u2032 (z, ri) and S R (z, c) in the Supplementary Materials. obtain the normalized relevance score P R (z i,j , c i ).\nThen we replace the traditional likelihood with the weighted likelihood using the normalized score.\nOur final training objective is to minimize the loss function L = n i=1 L(r i , c i ) where:\nL(ri, ci) = \u2212 log z\u2208Z i P R (z, ci)P G (ri|ci, z) (1)\nThe gradient of the generator G is calculated as follows:\n\u2207 G L(ri, ci) = \u2212\u03b1 \u2022 z\u2208Z i P R (z, ci)\u2207 G (P G (ri|ci, z)), (2)\nwhere \u03b1 \u22121 = z\u2208Z i P R (z, c i )P G (r i |c i , z). This equation demonstrates that the gradient of the generator G is scaled by the normalized relevance score P R (z, c i ), which indicates that the generator is less updated when the retrieved exemplar z is not relevant to the given context c i . This procedure helps the model ignore the irrelevant exemplars. Thus, the generator learns to fetch tokens from the exemplar more easily, which is relevant to the gold response. Difference between CORGE and Knowledgegrounded generative models The way of leveraging the relevance scores is already employed by knowledge-grounded generative models (Lewis et al., 2020;Sachan et al., 2021) in open-domain question answering. However, there is a significant difference between our CORGE and knowledgegrounded generative models. CORGE uses the relevance score P R (z, c i ) to penalize the irrelevant exemplars z to the given context c i since the exemplars are retrieved by S R \u2032 (z, r i ). Knowledgegrounded generative models use it as the latent variable to jointly train the retriever R and generator G. Especially, knowledge-grounded generative models also tend to ignore the retrieved exemplars due  Context Retrieval indicates the exemplar retrieved by using the context as a query, and kNE shows the exemplars selected by using the gold response as a query.\nSim measures the lexical similarity between the gold response and the exemplar and P R (z, c) indicates the normalized relevance score calculated by retriever.\nto the one-to-many nature in open-domain conversation when the retriever and generator are jointly trained. On the other hand, we do not perform the joint learning of the retriever and the generator, but freeze the retriever while training the generator.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Experiments", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Dataset", "text": "We utilize the following four datasets used in Roller et al. (2021), which are Blended Skill Talk (BST) (Smith et al., 2020), ConvAI2 (Zhang et al., 2018), Empathetic Dialogues (ED) (Rashkin et al., 2019), and Wizard of Wikipedia (WoW) . To simplify the notation, we denote the concatenated version of these four datasets as BST+. We split BST+ into train, validation, and test sets following Smith et al. (2020).", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "Baselines", "text": "Retrieval and Generative Models Bi-encoder 256M (Mazare et al., 2018) and Blender 90M (Roller et al., 2021) are considered as a baseline retrieval model and a baseline generative model. Further, they are also employed as a retriever and a generator of the following exemplarbased generative baselines, respectively.  (Roller et al., 2021), and MatToGen (Cai et al., 2019b), as baselines.\nRetNRef concatenates the retrieved exemplar with the given context as the input of the generator to produce the response. RetNRef \u03b1 is the dialogue retrieval version of RetNRef, which adopts \u03b1-blending to escape from simply ignoring the retrieved exemplars (\u03b1 = 0.5). MatToGen extracts the meaningful tokens from the exemplar to provide them to the generator.\nTo verify the effectiveness of our training method, we apply CORGE to RetNRef and Mat-ToGen instead of their training method. They are denoted as RetNRef +CORGE and MatTo-Gen+CORGE, respectively.\nKnowledge-grounded Generative Models Although RAG (Lewis et al., 2020) and KIF (Fan et al., 2021) are proposed to perform knowledgegrounded generation tasks, we employ RAG and KIF as baselines since they have a similar form with exemplar-based generative models. Our experiments demonstrate that these knowledge-grounded generative models cannot be directly applied to the open-domain conversation.", "n_publication_ref": 6, "n_figure_ref": 0}, {"heading": "Evaluation Metrics", "text": "To verify the effectiveness of our training method CORGE, we conduct a pair-wise comparison through the human evaluation following . We use two criteria: Appropriateness and Informativeness. Appropriateness measures how the generated response is fluent, logical, and appropriate to the given context. Informativeness measures how the generated response has meaningful information relevant to the given context. We use Amazon Mechanical Turk to collect the annotations, and more details are described in the Supplementary Material.\nWe also employ the automatic evaluation metrics, Perplexity (PPL), Dist-n, and BLEU (Papineni et al., 2002), to analyze the generated responses of each model. PPL measures how well the model predicts a response based on the given input context, and lower PPL indicates that the model predicts the response better. To analyze how much the exemplar-based generative model leverages the retrieved exemplar, we introduce two variants of PPL by utilizing conditional probability when exemplars are given: (1) PPL gold uses the  conditional probability P G (r|c, r), which assumes the situation when the gold response is given as an exemplar, and (2) PPL ret uses the conditional probability P G (r|c, z) where z is the retrieved exemplar by using S R \u2032 (z, r). Lower PPL gold denotes that the exemplar-based generative model predicts the gold response well when the gold response is given as an exemplar. Lower PPL ret indicates that the exemplar-based generative model well leverages the provided exemplar to predict the gold response. Dist-n (Li et al., 2016) is the ratio of distinct ngrams to a total number of n-grams for all the generated responses, which measures the degree of the diversity of the generated responses. BLEU (z,r) is adopted to measure the degree of the token overlap between the provided exemplar and the generated response pair (z, r). A higher BLEU (z,r) score indicates that the generator copies more from the provided exemplar while generating the response.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Implementation Details", "text": "We provide the details of our implementation in the Supplementary Material. We will the source codes of CORGE for the reproducibility of the conducted experiments.\n6 Experimental Results  PPL ret than RetNRef +CORGE. This result demonstrates that RetNRef \u03b1 does not make good use of the retrieved exemplar except when the gold response is given as the retrieved exemplar. From this observation, we claim that RetNRef \u03b1 generates a response highly over-fitted to the selected exemplar, which is caused by utilizing the gold response as an exemplar in the training phase. The same goes for MatToGen, where applying CORGE mitigates the over-fitting issue.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Pair-wise Comparison Results", "text": "Higher Dist-n of RetNRef +CORGE and Mat-ToGen+CORGE compared to Blender 90M shows that our exemplar-based generative models produce more diverse responses than the vanilla generative model. Moreover, RetNRef +CORGE has higher Dist-n than RetNRef, which shows that utilizing the exemplars helps the generator diversify the responses. Although RetNRef \u03b1 is the only one that achieves comparable Dist-n to that of the vanilla retrieval model, Bi-encoder 256M, it is derived from an over-fitting to the exemplar considering the gap between PPL gold and PPL ret , resulting in the degradation of appropriateness and informativeness in human evaluation.\nAverage BLEU (z,r) scores implicitly measure the overlap between the retrieved exemplar and the generated response; thus, a higher degree of BLEU (z,r) indicates that the generator depends more on the retrieved exemplar. RetNRef shows a negligible BLEU (z,r) score, which reaffirms that the model is almost not utilizing the retrieved exemplar. RetNRef \u03b1 and MatToGen have higher BLEU (z,r) scores compared to RetNRef +CORGE and MatToGen+CORGE, respectively, which verifies that the former depends more on the retrieved exemplar than the latter.  ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Incapability of Knowledge-grounded Generative Models in Open-domain Conversation", "text": "The automatic evaluation results in Table 3 confirm that knowledge-grounded generative models are ignoring the exemplar. PPL gold , PPL ret , and Dist-n of RAG and KIF have a similar degree to those of Blender 90M, which implies that the exemplars are not providing useful information while generating the response. The average BLEU (z,r) score also has a poor degree, indicating almost no overlap between the retrieved exemplars and the generated responses. We explain that these results are originated from the difference between the open-domain conversation and knowledge-grounded generation tasks. While training knowledge-grounded generative models, they use P R (z, c) to fetch the external knowledge. However, the generator also ignores the retrieved exemplar due to the one-to-many nature of the open-domain conversation.\nIn addition, we observe that jointly training the retriever with the generator causes the retriever stuck in the local minima. As shown in Figure 4, the standard deviation of normalized relevance scores P R (z, c) computed by the retriever   almost gets near zero when the retriever of RAG is jointly trained. A smaller standard deviation means the relevance scores are getting flattened.\nAlthough knowledge-grounded generative models empirically have shown that jointly training the retriever and generator improves the performance in knowledge-intensive NLP tasks (Lewis et al., 2020), in open-domain conversation, the retrieved exemplars are ignored. Thus, the retriever learns to produce an uninformative relevance score. As a result, the retriever collapses, which means the retriever may return inappropriate exemplars to the generator (also shown in the example of KIF and RAG in Table 4). Intriguingly, jointly training the retriever with CORGE also causes the retriever scores to be flattened, as shown in Figure 4, and we empirically observe the minor collapse of the retriever as we experienced in RAG as well. Thus, CORGE does not jointly train the retriever.", "n_publication_ref": 2, "n_figure_ref": 2}, {"heading": "Ablation Study", "text": "To verify the effectiveness of each component in CORGE, we conduct the ablation study. In Table 5 A Implementation Details", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "A.1 How the Retriever Calculates the Scores", "text": "Our retriever follows the architecture of Biencoder (Mazare et al., 2018), and the score S R (z, c) and S R \u2032 (z, r) are calculated as follows:\nS R (z, c) = d(z) \u2022 q(c), S R \u2032 (z, r) = d(z) \u2022 d(r), d(z) = BERT r (z), d(r) = BERT r (r), q(c) = BERT c (c),(3)\nwhere d(z) and d(r) are encoded vectors produced by response encoder BERT r and q(c) is an encoded vector produced by context encoder BERT c . The notation R \u2032 indicates that it only uses the response encoder instead of using the context encoder together. CORGE is not limited to use Bi-encoder as a retriever and can be applied to other types of a retriever (e.g. Poly-encoder (Humeau et al., 2019)).", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "A.2 Model Details", "text": "As we mentioned in Section 5.2, we employ Biencoder 256M and Blender 90M as a retriever and a generator of each exemplar-based generative model, respectively. For MatToGen, additional MLP layers are added to the retriever, as follows the details in Cai et al. (2019b). When training the models, weights of the retriever and the generator are initialized with the pre-trained Bi-encoder 256M and Blender 90M, respectively, For Blender 90M, we use the model released by ParlAI (Miller et al., 2017) ", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "A.4 Generation Strategy", "text": "When we generate samples using generative model, exemplar-based generative models, and knowledgegrounded generative models, we adopt a beam decoding strategy which is widely used in generative models (Graves, 2012). Following (Roller et al., 2021), we choose a minimum beam length and a beam size as 20 BPE tokens and 10, respectively, and use tri-gram beam blocking on context and response blocks. During the inference phase, both exemplar-based generative models and knowledgegrounded generative models use the top-1 scoring candidate as an exemplar chosen from utilizing the relevance score S R (z, c).", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "B Evaluation Details", "text": "We prepare dialogue cases that have three-turn input contexts and the gold response from the BST and evaluate them by human pair-wise comparison and automatic evaluation. There are 980 test cases, and we randomly choose 100 test cases for the human evaluation.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "B.1 Pair-wise Human Evaluation", "text": "As we described in Section 5.3, we use Amazon Mechanical Turk to collect the annotations. Each test case is rated by three annotators to improve the robustness of the evaluation result. We set a maximum number of annotations per worker in order to reduce the potential bias. To control the quality of the annotations, we only allowed annotators who satisfy the following requirements to evaluate our results: (1) HITs approval rate greater than 95%, (2) Location is one of Australia, Canada, New Zealand, United Kingdom, and the United States, (3) Lifetime number of HITs approved greater than 1000, following Li et al. (2018). Figure 5 shows the instructions and the interface for the human evaluation. To mitigate the bias from the annotator, we randomly shuffle the order of the model and the corresponding response.", "n_publication_ref": 1, "n_figure_ref": 1}, {"heading": "B.2 Automatic Evaluation", "text": "For automatic metrics, we calculate the metric for each case and take the average of those values. When calculating BLEU, we use sentence_bleu function in nltk python package (Loper and Bird, 2002). ", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "C Measuring Inference Time", "text": "We measure how much time spend when the model generates the responses. When generating the response, Blender 90M takes 0.481 seconds, and Ret-NRef +CORGE takes 0.523 seconds per instance.\nThere is only an 8.7% amount of inference time gap between Blender 90M and RetNRef +CORGE. This tells us that exemplar-based generation can significantly improve the quality of responses regarding appropriateness, informativeness, and diversity without increasing the amount of time to generate answers. We test our model on NVIDIA DGX Station A100 with PyTorch 1.7.1, CUDA 11.0, CuDNN 8.0, and here we adopt the generation strategy we describe above. When we measure the inference time, we only use a single GPU (NVIDIA A100 GPU, 40GB Memory), and the inference time is measured as the average inference time of 100 response generations.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "D Additional Results", "text": "We provide additional samples for the retrieved exemplar and the model response from the baselines and our models in Table 6.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Input Context", "text": "A: I crash around 230 to 300. I don't have much of a social life. B: Neither do I, you are not alone A: I am alone but I'm not lonely. I have a dog who's great company.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Bi-encoder 256M", "text": "Any friends? My dog is one of mine. Blender 90M\nThat 's good to hear, I 've a dog too, he' s my best friend. ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Exemplar", "text": "No we went to a haunted house and I got chased often.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "MatToGen", "text": "No we never got to go to the haunted house we went to once and got chased by a ghost. MatToGen + CORGE No, I don 't like to go to haunted houses. I' m scared of them.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Exemplar", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "nicde. KIF", "text": "Yes, I went to a haunted house and watched all the horror movies. It was so scary!", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Exemplar", "text": "Are you doing anything cool for halloween RAG No, I don' t think I' m going to. I' ve never been a fan of halloween.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Input Context", "text": "A: Oh God no! I can't stay tied down to one woman. Why would you want to do that? B: I know right? Most people consider marriage to be involving 2 people but in certain parts of the world that varies between cultures and religions, so it doesn't seem so bad A: Marriage is very good.  ", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Towards a human-like open-domain chatbot", "journal": "", "year": "2020", "authors": "Daniel Adiwardana; Minh-Thang Luong; David R So; Jamie Hall; Noah Fiedel; Romal Thoppilan; Zi Yang; Apoorv Kulshreshtha; Gaurav Nemade; Yifeng Lu"}, {"title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners", "journal": "Curran Associates, Inc", "year": "", "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel Ziegler; Jeffrey Wu; Clemens Winter; Chris Hesse; Mark Chen; Eric Sigler; Mateusz Litwin"}, {"title": "Skeletonto-response: Dialogue generation guided by retrieval memory", "journal": "", "year": "2019", "authors": "Deng Cai; Yan Wang; Wei Bi; Zhaopeng Tu; Xiaojiang Liu; Wai Lam; Shuming Shi"}, {"title": "Retrievalguided dialogue response generation via a matchingto-generation framework", "journal": "", "year": "2019", "authors": "Deng Cai; Yan Wang; Wei Bi; Zhaopeng Tu; Xiaojiang Liu; Shuming Shi"}, {"title": "Wizard of wikipedia: Knowledge-powered conversational agents", "journal": "", "year": "2018", "authors": "Emily Dinan; Stephen Roller; Kurt Shuster; Angela Fan; Michael Auli; Jason Weston"}, {"title": "Augmenting transformers with knnbased composite memory for dialog", "journal": "Transactions of the Association for Computational Linguistics", "year": "2021", "authors": "Angela Fan; Claire Gardent; Chlo\u00e9 Braud; Antoine Bordes"}, {"title": "Sequence transduction with recurrent neural networks", "journal": "", "year": "2012", "authors": "Alex Graves"}, {"title": "Controlling dialogue generation with semantic exemplars", "journal": "", "year": "2021", "authors": "Prakhar Gupta; P Jeffrey; Yulia Bigham; Amy Tsvetkov;  Pavel"}, {"title": "Generating sentences by editing prototypes", "journal": "Transactions of the Association for Computational Linguistics", "year": "2018", "authors": "Kelvin Guu; B Tatsunori; Yonatan Hashimoto; Percy Oren;  Liang"}, {"title": "Realm: Retrievalaugmented language model pre-training", "journal": "", "year": "2020", "authors": "Kelvin Guu; Kenton Lee; Zora Tung; Panupong Pasupat; Ming-Wei Chang"}, {"title": "The curious case of neural text degeneration", "journal": "", "year": "2019", "authors": "Ari Holtzman; Jan Buys; Li Du; Maxwell Forbes; Yejin Choi"}, {"title": "Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring", "journal": "", "year": "2019", "authors": "Samuel Humeau; Kurt Shuster; Marie-Anne Lachaux; Jason Weston"}, {"title": "Distilling the knowledge of large-scale generative models into retrieval models for efficient open-domain conversation", "journal": "", "year": "2021", "authors": "Beomsu Kim; Seokjun Seo; Seungju Han; Enkhbayar Erdenee; Buru Chang"}, {"title": "Retrieval-augmented generation for knowledgeintensive nlp tasks", "journal": "Curran Associates, Inc", "year": "2020", "authors": "Patrick Lewis; Ethan Perez; Aleksandra Piktus; Fabio Petroni; Vladimir Karpukhin; Naman Goyal; Heinrich K\u00fcttler; Mike Lewis; Wen-Tau Yih; Tim Rockt\u00e4schel; Sebastian Riedel; Douwe Kiela"}, {"title": "A diversity-promoting objective function for neural conversation models", "journal": "", "year": "2016", "authors": "Jiwei Li; Michel Galley; Chris Brockett; Jianfeng Gao; William B Dolan"}, {"title": "Don't say that! making inconsistent dialogue unlikely with unlikelihood training", "journal": "", "year": "2020", "authors": "Margaret Li; Stephen Roller; Ilia Kulikov; Sean Welleck; Y-Lan Boureau; Kyunghyun Cho; Jason Weston"}, {"title": "Towards deep conversational recommendations", "journal": "", "year": "2018", "authors": "Raymond Li; Samira Kahou; Hannes Schulz; Vincent Michalski; Laurent Charlin; Chris Pal"}, {"title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "journal": "", "year": "2016", "authors": "Chia-Wei Liu; Ryan Lowe; Iulian Vlad Serban; Mike Noseworthy; Laurent Charlin; Joelle Pineau"}, {"title": "Nltk: The natural language toolkit", "journal": "Association for Computational Linguistics", "year": "2002", "authors": "Edward Loper; Steven Bird"}, {"title": "Training millions of personalized dialogue agents", "journal": "", "year": "2018", "authors": "Pierre-Emmanuel Mazare; Samuel Humeau"}, {"title": "Parlai: A dialog research software platform", "journal": "", "year": "2017", "authors": "A H Miller; W Feng; A Fisch; J Lu; D Batra; A Bordes; D Parikh; J Weston"}, {"title": "Bleu: a method for automatic evaluation of machine translation", "journal": "", "year": "2002", "authors": "Kishore Papineni; Salim Roukos; Todd Ward; Wei-Jing Zhu"}, {"title": "Towards empathetic opendomain conversation models: A new benchmark and dataset", "journal": "", "year": "2019", "authors": "Eric Michael Hannah Rashkin; Margaret Smith; Y-Lan Li;  Boureau"}, {"title": "Recipes for building an open-domain chatbot", "journal": "", "year": "2021", "authors": "Stephen Roller; Emily Dinan; Naman Goyal; Da Ju; Mary Williamson; Yinhan Liu; Jing Xu; Myle Ott; Eric Michael Smith; Y-Lan Boureau"}, {"title": "End-to-end training of neural retrievers for open-domain question answering", "journal": "", "year": "2021", "authors": "Devendra Singh Sachan; Mostofa Patwary; Mohammad Shoeybi; Neel Kant; Wei Ping; L William; Bryan Hamilton;  Catanzaro"}, {"title": "Multiresolution recurrent neural networks: An application to dialogue response generation", "journal": "", "year": "2017", "authors": "Iulian Serban; Tim Klinger; Gerald Tesauro; Kartik Talamadupula; Bowen Zhou; Yoshua Bengio; Aaron Courville"}, {"title": "Can you put it all together: Evaluating conversational agents' ability to blend skills", "journal": "", "year": "2020", "authors": "Eric Michael Smith; Mary Williamson; Kurt Shuster; Jason Weston; Y-Lan Boureau"}, {"title": "Annual Meeting of the Association for Computational Linguistics", "journal": "", "year": "", "authors": ""}, {"title": "Neural text generation with unlikelihood training", "journal": "", "year": "2019", "authors": "Sean Welleck; Ilia Kulikov; Stephen Roller; Emily Dinan; Kyunghyun Cho; Jason Weston"}, {"title": "Retrieve and refine: Improved sequence generation models for dialogue", "journal": "", "year": "2018", "authors": "Jason Weston; Emily Dinan; Alexander Miller"}, {"title": "Response generation by context-aware prototype editing", "journal": "", "year": "2019", "authors": "Yu Wu; Furu Wei; Shaohan Huang; Yunli Wang; Zhoujun Li; Ming Zhou"}, {"title": "Personalizing dialogue agents: I have a dog, do you have pets too?", "journal": "Long Papers", "year": "2018", "authors": "Saizheng Zhang; Emily Dinan; Jack Urbanek; Arthur Szlam; Douwe Kiela; Jason Weston"}, {"title": "Dialogpt: Largescale generative pre-training for conversational response generation", "journal": "", "year": "2020", "authors": "Yizhe Zhang; Siqi Sun; Michel Galley; Yen-Chun Chen; Chris Brockett; Xiang Gao; Jianfeng Gao; Jingjing Liu; William B Dolan"}], "figures": [{"figure_label": "2", "figure_type": "", "figure_id": "fig_0", "figure_caption": "\u2022Figure 2 :2Figure 2: Illustration of the drawbacks of existing exemplar-based generative models. The black dotted line indicates the boundary of the relevant exemplars to the given context.", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 3 :3Figure 3: The procedure of our proposed training method, CORGE. (a): Selecting kNE of the gold response r based on S R \u2032 (z, r). (b): Filtering out the exemplars which are too close to the gold response r. (c): Weighting the exemplars z depending on their normalized relevance scores P R (z, c).", "figure_data": ""}, {"figure_label": "4", "figure_type": "", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure4: The standard deviation of the normalized retriever score gets smaller when we jointly train the retriever for exemplar-based generative models. Ours stands for RetNRef +CORGE, and joint indicates jointly training the retriever with the generator.", "figure_data": ""}, {"figure_label": "5", "figure_type": "", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: The interface of pairwise human evaluation for appropriateness and informativeness.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Samples of the exemplars selected by CORGE.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "MatToGen+CORGE outperformsBi-encoder 256M and exceeds Blender 90M, while MatToGen performs worse than Bi-encoder 256M and Blender 90M. Furthermore, CORGE enlarges the win rate of RetNRef \u03b1 for Blender 90M. These evaluation results demonstrate that CORGE leads the existing exemplar-based generative models to produce more fluent and informative responses. RetNRef +CORGE and MatToGen+CORGE show lower PPL ret than Blender 90M, which means that the exemplar-based generative models trained with CORGE make a better prediction of the gold response than Blender 90M by utilizing the provided exemplar. RetNRef +CORGE has a smaller degree of PPL gold and PPL ret than those of RetNRef, which infers RetNRef +CORGE leverages the provided exemplar better than Ret-NRef. RetNRef \u03b1 has lower PPL gold than Ret-NRef +CORGE, however, RetNRef \u03b1 has higher Models PPL gold PPLret Dist-2 Dist-3 BLEU (z,r) -2 BLEU (z,r) -3", "figure_data": "6.2 Investigating the Exemplar-based Generative Models with Automatic MetricsThrough the automatic evaluation, we verify thatexisting exemplar-based generative models ignorethe provided exemplar or generate responses over-fitted to the provided exemplar. As shown in Ta-ble 3,"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Automatic evaluation results. Since Blender 90M can not utilize the exemplar, we report PPL calculated from P G (r|c) in the place of PPL gold and PPL ret .", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "No way i do it a lot, at least when i am feeling well enough. B: Awesome. That's the only thing i'll never do. I do like the outdoors though.A: I'm a thrill seaker. Do you like extreme sports? Bi-encoder 256M I love extreme sports. Its the only real way I can get the adrenaline boost I need. Blender 90M No, I don 't think I' ve ever done that. I' d love to though. Exemplar I love extreme sports. Its the only real way I can get the adrenaline boost I need. RetNRef I don' t really have a lot of time for sports. I spend most of my free time working. Exemplar I love extreme sports. Its the only real way I can get the adrenaline boost I need. RetNRef\u03b1 I love extreme sports I need the adrenaline boost. Its the only way I can get the real adrenaline. Exemplar I love extreme sports. Its the only real way I can get the adrenaline boost I need. RetNRef + CORGE I love extreme sports as well. It' s a great way to get out and enjoy life.", "figure_data": "Input Context A: Exemplar nicde. KIF I don' t really have a lot of time for sports. I spend most of my time working.Exemplar RAGDo you like sports? I don' t really have a lot of time for sports. I spend most of my time working."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Examples for model responses and provided exemplars corresponding to given input contexts.", "figure_data": "ModelsPPL gold PPLret Dist-2 Dist-3 BLEU (z,r) -2 BLEU (z,r) -3RetNRef + CORGE RetNRef + CORGE \u2212 RS RetNRef + CORGE \u2212 kNE RetNRef + CORGE \u2212 JF4.863 6.482 8.657 1.69811.53 11.75 13.82 32.910.349 0.316 0.250 0.5370.520 0.478 0.380 0.7850.102 0.074 0.034 0.3320.048 0.031 0.010 0.207"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Results of the ablation study. \u2212RS, \u2212kNE, and \u2212JF denote that relevance score (RS), kNE, and Jaccard filter (JF) are removed from CORGE, respectively.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_9", "figure_caption": ", PPL ret from RetNRef +CORGE is lower than any other ablation counterparts, which confirms each component contributes to predicting the responses. RetNRef +CORGE\u2212RS and Ret-NRef +CORGE\u2212kNE have a higher degree of PPL ret and PPL gold , which indicates RS and kNE help the generator to utilize the exemplar while generating the response. RetNRef +CORGE\u2212JF provides a strong signal of over-fitting, where it has extremely low PPL gold but exceptionally high PPL ret . Dist-n shows our model produces the most diverse responses among the models except Ret-NRef +CORGE\u2212JF, where RetNRef +CORGE\u2212JF excessively copies the tokens from the retrieved exemplar. The average BLEU (z,r) scores also show the same trend, where reaffirms the effect of the components of CORGE.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_10", "figure_caption": ", which is fine-tuned on the BST+ dataset. For Bi-encoder 256M, we fine-tune the model released by ParlAI on the BST+ dataset, and we follow the hyperparameter settings ofHumeau et al. (2019), which are implemented in the ParlAI library. The pre-defined response set is constructed from the BST+ training set, which contains about 400K responses. We use NVIDIA DGX Station A100 for training the models. , and the learning rate is decayed in half when the training loss meets the plateau. The model is trained until there is no progress in the validation PPL.", "figure_data": "A.3 HyperparametersWhen training exemplar-based generative modelswith CORGE, five (k=5) exemplars are utilizedfor each training instance. The exemplar-basedgenerators are trained with a batch size of 32 andan initial learning rate of 7e-6"}], "doi": ""}