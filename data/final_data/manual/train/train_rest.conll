-DOCSTART- -X- O
Text -X- _ B-TaskName
Simplification -X- _ I-TaskName
improves -X- _ O
the -X- _ O
readability -X- _ O
of -X- _ O
sentences -X- _ O
through -X- _ O
several -X- _ O
rewriting -X- _ O
transformations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
lexical -X- _ O
paraphrasing -X- _ O
, -X- _ O
deletion -X- _ O
, -X- _ O
and -X- _ O
splitting -X- _ O
. -X- _ O
Current -X- _ O
simplification -X- _ O
systems -X- _ O
are -X- _ O
predominantly -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
to -X- _ O
perform -X- _ O
all -X- _ O
these -X- _ O
operations -X- _ O
simultaneously -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
systems -X- _ O
limit -X- _ O
themselves -X- _ O
to -X- _ O
mostly -X- _ O
deleting -X- _ O
words -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
easily -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
requirements -X- _ O
of -X- _ O
different -X- _ O
target -X- _ O
audiences -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
hybrid -X- _ O
approach -X- _ O
that -X- _ O
leverages -X- _ O
linguistically -X- _ O
- -X- _ O
motivated -X- _ O
rules -X- _ O
for -X- _ O
splitting -X- _ O
and -X- _ O
deletion -X- _ O
, -X- _ O
and -X- _ O
couples -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
neural -X- _ O
paraphrasing -X- _ O
model -X- _ O
to -X- _ O
produce -X- _ O
varied -X- _ O
rewriting -X- _ O
styles -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
paraphrasing -X- _ O
capability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Through -X- _ O
automatic -X- _ O
and -X- _ O
manual -X- _ O
evaluations -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
establishes -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
art -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
paraphrasing -X- _ O
more -X- _ O
often -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
systems -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
control -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
each -X- _ O
simplification -X- _ O
operation -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
texts -X- _ O
. -X- _ O
1 -X- _ O

We -X- _ O
presented -X- _ O
an -X- _ O
empirical -X- _ O
method -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
label -X- _ O
consistency -X- _ O
and -X- _ O
NER -X- _ B-TaskName
model -X- _ O
performance -X- _ O
. -X- _ O
It -X- _ O
identified -X- _ O
the -X- _ O
label -X- _ O
inconsistency -X- _ O
of -X- _ O
test -X- _ O
data -X- _ O
in -X- _ O
SCIERC -X- _ B-DatasetName
and -X- _ O
CoNLL03 -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
with -X- _ O
26.7 -X- _ O
% -X- _ O
and -X- _ O
5.4 -X- _ O
% -X- _ O
label -X- _ O
mistakes -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
validated -X- _ O
the -X- _ O
label -X- _ O
consistency -X- _ O
in -X- _ O
multiple -X- _ O
sets -X- _ O
of -X- _ O
NER -X- _ B-TaskName
data -X- _ O
annotation -X- _ O
on -X- _ O
two -X- _ O
benchmarks -X- _ O
, -X- _ O
CoNLL03 -X- _ B-DatasetName
and -X- _ O
SCIERC -X- _ B-DatasetName
. -X- _ O

SeqMix -X- _ B-MethodName
: -X- _ O
Augmenting -X- _ O
Active -X- _ O
Sequence -X- _ O
Labeling -X- _ O
via -X- _ O
Sequence -X- _ O
Mixup -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
SeqMix -X- _ B-MethodName
to -X- _ O
enhance -X- _ O
active -X- _ B-TaskName
sequence -X- _ I-TaskName
labeling -X- _ I-TaskName
. -X- _ O
By -X- _ O
performing -X- _ O
sequence -X- _ O
mixup -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
, -X- _ O
Se -X- _ B-MethodName
- -X- _ I-MethodName
qMix -X- _ I-MethodName
improves -X- _ O
data -X- _ O
diversity -X- _ O
during -X- _ O
active -X- _ O
learning -X- _ O
, -X- _ O
while -X- _ O
being -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
plausible -X- _ O
augmented -X- _ O
sequences -X- _ O
. -X- _ O
This -X- _ O
method -X- _ O
is -X- _ O
generic -X- _ O
to -X- _ O
different -X- _ O
active -X- _ O
learning -X- _ O
policies -X- _ O
and -X- _ O
various -X- _ O
sequence -X- _ O
labeling -X- _ O
tasks -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
SeqMix -X- _ B-MethodName
can -X- _ O
improve -X- _ O
active -X- _ O
learning -X- _ O
baselines -X- _ O
consistently -X- _ O
for -X- _ O
NER -X- _ B-TaskName
and -X- _ O
event -X- _ B-TaskName
detection -X- _ I-TaskName
tasks -X- _ O
; -X- _ O
and -X- _ O
its -X- _ O
benefits -X- _ O
are -X- _ O
especially -X- _ O
prominent -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
data -X- _ O
regimes -X- _ O
. -X- _ O
For -X- _ O
future -X- _ O
research -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
enhance -X- _ O
SeqMix -X- _ B-MethodName
with -X- _ O
language -X- _ O
models -X- _ O
during -X- _ O
the -X- _ O
mixup -X- _ O
process -X- _ O
, -X- _ O
and -X- _ O
harness -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
further -X- _ O
improving -X- _ O
diversity -X- _ O
and -X- _ O
plausibility -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
list -X- _ O
the -X- _ O
link -X- _ O
to -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
CoNLL -X- _ B-DatasetName
- -X- _ O
03 -X- _ O
: -X- _ O
https://github.com/ -X- _ O
synalp -X- _ O
/ -X- _ O
NER -X- _ O
/ -X- _ O
tree -X- _ O
/ -X- _ O
master -X- _ O
/ -X- _ O
corpus/ -X- _ O
CoNLL -X- _ O
- -X- _ O
2003 -X- _ O
. -X- _ O
ACE05 -X- _ B-DatasetName
: -X- _ O
We -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
downloadable -X- _ O
version -X- _ O
due -X- _ O
to -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
public -X- _ O
. -X- _ O
This -X- _ O
corpus -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
through -X- _ O
the -X- _ O
website -X- _ O
of -X- _ O
LDC -X- _ O
: -X- _ O
https://www.ldc.upenn.edu/ -X- _ O
collaborations -X- _ O
/ -X- _ O
past -X- _ O
- -X- _ O
projects/ -X- _ O
ace -X- _ O
. -X- _ O
Webpage -X- _ O
: -X- _ O
Please -X- _ O
refer -X- _ O
the -X- _ O
link -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
( -X- _ O
Ratinov -X- _ O
and -X- _ O
Roth -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
implement -X- _ O
bert -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
cased -X- _ I-MethodName
as -X- _ O
the -X- _ O
underlying -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
and -X- _ O
bert -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
multilingualcased -X- _ I-MethodName
as -X- _ O
the -X- _ O
underlying -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
event -X- _ B-TaskName
detection -X- _ I-TaskName
task -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
Huggingface -X- _ O
Transformer -X- _ O
codebase -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
repository -X- _ O
4 -X- _ O
to -X- _ O
finetune -X- _ O
our -X- _ O
model -X- _ O
for -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
table -X- _ O
of -X- _ O
tokens -X- _ O
W -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
contextual -X- _ O
embedding -X- _ O
E. -X- _ O
For -X- _ O
our -X- _ O
underlying -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
vocabulary -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
tokenizer -X- _ O
to -X- _ O
build -X- _ O
up -X- _ O
W -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
embedding -X- _ O
initialized -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
as -X- _ O
E. -X- _ O
We -X- _ O
also -X- _ O
need -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
collection -X- _ O
to -X- _ O
exclude -X- _ O
some -X- _ O
generation -X- _ O
in -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
sequence -X- _ O
mixing -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
places -X- _ O
token -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
at -X- _ O
the -X- _ O
starting -X- _ O
position -X- _ O
and -X- _ O
the -X- _ O
ending -X- _ O
position -X- _ O
for -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
pad -X- _ O
the -X- _ O
inputs -X- _ O
with -X- _ O
[ -X- _ O
PAD -X- _ O
] -X- _ O
. -X- _ O
We -X- _ O
exclude -X- _ O
these -X- _ O
disturbing -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
parent -X- _ O
tokens -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
5 -X- _ O
- -X- _ O
round -X- _ O
active -X- _ O
learning -X- _ O
with -X- _ O
SeqMix -X- _ O
augmentation -X- _ O
, -X- _ O
our -X- _ O
program -X- _ O
runs -X- _ O
about -X- _ O
500 -X- _ O
seconds -X- _ O
for -X- _ O
WebPage -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
1700 -X- _ O
seconds -X- _ O
for -X- _ O
the -X- _ O
CoNLL -X- _ B-DatasetName
slicing -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
3.5 -X- _ O
hours -X- _ O
for -X- _ O
ACE -X- _ B-DatasetName
2005 -X- _ I-DatasetName
. -X- _ O
If -X- _ O
the -X- _ O
QBC -X- _ O
query -X- _ O
policy -X- _ O
used -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
runtime -X- _ O
will -X- _ O
be -X- _ O
multiplied -X- _ O
about -X- _ O
3 -X- _ O
times -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
wanted -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
predictive -X- _ O
power -X- _ O
of -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
linguistic -X- _ O
features -X- _ O
towards -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
complaints -X- _ O
. -X- _ O
These -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
broadly -X- _ O
broken -X- _ O
down -X- _ O
into -X- _ O
four -X- _ O
groups -X- _ O
. -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
The -X- _ O
first -X- _ O
group -X- _ O
of -X- _ O
features -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
simple -X- _ O
semantic -X- _ O
properties -X- _ O
such -X- _ O
as -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
, -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
tags -X- _ O
. -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
The -X- _ O
second -X- _ O
group -X- _ O
of -X- _ O
features -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
sentiment -X- _ O
models -X- _ O
or -X- _ O
lexicons -X- _ O
. -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
The -X- _ O
third -X- _ O
group -X- _ O
of -X- _ O
features -X- _ O
use -X- _ O
orthographic -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
hashtags -X- _ O
, -X- _ O
user -X- _ O
mentions -X- _ O
, -X- _ O
and -X- _ O
intensifiers -X- _ O
. -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
The -X- _ O
last -X- _ O
group -X- _ O
of -X- _ O
features -X- _ O
again -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
or -X- _ O
lexicons -X- _ O
associated -X- _ O
with -X- _ O
request -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
closely -X- _ O
related -X- _ O
speech -X- _ O
act -X- _ O
( -X- _ O
Švárová -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
expect -X- _ O
sentiment -X- _ O
to -X- _ O
contribute -X- _ O
strongly -X- _ O
towards -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
complaints -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
two -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
: -X- _ O
Stanford -X- _ B-MethodName
Sentiment -X- _ I-MethodName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
VADER -X- _ B-MethodName
( -X- _ O
Hutto -X- _ O
and -X- _ O
Gilbert -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Namely -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
scores -X- _ O
predicted -X- _ O
by -X- _ O
these -X- _ O
models -X- _ O
as -X- _ O
representations -X- _ O
of -X- _ O
tweets -X- _ O
. -X- _ O
Likewise -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
two -X- _ O
sentiment -X- _ O
lexicons -X- _ O
: -X- _ O
MPQA -X- _ B-MethodName
( -X- _ O
Wilson -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
NRC -X- _ B-MethodName
( -X- _ O
Mohammad -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
for -X- _ O
assigning -X- _ O
sentiment -X- _ O
scores -X- _ O
to -X- _ O
tweets -X- _ O
. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
identify -X- _ O
how -X- _ O
mental -X- _ O
health -X- _ O
subreddit -X- _ O
activity -X- _ O
has -X- _ O
changed -X- _ O
during -X- _ O
the -X- _ O
pandemic -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
create -X- _ O
time -X- _ O
series -X- _ O
for -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
metrics -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
pandemic -X- _ O
, -X- _ O
encompassing -X- _ O
activity -X- _ O
levels -X- _ O
and -X- _ O
text -X- _ O
content -X- _ O
( -X- _ O
Section -X- _ O
4.1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
a -X- _ O
time -X- _ O
series -X- _ O
intervention -X- _ O
analysis -X- _ O
technique -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
there -X- _ O
are -X- _ O
significant -X- _ O
changes -X- _ O
in -X- _ O
our -X- _ O
metrics -X- _ O
during -X- _ O
the -X- _ O
pandemic -X- _ O
( -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
traditional -X- _ O
topic -X- _ B-TaskName
modeling -X- _ I-TaskName
( -X- _ O
LDA -X- _ B-MethodName
) -X- _ O
, -X- _ O
the -X- _ O
top -X- _ O
J -X- _ O
words -X- _ O
are -X- _ O
those -X- _ O
with -X- _ O
highest -X- _ O
probability -X- _ O
under -X- _ O
each -X- _ O
topic -X- _ O
- -X- _ O
word -X- _ O
distribution -X- _ O
. -X- _ O
For -X- _ O
centroid -X- _ O
based -X- _ O
clustering -X- _ O
algorithms -X- _ O
, -X- _ O
the -X- _ O
top -X- _ O
words -X- _ O
of -X- _ O
some -X- _ O
cluster -X- _ O
i -X- _ O
are -X- _ O
naturally -X- _ O
those -X- _ O
closest -X- _ O
to -X- _ O
the -X- _ O
cluster -X- _ O
center -X- _ O
c -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
with -X- _ O
highest -X- _ O
probability -X- _ O
under -X- _ O
the -X- _ O
cluster -X- _ O
parameters -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
this -X- _ O
means -X- _ O
choosing -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
types -X- _ O
J -X- _ O
as -X- _ O
argmin -X- _ O
J -X- _ O
: -X- _ O
| -X- _ O
J -X- _ O
| -X- _ O
= -X- _ O
10 -X- _ O
j -X- _ O
J -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
c -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
− -X- _ O
x -X- _ O
j -X- _ O
2 -X- _ O
2 -X- _ O
for -X- _ O
KM -X- _ O
/ -X- _ O
KD -X- _ O
, -X- _ O
cos -X- _ O
( -X- _ O
c -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
x -X- _ O
j -X- _ O
) -X- _ O
for -X- _ O
SK -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
| -X- _ O
c -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
Σ -X- _ O
i -X- _ O
) -X- _ O
for -X- _ O
GMM -X- _ B-MethodName
/ -X- _ O
VMFM -X- _ B-MethodName
. -X- _ O
Our -X- _ O
results -X- _ O
in -X- _ O
6 -X- _ O
focus -X- _ O
on -X- _ O
KM -X- _ B-MethodName
and -X- _ O
GMM -X- _ B-MethodName
, -X- _ O
as -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
k -X- _ O
- -X- _ O
medoids -X- _ O
, -X- _ O
spherical -X- _ O
KM -X- _ O
and -X- _ O
von -X- _ O
Mises -X- _ O
- -X- _ O
Fisher -X- _ O
tend -X- _ O
to -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
KM -X- _ B-MethodName
and -X- _ O
GMM -X- _ O
( -X- _ O
see -X- _ O
App -X- _ O
. -X- _ O
A -X- _ O
, -X- _ O
App -X- _ O
. -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
extend -X- _ O
this -X- _ O
approach -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
top -X- _ O
topics -X- _ O
given -X- _ O
a -X- _ O
document -X- _ O
: -X- _ O
compute -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
learned -X- _ O
topic -X- _ O
cluster -X- _ O
centers -X- _ O
and -X- _ O
all -X- _ O
word -X- _ O
embeddings -X- _ O
from -X- _ O
that -X- _ O
particular -X- _ O
document -X- _ O
, -X- _ O
and -X- _ O
normalize -X- _ O
them -X- _ O
using -X- _ O
softmax -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
( -X- _ O
non -X- _ O
- -X- _ O
calibrated -X- _ O
) -X- _ O
probability -X- _ O
distribution -X- _ O
. -X- _ O
Crucial -X- _ O
to -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
the -X- _ O
incorporation -X- _ O
of -X- _ O
corpus -X- _ O
statistics -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
vanilla -X- _ O
clustering -X- _ O
algorithms -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
describe -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

The -X- _ O
complexity -X- _ O
of -X- _ O
KM -X- _ B-MethodName
is -X- _ O
O -X- _ O
( -X- _ O
tknm -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
of -X- _ O
GMM -X- _ B-MethodName
is -X- _ O
O -X- _ O
( -X- _ O
tknm -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
t -X- _ O
iterations -X- _ O
, -X- _ O
3 -X- _ O
k -X- _ O
clusters -X- _ O
( -X- _ O
topics -X- _ O
) -X- _ O
, -X- _ O
n -X- _ O
word -X- _ O
types -X- _ O
( -X- _ O
unique -X- _ O
vocabulary -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
m -X- _ O
embedding -X- _ O
dimensions -X- _ O
. -X- _ O
Weighted -X- _ O
variants -X- _ O
have -X- _ O
a -X- _ O
oneoff -X- _ O
cost -X- _ O
of -X- _ O
weight -X- _ O
initialization -X- _ O
, -X- _ O
and -X- _ O
contribute -X- _ O
a -X- _ O
constant -X- _ O
factor -X- _ O
when -X- _ O
recalulculating -X- _ O
the -X- _ O
centroid -X- _ O
during -X- _ O
clustering -X- _ O
. -X- _ O
Reranking -X- _ O
has -X- _ O
an -X- _ O
additional -X- _ O
O -X- _ O
( -X- _ O
n -X- _ O
log -X- _ O
( -X- _ O
n -X- _ O
k -X- _ O
) -X- _ O
) -X- _ O
factor -X- _ O
, -X- _ O
where -X- _ O
n -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
elements -X- _ O
in -X- _ O
a -X- _ O
cluster -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
LDA -X- _ B-MethodName
via -X- _ O
collapsed -X- _ O
Gibbs -X- _ O
sampling -X- _ O
has -X- _ O
a -X- _ O
complexity -X- _ O
of -X- _ O
O -X- _ O
( -X- _ O
tkN -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
, -X- _ O
so -X- _ O
when -X- _ O
N -X- _ O
n -X- _ O
, -X- _ O
clustering -X- _ O
methods -X- _ O
can -X- _ O
potentially -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
- -X- _ O
complexity -X- _ O
tradeoffs -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
running -X- _ O
ELMo -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
over -X- _ O
documents -X- _ O
also -X- _ O
requires -X- _ O
iterating -X- _ O
over -X- _ O
all -X- _ O
tokens -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
once -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
for -X- _ O
every -X- _ O
topic -X- _ O
and -X- _ O
iteration -X- _ O
. -X- _ O

For -X- _ O
readily -X- _ O
available -X- _ O
pretrained -X- _ O
word -X- _ O
embeddings -X- _ O
such -X- _ O
as -X- _ O
word2vec -X- _ B-MethodName
, -X- _ O
FastText -X- _ B-MethodName
, -X- _ O
GloVe -X- _ B-MethodName
and -X- _ O
Spherical -X- _ B-MethodName
, -X- _ O
the -X- _ O
embeddings -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
' -X- _ O
given -X- _ O
' -X- _ O
as -X- _ O
the -X- _ O
practioner -X- _ O
does -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
generate -X- _ O
these -X- _ O
embeddings -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
However -X- _ O
for -X- _ O
contextual -X- _ O
embeddings -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
there -X- _ O
is -X- _ O
additional -X- _ O
computational -X- _ O
cost -X- _ O
in -X- _ O
obtaining -X- _ O
these -X- _ O
embeddings -X- _ O
before -X- _ O
clustering -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
passing -X- _ O
through -X- _ O
RNN -X- _ O
and -X- _ O
transformer -X- _ O
layers -X- _ O
respectively -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
trivially -X- _ O
parallelised -X- _ O
by -X- _ O
batching -X- _ O
the -X- _ O
context -X- _ O
window -X- _ O
( -X- _ O
usually -X- _ O
a -X- _ O
sentence -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
standard -X- _ O
pretrained -X- _ O
ELMo -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
therefore -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
runtime -X- _ O
of -X- _ O
training -X- _ O
these -X- _ O
models -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

We -X- _ O
lowercase -X- _ O
tokens -X- _ O
, -X- _ O
remove -X- _ O
stopwords -X- _ O
, -X- _ O
punctuation -X- _ O
and -X- _ O
digits -X- _ O
, -X- _ O
and -X- _ O
exclude -X- _ O
words -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
less -X- _ O
than -X- _ O
5 -X- _ O
documents -X- _ O
and -X- _ O
appear -X- _ O
in -X- _ O
long -X- _ O
sentences -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
50 -X- _ O
words -X- _ O
, -X- _ O
removing -X- _ O
email -X- _ O
artifacts -X- _ O
and -X- _ O
noisy -X- _ O
token -X- _ O
sequences -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
valid -X- _ O
sentences -X- _ O
. -X- _ O
An -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
rare -X- _ O
word -X- _ O
removal -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
6.2 -X- _ O
. -X- _ O
For -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
ELMo -X- _ B-MethodName
) -X- _ O
, -X- _ O
sentences -X- _ O
served -X- _ O
as -X- _ O
the -X- _ O
context -X- _ O
window -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O
Subword -X- _ O
representations -X- _ O
were -X- _ O
averaged -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
just -X- _ O
using -X- _ O
the -X- _ O
first -X- _ O
subword -X- _ O
. -X- _ O

Running -X- _ O
LDA -X- _ B-MethodName
with -X- _ O
MALLET -X- _ O
( -X- _ O
McCallum -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
takes -X- _ O
a -X- _ O
minute -X- _ O
, -X- _ O
but -X- _ O
performs -X- _ O
no -X- _ O
better -X- _ O
than -X- _ O
KM -X- _ B-MethodName
w -X- _ I-MethodName
r -X- _ I-MethodName
, -X- _ O
which -X- _ O
takes -X- _ O
little -X- _ O
more -X- _ O
than -X- _ O
10 -X- _ O
seconds -X- _ O
on -X- _ O
CPU -X- _ O
using -X- _ O
sklearn -X- _ O
( -X- _ O
Pedregosa -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
- -X- _ O
4 -X- _ O
seconds -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
implementation -X- _ O
using -X- _ O
JAX -X- _ O
( -X- _ O
Bradbury -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
on -X- _ O
GPU -X- _ O
. -X- _ O

From -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
reranking -X- _ O
and -X- _ O
weighting -X- _ O
greatly -X- _ O
improves -X- _ O
clustering -X- _ O
performance -X- _ O
across -X- _ O
different -X- _ O
embeddings -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
first -X- _ O
step -X- _ O
to -X- _ O
uncover -X- _ O
why -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
how -X- _ O
sensitive -X- _ O
our -X- _ O
methods -X- _ O
are -X- _ O
to -X- _ O
restricting -X- _ O
the -X- _ O
clustering -X- _ O
to -X- _ O
only -X- _ O
frequently -X- _ O
appearing -X- _ O
word -X- _ O
types -X- _ O
. -X- _ O
Visualized -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
as -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
cutoff -X- _ O
term -X- _ O
frequency -X- _ O
, -X- _ O
thus -X- _ O
changing -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
and -X- _ O
allowing -X- _ O
more -X- _ O
rare -X- _ O
words -X- _ O
on -X- _ O
the -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
, -X- _ O
NPMI -X- _ B-MetricName
is -X- _ O
more -X- _ O
affected -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
without -X- _ O
reweighting -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
reweighting -X- _ O
using -X- _ O
term -X- _ O
frequency -X- _ O
is -X- _ O
effective -X- _ O
for -X- _ O
clustering -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
ad -X- _ O
- -X- _ O
hoc -X- _ O
restriction -X- _ O
of -X- _ O
infrequent -X- _ O
terms -X- _ O
- -X- _ O
without -X- _ O
it -X- _ O
, -X- _ O
all -X- _ O
combinations -X- _ O
perform -X- _ O
poorly -X- _ O
compared -X- _ O
to -X- _ O
LDA -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
GMM -X- _ B-MethodName
outperforms -X- _ O
KM -X- _ B-MethodName
for -X- _ O
both -X- _ O
weighted -X- _ O
and -X- _ O
unweighted -X- _ O
variants -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
embedding -X- _ O
methods -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
) -X- _ O
. -X- _ O
7 -X- _ O

For -X- _ O
KM -X- _ B-MethodName
, -X- _ O
extracted -X- _ O
topics -X- _ O
before -X- _ O
reranking -X- _ O
results -X- _ O
in -X- _ O
reasonable -X- _ O
looking -X- _ O
themes -X- _ O
, -X- _ O
but -X- _ O
scores -X- _ O
poorly -X- _ O
on -X- _ O
NPMI -X- _ B-MetricName
. -X- _ O
Reranking -X- _ O
strongly -X- _ O
improves -X- _ O
KM -X- _ B-MethodName
on -X- _ O
average -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.02 -X- _ O
) -X- _ O
for -X- _ O
both -X- _ O
Reuters -X- _ B-DatasetName
and -X- _ O
20NG -X- _ B-DatasetName
. -X- _ O
Examples -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
reranking -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
while -X- _ O
cluster -X- _ O
centers -X- _ O
are -X- _ O
centered -X- _ O
around -X- _ O
valid -X- _ O
themes -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
surrounded -X- _ O
by -X- _ O
low -X- _ O
frequency -X- _ O
word -X- _ O
types -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
when -X- _ O
applying -X- _ O
reranking -X- _ O
to -X- _ O
GMM -X- _ B-MethodName
w -X- _ I-MethodName
the -X- _ O
gains -X- _ O
are -X- _ O
much -X- _ O
less -X- _ O
pronounced -X- _ O
than -X- _ O
KM -X- _ B-MethodName
w -X- _ I-MethodName
. -X- _ O
The -X- _ O
top -X- _ O
topic -X- _ O
words -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
reranking -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
GMM -X- _ I-MethodName
w -X- _ I-MethodName
have -X- _ O
an -X- _ O
average -X- _ B-MetricName
Jaccard -X- _ I-MetricName
similarity -X- _ I-MetricName
score -X- _ O
of -X- _ O
0.910 -X- _ B-MetricValue
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
cluster -X- _ O
centers -X- _ O
learned -X- _ O
by -X- _ O
weighted -X- _ O
GMMs -X- _ B-MethodName
are -X- _ O
already -X- _ O
centered -X- _ O
at -X- _ O
word -X- _ O
types -X- _ O
of -X- _ O
high -X- _ O
frequency -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O

Spherical -X- _ B-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
perform -X- _ O
consistently -X- _ O
well -X- _ O
across -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
For -X- _ O
20NG -X- _ B-DatasetName
, -X- _ O
KM -X- _ B-MethodName
w -X- _ I-MethodName
r -X- _ I-MethodName
Spherical -X- _ I-MethodName
and -X- _ O
LDA -X- _ B-MethodName
both -X- _ O
achieve -X- _ O
0.26 -X- _ B-MetricValue
NPMI -X- _ B-MetricName
. -X- _ O
For -X- _ O
Reuters -X- _ B-DatasetName
, -X- _ O
GMM -X- _ B-MethodName
w -X- _ I-MethodName
r -X- _ I-MethodName
BERT -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
top -X- _ O
NPMI -X- _ B-MetricName
score -X- _ O
of -X- _ O
0.15 -X- _ B-MetricValue
compared -X- _ O
to -X- _ O
0.12 -X- _ B-MetricValue
of -X- _ O
LDA -X- _ B-MethodName
. -X- _ O
Word2vec -X- _ B-MethodName
and -X- _ O
ELMo -X- _ B-MethodName
( -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
8 -X- _ O
) -X- _ O
perform -X- _ O
poorly -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
embeddings -X- _ O
. -X- _ O
Fast -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
and -X- _ O
GloVe -X- _ B-MethodName
can -X- _ O
achieve -X- _ O
similar -X- _ O
performance -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
20NG -X- _ B-DatasetName
but -X- _ O
are -X- _ O
slightly -X- _ O
inferior -X- _ O
on -X- _ O
Reuters -X- _ B-DatasetName
. -X- _ O
Training -X- _ O
or -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
embeddings -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
data -X- _ O
prior -X- _ O
to -X- _ O
clustering -X- _ O
could -X- _ O
potentially -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
leave -X- _ O
this -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
yields -X- _ O
a -X- _ O
greater -X- _ O
diversity -X- _ O
within -X- _ O
topics -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
LDA -X- _ B-MethodName
while -X- _ O
achieving -X- _ O
comparable -X- _ O
coherence -X- _ B-MetricName
scores -X- _ I-MetricName
( -X- _ O
App -X- _ O
. -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
topics -X- _ O
are -X- _ O
arguably -X- _ O
more -X- _ O
valuable -X- _ O
for -X- _ O
exploratory -X- _ O
analysis -X- _ O
. -X- _ O

We -X- _ O
outlined -X- _ O
a -X- _ O
methodology -X- _ O
for -X- _ O
clustering -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
document -X- _ I-TaskName
analysis -X- _ I-TaskName
, -X- _ O
and -X- _ O
presented -X- _ O
a -X- _ O
systematic -X- _ O
comparison -X- _ O
of -X- _ O
various -X- _ O
influential -X- _ O
embedding -X- _ O
methods -X- _ O
and -X- _ O
clustering -X- _ O
algorithms -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
suggest -X- _ O
that -X- _ O
pretrained -X- _ B-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
( -X- _ O
both -X- _ O
contextualized -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
contextualized -X- _ O
) -X- _ O
, -X- _ O
combined -X- _ O
with -X- _ O
tf -X- _ O
- -X- _ O
weighted -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
and -X- _ O
tf -X- _ O
- -X- _ O
based -X- _ O
reranking -X- _ O
, -X- _ O
provide -X- _ O
a -X- _ O
viable -X- _ O
alternative -X- _ O
to -X- _ O
traditional -X- _ O
topic -X- _ O
modeling -X- _ O
at -X- _ O
lower -X- _ O
complexity -X- _ O
and -X- _ O
runtime -X- _ O
. -X- _ O

We -X- _ O
thank -X- _ O
Aaron -X- _ O
Mueller -X- _ O
, -X- _ O
Pamela -X- _ O
Shapiro -X- _ O
, -X- _ O
Li -X- _ O
Ke -X- _ O
, -X- _ O
Adam -X- _ O
Poliak -X- _ O
, -X- _ O
Kevin -X- _ O
Duh -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
feedback -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
SAPBERT -X- _ B-MethodName
, -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
alignment -X- _ O
pretraining -X- _ O
scheme -X- _ O
for -X- _ O
learning -X- _ O
biomedical -X- _ O
entity -X- _ O
representations -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
consistent -X- _ O
performance -X- _ O
boost -X- _ O
achieved -X- _ O
by -X- _ O
SAPBERT -X- _ B-MethodName
, -X- _ O
obtaining -X- _ O
new -X- _ O
SOTA -X- _ O
in -X- _ O
all -X- _ O
six -X- _ O
widely -X- _ O
used -X- _ O
MEL -X- _ B-TaskName
benchmarking -X- _ O
datasets -X- _ O
. -X- _ O
Strikingly -X- _ O
, -X- _ O
without -X- _ O
any -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
labelled -X- _ O
data -X- _ O
, -X- _ O
SAPBERT -X- _ B-MethodName
already -X- _ O
outperforms -X- _ O
the -X- _ O
previous -X- _ O
supervised -X- _ O
SOTA -X- _ O
( -X- _ O
sophisticated -X- _ O
hybrid -X- _ O
entity -X- _ O
linking -X- _ O
systems -X- _ O
) -X- _ O
on -X- _ O
multiple -X- _ O
datasets -X- _ O
in -X- _ O
the -X- _ O
scientific -X- _ O
language -X- _ O
domain -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
opens -X- _ O
new -X- _ O
avenues -X- _ O
to -X- _ O
explore -X- _ O
for -X- _ O
general -X- _ O
domain -X- _ O
self -X- _ O
- -X- _ O
alignment -X- _ O
( -X- _ O
e.g. -X- _ O
by -X- _ O
leveraging -X- _ O
knowledge -X- _ O
graphs -X- _ O
such -X- _ O
as -X- _ O
DBpedia -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
plan -X- _ O
to -X- _ O
incorporate -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
relations -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
hypernymy -X- _ O
and -X- _ O
hyponymy -X- _ O
) -X- _ O
and -X- _ O
extend -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
our -X- _ O
ongoing -X- _ O
work -X- _ O
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
SAPBERT -X- _ B-MethodName
and -X- _ O
ADAPTER -X- _ O
is -X- _ O
a -X- _ O
promising -X- _ O
direction -X- _ O
for -X- _ O
tackling -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
. -X- _ O

NCBI -X- _ B-DatasetName
disease -X- _ I-DatasetName
( -X- _ O
Dogan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
corpus -X- _ O
containing -X- _ O
793 -X- _ O
fully -X- _ O
annotated -X- _ O
PubMed -X- _ O
abstracts -X- _ O
and -X- _ O
6 -X- _ O
, -X- _ O
881 -X- _ O
mentions -X- _ O
. -X- _ O
The -X- _ O
mentions -X- _ O
are -X- _ O
mapped -X- _ O
into -X- _ O
the -X- _ O
MEDIC -X- _ B-DatasetName
dictionary -X- _ O
( -X- _ O
Davis -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
this -X- _ O
dataset -X- _ O
as -X- _ O
" -X- _ O
NCBI -X- _ O
" -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
BC5CDR -X- _ B-DatasetName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
1 -X- _ O
, -X- _ O
500 -X- _ O
PubMed -X- _ O
articles -X- _ O
with -X- _ O
4 -X- _ O
, -X- _ O
409 -X- _ O
annotated -X- _ O
chemicals -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
818 -X- _ O
diseases -X- _ O
and -X- _ O
3 -X- _ O
, -X- _ O
116 -X- _ O
chemical -X- _ O
- -X- _ O
disease -X- _ O
interactions -X- _ O
. -X- _ O
The -X- _ O
disease -X- _ O
mentions -X- _ O
are -X- _ O
mapped -X- _ O
into -X- _ O
the -X- _ O
MEDIC -X- _ B-DatasetName
dictionary -X- _ O
like -X- _ O
the -X- _ O
NCBI -X- _ O
disease -X- _ O
corpus -X- _ O
. -X- _ O
The -X- _ O
chemical -X- _ O
mentions -X- _ O
are -X- _ O
mapped -X- _ O
into -X- _ O
the -X- _ O
Comparative -X- _ B-DatasetName
Toxicogenomics -X- _ I-DatasetName
Database -X- _ I-DatasetName
( -X- _ O
CTD -X- _ O
) -X- _ O
( -X- _ O
Davis -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
chemical -X- _ O
dictionary -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
disease -X- _ O
and -X- _ O
chemical -X- _ O
mention -X- _ O
sets -X- _ O
as -X- _ O
" -X- _ O
BC5CDRd -X- _ B-DatasetName
" -X- _ O
and -X- _ O
" -X- _ O
BC5CDR -X- _ B-DatasetName
- -X- _ I-DatasetName
c -X- _ I-DatasetName
" -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
NCBI -X- _ B-DatasetName
and -X- _ O
BC5CDR -X- _ B-DatasetName
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
evaluation -X- _ O
protocol -X- _ O
by -X- _ O
Sung -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
11 -X- _ O
MedMentions -X- _ B-DatasetName
( -X- _ O
Mohan -X- _ O
and -X- _ O
Li -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
verylarge -X- _ O
- -X- _ O
scale -X- _ O
entity -X- _ O
linking -X- _ O
dataset -X- _ O
containing -X- _ O
over -X- _ O
4 -X- _ O
, -X- _ O
000 -X- _ O
abstracts -X- _ O
and -X- _ O
over -X- _ O
350 -X- _ O
, -X- _ O
000 -X- _ O
mentions -X- _ O
linked -X- _ O
to -X- _ O
UMLS -X- _ B-DatasetName
2017AA -X- _ I-DatasetName
. -X- _ O
According -X- _ O
to -X- _ O
Mohan -X- _ O
and -X- _ O
Li -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
training -X- _ O
TAGGERONE -X- _ B-MethodName
, -X- _ O
a -X- _ O
very -X- _ O
popular -X- _ O
MEL -X- _ B-TaskName
system -X- _ O
, -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
MedMentions -X- _ B-DatasetName
require -X- _ O
> -X- _ O
900 -X- _ O
GB -X- _ O
of -X- _ O
RAM -X- _ O
. -X- _ O
Its -X- _ O
massive -X- _ O
number -X- _ O
of -X- _ O
mentions -X- _ O
and -X- _ O
more -X- _ O
importantly -X- _ O
the -X- _ O
used -X- _ O
reference -X- _ O
ontology -X- _ O
( -X- _ O
UMLS -X- _ O
2017AA -X- _ O
has -X- _ O
3M+ -X- _ O
concepts -X- _ O
) -X- _ O
make -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
most -X- _ O
MEL -X- _ B-TaskName
systems -X- _ O
infeasible -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
through -X- _ O
our -X- _ O
metric -X- _ O
learning -X- _ O
formulation -X- _ O
, -X- _ O
SAPBERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
on -X- _ O
MedMentions -X- _ B-DatasetName
with -X- _ O
minimal -X- _ O
effort -X- _ O
. -X- _ O

AskAPatient -X- _ B-DatasetName
( -X- _ O
Limsopatham -X- _ O
and -X- _ O
Collier -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
includes -X- _ O
17 -X- _ O
, -X- _ O
324 -X- _ O
adverse -X- _ O
drug -X- _ O
reaction -X- _ O
( -X- _ O
ADR -X- _ O
) -X- _ O
annotations -X- _ O
collected -X- _ O
from -X- _ O
askapatient.com -X- _ O
blog -X- _ O
posts -X- _ O
. -X- _ O
The -X- _ O
mentions -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
036 -X- _ O
medical -X- _ O
concepts -X- _ O
grounded -X- _ O
onto -X- _ O
SNOMED -X- _ B-DatasetName
- -X- _ I-DatasetName
CT -X- _ I-DatasetName
( -X- _ O
Donnelly -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
and -X- _ O
AMT -X- _ B-DatasetName
( -X- _ O
the -X- _ O
Australian -X- _ O
Medicines -X- _ O
Terminology -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
evaluation -X- _ O
protocol -X- _ O
stated -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
. -X- _ O
12 -X- _ O
COMETA -X- _ B-DatasetName
( -X- _ O
Basaldella -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
recently -X- _ O
released -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
MEL -X- _ O
dataset -X- _ O
that -X- _ O
specifically -X- _ O
focuses -X- _ O
on -X- _ O
MEL -X- _ O
in -X- _ O
the -X- _ O
social -X- _ O
media -X- _ O
domain -X- _ O
, -X- _ O
containing -X- _ O
around -X- _ O
20k -X- _ O
medical -X- _ O
mentions -X- _ O
extracted -X- _ O
from -X- _ O
health -X- _ O
- -X- _ O
related -X- _ O
discussions -X- _ O
on -X- _ O
reddit.com -X- _ O
. -X- _ O
Mentions -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
SNOMED -X- _ B-DatasetName
- -X- _ I-DatasetName
CT -X- _ I-DatasetName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
" -X- _ O
stratified -X- _ O
( -X- _ O
general -X- _ O
) -X- _ O
" -X- _ O
split -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
evaluation -X- _ O
protocol -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
. -X- _ O
13 -X- _ O

We -X- _ O
list -X- _ O
all -X- _ O
the -X- _ O
versions -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
linking -X- _ O
to -X- _ O
the -X- _ O
specific -X- _ O
versions -X- _ O
in -X- _ O
Tab -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
exhaustively -X- _ O
tried -X- _ O
all -X- _ O
official -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
ones -X- _ O
are -X- _ O
chosen -X- _ O
. -X- _ O
All -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
architecture -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
S -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
surface -X- _ O
forms -X- _ O
/ -X- _ O
synonyms -X- _ O
of -X- _ O
all -X- _ O
concepts -X- _ O
in -X- _ O
C -X- _ O
; -X- _ O
M -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
mentions -X- _ O
/ -X- _ O
queries -X- _ O
. -X- _ O
COMETA -X- _ O
( -X- _ O
s.g -X- _ O
. -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
z.g -X- _ O
. -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
stratified -X- _ O
( -X- _ O
general -X- _ O
) -X- _ O
and -X- _ O
zeroshot -X- _ O
( -X- _ O
general -X- _ O
) -X- _ O
split -X- _ O
respectively -X- _ O
. -X- _ O
model -X- _ O
NCBI -X- _ O
BC5CDR -X- _ O
- -X- _ O
d -X- _ O
BC5CDR -X- _ O
- -X- _ O
c -X- _ O
MedMentions -X- _ O
AskAPatient -X- _ O
COMETA -X- _ O
@1 -X- _ O
@5 -X- _ O
@1 -X- _ O
@5 -X- _ O
@1 -X- _ O
@5 -X- _ O
@1 -X- _ O
@5 -X- _ O
@1 -X- _ O
@5 -X- _ O
@1 -X- _ O
@5 -X- _ O
SIEVE -X- _ B-MethodName
- -X- _ I-MethodName
BASED -X- _ I-MethodName
( -X- _ O
D'Souza -X- _ O
and -X- _ O
Ng -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
84.7 -X- _ O
- -X- _ O
84.1 -X- _ O
- -X- _ O
90.7 -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
WORDCNN -X- _ B-MethodName
( -X- _ O
Limsopatham -X- _ O
and -X- _ O
Collier -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
81.4 -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
WORDGRU+TF -X- _ B-MethodName
- -X- _ I-MethodName
IDF -X- _ I-MethodName
( -X- _ O
Tutubalina -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
85.7 -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
TAGGERONE -X- _ B-MethodName
87.7 -X- _ O
- -X- _ O
88.9 -X- _ O
- -X- _ O
94.1 -X- _ O
- -X- _ O
OOM -X- _ O
OOM -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
NORMCO -X- _ B-MethodName
( -X- _ O
Wright -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
87.8 -X- _ O
- -X- _ O
88.0 -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
BNE -X- _ B-MethodName
( -X- _ O
Phan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
87.7 -X- _ O
- -X- _ O
90.6 -X- _ O
- -X- _ O
95.8 -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
BERTRANK -X- _ B-MethodName
( -X- _ O
Ji -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
89 -X- _ O
. -X- _ O

We -X- _ O
thank -X- _ O
the -X- _ O
three -X- _ O
reviewers -X- _ O
and -X- _ O
the -X- _ O
Area -X- _ O
Chair -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
and -X- _ O
suggestions -X- _ O
. -X- _ O
FL -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
Grace -X- _ O
& -X- _ O
Thomas -X- _ O
C.H. -X- _ O
Chan -X- _ O
Cambridge -X- _ O
Scholarship -X- _ O
. -X- _ O
NC -X- _ O
and -X- _ O
MB -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O

Being -X- _ O
able -X- _ O
to -X- _ O
perform -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
chat -X- _ O
with -X- _ O
humans -X- _ O
in -X- _ O
a -X- _ O
closed -X- _ O
domain -X- _ O
is -X- _ O
a -X- _ O
precondition -X- _ O
before -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
chatbot -X- _ O
can -X- _ O
ever -X- _ O
be -X- _ O
claimed -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
close -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
movie -X- _ O
domain -X- _ O
and -X- _ O
present -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
corpus -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
annotations -X- _ O
in -X- _ O
hope -X- _ O
of -X- _ O
pushing -X- _ O
the -X- _ O
limit -X- _ O
of -X- _ O
moviedomain -X- _ O
chatbots -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
, -X- _ O
readily -X- _ O
scalable -X- _ O
neural -X- _ O
approach -X- _ O
which -X- _ O
reconciles -X- _ O
all -X- _ O
subtasks -X- _ O
like -X- _ O
intent -X- _ B-TaskName
prediction -X- _ I-TaskName
and -X- _ O
knowledge -X- _ B-TaskName
retrieval -X- _ I-TaskName
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
huge -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
, -X- _ O
then -X- _ O
finetuned -X- _ O
on -X- _ O
our -X- _ O
corpus -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
this -X- _ O
simple -X- _ O
neural -X- _ O
approach -X- _ O
trained -X- _ O
on -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
data -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
outperform -X- _ O
commercial -X- _ O
systems -X- _ O
replying -X- _ O
on -X- _ O
complex -X- _ O
rules -X- _ O
. -X- _ O
On -X- _ O
both -X- _ O
the -X- _ O
static -X- _ O
and -X- _ O
interactive -X- _ O
tests -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
responses -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
system -X- _ O
exhibits -X- _ O
remarkably -X- _ O
good -X- _ O
engagement -X- _ O
and -X- _ O
sensibleness -X- _ O
close -X- _ O
to -X- _ O
human -X- _ O
- -X- _ O
written -X- _ O
ones -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
limits -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
and -X- _ O
point -X- _ O
out -X- _ O
potential -X- _ O
directions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
1 -X- _ O
. -X- _ O

Language -X- _ O
models -X- _ O
have -X- _ O
demonstrated -X- _ O
impressive -X- _ O
performance -X- _ O
as -X- _ O
a -X- _ O
universal -X- _ O
learner -X- _ O
across -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
this -X- _ O
, -X- _ O
our -X- _ O
dialogue -X- _ B-TaskName
generation -X- _ I-TaskName
model -X- _ O
is -X- _ O
implemented -X- _ O
as -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
- -X- _ O
based -X- _ O
language -X- _ O
model -X- _ O
like -X- _ O
GPT2 -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
a -X- _ O
pipeline -X- _ O
process -X- _ O
of -X- _ O
movie -X- _ O
tracker -X- _ O
, -X- _ O
intent -X- _ O
prediction -X- _ O
, -X- _ O
knowledge -X- _ O
retrieval -X- _ O
and -X- _ O
text -X- _ O
gener -X- _ O
- -X- _ O
7 -X- _ O
We -X- _ O
only -X- _ O
consider -X- _ O
recommending -X- _ O
movies -X- _ O
as -X- _ O
for -X- _ O
the -X- _ O
DA -X- _ O
about -X- _ O
recommendation -X- _ O
. -X- _ O
Recommending -X- _ O
other -X- _ O
aspects -X- _ O
require -X- _ O
assembling -X- _ O
recommendation -X- _ O
systems -X- _ O
of -X- _ O
different -X- _ O
domains -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
beyond -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

The -X- _ O
knowledge -X- _ O
retrieval -X- _ O
component -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
classical -X- _ O
DSSM -X- _ B-MethodName
model -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
replace -X- _ O
the -X- _ O
MLP -X- _ O
with -X- _ O
our -X- _ O
language -X- _ O
model -X- _ O
encoder -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
embedding -X- _ O
for -X- _ O
knowledge -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
only -X- _ O
select -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
movie -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
movie -X- _ O
tracker -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
" -X- _ O
will -X- _ O
be -X- _ O
fed -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
response -X- _ O
. -X- _ O
To -X- _ O
make -X- _ O
it -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
pretrained -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ O
, -X- _ O
the -X- _ O
position -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
decoded -X- _ O
response -X- _ O
will -X- _ O
skip -X- _ O
the -X- _ O
concatenated -X- _ O
intent -X- _ O
and -X- _ O
knowledge -X- _ O
and -X- _ O
directly -X- _ O
follow -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
this -X- _ O
beneficial -X- _ O
when -X- _ O
combined -X- _ O
with -X- _ O
pretrained -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
also -X- _ O
follows -X- _ O
the -X- _ O
pretrained -X- _ O
model -X- _ O
mixing -X- _ O
maximum -X- _ O
lilkelihood -X- _ O
and -X- _ O
unlikelihood -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
MovieChats -X- _ B-MethodName
: -X- _ O
a -X- _ O
movie -X- _ O
- -X- _ O
domain -X- _ O
chatbot -X- _ O
built -X- _ O
upon -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
, -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
conversational -X- _ O
corpus -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
with -X- _ O
a -X- _ O
simple -X- _ O
unified -X- _ O
language -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
powered -X- _ O
by -X- _ O
well -X- _ O
- -X- _ O
defined -X- _ O
knowledge -X- _ O
grounding -X- _ O
, -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
approach -X- _ O
human -X- _ O
performance -X- _ O
in -X- _ O
some -X- _ O
perspective -X- _ O
, -X- _ O
though -X- _ O
still -X- _ O
lagged -X- _ O
behind -X- _ O
when -X- _ O
it -X- _ O
comes -X- _ O
to -X- _ O
dealing -X- _ O
with -X- _ O
detailed -X- _ O
knowledge -X- _ O
or -X- _ O
long -X- _ O
- -X- _ O
turn -X- _ O
consistency -X- _ O
. -X- _ O

Preface -X- _ O
: -X- _ O
General -X- _ O
Chair -X- _ O

Mirella -X- _ O
Lapata -X- _ O
is -X- _ O
professor -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
in -X- _ O
the -X- _ O
School -X- _ O
of -X- _ O
Informatics -X- _ O
at -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Edinburgh -X- _ O
. -X- _ O
Her -X- _ O
research -X- _ O
focuses -X- _ O
on -X- _ O
getting -X- _ O
computers -X- _ O
to -X- _ O
understand -X- _ O
, -X- _ O
reason -X- _ O
with -X- _ O
, -X- _ O
and -X- _ O
generate -X- _ O
. -X- _ O
She -X- _ O
is -X- _ O
as -X- _ O
an -X- _ O
associate -X- _ O
editor -X- _ O
of -X- _ O
the -X- _ O
Journal -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
Research -X- _ O
and -X- _ O
has -X- _ O
served -X- _ O
on -X- _ O
the -X- _ O
editorial -X- _ O
boards -X- _ O
of -X- _ O
Transactions -X- _ O
of -X- _ O
the -X- _ O
ACL -X- _ O
and -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O
She -X- _ O
was -X- _ O
the -X- _ O
first -X- _ O
recipient -X- _ O
of -X- _ O
the -X- _ O
Karen -X- _ O
Sparck -X- _ O
Jones -X- _ O
award -X- _ O
of -X- _ O
the -X- _ O
British -X- _ O
Computer -X- _ O
Society -X- _ O
, -X- _ O
recognizing -X- _ O
key -X- _ O
contributions -X- _ O
to -X- _ O
NLP -X- _ O
and -X- _ O
information -X- _ O
retrieval -X- _ O
. -X- _ O
She -X- _ O
received -X- _ O
two -X- _ O
EMNLP -X- _ O
best -X- _ O
paper -X- _ O
awards -X- _ O
and -X- _ O
currently -X- _ O
holds -X- _ O
a -X- _ O
prestigious -X- _ O
Consolidator -X- _ O
Grant -X- _ O
from -X- _ O
the -X- _ O
European -X- _ O
Research -X- _ O
Council -X- _ O
. -X- _ O
xxiii -X- _ O

Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
We -X- _ O
use -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
massive -X- _ O
text -X- _ O
corpus -X- _ O
, -X- _ O
following -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
optimized -X- _ O
hyperparameters -X- _ O
and -X- _ O
a -X- _ O
modification -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
objective -X- _ O
, -X- _ O
which -X- _ O
excludes -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
and -X- _ O
only -X- _ O
uses -X- _ O
the -X- _ O
randomly -X- _ O
masked -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
on -X- _ O
a -X- _ O
certain -X- _ O
task -X- _ O
, -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
is -X- _ O
appended -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
after -X- _ O
the -X- _ O
pretraining -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
parameters -X- _ O
in -X- _ O
RoBERTa -X- _ B-MethodName
are -X- _ O
trained -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
way -X- _ O
using -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
training -X- _ O
word -X- _ O
representations -X- _ O
using -X- _ O
RoBERTa -X- _ B-MethodName
on -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
will -X- _ O
be -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
pretraining -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
taking -X- _ O
this -X- _ O
pretrained -X- _ O
model -X- _ O
and -X- _ O
adding -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
with -X- _ O
additional -X- _ O
updates -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
parameters -X- _ O
will -X- _ O
be -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Task -X- _ O
- -X- _ O
adaptive -X- _ O
pretraining -X- _ O
( -X- _ O
TAPT -X- _ O
) -X- _ O
Although -X- _ O
RoBERTa -X- _ B-MethodName
achieves -X- _ O
strong -X- _ O
performance -X- _ O
by -X- _ O
simply -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
PLMs -X- _ O
on -X- _ O
a -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
there -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
distributional -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
pretraining -X- _ O
and -X- _ O
target -X- _ O
corpora -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
pretraining -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
or -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
usefully -X- _ O
employed -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
and -X- _ O
it -X- _ O
further -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
PLMs -X- _ O
. -X- _ O
Such -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
Domain -X- _ O
- -X- _ O
Adaptive -X- _ O
Pretraining -X- _ O
( -X- _ O
DAPT -X- _ O
) -X- _ O
or -X- _ O
Task -X- _ O
Adaptive -X- _ O
- -X- _ O
Pretraining -X- _ O
( -X- _ O
TAPT -X- _ O
) -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
limit -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
our -X- _ O
works -X- _ O
to -X- _ O
TAPT -X- _ O
as -X- _ O
domain -X- _ O
text -X- _ O
corpus -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
available -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
whereas -X- _ O
TAPT -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
applied -X- _ O
by -X- _ O
directly -X- _ O
using -X- _ O
the -X- _ O
dataset -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
while -X- _ O
its -X- _ O
performance -X- _ O
often -X- _ O
matches -X- _ O
with -X- _ O
DAPT -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
TAPT -X- _ O
, -X- _ O
the -X- _ O
second -X- _ O
phase -X- _ O
of -X- _ O
pretraining -X- _ O
is -X- _ O
per -X- _ O
- -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
adapter -X- _ O
achitecture -X- _ O
in -X- _ O
the -X- _ O
Transformer -X- _ O
layer -X- _ O
( -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
formed -X- _ O
with -X- _ O
RoBERTa -X- _ B-MethodName
using -X- _ O
the -X- _ O
unlabeled -X- _ O
text -X- _ O
corpus -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
it -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
Adapter -X- _ O
Adapter -X- _ O
modules -X- _ O
have -X- _ O
been -X- _ O
employed -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
Rebuffi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
have -X- _ O
been -X- _ O
recently -X- _ O
adopted -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
literature -X- _ O
as -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
to -X- _ O
fully -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
PLMs -X- _ O
. -X- _ O
Adapters -X- _ O
are -X- _ O
sets -X- _ O
of -X- _ O
new -X- _ O
weights -X- _ O
that -X- _ O
are -X- _ O
typically -X- _ O
embedded -X- _ O
in -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
of -X- _ O
PLMs -X- _ O
and -X- _ O
consist -X- _ O
of -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
with -X- _ O
normalizations -X- _ O
, -X- _ O
residual -X- _ O
connections -X- _ O
, -X- _ O
and -X- _ O
projection -X- _ O
layers -X- _ O
. -X- _ O
The -X- _ O
architectures -X- _ O
of -X- _ O
adapters -X- _ O
vary -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
configuration -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
configuration -X- _ O
proposed -X- _ O
by -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020a -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
which -X- _ O
turned -X- _ O
out -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
on -X- _ O
diverse -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
the -X- _ O
adapter -X- _ O
layer -X- _ O
to -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
. -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020c -X- _ O
use -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
adapter -X- _ O
: -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
adapters -X- _ O
and -X- _ O
taskspecific -X- _ O
adapters -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
adapter -X- _ O
modules -X- _ O
have -X- _ O
similar -X- _ O
architecture -X- _ O
as -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
adapters -X- _ O
involve -X- _ O
invertible -X- _ O
adapters -X- _ O
after -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
to -X- _ O
capture -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
language -X- _ O
representation -X- _ O
when -X- _ O
those -X- _ O
are -X- _ O
trained -X- _ O
via -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
stage -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
task -X- _ O
adapters -X- _ O
are -X- _ O
simply -X- _ O
embedded -X- _ O
in -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
and -X- _ O
trained -X- _ O
in -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
task -X- _ O
representation -X- _ O
. -X- _ O
Following -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020c -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
language -X- _ O
adapter -X- _ O
modules -X- _ O
with -X- _ O
invertible -X- _ O
adapter -X- _ O
layers -X- _ O
to -X- _ O
perform -X- _ O
pretraining -X- _ O
adapters -X- _ O
on -X- _ O
the -X- _ O
unlabeled -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
adapter -X- _ O
modules -X- _ O
for -X- _ O
evaluation -X- _ O
to -X- _ O
align -X- _ O
with -X- _ O
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
( -X- _ O
CHEMPROT -X- _ O
( -X- _ O
Kringelum -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
ACL -X- _ O
- -X- _ O
ARC -X- _ O
( -X- _ O
Jurgens -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SCIERC -X- _ O
( -X- _ O
Luan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
HYPERPARTISAN -X- _ O
( -X- _ O
Kiesel -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
settings -X- _ O
. -X- _ O
TAPT -X- _ O
, -X- _ O
whereas -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020c -X- _ O
employ -X- _ O
both -X- _ O
the -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
adapters -X- _ O
by -X- _ O
stacking -X- _ O
task -X- _ O
adapters -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
adapters -X- _ O
. -X- _ O

Comparing -X- _ O
CRF -X- _ B-MethodName
and -X- _ O
LSTM -X- _ B-MethodName
performance -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
morphosyntactic -X- _ B-TaskName
tagging -X- _ I-TaskName
of -X- _ O
non -X- _ O
- -X- _ O
standard -X- _ O
varieties -X- _ O
of -X- _ O
South -X- _ O
Slavic -X- _ O
languages -X- _ O

This -X- _ O
paper -X- _ O
presents -X- _ O
two -X- _ O
systems -X- _ O
taking -X- _ O
part -X- _ O
in -X- _ O
the -X- _ O
Morphosyntactic -X- _ B-TaskName
Tagging -X- _ I-TaskName
of -X- _ I-TaskName
Tweets -X- _ I-TaskName
shared -X- _ O
task -X- _ O
on -X- _ O
Slovene -X- _ O
, -X- _ O
Croatian -X- _ O
and -X- _ O
Serbian -X- _ O
data -X- _ O
, -X- _ O
organized -X- _ O
inside -X- _ O
the -X- _ O
VarDial -X- _ O
Evaluation -X- _ O
Campaign -X- _ O
. -X- _ O
While -X- _ O
one -X- _ O
system -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
traditional -X- _ O
method -X- _ O
for -X- _ O
sequence -X- _ O
labeling -X- _ O
( -X- _ O
conditional -X- _ B-MethodName
random -X- _ I-MethodName
fields -X- _ I-MethodName
) -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
relies -X- _ O
on -X- _ O
its -X- _ O
neural -X- _ O
alternative -X- _ O
( -X- _ O
bidirectional -X- _ B-MethodName
long -X- _ I-MethodName
short -X- _ I-MethodName
- -X- _ I-MethodName
term -X- _ I-MethodName
memory -X- _ I-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
investigate -X- _ O
the -X- _ O
similarities -X- _ O
and -X- _ O
differences -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
approaches -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
both -X- _ O
methods -X- _ O
yield -X- _ O
very -X- _ O
good -X- _ O
and -X- _ O
quite -X- _ O
similar -X- _ O
results -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
neural -X- _ O
model -X- _ O
outperforming -X- _ O
the -X- _ O
traditional -X- _ O
one -X- _ O
more -X- _ O
as -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
standardness -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
increases -X- _ O
. -X- _ O
Through -X- _ O
an -X- _ O
error -X- _ O
analysis -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
neural -X- _ O
system -X- _ O
is -X- _ O
better -X- _ O
at -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
traditional -X- _ O
system -X- _ O
excels -X- _ O
and -X- _ O
slightly -X- _ O
outperforms -X- _ O
the -X- _ O
neural -X- _ O
system -X- _ O
at -X- _ O
the -X- _ O
local -X- _ O
ones -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
morphosyntactic -X- _ B-TaskName
annotation -X- _ I-TaskName
of -X- _ O
non -X- _ O
- -X- _ O
standard -X- _ O
text -X- _ O
for -X- _ O
Slovene -X- _ O
, -X- _ O
Croatian -X- _ O
and -X- _ O
Serbian -X- _ O
. -X- _ O

We -X- _ O
collected -X- _ O
tweets -X- _ O
using -X- _ O
the -X- _ O
Twitter -X- _ O
streaming -X- _ O
API -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
prior -X- _ O
works -X- _ O
( -X- _ O
Mohammad -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
) -X- _ O
that -X- _ O
target -X- _ O
presidential -X- _ O
candidates -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
our -X- _ O
attention -X- _ O
on -X- _ O
three -X- _ O
political -X- _ O
figures -X- _ O
2 -X- _ O
in -X- _ O
the -X- _ O
presidential -X- _ O
race -X- _ O
of -X- _ O
2020 -X- _ O
: -X- _ O
" -X- _ O
Donald -X- _ O
Trump -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
Joe -X- _ O
Biden -X- _ O
, -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Bernie -X- _ O
Sanders -X- _ O
. -X- _ O
" -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
query -X- _ O
hashtags -X- _ O
as -X- _ O
seeds -X- _ O
to -X- _ O
collect -X- _ O
target -X- _ O
- -X- _ O
related -X- _ O
tweets -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
as -X- _ O
favor -X- _ O
hashtags -X- _ O
, -X- _ O
against -X- _ O
hashtags -X- _ O
and -X- _ O
neutral -X- _ O
hashtags -X- _ O
( -X- _ O
Mohammad -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
examples -X- _ O
of -X- _ O
these -X- _ O
query -X- _ O
hashtags -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
gathered -X- _ O
around -X- _ O
2.8 -X- _ O
million -X- _ O
tweets -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
targets -X- _ O
combined -X- _ O
. -X- _ O

An -X- _ O
Empirical -X- _ O
Study -X- _ O
of -X- _ O
Incorporating -X- _ O
Pseudo -X- _ O
Data -X- _ O
into -X- _ O
Grammatical -X- _ B-TaskName
Error -X- _ I-TaskName
Correction -X- _ I-TaskName

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
main -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
testing -X- _ O
the -X- _ O
relation -X- _ O
embeddings -X- _ O
learned -X- _ O
by -X- _ O
RelBERT -X- _ B-MethodName
on -X- _ O
analogy -X- _ B-TaskName
questions -X- _ I-TaskName
( -X- _ O
Section -X- _ O
5.1 -X- _ O
) -X- _ O
and -X- _ O
relation -X- _ B-TaskName
classification -X- _ I-TaskName
( -X- _ O
Section -X- _ O
5.2 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
main -X- _ O
experiments -X- _ O
, -X- _ O
RelBERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
SemEval -X- _ B-DatasetName
2012 -X- _ I-DatasetName
Task -X- _ O
2 -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
dataset -X- _ O
contains -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
including -X- _ O
hypernymy -X- _ O
and -X- _ O
meronymy -X- _ O
relations -X- _ O
. -X- _ O
This -X- _ O
raises -X- _ O
an -X- _ O
important -X- _ O
question -X- _ O
: -X- _ O
Does -X- _ O
RelBERT -X- _ B-MethodName
provide -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
extract -X- _ O
relational -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
As -X- _ O
a -X- _ O
further -X- _ O
analysis -X- _ O
, -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
a -X- _ O
breakdown -X- _ O
of -X- _ O
the -X- _ O
Google -X- _ O
and -X- _ O
BATS -X- _ O
analogy -X- _ O
results -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
level -X- _ O
categories -X- _ O
from -X- _ O
these -X- _ O
datasets -X- _ O
. -X- _ O
10 -X- _ O
While -X- _ O
RelBERT -X- _ B-MethodName
is -X- _ O
outperformed -X- _ O
by -X- _ O
FastText -X- _ B-MethodName
on -X- _ O
the -X- _ O
morphological -X- _ O
relations -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
differences -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
while -X- _ O
such -X- _ O
relations -X- _ O
are -X- _ O
of -X- _ O
a -X- _ O
very -X- _ O
different -X- _ O
nature -X- _ O
than -X- _ O
those -X- _ O
from -X- _ O
the -X- _ O
SemEval -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
confirms -X- _ O
that -X- _ O
RelBERT -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
model -X- _ O
a -X- _ O
broad -X- _ O
range -X- _ O
of -X- _ O
relations -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
expected -X- _ O
that -X- _ O
better -X- _ O
results -X- _ O
would -X- _ O
be -X- _ O
possible -X- _ O
by -X- _ O
including -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
training -X- _ O
data -X- _ O
into -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
( -X- _ O
e.g. -X- _ O
including -X- _ O
morphological -X- _ O
relations -X- _ O
for -X- _ O
tasks -X- _ O
where -X- _ O
such -X- _ O
relations -X- _ O
matter -X- _ O
) -X- _ O
. -X- _ O

Nearest -X- _ O
Neighbors -X- _ O
barista -X- _ O
: -X- _ O
coffee -X- _ O
baker -X- _ O
: -X- _ O
bread -X- _ O
, -X- _ O
brewer -X- _ O
: -X- _ O
beer -X- _ O
, -X- _ O
bartender -X- _ O
: -X- _ O
cocktail -X- _ O
, -X- _ O
winemaker -X- _ O
: -X- _ O
wine -X- _ O
, -X- _ O
bartender -X- _ O
: -X- _ O
drink -X- _ O
, -X- _ O
baker -X- _ O
: -X- _ O
cake -X- _ O
bag -X- _ O
: -X- _ O
plastic -X- _ O
bottle -X- _ O
: -X- _ O
plastic -X- _ O
, -X- _ O
bag -X- _ O
: -X- _ O
leather -X- _ O
, -X- _ O
container -X- _ O
: -X- _ O
plastic -X- _ O
, -X- _ O
box -X- _ O
: -X- _ O
plastic -X- _ O
, -X- _ O
jug -X- _ O
: -X- _ O
glass -X- _ O
, -X- _ O
bottle -X- _ O
: -X- _ O
glass -X- _ O
duck -X- _ O
: -X- _ O
duckling -X- _ O
chicken -X- _ O
: -X- _ O
chick -X- _ O
, -X- _ O
pig -X- _ O
: -X- _ O
piglet -X- _ O
, -X- _ O
cat -X- _ O
: -X- _ O
kitten -X- _ O
, -X- _ O
ox -X- _ O
: -X- _ O
calf -X- _ O
, -X- _ O
butterfly -X- _ O
: -X- _ O
larvae -X- _ O
, -X- _ O
bear -X- _ O
: -X- _ O
cub -X- _ O
cooked -X- _ O
: -X- _ O
raw -X- _ O
raw -X- _ O
: -X- _ O
cooked -X- _ O
, -X- _ O
regulated -X- _ O
: -X- _ O
unregulated -X- _ O
, -X- _ O
sober -X- _ O
: -X- _ O
drunk -X- _ O
, -X- _ O
loaded -X- _ O
: -X- _ O
unloaded -X- _ O
, -X- _ O
armed -X- _ O
: -X- _ O
unarmed -X- _ O
, -X- _ O
published -X- _ O
: -X- _ O
unpublished -X- _ O
chihuahua -X- _ O
: -X- _ O
dog -X- _ O
dachshund -X- _ O
: -X- _ O
dog -X- _ O
, -X- _ O
poodle -X- _ O
: -X- _ O
dog -X- _ O
, -X- _ O
terrier -X- _ O
: -X- _ O
dog -X- _ O
, -X- _ O
chinchilla -X- _ O
: -X- _ O
rodent -X- _ O
, -X- _ O
macaque -X- _ O
: -X- _ O
monkey -X- _ O
, -X- _ O
dalmatian -X- _ O
: -X- _ O
dog -X- _ O
dog -X- _ O
: -X- _ O
dogs -X- _ O
cat -X- _ O
: -X- _ O
cats -X- _ O
, -X- _ O
horse -X- _ O
: -X- _ O
horses -X- _ O
, -X- _ O
pig -X- _ O
: -X- _ O
pigs -X- _ O
, -X- _ O
rat -X- _ O
: -X- _ O
rats -X- _ O
, -X- _ O
wolf -X- _ O
: -X- _ O
wolves -X- _ O
, -X- _ O
monkey -X- _ O
: -X- _ O
monkeys -X- _ O
spy -X- _ O
: -X- _ O
espionage -X- _ O
pirate -X- _ O
: -X- _ O
piracy -X- _ O
, -X- _ O
robber -X- _ O
: -X- _ O
robbery -X- _ O
, -X- _ O
lobbyist -X- _ O
: -X- _ O
lobbying -X- _ O
, -X- _ O
scout -X- _ O
: -X- _ O
scouting -X- _ O
, -X- _ O
terrorist -X- _ O
: -X- _ O
terrorism -X- _ O
, -X- _ O
witch -X- _ O
: -X- _ O
witchcraft -X- _ O

Figure -X- _ O
3 -X- _ O
compares -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RelBERT -X- _ B-MethodName
with -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
vanilla -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
i.e. -X- _ O
when -X- _ O
only -X- _ O
the -X- _ O
prompt -X- _ O
is -X- _ O
optimized -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
achieving -X- _ O
good -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
main -X- _ O
RelBERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
with -X- _ O
versions -X- _ O
that -X- _ O
were -X- _ O
instead -X- _ O
initialized -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
11 -X- _ O
RoBERTa -X- _ B-MethodName
clearly -X- _ O
outperforms -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
LMs -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
in -X- _ O
accordance -X- _ O
with -X- _ O
findings -X- _ O
from -X- _ O
the -X- _ O
literature -X- _ O
suggesting -X- _ O
that -X- _ O
RoBERTa -X- _ B-MethodName
captures -X- _ O
more -X- _ O
semantic -X- _ O
knowledge -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
Transformer -X- _ O
network -X- _ O
[ -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
] -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
widely -X- _ O
in -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
[ -X- _ O
Tubay -X- _ O
and -X- _ O
Costa -X- _ O
- -X- _ O
jussà -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
Xia -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
and -X- _ O
has -X- _ O
proven -X- _ O
effective -X- _ O
for -X- _ O
sentiment -X- _ O
analysis -X- _ O
and -X- _ O
emotion -X- _ O
recognition -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
existing -X- _ O
architectures -X- _ O
are -X- _ O
very -X- _ O
dense -X- _ O
compared -X- _ O
to -X- _ O
our -X- _ O
three -X- _ O
lightweight -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
Multimodal -X- _ B-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
MuLT -X- _ B-MethodName
) -X- _ O
of -X- _ O
Tsai -X- _ O
et -X- _ O
al -X- _ O
[ -X- _ O
2019 -X- _ O
] -X- _ O
modifies -X- _ O
the -X- _ O
Transformer -X- _ O
block -X- _ O
to -X- _ O
compute -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
attention -X- _ O
for -X- _ O
two -X- _ O
modalities -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
It -X- _ O
combines -X- _ O
modalities -X- _ O
in -X- _ O
directed -X- _ O
pairs -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
six -X- _ O
Transformers -X- _ O
, -X- _ O
whose -X- _ O
outputs -X- _ O
are -X- _ O
then -X- _ O
merged -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
multimodal -X- _ O
representation -X- _ O
. -X- _ O
Unlike -X- _ O
other -X- _ O
works -X- _ O
, -X- _ O
MuLT -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
handle -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
three -X- _ O
modalities -X- _ O
are -X- _ O
not -X- _ O
aligned -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
; -X- _ O
it -X- _ O
learns -X- _ O
soft -X- _ O
alignments -X- _ O
via -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
attention -X- _ O
weights -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
modalities -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
works -X- _ O
well -X- _ O
in -X- _ O
the -X- _ O
unaligned -X- _ O
case -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
the -X- _ O
aligned -X- _ O
case -X- _ O
, -X- _ O
it -X- _ O
gives -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
performance -X- _ O
the -X- _ O
Happy -X- _ O
emotion -X- _ O
in -X- _ O
IEMO -X- _ B-DatasetName
- -X- _ I-DatasetName
CAP -X- _ I-DatasetName
. -X- _ O
The -X- _ O
Factorized -X- _ B-MethodName
Multimodal -X- _ I-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
FMT -X- _ B-MethodName
) -X- _ O
of -X- _ O
introduces -X- _ O
Factorized -X- _ O
Multimodal -X- _ O
Self -X- _ O
- -X- _ O
Attention -X- _ O
( -X- _ O
FSM -X- _ O
) -X- _ O
modules -X- _ O
, -X- _ O
which -X- _ O
compute -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
over -X- _ O
unimodal -X- _ O
, -X- _ O
bimodal -X- _ O
, -X- _ O
and -X- _ O
trimodal -X- _ O
inputs -X- _ O
in -X- _ O
parallel -X- _ O
. -X- _ O
FMT -X- _ B-MethodName
gives -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
aligned -X- _ O
case -X- _ O
on -X- _ O
CMU -X- _ B-DatasetName
- -X- _ I-DatasetName
MOSI -X- _ I-DatasetName
and -X- _ O
on -X- _ O
the -X- _ O
Sad -X- _ O
, -X- _ O
Angry -X- _ O
, -X- _ O
and -X- _ O
Neutral -X- _ O
emotions -X- _ O
in -X- _ O
IEMOCAP -X- _ B-DatasetName
. -X- _ O
We -X- _ O
use -X- _ O
FMT -X- _ B-MethodName
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
aligned -X- _ O
version -X- _ O
of -X- _ O
MuLT -X- _ B-MethodName
, -X- _ O
as -X- _ O
baselines -X- _ O
for -X- _ O
comparison -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
give -X- _ O
an -X- _ O
exhaustive -X- _ O
list -X- _ O
of -X- _ O
prior -X- _ O
work -X- _ O
in -X- _ O
multimodal -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
, -X- _ O
but -X- _ O
focus -X- _ O
on -X- _ O
recent -X- _ O
neural -X- _ O
approaches -X- _ O
that -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
at -X- _ O
their -X- _ O
times -X- _ O
of -X- _ O
publication -X- _ O
. -X- _ O

We -X- _ O
relied -X- _ O
on -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
English -X- _ O
version -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
uncased -X- _ O
, -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
) -X- _ O
for -X- _ O
the -X- _ O
extraction -X- _ O
of -X- _ O
the -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
To -X- _ O
obtain -X- _ O
the -X- _ O
representations -X- _ O
for -X- _ O
our -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
we -X- _ O
experimented -X- _ O
the -X- _ O
activation -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
1 -X- _ O
and -X- _ O
four -X- _ O
different -X- _ O
combining -X- _ O
methods -X- _ O
: -X- _ O
Max -X- _ O
- -X- _ O
pooling -X- _ O
, -X- _ O
Min -X- _ O
- -X- _ O
pooling -X- _ O
, -X- _ O
Mean -X- _ O
and -X- _ O
Sum -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
this -X- _ O
four -X- _ O
combining -X- _ O
methods -X- _ O
returns -X- _ O
a -X- _ O
single -X- _ O
s -X- _ O
vector -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
each -X- _ O
s -X- _ O
n -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
n -X- _ O
th -X- _ O
components -X- _ O
w -X- _ O
1n -X- _ O
, -X- _ O
w -X- _ O
2n -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
mn -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
conduct -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
contextbased -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
representations -X- _ O
when -X- _ O
solving -X- _ O
our -X- _ O
set -X- _ O
of -X- _ O
probing -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
all -X- _ O
the -X- _ O
probing -X- _ O
experiments -X- _ O
using -X- _ O
also -X- _ O
the -X- _ O
embeddings -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
version -X- _ O
of -X- _ O
Word2vec -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
dump -X- _ O
of -X- _ O
March -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
300 -X- _ O
- -X- _ O
dimensional -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
same -X- _ O
manner -X- _ O
as -X- _ O
BERT -X- _ O
's -X- _ O
contextual -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
experimented -X- _ O
four -X- _ O
combining -X- _ O
methods -X- _ O
: -X- _ O
Max -X- _ O
- -X- _ O
pooling -X- _ O
, -X- _ O
Min -X- _ O
- -X- _ O
pooling -X- _ O
, -X- _ O
Mean -X- _ O
and -X- _ O
Sum -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
linear -X- _ O
Support -X- _ B-MethodName
Vector -X- _ I-MethodName
Regression -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
LinearSVR -X- _ O
) -X- _ O
as -X- _ O
probing -X- _ O
model -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
removed -X- _ O
all -X- _ O
the -X- _ O
punctuations -X- _ O
, -X- _ O
numbers -X- _ O
, -X- _ O
links -X- _ O
and -X- _ O
stop -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
used -X- _ O
lemmatization -X- _ O
for -X- _ O
grouping -X- _ O
together -X- _ O
the -X- _ O
different -X- _ O
forms -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
. -X- _ O
NLTK -X- _ O
wordnet -X- _ O
( -X- _ O
Loper -X- _ O
and -X- _ O
Bird -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
lemmatization -X- _ O
. -X- _ O

Multivalent -X- _ B-MethodName
Entailment -X- _ I-MethodName
Graphs -X- _ I-MethodName
for -X- _ O
Question -X- _ B-TaskName
Answering -X- _ I-TaskName

The -X- _ O
task -X- _ O
of -X- _ O
recognizing -X- _ B-TaskName
textual -X- _ I-TaskName
entailment -X- _ I-TaskName
( -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
requires -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
relation -X- _ O
between -X- _ O
a -X- _ O
text -X- _ O
T -X- _ O
and -X- _ O
hypothesis -X- _ O
H -X- _ O
; -X- _ O
" -X- _ O
T -X- _ O
entails -X- _ O
H -X- _ O
if -X- _ O
, -X- _ O
typically -X- _ O
, -X- _ O
a -X- _ O
human -X- _ O
reading -X- _ O
T -X- _ O
would -X- _ O
infer -X- _ O
that -X- _ O
H -X- _ O
is -X- _ O
most -X- _ O
likely -X- _ O
true -X- _ O
. -X- _ O
" -X- _ O
From -X- _ O
here -X- _ O
, -X- _ O
research -X- _ O
has -X- _ O
moved -X- _ O
in -X- _ O
several -X- _ O
directions -X- _ O
. -X- _ O
We -X- _ O
study -X- _ O
predicates -X- _ O
, -X- _ O
including -X- _ O
verbs -X- _ O
and -X- _ O
phrases -X- _ O
that -X- _ O
apply -X- _ O
to -X- _ O
arguments -X- _ O
. -X- _ O
Research -X- _ O
in -X- _ O
predicate -X- _ O
entailment -X- _ O
graphs -X- _ O
has -X- _ O
evolved -X- _ O
from -X- _ O
" -X- _ O
local -X- _ O
" -X- _ O
learning -X- _ O
of -X- _ O
entailment -X- _ O
rules -X- _ O
( -X- _ O
Geffet -X- _ O
and -X- _ O
Dagan -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Szpektor -X- _ O
and -X- _ O
Dagan -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
to -X- _ O
later -X- _ O
work -X- _ O
on -X- _ O
joint -X- _ O
learning -X- _ O
of -X- _ O
" -X- _ O
globalized -X- _ O
" -X- _ O
rules -X- _ O
, -X- _ O
overcoming -X- _ O
sparsity -X- _ O
in -X- _ O
local -X- _ O
graphs -X- _ O
( -X- _ O
Berant -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Hosseini -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
graphs -X- _ O
frequently -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
DIH -X- _ O
for -X- _ O
the -X- _ O
local -X- _ O
learning -X- _ O
step -X- _ O
to -X- _ O
learn -X- _ O
initial -X- _ O
predicate -X- _ O
entailments -X- _ O
. -X- _ O
The -X- _ O
DIH -X- _ O
states -X- _ O
that -X- _ O
for -X- _ O
some -X- _ O
predicates -X- _ O
p -X- _ O
and -X- _ O
q -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
contextual -X- _ O
features -X- _ O
of -X- _ O
p -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
those -X- _ O
of -X- _ O
q -X- _ O
, -X- _ O
then -X- _ O
p -X- _ O
entails -X- _ O
q -X- _ O
( -X- _ O
Geffet -X- _ O
and -X- _ O
Dagan -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
previous -X- _ O
work -X- _ O
predicate -X- _ O
arguments -X- _ O
are -X- _ O
successfully -X- _ O
used -X- _ O
as -X- _ O
these -X- _ O
contextual -X- _ O
features -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
predicates -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
valency -X- _ O
are -X- _ O
considered -X- _ O
( -X- _ O
e.g. -X- _ O
binary -X- _ O
predicates -X- _ O
entail -X- _ O
binary -X- _ O
; -X- _ O
unary -X- _ O
entail -X- _ O
unary -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
further -X- _ O
research -X- _ O
computes -X- _ O
additional -X- _ O
edges -X- _ O
in -X- _ O
these -X- _ O
same -X- _ O
- -X- _ O
valency -X- _ O
graphs -X- _ O
such -X- _ O
as -X- _ O
with -X- _ O
link -X- _ O
prediction -X- _ O
( -X- _ O
Hosseini -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
leaves -X- _ O
out -X- _ O
crucial -X- _ O
inferences -X- _ O
that -X- _ O
cross -X- _ O
valencies -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
kill -X- _ O
/ -X- _ O
die -X- _ O
example -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
easy -X- _ O
for -X- _ O
humans -X- _ O
. -X- _ O
We -X- _ O
generalize -X- _ O
the -X- _ O
DIH -X- _ O
to -X- _ O
learn -X- _ O
entailments -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
valencies -X- _ O
. -X- _ O
Typing -X- _ O
is -X- _ O
very -X- _ O
helpful -X- _ O
for -X- _ O
entailment -X- _ O
graph -X- _ O
learning -X- _ O
( -X- _ O
Berant -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Lewis -X- _ O
and -X- _ O
Steedman -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Hosseini -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Inducing -X- _ O
a -X- _ O
type -X- _ O
for -X- _ O
each -X- _ O
entity -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
person -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
location -X- _ O
, -X- _ O
" -X- _ O
etc -X- _ O
. -X- _ O
enables -X- _ O
generalized -X- _ O
learning -X- _ O
across -X- _ O
instances -X- _ O
and -X- _ O
disambiguates -X- _ O
word -X- _ O
sense -X- _ O
, -X- _ O
e.g. -X- _ O
" -X- _ O
running -X- _ O
a -X- _ O
company -X- _ O
" -X- _ O
has -X- _ O
different -X- _ O
entailments -X- _ O
than -X- _ O
" -X- _ O
running -X- _ O
code -X- _ O
. -X- _ O
" -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
several -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
strong -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
setting -X- _ O
using -X- _ O
similarity -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
generates -X- _ O
impressive -X- _ O
word -X- _ O
representations -X- _ O
, -X- _ O
even -X- _ O
unsupervised -X- _ O
( -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
on -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
predicate -X- _ O
inference -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
test -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
robust -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
pretraining -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
. -X- _ O
These -X- _ O
non -X- _ O
- -X- _ O
directional -X- _ O
similarity -X- _ O
models -X- _ O
provide -X- _ O
a -X- _ O
strong -X- _ O
baseline -X- _ O
for -X- _ O
evaluating -X- _ O
directional -X- _ O
entailment -X- _ O
graphs -X- _ O
. -X- _ O

We -X- _ O
sample -X- _ O
300 -X- _ O
false -X- _ O
positives -X- _ O
( -X- _ O
100 -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
) -X- _ O
and -X- _ O
report -X- _ O
analyses -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
models -X- _ O
spurious -X- _ O
entailments -X- _ O
are -X- _ O
the -X- _ O
largest -X- _ O
issue -X- _ O
, -X- _ O
and -X- _ O
may -X- _ O
occur -X- _ O
due -X- _ O
to -X- _ O
normalization -X- _ O
of -X- _ O
predicates -X- _ O
during -X- _ O
learning -X- _ O
, -X- _ O
or -X- _ O
incidental -X- _ O
correlations -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
UU -X- _ B-MethodName
and -X- _ O
BU -X- _ B-MethodName
models -X- _ O
also -X- _ O
suffer -X- _ O
during -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
parsing -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
fail -X- _ O
to -X- _ O
parse -X- _ O
a -X- _ O
second -X- _ O
argument -X- _ O
for -X- _ O
a -X- _ O
predicate -X- _ O
we -X- _ O
assume -X- _ O
it -X- _ O
only -X- _ O
has -X- _ O
one -X- _ O
and -X- _ O
extract -X- _ O
a -X- _ O
malformed -X- _ O
unary -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
interfere -X- _ O
with -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
e.g. -X- _ O
reporting -X- _ O
verbs -X- _ O
" -X- _ O
explain -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
announce -X- _ O
, -X- _ O
" -X- _ O
etc -X- _ O
. -X- _ O
which -X- _ O
fail -X- _ O
to -X- _ O
parse -X- _ O
with -X- _ O
their -X- _ O
quote -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
relatively -X- _ O
few -X- _ O
poorly -X- _ O
generated -X- _ O
negatives -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
actually -X- _ O
true -X- _ O
given -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
In -X- _ O
these -X- _ O
cases -X- _ O
the -X- _ O
model -X- _ O
finds -X- _ O
an -X- _ O
entailment -X- _ O
which -X- _ O
the -X- _ O
authors -X- _ O
judge -X- _ O
to -X- _ O
be -X- _ O
correct -X- _ O
. -X- _ O

MLEC -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
: -X- _ O
A -X- _ O
Chinese -X- _ O
Multi -X- _ O
- -X- _ O
Choice -X- _ O
Biomedical -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
Dataset -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
ERC -X- _ O
H2020 -X- _ O
Advanced -X- _ O
Fellowship -X- _ O
GA -X- _ O
742137 -X- _ O
SEMANTAX -X- _ O
, -X- _ O

Multi -X- _ B-TaskName
- -X- _ I-TaskName
source -X- _ I-TaskName
translation -X- _ I-TaskName
consists -X- _ O
in -X- _ O
exploiting -X- _ O
multiple -X- _ O
text -X- _ O
inputs -X- _ O
to -X- _ O
improve -X- _ O
NMT -X- _ B-TaskName
( -X- _ O
Zoph -X- _ O
and -X- _ O
Knight -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
using -X- _ O
this -X- _ O
approach -X- _ O
in -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
architecture -X- _ O
described -X- _ O
above -X- _ O
and -X- _ O
using -X- _ O
only -X- _ O
inputs -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
family -X- _ O
. -X- _ O

The -X- _ O
experimental -X- _ O
framework -X- _ O
is -X- _ O
the -X- _ O
Biomedical -X- _ B-TaskName
Translation -X- _ I-TaskName
Task -X- _ I-TaskName
( -X- _ O
WMT18 -X- _ B-DatasetName
) -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
corpus -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
are -X- _ O
the -X- _ O
one -X- _ O
provided -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
selected -X- _ O
languages -X- _ O
pairs -X- _ O
: -X- _ O
Spanishto -X- _ O
- -X- _ O
English -X- _ O
( -X- _ O
es2en -X- _ O
) -X- _ O
, -X- _ O
French -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
( -X- _ O
fr2en -X- _ O
) -X- _ O
and -X- _ O
Portuguese -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
( -X- _ O
pt2en -X- _ O
) -X- _ O
. -X- _ O
Sources -X- _ O
are -X- _ O
mainly -X- _ O
from -X- _ O
Scielo -X- _ O
and -X- _ O
Medline -X- _ O
and -X- _ O
detailed -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Validation -X- _ O
sets -X- _ O
were -X- _ O
taken -X- _ O
from -X- _ O
Khresmoi -X- _ O
development -X- _ O
data -X- _ O
3 -X- _ O
, -X- _ O
as -X- _ O
recommended -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
description -X- _ O
. -X- _ O
Each -X- _ O
validation -X- _ O
dataset -X- _ O
contains -X- _ O
500 -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
Test -X- _ O
sets -X- _ O
were -X- _ O
the -X- _ O
ones -X- _ O
provides -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
previous -X- _ O
year -X- _ O
competition -X- _ O
( -X- _ O
WMT17 -X- _ B-DatasetName
4 -X- _ O
) -X- _ O
. -X- _ O
Preprocessing -X- _ O
relied -X- _ O
on -X- _ O
three -X- _ O
basic -X- _ O
steps -X- _ O
: -X- _ O
tokenization -X- _ O
, -X- _ O
truecasing -X- _ O
and -X- _ O
limiting -X- _ O
sentence -X- _ O
length -X- _ O
to -X- _ O
80 -X- _ O
words -X- _ O
. -X- _ O
Words -X- _ O
were -X- _ O
segmented -X- _ O
by -X- _ O
means -X- _ O
of -X- _ O
Byte -X- _ O
- -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

CODEX -X- _ B-DatasetName
: -X- _ O
A -X- _ O
Comprehensive -X- _ O
Knowledge -X- _ B-TaskName
Graph -X- _ I-TaskName
Completion -X- _ I-TaskName
Benchmark -X- _ O

We -X- _ O
first -X- _ O
compare -X- _ O
the -X- _ O
content -X- _ O
in -X- _ O
CODEX -X- _ B-DatasetName
- -X- _ I-DatasetName
M -X- _ I-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
Wikidata -X- _ O
, -X- _ O
with -X- _ O
that -X- _ O
of -X- _ O
FB15 -X- _ B-DatasetName
K -X- _ I-DatasetName
- -X- _ I-DatasetName
237 -X- _ I-DatasetName
, -X- _ O
which -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
Freebase -X- _ O
. -X- _ O
For -X- _ O
brevity -X- _ O
, -X- _ O
Figure -X- _ O
2 -X- _ O
compares -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
15 -X- _ O
relations -X- _ O
by -X- _ O
mention -X- _ O
count -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
Appendix -X- _ O
E -X- _ O
provides -X- _ O
more -X- _ O
content -X- _ O
comparisons -X- _ O
. -X- _ O
Diversity -X- _ O
The -X- _ O
most -X- _ O
common -X- _ O
relation -X- _ O
in -X- _ O
CODEX -X- _ B-DatasetName
- -X- _ I-DatasetName
M -X- _ I-DatasetName
is -X- _ O
occupation -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
because -X- _ O
most -X- _ O
people -X- _ O
on -X- _ O
Wikidata -X- _ O
have -X- _ O
multiple -X- _ O
occupations -X- _ O
listed -X- _ O
. -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
frequent -X- _ O
relations -X- _ O
in -X- _ O
FB15 -X- _ B-DatasetName
K -X- _ I-DatasetName
- -X- _ I-DatasetName
237 -X- _ I-DatasetName
are -X- _ O
mostly -X- _ O
related -X- _ O
to -X- _ O
awards -X- _ O
and -X- _ O
film -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
over -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
triples -X- _ O
in -X- _ O
FB15 -X- _ B-DatasetName
K -X- _ I-DatasetName
- -X- _ I-DatasetName
237 -X- _ I-DatasetName
belong -X- _ O
to -X- _ O
the -X- _ O
/award -X- _ O
relation -X- _ O
domain -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
CODEX -X- _ B-DatasetName
covers -X- _ O
a -X- _ O
more -X- _ O
diverse -X- _ O
selection -X- _ O
of -X- _ O
content -X- _ O
. -X- _ O
Interpretability -X- _ O
The -X- _ O
Freebase -X- _ B-DatasetName
- -X- _ O
style -X- _ O
relations -X- _ O
are -X- _ O
also -X- _ O
arguably -X- _ O
less -X- _ O
interpretable -X- _ O
than -X- _ O
those -X- _ O
in -X- _ O
Wikidata -X- _ B-DatasetName
. -X- _ O
Whereas -X- _ O
Wikidata -X- _ B-DatasetName
relations -X- _ O
have -X- _ O
concise -X- _ O
natural -X- _ O
language -X- _ O
labels -X- _ O
, -X- _ O
the -X- _ O
Freebase -X- _ B-DatasetName
relation -X- _ O
labels -X- _ O
are -X- _ O
hierarchical -X- _ O
, -X- _ O
often -X- _ O
at -X- _ O
five -X- _ O
or -X- _ O
six -X- _ O
levels -X- _ O
of -X- _ O
hierarchy -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
all -X- _ O
relations -X- _ O
in -X- _ O
Wikidata -X- _ B-DatasetName
are -X- _ O
binary -X- _ O
, -X- _ O
whereas -X- _ O
some -X- _ O
Freebase -X- _ B-DatasetName
relations -X- _ O
are -X- _ O
n -X- _ O
- -X- _ O
nary -X- _ O
( -X- _ O
Tanon -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
they -X- _ O
connect -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
entities -X- _ O
. -X- _ O
The -X- _ O
relations -X- _ O
containing -X- _ O
a -X- _ O
dot -X- _ O
( -X- _ O
" -X- _ O
. -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
such -X- _ O
n -X- _ O
- -X- _ O
nary -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
difficult -X- _ O
to -X- _ O
reason -X- _ O
about -X- _ O
without -X- _ O
understanding -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
Freebase -X- _ B-DatasetName
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
deprecated -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
discuss -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
such -X- _ O
n -X- _ O
- -X- _ O
nary -X- _ O
relations -X- _ O
for -X- _ O
link -X- _ O
prediction -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
CODEX -X- _ B-DatasetName
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
knowledge -X- _ O
graph -X- _ O
COmpletion -X- _ O
Datasets -X- _ O
EXtracted -X- _ O
from -X- _ O
Wikidata -X- _ O
and -X- _ O
Wikipedia -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
CODEX -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
multiple -X- _ O
KGC -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
data -X- _ O
, -X- _ O
code -X- _ O
, -X- _ O
and -X- _ O
pretrained -X- _ O
models -X- _ O
for -X- _ O
use -X- _ O
by -X- _ O
the -X- _ O
community -X- _ O
at -X- _ O
https://bit.ly/2EPbrJs -X- _ O
. -X- _ O
Some -X- _ O
promising -X- _ O
future -X- _ O
directions -X- _ O
on -X- _ O
CODEX -X- _ B-DatasetName
include -X- _ O
: -X- _ O
Better -X- _ O
model -X- _ O
understanding -X- _ O
CODEX -X- _ B-DatasetName
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
hyperparameters -X- _ O
, -X- _ O
training -X- _ O
strategies -X- _ O
, -X- _ O
and -X- _ O
model -X- _ O
architectures -X- _ O
in -X- _ O
KGC -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Revival -X- _ O
of -X- _ O
triple -X- _ O
classification -X- _ O
We -X- _ O
encourage -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
triple -X- _ B-TaskName
classification -X- _ I-TaskName
on -X- _ O
CODEX -X- _ B-DatasetName
in -X- _ O
addition -X- _ O
to -X- _ O
link -X- _ O
prediction -X- _ O
because -X- _ O
it -X- _ O
directly -X- _ O
tests -X- _ O
discriminative -X- _ O
power -X- _ O
. -X- _ O
Fusing -X- _ O
text -X- _ O
and -X- _ O
structure -X- _ O
Including -X- _ O
text -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
link -X- _ B-TaskName
prediction -X- _ I-TaskName
and -X- _ O
triple -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
should -X- _ O
substantially -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
text -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
link -X- _ O
prediction -X- _ O
, -X- _ O
an -X- _ O
emerging -X- _ O
research -X- _ O
direction -X- _ O
( -X- _ O
Xiong -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Shi -X- _ O
and -X- _ O
Weninger -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
that -X- _ O
CODEX -X- _ B-DatasetName
will -X- _ O
provide -X- _ O
a -X- _ O
boost -X- _ O
to -X- _ O
research -X- _ O
in -X- _ O
KGC -X- _ B-TaskName
, -X- _ O
which -X- _ O
will -X- _ O
in -X- _ O
turn -X- _ O
impact -X- _ O
many -X- _ O
other -X- _ O
fields -X- _ O
of -X- _ O
artificial -X- _ O
intelligence -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explored -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
various -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
under -X- _ O
the -X- _ O
NAG -X- _ B-TaskName
framework -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
problems -X- _ O
from -X- _ O
NAG -X- _ B-TaskName
models -X- _ O
previously -X- _ O
having -X- _ O
a -X- _ O
prefixed -X- _ O
output -X- _ O
length -X- _ O
, -X- _ O
we -X- _ O
devised -X- _ O
a -X- _ O
decoding -X- _ O
mechanism -X- _ O
which -X- _ O
enables -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
output -X- _ O
length -X- _ O
dynamically -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
errors -X- _ O
stemming -X- _ O
from -X- _ O
the -X- _ O
assumption -X- _ O
of -X- _ O
conditional -X- _ O
independence -X- _ O
of -X- _ O
output -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
a -X- _ O
context -X- _ O
- -X- _ O
aware -X- _ O
objective -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
using -X- _ O
a -X- _ O
CRF -X- _ O
decoding -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
inference -X- _ O
speed -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
a -X- _ O
ratio -X- _ O
- -X- _ O
first -X- _ O
decoding -X- _ O
strategy -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
many -X- _ O
strong -X- _ O
NAG -X- _ B-TaskName
baselines -X- _ O
and -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
many -X- _ O
strong -X- _ O
AG -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
open -X- _ O
data -X- _ O
sets -X- _ O
from -X- _ O
CoNLL -X- _ B-DatasetName
, -X- _ O
Twitter -X- _ B-DatasetName
and -X- _ O
OntoNotes -X- _ B-DatasetName
. -X- _ O
The -X- _ O
training -X- _ O
, -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
splits -X- _ O
of -X- _ O
CoNLL -X- _ B-DatasetName
and -X- _ O
OntoNotes -X- _ B-DatasetName
follows -X- _ O
the -X- _ O
standard -X- _ O
splits -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
split -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
data -X- _ O
set -X- _ O
randomly -X- _ O
into -X- _ O
70 -X- _ O
% -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
for -X- _ O
development -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
train -X- _ O
, -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
joining -X- _ O
all -X- _ O
the -X- _ O
respective -X- _ O
splits -X- _ O
across -X- _ O
the -X- _ O
individual -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O

For -X- _ O
subtask -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
modeled -X- _ O
the -X- _ O
problem -X- _ O
as -X- _ O
a -X- _ O
multilabel -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
of -X- _ O
the -X- _ O
meme -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
content -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
parallel -X- _ O
channel -X- _ O
model -X- _ O
of -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
channels -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
concatenated -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
features -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
two -X- _ O
parallel -X- _ O
channels -X- _ O
to -X- _ O
apply -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
meme -X- _ O
classification -X- _ O
. -X- _ O
The -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Text -X- _ O
Channel -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
text -X- _ O
channel -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
model -X- _ O
used -X- _ O
in -X- _ O
subtask -X- _ O
1 -X- _ O
, -X- _ O
taking -X- _ O
the -X- _ O
text -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
meme -X- _ O
content -X- _ O
as -X- _ O
an -X- _ O
input -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
768 -X- _ O
- -X- _ O
dimensional -X- _ O
text -X- _ O
feature -X- _ O
vector -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
Image -X- _ O
Channel -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
image -X- _ O
channel -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
ResNet -X- _ B-MethodName
and -X- _ O
VGGNet -X- _ B-MethodName
, -X- _ O
taking -X- _ O
the -X- _ O
image -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
meme -X- _ O
content -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
512 -X- _ O
- -X- _ O
dimensional -X- _ O
image -X- _ O
feature -X- _ O
vector -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
The -X- _ O
ResNet -X- _ B-MethodName
model -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
deep -X- _ O
residual -X- _ O
learning -X- _ O
model -X- _ O
for -X- _ O
image -X- _ O
recognition -X- _ O
, -X- _ O
and -X- _ O
presents -X- _ O
the -X- _ O
interlayer -X- _ O
residual -X- _ O
jump -X- _ O
connection -X- _ O
and -X- _ O
solves -X- _ O
the -X- _ O
deep -X- _ O
vanishing -X- _ O
gradient -X- _ O
problem -X- _ O
. -X- _ O
VGGNet -X- _ B-MethodName
( -X- _ O
Simonyan -X- _ O
and -X- _ O
Zisserman -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
deep -X- _ O
convolutional -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
small -X- _ O
- -X- _ O
sized -X- _ O
convolutional -X- _ O
kernels -X- _ O
and -X- _ O
a -X- _ O
regular -X- _ O
network -X- _ O
structure -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
convolution -X- _ I-HyperparameterName
kernels -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
VGG16 -X- _ B-MethodName
in -X- _ O
our -X- _ O
experiment -X- _ O
is -X- _ O
3 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
3 -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
pooling -X- _ O
kernels -X- _ O
is -X- _ O
2 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
2 -X- _ I-HyperparameterValue
. -X- _ O
Furthermore -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
structures -X- _ O
of -X- _ O
the -X- _ O
ResNet -X- _ B-MethodName
and -X- _ O
VGGNet -X- _ B-MethodName
were -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiment -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
weights -X- _ O
were -X- _ O
not -X- _ O
applied -X- _ O
. -X- _ O

Subtask -X- _ O
2 -X- _ O
was -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
label -X- _ I-TaskName
sequence -X- _ I-TaskName
- -X- _ I-TaskName
labeling -X- _ I-TaskName
task -X- _ O
. -X- _ O
We -X- _ O
built -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
converting -X- _ O
the -X- _ O
problem -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
coverage -X- _ O
of -X- _ O
each -X- _ O
propagation -X- _ O
technique -X- _ O
separately -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
built -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
sequence -X- _ I-TaskName
labeling -X- _ I-TaskName
model -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
was -X- _ O
first -X- _ O
obtained -X- _ O
using -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
hidden -X- _ O
representation -X- _ O
matrix -X- _ O
with -X- _ O
dimensions -X- _ B-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
× -X- _ O
768 -X- _ B-HyperparameterValue
. -X- _ O
Subsequently -X- _ O
, -X- _ O
20 -X- _ B-HyperparameterValue
parallel -X- _ O
fully -X- _ B-HyperparameterName
connected -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
were -X- _ O
input -X- _ O
separately -X- _ O
for -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
each -X- _ O
propaganda -X- _ O
technique -X- _ O
coverage -X- _ O
span -X- _ O
( -X- _ O
For -X- _ O
each -X- _ O
propagation -X- _ O
technique -X- _ O
, -X- _ O
the -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
is -X- _ O
performed -X- _ O
separately -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
technique -X- _ O
, -X- _ O
the -X- _ O
intermediate -X- _ O
result -X- _ O
of -X- _ O
each -X- _ O
parallel -X- _ O
channel -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
512 -X- _ O
× -X- _ O
41 -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
ensemble -X- _ O
layer -X- _ O
represents -X- _ O
the -X- _ O
stacking -X- _ O
of -X- _ O
20 -X- _ O
matrices -X- _ O
from -X- _ O
20 -X- _ O
parallel -X- _ O
channels -X- _ O
, -X- _ O
the -X- _ O
dimensions -X- _ O
of -X- _ O
the -X- _ O
final -X- _ O
output -X- _ O
were -X- _ O
20 -X- _ O
× -X- _ O
512 -X- _ O
× -X- _ O
41 -X- _ O
, -X- _ O
which -X- _ O
denote -X- _ O
the -X- _ O
propaganda -X- _ O
technique -X- _ O
category -X- _ O
, -X- _ O
maximum -X- _ O
sentence -X- _ O
length -X- _ O
, -X- _ O
and -X- _ O
code -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
technique -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
memes -X- _ O
combining -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
social -X- _ O
media -X- _ O
, -X- _ O
and -X- _ O
memes -X- _ O
are -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
popular -X- _ O
types -X- _ O
of -X- _ O
content -X- _ O
used -X- _ O
in -X- _ O
online -X- _ O
disinformation -X- _ O
campaigns -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
persuasion -X- _ O
techniques -X- _ O
in -X- _ O
texts -X- _ O
and -X- _ O
images -X- _ O
in -X- _ O
SemEval -X- _ O
- -X- _ O
2021 -X- _ O
Task -X- _ O
6 -X- _ O
is -X- _ O
summarized -X- _ O
. -X- _ O
For -X- _ O
propaganda -X- _ O
technology -X- _ O
detection -X- _ O
in -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
combination -X- _ O
model -X- _ O
of -X- _ O
both -X- _ O
AL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
Text -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
for -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
sequence -X- _ O
labeling -X- _ O
model -X- _ O
for -X- _ O
propaganda -X- _ O
technology -X- _ O
coverage -X- _ O
span -X- _ B-TaskName
detection -X- _ I-TaskName
. -X- _ O
For -X- _ O
the -X- _ O
meme -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
involved -X- _ O
in -X- _ O
text -X- _ O
understanding -X- _ O
and -X- _ O
visual -X- _ O
feature -X- _ O
extraction -X- _ O
, -X- _ O
we -X- _ O
designed -X- _ O
a -X- _ O
parallel -X- _ O
channel -X- _ O
model -X- _ O
divided -X- _ O
into -X- _ O
text -X- _ O
and -X- _ O
image -X- _ O
channels -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
1 -X- _ O
achieved -X- _ O
a -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
subtasks -X- _ O
1 -X- _ O
and -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
micro -X- _ B-MetricName
F -X- _ I-MetricName
1scores -X- _ I-MetricName
of -X- _ O
0.492 -X- _ B-MetricValue
, -X- _ O
0.091 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
0.446 -X- _ B-MetricValue
achieved -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
subtasks -X- _ O
ranked -X- _ O
12th -X- _ O
, -X- _ O
7th -X- _ O
, -X- _ O
and -X- _ O
11th -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
are -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
. -X- _ O

YNU -X- _ O
- -X- _ O
HPCC -X- _ O
at -X- _ O
SemEval -X- _ O
- -X- _ O
2021 -X- _ O
Task -X- _ O
6 -X- _ O
: -X- _ O
Combining -X- _ O
ALBERT -X- _ B-MethodName
and -X- _ O
Text -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
for -X- _ O
Persuasion -X- _ B-TaskName
Detection -X- _ I-TaskName
in -X- _ O
Texts -X- _ O
and -X- _ O
Images -X- _ O

Current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
systems -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architectures -X- _ O
, -X- _ O
that -X- _ O
first -X- _ O
encode -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
generate -X- _ O
an -X- _ O
output -X- _ O
sequence -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
encoding -X- _ O
. -X- _ O
Both -X- _ O
are -X- _ O
interfaced -X- _ O
with -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
that -X- _ O
recombines -X- _ O
a -X- _ O
fixed -X- _ O
encoding -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
decoder -X- _ O
state -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
which -X- _ O
instead -X- _ O
relies -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
2D -X- _ B-MethodName
convolutional -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
across -X- _ O
both -X- _ O
sequences -X- _ O
. -X- _ O
Each -X- _ O
layer -X- _ O
of -X- _ O
our -X- _ O
network -X- _ O
recodes -X- _ O
source -X- _ O
tokens -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
sequence -X- _ O
produced -X- _ O
so -X- _ O
far -X- _ O
. -X- _ O
Attention -X- _ O
- -X- _ O
like -X- _ O
properties -X- _ O
are -X- _ O
therefore -X- _ O
pervasive -X- _ O
throughout -X- _ O
the -X- _ O
network -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
yields -X- _ O
excellent -X- _ O
results -X- _ O
, -X- _ O
outperforming -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
encoderdecoder -X- _ O
systems -X- _ O
, -X- _ O
while -X- _ O
being -X- _ O
conceptually -X- _ O
simpler -X- _ O
and -X- _ O
having -X- _ O
fewer -X- _ O
parameters -X- _ O
. -X- _ O

To -X- _ O
understand -X- _ O
why -X- _ O
our -X- _ O
proposed -X- _ O
VAT -X- _ B-MethodName
model -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
two -X- _ O
examples -X- _ O
of -X- _ O
LSTM -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
using -X- _ O
attention -X- _ O
heatmaps -X- _ O
( -X- _ O
Figure -X- _ O
7 -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
standard -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
LSTM -X- _ B-MethodName
model -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
wrong -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
this -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
work -X- _ O
" -X- _ O
) -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
predicts -X- _ O
the -X- _ O
right -X- _ O
sentiment -X- _ O
while -X- _ O
our -X- _ O
VAT -X- _ B-MethodName
model -X- _ O
finds -X- _ O
the -X- _ O
correct -X- _ O
words -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
admired -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
lot -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
integrating -X- _ O
IB -X- _ O
into -X- _ O
attention -X- _ O
can -X- _ O
help -X- _ O
it -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
key -X- _ O
words -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
noisy -X- _ O
information -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
can -X- _ O
also -X- _ O
improve -X- _ O
the -X- _ O
attention -X- _ O
's -X- _ O
performance -X- _ O
by -X- _ O
capturing -X- _ O
the -X- _ O
critical -X- _ O
words -X- _ O
accurately -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
" -X- _ O
That -X- _ O
sucks -X- _ O
if -X- _ O
you -X- _ O
have -X- _ O
to -X- _ O
take -X- _ O
the -X- _ O
sats -X- _ O
tomorrow -X- _ O
. -X- _ O
" -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
right -X- _ O
class -X- _ O
label -X- _ O
by -X- _ O
attending -X- _ O
the -X- _ O
words -X- _ O
" -X- _ O
sucks -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
have -X- _ O
to -X- _ O
. -X- _ O
" -X- _ O

For -X- _ O
LSTM -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
GloVe -X- _ O
embedding -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
300 -X- _ O
- -X- _ O
dimension -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
initialize -X- _ O
all -X- _ O
outof -X- _ O
- -X- _ O
vocabulary -X- _ O
words -X- _ O
and -X- _ O
weights -X- _ O
with -X- _ O
the -X- _ O
uniform -X- _ O
distribution -X- _ O
U -X- _ O
p´0.1 -X- _ O
, -X- _ O
0.1q -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
base -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
experiments -X- _ O
that -X- _ O
contribute -X- _ O
to -X- _ O
our -X- _ O
submission -X- _ O
to -X- _ O
the -X- _ O
WMT -X- _ O
2021 -X- _ O
shared -X- _ O
task -X- _ O
of -X- _ O
Very -X- _ B-TaskName
Low -X- _ I-TaskName
Resource -X- _ I-TaskName
Supervised -X- _ I-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
. -X- _ O
These -X- _ O
experiments -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
good -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
final -X- _ O
submission -X- _ O
, -X- _ O
show -X- _ O
that -X- _ O
dual -X- _ O
transfer -X- _ O
can -X- _ O
work -X- _ O
in -X- _ O
synergy -X- _ O
with -X- _ O
several -X- _ O
widely -X- _ O
used -X- _ O
techniques -X- _ O
in -X- _ O
realistic -X- _ O
scenarios -X- _ O
. -X- _ O

Towards -X- _ O
Generative -X- _ B-TaskName
Aspect -X- _ I-TaskName
- -X- _ I-TaskName
Based -X- _ I-TaskName
Sentiment -X- _ I-TaskName
Analysis -X- _ I-TaskName
* -X- _ O

The -X- _ O
BERT -X- _ B-MethodName
QA -X- _ O
model -X- _ O
concatenates -X- _ O
question -X- _ O
and -X- _ O
document -X- _ O
pairs -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
by -X- _ O
a -X- _ O
dot -X- _ O
product -X- _ O
between -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vectors -X- _ O
, -X- _ O
a -X- _ O
start -X- _ O
vector -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
vector -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
memory -X- _ O
and -X- _ O
computational -X- _ O
requirements -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
can -X- _ O
encode -X- _ O
sequences -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ O
that -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
the -X- _ O
average -X- _ O
sample -X- _ O
length -X- _ O
in -X- _ O
NLQuAD -X- _ B-DatasetName
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
sliding -X- _ O
window -X- _ O
approach -X- _ O
. -X- _ O
We -X- _ O
split -X- _ O
the -X- _ O
samples -X- _ O
into -X- _ O
segments -X- _ O
using -X- _ O
a -X- _ O
sliding -X- _ B-HyperparameterName
window -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ O
and -X- _ O
a -X- _ O
stride -X- _ O
of -X- _ O
128 -X- _ B-HyperparameterValue
tokens -X- _ O
. -X- _ O
Each -X- _ O
segment -X- _ O
is -X- _ O
augmented -X- _ O
with -X- _ O
its -X- _ O
corresponding -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
segments -X- _ O
can -X- _ O
include -X- _ O
no -X- _ O
answer -X- _ O
, -X- _ O
a -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
entire -X- _ O
answer -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
segments -X- _ O
independently -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
predicted -X- _ O
spans -X- _ O
corresponding -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
sample -X- _ O
are -X- _ O
aggregated -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
final -X- _ O
span -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
span -X- _ O
between -X- _ O
the -X- _ O
earliest -X- _ O
start -X- _ O
position -X- _ O
and -X- _ O
the -X- _ O
latest -X- _ O
end -X- _ O
position -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
is -X- _ O
considered -X- _ O
empty -X- _ O
when -X- _ O
all -X- _ O
segments -X- _ O
have -X- _ O
empty -X- _ O
spans -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
has -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
input -X- _ O
length -X- _ O
limitation -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
but -X- _ O
with -X- _ O
a -X- _ O
robustly -X- _ O
optimized -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
scheme -X- _ O
allowing -X- _ O
it -X- _ O
to -X- _ O
generalize -X- _ O
better -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
QA -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
sliding -X- _ O
window -X- _ O
approach -X- _ O
for -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O

The -X- _ O
left -X- _ O
null -X- _ O
space -X- _ O
of -X- _ O
a -X- _ O
m -X- _ O
p -X- _ O
× -X- _ O
n -X- _ O
p -X- _ O
matrix -X- _ O
P -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
vectors -X- _ O
v -X- _ O
- -X- _ O
LN -X- _ O
P -X- _ O
= -X- _ O
{ -X- _ O
v -X- _ O
T -X- _ O
R -X- _ O
1×mp -X- _ O
| -X- _ O
v -X- _ O
T -X- _ O
P -X- _ O
= -X- _ O
0 -X- _ O
} -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
If -X- _ O
the -X- _ O
rows -X- _ O
of -X- _ O
P -X- _ O
are -X- _ O
linearly -X- _ O
independent -X- _ O
( -X- _ O
P -X- _ O
is -X- _ O
full -X- _ O
- -X- _ O
row -X- _ O
rank -X- _ O
) -X- _ O
the -X- _ O
left -X- _ O
null -X- _ O
space -X- _ O
of -X- _ O
P -X- _ O
is -X- _ O
zero -X- _ O
dimensional -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
solution -X- _ O
to -X- _ O
the -X- _ O
system -X- _ O
of -X- _ O
equations -X- _ O
v -X- _ O
P -X- _ O
= -X- _ O
0 -X- _ O
is -X- _ O
trivial -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
v=0 -X- _ O
. -X- _ O
The -X- _ O
dimensions -X- _ O
of -X- _ O
the -X- _ O
null -X- _ O
space -X- _ O
, -X- _ O
known -X- _ O
as -X- _ O
nullity -X- _ O
, -X- _ O
of -X- _ O
P -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
as -X- _ O
dim -X- _ O
LN -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
= -X- _ O
m -X- _ O
p -X- _ O
− -X- _ O
rank -X- _ O
( -X- _ O
P -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
nullity -X- _ O
of -X- _ O
P -X- _ O
sets -X- _ O
the -X- _ O
dimensions -X- _ O
of -X- _ O
the -X- _ O
space -X- _ O
v -X- _ O
lies -X- _ O
in -X- _ O
. -X- _ O
In -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
our -X- _ O
knowledge -X- _ O
of -X- _ O
appendix -X- _ O
A.2 -X- _ O
and -X- _ O
appendix -X- _ O
A.3 -X- _ O
to -X- _ O
analyse -X- _ O
identifiability -X- _ O
in -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
. -X- _ O

This -X- _ O
work -X- _ O
probed -X- _ O
Transformer -X- _ B-MethodName
for -X- _ O
identifiability -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
can -X- _ O
be -X- _ O
uniquely -X- _ O
identified -X- _ O
from -X- _ O
the -X- _ O
head -X- _ O
's -X- _ O
output -X- _ O
. -X- _ O
With -X- _ O
theoretical -X- _ O
analysis -X- _ O
and -X- _ O
supporting -X- _ O
empirical -X- _ O
evidence -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
study -X- _ O
by -X- _ O
Brunner -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
the -X- _ O
study -X- _ O
largely -X- _ O
ignored -X- _ O
the -X- _ O
constraint -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
key -X- _ I-HyperparameterName
vector -X- _ I-HyperparameterName
. -X- _ O
Later -X- _ O
, -X- _ O
we -X- _ O
proved -X- _ O
how -X- _ O
we -X- _ O
can -X- _ O
utilize -X- _ O
d -X- _ B-HyperparameterName
k -X- _ I-HyperparameterName
to -X- _ O
make -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
more -X- _ O
identifiable -X- _ O
. -X- _ O
To -X- _ O
give -X- _ O
a -X- _ O
more -X- _ O
concrete -X- _ O
solution -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
encoder -X- _ O
variants -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
identifiable -X- _ O
, -X- _ O
theoretically -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
experimentally -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
range -X- _ O
of -X- _ O
input -X- _ O
sequence -X- _ O
lengths -X- _ O
. -X- _ O
The -X- _ O
identifiable -X- _ O
variants -X- _ O
do -X- _ O
not -X- _ O
show -X- _ O
any -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
experiments -X- _ O
are -X- _ O
done -X- _ O
on -X- _ O
varied -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
Future -X- _ O
works -X- _ O
may -X- _ O
analyse -X- _ O
the -X- _ O
critical -X- _ O
impact -X- _ O
of -X- _ O
identifiability -X- _ O
on -X- _ O
the -X- _ O
explainability -X- _ O
and -X- _ O
interpretability -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
. -X- _ O

IMDB -X- _ B-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
consist -X- _ O
of -X- _ O
IMDB -X- _ O
movie -X- _ O
reviews -X- _ O
with -X- _ O
their -X- _ O
sentiment -X- _ O
as -X- _ O
positive -X- _ O
or -X- _ O
negative -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
the -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
contain -X- _ O
25 -X- _ O
, -X- _ O
000 -X- _ O
data -X- _ O
samples -X- _ O
equally -X- _ O
distributed -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
sentiment -X- _ O
polarities -X- _ O
. -X- _ O
TREC -X- _ B-DatasetName
( -X- _ O
Voorhees -X- _ O
and -X- _ O
Tice -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
6 -X- _ O
- -X- _ O
class -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
question -X- _ B-TaskName
classification -X- _ I-TaskName
consisting -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
, -X- _ O
facet -X- _ O
- -X- _ O
based -X- _ O
questions -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
5 -X- _ O
, -X- _ O
452 -X- _ O
and -X- _ O
500 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
SST -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Stanford -X- _ O
sentiment -X- _ O
analysis -X- _ O
dataset -X- _ O
consist -X- _ O
of -X- _ O
11 -X- _ O
, -X- _ O
855 -X- _ O
sentences -X- _ O
obtained -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
3 -X- _ O
- -X- _ O
class -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
. -X- _ O
Each -X- _ O
review -X- _ O
is -X- _ O
labeled -X- _ O
as -X- _ O
positive -X- _ O
, -X- _ O
neutral -X- _ O
, -X- _ O
or -X- _ O
negative -X- _ O
. -X- _ O
The -X- _ O
provided -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
valid -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
is -X- _ O
8 -X- _ O
, -X- _ O
544/2 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
210/1 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
101 -X- _ I-HyperparameterValue
. -X- _ O
8 -X- _ O
ds -X- _ O
- -X- _ O
max -X- _ O
< -X- _ O
de -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
regular -X- _ O
Transformer -X- _ O
setting -X- _ O
. -X- _ O

SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
contain -X- _ O
549 -X- _ O
, -X- _ O
367 -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
9 -X- _ O
, -X- _ O
842 -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
9 -X- _ O
, -X- _ O
824 -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
recognizing -X- _ B-TaskName
textual -X- _ I-TaskName
entailment -X- _ I-TaskName
, -X- _ O
each -X- _ O
sample -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
premisehypothesis -X- _ O
sentence -X- _ O
pair -X- _ O
and -X- _ O
a -X- _ O
label -X- _ O
indicating -X- _ O
whether -X- _ O
the -X- _ O
hypothesis -X- _ O
entails -X- _ O
the -X- _ O
premise -X- _ O
, -X- _ O
contradicts -X- _ O
it -X- _ O
, -X- _ O
or -X- _ O
neutral -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
about -X- _ O
the -X- _ O
following -X- _ O
datasets -X- _ O
: -X- _ O
Yelp -X- _ B-DatasetName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
Yelp -X- _ O
review -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
binary -X- _ B-TaskName
sentiment -X- _ I-TaskName
classification -X- _ I-TaskName
. -X- _ O
There -X- _ O
are -X- _ O
560 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
38 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
testing -X- _ O
, -X- _ O
equally -X- _ O
split -X- _ O
into -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
polarities -X- _ O
. -X- _ O
DBPedia -X- _ B-DatasetName
. -X- _ O
The -X- _ O
Ontology -X- _ O
dataset -X- _ O
for -X- _ O
topic -X- _ B-TaskName
classification -X- _ I-TaskName
consist -X- _ O
of -X- _ O
14 -X- _ O
non -X- _ O
- -X- _ O
overlapping -X- _ O
classes -X- _ O
each -X- _ O
with -X- _ O
40 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
5 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
Sogou -X- _ B-DatasetName
News -X- _ I-DatasetName
. -X- _ O
The -X- _ O
dataset -X- _ O
for -X- _ O
news -X- _ B-TaskName
article -X- _ I-TaskName
classification -X- _ I-TaskName
consist -X- _ O
of -X- _ O
450 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
60 -X- _ O
, -X- _ O
000 -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
Each -X- _ O
article -X- _ O
is -X- _ O
labeled -X- _ O
in -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
news -X- _ O
categories -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
perfectly -X- _ O
balanced -X- _ O
. -X- _ O
AG -X- _ B-DatasetName
News -X- _ I-DatasetName
. -X- _ O
The -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
news -X- _ O
articles -X- _ O
classification -X- _ O
partitioned -X- _ O
into -X- _ O
four -X- _ O
categories -X- _ O
. -X- _ O
The -X- _ O
balanced -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
consist -X- _ O
of -X- _ O
120 -X- _ O
, -X- _ O
000 -X- _ O
and -X- _ O
7 -X- _ O
, -X- _ O
600 -X- _ O
samples -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Yahoo -X- _ B-DatasetName
! -X- _ I-DatasetName
Answers -X- _ I-DatasetName
. -X- _ O
The -X- _ O
balanced -X- _ O
dataset -X- _ O
for -X- _ O
10class -X- _ O
topic -X- _ B-TaskName
classification -X- _ I-TaskName
contain -X- _ O
1 -X- _ O
, -X- _ O
400 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
50 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
Amazon -X- _ B-DatasetName
Reviews -X- _ I-DatasetName
. -X- _ O
For -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
the -X- _ O
dataset -X- _ O
contain -X- _ O
3 -X- _ O
, -X- _ O
600 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
400 -X- _ O
, -X- _ O
000 -X- _ O
samples -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
The -X- _ O
samples -X- _ O
are -X- _ O
equally -X- _ O
divided -X- _ O
into -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
sentiment -X- _ O
labels -X- _ O
. -X- _ O
Except -X- _ O
for -X- _ O
the -X- _ O
SST -X- _ B-DatasetName
and -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
where -X- _ O
the -X- _ O
validation -X- _ O
split -X- _ O
is -X- _ O
already -X- _ O
provided -X- _ O
, -X- _ O
we -X- _ O
flag -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
train -X- _ O
set -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
70 -X- _ O
% -X- _ O
were -X- _ O
used -X- _ O
for -X- _ O
model -X- _ O
parameter -X- _ O
learning -X- _ O
. -X- _ O

Hyperbolic -X- _ B-MethodName
Capsule -X- _ I-MethodName
Networks -X- _ I-MethodName
for -X- _ O
Multi -X- _ B-TaskName
- -X- _ I-TaskName
Label -X- _ I-TaskName
Classification -X- _ I-TaskName

We -X- _ O
report -X- _ O
experimental -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
a -X- _ O
teacher -X- _ O
distillation -X- _ O
step -X- _ O
as -X- _ O
previous -X- _ O
work -X- _ O
showed -X- _ O
this -X- _ O
boosts -X- _ O
movement -X- _ O
pruning -X- _ O
at -X- _ O
little -X- _ O
cost -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
distillation -X- _ O
using -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
teacher -X- _ O
. -X- _ O

We -X- _ O
are -X- _ O
using -X- _ O
a -X- _ O
minimal -X- _ O
set -X- _ O
of -X- _ O
hyperparameters -X- _ O
. -X- _ O
The -X- _ O
ratio -X- _ O
of -X- _ O
λ -X- _ B-HyperparameterName
att -X- _ I-HyperparameterName
and -X- _ O
λ -X- _ B-HyperparameterName
ffn -X- _ I-HyperparameterName
is -X- _ O
fixed -X- _ O
by -X- _ O
the -X- _ O
relative -X- _ O
sizes -X- _ O
. -X- _ O
We -X- _ O
performed -X- _ O
a -X- _ O
few -X- _ O
experiments -X- _ O
with -X- _ O
differ -X- _ O
- -X- _ O
ent -X- _ O
values -X- _ O
fixed -X- _ O
manually -X- _ O
for -X- _ O
these -X- _ O
parameters -X- _ O
, -X- _ O
but -X- _ O
their -X- _ O
influence -X- _ O
is -X- _ O
minor -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
hyperparameter -X- _ O
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
, -X- _ O
we -X- _ O
are -X- _ O
using -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
instead -X- _ O
of -X- _ O
typically -X- _ O
2 -X- _ B-HyperparameterValue
for -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
taking -X- _ O
about -X- _ O
12h -X- _ O
with -X- _ O
our -X- _ O
method -X- _ O
instead -X- _ O
of -X- _ O
45mn -X- _ O
with -X- _ O
a -X- _ O
standard -X- _ O
finetuning -X- _ O
setup -X- _ O
. -X- _ O
This -X- _ O
number -X- _ O
has -X- _ O
to -X- _ O
be -X- _ O
large -X- _ O
enough -X- _ O
to -X- _ O
let -X- _ O
pruning -X- _ O
happen -X- _ O
slowly -X- _ O
enough -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
warming -X- _ O
up -X- _ O
phase -X- _ O
and -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
pruning -X- _ O
cooldown -X- _ O
phase -X- _ O
are -X- _ O
helpful -X- _ O
, -X- _ O
but -X- _ O
their -X- _ O
exact -X- _ O
length -X- _ O
has -X- _ O
not -X- _ O
a -X- _ O
large -X- _ O
impact -X- _ O
on -X- _ O
final -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
the -X- _ O
training -X- _ O
time -X- _ O
is -X- _ O
less -X- _ O
important -X- _ O
than -X- _ O
the -X- _ O
inference -X- _ O
time -X- _ O
for -X- _ O
energy -X- _ O
consideration -X- _ O
, -X- _ O
as -X- _ O
inference -X- _ O
is -X- _ O
performed -X- _ O
repeatedly -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
is -X- _ O
optimizing -X- _ O
inference -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
factor -X- _ O
: -X- _ O
the -X- _ O
training -X- _ O
energy -X- _ O
is -X- _ O
potentially -X- _ O
recouped -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
with -X- _ O
inference -X- _ O
savings -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
checkpoints -X- _ O
created -X- _ O
during -X- _ O
the -X- _ O
experiments -X- _ O
are -X- _ O
available -X- _ O
on -X- _ O
an -X- _ O
AWS -X- _ O
S3 -X- _ O
bucket -X- _ O
, -X- _ O
with -X- _ O
their -X- _ O
metadata -X- _ O
and -X- _ O
training -X- _ O
parameters -X- _ O
, -X- _ O
totaling -X- _ O
3 -X- _ O
TB -X- _ O
of -X- _ O
data -X- _ O
, -X- _ O
to -X- _ O
facilitate -X- _ O
reproduction -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
and -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
study -X- _ O
further -X- _ O
the -X- _ O
behavior -X- _ O
of -X- _ O
those -X- _ O
models -X- _ O
. -X- _ O
Code -X- _ O
for -X- _ O
experiments -X- _ O
, -X- _ O
analysis -X- _ O
, -X- _ O
and -X- _ O
tools -X- _ O
to -X- _ O
prepare -X- _ O
the -X- _ O
present -X- _ O
paper -X- _ O
are -X- _ O
available -X- _ O
on -X- _ O
GitHub -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
is -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
version -X- _ O
of -X- _ O
all -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
used -X- _ O
and -X- _ O
their -X- _ O
pretraining -X- _ O
methods -X- _ O
. -X- _ O
D -X- _ O
Detailed -X- _ O
metrics -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
( -X- _ O
Weissenbacher -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
" -X- _ O
partial"matches -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
it -X- _ O
is -X- _ O
sufficient -X- _ O
for -X- _ O
a -X- _ O
system -X- _ O
prediction -X- _ O
to -X- _ O
partially -X- _ O
overlap -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
annotation -X- _ O
to -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
true -X- _ O
match -X- _ O
. -X- _ O

Pretrained -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
variants -X- _ O
, -X- _ O
have -X- _ O
become -X- _ O
a -X- _ O
common -X- _ O
choice -X- _ O
to -X- _ O
obtain -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performances -X- _ O
in -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
identification -X- _ B-TaskName
of -X- _ I-TaskName
Adverse -X- _ I-TaskName
Drug -X- _ I-TaskName
Events -X- _ I-TaskName
( -X- _ O
ADE -X- _ O
) -X- _ O
from -X- _ O
social -X- _ O
media -X- _ O
texts -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
architectures -X- _ O
rank -X- _ O
first -X- _ O
in -X- _ O
the -X- _ O
leaderboard -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
a -X- _ O
systematic -X- _ O
comparison -X- _ O
between -X- _ O
these -X- _ O
models -X- _ O
has -X- _ O
not -X- _ O
yet -X- _ O
been -X- _ O
done -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
at -X- _ O
shedding -X- _ O
light -X- _ O
on -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
their -X- _ O
performance -X- _ O
analyzing -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
12 -X- _ O
models -X- _ O
, -X- _ O
tested -X- _ O
on -X- _ O
two -X- _ O
standard -X- _ O
benchmarks -X- _ O
. -X- _ O
SpanBERT -X- _ B-MethodName
and -X- _ O
PubMedBERT -X- _ B-MethodName
emerged -X- _ O
as -X- _ O
the -X- _ O
best -X- _ O
models -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
: -X- _ O
this -X- _ O
result -X- _ O
clearly -X- _ O
shows -X- _ O
that -X- _ O
span -X- _ O
- -X- _ O
based -X- _ O
pretraining -X- _ O
gives -X- _ O
a -X- _ O
decisive -X- _ O
advantage -X- _ O
in -X- _ O
the -X- _ O
precise -X- _ O
recognition -X- _ O
of -X- _ O
ADEs -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
language -X- _ O
pretraining -X- _ O
is -X- _ O
particularly -X- _ O
useful -X- _ O
when -X- _ O
the -X- _ O
transformer -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
just -X- _ O
on -X- _ O
biomedical -X- _ O
text -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

BERT -X- _ O
Prescriptions -X- _ O
to -X- _ O
Avoid -X- _ O
Unwanted -X- _ O
Headaches -X- _ O
: -X- _ O
A -X- _ O
Comparison -X- _ O
of -X- _ O
Transformer -X- _ O
Architectures -X- _ O
for -X- _ O
Adverse -X- _ B-TaskName
Drug -X- _ I-TaskName
Event -X- _ I-TaskName
Detection -X- _ I-TaskName

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
an -X- _ O
ensemble -X- _ O
learning -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
geolocation -X- _ B-TaskName
of -X- _ I-TaskName
Swiss -X- _ I-TaskName
German -X- _ I-TaskName
social -X- _ I-TaskName
media -X- _ I-TaskName
posts -X- _ I-TaskName
. -X- _ O
The -X- _ O
ensemble -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
XGBoost -X- _ B-MethodName
meta -X- _ I-MethodName
- -X- _ I-MethodName
learner -X- _ I-MethodName
applied -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
three -X- _ O
individual -X- _ O
models -X- _ O
: -X- _ O
a -X- _ O
hybrid -X- _ B-MethodName
CNN -X- _ I-MethodName
, -X- _ O
an -X- _ O
approach -X- _ O
based -X- _ O
on -X- _ O
string -X- _ O
kernels -X- _ O
and -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
German -X- _ B-MethodName
BERT -X- _ I-MethodName
model -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
final -X- _ O
results -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
SMG -X- _ O
- -X- _ O
CH -X- _ O
subtask -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
predicting -X- _ O
the -X- _ O
location -X- _ O
of -X- _ O
Swiss -X- _ O
German -X- _ O
social -X- _ O
media -X- _ O
posts -X- _ O
is -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
median -X- _ B-MetricName
distance -X- _ I-MetricName
being -X- _ O
higher -X- _ O
than -X- _ O
20 -X- _ B-MetricValue
km -X- _ I-MetricValue
. -X- _ O
Using -X- _ O
external -X- _ O
data -X- _ O
sources -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
more -X- _ O
promising -X- _ O
path -X- _ O
towards -X- _ O
success -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
by -X- _ O
the -X- _ O
final -X- _ O
standings -X- _ O
of -X- _ O
the -X- _ O
VarDial -X- _ O
2020 -X- _ O
( -X- _ O
Gȃman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
2021 -X- _ O
( -X- _ O
Chakravarthi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
SMG -X- _ O
shared -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
ensemble -X- _ O
on -X- _ O
other -X- _ O
geolocation -X- _ O
tasks -X- _ O
, -X- _ O
perhaps -X- _ O
taking -X- _ O
into -X- _ O
consideration -X- _ O
future -X- _ O
VarDial -X- _ O
challenges -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
three -X- _ O
different -X- _ O
models -X- _ O
which -X- _ O
rely -X- _ O
on -X- _ O
different -X- _ O
learning -X- _ O
methods -X- _ O
and -X- _ O
types -X- _ O
of -X- _ O
features -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
required -X- _ O
double -X- _ O
regression -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
hybrid -X- _ B-MethodName
CNN -X- _ I-MethodName
relying -X- _ O
on -X- _ O
both -X- _ O
words -X- _ O
and -X- _ O
characters -X- _ O
as -X- _ O
features -X- _ O
, -X- _ O
the -X- _ O
shallow -X- _ B-MethodName
ν -X- _ I-MethodName
- -X- _ I-MethodName
SVR -X- _ I-MethodName
based -X- _ O
on -X- _ O
string -X- _ O
kernels -X- _ O
and -X- _ O
three -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
German -X- _ B-MethodName
BERT -X- _ I-MethodName
models -X- _ O
looking -X- _ O
at -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
and -X- _ O
understanding -X- _ O
dependencies -X- _ O
in -X- _ O
a -X- _ O
bidirectional -X- _ O
manner -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
preliminary -X- _ O
results -X- _ O
obtained -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
by -X- _ O
each -X- _ O
individual -X- _ O
model -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
submitted -X- _ O
XGBoost -X- _ B-MethodName
ensemble -X- _ I-MethodName
. -X- _ O
The -X- _ O
individual -X- _ O
models -X- _ O
provide -X- _ O
quite -X- _ O
similar -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
median -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
predicted -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
locations -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
stay -X- _ O
around -X- _ O
a -X- _ O
value -X- _ O
of -X- _ O
30 -X- _ B-MetricValue
km -X- _ I-MetricValue
for -X- _ O
the -X- _ O
median -X- _ B-MetricName
distance -X- _ I-MetricName
and -X- _ O
35 -X- _ B-MetricValue
km -X- _ I-MetricValue
for -X- _ O
the -X- _ O
mean -X- _ B-MetricName
distance -X- _ I-MetricName
. -X- _ O
Among -X- _ O
the -X- _ O
independent -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
hybrid -X- _ B-MethodName
CNN -X- _ I-MethodName
obtains -X- _ O
slightly -X- _ O
better -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
median -X- _ B-MetricName
distance -X- _ I-MetricName
( -X- _ O
30.05 -X- _ B-MetricValue
km -X- _ I-MetricValue
) -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
second -X- _ O
attempt -X- _ O
at -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
gives -X- _ O
the -X- _ O
worst -X- _ O
distances -X- _ O
, -X- _ O
namely -X- _ O
33.86 -X- _ B-MetricValue
km -X- _ I-MetricValue
for -X- _ O
the -X- _ O
median -X- _ B-MetricName
distance -X- _ I-MetricName
and -X- _ O
38.85 -X- _ O
km -X- _ O
for -X- _ O
the -X- _ O
mean -X- _ B-MetricName
distance -X- _ I-MetricName
. -X- _ O
ν -X- _ B-MethodName
- -X- _ I-MethodName
SVR -X- _ I-MethodName
surpasses -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
by -X- _ O
a -X- _ O
small -X- _ O
margin -X- _ O
, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ B-MetricName
distance -X- _ I-MetricName
( -X- _ O
34.82 -X- _ B-MetricValue
km -X- _ I-MetricValue
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
submitted -X- _ O
XGBoost -X- _ B-MethodName
ensemble -X- _ I-MethodName
model -X- _ O
stand -X- _ O
proof -X- _ O
that -X- _ O
our -X- _ O
intuition -X- _ O
was -X- _ O
correct -X- _ O
, -X- _ O
namely -X- _ O
that -X- _ O
all -X- _ O
these -X- _ O
individual -X- _ O
models -X- _ O
have -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
complement -X- _ O
each -X- _ O
other -X- _ O
if -X- _ O
put -X- _ O
together -X- _ O
in -X- _ O
an -X- _ O
ensemble -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
the -X- _ O
submitted -X- _ O
system -X- _ O
clearly -X- _ O
surpasses -X- _ O
the -X- _ O
best -X- _ O
individual -X- _ O
model -X- _ O
by -X- _ O
approximately -X- _ O
5 -X- _ B-MetricValue
km -X- _ I-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
median -X- _ O
and -X- _ O
the -X- _ O
mean -X- _ O
distance -X- _ O
metrics -X- _ O
. -X- _ O

Transformers -X- _ B-MethodName
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
represent -X- _ O
an -X- _ O
important -X- _ O
advance -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
with -X- _ O
many -X- _ O
benefits -X- _ O
over -X- _ O
the -X- _ O
traditional -X- _ O
sequential -X- _ O
neural -X- _ O
architectures -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architecture -X- _ O
with -X- _ O
attention -X- _ O
, -X- _ O
transformers -X- _ B-MethodName
proved -X- _ O
to -X- _ O
be -X- _ O
better -X- _ O
at -X- _ O
modeling -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
dependencies -X- _ O
in -X- _ O
sequences -X- _ O
, -X- _ O
while -X- _ O
being -X- _ O
effectively -X- _ O
trained -X- _ O
as -X- _ O
the -X- _ O
sequential -X- _ O
dependency -X- _ O
of -X- _ O
previous -X- _ O
tokens -X- _ O
is -X- _ O
removed -X- _ O
. -X- _ O
Unlike -X- _ O
other -X- _ O
contemporary -X- _ O
attempts -X- _ O
at -X- _ O
using -X- _ O
transformers -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
builds -X- _ O
deep -X- _ O
language -X- _ O
representations -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
fashion -X- _ O
and -X- _ O
incorporates -X- _ O
context -X- _ O
from -X- _ O
both -X- _ O
directions -X- _ O
. -X- _ O
The -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
technique -X- _ O
enables -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
pretrain -X- _ O
these -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
, -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
and -X- _ O
adapted -X- _ O
for -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
without -X- _ O
significant -X- _ O
architectural -X- _ O
updates -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
this -X- _ O
property -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
work -X- _ O
, -X- _ O
employing -X- _ O
the -X- _ O
Hugging -X- _ O
Face -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
cased -X- _ O
German -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
was -X- _ O
initially -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
latest -X- _ O
German -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
dump -X- _ O
, -X- _ O
the -X- _ O
OpenLe -X- _ B-DatasetName
- -X- _ I-DatasetName
galData -X- _ I-DatasetName
dump -X- _ O
and -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
news -X- _ O
articles -X- _ O
, -X- _ O
summing -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
12 -X- _ O
GB -X- _ O
of -X- _ O
text -X- _ O
files -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
this -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
German -X- _ B-MethodName
BERT -X- _ I-MethodName
model -X- _ O
for -X- _ O
the -X- _ O
geolocation -X- _ B-TaskName
of -X- _ I-TaskName
Swiss -X- _ I-TaskName
German -X- _ I-TaskName
short -X- _ I-TaskName
texts -X- _ I-TaskName
, -X- _ O
in -X- _ O
a -X- _ O
regression -X- _ O
setup -X- _ O
. -X- _ O
The -X- _ O
choice -X- _ O
of -X- _ O
hyperparameters -X- _ O
is -X- _ O
, -X- _ O
in -X- _ O
part -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
winning -X- _ O
system -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
year -X- _ O
's -X- _ O
SMG -X- _ O
- -X- _ O
CH -X- _ O
subtask -X- _ O
at -X- _ O
VarDial -X- _ O
( -X- _ O
Scherrer -X- _ O
and -X- _ O
Ljubešić -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
research -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
DARPA -X- _ O
Communicating -X- _ O
with -X- _ O
Computers -X- _ O
program -X- _ O
, -X- _ O
under -X- _ O
ARO -X- _ O
contract -X- _ O
W911NF -X- _ O
- -X- _ O
15 -X- _ O
- -X- _ O
1 -X- _ O
- -X- _ O
0542 -X- _ O
. -X- _ O

The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
datasets -X- _ O
on -X- _ O
Turkish -X- _ O
- -X- _ O
English -X- _ O
and -X- _ O
Uyghur -X- _ O
- -X- _ O
Chinese -X- _ O
machine -X- _ O
translation -X- _ O
tasks -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Turkish -X- _ O
- -X- _ O
English -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
WIT -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Cettolo -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
SETimes -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Tyers -X- _ O
and -X- _ O
Alperen -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
merge -X- _ O
the -X- _ O
dev2010 -X- _ O
and -X- _ O
tst2010 -X- _ O
as -X- _ O
the -X- _ O
validation -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
tst2011 -X- _ O
, -X- _ O
tst2012 -X- _ O
, -X- _ O
tst2013 -X- _ O
, -X- _ O
tst2014 -X- _ O
from -X- _ O
the -X- _ O
IWSLT -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
the -X- _ O
talks -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
IWSLT -X- _ O
evaluation -X- _ O
campaign -X- _ O
1 -X- _ O
in -X- _ O
2018 -X- _ O
and -X- _ O
the -X- _ O
news -X- _ O
data -X- _ O
from -X- _ O
News -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
corpora -X- _ O
2 -X- _ O
in -X- _ O
2017 -X- _ O
as -X- _ O
external -X- _ O
monolingual -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
stemming -X- _ O
task -X- _ O
on -X- _ O
Turkish -X- _ O
sentences -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Uyghur -X- _ O
- -X- _ O
Chinese -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
news -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
China -X- _ O
Workshop -X- _ O
on -X- _ O
Machine -X- _ O
Translation -X- _ O
in -X- _ O
2017 -X- _ O
( -X- _ O
CWMT2017 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
and -X- _ O
validation -X- _ O
dataset -X- _ O
, -X- _ O
use -X- _ O
the -X- _ O
news -X- _ O
data -X- _ O
from -X- _ O
CWMT2015 -X- _ B-DatasetName
as -X- _ O
the -X- _ O
test -X- _ O
dataset -X- _ O
. -X- _ O
Each -X- _ O
Uyghur -X- _ O
sentence -X- _ O
has -X- _ O
four -X- _ O
Chinese -X- _ O
reference -X- _ O
sentences -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
news -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
Tianshan -X- _ O
website -X- _ O
3 -X- _ O
as -X- _ O
external -X- _ O
monolingual -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
stemming -X- _ O
task -X- _ O
on -X- _ O
Uyghur -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
neural -X- _ I-MethodName
model -X- _ I-MethodName
for -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
from -X- _ O
and -X- _ O
into -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
and -X- _ O
morphologically -X- _ O
- -X- _ O
rich -X- _ O
agglutinative -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
jointly -X- _ O
learn -X- _ O
to -X- _ O
perform -X- _ O
both -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
translation -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
stemming -X- _ O
task -X- _ O
on -X- _ O
an -X- _ O
agglutinative -X- _ O
language -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
standard -X- _ O
NMT -X- _ B-TaskName
framework -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
artificial -X- _ O
token -X- _ O
before -X- _ O
each -X- _ O
source -X- _ O
sentence -X- _ O
to -X- _ O
specify -X- _ O
the -X- _ O
desired -X- _ O
target -X- _ O
outputs -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
Turkish -X- _ O
- -X- _ O
English -X- _ O
translation -X- _ O
task -X- _ O
as -X- _ O
example -X- _ O
. -X- _ O
The -X- _ O
" -X- _ O
< -X- _ O
MT -X- _ O
> -X- _ O
" -X- _ O
token -X- _ O
denotes -X- _ O
the -X- _ O
bilingual -X- _ O
translation -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
" -X- _ O
< -X- _ O
ST -X- _ O
> -X- _ O
" -X- _ O
token -X- _ O
denotes -X- _ O
the -X- _ O
stemming -X- _ O
task -X- _ O
on -X- _ O
Turkish -X- _ O
sentence -X- _ O
. -X- _ O

Neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-TaskName
) -X- _ O
has -X- _ O
achieved -X- _ O
impressive -X- _ O
performance -X- _ O
recently -X- _ O
by -X- _ O
using -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
parallel -X- _ O
corpora -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
struggles -X- _ O
in -X- _ O
the -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
and -X- _ O
morphologically -X- _ O
- -X- _ O
rich -X- _ O
scenarios -X- _ O
of -X- _ O
agglutinative -X- _ O
language -X- _ O
translation -X- _ O
task -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
finding -X- _ O
that -X- _ O
monolingual -X- _ O
data -X- _ O
can -X- _ O
greatly -X- _ O
improve -X- _ O
the -X- _ O
NMT -X- _ B-TaskName
performance -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
neural -X- _ I-MethodName
model -X- _ I-MethodName
that -X- _ O
jointly -X- _ O
learns -X- _ O
to -X- _ O
perform -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
translation -X- _ O
and -X- _ O
agglutinative -X- _ O
language -X- _ O
stemming -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
employs -X- _ O
the -X- _ O
shared -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
without -X- _ O
changing -X- _ O
the -X- _ O
standard -X- _ O
NMT -X- _ B-TaskName
architecture -X- _ O
but -X- _ O
instead -X- _ O
adding -X- _ O
a -X- _ O
token -X- _ O
before -X- _ O
each -X- _ O
source -X- _ O
- -X- _ O
side -X- _ O
sentence -X- _ O
to -X- _ O
specify -X- _ O
the -X- _ O
desired -X- _ O
target -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
Turkish -X- _ O
- -X- _ O
English -X- _ O
and -X- _ O
Uyghur -X- _ O
- -X- _ O
Chinese -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
on -X- _ O
agglutinative -X- _ O
languages -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
monolingual -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
conducted -X- _ O
two -X- _ O
rounds -X- _ O
of -X- _ O
human -X- _ B-MetricName
evaluations -X- _ I-MetricName
, -X- _ O
each -X- _ O
time -X- _ O
across -X- _ O
200 -X- _ O
examples -X- _ O
from -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
Annotators -X- _ O
were -X- _ O
crowd -X- _ O
sourced -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
example -X- _ O
was -X- _ O
rated -X- _ O
by -X- _ O
seven -X- _ O
judges -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
1400 -X- _ O
judgements -X- _ O
. -X- _ O
8 -X- _ O
Command -X- _ O
and -X- _ O
Grounding -X- _ O
In -X- _ O
our -X- _ O
first -X- _ O
round -X- _ O
of -X- _ O
human -X- _ B-MetricName
evaluations -X- _ I-MetricName
we -X- _ O
compared -X- _ O
our -X- _ O
model -X- _ O
's -X- _ O
top -X- _ O
output -X- _ O
from -X- _ O
beam -X- _ O
search -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
edit -X- _ O
. -X- _ O
There -X- _ O
were -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
asked -X- _ O
judges -X- _ O
to -X- _ O
choose -X- _ O
which -X- _ O
system -X- _ O
better -X- _ O
accomplished -X- _ O
the -X- _ O
command -X- _ O
q. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
, -X- _ O
we -X- _ O
asked -X- _ O
which -X- _ O
system -X- _ O
was -X- _ O
more -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
grounding -X- _ O
G. -X- _ O
8 -X- _ O
: -X- _ O
Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName
: -X- _ O
comparisons -X- _ O
between -X- _ O
absolute -X- _ O
evaluations -X- _ O
of -X- _ O
different -X- _ O
settings -X- _ O
. -X- _ O
Raters -X- _ O
were -X- _ O
asked -X- _ O
whether -X- _ O
edits -X- _ O
were -X- _ O
satisfactory -X- _ O
. -X- _ O
0 -X- _ O
corresponds -X- _ O
to -X- _ O
strong -X- _ O
disagreement -X- _ O
, -X- _ O
and -X- _ O
5 -X- _ O
to -X- _ O
strong -X- _ O
agreement -X- _ O
. -X- _ O
Systems -X- _ O
are -X- _ O
given -X- _ O
by -X- _ O
model -X- _ O
( -X- _ O
full -X- _ O
or -X- _ O
with -X- _ O
the -X- _ O
comment -X- _ O
ablated -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
whether -X- _ O
the -X- _ O
command -X- _ O
was -X- _ O
shown -X- _ O
to -X- _ O
the -X- _ O
raters -X- _ O
( -X- _ O
+ -X- _ O
or -X- _ O
- -X- _ O
) -X- _ O
. -X- _ O
Bolded -X- _ O
numbers -X- _ O
indicate -X- _ O
significant -X- _ O
difference -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.0125 -X- _ O
. -X- _ O
than -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
9 -X- _ O
In -X- _ O
the -X- _ O
grounding -X- _ O
task -X- _ O
, -X- _ O
Interactive -X- _ O
Editor -X- _ O
demonstrates -X- _ O
good -X- _ O
correspondence -X- _ O
with -X- _ O
the -X- _ O
background -X- _ O
material -X- _ O
. -X- _ O
10 -X- _ O
Judges -X- _ O
were -X- _ O
further -X- _ O
asked -X- _ O
whether -X- _ O
the -X- _ O
retrieved -X- _ O
grounding -X- _ O
was -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
context -X- _ O
D -X- _ O
: -X- _ O
92.86 -X- _ O
% -X- _ O
of -X- _ O
judgments -X- _ O
recorded -X- _ O
the -X- _ O
grounding -X- _ O
as -X- _ O
either -X- _ O
" -X- _ O
Somewhat -X- _ O
relevant -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
Very -X- _ O
relevant -X- _ O
" -X- _ O
. -X- _ O

We -X- _ O
begin -X- _ O
with -X- _ O
various -X- _ O
definitions -X- _ O
and -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
simulation -X- _ O
of -X- _ O
Turing -X- _ O
machines -X- _ O
by -X- _ O
RNNs -X- _ O
and -X- _ O
state -X- _ O
the -X- _ O
Turing -X- _ O
- -X- _ O
completeness -X- _ O
result -X- _ O
for -X- _ O
RNNs -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
vanilla -X- _ O
and -X- _ O
directional -X- _ O
Transformers -X- _ O
and -X- _ O
what -X- _ O
it -X- _ O
means -X- _ O
for -X- _ O
Transformers -X- _ O
to -X- _ O
simulate -X- _ O
RNNs -X- _ O
. -X- _ O
Many -X- _ O
of -X- _ O
the -X- _ O
definitions -X- _ O
from -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
are -X- _ O
reproduced -X- _ O
here -X- _ O
, -X- _ O
but -X- _ O
in -X- _ O
more -X- _ O
detail -X- _ O
. -X- _ O
In -X- _ O
Sec -X- _ O
. -X- _ O
C.1 -X- _ O
we -X- _ O
discuss -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
removing -X- _ O
a -X- _ O
residual -X- _ O
connection -X- _ O
on -X- _ O
computational -X- _ O
power -X- _ O
of -X- _ O
Transformers -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
C.2 -X- _ O
contains -X- _ O
the -X- _ O
proof -X- _ O
of -X- _ O
Turing -X- _ O
completeness -X- _ O
of -X- _ O
vanilla -X- _ O
Transformers -X- _ O
and -X- _ O
Sec -X- _ O
. -X- _ O
D -X- _ O
the -X- _ O
corresponding -X- _ O
proof -X- _ O
for -X- _ O
directional -X- _ O
Transformers -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Sec -X- _ O
. -X- _ O
5 -X- _ O
has -X- _ O
further -X- _ O
details -X- _ O
of -X- _ O
experiments -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
automatic -X- _ B-TaskName
event -X- _ I-TaskName
detection -X- _ I-TaskName
systems -X- _ O
on -X- _ O
modeling -X- _ O
the -X- _ O
spatial -X- _ O
and -X- _ O
temporal -X- _ O
pattern -X- _ O
of -X- _ O
a -X- _ O
social -X- _ O
protest -X- _ O
movement -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
participant -X- _ O
systems -X- _ O
to -X- _ O
reproduce -X- _ O
a -X- _ O
manually -X- _ O
curated -X- _ O
BLM -X- _ O
- -X- _ O
related -X- _ O
protest -X- _ B-DatasetName
event -X- _ I-DatasetName
data -X- _ I-DatasetName
set -X- _ I-DatasetName
, -X- _ O
by -X- _ O
detecting -X- _ O
BLM -X- _ O
event -X- _ O
reports -X- _ O
, -X- _ O
enriched -X- _ O
with -X- _ O
location -X- _ O
and -X- _ O
date -X- _ O
attributes -X- _ O
, -X- _ O
from -X- _ O
a -X- _ O
news -X- _ O
corpus -X- _ O
collection -X- _ O
, -X- _ O
a -X- _ O
Twitter -X- _ O
collection -X- _ O
, -X- _ O
and -X- _ O
from -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
. -X- _ O

Lemma -X- _ O
D.2 -X- _ O
. -X- _ O
There -X- _ O
exists -X- _ O
a -X- _ O
function -X- _ O
O -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
defined -X- _ O
by -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
such -X- _ O
that -X- _ O
, -X- _ O
Proof -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
O -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
such -X- _ O
that -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
O -X- _ O
( -X- _ O
a -X- _ O
t -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O

We -X- _ O
recruit -X- _ O
3 -X- _ O
annotators -X- _ O
that -X- _ O
work -X- _ O
as -X- _ O
academic -X- _ O
researchers -X- _ O
in -X- _ O
the -X- _ O
areas -X- _ O
of -X- _ O
NLP -X- _ O
and -X- _ O
social -X- _ O
science -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
30 -X- _ O
topics -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
are -X- _ O
provided -X- _ O
with -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
10 -X- _ O
topic -X- _ O
keywords -X- _ O
and -X- _ O
the -X- _ O
summaries -X- _ O
of -X- _ O
top -X- _ O
- -X- _ O
10 -X- _ O
most -X- _ O
relevant -X- _ O
documents -X- _ O
from -X- _ O
each -X- _ O
news -X- _ O
corpus -X- _ O
( -X- _ O
as -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
60 -X- _ O
documents -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
select -X- _ O
15 -X- _ O
topics -X- _ O
on -X- _ O
which -X- _ O
they -X- _ O
feel -X- _ O
it -X- _ O
is -X- _ O
straightforward -X- _ O
to -X- _ O
find -X- _ O
two -X- _ O
polarized -X- _ O
political -X- _ O
stances -X- _ O
by -X- _ O
reading -X- _ O
the -X- _ O
relevant -X- _ O
documents -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
on -X- _ O
topic -X- _ O
12 -X- _ O
about -X- _ O
Democratic -X- _ O
primaries -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
intuitive -X- _ O
to -X- _ O
perceive -X- _ O
the -X- _ O
two -X- _ O
political -X- _ O
stances -X- _ O
are -X- _ O
" -X- _ O
endorsing -X- _ O
Biden -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
endorsing -X- _ O
Sanders -X- _ O
" -X- _ O
after -X- _ O
reading -X- _ O
relevant -X- _ O
articles -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
this -X- _ O
topic -X- _ O
is -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
selected -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
overlap -X- _ O
of -X- _ O
the -X- _ O
15 -X- _ O
selected -X- _ O
topics -X- _ O
from -X- _ O
3 -X- _ O
annotators -X- _ O
and -X- _ O
obtain -X- _ O
10 -X- _ O
topics -X- _ O
: -X- _ O
T -X- _ O
labeled -X- _ O
= -X- _ O
{ -X- _ O
t -X- _ O
1 -X- _ O
, -X- _ O
t -X- _ O
2 -X- _ O
, -X- _ O
t -X- _ O
8 -X- _ O
, -X- _ O
t -X- _ O
9 -X- _ O
, -X- _ O
t -X- _ O
10 -X- _ O
, -X- _ O
t -X- _ O
11 -X- _ O
, -X- _ O
t -X- _ O
12 -X- _ O
, -X- _ O
t -X- _ O
27 -X- _ O
, -X- _ O
t -X- _ O
30 -X- _ O
, -X- _ O
t -X- _ O
33 -X- _ O
} -X- _ O
with -X- _ O
defined -X- _ O
polarized -X- _ O
political -X- _ O
stances -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
reach -X- _ O
an -X- _ O
agreement -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
clear -X- _ O
on -X- _ O
these -X- _ O
10 -X- _ O
topics -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
political -X- _ O
stances -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
10 -X- _ O
topics -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
stances -X- _ O
defined -X- _ O
by -X- _ O
3 -X- _ O
annotators -X- _ O
reach -X- _ O
a -X- _ O
complete -X- _ O
agreement -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
annotate -X- _ O
all -X- _ O
topics -X- _ O
because -X- _ O
1 -X- _ O
) -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
for -X- _ O
humans -X- _ O
to -X- _ O
discern -X- _ O
the -X- _ O
two -X- _ O
political -X- _ O
stances -X- _ O
on -X- _ O
some -X- _ O
topics -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
such -X- _ O
two -X- _ O
stances -X- _ O
do -X- _ O
not -X- _ O
exist -X- _ O
at -X- _ O
all -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
vanilla -X- _ O
LDA -X- _ O
topic -X- _ O
modeling -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
modeled -X- _ O
topics -X- _ O
will -X- _ O
change -X- _ O
using -X- _ O
different -X- _ O
topic -X- _ O
models -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
case -X- _ O
the -X- _ O
annotating -X- _ O
step -X- _ O
should -X- _ O
be -X- _ O
repeated -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
annotating -X- _ O
10 -X- _ O
topics -X- _ O
is -X- _ O
sufficient -X- _ O
to -X- _ O
quantitatively -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
PaCTE -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
topic -X- _ O
t -X- _ O
from -X- _ O
T -X- _ O
labeled -X- _ O
, -X- _ O
the -X- _ O
defined -X- _ O
two -X- _ O
stances -X- _ O
, -X- _ O
and -X- _ O
its -X- _ O
60 -X- _ O
most -X- _ O
relevant -X- _ O
documents -X- _ O
( -X- _ O
10 -X- _ O
from -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
news -X- _ O
sources -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
document -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
label -X- _ O
which -X- _ O
stance -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
and -X- _ O
label -X- _ O
it -X- _ O
as -X- _ O
0 -X- _ O
or -X- _ O
1 -X- _ O
; -X- _ O
if -X- _ O
the -X- _ O
annotator -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
perceive -X- _ O
a -X- _ O
clear -X- _ O
political -X- _ O
stance -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
annotator -X- _ O
will -X- _ O
label -X- _ O
it -X- _ O
as -X- _ O
- -X- _ O
1 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
document -X- _ O
, -X- _ O
the -X- _ O
majority -X- _ O
vote -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
labels -X- _ O
with -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
annotation -X- _ O
. -X- _ O
If -X- _ O
no -X- _ O
majority -X- _ O
vote -X- _ O
is -X- _ O
achieved -X- _ O
, -X- _ O
in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
three -X- _ O
annotators -X- _ O
give -X- _ O
three -X- _ O
different -X- _ O
labels -X- _ O
to -X- _ O
a -X- _ O
document -X- _ O
, -X- _ O
then -X- _ O
a -X- _ O
fourth -X- _ O
annotator -X- _ O
will -X- _ O
read -X- _ O
the -X- _ O
document -X- _ O
again -X- _ O
and -X- _ O
decide -X- _ O
the -X- _ O
final -X- _ O
label -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
complete -X- _ O
list -X- _ O
of -X- _ O
all -X- _ O
document -X- _ O
labels -X- _ O
on -X- _ O
the -X- _ O
10 -X- _ O
selected -X- _ O
topics -X- _ O
, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
our -X- _ O
public -X- _ O
repository -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
MALLET -X- _ B-DatasetName
5 -X- _ O
topic -X- _ O
modeling -X- _ O
. -X- _ O
The -X- _ O
top -X- _ O
- -X- _ O
10 -X- _ O
keywords -X- _ O
of -X- _ O
all -X- _ O
39 -X- _ O
topics -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
topic -X- _ O
0 -X- _ O
, -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
, -X- _ O
14 -X- _ O
, -X- _ O
16 -X- _ O
, -X- _ O
26 -X- _ O
, -X- _ O
35 -X- _ O
, -X- _ O
36 -X- _ O
, -X- _ O
37 -X- _ O
are -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
further -X- _ O
analysis -X- _ O
because -X- _ O
after -X- _ O
reading -X- _ O
relevant -X- _ O
articles -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
about -X- _ O
advertisements -X- _ O
, -X- _ O
sport -X- _ O
events -X- _ O
, -X- _ O
gossip -X- _ O
news -X- _ O
and -X- _ O
recipes -X- _ O
and -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
more -X- _ O
factual -X- _ O
and -X- _ O
convey -X- _ O
limited -X- _ O
media -X- _ O
ideologies -X- _ O
. -X- _ O
30 -X- _ O
topics -X- _ O
are -X- _ O
left -X- _ O
after -X- _ O
removing -X- _ O
the -X- _ O
9 -X- _ O
topics -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
lists -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
10 -X- _ O
keywords -X- _ O
of -X- _ O
the -X- _ O
30 -X- _ O
topics -X- _ O
. -X- _ O

The -X- _ O
Strength -X- _ O
of -X- _ O
the -X- _ O
Weakest -X- _ O
Supervision -X- _ O
: -X- _ O
Topic -X- _ B-TaskName
Classification -X- _ I-TaskName
Using -X- _ O
Class -X- _ O
Labels -X- _ O

This -X- _ O
paper -X- _ O
proposes -X- _ O
a -X- _ O
VAT -X- _ B-MethodName
- -X- _ O
based -X- _ O
framework -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
interpretability -X- _ O
of -X- _ O
attentions -X- _ O
via -X- _ O
both -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
compressing -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
eight -X- _ O
benchmark -X- _ O
datasets -X- _ O
for -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
within -X- _ O
this -X- _ O
framework -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
framework -X- _ O
for -X- _ O
sentiment -X- _ O
detection -X- _ O
, -X- _ O
which -X- _ O
further -X- _ O
demonstrates -X- _ O
the -X- _ O
superiority -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
interpretability -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
interesting -X- _ O
to -X- _ O
find -X- _ O
that -X- _ O
training -X- _ O
the -X- _ O
models -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
compressing -X- _ O
iteratively -X- _ O
is -X- _ O
effective -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
text -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
attention -X- _ O
framework -X- _ O
for -X- _ O
other -X- _ O
tasks -X- _ O
and -X- _ O
areas -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
and -X- _ O
visual -X- _ O
question -X- _ O
answering -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
describe -X- _ O
several -X- _ O
strategies -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
role -X- _ O
- -X- _ O
playing -X- _ O
accuracy -X- _ O
of -X- _ O
dialogue -X- _ O
agents -X- _ O
, -X- _ O
specifically -X- _ O
ways -X- _ O
to -X- _ O
improve -X- _ O
our -X- _ O
transformer -X- _ B-MethodName
baselines -X- _ O
. -X- _ O

Word -X- _ O
embeddings -X- _ O
create -X- _ O
a -X- _ O
vector -X- _ O
- -X- _ O
space -X- _ O
representation -X- _ O
in -X- _ O
which -X- _ O
words -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
meaning -X- _ O
are -X- _ O
in -X- _ O
close -X- _ O
proximity -X- _ O
. -X- _ O
Existing -X- _ O
approaches -X- _ O
to -X- _ O
make -X- _ O
embeddings -X- _ O
interpretable -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
via -X- _ O
contextual -X- _ O
( -X- _ O
Subramanian -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
sparse -X- _ O
embeddings -X- _ O
( -X- _ O
Panigrahi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
learned -X- _ O
( -X- _ O
Senel -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
transformations -X- _ O
( -X- _ O
Mathew -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
- -X- _ O
all -X- _ O
focus -X- _ O
on -X- _ O
text -X- _ O
only -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
emoji -X- _ O
are -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
casual -X- _ O
communication -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Online -X- _ O
Social -X- _ O
Networks -X- _ O
( -X- _ O
OSN -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
known -X- _ O
to -X- _ O
extend -X- _ O
textual -X- _ O
expressiveness -X- _ O
, -X- _ O
demonstrated -X- _ O
to -X- _ O
benefit -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
sentiment -X- _ O
analysis -X- _ O
( -X- _ O
Novak -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
study -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
emoji -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
add -X- _ O
interpretability -X- _ O
to -X- _ O
embeddings -X- _ O
of -X- _ O
text -X- _ O
and -X- _ O
emoji -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
the -X- _ O
POLAR -X- _ B-MethodName
- -X- _ O
framework -X- _ O
that -X- _ O
transforms -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
interpretable -X- _ O
counterparts -X- _ O
and -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
word -X- _ O
- -X- _ O
emoji -X- _ O
embeddings -X- _ O
trained -X- _ O
on -X- _ O
four -X- _ O
years -X- _ O
of -X- _ O
messaging -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
Jodel -X- _ O
social -X- _ O
network -X- _ O
. -X- _ O
We -X- _ O
devise -X- _ O
a -X- _ O
crowdsourced -X- _ O
human -X- _ O
judgement -X- _ O
experiment -X- _ O
to -X- _ O
study -X- _ O
six -X- _ O
usecases -X- _ O
, -X- _ O
evaluating -X- _ O
against -X- _ O
words -X- _ O
only -X- _ O
, -X- _ O
what -X- _ O
role -X- _ O
emoji -X- _ O
can -X- _ O
play -X- _ O
in -X- _ O
adding -X- _ O
interpretability -X- _ O
to -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
revised -X- _ O
POLAR -X- _ B-MethodName
approach -X- _ O
interpreting -X- _ O
words -X- _ O
and -X- _ O
emoji -X- _ O
with -X- _ O
words -X- _ O
, -X- _ O
emoji -X- _ O
or -X- _ O
both -X- _ O
according -X- _ O
to -X- _ O
human -X- _ O
judgement -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
statistically -X- _ O
significant -X- _ O
trends -X- _ O
demonstrating -X- _ O
that -X- _ O
emoji -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
interpret -X- _ O
other -X- _ O
emoji -X- _ O
very -X- _ O
well -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
process -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
entire -X- _ O
documents -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Longformer -X- _ B-MethodName
model -X- _ O
. -X- _ O
It -X- _ O
employs -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
scaling -X- _ O
linearly -X- _ O
with -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
which -X- _ O
enables -X- _ O
Longformer -X- _ B-MethodName
to -X- _ O
process -X- _ O
up -X- _ O
to -X- _ O
4 -X- _ O
, -X- _ O
096 -X- _ O
tokens -X- _ O
. -X- _ O
It -X- _ O
uses -X- _ O
multiple -X- _ O
attention -X- _ O
heads -X- _ O
with -X- _ O
different -X- _ O
dilation -X- _ O
configurations -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
entire -X- _ O
sequence -X- _ O
and -X- _ O
includes -X- _ O
global -X- _ O
attention -X- _ O
to -X- _ O
question -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
Question -X- _ O
and -X- _ O
document -X- _ O
pairs -X- _ O
are -X- _ O
packed -X- _ O
together -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
without -X- _ O
having -X- _ O
to -X- _ O
use -X- _ O
sliding -X- _ O
windows -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
a -X- _ O
dot -X- _ O
product -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
factoid -X- _ O
span -X- _ O
detection -X- _ O
data -X- _ O
set -X- _ O
with -X- _ O
short -X- _ O
answers -X- _ O
. -X- _ O
Crowdworkers -X- _ O
generated -X- _ O
the -X- _ O
questions -X- _ O
given -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
articles -X- _ O
. -X- _ O
DROP -X- _ B-DatasetName
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
makes -X- _ O
the -X- _ O
problem -X- _ O
more -X- _ O
challenging -X- _ O
by -X- _ O
adversarially -X- _ O
- -X- _ O
created -X- _ O
questions -X- _ O
requiring -X- _ O
discrete -X- _ O
reasoning -X- _ O
over -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
DROP -X- _ B-DatasetName
use -X- _ O
Wikipedia -X- _ O
pages -X- _ O
as -X- _ O
context -X- _ O
passages -X- _ O
whereas -X- _ O
SearchQA -X- _ B-DatasetName
( -X- _ O
Dunn -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
uses -X- _ O
IR -X- _ O
approaches -X- _ O
to -X- _ O
collect -X- _ O
context -X- _ O
passages -X- _ O
. -X- _ O
Answer -X- _ O
generation -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
passages -X- _ O
is -X- _ O
another -X- _ O
approach -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
MS -X- _ B-DatasetName
MARCO -X- _ I-DatasetName
( -X- _ O
Bajaj -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
search -X- _ O
queries -X- _ O
and -X- _ O
retrieved -X- _ O
documents -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
queries -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
also -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
QA -X- _ B-TaskName
data -X- _ O
sets -X- _ O
such -X- _ O
as -X- _ O
Antique -X- _ O
( -X- _ O
Hashemi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
data -X- _ O
set -X- _ O
for -X- _ O
answer -X- _ O
retrieval -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
factoid -X- _ O
ques -X- _ O
- -X- _ O
tions -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
multiple -X- _ O
- -X- _ O
choice -X- _ O
QA -X- _ B-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
RACE -X- _ B-DatasetName
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
ARC -X- _ B-DatasetName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SWAQ -X- _ B-DatasetName
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
COS -X- _ B-DatasetName
- -X- _ I-DatasetName
MOS -X- _ I-DatasetName
QA -X- _ I-DatasetName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
clustered -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
short -X- _ O
- -X- _ O
context -X- _ O
QA -X- _ B-TaskName
data -X- _ O
sets -X- _ O
. -X- _ O

NLQuAD -X- _ B-DatasetName
: -X- _ O
A -X- _ O
Non -X- _ O
- -X- _ O
Factoid -X- _ O
Long -X- _ O
Question -X- _ O
Answering -X- _ O
Data -X- _ O
Set -X- _ O

Fully -X- _ B-MethodName
Quantized -X- _ I-MethodName
Transformer -X- _ I-MethodName
for -X- _ O
Machine -X- _ B-TaskName
Translation -X- _ I-TaskName

Transformer -X- _ O
based -X- _ O
Natural -X- _ O
Language -X- _ O
Generation -X- _ O
for -X- _ O
Question -X- _ B-TaskName
- -X- _ I-TaskName
Answering -X- _ I-TaskName

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
datasets -X- _ O
using -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
and -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
many -X- _ O
multilingual -X- _ O
translation -X- _ O
scenarios -X- _ O
. -X- _ O
Many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Many -X- _ O
For -X- _ O
this -X- _ O
translation -X- _ O
scenario -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
IWSLT -X- _ B-DatasetName
- -X- _ O
17 -X- _ O
1 -X- _ O
translation -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
English -X- _ O
, -X- _ O
Italian -X- _ O
, -X- _ O
Romanian -X- _ O
, -X- _ O
Dutch -X- _ O
( -X- _ O
briefly -X- _ O
, -X- _ O
En -X- _ O
, -X- _ O
It -X- _ O
, -X- _ O
Ro -X- _ O
, -X- _ O
Nl -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
experimented -X- _ O
in -X- _ O
eight -X- _ O
directions -X- _ O
, -X- _ O
including -X- _ O
It↔En -X- _ O
, -X- _ O
Ro↔En -X- _ O
, -X- _ O
Nl↔En -X- _ O
, -X- _ O
and -X- _ O
It↔Ro -X- _ O
, -X- _ O
with -X- _ O
231.6k -X- _ O
, -X- _ O
220.5k -X- _ O
, -X- _ O
237.2k -X- _ O
, -X- _ O
and -X- _ O
217.5k -X- _ O
data -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
test2016 -X- _ O
and -X- _ O
test2017 -X- _ O
as -X- _ O
our -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Sentences -X- _ O
of -X- _ O
all -X- _ O
languages -X- _ O
were -X- _ O
tokenized -X- _ O
by -X- _ O
the -X- _ O
Moses -X- _ O
scripts -X- _ O
2 -X- _ O
and -X- _ O
further -X- _ O
segmented -X- _ O
into -X- _ O
subword -X- _ O
symbols -X- _ O
using -X- _ O
Byte -X- _ O
- -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
rules -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
40 -X- _ O
K -X- _ O
merge -X- _ O
operations -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
jointly -X- _ O
. -X- _ O
One -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Many -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
our -X- _ O
multilingual -X- _ O
translation -X- _ O
models -X- _ O
using -X- _ O
training -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
Europarl -X- _ B-DatasetName
Corpus -X- _ O
3 -X- _ O
, -X- _ O
Release -X- _ O
V7 -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
focus -X- _ O
on -X- _ O
English -X- _ O
to -X- _ O
twelve -X- _ O
primary -X- _ O
languages -X- _ O
: -X- _ O
Czech -X- _ O
, -X- _ O
Finnish -X- _ O
, -X- _ O
Greek -X- _ O
, -X- _ O
Hungarian -X- _ O
, -X- _ O
Lithuanian -X- _ O
, -X- _ O
Latvian -X- _ O
, -X- _ O
Polish -X- _ O
, -X- _ O
Portuguese -X- _ O
, -X- _ O
Slovak -X- _ O
, -X- _ O
Slovene -X- _ O
, -X- _ O
Swedish -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
briefly -X- _ O
, -X- _ O
Cs -X- _ O
, -X- _ O
Fi -X- _ O
, -X- _ O
El -X- _ O
, -X- _ O
Hu -X- _ O
, -X- _ O
Lt -X- _ O
, -X- _ O
Lv -X- _ O
, -X- _ O
Pl -X- _ O
, -X- _ O
Pt -X- _ O
, -X- _ O
Sk -X- _ O
, -X- _ O
Sl -X- _ O
, -X- _ O
Sv -X- _ O
, -X- _ O
Es -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sampled -X- _ O
0.6 -X- _ O
M -X- _ O
parallel -X- _ O
sentences -X- _ O
as -X- _ O
training -X- _ O
corpus -X- _ O
( -X- _ O
7.2 -X- _ O
M -X- _ O
in -X- _ O
all -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Europarl -X- _ B-DatasetName
evaluation -X- _ O
data -X- _ O
set -X- _ O
dev2006 -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
our -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
while -X- _ O
devtest2006 -X- _ O
is -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
language -X- _ O
pairs -X- _ O
without -X- _ O
available -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
split -X- _ O
1 -X- _ O
K -X- _ O
unseen -X- _ O
sentence -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
training -X- _ O
set -X- _ O
as -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
data -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
tokenize -X- _ O
and -X- _ O
truecase -X- _ O
the -X- _ O
sentences -X- _ O
with -X- _ O
Moses -X- _ O
scripts -X- _ O
and -X- _ O
apply -X- _ O
a -X- _ O
jointly -X- _ O
- -X- _ O
learned -X- _ O
set -X- _ O
of -X- _ O
90k -X- _ O
BPE -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
merged -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sides -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
twelve -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O

Multilingual -X- _ B-TaskName
neural -X- _ I-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
with -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
has -X- _ O
drawn -X- _ O
much -X- _ O
attention -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
capability -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
multiple -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
current -X- _ O
multilingual -X- _ O
translation -X- _ O
paradigm -X- _ O
often -X- _ O
makes -X- _ O
the -X- _ O
model -X- _ O
tend -X- _ O
to -X- _ O
preserve -X- _ O
the -X- _ O
general -X- _ O
knowledge -X- _ O
, -X- _ O
but -X- _ O
ignore -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
. -X- _ O
Some -X- _ O
previous -X- _ O
works -X- _ O
try -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
by -X- _ O
adding -X- _ O
various -X- _ O
kinds -X- _ O
of -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
modules -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
parameter -X- _ O
explosion -X- _ O
problem -X- _ O
and -X- _ O
require -X- _ O
specialized -X- _ O
manual -X- _ O
design -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
these -X- _ O
problems -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
divide -X- _ O
the -X- _ O
model -X- _ O
neurons -X- _ O
into -X- _ O
general -X- _ O
and -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
parts -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
importance -X- _ O
across -X- _ O
languages -X- _ O
. -X- _ O
The -X- _ O
general -X- _ O
part -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
preserving -X- _ O
the -X- _ O
general -X- _ O
knowledge -X- _ O
and -X- _ O
participating -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
languages -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
part -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
preserving -X- _ O
the -X- _ O
languagespecific -X- _ O
knowledge -X- _ O
and -X- _ O
participating -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
of -X- _ O
some -X- _ O
specific -X- _ O
languages -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
several -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
covering -X- _ O
IWSLT -X- _ B-DatasetName
and -X- _ O
Europarl -X- _ B-DatasetName
corpus -X- _ O
datasets -X- _ O
, -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
and -X- _ O
universality -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O

Multilingual -X- _ B-MethodName
Code -X- _ I-MethodName
- -X- _ I-MethodName
Switching -X- _ I-MethodName
for -X- _ O
Zero -X- _ B-TaskName
- -X- _ I-TaskName
Shot -X- _ I-TaskName
Cross -X- _ I-TaskName
- -X- _ I-TaskName
Lingual -X- _ I-TaskName
Intent -X- _ I-TaskName
Prediction -X- _ I-TaskName
and -X- _ O
Slot -X- _ B-TaskName
Filling -X- _ I-TaskName

This -X- _ O
preliminary -X- _ O
work -X- _ O
demonstrates -X- _ O
that -X- _ O
a -X- _ O
single -X- _ O
NLU -X- _ O
model -X- _ O
can -X- _ O
perform -X- _ O
simultaneous -X- _ O
slot -X- _ B-TaskName
filling -X- _ I-TaskName
, -X- _ O
translation -X- _ B-TaskName
, -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
and -X- _ O
language -X- _ B-TaskName
identification -X- _ I-TaskName
across -X- _ O
7 -X- _ O
languages -X- _ O
using -X- _ O
MultiATIS++ -X- _ B-DatasetName
. -X- _ O
Such -X- _ O
an -X- _ O
NLU -X- _ O
model -X- _ O
would -X- _ O
negate -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
multiple -X- _ O
- -X- _ O
language -X- _ O
support -X- _ O
in -X- _ O
some -X- _ O
portion -X- _ O
of -X- _ O
downstream -X- _ O
system -X- _ O
components -X- _ O
. -X- _ O
Performance -X- _ O
is -X- _ O
not -X- _ O
irreconcilably -X- _ O
worse -X- _ O
than -X- _ O
traditional -X- _ O
slot -X- _ B-TaskName
- -X- _ I-TaskName
filling -X- _ I-TaskName
models -X- _ O
, -X- _ O
and -X- _ O
performance -X- _ O
is -X- _ O
statistically -X- _ O
equivalent -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
additional -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Looking -X- _ O
forward -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
challenging -X- _ O
dataset -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
further -X- _ O
develop -X- _ O
the -X- _ O
translation -X- _ O
compo -X- _ O
- -X- _ O
nent -X- _ O
of -X- _ O
the -X- _ O
STIL -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
English -X- _ O
MultiATIS++ -X- _ B-DatasetName
test -X- _ O
set -X- _ O
only -X- _ O
contains -X- _ O
455 -X- _ O
unique -X- _ O
entity -X- _ O
- -X- _ O
slot -X- _ O
pairs -X- _ O
. -X- _ O
An -X- _ O
ideal -X- _ O
future -X- _ O
dataset -X- _ O
would -X- _ O
include -X- _ O
freeform -X- _ O
and -X- _ O
varied -X- _ O
content -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
text -X- _ O
messages -X- _ O
, -X- _ O
song -X- _ O
titles -X- _ O
, -X- _ O
or -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
questions -X- _ O
. -X- _ O
Until -X- _ O
then -X- _ O
, -X- _ O
work -X- _ O
remains -X- _ O
to -X- _ O
achieve -X- _ O
parity -X- _ O
with -X- _ O
English -X- _ O
- -X- _ O
only -X- _ O
ATIS -X- _ B-DatasetName
models -X- _ O
. -X- _ O

The -X- _ O
Airline -X- _ B-DatasetName
Travel -X- _ I-DatasetName
Information -X- _ I-DatasetName
System -X- _ I-DatasetName
( -X- _ O
ATIS -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
classic -X- _ O
benchmark -X- _ O
for -X- _ O
goal -X- _ O
- -X- _ O
oriented -X- _ O
NLU -X- _ B-TaskName
( -X- _ O
Price -X- _ O
, -X- _ O
1990 -X- _ O
; -X- _ O
Tur -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
utterances -X- _ O
focused -X- _ O
on -X- _ O
airline -X- _ O
travel -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
how -X- _ O
much -X- _ O
is -X- _ O
the -X- _ O
cheapest -X- _ O
flight -X- _ O
from -X- _ O
Boston -X- _ O
to -X- _ O
New -X- _ O
York -X- _ O
tomorrow -X- _ O
morning -X- _ O
? -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
17 -X- _ O
intents -X- _ O
, -X- _ O
though -X- _ O
the -X- _ O
distribution -X- _ O
is -X- _ O
skewed -X- _ O
, -X- _ O
with -X- _ O
70 -X- _ O
% -X- _ O
of -X- _ O
intents -X- _ O
being -X- _ O
the -X- _ O
flight -X- _ O
intent -X- _ O
. -X- _ O
Slots -X- _ O
are -X- _ O
labeled -X- _ O
using -X- _ O
the -X- _ O
Beginning -X- _ O
Inside -X- _ O
Outside -X- _ O
( -X- _ O
BIO -X- _ O
) -X- _ O
format -X- _ O
. -X- _ O
ATIS -X- _ B-DatasetName
was -X- _ O
localized -X- _ O
to -X- _ O
Turkish -X- _ O
and -X- _ O
Hindi -X- _ O
in -X- _ O
2018 -X- _ O
, -X- _ O
forming -X- _ O
MultiATIS -X- _ B-DatasetName
( -X- _ O
Upadhyay -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
to -X- _ O
Spanish -X- _ O
, -X- _ O
Portuguese -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
Chinese -X- _ O
, -X- _ O
and -X- _ O
Japanese -X- _ O
in -X- _ O
2020 -X- _ O
, -X- _ O
forming -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
ATIS++ -X- _ I-DatasetName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
Portuguese -X- _ O
was -X- _ O
excluded -X- _ O
due -X- _ O
to -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
Portuguese -X- _ O
pretraining -X- _ O
in -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
mBART -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
Japanese -X- _ O
was -X- _ O
excluded -X- _ O
due -X- _ O
to -X- _ O
a -X- _ O
current -X- _ O
lack -X- _ O
of -X- _ O
alignment -X- _ O
between -X- _ O
Japanese -X- _ O
and -X- _ O
English -X- _ O
samples -X- _ O
in -X- _ O
MultiATIS++ -X- _ B-DatasetName
. -X- _ O
Hindi -X- _ O
and -X- _ O
Turkish -X- _ O
data -X- _ O
were -X- _ O
taken -X- _ O
from -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
ATIS -X- _ I-DatasetName
, -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
were -X- _ O
upsampled -X- _ O
by -X- _ O
3x -X- _ O
for -X- _ O
Hindi -X- _ O
and -X- _ O
7x -X- _ O
for -X- _ O
Turkish -X- _ O
. -X- _ O
Prior -X- _ O
to -X- _ O
any -X- _ O
upsampling -X- _ O
, -X- _ O
there -X- _ O
were -X- _ O
4 -X- _ O
, -X- _ O
488 -X- _ O
training -X- _ O
samples -X- _ O
for -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
. -X- _ O
The -X- _ O
test -X- _ O
sets -X- _ O
contained -X- _ O
893 -X- _ O
samples -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
except -X- _ O
Turkish -X- _ O
, -X- _ O
which -X- _ O
had -X- _ O
715 -X- _ O
samples -X- _ O
. -X- _ O
For -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
, -X- _ O
validation -X- _ O
sets -X- _ O
of -X- _ O
490 -X- _ O
samples -X- _ O
were -X- _ O
used -X- _ O
in -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
smaller -X- _ O
data -X- _ O
quantities -X- _ O
for -X- _ O
Hindi -X- _ O
and -X- _ O
Turkish -X- _ O
, -X- _ O
two -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
set -X- _ O
configurations -X- _ O
were -X- _ O
considered -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
configuration -X- _ O

Multilingual -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Understanding -X- _ I-TaskName
( -X- _ O
NLU -X- _ B-TaskName
) -X- _ O
, -X- _ O
also -X- _ O
called -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NLU -X- _ I-TaskName
, -X- _ O
is -X- _ O
a -X- _ O
technique -X- _ O
by -X- _ O
which -X- _ O
an -X- _ O
NLU -X- _ B-TaskName
- -X- _ O
based -X- _ O
system -X- _ O
can -X- _ O
scale -X- _ O
to -X- _ O
multiple -X- _ O
languages -X- _ O
. -X- _ O
A -X- _ O
single -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
accept -X- _ O
input -X- _ O
from -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
language -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
most -X- _ O
recent -X- _ O
high -X- _ O
- -X- _ O
performing -X- _ O
systems -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
supported -X- _ O
languages -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
tuned -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
using -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Two -X- _ O
typical -X- _ O
tasks -X- _ O
for -X- _ O
goal -X- _ O
- -X- _ O
based -X- _ O
systems -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
virtual -X- _ O
assistants -X- _ O
and -X- _ O
chatbots -X- _ O
, -X- _ O
are -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
slot -X- _ B-TaskName
filling -X- _ I-TaskName
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O
Though -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
creates -X- _ O
a -X- _ O
language -X- _ O
agnostic -X- _ O
output -X- _ O
( -X- _ O
the -X- _ O
intent -X- _ O
of -X- _ O
the -X- _ O
user -X- _ O
) -X- _ O
, -X- _ O
slot -X- _ B-TaskName
filling -X- _ I-TaskName
does -X- _ O
not -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
a -X- _ O
slot -X- _ O
- -X- _ O
filling -X- _ O
model -X- _ O
outputs -X- _ O
the -X- _ O
labels -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
input -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
user -X- _ O
. -X- _ O
Suppose -X- _ O
the -X- _ O
slot -X- _ O
- -X- _ O
filling -X- _ O
model -X- _ O
can -X- _ O
handle -X- _ O
L -X- _ O
languages -X- _ O
. -X- _ O
Downstream -X- _ O
components -X- _ O
must -X- _ O
therefore -X- _ O
handle -X- _ O
all -X- _ O
L -X- _ O
languages -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
system -X- _ O
to -X- _ O
be -X- _ O
multilingual -X- _ O
across -X- _ O
L -X- _ O
languages -X- _ O
. -X- _ O
Machine -X- _ O
translation -X- _ O
could -X- _ O
be -X- _ O
performed -X- _ O
before -X- _ O
the -X- _ O
slot -X- _ O
filling -X- _ O
model -X- _ O
at -X- _ O
system -X- _ O
runtime -X- _ O
, -X- _ O
though -X- _ O
the -X- _ O
latency -X- _ O
would -X- _ O
be -X- _ O
fully -X- _ O
additive -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
amount -X- _ O
of -X- _ O
information -X- _ O
useful -X- _ O
to -X- _ O
the -X- _ O
slotfilling -X- _ O
model -X- _ O
may -X- _ O
be -X- _ O
lost -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
translation -X- _ O
could -X- _ O
occur -X- _ O
after -X- _ O
the -X- _ O
slot -X- _ O
- -X- _ O
filling -X- _ O
model -X- _ O
at -X- _ O
runtime -X- _ O
, -X- _ O
but -X- _ O
slot -X- _ O
alignment -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
task -X- _ O
( -X- _ O
Jain -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
was -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
simultaneously -X- _ O
translate -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
output -X- _ O
slotted -X- _ O
text -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
( -X- _ O
English -X- _ O
) -X- _ O
, -X- _ O
classify -X- _ O
the -X- _ O
intent -X- _ O
, -X- _ O
and -X- _ O
classify -X- _ O
the -X- _ O
input -X- _ O
language -X- _ O
( -X- _ O
See -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
STIL -X- _ B-TaskName
task -X- _ O
is -X- _ O
defined -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
language -X- _ O
tag -X- _ O
is -X- _ O
not -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
language -X- _ O
identification -X- _ O
is -X- _ O
necessary -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
system -X- _ O
can -X- _ O
communicate -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
in -X- _ O
the -X- _ O
correct -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
STIL -X- _ B-TaskName
cases -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
Each -X- _ O
token -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
its -X- _ O
BIO -X- _ O
- -X- _ O
tagged -X- _ O
slot -X- _ O
label -X- _ O
. -X- _ O
The -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
and -X- _ O
slots -X- _ O
are -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
intent -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O
sification -X- _ O
, -X- _ O
and -X- _ O
Language -X- _ O
identification -X- _ O
( -X- _ O
STIL -X- _ B-TaskName
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
both -X- _ O
non -X- _ O
- -X- _ O
translated -X- _ O
and -X- _ O
STIL -X- _ B-TaskName
results -X- _ O
using -X- _ O
the -X- _ O
mBART -X- _ B-MethodName
model -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
trained -X- _ O
using -X- _ O
a -X- _ O
fully -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
data -X- _ O
format -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
public -X- _ O
release -X- _ O
of -X- _ O
source -X- _ O
code -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
goal -X- _ O
toward -X- _ O
reproducibility -X- _ O
and -X- _ O
future -X- _ O
work -X- _ O
on -X- _ O
the -X- _ O
STIL -X- _ B-TaskName
task -X- _ O
1 -X- _ O
. -X- _ O

STIL -X- _ B-TaskName
- -X- _ O
Simultaneous -X- _ B-TaskName
Slot -X- _ I-TaskName
Filling -X- _ I-TaskName
, -X- _ I-TaskName
Translation -X- _ I-TaskName
, -X- _ I-TaskName
Intent -X- _ I-TaskName
Classification -X- _ I-TaskName
, -X- _ I-TaskName
and -X- _ I-TaskName
Language -X- _ I-TaskName
Identification -X- _ I-TaskName
: -X- _ O
Initial -X- _ O
Results -X- _ O
using -X- _ O
mBART -X- _ B-MethodName
on -X- _ O
MultiATIS++ -X- _ B-DatasetName

Previous -X- _ O
approaches -X- _ O
for -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
slot -X- _ B-TaskName
filling -X- _ I-TaskName
have -X- _ O
used -X- _ O
either -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
separate -X- _ O
models -X- _ O
for -X- _ O
slot -X- _ O
filling -X- _ O
, -X- _ O
including -X- _ O
support -X- _ O
vector -X- _ O
machines -X- _ O
( -X- _ O
Moschitti -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
conditional -X- _ O
random -X- _ O
fields -X- _ O
( -X- _ O
Xu -X- _ O
and -X- _ O
Sarikaya -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
of -X- _ O
various -X- _ O
types -X- _ O
( -X- _ O
Kurata -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
or -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
joint -X- _ O
models -X- _ O
that -X- _ O
diverge -X- _ O
into -X- _ O
separate -X- _ O
decoders -X- _ O
or -X- _ O
layers -X- _ O
for -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
slot -X- _ B-TaskName
filling -X- _ I-TaskName
( -X- _ O
Xu -X- _ O
and -X- _ O
Sarikaya -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Lane -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hakkani -X- _ O
- -X- _ O
Tür -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
or -X- _ O
that -X- _ O
share -X- _ O
hidden -X- _ O
states -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
fully -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
approach -X- _ O
similar -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
T5 -X- _ O
model -X- _ O
was -X- _ O
used -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
would -X- _ O
have -X- _ O
maximum -X- _ O
information -X- _ O
sharing -X- _ O
across -X- _ O
the -X- _ O
four -X- _ O
STIL -X- _ O
sub -X- _ O
- -X- _ O
tasks -X- _ O
. -X- _ O
Encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
, -X- _ O
first -X- _ O
introduced -X- _ O
in -X- _ O
2014 -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
a -X- _ O
mainstay -X- _ O
of -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
transformer -X- _ O
model -X- _ O
included -X- _ O
both -X- _ O
an -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
decoder -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
then -X- _ O
, -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
work -X- _ O
on -X- _ O
transformers -X- _ O
focuses -X- _ O
on -X- _ O
models -X- _ O
with -X- _ O
only -X- _ O
an -X- _ O
encoder -X- _ O
pretrained -X- _ O
with -X- _ O
autoencoding -X- _ O
techniques -X- _ O
( -X- _ O
e.g. -X- _ O
BERT -X- _ O
by -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
or -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
models -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
decoder -X- _ O
( -X- _ O
e.g. -X- _ O
GPT -X- _ O
by -X- _ O
Radford -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
it -X- _ O
was -X- _ O
assumed -X- _ O
that -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BART -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
T5 -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
the -X- _ O
best -X- _ O
architectural -X- _ O
candidates -X- _ O
given -X- _ O
the -X- _ O
translation -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
STIL -X- _ B-TaskName
task -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
past -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
advancement -X- _ O
by -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
on -X- _ O
ATIS -X- _ O
, -X- _ O
cited -X- _ O
above -X- _ O
. -X- _ O
Rigorous -X- _ O
architectural -X- _ O
comparisons -X- _ O
are -X- _ O
left -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
studied -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
training -X- _ O
topic -X- _ O
classifiers -X- _ O
using -X- _ O
only -X- _ O
class -X- _ O
labels -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
six -X- _ O
data -X- _ O
sets -X- _ O
show -X- _ O
that -X- _ O
class -X- _ O
labels -X- _ O
can -X- _ O
save -X- _ O
a -X- _ O
significant -X- _ O
amount -X- _ O
of -X- _ O
labeled -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
beginning -X- _ O
. -X- _ O
Retrieval -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
methods -X- _ O
tend -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
long -X- _ O
documents -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
performs -X- _ O
better -X- _ O
on -X- _ O
short -X- _ O
documents -X- _ O
. -X- _ O
This -X- _ O
study -X- _ O
opens -X- _ O
up -X- _ O
many -X- _ O
interesting -X- _ O
avenues -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
perspective -X- _ O
on -X- _ O
text -X- _ O
classification -X- _ O
: -X- _ O
can -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
text -X- _ O
classifier -X- _ O
by -X- _ O
just -X- _ O
providing -X- _ O
a -X- _ O
short -X- _ O
description -X- _ O
of -X- _ O
each -X- _ O
class -X- _ O
? -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
challenging -X- _ O
( -X- _ O
but -X- _ O
more -X- _ O
user -X- _ O
- -X- _ O
friendly -X- _ O
) -X- _ O
setup -X- _ O
than -X- _ O
standard -X- _ O
supervised -X- _ O
classification -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
future -X- _ O
work -X- _ O
can -X- _ O
investigate -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
sentiment -X- _ O
and -X- _ O
emotion -X- _ O
classification -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
more -X- _ O
challenging -X- _ O
than -X- _ O
topic -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
approaches -X- _ O
- -X- _ O
leveraging -X- _ O
unlabeled -X- _ O
data -X- _ O
( -X- _ O
retrievalbased -X- _ O
and -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
methods -X- _ O
) -X- _ O
and -X- _ O
leveraging -X- _ O
pretrained -X- _ O
models -X- _ O
( -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
) -X- _ O
could -X- _ O
be -X- _ O
combined -X- _ O
to -X- _ O
give -X- _ O
robust -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
short -X- _ O
and -X- _ O
long -X- _ O
documents -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
invite -X- _ O
users -X- _ O
into -X- _ O
the -X- _ O
training -X- _ O
loop -X- _ O
: -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
labeling -X- _ O
documents -X- _ O
, -X- _ O
users -X- _ O
can -X- _ O
also -X- _ O
revise -X- _ O
the -X- _ O
class -X- _ O
definitions -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
classifier -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
six -X- _ O
topic -X- _ O
classification -X- _ O
data -X- _ O
sets -X- _ O
with -X- _ O
different -X- _ O
document -X- _ O
lengths -X- _ O
and -X- _ O
application -X- _ O
domains -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
summarizes -X- _ O
basic -X- _ O
statistics -X- _ O
of -X- _ O
these -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
and -X- _ O
Three -X- _ O
short -X- _ O
text -X- _ O
data -X- _ O
sets -X- _ O
are -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Wiki -X- _ B-DatasetName
Titles -X- _ I-DatasetName
: -X- _ O
Wikipedia -X- _ O
article -X- _ O
titles -X- _ O
sampled -X- _ O
from -X- _ O
15 -X- _ O
main -X- _ O
categories -X- _ O
( -X- _ O
Wikipedia -X- _ O
Main -X- _ O
Topic -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
News -X- _ B-DatasetName
Titles -X- _ I-DatasetName
: -X- _ O
The -X- _ O
UCI -X- _ B-DatasetName
news -X- _ I-DatasetName
title -X- _ I-DatasetName
data -X- _ I-DatasetName
set -X- _ I-DatasetName
( -X- _ O
Lichman -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Y -X- _ B-DatasetName
Questions -X- _ I-DatasetName
: -X- _ O
User -X- _ O
- -X- _ O
posted -X- _ O
questions -X- _ O
in -X- _ O
Yahoo -X- _ O
Answers -X- _ O
( -X- _ O
Yahoo -X- _ O
Language -X- _ O
Data -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
Three -X- _ O
long -X- _ O
text -X- _ O
data -X- _ O
sets -X- _ O
are -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
20 -X- _ B-DatasetName
News -X- _ I-DatasetName
: -X- _ O
The -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
20 -X- _ B-DatasetName
newsgroup -X- _ I-DatasetName
data -X- _ I-DatasetName
set -X- _ I-DatasetName
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Reuters -X- _ B-DatasetName
. -X- _ O
The -X- _ O
Reuters -X- _ B-DatasetName
- -X- _ I-DatasetName
21578 -X- _ I-DatasetName
data -X- _ I-DatasetName
set -X- _ I-DatasetName
( -X- _ O
Lewis -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
10 -X- _ O
largest -X- _ O
topics -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Med -X- _ B-DatasetName
WSD -X- _ I-DatasetName
: -X- _ O
The -X- _ O
MeSH -X- _ B-DatasetName
word -X- _ O
sense -X- _ O
disambiguation -X- _ O
( -X- _ O
WSD -X- _ O
) -X- _ O
data -X- _ O
set -X- _ O
( -X- _ O
Jimeno -X- _ O
- -X- _ O
Yepes -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
WSD -X- _ O
task -X- _ O
aims -X- _ O
to -X- _ O
tell -X- _ O
the -X- _ O
sense -X- _ O
( -X- _ O
meaning -X- _ O
) -X- _ O
of -X- _ O
an -X- _ O
ambiguous -X- _ O
term -X- _ O
in -X- _ O
a -X- _ O
MEDLINE -X- _ O
abstract -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
term -X- _ O
" -X- _ O
cold -X- _ O
" -X- _ O
may -X- _ O
refer -X- _ O
to -X- _ O
Low -X- _ O
Temperature -X- _ O
, -X- _ O
Common -X- _ O
Cold -X- _ O
, -X- _ O
or -X- _ O
Chronic -X- _ O
Obstructive -X- _ O
Lung -X- _ O
Disease -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O
These -X- _ O
senses -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
class -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
198 -X- _ O
ambiguous -X- _ O
words -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
100 -X- _ O
labeled -X- _ O
abstracts -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
statistics -X- _ O
over -X- _ O
198 -X- _ O
independent -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
Although -X- _ O
no -X- _ O
true -X- _ O
labels -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
some -X- _ O
methods -X- _ O
require -X- _ O
unlabeled -X- _ O
data -X- _ O
for -X- _ O
retrieval -X- _ O
, -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
, -X- _ O
and -X- _ O
re -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
split -X- _ O
unlabeled -X- _ O
data -X- _ O
into -X- _ O
5 -X- _ O
folds -X- _ O
, -X- _ O
using -X- _ O
4 -X- _ O
folds -X- _ O
to -X- _ O
" -X- _ O
train -X- _ O
" -X- _ O
a -X- _ O
classifier -X- _ O
and -X- _ O
1 -X- _ O
fold -X- _ O
for -X- _ O
test -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
macroaveraged -X- _ B-MetricName
F -X- _ I-MetricName
1 -X- _ I-MetricName
as -X- _ O
the -X- _ O
performance -X- _ O
metric -X- _ O
because -X- _ O
not -X- _ O
all -X- _ O
data -X- _ O
sets -X- _ O
have -X- _ O
a -X- _ O
balanced -X- _ O
class -X- _ O
distribution -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
methods -X- _ O
on -X- _ O
six -X- _ O
topic -X- _ O
classification -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
goals -X- _ O
are -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
best -X- _ O
classification -X- _ O
performance -X- _ O
achievable -X- _ O
using -X- _ O
class -X- _ O
labels -X- _ O
only -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
equivalent -X- _ O
amount -X- _ O
of -X- _ O
true -X- _ O
labels -X- _ O
needed -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
same -X- _ O
warm -X- _ O
- -X- _ O
start -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
explored -X- _ O
statistical -X- _ O
and -X- _ O
neural -X- _ O
models -X- _ O
for -X- _ O
noun -X- _ B-TaskName
ellipsis -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ I-TaskName
resolution -X- _ I-TaskName
, -X- _ O
presenting -X- _ O
a -X- _ O
strong -X- _ O
results -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
neural -X- _ O
classifiers -X- _ O
perform -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
statistical -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
representation -X- _ O
. -X- _ O
As -X- _ O
with -X- _ O
several -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
contextual -X- _ O
nature -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
useful -X- _ O
for -X- _ O
noun -X- _ B-TaskName
ellipsis -X- _ I-TaskName
resolution -X- _ I-TaskName
too -X- _ O
, -X- _ O
making -X- _ O
robust -X- _ O
predictions -X- _ O
with -X- _ O
simple -X- _ O
neural -X- _ O
classifiers -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
addition -X- _ O
of -X- _ O
manual -X- _ O
features -X- _ O
boosts -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
classifiers -X- _ O
including -X- _ O
those -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
highlighting -X- _ O
that -X- _ O
ellipsis -X- _ O
is -X- _ O
a -X- _ O
syntactically -X- _ O
constrained -X- _ O
phenomenon -X- _ O
. -X- _ O

We -X- _ O
explore -X- _ O
utilizing -X- _ O
an -X- _ O
unlikelihood -X- _ B-MetricName
( -X- _ O
UL -X- _ B-MetricName
) -X- _ O
loss -X- _ O
While -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
LIGHT -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
standard -X- _ O
NLL -X- _ B-MetricName
loss -X- _ O
, -X- _ O
with -X- _ O
some -X- _ O
fixed -X- _ O
probability -X- _ O
we -X- _ O
consider -X- _ O
a -X- _ O
candidate -X- _ O
model -X- _ O
generation -X- _ O
for -X- _ O
UL -X- _ B-MetricName
loss -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
generation -X- _ O
is -X- _ O
sent -X- _ O
to -X- _ O
the -X- _ O
RPA -X- _ O
classifier -X- _ O
; -X- _ O
if -X- _ O
the -X- _ O
generation -X- _ O
is -X- _ O
classified -X- _ O
as -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
incorrect -X- _ O
character -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
each -X- _ O
partial -X- _ O
generated -X- _ O
sequence -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
, -X- _ O
and -X- _ O
send -X- _ O
these -X- _ O
sequences -X- _ O
to -X- _ O
the -X- _ O
LTR -X- _ O
RPA -X- _ O
classifier -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
candidate -X- _ O
partial -X- _ O
sequences -X- _ O
match -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
character -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
UL -X- _ O
loss -X- _ O
to -X- _ O
tokens -X- _ O
that -X- _ O
yield -X- _ O
the -X- _ O
wrong -X- _ O
character -X- _ O
classification -X- _ O
. -X- _ O

We -X- _ O
tackle -X- _ O
various -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
in -X- _ O
a -X- _ O
novel -X- _ O
generative -X- _ O
framework -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
By -X- _ O
formulating -X- _ O
the -X- _ O
target -X- _ O
sentences -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
annotation -X- _ O
- -X- _ O
style -X- _ O
and -X- _ O
extraction -X- _ O
- -X- _ O
style -X- _ O
paradigms -X- _ O
, -X- _ O
we -X- _ O
solve -X- _ O
multiple -X- _ O
sentiment -X- _ O
pair -X- _ O
or -X- _ O
triplet -X- _ O
extraction -X- _ O
tasks -X- _ O
with -X- _ O
a -X- _ O
unified -X- _ O
generation -X- _ O
model -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
multiple -X- _ O
benchmarks -X- _ O
across -X- _ O
four -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
an -X- _ O
initial -X- _ O
attempt -X- _ O
on -X- _ O
transforming -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
typically -X- _ O
treated -X- _ O
as -X- _ O
classification -X- _ O
problems -X- _ O
, -X- _ O
into -X- _ O
text -X- _ O
generation -X- _ O
problems -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
such -X- _ O
transformation -X- _ O
is -X- _ O
an -X- _ O
effective -X- _ O
solution -X- _ O
to -X- _ O
tackle -X- _ O
various -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Following -X- _ O
this -X- _ O
direction -X- _ O
, -X- _ O
designing -X- _ O
more -X- _ O
effective -X- _ O
generation -X- _ O
paradigms -X- _ O
and -X- _ O
extending -X- _ O
such -X- _ O
ideas -X- _ O
to -X- _ O
other -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
interesting -X- _ O
research -X- _ O
problems -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
as -X- _ O
the -X- _ O
main -X- _ O
evaluation -X- _ O
metrics -X- _ O
for -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
A -X- _ O
prediction -X- _ O
is -X- _ O
correct -X- _ O
if -X- _ O
and -X- _ O
only -X- _ O
if -X- _ O
all -X- _ O
its -X- _ O
predicted -X- _ O
sentiment -X- _ O
elements -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
or -X- _ O
triplet -X- _ O
are -X- _ O
correct -X- _ O
. -X- _ O

Aspect -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
( -X- _ O
ABSA -X- _ B-TaskName
) -X- _ O
has -X- _ O
received -X- _ O
increasing -X- _ O
attention -X- _ O
recently -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
work -X- _ O
tackles -X- _ O
ABSA -X- _ B-TaskName
in -X- _ O
a -X- _ O
discriminative -X- _ O
manner -X- _ O
, -X- _ O
designing -X- _ O
various -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
classification -X- _ O
networks -X- _ O
for -X- _ O
the -X- _ O
prediction -X- _ O
. -X- _ O
Despite -X- _ O
their -X- _ O
effectiveness -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
ignore -X- _ O
the -X- _ O
rich -X- _ O
label -X- _ O
semantics -X- _ O
in -X- _ O
ABSA -X- _ B-TaskName
problems -X- _ O
and -X- _ O
require -X- _ O
extensive -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
designs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
tackle -X- _ O
various -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
generative -X- _ O
framework -X- _ O
. -X- _ O
Two -X- _ O
types -X- _ O
of -X- _ O
paradigms -X- _ O
, -X- _ O
namely -X- _ O
annotation -X- _ O
- -X- _ O
style -X- _ O
and -X- _ O
extraction -X- _ O
- -X- _ O
style -X- _ O
modeling -X- _ O
, -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
by -X- _ O
formulating -X- _ O
each -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
as -X- _ O
a -X- _ O
text -X- _ O
generation -X- _ O
problem -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
ABSA -X- _ B-TaskName
tasks -X- _ O
across -X- _ O
multiple -X- _ O
benchmark -X- _ O
datasets -X- _ O
where -X- _ O
our -X- _ O
proposed -X- _ O
generative -X- _ O
approach -X- _ O
achieves -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
This -X- _ O
also -X- _ O
validates -X- _ O
the -X- _ O
strong -X- _ O
generality -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
adapted -X- _ O
to -X- _ O
arbitrary -X- _ O
ABSA -X- _ B-TaskName
task -X- _ O
without -X- _ O
additional -X- _ O
taskspecific -X- _ O
model -X- _ O
design -X- _ O
. -X- _ O
1 -X- _ O

The -X- _ O
original -X- _ O
paper -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
evaluated -X- _ O
dual -X- _ O
transfer -X- _ O
only -X- _ O
with -X- _ O
Transformer -X- _ O
base -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
scale -X- _ O
up -X- _ O
to -X- _ O
Transformer -X- _ O
big -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
face -X- _ O
a -X- _ O
more -X- _ O
realistic -X- _ O
setting -X- _ O
where -X- _ O
the -X- _ O
monolingual -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
low -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
chv -X- _ O
and -X- _ O
hsb -X- _ O
) -X- _ O
are -X- _ O
quite -X- _ O
scarce -X- _ O
. -X- _ O
Therefore -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
testing -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
scaling -X- _ O
up -X- _ O
. -X- _ O
Results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
show -X- _ O
that -X- _ O
Transformer -X- _ O
big -X- _ O
brings -X- _ O
consistent -X- _ O
improvements -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
runtime -X- _ O
of -X- _ O
each -X- _ O
step -X- _ O
in -X- _ O
dual -X- _ O
transfer -X- _ O
for -X- _ O
NMT -X- _ B-TaskName
chv -X- _ O
ru -X- _ O
with -X- _ O
Transformer -X- _ O
big -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
for -X- _ O
reference -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
numbers -X- _ O
can -X- _ O
vary -X- _ O
depending -X- _ O
on -X- _ O
implementation -X- _ O
and -X- _ O
data -X- _ O
size -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
experiments -X- _ O
and -X- _ O
our -X- _ O
final -X- _ O
submission -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Transformer -X- _ O
big -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
reproduced -X- _ O
the -X- _ O
illustration -X- _ O
of -X- _ O
dual -X- _ O
transfer -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
This -X- _ O
illustration -X- _ O
shows -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
general -X- _ O
transfer -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
high -X- _ O
resource -X- _ O
translation -X- _ O
direction -X- _ O
is -X- _ O
A -X- _ O
B -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
low -X- _ O
resource -X- _ O
translation -X- _ O
direction -X- _ O
is -X- _ O
P -X- _ O
Q. -X- _ O
As -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
, -X- _ O
in -X- _ O
many -X- _ O
cases -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
use -X- _ O
shared -X- _ O
target -X- _ O
transfer -X- _ O
( -X- _ O
B -X- _ O
= -X- _ O
Q -X- _ O
) -X- _ O
or -X- _ O
shared -X- _ O
source -X- _ O
transfer -X- _ O
( -X- _ O
A -X- _ O
= -X- _ O
P -X- _ O
) -X- _ O
. -X- _ O
Taking -X- _ O
chv -X- _ O
ru -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
choose -X- _ O
en -X- _ O
ru -X- _ O
as -X- _ O
the -X- _ O
high -X- _ O
resource -X- _ O
translation -X- _ O
direction -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
an -X- _ O
instance -X- _ O
of -X- _ O
shared -X- _ O
target -X- _ O
transfer -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
when -X- _ O
training -X- _ O
the -X- _ O
high -X- _ O
resource -X- _ O
translation -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
initialize -X- _ O
the -X- _ O
shared -X- _ O
language -X- _ O
side -X- _ O
with -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

NoahNMT -X- _ B-MethodName
at -X- _ O
WMT -X- _ O
2021 -X- _ O
: -X- _ O
Dual -X- _ O
Transfer -X- _ O
for -X- _ O
Very -X- _ O
Low -X- _ O
Resource -X- _ O
Supervised -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName

We -X- _ O
next -X- _ O
propose -X- _ O
an -X- _ O
approach -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
interpretability -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
by -X- _ O
adding -X- _ O
emoji -X- _ O
. -X- _ O
It -X- _ O
uses -X- _ O
our -X- _ O
extended -X- _ O
version -X- _ O
POLAR -X- _ B-MethodName
ρ -X- _ I-MethodName
and -X- _ O
adds -X- _ O
emoji -X- _ O
to -X- _ O
the -X- _ O
POLAR -X- _ B-MethodName
space -X- _ O
by -X- _ O
creating -X- _ O
word -X- _ O
embeddings -X- _ O
that -X- _ O
include -X- _ O
emoji -X- _ O
. -X- _ O

Style -X- _ B-TaskName
transfer -X- _ I-TaskName
has -X- _ O
been -X- _ O
widely -X- _ O
explored -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
with -X- _ O
non -X- _ O
- -X- _ O
parallel -X- _ O
corpus -X- _ O
by -X- _ O
directly -X- _ O
or -X- _ O
indirectly -X- _ O
extracting -X- _ O
a -X- _ O
notion -X- _ O
of -X- _ O
style -X- _ O
from -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
domain -X- _ O
corpus -X- _ O
. -X- _ O
A -X- _ O
common -X- _ O
shortcoming -X- _ O
of -X- _ O
existing -X- _ O
approaches -X- _ O
is -X- _ O
the -X- _ O
prerequisite -X- _ O
of -X- _ O
joint -X- _ O
annotations -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
stylistic -X- _ O
dimensions -X- _ O
under -X- _ O
consideration -X- _ O
. -X- _ O
Availability -X- _ O
of -X- _ O
such -X- _ O
dataset -X- _ O
across -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
styles -X- _ O
limits -X- _ O
the -X- _ O
extension -X- _ O
of -X- _ O
these -X- _ O
setups -X- _ O
to -X- _ O
multiple -X- _ O
style -X- _ O
dimensions -X- _ O
. -X- _ O
While -X- _ O
cascading -X- _ O
single -X- _ O
- -X- _ O
dimensional -X- _ O
models -X- _ O
across -X- _ O
multiple -X- _ O
styles -X- _ O
is -X- _ O
a -X- _ O
possibility -X- _ O
, -X- _ O
it -X- _ O
suffers -X- _ O
from -X- _ O
content -X- _ O
loss -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
the -X- _ O
style -X- _ O
dimensions -X- _ O
are -X- _ O
not -X- _ O
completely -X- _ O
independent -X- _ O
of -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
relax -X- _ O
this -X- _ O
requirement -X- _ O
of -X- _ O
jointly -X- _ O
annotated -X- _ O
data -X- _ O
across -X- _ O
multiple -X- _ O
styles -X- _ O
by -X- _ O
using -X- _ O
independently -X- _ O
acquired -X- _ O
data -X- _ O
across -X- _ O
different -X- _ O
style -X- _ O
dimensions -X- _ O
without -X- _ O
any -X- _ O
additional -X- _ O
annotations -X- _ O
. -X- _ O
We -X- _ O
initialize -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
setup -X- _ O
with -X- _ O
transformerbased -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
generic -X- _ O
corpus -X- _ O
and -X- _ O
enhance -X- _ O
its -X- _ O
re -X- _ O
- -X- _ O
writing -X- _ O
capability -X- _ O
to -X- _ O
multiple -X- _ O
target -X- _ O
style -X- _ O
dimensions -X- _ O
by -X- _ O
employing -X- _ O
multiple -X- _ O
style -X- _ O
- -X- _ O
aware -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
discriminators -X- _ O
. -X- _ O
Through -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
control -X- _ O
styles -X- _ O
across -X- _ O
multiple -X- _ O
style -X- _ O
dimensions -X- _ O
while -X- _ O
preserving -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
it -X- _ O
against -X- _ O
baselines -X- _ O
involving -X- _ O
cascaded -X- _ B-MethodName
state -X- _ I-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
the -X- _ I-MethodName
- -X- _ I-MethodName
art -X- _ I-MethodName
uni -X- _ I-MethodName
- -X- _ I-MethodName
dimensional -X- _ I-MethodName
style -X- _ I-MethodName
transfer -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

We -X- _ O
test -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
on -X- _ O
unconditional -X- _ O
and -X- _ O
conditional -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
and -X- _ O
analyze -X- _ O
the -X- _ O
results -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
performance -X- _ O
gained -X- _ O
by -X- _ O
the -X- _ O
guider -X- _ O
network -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
investigation -X- _ O
on -X- _ O
the -X- _ O
improvements -X- _ O
brought -X- _ O
by -X- _ O
each -X- _ O
part -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
consider -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
parallel -X- _ I-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
All -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Tesla -X- _ O
P100 -X- _ O
GPU -X- _ O
and -X- _ O
implemented -X- _ O
with -X- _ O
TensorFlow -X- _ O
and -X- _ O
Theano -X- _ O
. -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
and -X- _ O
model -X- _ O
architectures -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

Acknowledgement -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
. -X- _ O
The -X- _ O
research -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
DARPA -X- _ O
, -X- _ O
DOE -X- _ O
, -X- _ O
NIH -X- _ O
, -X- _ O
NSF -X- _ O
and -X- _ O
ONR -X- _ O
. -X- _ O

The -X- _ O
LSTM -X- _ O
state -X- _ O
of -X- _ O
dimension -X- _ O
for -X- _ O
the -X- _ O
generator -X- _ O
is -X- _ O
300 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
LSTM -X- _ O
state -X- _ O
of -X- _ O
dimension -X- _ O
for -X- _ O
the -X- _ O
guider -X- _ O
is -X- _ O
300 -X- _ O
. -X- _ O
The -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
word -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
embedding -X- _ I-HyperparameterName
is -X- _ O
300 -X- _ B-HyperparameterValue
. -X- _ O

More -X- _ O
Generated -X- _ O
Samples -X- _ O
of -X- _ O
Text -X- _ B-TaskName
Generation -X- _ I-TaskName
Table -X- _ O
13 -X- _ O
lists -X- _ O
more -X- _ O
generated -X- _ O
samples -X- _ O
on -X- _ O
the -X- _ O
proposed -X- _ O
GMGAN -X- _ O
and -X- _ O
its -X- _ O
baselines -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
SeqGAN -X- _ B-MethodName
tends -X- _ O
to -X- _ O
generate -X- _ O
shorter -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
readability -X- _ O
and -X- _ O
fluency -X- _ O
is -X- _ O
very -X- _ O
poor -X- _ O
. -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
LeakGAN -X- _ B-MethodName
tends -X- _ O
to -X- _ O
generate -X- _ O
very -X- _ O
long -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
usually -X- _ O
longer -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
even -X- _ O
with -X- _ O
good -X- _ O
locality -X- _ O
fluency -X- _ O
, -X- _ O
its -X- _ O
sentences -X- _ O
usually -X- _ O
are -X- _ O
not -X- _ O
semantically -X- _ O
consistent -X- _ O
. -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
GMGAN -X- _ B-MethodName
can -X- _ O
generate -X- _ O
sentences -X- _ O
with -X- _ O
similar -X- _ O
length -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
good -X- _ O
readability -X- _ O
and -X- _ O
fluency -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
validated -X- _ O
in -X- _ O
the -X- _ O
Human -X- _ B-MethodName
evaluation -X- _ I-MethodName
experiment -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
model -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
imitationlearning -X- _ I-MethodName
framework -X- _ O
for -X- _ O
adversarial -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
by -X- _ O
introducing -X- _ O
a -X- _ O
guider -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
generation -X- _ O
environment -X- _ O
. -X- _ O
The -X- _ O
guider -X- _ O
network -X- _ O
provides -X- _ O
a -X- _ O
plan -X- _ O
- -X- _ O
ahead -X- _ O
mechanism -X- _ O
for -X- _ O
next -X- _ O
- -X- _ O
word -X- _ O
selection -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
this -X- _ O
framework -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
sparse -X- _ O
- -X- _ O
reward -X- _ O
issue -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
intermediate -X- _ O
rewards -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
generator -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
models -X- _ O
are -X- _ O
validated -X- _ O
on -X- _ O
both -X- _ O
unconditional -X- _ O
and -X- _ O
conditional -X- _ O
text -X- _ O
generation -X- _ O
, -X- _ O
including -X- _ O
adversarial -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
and -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
parallel -X- _ I-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
We -X- _ O
achieve -X- _ O
improved -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
generation -X- _ B-MetricName
quality -X- _ I-MetricName
and -X- _ O
diversity -X- _ B-MetricName
for -X- _ O
unconditional -X- _ O
and -X- _ O
conditional -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
autoeocoder -X- _ O
( -X- _ O
AE -X- _ O
) -X- _ O
structure -X- _ O
for -X- _ O
sentence -X- _ O
feature -X- _ O
extraction -X- _ O
and -X- _ O
generation -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
is -X- _ O
shared -X- _ O
for -X- _ O
sentences -X- _ O
from -X- _ O
both -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
generated -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
explained -X- _ O
in -X- _ O
detail -X- _ O
below -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
an -X- _ O
imitationlearning -X- _ O
problem -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
timestep -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
, -X- _ O
also -X- _ O
called -X- _ O
a -X- _ O
generator -X- _ O
( -X- _ O
which -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
LSTM -X- _ O
decoder -X- _ O
) -X- _ O
, -X- _ O
takes -X- _ O
the -X- _ O
current -X- _ O
LSTM -X- _ O
state -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
s -X- _ O
t -X- _ O
. -X- _ O
The -X- _ O
policy -X- _ O
π -X- _ O
φ -X- _ O
( -X- _ O
| -X- _ O
s -X- _ O
t -X- _ O
) -X- _ O
parameterized -X- _ O
by -X- _ O
φ -X- _ O
is -X- _ O
a -X- _ O
conditional -X- _ O
generator -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
( -X- _ O
action -X- _ O
) -X- _ O
given -X- _ O
s -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
observation -X- _ O
representing -X- _ O
the -X- _ O
current -X- _ O
generated -X- _ O
sentence -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
of -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
is -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
total -X- _ B-MetricName
reward -X- _ I-MetricName
as -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
detail -X- _ O
the -X- _ O
components -X- _ O
for -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
subsections -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
objective -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
dialog -X- _ O
system -X- _ O
toolkit -X- _ O
that -X- _ O
allows -X- _ O
for -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
modal -X- _ I-TaskName
information -X- _ I-TaskName
processing -X- _ I-TaskName
and -X- _ O
that -X- _ O
provides -X- _ O
different -X- _ O
modules -X- _ O
for -X- _ O
extracting -X- _ O
social -X- _ O
signals -X- _ O
such -X- _ O
as -X- _ O
emotional -X- _ O
states -X- _ O
and -X- _ O
for -X- _ O
integrating -X- _ O
them -X- _ O
into -X- _ O
the -X- _ O
decision -X- _ O
making -X- _ O
process -X- _ O
. -X- _ O
The -X- _ O
toolkit -X- _ O
should -X- _ O
be -X- _ O
easy -X- _ O
to -X- _ O
use -X- _ O
and -X- _ O
extend -X- _ O
for -X- _ O
users -X- _ O
of -X- _ O
all -X- _ O
levels -X- _ O
of -X- _ O
technical -X- _ O
experience -X- _ O
, -X- _ O
providing -X- _ O
a -X- _ O
flexible -X- _ O
collaborative -X- _ O
research -X- _ O
platform -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
ADVISER -X- _ B-MethodName
1 -X- _ I-MethodName
- -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
, -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
dialog -X- _ O
system -X- _ O
toolkit -X- _ O
that -X- _ O
enables -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
( -X- _ O
incorporating -X- _ O
speech -X- _ O
, -X- _ O
text -X- _ O
and -X- _ O
vision -X- _ O
) -X- _ O
, -X- _ O
sociallyengaged -X- _ O
( -X- _ O
e.g. -X- _ O
emotion -X- _ O
recognition -X- _ O
, -X- _ O
engagement -X- _ O
level -X- _ O
prediction -X- _ O
and -X- _ O
backchanneling -X- _ O
) -X- _ O
conversational -X- _ O
agents -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
Python -X- _ O
- -X- _ O
based -X- _ O
implementation -X- _ O
of -X- _ O
our -X- _ O
toolkit -X- _ O
is -X- _ O
flexible -X- _ O
, -X- _ O
easy -X- _ O
to -X- _ O
use -X- _ O
, -X- _ O
and -X- _ O
easy -X- _ O
to -X- _ O
extend -X- _ O
not -X- _ O
only -X- _ O
for -X- _ O
technically -X- _ O
experienced -X- _ O
users -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
learning -X- _ O
researchers -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
for -X- _ O
less -X- _ O
technically -X- _ O
experienced -X- _ O
users -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
linguists -X- _ O
or -X- _ O
cognitive -X- _ O
scientists -X- _ O
, -X- _ O
thereby -X- _ O
providing -X- _ O
a -X- _ O
flexible -X- _ O
platform -X- _ O
for -X- _ O
collaborative -X- _ O
research -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
including -X- _ O
more -X- _ O
data -X- _ O
in -X- _ O
a -X- _ O
reading -X- _ O
comprehension -X- _ O
system -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
gen -X- _ O
- -X- _ O
eralization -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
given -X- _ O
that -X- _ O
our -X- _ O
created -X- _ O
dataset -X- _ O
has -X- _ O
the -X- _ O
SBRCS -X- _ O
which -X- _ O
are -X- _ O
missed -X- _ O
in -X- _ O
previous -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
steps -X- _ O
method -X- _ O
to -X- _ O
generate -X- _ O
skillrelated -X- _ O
questions -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
story -X- _ O
: -X- _ O
HTA -X- _ B-MethodName
followed -X- _ O
by -X- _ O
WTA -X- _ B-MethodName
. -X- _ O
HTA -X- _ B-MethodName
teaches -X- _ O
the -X- _ O
model -X- _ O
the -X- _ O
typical -X- _ O
format -X- _ O
for -X- _ O
comprehension -X- _ O
questions -X- _ O
using -X- _ O
large -X- _ O
previously -X- _ O
released -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
datasets -X- _ O
, -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
Cos -X- _ B-DatasetName
- -X- _ I-DatasetName
mosQA -X- _ I-DatasetName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Appendix -X- _ O
A.3 -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
both -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
. -X- _ O
These -X- _ O
previous -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
annotated -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
types -X- _ O
outlined -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
HTA -X- _ B-MethodName
phase -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
those -X- _ O
datasets -X- _ O
. -X- _ O
WTA -X- _ B-MethodName
guides -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
questions -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
specific -X- _ O
comprehension -X- _ O
skills -X- _ O
enumerated -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
in -X- _ O
HTA -X- _ B-MethodName
, -X- _ O
we -X- _ O
train -X- _ O
( -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
) -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
large -X- _ O
QG -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
teach -X- _ O
the -X- _ O
model -X- _ O
what -X- _ O
to -X- _ O
ask -X- _ O
( -X- _ O
WTA -X- _ B-MethodName
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
generation -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Text -X- _ O
Transfer -X- _ O
Transformer -X- _ O
T5 -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
closely -X- _ O
follows -X- _ O
the -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
T5 -X- _ O
is -X- _ O
a -X- _ O
SOTA -X- _ O
model -X- _ O
on -X- _ O
multiple -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
QA -X- _ O
. -X- _ O

Our -X- _ O
stories -X- _ O
( -X- _ O
passages -X- _ O
) -X- _ O
are -X- _ O
multi -X- _ O
- -X- _ O
genre -X- _ O
, -X- _ O
selfcontained -X- _ O
narratives -X- _ O
. -X- _ O
This -X- _ O
content -X- _ O
variety -X- _ O
leads -X- _ O
annotators -X- _ O
towards -X- _ O
asking -X- _ O
non -X- _ O
- -X- _ O
localized -X- _ O
questions -X- _ O
that -X- _ O
test -X- _ O
for -X- _ O
more -X- _ O
advanced -X- _ O
reading -X- _ O
comprehension -X- _ O
skills -X- _ O
. -X- _ O
The -X- _ O
stories -X- _ O
are -X- _ O
generated -X- _ O
using -X- _ O
several -X- _ O
resources -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
acquired -X- _ O
from -X- _ O
free -X- _ O
public -X- _ O
domain -X- _ O
content -X- _ O
( -X- _ O
Gutenberg -X- _ O
Project -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
2 -X- _ O
. -X- _ O
partnerships -X- _ O
with -X- _ O
a -X- _ O
publishing -X- _ O
house -X- _ O
( -X- _ O
Blue -X- _ O
Moon -X- _ O
Publishers -X- _ O
3 -X- _ O
) -X- _ O
and -X- _ O
an -X- _ O
educational -X- _ O
curriculum -X- _ O
development -X- _ O
foundation -X- _ O
( -X- _ O
The -X- _ O
Reimagined -X- _ O
Classroom -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
. -X- _ O
authored -X- _ O
by -X- _ O
two -X- _ O
professional -X- _ O
writers -X- _ O
, -X- _ O
( -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
stories -X- _ O
are -X- _ O
from -X- _ O
this -X- _ O
last -X- _ O
category -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
good -X- _ O
lexical -X- _ O
coverage -X- _ O
and -X- _ O
diverse -X- _ O
stories -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
to -X- _ O
write -X- _ O
and -X- _ O
collect -X- _ O
stories -X- _ O
that -X- _ O
come -X- _ O
from -X- _ O
a -X- _ O
varied -X- _ O
set -X- _ O
of -X- _ O
genres -X- _ O
( -X- _ O
e.g. -X- _ O
science -X- _ O
, -X- _ O
social -X- _ O
studies -X- _ O
, -X- _ O
fantasy -X- _ O
, -X- _ O
fairy -X- _ O
tale -X- _ O
, -X- _ O
historical -X- _ O
fiction -X- _ O
, -X- _ O
horror -X- _ O
, -X- _ O
mystery -X- _ O
, -X- _ O
adventure -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
726 -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
stories -X- _ O
. -X- _ O
The -X- _ O
stories -X- _ O
' -X- _ O
lengths -X- _ O
range -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
to -X- _ O
113 -X- _ O
sentences -X- _ O
. -X- _ O

QG -X- _ B-TaskName
has -X- _ O
progressed -X- _ O
rapidly -X- _ O
due -X- _ O
to -X- _ O
new -X- _ O
datasets -X- _ O
and -X- _ O
model -X- _ O
improvements -X- _ O
. -X- _ O
Many -X- _ O
different -X- _ O
QG -X- _ B-TaskName
models -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
starting -X- _ O
for -X- _ O
simple -X- _ O
vanilla -X- _ O
Sequence -X- _ O
to -X- _ O
Sequence -X- _ O
Neural -X- _ O
Networks -X- _ O
models -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
Yuan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
more -X- _ O
recent -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Chan -X- _ O
and -X- _ O
Fan -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Varanasi -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
QG -X- _ B-TaskName
systems -X- _ O
use -X- _ O
manual -X- _ O
linguistic -X- _ O
features -X- _ O
in -X- _ O
their -X- _ O
models -X- _ O
( -X- _ O
Harrison -X- _ O
and -X- _ O
Walker -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Khullar -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
Dhole -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
some -X- _ O
consider -X- _ O
how -X- _ O
to -X- _ O
select -X- _ O
question -X- _ O
- -X- _ O
worthy -X- _ O
content -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Scialom -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
systems -X- _ O
explicitly -X- _ O
model -X- _ O
question -X- _ O
types -X- _ O
( -X- _ O
Duan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Kang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
group -X- _ O
focused -X- _ O
only -X- _ O
on -X- _ O
generating -X- _ O
questions -X- _ O
that -X- _ O
start -X- _ O
with -X- _ O
specific -X- _ O
interrogative -X- _ O
words -X- _ O
( -X- _ O
what -X- _ O
, -X- _ O
how -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
QG -X- _ B-TaskName
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
solve -X- _ O
many -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
problems -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
QG -X- _ B-TaskName
in -X- _ O
conversational -X- _ O
dialogue -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
where -X- _ O
models -X- _ O
were -X- _ O
taught -X- _ O
to -X- _ O
ask -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
coherent -X- _ O
questions -X- _ O
grounded -X- _ O
in -X- _ O
a -X- _ O
QA -X- _ O
style -X- _ O
, -X- _ O
QG -X- _ B-TaskName
based -X- _ O
on -X- _ O
visual -X- _ O
input -X- _ O
( -X- _ O
Mostafazadeh -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shukla -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
QG -X- _ B-TaskName
for -X- _ O
deep -X- _ O
questions -X- _ O
such -X- _ O
as -X- _ O
mathematical -X- _ O
, -X- _ O
curiosity -X- _ O
- -X- _ O
driven -X- _ O
, -X- _ O
clinical -X- _ O
, -X- _ O
and -X- _ O
examinationtype -X- _ O
questions -X- _ O
( -X- _ O
Liyanage -X- _ O
and -X- _ O
Ranathunga -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yue -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Reading -X- _ O
is -X- _ O
integral -X- _ O
to -X- _ O
everyday -X- _ O
life -X- _ O
, -X- _ O
and -X- _ O
yet -X- _ O
learning -X- _ O
to -X- _ O
read -X- _ O
is -X- _ O
a -X- _ O
struggle -X- _ O
for -X- _ O
many -X- _ O
young -X- _ O
learners -X- _ O
. -X- _ O
During -X- _ O
lessons -X- _ O
, -X- _ O
teachers -X- _ O
can -X- _ O
use -X- _ O
comprehension -X- _ O
questions -X- _ O
to -X- _ O
increase -X- _ O
engagement -X- _ O
, -X- _ O
test -X- _ O
reading -X- _ O
skills -X- _ O
, -X- _ O
and -X- _ O
improve -X- _ O
retention -X- _ O
. -X- _ O
Historically -X- _ O
such -X- _ O
questions -X- _ O
were -X- _ O
written -X- _ O
by -X- _ O
skilled -X- _ O
teachers -X- _ O
, -X- _ O
but -X- _ O
recently -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
comprehension -X- _ O
questions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
many -X- _ O
existing -X- _ O
Question -X- _ B-TaskName
Generation -X- _ I-TaskName
( -X- _ O
QG -X- _ B-TaskName
) -X- _ O
systems -X- _ O
focus -X- _ O
on -X- _ O
generating -X- _ O
literal -X- _ O
questions -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
have -X- _ O
no -X- _ O
way -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
QG -X- _ B-TaskName
for -X- _ O
reading -X- _ O
comprehension -X- _ O
where -X- _ O
inferential -X- _ O
questions -X- _ O
are -X- _ O
critical -X- _ O
and -X- _ O
extractive -X- _ O
techniques -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
model -X- _ O
( -X- _ O
HTA -X- _ B-MethodName
- -X- _ I-MethodName
WTA -X- _ I-MethodName
) -X- _ O
that -X- _ O
takes -X- _ O
advantage -X- _ O
of -X- _ O
previous -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
generate -X- _ O
questions -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
targeted -X- _ O
comprehension -X- _ O
skill -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
reading -X- _ O
comprehension -X- _ O
dataset -X- _ O
that -X- _ O
contains -X- _ O
questions -X- _ O
annotated -X- _ O
with -X- _ O
story -X- _ O
- -X- _ O
based -X- _ O
reading -X- _ O
comprehension -X- _ O
skills -X- _ O
( -X- _ O
SBRCS -X- _ B-DatasetName
) -X- _ O
, -X- _ O
allowing -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
complete -X- _ O
reader -X- _ O
assessment -X- _ O
. -X- _ O
Across -X- _ O
several -X- _ O
experiments -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
HTA -X- _ B-MethodName
- -X- _ I-MethodName
WTA -X- _ I-MethodName
outperforms -X- _ O
multiple -X- _ O
strong -X- _ O
baselines -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
HTA -X- _ B-MethodName
- -X- _ I-MethodName
WTA -X- _ I-MethodName
model -X- _ O
tests -X- _ O
for -X- _ O
strong -X- _ O
SCRS -X- _ B-DatasetName
by -X- _ O
asking -X- _ O
deep -X- _ O
inferential -X- _ O
questions -X- _ O
. -X- _ O

BERT -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
Transformer -X- _ O
encoder -X- _ O
; -X- _ O
for -X- _ O
background -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
readers -X- _ O
to -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
or -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
excellent -X- _ O
tutorials -X- _ O
( -X- _ O
Alammar -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Klein -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
presented -X- _ O
a -X- _ O
system -X- _ O
which -X- _ O
uses -X- _ O
sophisticated -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
method -X- _ O
with -X- _ O
semantic -X- _ O
features -X- _ O
to -X- _ O
obtain -X- _ O
promising -X- _ O
results -X- _ O
on -X- _ O
ranking -X- _ O
similar -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
paper -X- _ O
shows -X- _ O
that -X- _ O
semantic -X- _ O
features -X- _ O
and -X- _ O
pairwise -X- _ O
learning -X- _ O
are -X- _ O
essential -X- _ O
components -X- _ O
to -X- _ O
the -X- _ O
system -X- _ O
by -X- _ O
ablation -X- _ O
tests -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
extend -X- _ O
our -X- _ O
neural -X- _ O
architecture -X- _ O
to -X- _ O
attention -X- _ O
based -X- _ O
models -X- _ O
which -X- _ O
have -X- _ O
shown -X- _ O
success -X- _ O
in -X- _ O
recent -X- _ O
times -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
plan -X- _ O
to -X- _ O
use -X- _ O
Triplet -X- _ O
loss -X- _ O
( -X- _ O
Hoffer -X- _ O
and -X- _ O
Ailon -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
which -X- _ O
captures -X- _ O
ranking -X- _ O
task -X- _ O
in -X- _ O
better -X- _ O
way -X- _ O
. -X- _ O
Another -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
art -X- _ O
listwise -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
methods -X- _ O
that -X- _ O
can -X- _ O
directly -X- _ O
optimize -X- _ O
MAP -X- _ B-MetricName
. -X- _ O

We -X- _ O
use -X- _ O
pairwise -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
for -X- _ O
ranking -X- _ O
task -X- _ O
which -X- _ O
poses -X- _ O
the -X- _ O
ranking -X- _ O
problem -X- _ O
as -X- _ O
classification -X- _ O
problem -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
inversions -X- _ O
in -X- _ O
ranking -X- _ O
. -X- _ O
This -X- _ O
formulation -X- _ O
is -X- _ O
more -X- _ O
closer -X- _ O
to -X- _ O
ranking -X- _ O
task -X- _ O
than -X- _ O
predicting -X- _ O
relevance -X- _ O
as -X- _ O
regression -X- _ O
and -X- _ O
also -X- _ O
has -X- _ O
theoretical -X- _ O
guarantees -X- _ O
of -X- _ O
maximizing -X- _ O
the -X- _ O
MAP -X- _ B-MetricName
in -X- _ O
ranking -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
these -X- _ O
pairs -X- _ O
by -X- _ O
taking -X- _ O
original -X- _ O
question -X- _ O
Q -X- _ O
o -X- _ O
and -X- _ O
two -X- _ O
candidate -X- _ O
questions -X- _ O
of -X- _ O
which -X- _ O
one -X- _ O
was -X- _ O
relevant -X- _ O
and -X- _ O
other -X- _ O
one -X- _ O
not -X- _ O
, -X- _ O
Q -X- _ O
c1 -X- _ O
and -X- _ O
Q -X- _ O
c2 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
generate -X- _ O
above -X- _ O
mentioned -X- _ O
feature -X- _ O
vectors -X- _ O
f -X- _ O
( -X- _ O
Q -X- _ O
o -X- _ O
, -X- _ O
Q -X- _ O
c1 -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
Q -X- _ O
o -X- _ O
, -X- _ O
Q -X- _ O
c2 -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
feature -X- _ O
dif -X- _ O
- -X- _ O
ference -X- _ O
f -X- _ O
( -X- _ O
Q -X- _ O
o -X- _ O
, -X- _ O
Q -X- _ O
c1 -X- _ O
) -X- _ O
− -X- _ O
f -X- _ O
( -X- _ O
Q -X- _ O
o -X- _ O
, -X- _ O
Q -X- _ O
c2 -X- _ O
) -X- _ O

Topic -X- _ O
modeling -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
salient -X- _ O
topics -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Latent -X- _ O
Dirichlet -X- _ O
al -X- _ O
ocation -X- _ O
( -X- _ O
LDA -X- _ O
) -X- _ O
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
topic -X- _ O
similarity -X- _ O
between -X- _ O
texts -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
LDA -X- _ O
topic -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
whole -X- _ O
text -X- _ O
( -X- _ O
body -X- _ O
and -X- _ O
subject -X- _ O
) -X- _ O
as -X- _ O
corpus -X- _ O
. -X- _ O
Then -X- _ O
a -X- _ O
topic -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
50 -X- _ O
topics -X- _ O
is -X- _ O
computed -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
cosine -X- _ O
similarity -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
in -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
rank -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
. -X- _ O
This -X- _ O
gives -X- _ O
the -X- _ O
system -X- _ O
the -X- _ O
baseline -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
ranking -X- _ O
task -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
uses -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
( -X- _ O
Trotman -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
ranking -X- _ O
of -X- _ O
questions -X- _ O
. -X- _ O
Learning -X- _ O
to -X- _ O
rank -X- _ O
refers -X- _ O
to -X- _ O
various -X- _ O
machine -X- _ O
learning -X- _ O
techniques -X- _ O
used -X- _ O
in -X- _ O
ranking -X- _ O
tasks -X- _ O
. -X- _ O
These -X- _ O
have -X- _ O
been -X- _ O
studied -X- _ O
in -X- _ O
information -X- _ O
retrieval -X- _ O
literature -X- _ O
and -X- _ O
they -X- _ O
power -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
industrial -X- _ O
search -X- _ O
engines -X- _ O
. -X- _ O
These -X- _ O
systems -X- _ O
mainly -X- _ O
fall -X- _ O
into -X- _ O
3 -X- _ O
categories -X- _ O
: -X- _ O
pointwise -X- _ O
, -X- _ O
pairwise -X- _ O
and -X- _ O
listwise -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
pairwise -X- _ O
methods -X- _ O
for -X- _ O
our -X- _ O
system -X- _ O
with -X- _ O
rich -X- _ O
feature -X- _ O
set -X- _ O
. -X- _ O
Our -X- _ O
feature -X- _ O
set -X- _ O
is -X- _ O
combination -X- _ O
of -X- _ O
various -X- _ O
hand -X- _ O
generated -X- _ O
features -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
learned -X- _ O
by -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
these -X- _ O
features -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
method -X- _ O
used -X- _ O
. -X- _ O

We -X- _ O
primarily -X- _ O
use -X- _ O
the -X- _ O
annotated -X- _ O
training -X- _ O
, -X- _ O
development -X- _ O
and -X- _ O
testing -X- _ O
dataset -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
SemEval -X- _ B-DatasetName
- -X- _ I-DatasetName
2017 -X- _ I-DatasetName
task -X- _ O
3 -X- _ O
organizers -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
collected -X- _ O
by -X- _ O
organizers -X- _ O
from -X- _ O
Qatar -X- _ O
living -X- _ O
forum -X- _ O
. -X- _ O
It -X- _ O
's -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
an -X- _ O
original -X- _ O
question -X- _ O
and -X- _ O
set -X- _ O
of -X- _ O
related -X- _ O
questions -X- _ O
. -X- _ O
Each -X- _ O
related -X- _ O
question -X- _ O
in -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
dataset -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
3 -X- _ O
possible -X- _ O
tags -X- _ O
, -X- _ O
PerfectMatch -X- _ O
, -X- _ O
Relevant -X- _ O
or -X- _ O
Irrelevant -X- _ O
. -X- _ O
A -X- _ O
ranking -X- _ O
task -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
rank -X- _ O
both -X- _ O
Per -X- _ O
- -X- _ O
fectMatch -X- _ O
and -X- _ O
Relevant -X- _ O
above -X- _ O
Irrelevant -X- _ O
questions -X- _ O
without -X- _ O
any -X- _ O
distinction -X- _ O
between -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
. -X- _ O
The -X- _ O
train -X- _ O
dataset -X- _ O
for -X- _ O
subtask -X- _ O
B -X- _ O
consists -X- _ O
of -X- _ O
317 -X- _ O
original -X- _ O
questions -X- _ O
and -X- _ O
3169 -X- _ O
retrieved -X- _ O
questions -X- _ O
by -X- _ O
search -X- _ O
engine -X- _ O
roughly -X- _ O
10 -X- _ O
related -X- _ O
questions -X- _ O
per -X- _ O
original -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
organizers -X- _ O
have -X- _ O
also -X- _ O
provided -X- _ O
annotated -X- _ O
test -X- _ O
dataset -X- _ O
from -X- _ O
SemEval -X- _ B-DatasetName
- -X- _ I-DatasetName
2016 -X- _ I-DatasetName
challenge -X- _ O
. -X- _ O
Along -X- _ O
with -X- _ O
these -X- _ O
we -X- _ O
also -X- _ O
used -X- _ O
Glove -X- _ O
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
which -X- _ O
were -X- _ O
pretrained -X- _ O
using -X- _ O
6 -X- _ O
billion -X- _ O
tokens -X- _ O
from -X- _ O
Wikipedia -X- _ O
- -X- _ O
2014 -X- _ O
and -X- _ O
Gigaword -X- _ O
dataset -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
describes -X- _ O
our -X- _ O
official -X- _ O
entry -X- _ O
LearningToQuestion -X- _ B-MethodName
for -X- _ O
SemEval -X- _ B-DatasetName
2017 -X- _ I-DatasetName
task -X- _ O
3 -X- _ O
community -X- _ O
question -X- _ O
answer -X- _ O
, -X- _ O
subtask -X- _ O
B. -X- _ O
The -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
rerank -X- _ O
questions -X- _ O
obtained -X- _ O
in -X- _ O
web -X- _ O
forum -X- _ O
as -X- _ O
per -X- _ O
their -X- _ O
similarity -X- _ O
to -X- _ O
original -X- _ O
question -X- _ O
. -X- _ O
Our -X- _ O
system -X- _ O
uses -X- _ O
pairwise -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
methods -X- _ O
on -X- _ O
rich -X- _ O
set -X- _ O
of -X- _ O
hand -X- _ O
designed -X- _ O
and -X- _ O
representation -X- _ O
learning -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
various -X- _ O
semantic -X- _ O
features -X- _ O
that -X- _ O
help -X- _ O
our -X- _ O
system -X- _ O
to -X- _ O
achieve -X- _ O
promising -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
achieved -X- _ O
second -X- _ O
highest -X- _ O
results -X- _ O
on -X- _ O
official -X- _ O
metrics -X- _ O
MAP -X- _ B-MetricName
and -X- _ O
good -X- _ O
results -X- _ O
on -X- _ O
other -X- _ O
search -X- _ O
metrics -X- _ O
. -X- _ O

In -X- _ O
online -X- _ O
forums -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
popular -X- _ O
way -X- _ O
for -X- _ O
users -X- _ O
to -X- _ O
share -X- _ O
information -X- _ O
between -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
unstructured -X- _ O
nature -X- _ O
of -X- _ O
these -X- _ O
forums -X- _ O
, -X- _ O
it -X- _ O
's -X- _ O
a -X- _ O
problem -X- _ O
to -X- _ O
find -X- _ O
relevant -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
already -X- _ O
existing -X- _ O
information -X- _ O
for -X- _ O
users -X- _ O
. -X- _ O
One -X- _ O
way -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
is -X- _ O
to -X- _ O
design -X- _ O
systems -X- _ O
to -X- _ O
automatically -X- _ O
find -X- _ O
similar -X- _ O
content -X- _ O
( -X- _ O
question -X- _ O
, -X- _ O
answer -X- _ O
, -X- _ O
comment -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
posted -X- _ O
question -X- _ O
. -X- _ O
SemEval -X- _ B-DatasetName
- -X- _ I-DatasetName
2017 -X- _ I-DatasetName
task -X- _ O
3 -X- _ O
( -X- _ O
Nakov -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
solving -X- _ O
this -X- _ O
problem -X- _ O
in -X- _ O
community -X- _ O
question -X- _ O
answer -X- _ O
by -X- _ O
various -X- _ O
subtasks -X- _ O
of -X- _ O
ranking -X- _ O
relevant -X- _ O
information -X- _ O
in -X- _ O
Qatar -X- _ O
living -X- _ O
forums -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
focuses -X- _ O
on -X- _ O
subtask -X- _ O
B -X- _ O
, -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
rank -X- _ O
given -X- _ O
set -X- _ O
of -X- _ O
questions -X- _ O
retrieved -X- _ O
by -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
in -X- _ O
their -X- _ O
similarity -X- _ O
to -X- _ O
original -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
is -X- _ O
mainly -X- _ O
designed -X- _ O
by -X- _ O
employing -X- _ O
learning -X- _ O
to -X- _ O
rank -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
rich -X- _ O
feature -X- _ O
set -X- _ O
obtained -X- _ O
by -X- _ O
text -X- _ O
processing -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
text -X- _ O
. -X- _ O

We -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
feedback -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Newsela -X- _ O
for -X- _ O
sharing -X- _ O
the -X- _ O
data -X- _ O
and -X- _ O
NVIDIA -X- _ O
for -X- _ O
providing -X- _ O
GPU -X- _ O
computing -X- _ O
resources -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
is -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
NSF -X- _ O
award -X- _ O
IIS -X- _ O
- -X- _ O
1822754 -X- _ O
, -X- _ O
ODNI -X- _ O
and -X- _ O
IARPA -X- _ O
via -X- _ O
the -X- _ O
BETTER -X- _ O
program -X- _ O
contract -X- _ O
19051600004 -X- _ O
. -X- _ O
The -X- _ O
views -X- _ O
and -X- _ O
conclusions -X- _ O
contained -X- _ O
herein -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
necessarily -X- _ O
representing -X- _ O
the -X- _ O
official -X- _ O
policies -X- _ O
, -X- _ O
either -X- _ O
expressed -X- _ O
or -X- _ O
implied -X- _ O
, -X- _ O
of -X- _ O
NSF -X- _ O
, -X- _ O
ODNI -X- _ O
, -X- _ O
IARPA -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
U.S. -X- _ O
Government -X- _ O
. -X- _ O
The -X- _ O
U.S. -X- _ O
Government -X- _ O
is -X- _ O
authorized -X- _ O
to -X- _ O
reproduce -X- _ O
and -X- _ O
distribute -X- _ O
reprints -X- _ O
for -X- _ O
governmental -X- _ O
purposes -X- _ O
notwithstanding -X- _ O
any -X- _ O
copyright -X- _ O
annotation -X- _ O
therein -X- _ O
. -X- _ O

As -X- _ O
she -X- _ O
spoke -X- _ O
, -X- _ O
the -X- _ O
building -X- _ O
echoed -X- _ O
with -X- _ O
music -X- _ O
and -X- _ O
the -X- _ O
beat -X- _ O
of -X- _ O
drums -X- _ O
. -X- _ O
Hybrid -X- _ B-MethodName
- -X- _ I-MethodName
NG -X- _ I-MethodName
echoed -X- _ O
the -X- _ O
room -X- _ O
. -X- _ O
LSTM -X- _ B-MethodName
the -X- _ O
room -X- _ O
echoed -X- _ O
with -X- _ O
the -X- _ O
sounds -X- _ O
of -X- _ O
song -X- _ O
, -X- _ O
the -X- _ O
voices -X- _ O
of -X- _ O
young -X- _ O
men -X- _ O
. -X- _ O
Transformer -X- _ B-MethodName
bert -X- _ I-MethodName
the -X- _ O
room -X- _ O
echoed -X- _ O
with -X- _ O
the -X- _ O
sound -X- _ O
of -X- _ O
song -X- _ O
, -X- _ O
the -X- _ O
beat -X- _ O
of -X- _ O
drums -X- _ O
, -X- _ O
the -X- _ O
voices -X- _ O
of -X- _ O
young -X- _ O
men -X- _ O
. -X- _ O

Validating -X- _ O
Label -X- _ O
Consistency -X- _ O
in -X- _ O
NER -X- _ B-TaskName
Data -X- _ O
Annotation -X- _ O

Sentiment -X- _ B-TaskName
Analysis -X- _ I-TaskName
( -X- _ O
ABSA -X- _ O
) -X- _ O
This -X- _ O
subtask -X- _ O
contains -X- _ O
different -X- _ O
slots -X- _ O
, -X- _ O
having -X- _ O
participated -X- _ O
in -X- _ O
three -X- _ O
of -X- _ O
them -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
slot -X- _ O
1 -X- _ O
, -X- _ O
slot -X- _ O
2 -X- _ O
and -X- _ O
slot -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
for -X- _ O
Spanish -X- _ O
and -X- _ O
English -X- _ O
language -X- _ O
is -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
both -X- _ O
slots -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
. -X- _ O
1 -X- _ O
Taken -X- _ O
from -X- _ O
the -X- _ O
lists -X- _ O
available -X- _ O
at -X- _ O
https://es.speaklanguages.com/inglés/vocabulario/comidas -X- _ O

Transformers -X- _ O
are -X- _ O
being -X- _ O
used -X- _ O
extensively -X- _ O
across -X- _ O
several -X- _ O
sequence -X- _ O
modeling -X- _ O
tasks -X- _ O
. -X- _ O
Significant -X- _ O
research -X- _ O
effort -X- _ O
has -X- _ O
been -X- _ O
devoted -X- _ O
to -X- _ O
experimentally -X- _ O
probe -X- _ O
the -X- _ O
inner -X- _ O
workings -X- _ O
of -X- _ O
Transformers -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
conceptual -X- _ O
and -X- _ O
theoretical -X- _ O
understanding -X- _ O
of -X- _ O
their -X- _ O
power -X- _ O
and -X- _ O
inherent -X- _ O
limitations -X- _ O
is -X- _ O
still -X- _ O
nascent -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
roles -X- _ O
of -X- _ O
various -X- _ O
components -X- _ O
in -X- _ O
Transformers -X- _ O
such -X- _ O
as -X- _ O
positional -X- _ O
encodings -X- _ O
, -X- _ O
attention -X- _ O
heads -X- _ O
, -X- _ O
residual -X- _ O
connections -X- _ O
, -X- _ O
and -X- _ O
feedforward -X- _ O
networks -X- _ O
, -X- _ O
are -X- _ O
not -X- _ O
clear -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
step -X- _ O
towards -X- _ O
answering -X- _ O
these -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
computational -X- _ O
power -X- _ O
as -X- _ O
captured -X- _ O
by -X- _ O
Turing -X- _ O
- -X- _ O
completeness -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
provide -X- _ O
an -X- _ O
alternate -X- _ O
and -X- _ O
simpler -X- _ O
proof -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
vanilla -X- _ O
Transformers -X- _ O
are -X- _ O
Turing -X- _ O
- -X- _ O
complete -X- _ O
and -X- _ O
then -X- _ O
we -X- _ O
prove -X- _ O
that -X- _ O
Transformers -X- _ O
with -X- _ O
only -X- _ O
positional -X- _ O
masking -X- _ O
and -X- _ O
without -X- _ O
any -X- _ O
positional -X- _ O
encoding -X- _ O
are -X- _ O
also -X- _ O
Turing -X- _ O
- -X- _ O
complete -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
for -X- _ O
the -X- _ O
Turing -X- _ O
- -X- _ O
completeness -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
; -X- _ O
interestingly -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
a -X- _ O
particular -X- _ O
type -X- _ O
of -X- _ O
residual -X- _ O
connection -X- _ O
is -X- _ O
necessary -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
practical -X- _ O
implications -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
via -X- _ O
experiments -X- _ O
on -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
and -X- _ O
synthetic -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
task -X- _ B-MethodName
- -X- _ I-MethodName
oriented -X- _ I-MethodName
dialogue -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
TOD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
) -X- _ O
trained -X- _ O
on -X- _ O
nine -X- _ O
human -X- _ O
- -X- _ O
human -X- _ O
and -X- _ O
multiturn -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
datasets -X- _ O
across -X- _ O
over -X- _ O
60 -X- _ O
domains -X- _ O
. -X- _ O
TOD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
outperforms -X- _ O
BERT -X- _ O
on -X- _ O
four -X- _ O
dialogue -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
intention -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
dialogue -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
, -X- _ O
dialogue -X- _ B-TaskName
act -X- _ I-TaskName
prediction -X- _ I-TaskName
, -X- _ O
and -X- _ O
response -X- _ B-TaskName
selection -X- _ I-TaskName
. -X- _ O
It -X- _ O
also -X- _ O
has -X- _ O
a -X- _ O
clear -X- _ O
advantage -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
experiments -X- _ O
when -X- _ O
only -X- _ O
limited -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O
TOD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
is -X- _ O
easy -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
deploy -X- _ O
and -X- _ O
will -X- _ O
be -X- _ O
open -X- _ O
- -X- _ O
sourced -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
NLP -X- _ O
research -X- _ O
community -X- _ O
to -X- _ O
apply -X- _ O
or -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
any -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
conversational -X- _ O
problem -X- _ O
. -X- _ O

This -X- _ O
submission -X- _ O
uses -X- _ O
a -X- _ O
jumble -X- _ O
of -X- _ O
features -X- _ O
and -X- _ O
classifiers -X- _ O
, -X- _ O
most -X- _ O
from -X- _ O
the -X- _ O
sklearn -X- _ O
module -X- _ O
( -X- _ O
Buitinck -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
classifier -X- _ O
is -X- _ O
a -X- _ O
hard -X- _ O
voting -X- _ O
classifier -X- _ O
with -X- _ O
three -X- _ O
input -X- _ O
streams -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
Soft -X- _ O
voting -X- _ O
classifier -X- _ O
on -X- _ O
: -X- _ O
on -X- _ O
language -X- _ O
- -X- _ O
model -X- _ O
- -X- _ O
scores -X- _ O
for -X- _ O
character -X- _ O
and -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
corpus -X- _ O
- -X- _ O
6 -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
character -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
the -X- _ O
corpus -X- _ O
- -X- _ O
26 -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
Support -X- _ O
vector -X- _ O
machine -X- _ O
, -X- _ O
svm -X- _ O
. -X- _ O
SVC -X- _ O
( -X- _ O
gamma='scale -X- _ O
' -X- _ O
, -X- _ O
kernel -X- _ O
= -X- _ O
' -X- _ O
poly -X- _ O
' -X- _ O
, -X- _ O
degree -X- _ O
= -X- _ O
2 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
features -X- _ O
as -X- _ O
item -X- _ O
1e -X- _ O
. -X- _ O

Pretrained -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ O
have -X- _ O
achieved -X- _ O
good -X- _ O
results -X- _ O
on -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
impractical -X- _ O
on -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
devices -X- _ O
due -X- _ O
to -X- _ O
memory -X- _ O
footprint -X- _ O
. -X- _ O
A -X- _ O
large -X- _ O
fraction -X- _ O
of -X- _ O
this -X- _ O
footprint -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
embeddings -X- _ O
with -X- _ O
large -X- _ O
input -X- _ O
vocabulary -X- _ O
and -X- _ O
embedding -X- _ O
dimensions -X- _ O
. -X- _ O
Existing -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
methods -X- _ O
used -X- _ O
for -X- _ O
model -X- _ O
compression -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
directly -X- _ O
applied -X- _ O
to -X- _ O
train -X- _ O
student -X- _ O
models -X- _ O
with -X- _ O
reduced -X- _ O
vocabulary -X- _ O
sizes -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
distillation -X- _ O
method -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
embeddings -X- _ O
via -X- _ O
mixed -X- _ O
- -X- _ O
vocabulary -X- _ O
training -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
compresses -X- _ O
BERT -X- _ O
LARGE -X- _ O
to -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
model -X- _ O
with -X- _ O
smaller -X- _ O
vocabulary -X- _ O
and -X- _ O
hidden -X- _ O
dimensions -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
smaller -X- _ O
than -X- _ O
other -X- _ O
distilled -X- _ O
BERT -X- _ O
models -X- _ O
and -X- _ O
offers -X- _ O
a -X- _ O
better -X- _ O
size -X- _ O
- -X- _ O
accuracy -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
on -X- _ O
language -X- _ O
understanding -X- _ O
benchmarks -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
practical -X- _ O
dialogue -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Tab -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
CNNDM -X- _ B-DatasetName
and -X- _ O
NYT -X- _ B-DatasetName
we -X- _ O
use -X- _ O
BART -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
while -X- _ O
for -X- _ O
XSum -X- _ B-DatasetName
we -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
PEGASUS -X- _ O
model -X- _ O
as -X- _ O
our -X- _ O
base -X- _ O
model -X- _ O
since -X- _ O
it -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
BART -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Ctr -X- _ I-MethodName
outperforms -X- _ O
SimCLS -X- _ B-MethodName
, -X- _ O
its -X- _ O
counterpart -X- _ O
as -X- _ O
an -X- _ O
evaluation -X- _ O
model -X- _ O
in -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
summarization -X- _ O
framework -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
both -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Ctr -X- _ I-MethodName
and -X- _ O
SimCLS -X- _ B-MethodName
are -X- _ O
used -X- _ O
to -X- _ O
score -X- _ O
the -X- _ O
candidate -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
a -X- _ O
Seq2Seq -X- _ O
abstractive -X- _ O
model -X- _ O
( -X- _ O
BART -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
outputs -X- _ O
are -X- _ O
selected -X- _ O
based -X- _ O
on -X- _ O
those -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
attribute -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Ctr -X- _ I-MethodName
's -X- _ O
superior -X- _ O
performance -X- _ O
to -X- _ O
its -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
architecture -X- _ O
( -X- _ O
BART -X- _ O
) -X- _ O
for -X- _ O
both -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
scoring -X- _ O
, -X- _ O
while -X- _ O
SimCLS -X- _ B-MethodName
uses -X- _ O
RoBERTa -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Ctr -X- _ I-MethodName
maximizes -X- _ O
the -X- _ O
parameter -X- _ O
sharing -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
stages -X- _ O
, -X- _ O
and -X- _ O
preserves -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
Seq2Seq -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Mul -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
establish -X- _ O
the -X- _ O
new -X- _ O
stare -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
. -X- _ O
Notably -X- _ O
, -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
, -X- _ O
GSum -X- _ B-MethodName
, -X- _ O
takes -X- _ O
additional -X- _ O
guidance -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
needs -X- _ O
a -X- _ O
separate -X- _ O
encoder -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
guidance -X- _ O
information -X- _ O
, -X- _ O
while -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Mul -X- _ I-MethodName
uses -X- _ O
the -X- _ O
same -X- _ O
parameterization -X- _ O
of -X- _ O
BART -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
other -X- _ O
methods -X- _ O
( -X- _ O
ConSum -X- _ B-MethodName
, -X- _ O
SeqCo -X- _ B-MethodName
, -X- _ O
GOLD -X- _ B-MethodName
) -X- _ O
that -X- _ O
aim -X- _ O
to -X- _ O
improve -X- _ O
upon -X- _ O
BART -X- _ O
, -X- _ O
BRIO -X- _ B-MethodName
- -X- _ I-MethodName
Mul -X- _ I-MethodName
performs -X- _ O
much -X- _ O
better -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
training -X- _ O
method -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Since -X- _ O
on -X- _ O
XSum -X- _ B-DatasetName
we -X- _ O
use -X- _ O
PEGASUS -X- _ O
instead -X- _ O
of -X- _ O
BART -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
restricted -X- _ O
to -X- _ O
the -X- _ O
specific -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
. -X- _ O

Abstractive -X- _ O
summarization -X- _ O
models -X- _ O
are -X- _ O
commonly -X- _ O
trained -X- _ O
using -X- _ O
maximum -X- _ O
likelihood -X- _ O
estimation -X- _ O
, -X- _ O
which -X- _ O
assumes -X- _ O
a -X- _ O
deterministic -X- _ O
( -X- _ O
onepoint -X- _ O
) -X- _ O
target -X- _ O
distribution -X- _ O
in -X- _ O
which -X- _ O
an -X- _ O
ideal -X- _ O
model -X- _ O
will -X- _ O
assign -X- _ O
all -X- _ O
the -X- _ O
probability -X- _ O
mass -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
. -X- _ O
This -X- _ O
assumption -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
compare -X- _ O
several -X- _ O
system -X- _ O
- -X- _ O
generated -X- _ O
( -X- _ O
candidate -X- _ O
) -X- _ O
summaries -X- _ O
that -X- _ O
have -X- _ O
deviated -X- _ O
from -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
training -X- _ O
paradigm -X- _ O
which -X- _ O
assumes -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
deterministic -X- _ O
distribution -X- _ O
so -X- _ O
that -X- _ O
different -X- _ O
candidate -X- _ O
summaries -X- _ O
are -X- _ O
assigned -X- _ O
probability -X- _ O
mass -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
quality -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
achieves -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
( -X- _ O
47.78 -X- _ B-MetricValue
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
1 -X- _ I-MetricName
) -X- _ O
and -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
49.07 -X- _ B-MetricValue
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
1 -X- _ I-MetricName
) -X- _ O
datasets -X- _ O
. -X- _ O
Further -X- _ O
analysis -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
estimate -X- _ O
probabilities -X- _ O
of -X- _ O
candidate -X- _ O
summaries -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
correlated -X- _ O
with -X- _ O
their -X- _ O
level -X- _ O
of -X- _ O
quality -X- _ O
. -X- _ O
1 -X- _ O

For -X- _ O
embedding -X- _ O
and -X- _ O
annotation -X- _ O
projections -X- _ O
, -X- _ O
a -X- _ B-MethodName
bidirectional -X- _ I-MethodName
LSTM -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
NER -X- _ I-MethodName
tagger -X- _ I-MethodName
using -X- _ O
a -X- _ O
CRF -X- _ O
decoder -X- _ O
is -X- _ O
adapted -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
NER -X- _ B-TaskName
models -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O

We -X- _ O
further -X- _ O
study -X- _ O
the -X- _ O
domains -X- _ O
that -X- _ O
are -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
methods -X- _ O
above -X- _ O
by -X- _ O
creating -X- _ O
confusion -X- _ O
matrices -X- _ O
between -X- _ O
the -X- _ O
domain -X- _ O
predictions -X- _ O
of -X- _ O
three -X- _ O
setups -X- _ O
: -X- _ O
domain -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
domain -X- _ B-TaskName
prediction -X- _ I-TaskName
in -X- _ O
the -X- _ O
proposed -X- _ O
MultDomain -X- _ B-MethodName
- -X- _ I-MethodName
SP -X- _ I-MethodName
- -X- _ I-MethodName
Aux -X- _ I-MethodName
model -X- _ I-MethodName
and -X- _ O
the -X- _ O
oracle -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
choice -X- _ O
on -X- _ O
gold -X- _ O
data -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
Oracle -X- _ B-MethodName
model -X- _ I-MethodName
relies -X- _ O
on -X- _ O
the -X- _ O
corresponding -X- _ O
InDomain -X- _ O
model -X- _ O
to -X- _ O
only -X- _ O
a -X- _ O
limited -X- _ O
extent -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
uniformly -X- _ O
many -X- _ O
cases -X- _ O
, -X- _ O
predictions -X- _ O
from -X- _ O
other -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
models -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
one -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
variability -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
. -X- _ O
The -X- _ O
domain -X- _ O
classifier -X- _ O
predictions -X- _ O
align -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
actual -X- _ O
domains -X- _ O
. -X- _ O
The -X- _ O
MultDomain -X- _ B-MethodName
- -X- _ I-MethodName
SP -X- _ I-MethodName
- -X- _ I-MethodName
Aux -X- _ I-MethodName
model -X- _ I-MethodName
also -X- _ O
tends -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
domain -X- _ O
correctly -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
it -X- _ O
better -X- _ O
learns -X- _ O
the -X- _ O
NW -X- _ O
, -X- _ O
WB -X- _ O
and -X- _ O
BN -X- _ O
domains -X- _ O
. -X- _ O
Note -X- _ O
noting -X- _ O
that -X- _ O
the -X- _ O
MultDomain -X- _ B-MethodName
- -X- _ I-MethodName
SP -X- _ I-MethodName
- -X- _ I-MethodName
Aux -X- _ I-MethodName
model -X- _ I-MethodName
does -X- _ O
not -X- _ O
use -X- _ O
these -X- _ O
domain -X- _ O
predictions -X- _ O
in -X- _ O
inference -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
uses -X- _ O
the -X- _ O
shared -X- _ O
components -X- _ O
for -X- _ O
unknown -X- _ O
domains -X- _ O
or -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
data -X- _ O
sets -X- _ O
spanning -X- _ O
eight -X- _ O
genres -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
methods -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
feasibility -X- _ O
of -X- _ O
NER -X- _ B-TaskName
tagging -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
domain -X- _ O
setup -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
additional -X- _ O
data -X- _ O
covering -X- _ O
four -X- _ O
other -X- _ O
genres -X- _ O
. -X- _ O
Each -X- _ O
genre -X- _ O
of -X- _ O
documents -X- _ O
is -X- _ O
considered -X- _ O
a -X- _ O
domain -X- _ O
in -X- _ O
modelling -X- _ O
. -X- _ O

The -X- _ O
basic -X- _ O
component -X- _ O
of -X- _ O
our -X- _ O
NER -X- _ B-TaskName
models -X- _ O
is -X- _ O
an -X- _ O
architecture -X- _ O
which -X- _ O
has -X- _ O
reached -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
several -X- _ O
times -X- _ O
over -X- _ O
the -X- _ O
last -X- _ O
few -X- _ O
years -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
task -X- _ O
is -X- _ O
a -X- _ O
structured -X- _ O
prediction -X- _ O
task -X- _ O
and -X- _ O
earlier -X- _ O
statistical -X- _ O
approaches -X- _ O
are -X- _ O
based -X- _ O
models -X- _ O
like -X- _ O
Conditional -X- _ O
Random -X- _ O
Fields -X- _ O
( -X- _ O
Lafferty -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2001 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
rely -X- _ O
on -X- _ O
features -X- _ O
often -X- _ O
designed -X- _ O
based -X- _ O
on -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
( -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
current -X- _ O
dominant -X- _ O
approach -X- _ O
to -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
consists -X- _ O
of -X- _ O
neural -X- _ O
architectures -X- _ O
based -X- _ O
on -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
with -X- _ O
different -X- _ O
choices -X- _ O
of -X- _ O
input -X- _ O
representations -X- _ O
Ma -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018Akbik -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
, -X- _ O
2019 -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
pretrained -X- _ O
word -X- _ O
embeddings -X- _ O
and -X- _ O
character -X- _ O
embeddings -X- _ O
. -X- _ O
Character -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
an -X- _ O
LSTM -X- _ O
from -X- _ O
randomly -X- _ O
initialized -X- _ O
vectors -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Word -X- _ O
embeddings -X- _ O
are -X- _ O
derived -X- _ O
from -X- _ O
a -X- _ O
combination -X- _ O
GloVe -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
FastText -X- _ O
( -X- _ O
Bojanowski -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
as -X- _ O
used -X- _ O
in -X- _ O
( -X- _ O
Ma -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
choice -X- _ O
of -X- _ O
embeddings -X- _ O
is -X- _ O
orthogonal -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
and -X- _ O
thus -X- _ O
, -X- _ O
we -X- _ O
hold -X- _ O
these -X- _ O
constant -X- _ O
in -X- _ O
all -X- _ O
experiments -X- _ O
. -X- _ O
This -X- _ O
representation -X- _ O
is -X- _ O
passed -X- _ O
through -X- _ O
two -X- _ O
LSTM -X- _ O
layers -X- _ O
that -X- _ O
process -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
in -X- _ O
differ -X- _ O
- -X- _ O
. -X- _ O
The -X- _ O
outputs -X- _ O
of -X- _ O
these -X- _ O
layers -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
word -X- _ O
representation -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
LSTM -X- _ O
module -X- _ O
into -X- _ O
the -X- _ O
label -X- _ O
distribution -X- _ O
, -X- _ O
passed -X- _ O
to -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
layer -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
. -X- _ O
A -X- _ O
Conditional -X- _ O
Random -X- _ O
Field -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
predictions -X- _ O
to -X- _ O
jointly -X- _ O
assign -X- _ O
the -X- _ O
sequence -X- _ O
tags -X- _ O
using -X- _ O
a -X- _ O
transition -X- _ O
matrix -X- _ O
. -X- _ O
This -X- _ O
CRF -X- _ O
layer -X- _ O
improves -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
as -X- _ O
it -X- _ O
ensures -X- _ O
the -X- _ O
output -X- _ O
sequence -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
tags -X- _ O
and -X- _ O
also -X- _ O
models -X- _ O
the -X- _ O
constraints -X- _ O
the -X- _ O
output -X- _ O
sequence -X- _ O
adheres -X- _ O
to -X- _ O
( -X- _ O
e.g. -X- _ O
I -X- _ O
- -X- _ O
PER -X- _ O
can -X- _ O
not -X- _ O
follow -X- _ O
B -X- _ O
- -X- _ O
LOC -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
section -X- _ O
describes -X- _ O
the -X- _ O
proposed -X- _ O
NER -X- _ B-TaskName
architecture -X- _ O
tailored -X- _ O
the -X- _ O
architecture -X- _ O
to -X- _ O
our -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
experimental -X- _ O
setups -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
independent -X- _ O
of -X- _ O
input -X- _ O
embedding -X- _ O
representation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
to -X- _ O
construct -X- _ O
sentiment -X- _ O
lexicons -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
sentiment -X- _ O
- -X- _ O
aware -X- _ O
word -X- _ O
representation -X- _ O
learning -X- _ O
approach -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
traditional -X- _ O
methods -X- _ O
normally -X- _ O
learned -X- _ O
based -X- _ O
on -X- _ O
only -X- _ O
the -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
sentiment -X- _ O
supervision -X- _ O
. -X- _ O
We -X- _ O
proposed -X- _ O
word -X- _ B-TaskName
representation -X- _ I-TaskName
learning -X- _ I-TaskName
via -X- _ O
hierarchical -X- _ B-MethodName
sentiment -X- _ I-MethodName
supervision -X- _ I-MethodName
, -X- _ O
i.e. -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
supervi -X- _ O
- -X- _ O
sion -X- _ O
at -X- _ O
both -X- _ O
word -X- _ O
and -X- _ O
document -X- _ O
levels -X- _ O
. -X- _ O
The -X- _ O
wordlevel -X- _ O
supervision -X- _ O
can -X- _ O
be -X- _ O
provided -X- _ O
based -X- _ O
on -X- _ O
either -X- _ O
predefined -X- _ O
sentiment -X- _ O
lexicons -X- _ O
or -X- _ O
the -X- _ O
learned -X- _ O
PMI -X- _ O
- -X- _ O
SO -X- _ O
based -X- _ O
sentiment -X- _ O
annotation -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O
A -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
experiments -X- _ O
were -X- _ O
conducted -X- _ O
on -X- _ O
several -X- _ O
benchmark -X- _ O
sentiment -X- _ O
classification -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
quite -X- _ O
effective -X- _ O
for -X- _ O
sentiment -X- _ O
- -X- _ O
aware -X- _ O
word -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
sentiment -X- _ O
lexicon -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
approach -X- _ O
beats -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sentiment -X- _ O
lexicon -X- _ O
construction -X- _ O
approaches -X- _ O
. -X- _ O

Multi -X- _ B-TaskName
- -X- _ I-TaskName
Domain -X- _ I-TaskName
Named -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
with -X- _ O
Genre -X- _ O
- -X- _ O
Aware -X- _ O
and -X- _ O
Agnostic -X- _ O
Inference -X- _ O

Table -X- _ O
4 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
ELI5 -X- _ B-DatasetName
test -X- _ O
set -X- _ O
. -X- _ O
11 -X- _ O
All -X- _ O
models -X- _ O
outperform -X- _ O
the -X- _ O
majority -X- _ O
and -X- _ O
summarylead -X- _ O
baselines -X- _ O
. -X- _ O
The -X- _ O
sequential -X- _ O
prediction -X- _ O
model -X- _ O
( -X- _ O
T5 -X- _ B-MethodName
) -X- _ O
significantly -X- _ O
outperform -X- _ O
classification -X- _ O
model -X- _ O
( -X- _ O
RoBERTa -X- _ B-MethodName
) -X- _ O
which -X- _ O
makes -X- _ O
a -X- _ O
prediction -X- _ O
per -X- _ O
sentence -X- _ O
. -X- _ O
The -X- _ O
roles -X- _ O
with -X- _ O
lower -X- _ O
human -X- _ O
agreement -X- _ O
( -X- _ O
auxiliary -X- _ O
, -X- _ O
organizational -X- _ O
sentence -X- _ O
, -X- _ O
answer -X- _ O
) -X- _ O
also -X- _ O
exhibit -X- _ O
low -X- _ O
model -X- _ O
performances -X- _ O
, -X- _ O
reflecting -X- _ O
the -X- _ O
subjectivity -X- _ O
and -X- _ O
ambiguity -X- _ O
of -X- _ O
roles -X- _ O
for -X- _ O
some -X- _ O
sentences -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
moderate -X- _ O
amount -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
( -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
) -X- _ O
can -X- _ O
reliably -X- _ O
classify -X- _ O
functional -X- _ O
roles -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
long -X- _ O
- -X- _ O
form -X- _ O
answers -X- _ O
, -X- _ O
showing -X- _ O
comparable -X- _ O
performances -X- _ O
to -X- _ O
human -X- _ O
lower -X- _ O
bound -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
out -X- _ O
- -X- _ O
ofdomain -X- _ O
datasets -X- _ O
, -X- _ O
WebGPT -X- _ B-DatasetName
, -X- _ O
NQ -X- _ B-DatasetName
and -X- _ O
ELI5 -X- _ B-DatasetName
- -X- _ O
model -X- _ O
( -X- _ O
model -X- _ O
- -X- _ O
generated -X- _ O
answers -X- _ O
) -X- _ O
. -X- _ O
Human -X- _ B-MetricName
agreement -X- _ I-MetricName
numbers -X- _ I-MetricName
are -X- _ O
comparable -X- _ O
across -X- _ O
all -X- _ O
datasets -X- _ O
( -X- _ O
0.53 -X- _ B-MetricValue
- -X- _ I-MetricValue
0.59 -X- _ I-MetricValue
for -X- _ O
lower -X- _ O
bound -X- _ O
, -X- _ O
0.73 -X- _ B-MetricValue
- -X- _ I-MetricValue
0.78 -X- _ I-MetricValue
for -X- _ O
upper -X- _ O
bound -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
still -X- _ O
exhibits -X- _ O
the -X- _ O
best -X- _ O
overall -X- _ O
performance -X- _ O
, -X- _ O
all -X- _ O
learned -X- _ O
models -X- _ O
perform -X- _ O
worse -X- _ O
, -X- _ O
partially -X- _ O
as -X- _ O
the -X- _ O
role -X- _ O
distribution -X- _ O
has -X- _ O
changed -X- _ O
. -X- _ O
Despite -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
ELI5 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
role -X- _ O
classification -X- _ O
model -X- _ O
also -X- _ O
perform -X- _ O
worse -X- _ O
on -X- _ O
model -X- _ O
- -X- _ O
generated -X- _ O
answers -X- _ O
( -X- _ O
ELI5model -X- _ B-MethodName
) -X- _ O
, -X- _ O
echoing -X- _ O
our -X- _ O
observation -X- _ O
that -X- _ O
human -X- _ O
annotators -X- _ O
find -X- _ O
it -X- _ O
challenging -X- _ O
to -X- _ O
process -X- _ O
the -X- _ O
discourse -X- _ O
structure -X- _ O
of -X- _ O
model -X- _ O
- -X- _ O
generated -X- _ O
answers -X- _ O
. -X- _ O
Our -X- _ O
pilot -X- _ O
showed -X- _ O
that -X- _ O
training -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
improved -X- _ O
the -X- _ O
performances -X- _ O
consistently -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
evaluation -X- _ O
is -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
( -X- _ O
after -X- _ O
setting -X- _ O
apart -X- _ O
some -X- _ O
for -X- _ O
training -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
report -X- _ O
it -X- _ O
here -X- _ O
. -X- _ O
We -X- _ O
anticipate -X- _ O
that -X- _ O
automatic -X- _ O
role -X- _ O
classification -X- _ O
is -X- _ O
feasible -X- _ O
given -X- _ O
moderate -X- _ O
amount -X- _ O
of -X- _ O
annotation -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
humanwritten -X- _ O
long -X- _ O
- -X- _ O
form -X- _ O
answer -X- _ O
datasets -X- _ O
we -X- _ O
study -X- _ O
. -X- _ O

Question -X- _ B-TaskName
Generation -X- _ I-TaskName
for -X- _ I-TaskName
Reading -X- _ I-TaskName
Comprehension -X- _ I-TaskName
Assessment -X- _ O
by -X- _ O
Modeling -X- _ O
How -X- _ O
and -X- _ O
What -X- _ O
to -X- _ O
Ask -X- _ O

To -X- _ O
understand -X- _ O
the -X- _ O
errors -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
classified -X- _ O
200 -X- _ O
simplifications -X- _ O
from -X- _ O
the -X- _ O
NEWSELA -X- _ B-DatasetName
- -X- _ I-DatasetName
AUTO -X- _ I-DatasetName
test -X- _ O
set -X- _ O
into -X- _ O
the -X- _ O
following -X- _ O
categories -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
Good -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
generated -X- _ O
meaningful -X- _ O
simplifications -X- _ O
, -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Hallucinations -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
introduced -X- _ O
information -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
Fluency -X- _ O
Errors -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
generated -X- _ O
ungrammatical -X- _ O
output -X- _ O
, -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
Anaphora -X- _ O
Resolution -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
was -X- _ O
difficult -X- _ O
to -X- _ O
resolve -X- _ O
pronouns -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
Bad -X- _ O
substitution -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
inserted -X- _ O
an -X- _ O
incorrect -X- _ O
simpler -X- _ O
phrase -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
Human -X- _ O
Reference -X- _ O
Errors -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
reference -X- _ O
does -X- _ O
not -X- _ O
reflect -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
a -X- _ O
simplification -X- _ O
can -X- _ O
belong -X- _ O
to -X- _ O
multiple -X- _ O
error -X- _ O
categories -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
examples -X- _ O
of -X- _ O
each -X- _ O
category -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
I -X- _ O
present -X- _ O
my -X- _ O
result -X- _ O
on -X- _ O
Offensive -X- _ B-TaskName
Language -X- _ I-TaskName
Identification -X- _ I-TaskName
in -X- _ O
Dravidian -X- _ O
Languages -X- _ O
- -X- _ O
EACL -X- _ O
2021 -X- _ O
which -X- _ O
includes -X- _ O
three -X- _ O
tasks -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
I -X- _ O
regard -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
multiple -X- _ O
classification -X- _ O
task -X- _ O
, -X- _ O
I -X- _ O
use -X- _ O
the -X- _ O
BiGRU -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
based -X- _ O
on -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
model -X- _ O
to -X- _ O
complete -X- _ O
, -X- _ O
and -X- _ O
my -X- _ O
model -X- _ O
works -X- _ O
very -X- _ O
well -X- _ O
. -X- _ O
I -X- _ O
also -X- _ O
summarized -X- _ O
the -X- _ O
possible -X- _ O
reasons -X- _ O
for -X- _ O
classifying -X- _ O
only -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
I -X- _ O
also -X- _ O
use -X- _ O
some -X- _ O
other -X- _ O
neural -X- _ O
networks -X- _ O
for -X- _ O
comparative -X- _ O
experiments -X- _ O
to -X- _ O
prove -X- _ O
that -X- _ O
my -X- _ O
model -X- _ O
can -X- _ O
obtain -X- _ O
excellent -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
my -X- _ O
model -X- _ O
ranks -X- _ O
5th -X- _ O
in -X- _ O
the -X- _ O
Malayalam -X- _ O
task -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
continuous -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
offensive -X- _ O
information -X- _ O
on -X- _ O
the -X- _ O
Internet -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
accurately -X- _ O
describe -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
this -X- _ O
information -X- _ O
only -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
data -X- _ O
mining -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
impossible -X- _ O
to -X- _ O
model -X- _ O
this -X- _ O
information -X- _ O
effectively -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
I -X- _ O
will -X- _ O
use -X- _ O
methods -X- _ O
based -X- _ O
on -X- _ O
multidisciplinary -X- _ O
discovery -X- _ O
to -X- _ O
guide -X- _ O
model -X- _ O
learning -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
use -X- _ O
limited -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
more -X- _ O
effective -X- _ O
models -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
I -X- _ O
will -X- _ O
also -X- _ O
consider -X- _ O
whether -X- _ O
I -X- _ O
can -X- _ O
use -X- _ O
other -X- _ O
transfer -X- _ O
learning -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
BiGRU -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
Cover -X- _ O
and -X- _ O
Hart -X- _ O
, -X- _ O
1967 -X- _ O
) -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
three -X- _ O
parts -X- _ O
: -X- _ O
text -X- _ O
vector -X- _ O
input -X- _ O
layer -X- _ O
, -X- _ O
hidden -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
output -X- _ O
layer -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
the -X- _ O
hidden -X- _ O
layer -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
layers -X- _ O
: -X- _ O
the -X- _ O
BiGRU -X- _ O
layer -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Dense -X- _ O
layer -X- _ O
( -X- _ O
fully -X- _ O
connected -X- _ O
layer -X- _ O
) -X- _ O
. -X- _ O
I -X- _ O
set -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
After -X- _ O
receiving -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
it -X- _ O
uses -X- _ O
the -X- _ O
BiGRU -X- _ O
neural -X- _ O
network -X- _ O
layer -X- _ O
to -X- _ O
extract -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
deep -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
firstly -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
it -X- _ O
uses -X- _ O
the -X- _ O
attention -X- _ O
layer -X- _ O
to -X- _ O
assign -X- _ O
corresponding -X- _ O
weights -X- _ O
to -X- _ O
the -X- _ O
deep -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
extracted -X- _ O
text -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
text -X- _ O
feature -X- _ O
information -X- _ O
with -X- _ O
different -X- _ O
weights -X- _ O
is -X- _ O
put -X- _ O
into -X- _ O
the -X- _ O
softmax -X- _ O
function -X- _ O
layer -X- _ O
for -X- _ O
classification -X- _ O
. -X- _ O
The -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
BiGRU -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
model -X- _ I-MethodName
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

An -X- _ O
overall -X- _ O
framework -X- _ O
and -X- _ O
processing -X- _ O
pipeline -X- _ O
of -X- _ O
my -X- _ O
solution -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
In -X- _ O
my -X- _ O
job -X- _ O
, -X- _ O
I -X- _ O
use -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
model -X- _ O
as -X- _ O
my -X- _ O
base -X- _ O
model -X- _ O
and -X- _ O
take -X- _ O
BiGRU -X- _ O
- -X- _ O
Attention -X- _ O
behind -X- _ O
it -X- _ O
. -X- _ O
My -X- _ O
model -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

