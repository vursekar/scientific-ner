-DOCSTART- -X- O
We -X- _ O
trained -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
model -X- _ O
for -X- _ O
complaint -X- _ O
detection -X- _ O
using -X- _ O
each -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
features -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
4.1 -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
summarizes -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
macro -X- _ B-MetricName
averaged -X- _ I-MetricName
F1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
. -X- _ O
The -X- _ O
best -X- _ O
performing -X- _ O
model -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
unigrams -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
75.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
There -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
significant -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
sentiment -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
interesting -X- _ O
to -X- _ O
observe -X- _ O
that -X- _ O
simple -X- _ O
features -X- _ O
like -X- _ O
the -X- _ O
counts -X- _ O
of -X- _ O
different -X- _ O
pronoun -X- _ O
types -X- _ O
and -X- _ O
counts -X- _ O
of -X- _ O
intensifiers -X- _ O
have -X- _ O
strong -X- _ O
predictive -X- _ O
ability -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
features -X- _ O
studied -X- _ O
here -X- _ O
have -X- _ O
some -X- _ O
ability -X- _ O
to -X- _ O
predict -X- _ O
complaints -X- _ O
. -X- _ O

The -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
drawn -X- _ O
from -X- _ O
news -X- _ O
headlines -X- _ O
and -X- _ O
other -X- _ O
sources -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
5 -X- _ O
denoting -X- _ O
how -X- _ O
similar -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
semantic -X- _ O
meaning -X- _ O
. -X- _ O
MRPC -X- _ B-DatasetName
Microsoft -X- _ I-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
automatically -X- _ O
extracted -X- _ O
from -X- _ O
online -X- _ O
news -X- _ O
sources -X- _ O
, -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
for -X- _ O
whether -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
RTE -X- _ B-DatasetName
Recognizing -X- _ I-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
entailment -X- _ O
task -X- _ O
similar -X- _ O
to -X- _ O
MNLI -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
much -X- _ O
less -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
14 -X- _ O
WNLI -X- _ B-DatasetName
Winograd -X- _ I-DatasetName
NLI -X- _ I-DatasetName
is -X- _ O
a -X- _ O
small -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
dataset -X- _ O
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
GLUE -X- _ O
webpage -X- _ O
notes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
15 -X- _ O
and -X- _ O
every -X- _ O
trained -X- _ O
system -X- _ O
that -X- _ O
's -X- _ O
been -X- _ O
submitted -X- _ O
to -X- _ O
GLUE -X- _ O
has -X- _ O
performed -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
65.1 -X- _ B-MetricValue
baseline -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
predicting -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
exclude -X- _ O
this -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
fair -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O
For -X- _ O
our -X- _ O
GLUE -X- _ O
submission -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
predicted -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
. -X- _ O

The -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
task -X- _ O
extends -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
problem -X- _ O
definition -X- _ O
by -X- _ O
allowing -X- _ O
for -X- _ O
the -X- _ O
possibility -X- _ O
that -X- _ O
no -X- _ O
short -X- _ O
answer -X- _ O
exists -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
paragraph -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
problem -X- _ O
more -X- _ O
realistic -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
approach -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
SQuAD -X- _ B-MethodName
v1.1 -X- _ I-MethodName
BERT -X- _ I-MethodName
model -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
treat -X- _ O
questions -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
answer -X- _ O
as -X- _ O
having -X- _ O
an -X- _ O
answer -X- _ O
span -X- _ O
with -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
at -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
probability -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
answer -X- _ O
span -X- _ O
positions -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
no -X- _ O
- -X- _ O
answer -X- _ O
span -X- _ O
: -X- _ O
s -X- _ O
null -X- _ O
= -X- _ O
S -X- _ O
C -X- _ O
+ -X- _ O
E -X- _ O
C -X- _ O
to -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
span -X- _ O
12 -X- _ O
The -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
we -X- _ O
used -X- _ O
consists -X- _ O
of -X- _ O
paragraphs -X- _ O
from -X- _ O
TriviaQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Wiki -X- _ I-DatasetName
formed -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
400 -X- _ O
tokens -X- _ O
in -X- _ O
documents -X- _ O
, -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
possible -X- _ O
answers -X- _ O
. -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
max -X- _ O
j≥i -X- _ O
S -X- _ O
T -X- _ O
i -X- _ O
+ -X- _ O
E -X- _ O
T -X- _ O
j -X- _ O
. -X- _ O
We -X- _ O
predict -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
answer -X- _ O
whenŝ -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
> -X- _ O
s -X- _ O
null -X- _ O
+ -X- _ O
τ -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
threshold -X- _ O
τ -X- _ O
is -X- _ O
selected -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
to -X- _ O
maximize -X- _ O
F1 -X- _ B-MetricName
. -X- _ O
We -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
for -X- _ O
this -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
2 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
48 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
prior -X- _ O
leaderboard -X- _ O
entries -X- _ O
and -X- _ O
top -X- _ O
published -X- _ O
work -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
excluding -X- _ O
systems -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
components -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
+5.1 -X- _ B-HyperparameterValue
F1 -X- _ B-MetricName
improvement -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
system -X- _ O
. -X- _ O

Understanding -X- _ O
Tasks -X- _ O
The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
, -X- _ O
GELU -X- _ B-HyperparameterValue
activation -X- _ B-HyperparameterName
, -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
512 -X- _ B-HyperparameterValue
max -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
initialize -X- _ O
Unicoder -X- _ B-MethodName
LC -X- _ I-MethodName
with -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
base -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
run -X- _ O
continue -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
the -X- _ O
accumulated -X- _ O
8 -X- _ O
, -X- _ O
192 -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
with -X- _ O
gradients -X- _ O
accumulation -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ O
Optimizer -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
3e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
select -X- _ O
different -X- _ O
understanding -X- _ O
tasks -X- _ O
randomly -X- _ O
in -X- _ O
different -X- _ O
batches -X- _ O
. -X- _ O
This -X- _ O
costed -X- _ O
12 -X- _ O
days -X- _ O
on -X- _ O
16 -X- _ O
V100 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ O
Optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
5e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
all -X- _ O
sentence -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
For -X- _ O
POS -X- _ B-TaskName
Tagging -X- _ I-TaskName
and -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
And -X- _ O
for -X- _ O
POS -X- _ B-TaskName
Tagging -X- _ I-TaskName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
2e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
MLQA -X- _ B-TaskName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
3e -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
12 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
2 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
following -X- _ O
BERT -X- _ O
for -X- _ O
SQuAD -X- _ O
. -X- _ O
After -X- _ O
each -X- _ O
epoch -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
sets -X- _ O
of -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
average -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
sets -X- _ O
of -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
, -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
, -X- _ O
GELU -X- _ B-HyperparameterValue
activation -X- _ B-HyperparameterName
, -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
512 -X- _ B-HyperparameterValue
max -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
encoder -X- _ O
, -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
in -X- _ O
decoder -X- _ O
. -X- _ O

Baseline -X- _ O
We -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
passage -X- _ I-MethodName
ranker -X- _ I-MethodName
( -X- _ O
Nie -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
commonly -X- _ O
used -X- _ O
on -X- _ O
open -X- _ B-TaskName
- -X- _ I-TaskName
domain -X- _ I-TaskName
QA -X- _ I-TaskName
including -X- _ O
HotpotQA -X- _ B-DatasetName
. -X- _ O
The -X- _ O
baseline -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
BERT -X- _ O
architecture -X- _ O
as -X- _ O
our -X- _ O
approach -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2.2 -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
only -X- _ O
the -X- _ O
relevancy -X- _ B-MetricName
loss -X- _ I-MetricName
( -X- _ O
Eq -X- _ O
5 -X- _ O
) -X- _ O
and -X- _ O
therefore -X- _ O
only -X- _ O
consider -X- _ O
the -X- _ O
relevancy -X- _ O
when -X- _ O
selecting -X- _ O
evidence -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
compare -X- _ O
the -X- _ O
DRN -X- _ B-MethodName
model -X- _ O
from -X- _ O
( -X- _ O
Harel -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
designed -X- _ O
for -X- _ O
the -X- _ O
SRD -X- _ O
task -X- _ O
. -X- _ O
Their -X- _ O
ensemble -X- _ O
system -X- _ O
first -X- _ O
finds -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
evidence -X- _ O
to -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
select -X- _ O
the -X- _ O
second -X- _ O
diverse -X- _ O
evidence -X- _ O
using -X- _ O
their -X- _ O
score -X- _ O
function -X- _ O
. -X- _ O
The -X- _ O
major -X- _ O
differences -X- _ O
from -X- _ O
our -X- _ O
method -X- _ O
are -X- _ O
that -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
they -X- _ O
train -X- _ O
two -X- _ O
separate -X- _ O
models -X- _ O
for -X- _ O
evidence -X- _ O
selection -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
compactness -X- _ O
among -X- _ O
the -X- _ O
evidences -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
their -X- _ O
LSTM -X- _ O
encoder -X- _ O
with -X- _ O
BERT -X- _ O
encoder -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
Metric -X- _ O
During -X- _ O
the -X- _ O
evaluation -X- _ O
we -X- _ O
make -X- _ O
each -X- _ O
method -X- _ O
output -X- _ O
its -X- _ O
top -X- _ O
2 -X- _ O
ranked -X- _ O
results -X- _ O
3 -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
top -X- _ O
1 -X- _ O
ranked -X- _ O
pair -X- _ O
from -X- _ O
our -X- _ O
method -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
prediction -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
performance -X- _ O
is -X- _ O
evaluated -X- _ O
by -X- _ O
exact -X- _ B-MetricName
match -X- _ I-MetricName
( -X- _ O
EM -X- _ B-MetricName
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
whether -X- _ O
both -X- _ O
true -X- _ O
evidence -X- _ O
passages -X- _ O
are -X- _ O
covered -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O

Score -X- _ O
Function -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
score -X- _ O
function -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
paragraph -X- _ O
combination -X- _ O
: -X- _ O
g -X- _ O
( -X- _ O
P -X- _ O
sel -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
i -X- _ O
P -X- _ O
( -X- _ O
pi -X- _ O
| -X- _ O
q -X- _ O
) -X- _ O
+ -X- _ O
α -X- _ B-HyperparameterName
cos -X- _ O
( -X- _ O
p -X- _ O
i -X- _ O
pi -X- _ O
, -X- _ O
q -X- _ O
) -X- _ O
+ -X- _ O
β -X- _ B-HyperparameterName
p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
j -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
1 -X- _ O
( -X- _ O
pi -X- _ O
, -X- _ O
pj -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
where -X- _ O
α -X- _ B-HyperparameterName
and -X- _ O
β -X- _ B-HyperparameterName
are -X- _ O
hyperparameters -X- _ O
similar -X- _ O
to -X- _ O
Eq -X- _ O
4 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
requires -X- _ O
to -X- _ O
encode -X- _ O
each -X- _ O
passage -X- _ O
in -X- _ O
P -X- _ O
only -X- _ O
once -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
an -X- _ O
O -X- _ O
( -X- _ O
K -X- _ O
) -X- _ O
time -X- _ O
complexity -X- _ O
of -X- _ O
encoding -X- _ O
( -X- _ O
K -X- _ O
= -X- _ O
| -X- _ O
P -X- _ O
| -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
the -X- _ O
subset -X- _ O
selection -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
the -X- _ O
vector -X- _ O
space -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
more -X- _ O
efficient -X- _ O
than -X- _ O
selecting -X- _ O
subsets -X- _ O
before -X- _ O
encoding -X- _ O
. -X- _ O
Beam -X- _ O
Search -X- _ O
In -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
application -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
usually -X- _ O
a -X- _ O
large -X- _ O
candidate -X- _ O
set -X- _ O
of -X- _ O
P -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
retrieved -X- _ O
passages -X- _ O
for -X- _ O
q -X- _ O
via -X- _ O
a -X- _ O
traditional -X- _ O
IR -X- _ O
system -X- _ O
. -X- _ O
Our -X- _ O
algorithm -X- _ O
requires -X- _ O
O -X- _ O
( -X- _ O
K -X- _ O
) -X- _ O
time -X- _ O
encoding -X- _ O
, -X- _ O
and -X- _ O
O -X- _ O
( -X- _ O
K -X- _ O
L -X- _ O
) -X- _ O
time -X- _ O
scoring -X- _ O
in -X- _ O
vector -X- _ O
space -X- _ O
when -X- _ O
ranking -X- _ O
all -X- _ O
the -X- _ O
combinations -X- _ O
in -X- _ O
L -X- _ O
candidates -X- _ O
. -X- _ O
Thus -X- _ O
when -X- _ O
K -X- _ O
becomes -X- _ O
large -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
inefficient -X- _ O
even -X- _ O
when -X- _ O
L -X- _ O
= -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
resort -X- _ O
to -X- _ O
beam -X- _ O
search -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
scenarios -X- _ O
with -X- _ O
large -X- _ O
Ks -X- _ O
. -X- _ O
The -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
3 -X- _ O
Experiments -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
supervised -X- _ O
training -X- _ O
objective -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
BERT -X- _ O
encoder -X- _ O
for -X- _ O
QA -X- _ B-TaskName
that -X- _ O
optimizes -X- _ O
the -X- _ O
previous -X- _ O
conditions -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
assume -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
training -X- _ O
examples -X- _ O
are -X- _ O
available -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
annotations -X- _ O
contain -X- _ O
complementary -X- _ O
supporting -X- _ O
paragraphs -X- _ O
. -X- _ O
Recently -X- _ O
there -X- _ O
was -X- _ O
a -X- _ O
growing -X- _ O
in -X- _ O
such -X- _ O
datasets -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
increasing -X- _ O
interest -X- _ O
in -X- _ O
model -X- _ O
explainability -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
such -X- _ O
supervision -X- _ O
signals -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
obtained -X- _ O
with -X- _ O
distant -X- _ O
supervision -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
training -X- _ O
instance -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
+ -X- _ O
= -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
∀i -X- _ O
{ -X- _ O
i -X- _ O
| -X- _ O
p -X- _ O
i -X- _ O
P -X- _ O
+ -X- _ O
} -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
− -X- _ O
= -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
∀i -X- _ O
{ -X- _ O
i -X- _ O
| -X- _ O
p -X- _ O
i -X- _ O
P -X- _ O
− -X- _ O
} -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
= -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
+ -X- _ O
∪ -X- _ O
{ -X- _ O
p -X- _ O
i -X- _ O
} -X- _ O
− -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Denoting -X- _ O
y -X- _ O
p -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
if -X- _ O
p -X- _ O
i -X- _ O
P -X- _ O
+ -X- _ O
and -X- _ O
y -X- _ O
p -X- _ O
i -X- _ O
= -X- _ O
0 -X- _ O
if -X- _ O
p -X- _ O
i -X- _ O
P -X- _ O
− -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
following -X- _ O
training -X- _ O
objective -X- _ O
function -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
Lsup -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
αL -X- _ B-HyperparameterName
d -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
+ -X- _ O
) -X- _ O
+ -X- _ O
βLc -X- _ B-HyperparameterName
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
Lsup -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
i -X- _ O
yp -X- _ O
i -X- _ O
log -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
pi -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
L -X- _ O
d -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
+ -X- _ O
) -X- _ O
= -X- _ O
p -X- _ O
i -X- _ O
, -X- _ O
p -X- _ O
j -X- _ O
, -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
1 -X- _ O
( -X- _ O
pi -X- _ O
, -X- _ O
p -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Lc -X- _ O
( -X- _ O
{ -X- _ O
pi -X- _ O
} -X- _ O
; -X- _ O
q -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
 -X- _ O
1 -X- _ O
− -X- _ O
cos -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
i -X- _ O
pi -X- _ O
) -X- _ O
, -X- _ O
if -X- _ O
Πp -X- _ O
i -X- _ O
yp -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
max -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
cos -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
i -X- _ O
pi -X- _ O
) -X- _ O
− -X- _ O
γ -X- _ O
) -X- _ O
, -X- _ O
if -X- _ O
Πp -X- _ O
i -X- _ O
yp -X- _ O
i -X- _ O
= -X- _ O
0 -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
where -X- _ O
α -X- _ B-HyperparameterName
and -X- _ O
β -X- _ B-HyperparameterName
are -X- _ O
the -X- _ O
hyperparameter -X- _ O
weights -X- _ O
and -X- _ O
1 -X- _ O
( -X- _ O
, -X- _ O
) -X- _ O
denotes -X- _ O
L1 -X- _ O
loss -X- _ O
between -X- _ O
two -X- _ O
input -X- _ O
vectors -X- _ O
. -X- _ O
Eq -X- _ O
5 -X- _ O
is -X- _ O
the -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
corresponding -X- _ O
to -X- _ O
relevance -X- _ O
condition -X- _ O
; -X- _ O
Eq -X- _ O
6 -X- _ O
regularizes -X- _ O
the -X- _ O
diversity -X- _ O
condition -X- _ O
; -X- _ O
Eq -X- _ O
7 -X- _ O
is -X- _ O
the -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
embedding -X- _ I-MetricName
loss -X- _ I-MetricName
2 -X- _ O
for -X- _ O
the -X- _ O
compactness -X- _ O
condition -X- _ O
and -X- _ O
γ -X- _ O
> -X- _ O
0 -X- _ O
is -X- _ O
the -X- _ O
margin -X- _ O
to -X- _ O
encourage -X- _ O
data -X- _ O
samples -X- _ O
with -X- _ O
better -X- _ O
question -X- _ O
coverage -X- _ O
. -X- _ O
2 -X- _ O
Refer -X- _ O
to -X- _ O
CosineEmbeddingLoss -X- _ O
in -X- _ O
PyTorch -X- _ O
. -X- _ O

Named -X- _ B-TaskName
entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
has -X- _ O
been -X- _ O
excavated -X- _ O
for -X- _ O
a -X- _ O
long -X- _ O
time -X- _ O
( -X- _ O
Collins -X- _ O
and -X- _ O
Singer -X- _ O
, -X- _ O
1999 -X- _ O
; -X- _ O
, -X- _ O
which -X- _ O
classifies -X- _ O
coarsegrained -X- _ O
types -X- _ O
( -X- _ O
e.g. -X- _ O
person -X- _ O
, -X- _ O
location -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
( -X- _ O
Nagesh -X- _ O
and -X- _ O
Surdeanu -X- _ O
, -X- _ O
2018a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
applied -X- _ O
ladder -X- _ O
network -X- _ O
( -X- _ O
Rasmus -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
coarse -X- _ O
- -X- _ O
grained -X- _ O
entity -X- _ O
classification -X- _ O
in -X- _ O
a -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
fashion -X- _ O
. -X- _ O
( -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
proposed -X- _ O
Fine -X- _ B-MethodName
- -X- _ I-MethodName
Grained -X- _ I-MethodName
Entity -X- _ I-MethodName
Recognition -X- _ I-MethodName
( -X- _ O
FET -X- _ B-MethodName
) -X- _ O
. -X- _ O
They -X- _ O
used -X- _ O
distant -X- _ O
supervision -X- _ O
to -X- _ O
get -X- _ O
training -X- _ O
corpus -X- _ O
for -X- _ O
FET -X- _ B-MethodName
. -X- _ O
Embedding -X- _ O
techniques -X- _ O
was -X- _ O
applied -X- _ O
to -X- _ O
learn -X- _ O
feature -X- _ O
representations -X- _ O
since -X- _ O
( -X- _ O
Yogatama -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
Shimaoka -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
introduced -X- _ O
attention -X- _ O
mechanism -X- _ O
for -X- _ O
FET -X- _ B-MethodName
to -X- _ O
capture -X- _ O
informative -X- _ O
words -X- _ O
. -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
used -X- _ O
the -X- _ O
TransE -X- _ O
entity -X- _ O
embeddings -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
vector -X- _ O
of -X- _ O
attention -X- _ O
. -X- _ O
Early -X- _ O
works -X- _ O
ignore -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
context -X- _ O
noise -X- _ O
, -X- _ O
( -X- _ O
Gillick -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
proposed -X- _ O
context -X- _ O
dependent -X- _ O
FET -X- _ O
and -X- _ O
use -X- _ O
three -X- _ O
heuristics -X- _ O
to -X- _ O
clean -X- _ O
the -X- _ O
noisy -X- _ O
labels -X- _ O
with -X- _ O
the -X- _ O
side -X- _ O
effect -X- _ O
of -X- _ O
losing -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
utilize -X- _ O
noisy -X- _ O
data -X- _ O
, -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
distinguished -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
of -X- _ O
noisy -X- _ O
data -X- _ O
from -X- _ O
clean -X- _ O
data -X- _ O
via -X- _ O
partial -X- _ B-MetricName
label -X- _ I-MetricName
loss -X- _ I-MetricName
( -X- _ O
PLL -X- _ B-MetricName
) -X- _ O
. -X- _ O
( -X- _ O
Abhishek -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
variants -X- _ O
of -X- _ O
PLL -X- _ B-MetricName
, -X- _ O
which -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
confirmation -X- _ O
bias -X- _ O
. -X- _ O
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
hierarchical -X- _ O
loss -X- _ O
to -X- _ O
handle -X- _ O
over -X- _ O
- -X- _ O
specific -X- _ O
noise -X- _ O
. -X- _ O
On -X- _ O
top -X- _ O
of -X- _ O
AFET -X- _ O
, -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016b -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
method -X- _ O
PLE -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
, -X- _ O
which -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
great -X- _ O
success -X- _ O
in -X- _ O
FET -X- _ B-MethodName
. -X- _ O
Because -X- _ O
label -X- _ O
noise -X- _ O
reduction -X- _ O
is -X- _ O
separated -X- _ O
from -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
FET -X- _ B-MethodName
, -X- _ O
there -X- _ O
might -X- _ O
be -X- _ O
error -X- _ O
propagation -X- _ O
problem -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
proposed -X- _ O
utilizing -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
measures -X- _ O
the -X- _ O
compatibility -X- _ O
between -X- _ O
context -X- _ O
and -X- _ O
type -X- _ O
names -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
repel -X- _ O
the -X- _ O
interference -X- _ O
of -X- _ O
noisy -X- _ O
labels -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
compatibility -X- _ O
got -X- _ O
by -X- _ O
language -X- _ O
model -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
right -X- _ O
and -X- _ O
type -X- _ O
information -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
corpus -X- _ O
and -X- _ O
annotation -X- _ O
guidelines -X- _ O
rather -X- _ O
than -X- _ O
type -X- _ O
names -X- _ O
as -X- _ O
is -X- _ O
mentioned -X- _ O
in -X- _ O
( -X- _ O
Azad -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
some -X- _ O
work -X- _ O
about -X- _ O
entity -X- _ O
- -X- _ O
level -X- _ O
typing -X- _ O
which -X- _ O
aim -X- _ O
to -X- _ O
figure -X- _ O
out -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
KB -X- _ O
( -X- _ O
Yaghoobzadeh -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
performance -X- _ O
comparison -X- _ O
between -X- _ O
the -X- _ O
proposed -X- _ O
CLSC -X- _ B-MethodName
model -X- _ O
and -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
. -X- _ O
On -X- _ O
both -X- _ O
benchmarks -X- _ O
, -X- _ O
the -X- _ O
CLSC -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
metrics -X- _ O
. -X- _ O
When -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
comparison -X- _ O
between -X- _ O
NFETC -X- _ B-MethodName
and -X- _ O
CLSC -X- _ B-MethodName
, -X- _ O
we -X- _ O
have -X- _ O
following -X- _ O
observation -X- _ O
: -X- _ O
Compact -X- _ O
Latent -X- _ O
Space -X- _ O
Clustering -X- _ O
shows -X- _ O
its -X- _ O
effectiveness -X- _ O
on -X- _ O
both -X- _ O
clean -X- _ O
data -X- _ O
and -X- _ O
noisy -X- _ O
data -X- _ O
. -X- _ O
By -X- _ O
applying -X- _ O
CLSC -X- _ B-MethodName
regularization -X- _ O
on -X- _ O
the -X- _ O
basic -X- _ O
NFETC -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
consistent -X- _ O
and -X- _ O
significant -X- _ O
performance -X- _ O
boost -X- _ O
; -X- _ O
Hierarchical -X- _ O
- -X- _ O
aware -X- _ O
loss -X- _ O
shows -X- _ O
significant -X- _ O
advantage -X- _ O
on -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
while -X- _ O
showing -X- _ O
insignificant -X- _ O
performance -X- _ O
boost -X- _ O
on -X- _ O
the -X- _ O
BBN -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
different -X- _ O
distribution -X- _ O
of -X- _ O
labels -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
proportion -X- _ O
of -X- _ O
terminal -X- _ O
types -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
69 -X- _ O
% -X- _ O
for -X- _ O
the -X- _ O
BBN -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
while -X- _ O
is -X- _ O
only -X- _ O
33 -X- _ O
% -X- _ O
on -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
applying -X- _ O
hierarchical -X- _ B-MetricName
- -X- _ I-MetricName
aware -X- _ I-MetricName
loss -X- _ I-MetricName
on -X- _ O
the -X- _ O
BBN -X- _ B-DatasetName
dataset -X- _ O
brings -X- _ O
little -X- _ O
improvement -X- _ O
; -X- _ O
Both -X- _ O
algorithms -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
utilize -X- _ O
noisy -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
further -X- _ O
study -X- _ O
their -X- _ O
performance -X- _ O
in -X- _ O
different -X- _ O
noisy -X- _ O
scenarios -X- _ O
in -X- _ O
following -X- _ O
discussions -X- _ O
. -X- _ O
By -X- _ O
principle -X- _ O
, -X- _ O
with -X- _ O
sufficient -X- _ O
amount -X- _ O
of -X- _ O
clean -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
most -X- _ O
typing -X- _ O
systems -X- _ O
can -X- _ O
achieve -X- _ O
satisfying -X- _ O
performance -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
study -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
to -X- _ O
label -X- _ O
noise -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
their -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
25 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
and -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
clean -X- _ B-HyperparameterName
training -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
and -X- _ O
all -X- _ O
noisy -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
curves -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
clean -X- _ O
data -X- _ O
drops -X- _ O
. -X- _ O
As -X- _ O
it -X- _ O
reveals -X- _ O
, -X- _ O
the -X- _ O
CLSC -X- _ B-MethodName
model -X- _ O
consistently -X- _ O
wins -X- _ O
in -X- _ O
the -X- _ O
comparison -X- _ O
. -X- _ O
The -X- _ O
advantage -X- _ O
is -X- _ O
especially -X- _ O
clear -X- _ O
on -X- _ O
the -X- _ O
BBN -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
which -X- _ O
offers -X- _ O
less -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
27.9 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
training -X- _ B-HyperparameterName
data -X- _ I-HyperparameterName
( -X- _ O
when -X- _ O
only -X- _ O
leaving -X- _ O
5 -X- _ O
% -X- _ O
clean -X- _ O
data -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
BBN -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
CLSC -X- _ B-MethodName
model -X- _ O
yield -X- _ O
a -X- _ O
comparable -X- _ O
result -X- _ O
with -X- _ O
the -X- _ O
NFETC -X- _ B-MethodName
model -X- _ O
trained -X- _ O
on -X- _ O
full -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
comparison -X- _ O
clearly -X- _ O
shows -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
utilizing -X- _ O
noisy -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
search -X- _ O
the -X- _ O
hyper -X- _ O
parameter -X- _ O
of -X- _ O
Ontonotes -X- _ B-DatasetName
and -X- _ O
BBN -X- _ B-DatasetName
respectively -X- _ O
via -X- _ O
Hyperopt -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Bergstra -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Hyper -X- _ O
parameters -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
We -X- _ O
optimize -X- _ O
the -X- _ O
model -X- _ O
via -X- _ O
Adam -X- _ O
Optimizer -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
hyper -X- _ O
parameters -X- _ O
includes -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
lr -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
dimension -X- _ O
d -X- _ B-HyperparameterName
p -X- _ I-HyperparameterName
of -X- _ O
word -X- _ O
position -X- _ O
embedding -X- _ O
, -X- _ O
the -X- _ O
dimension -X- _ O
d -X- _ B-HyperparameterName
l -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
mention -X- _ O
encoder -X- _ O
's -X- _ O
output -X- _ O
( -X- _ O
equal -X- _ O
to -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
encoder -X- _ O
's -X- _ O
ourput -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
input -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
keep -X- _ I-HyperparameterName
probability -X- _ I-HyperparameterName
p -X- _ B-HyperparameterName
i -X- _ I-HyperparameterName
and -X- _ O
output -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
keep -X- _ I-HyperparameterName
probability -X- _ I-HyperparameterName
p -X- _ B-HyperparameterName
o -X- _ I-HyperparameterName
for -X- _ O
LSTM -X- _ O
layers -X- _ O
( -X- _ O
in -X- _ O
context -X- _ O
encoder -X- _ O
and -X- _ O
LSTM -X- _ O
mention -X- _ O
encoder -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
L2 -X- _ B-HyperparameterName
regularization -X- _ I-HyperparameterName
parameter -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
factor -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
hierarchical -X- _ I-HyperparameterName
loss -X- _ I-HyperparameterName
normalization -X- _ I-HyperparameterName
α -X- _ B-HyperparameterName
( -X- _ O
α -X- _ B-HyperparameterName
> -X- _ O
0 -X- _ O
means -X- _ O
use -X- _ O
the -X- _ O
normalization -X- _ O
) -X- _ O
, -X- _ O
BN -X- _ B-HyperparameterName
( -X- _ O
whether -X- _ O
using -X- _ O
Batch -X- _ O
normalization -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
step -X- _ I-HyperparameterName
S -X- _ B-HyperparameterName
lp -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
label -X- _ O
propagation -X- _ O
, -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
S -X- _ B-HyperparameterName
m -X- _ I-HyperparameterName
of -X- _ O
Markov -X- _ O
chain -X- _ O
, -X- _ O
the -X- _ O
influence -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
clsc -X- _ I-HyperparameterName
of -X- _ O
CLSC -X- _ B-MethodName
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
B -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
n -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
hidden -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
in -X- _ O
q -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
h -X- _ I-HyperparameterName
n -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
hidden -X- _ I-HyperparameterName
units -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
all -X- _ O
models -X- _ O
using -X- _ O
Tensorflow -X- _ O
4 -X- _ O
. -X- _ O

For -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
strict -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
loose -X- _ B-MetricName
macro -X- _ I-MetricName
, -X- _ O
and -X- _ O
loose -X- _ B-MetricName
micro -X- _ I-MetricName
F -X- _ I-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
widely -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
FET -X- _ B-TaskName
task -X- _ O
( -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
fine -X- _ O
tuning -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sampled -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
as -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
for -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
hyperparameter -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
4.4 -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
the -X- _ O
model -X- _ O
five -X- _ O
times -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
strict -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
micro -X- _ B-MetricName
F1 -X- _ I-MetricName
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
with -X- _ O
several -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
3 -X- _ O
: -X- _ O
Attentive -X- _ B-MethodName
( -X- _ O
Shimaoka -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
uses -X- _ O
an -X- _ O
attention -X- _ O
based -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
does -X- _ O
n't -X- _ O
distinguish -X- _ O
clean -X- _ O
from -X- _ O
noisy -X- _ O
data -X- _ O
; -X- _ O
AFET -X- _ B-MethodName
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
trains -X- _ O
label -X- _ O
embedding -X- _ O
with -X- _ O
partial -X- _ O
label -X- _ O
loss -X- _ O
; -X- _ O
AAA -X- _ B-MethodName
( -X- _ O
Abhishek -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
learns -X- _ O
joint -X- _ O
representation -X- _ O
of -X- _ O
mentions -X- _ O
and -X- _ O
type -X- _ O
labels -X- _ O
; -X- _ O
PLE+HYENA -X- _ B-MethodName
/ -X- _ I-MethodName
FIGER -X- _ I-MethodName
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016b -X- _ O
) -X- _ O
proposes -X- _ O
heterogeneous -X- _ O
partial -X- _ O
- -X- _ O
label -X- _ O
embedding -X- _ O
for -X- _ O
label -X- _ O
noise -X- _ O
reduction -X- _ O
to -X- _ O
boost -X- _ O
typing -X- _ O
systems -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
two -X- _ O
PLE -X- _ O
models -X- _ O
with -X- _ O
HYENA -X- _ B-MethodName
( -X- _ O
Yogatama -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
FIGER -X- _ B-MethodName
( -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
typing -X- _ O
system -X- _ O
respectively -X- _ O
; -X- _ O
NFETC -X- _ B-MethodName
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
trains -X- _ O
neural -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
typing -X- _ O
system -X- _ O
with -X- _ O
hierarchy -X- _ O
- -X- _ O
aware -X- _ O
loss -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
NFETC -X- _ B-MethodName
model -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
loss -X- _ O
functions -X- _ O
: -X- _ O
partial -X- _ B-MetricName
- -X- _ I-MetricName
label -X- _ I-MetricName
loss -X- _ I-MetricName
and -X- _ O
PLL+hierarchical -X- _ B-MetricName
loss -X- _ I-MetricName
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
two -X- _ O
variants -X- _ O
as -X- _ O
NFETC -X- _ B-MethodName
and -X- _ O
NFETC -X- _ B-MethodName
hier -X- _ I-MethodName
respectively -X- _ O
; -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
CLSC -X- _ I-MethodName
is -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
NFETC -X- _ B-MethodName
model -X- _ O
as -X- _ O
our -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
apply -X- _ O
Compact -X- _ O
Latent -X- _ O
Space -X- _ O
Clustering -X- _ O
Regularization -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
; -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
produced -X- _ O
by -X- _ O
using -X- _ O
both -X- _ O
KLdivergense -X- _ B-MetricName
- -X- _ O
based -X- _ O
loss -X- _ O
( -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
CLSC -X- _ I-MethodName
) -X- _ O
and -X- _ O
KL+hierarchical -X- _ B-MetricName
loss -X- _ I-MetricName
( -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
CLSC -X- _ I-MethodName
hier -X- _ I-MethodName
) -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
a -X- _ O
mention -X- _ O
, -X- _ O
the -X- _ O
type -X- _ O
posterior -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
a -X- _ O
standard -X- _ O
softmax -X- _ O
classifier -X- _ O
parameterized -X- _ O
by -X- _ O
θ -X- _ O
g -X- _ O
: -X- _ O
P -X- _ O
( -X- _ O
ŷ -X- _ O
i -X- _ O
| -X- _ O
z -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
g -X- _ O
) -X- _ O
= -X- _ O
sof -X- _ O
tmax -X- _ O
( -X- _ O
W -X- _ O
c -X- _ O
z -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
where -X- _ O
W -X- _ O
c -X- _ O
R -X- _ O
K×dz -X- _ O
is -X- _ O
a -X- _ O
parameter -X- _ O
matrix -X- _ O
, -X- _ O
b -X- _ O
R -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
bias -X- _ O
vector -X- _ O
, -X- _ O
where -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
types -X- _ O
. -X- _ O
The -X- _ O
predicted -X- _ O
type -X- _ O
is -X- _ O
then -X- _ O
given -X- _ O
byt -X- _ O
i -X- _ O
= -X- _ O
argmax -X- _ O
y -X- _ O
i -X- _ O
P -X- _ O
( -X- _ O
ŷ -X- _ O
i -X- _ O
| -X- _ O
z -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
g -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
loss -X- _ O
function -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
parts -X- _ O
. -X- _ O
L -X- _ O
sup -X- _ O
is -X- _ O
supervision -X- _ O
loss -X- _ O
defined -X- _ O
by -X- _ O
KL -X- _ B-MetricName
divergence -X- _ I-MetricName
: -X- _ O
L -X- _ O
sup -X- _ O
= -X- _ O
− -X- _ O
1 -X- _ O
B -X- _ O
c -X- _ O
Bc -X- _ O
i=1 -X- _ O
K -X- _ O
k=1 -X- _ O
y -X- _ O
ik -X- _ O
log -X- _ O
( -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
i -X- _ O
| -X- _ O
z -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
g -X- _ O
) -X- _ O
) -X- _ O
k -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O
Here -X- _ O
B -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
clean -X- _ O
data -X- _ O
in -X- _ O
a -X- _ O
training -X- _ O
batch -X- _ O
, -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
target -X- _ O
types -X- _ O
. -X- _ O
The -X- _ O
regularization -X- _ O
term -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
L -X- _ O
clsc -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
the -X- _ O
overall -X- _ O
loss -X- _ O
function -X- _ O
is -X- _ O
: -X- _ O
L -X- _ O
f -X- _ O
inal -X- _ O
= -X- _ O
L -X- _ O
sup -X- _ O
+ -X- _ O
λ -X- _ B-HyperparameterName
clsc -X- _ I-HyperparameterName
× -X- _ O
L -X- _ O
clsc -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
λ -X- _ B-HyperparameterName
clsc -X- _ I-HyperparameterName
is -X- _ O
a -X- _ O
hyper -X- _ O
parameter -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
CLSC -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
illustrates -X- _ O
our -X- _ O
feature -X- _ O
extractor -X- _ O
. -X- _ O
For -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
feature -X- _ O
extraction -X- _ O
pipeline -X- _ O
as -X- _ O
used -X- _ O
in -X- _ O
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
feature -X- _ O
extractor -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
an -X- _ O
embedding -X- _ O
layer -X- _ O
and -X- _ O
two -X- _ O
encoders -X- _ O
which -X- _ O
encode -X- _ O
mentions -X- _ O
and -X- _ O
contexts -X- _ O
respectively -X- _ O
. -X- _ O
Embedding -X- _ O
Layer -X- _ O
: -X- _ O
The -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
layer -X- _ O
is -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
word -X- _ O
embedding -X- _ O
and -X- _ O
word -X- _ O
position -X- _ O
embedding -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
popular -X- _ O
300dimensional -X- _ B-HyperparameterValue
word -X- _ O
embedding -X- _ O
supplied -X- _ O
by -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
information -X- _ O
and -X- _ O
random -X- _ O
initialized -X- _ O
position -X- _ O
embedding -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
acquire -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
mentions -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
Given -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
matrix -X- _ O
W -X- _ O
word -X- _ O
of -X- _ O
shape -X- _ O
d -X- _ O
w -X- _ O
× -X- _ O
| -X- _ O
V -X- _ O
| -X- _ O
, -X- _ O
where -X- _ O
V -X- _ O
is -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
d -X- _ O
w -X- _ O
is -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
word -X- _ I-HyperparameterName
embedding -X- _ I-HyperparameterName
, -X- _ O
each -X- _ O
column -X- _ O
of -X- _ O
W -X- _ O
word -X- _ O
represents -X- _ O
a -X- _ O
specific -X- _ O
word -X- _ O
w -X- _ O
in -X- _ O
V -X- _ O
. -X- _ O
We -X- _ O
map -X- _ O
each -X- _ O
word -X- _ O
w -X- _ O
j -X- _ O
in -X- _ O
( -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
w -X- _ O
d -X- _ O
j -X- _ O
R -X- _ O
dw -X- _ O
. -X- _ O
Analogously -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
word -X- _ O
position -X- _ O
embedding -X- _ O
w -X- _ O
p -X- _ O
j -X- _ O
R -X- _ O
dp -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
relative -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
word -X- _ O
and -X- _ O
the -X- _ O
mention -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
a -X- _ O
fixed -X- _ O
length -X- _ O
context -X- _ O
here -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
is -X- _ O
w -X- _ O
E -X- _ O
j -X- _ O
= -X- _ O
[ -X- _ O
w -X- _ O
d -X- _ O
j -X- _ O
, -X- _ O
w -X- _ O
p -X- _ O
j -X- _ O
] -X- _ O
. -X- _ O
Mention -X- _ O
Encoder -X- _ O
: -X- _ O
To -X- _ O
capture -X- _ O
lexical -X- _ O
level -X- _ O
information -X- _ O
of -X- _ O
mentions -X- _ O
, -X- _ O
an -X- _ O
averaging -X- _ O
mention -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
LSTM -X- _ O
mention -X- _ O
encoder -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
encode -X- _ O
mentions -X- _ O
. -X- _ O
Given -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
( -X- _ O
w -X- _ O
s -X- _ O
, -X- _ O
w -X- _ O
s+1 -X- _ O
, -X- _ O
, -X- _ O
w -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
aver -X- _ O
- -X- _ O
aging -X- _ O
mention -X- _ O
representation -X- _ O
r -X- _ O
a -X- _ O
i -X- _ O
R -X- _ O
dw -X- _ O
is -X- _ O
: -X- _ O
r -X- _ O
a -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
e -X- _ O
− -X- _ O
s -X- _ O
+ -X- _ O
1 -X- _ O
e -X- _ O
j -X- _ O
= -X- _ O
s -X- _ O
w -X- _ O
d -X- _ O
j -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
By -X- _ O
applying -X- _ O
a -X- _ O
LSTM -X- _ O
over -X- _ O
an -X- _ O
extended -X- _ O
mention -X- _ O
( -X- _ O
w -X- _ O
s−1 -X- _ O
, -X- _ O
w -X- _ O
s -X- _ O
, -X- _ O
w -X- _ O
s+1 -X- _ O
, -X- _ O
, -X- _ O
w -X- _ O
e -X- _ O
, -X- _ O
w -X- _ O
e+1 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
a -X- _ O
sequence -X- _ O
( -X- _ O
h -X- _ O
s−1 -X- _ O
, -X- _ O
h -X- _ O
s -X- _ O
, -X- _ O
h -X- _ O
s+1 -X- _ O
, -X- _ O
, -X- _ O
h -X- _ O
e -X- _ O
, -X- _ O
h -X- _ O
e+1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
h -X- _ O
e+1 -X- _ O
as -X- _ O
LSTM -X- _ O
mention -X- _ O
representation -X- _ O
r -X- _ O
l -X- _ O
i -X- _ O
R -X- _ O
d -X- _ O
l -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
mention -X- _ O
representation -X- _ O
is -X- _ O
r -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
r -X- _ O
a -X- _ O
i -X- _ O
, -X- _ O
r -X- _ O
l -X- _ O
i -X- _ O
] -X- _ O
R -X- _ O
dw+d -X- _ O
l -X- _ O
. -X- _ O
Context -X- _ O
Encoder -X- _ O
: -X- _ O
A -X- _ O
bidirectional -X- _ O
LSTM -X- _ O
with -X- _ O
d -X- _ O
l -X- _ O
hidden -X- _ O
units -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
encode -X- _ O
embedding -X- _ O
se -X- _ O
- -X- _ O
quence -X- _ O
( -X- _ O
w -X- _ O
E -X- _ O
s−W -X- _ O
, -X- _ O
w -X- _ O
E -X- _ O
s−W+1 -X- _ O
, -X- _ O
, -X- _ O
w -X- _ O
E -X- _ O
e+W -X- _ O
) -X- _ O
: -X- _ O
− -X- _ O
h -X- _ O
j -X- _ O
= -X- _ O
LST -X- _ O
M -X- _ O
( -X- _ O
−− -X- _ O
h -X- _ O
j−1 -X- _ O
, -X- _ O
w -X- _ O
E -X- _ O
j−1 -X- _ O
) -X- _ O
− -X- _ O
h -X- _ O
j -X- _ O
= -X- _ O
LST -X- _ O
M -X- _ O
( -X- _ O
−− -X- _ O
h -X- _ O
j−1 -X- _ O
, -X- _ O
w -X- _ O
E -X- _ O
j−1 -X- _ O
) -X- _ O
h -X- _ O
j -X- _ O
= -X- _ O
[ -X- _ O
− -X- _ O
h -X- _ O
j -X- _ O
− -X- _ O
h -X- _ O
j -X- _ O
] -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
where -X- _ O
denotes -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
plus -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
attention -X- _ O
mechanism -X- _ O
computes -X- _ O
a -X- _ O
score -X- _ O
β -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
over -X- _ O
different -X- _ O
word -X- _ O
j -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
c -X- _ O
i -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
final -X- _ O
context -X- _ O
representation -X- _ O
r -X- _ O
c -X- _ O
i -X- _ O
: -X- _ O
α -X- _ O
j -X- _ O
= -X- _ O
w -X- _ O
T -X- _ O
tanh -X- _ O
( -X- _ O
h -X- _ O
j -X- _ O
) -X- _ O
β -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
α -X- _ O
j -X- _ O
) -X- _ O
k -X- _ O
exp -X- _ O
( -X- _ O
α -X- _ O
k -X- _ O
) -X- _ O
r -X- _ O
c -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
β -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
h -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
use -X- _ O
r -X- _ O
i -X- _ O
= -X- _ O
[ -X- _ O
r -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
r -X- _ O
c -X- _ O
i -X- _ O
] -X- _ O
R -X- _ O
dz -X- _ O
= -X- _ O
R -X- _ O
dw+d -X- _ O
l -X- _ O
+ -X- _ O
d -X- _ O
l -X- _ O
as -X- _ O
the -X- _ O
feature -X- _ O
representation -X- _ O
of -X- _ O
( -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
Neural -X- _ O
Networks -X- _ O
q -X- _ O
over -X- _ O
r -X- _ O
i -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
feature -X- _ O
vector -X- _ O
z -X- _ O
i -X- _ O
. -X- _ O
q -X- _ O
has -X- _ O
n -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
with -X- _ O
h -X- _ B-HyperparameterValue
n -X- _ I-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
and -X- _ O
use -X- _ O
ReLu -X- _ B-HyperparameterName
activation -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
employ -X- _ O
a -X- _ O
critic -X- _ O
network -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
reinforcement -X- _ O
learning -X- _ O
rewards -X- _ O
for -X- _ O
our -X- _ O
generators -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
as -X- _ O
critic -X- _ O
by -X- _ O
extracting -X- _ O
training -X- _ O
instances -X- _ O
( -X- _ O
s -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
L -X- _ O
= -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
3 -X- _ O
( -X- _ O
s -X- _ O
A -X- _ O
, -X- _ O
r -X- _ O
A -X- _ O
, -X- _ O
L -X- _ O
= -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
s -X- _ O
B -X- _ O
, -X- _ O
r -X- _ O
B -X- _ O
, -X- _ O
L -X- _ O
= -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
can -X- _ O
derive -X- _ O
two -X- _ O
negative -X- _ O
samples -X- _ O
as -X- _ O
: -X- _ O
( -X- _ O
s -X- _ O
A -X- _ O
, -X- _ O
r -X- _ O
B -X- _ O
, -X- _ O
L -X- _ O
= -X- _ O
0 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
s -X- _ O
B -X- _ O
, -X- _ O
r -X- _ O
A -X- _ O
, -X- _ O
L -X- _ O
= -X- _ O
0 -X- _ O
) -X- _ O
. -X- _ O
Thereafter -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
a -X- _ O
binary -X- _ O
classifier -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
our -X- _ O
critic -X- _ O
in -X- _ O
RL -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
partition -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
binary -X- _ B-MetricName
cross -X- _ I-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
: -X- _ O
−Llog -X- _ O
( -X- _ O
P -X- _ O
( -X- _ O
L -X- _ O
| -X- _ O
s -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
) -X- _ O
− -X- _ O
( -X- _ O
1−L -X- _ O
) -X- _ O
log -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
L -X- _ O
| -X- _ O
s -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
binary -X- _ O
label -X- _ O
L -X- _ O
indicates -X- _ O
whether -X- _ O
the -X- _ O
response -X- _ O
is -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
personas -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
this -X- _ O
classifier -X- _ O
acting -X- _ O
as -X- _ O
a -X- _ O
critic -X- _ O
network -X- _ O
that -X- _ O
outputsL -X- _ O
, -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
generated -X- _ O
partner -X- _ O
personasp -X- _ O
and -X- _ O
generated -X- _ O
responser -X- _ O
. -X- _ O
The -X- _ O
predicted -X- _ O
binary -X- _ O
labelL -X- _ O
is -X- _ O
then -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
reward -X- _ O
R. -X- _ O
R -X- _ O
is -X- _ O
a -X- _ O
positive -X- _ O
reward -X- _ O
whenL -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
R -X- _ O
is -X- _ O
a -X- _ O
negative -X- _ O
reward -X- _ O
whenL -X- _ O
= -X- _ O
0 -X- _ O
. -X- _ O
We -X- _ O
empirically -X- _ O
set -X- _ O
the -X- _ O
reward -X- _ O
R -X- _ B-HyperparameterName
for -X- _ O
RL -X- _ O
to -X- _ O
{ -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
- -X- _ B-HyperparameterValue
1 -X- _ I-HyperparameterValue
} -X- _ O
for -X- _ O
both -X- _ O
PPG -X- _ B-MethodName
and -X- _ O
DRG -X- _ B-MethodName
. -X- _ O
We -X- _ O
then -X- _ O
update -X- _ O
our -X- _ O
RL -X- _ O
agents -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
gradients -X- _ O
: -X- _ O
∆θ -X- _ O
PPG -X- _ O
= -X- _ O
−R -X- _ O
▽ -X- _ O
θ -X- _ O
PPG -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
p -X- _ O
| -X- _ O
s -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
partner -X- _ B-MethodName
personas -X- _ I-MethodName
generator -X- _ I-MethodName
( -X- _ O
PPG -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
dialogue -X- _ B-MethodName
response -X- _ I-MethodName
generator -X- _ I-MethodName
( -X- _ O
DRG -X- _ B-MethodName
) -X- _ O
: -X- _ O
∆θ -X- _ O
DRG -X- _ O
= -X- _ O
−R -X- _ O
▽ -X- _ O
θ -X- _ O
DRG -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
r -X- _ O
| -X- _ O
s -X- _ O
, -X- _ O
p -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
By -X- _ O
formulating -X- _ O
a -X- _ O
reward -X- _ O
that -X- _ O
measures -X- _ O
the -X- _ O
relevance -X- _ O
between -X- _ O
generated -X- _ O
partner -X- _ O
personas -X- _ O
and -X- _ O
generated -X- _ O
dialogue -X- _ O
response -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
motivated -X- _ O
by -X- _ O
the -X- _ O
following -X- _ O
objectives -X- _ O
: -X- _ O
Further -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
partner -X- _ O
personas -X- _ O
generator -X- _ O
to -X- _ O
generate -X- _ O
personas -X- _ O
that -X- _ O
benefits -X- _ O
the -X- _ O
downstream -X- _ O
dialogue -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Further -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
dialogue -X- _ O
response -X- _ O
generator -X- _ O
trained -X- _ O
with -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
partner -X- _ O
personas -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
noisy -X- _ O
partner -X- _ O
personas -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
partner -X- _ O
personas -X- _ O
generator -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
motivation -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
generating -X- _ O
the -X- _ O
complete -X- _ O
personas -X- _ O
profile -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
can -X- _ O
be -X- _ O
irrelevant -X- _ O
and -X- _ O
unhelpful -X- _ O
for -X- _ O
the -X- _ O
next -X- _ O
- -X- _ O
turn -X- _ O
dialogue -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
It -X- _ O
could -X- _ O
be -X- _ O
challenging -X- _ O
for -X- _ O
the -X- _ O
partner -X- _ O
personas -X- _ O
generator -X- _ O
alone -X- _ O
to -X- _ O
identify -X- _ O
which -X- _ O
personas -X- _ O
could -X- _ O
be -X- _ O
helpful -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
such -X- _ O
a -X- _ O
reward -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
personas -X- _ O
generator -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
personas -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
helpful -X- _ O
for -X- _ O
the -X- _ O
downstream -X- _ O
dialogue -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Our -X- _ O
second -X- _ O
motivation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
dialogue -X- _ O
response -X- _ O
generator -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
exposed -X- _ O
to -X- _ O
the -X- _ O
generated -X- _ O
partner -X- _ O
personas -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
response -X- _ O
generator -X- _ O
to -X- _ O
mitigate -X- _ O
the -X- _ O
potential -X- _ O
traininginference -X- _ O
discrepancy -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
our -X- _ O
design -X- _ O
empirically -X- _ O
works -X- _ O
well -X- _ O
. -X- _ O
The -X- _ O
previous -X- _ O
work -X- _ O
from -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2019a -X- _ O
) -X- _ O
employed -X- _ O
critic -X- _ O
network -X- _ O
for -X- _ O
RL -X- _ O
loss -X- _ O
backpropagation -X- _ O
. -X- _ O
The -X- _ O
major -X- _ O
difference -X- _ O
is -X- _ O
that -X- _ O
their -X- _ O
critic -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
adversarial -X- _ O
manner -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
pick -X- _ O
up -X- _ O
the -X- _ O
gold -X- _ O
response -X- _ O
among -X- _ O
other -X- _ O
negative -X- _ O
candidates -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
their -X- _ O
critic -X- _ O
network -X- _ O
conditions -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
dialogue -X- _ O
response -X- _ O
but -X- _ O
not -X- _ O
on -X- _ O
the -X- _ O
generated -X- _ O
skeleton -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
for -X- _ O
improved -X- _ O
response -X- _ O
generation -X- _ O
with -X- _ O
a -X- _ O
classifier -X- _ O
conditioning -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
generated -X- _ O
personas -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
. -X- _ O

Overview -X- _ O
. -X- _ O
The -X- _ O
basic -X- _ O
assumptions -X- _ O
of -X- _ O
our -X- _ O
idea -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
all -X- _ O
mentions -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
should -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
the -X- _ O
representation -X- _ O
space -X- _ O
because -X- _ O
they -X- _ O
should -X- _ O
have -X- _ O
similar -X- _ O
context -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
similar -X- _ O
contexts -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
. -X- _ O
For -X- _ O
clean -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
compact -X- _ O
the -X- _ O
representation -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
to -X- _ O
comply -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
noisy -X- _ O
data -X- _ O
, -X- _ O
given -X- _ O
assumption -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
infer -X- _ O
the -X- _ O
their -X- _ O
type -X- _ O
distributions -X- _ O
via -X- _ O
label -X- _ O
propagation -X- _ O
and -X- _ O
candidate -X- _ O
types -X- _ O
constrain -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
overall -X- _ O
framework -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
Clean -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
classifier -X- _ O
and -X- _ O
feature -X- _ O
extractor -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
endly -X- _ O
, -X- _ O
while -X- _ O
noisy -X- _ O
data -X- _ O
is -X- _ O
only -X- _ O
used -X- _ O
in -X- _ O
CLSC -X- _ O
regularization -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
samples -X- _ O
{ -X- _ O
( -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
, -X- _ O
Y -X- _ O
t -X- _ O
i -X- _ O
) -X- _ O
} -X- _ O
B -X- _ O
i=1 -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
convert -X- _ O
each -X- _ O
sample -X- _ O
( -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
into -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
vector -X- _ O
z -X- _ O
i -X- _ O
via -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
z -X- _ O
( -X- _ O
( -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
; -X- _ O
θ -X- _ O
z -X- _ O
) -X- _ O
parameterized -X- _ O
by -X- _ O
θ -X- _ O
z -X- _ O
. -X- _ O
Then -X- _ O
a -X- _ O
type -X- _ O
classifier -X- _ O
g -X- _ O
( -X- _ O
z -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
g -X- _ O
) -X- _ O
parameterized -X- _ O
by -X- _ O
θ -X- _ O
g -X- _ O
gives -X- _ O
the -X- _ O
posterior -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
z -X- _ O
i -X- _ O
; -X- _ O
θ -X- _ O
g -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
incorporating -X- _ O
CLSC -X- _ O
regularization -X- _ O
in -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
encourage -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
z -X- _ O
to -X- _ O
group -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
into -X- _ O
a -X- _ O
compact -X- _ O
cluster -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
classification -X- _ O
as -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
Noisy -X- _ O
data -X- _ O
enhances -X- _ O
the -X- _ O
formation -X- _ O
of -X- _ O
compact -X- _ O
clusters -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
label -X- _ O
propagation -X- _ O
. -X- _ O

Recent -X- _ O
years -X- _ O
have -X- _ O
seen -X- _ O
a -X- _ O
surge -X- _ O
of -X- _ O
interests -X- _ O
in -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
grained -X- _ I-TaskName
entity -X- _ I-TaskName
typing -X- _ I-TaskName
( -X- _ O
FET -X- _ B-TaskName
) -X- _ O
as -X- _ O
it -X- _ O
serves -X- _ O
as -X- _ O
an -X- _ O
important -X- _ O
cornerstone -X- _ O
of -X- _ O
several -X- _ O
nature -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
including -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Mintz -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
entity -X- _ O
linking -X- _ O
( -X- _ O
Raiman -X- _ O
and -X- _ O
Raiman -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
knowledge -X- _ O
base -X- _ O
completion -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
manual -X- _ O
efforts -X- _ O
in -X- _ O
labelling -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
distant -X- _ O
supervision -X- _ O
( -X- _ O
Mintz -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
adopted -X- _ O
by -X- _ O
recent -X- _ O
FET -X- _ O
systems -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
an -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
entity -X- _ O
mention -X- _ O
is -X- _ O
first -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
- -X- _ O
SNE -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
mention -X- _ O
embeddings -X- _ O
generated -X- _ O
by -X- _ O
NFETC -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
and -X- _ O
CLSC -X- _ O
( -X- _ O
right -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
BBN -X- _ O
dataset -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
( -X- _ O
CLSC -X- _ B-MethodName
) -X- _ O
clearly -X- _ O
groups -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
into -X- _ O
a -X- _ O
compact -X- _ O
cluster -X- _ O
. -X- _ O
linked -X- _ O
to -X- _ O
an -X- _ O
existing -X- _ O
entity -X- _ O
in -X- _ O
KB -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
labeled -X- _ O
with -X- _ O
all -X- _ O
possible -X- _ O
types -X- _ O
of -X- _ O
the -X- _ O
KB -X- _ O
entity -X- _ O
as -X- _ O
supervision -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
despite -X- _ O
its -X- _ O
efficiency -X- _ O
, -X- _ O
distant -X- _ O
supervision -X- _ O
also -X- _ O
brings -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
outof -X- _ O
- -X- _ O
context -X- _ O
noise -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
assigns -X- _ O
labels -X- _ O
in -X- _ O
a -X- _ O
context -X- _ O
agnostic -X- _ O
manner -X- _ O
. -X- _ O
Early -X- _ O
works -X- _ O
usually -X- _ O
ignore -X- _ O
such -X- _ O
noise -X- _ O
in -X- _ O
supervision -X- _ O
( -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Shimaoka -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
dampens -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
distantly -X- _ O
supervised -X- _ O
models -X- _ O
. -X- _ O
Towards -X- _ O
overcoming -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
context -X- _ O
noise -X- _ O
, -X- _ O
two -X- _ O
lines -X- _ O
of -X- _ O
work -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
distantly -X- _ O
supervised -X- _ O
FET -X- _ B-TaskName
. -X- _ O
The -X- _ O
first -X- _ O
kind -X- _ O
of -X- _ O
work -X- _ O
try -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
noisy -X- _ O
labels -X- _ O
using -X- _ O
heuristic -X- _ O
rules -X- _ O
( -X- _ O
Gillick -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
heuristic -X- _ O
pruning -X- _ O
significantly -X- _ O
reduces -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
can -X- _ O
not -X- _ O
make -X- _ O
full -X- _ O
use -X- _ O
of -X- _ O
distantly -X- _ O
annotated -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
thread -X- _ O
of -X- _ O
works -X- _ O
try -X- _ O
to -X- _ O
incorporate -X- _ O
such -X- _ O
imperfect -X- _ O
annotation -X- _ O
by -X- _ O
partiallabel -X- _ B-MetricName
loss -X- _ I-MetricName
( -X- _ O
PLL -X- _ B-MetricName
) -X- _ O
. -X- _ O
The -X- _ O
basic -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
noisy -X- _ O
mention -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
score -X- _ O
associated -X- _ O
with -X- _ O
its -X- _ O
candidate -X- _ O
types -X- _ O
should -X- _ O
be -X- _ O
greater -X- _ O
than -X- _ O
the -X- _ O
scores -X- _ O
associated -X- _ O
with -X- _ O
any -X- _ O
other -X- _ O
non -X- _ O
- -X- _ O
candidate -X- _ O
types -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
Abhishek -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
their -X- _ O
success -X- _ O
, -X- _ O
PLLbased -X- _ O
models -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
Confirmation -X- _ O
Bias -X- _ O
by -X- _ O
taking -X- _ O
its -X- _ O
own -X- _ O
prediction -X- _ O
as -X- _ O
optimization -X- _ O
objective -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
entity -X- _ O
mention -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
typing -X- _ O
system -X- _ O
selected -X- _ O
a -X- _ O
wrong -X- _ O
type -X- _ O
with -X- _ O
the -X- _ O
maximum -X- _ O
score -X- _ O
among -X- _ O
all -X- _ O
candidates -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
try -X- _ O
to -X- _ O
further -X- _ O
maximize -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
wrong -X- _ O
type -X- _ O
in -X- _ O
following -X- _ O
optimization -X- _ O
epoches -X- _ O
( -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
minimize -X- _ O
PLL -X- _ B-MetricName
) -X- _ O
, -X- _ O
thus -X- _ O
amplifying -X- _ O
the -X- _ O
confirmation -X- _ O
bias -X- _ O
. -X- _ O
Such -X- _ O
bias -X- _ O
starts -X- _ O
from -X- _ O
the -X- _ O
early -X- _ O
stage -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
typing -X- _ O
model -X- _ O
is -X- _ O
still -X- _ O
very -X- _ O
suboptimal -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
accumulate -X- _ O
in -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
Related -X- _ O
discussion -X- _ O
can -X- _ O
be -X- _ O
also -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2006 -X- _ O
; -X- _ O
Laine -X- _ O
and -X- _ O
Aila -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Tarvainen -X- _ O
and -X- _ O
Valpola -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
for -X- _ O
distantly -X- _ O
supervised -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
entity -X- _ O
typing -X- _ O
. -X- _ O
Enlightened -X- _ O
by -X- _ O
( -X- _ O
Kamnitsas -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
effectively -X- _ O
utilize -X- _ O
imperfect -X- _ O
annotation -X- _ O
as -X- _ O
model -X- _ O
regularization -X- _ O
via -X- _ O
Compact -X- _ O
Latent -X- _ O
Space -X- _ O
Clustering -X- _ O
( -X- _ O
CLSC -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
encourages -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
to -X- _ O
group -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
as -X- _ O
a -X- _ O
compact -X- _ O
cluster -X- _ O
( -X- _ O
dense -X- _ O
region -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
representation -X- _ O
space -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
better -X- _ O
classification -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
data -X- _ O
with -X- _ O
noisy -X- _ O
labels -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
generating -X- _ O
pseudo -X- _ O
supervision -X- _ O
by -X- _ O
the -X- _ O
typing -X- _ O
model -X- _ O
itself -X- _ O
, -X- _ O
we -X- _ O
dynamically -X- _ O
construct -X- _ O
a -X- _ O
similarity -X- _ O
- -X- _ O
weighted -X- _ O
graph -X- _ O
between -X- _ O
clean -X- _ O
and -X- _ O
noisy -X- _ O
mentions -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
label -X- _ O
propagation -X- _ O
on -X- _ O
the -X- _ O
graph -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
formation -X- _ O
of -X- _ O
compact -X- _ O
clusters -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
in -X- _ O
clustering -X- _ O
mentions -X- _ O
of -X- _ O
different -X- _ O
types -X- _ O
into -X- _ O
dense -X- _ O
regions -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
PLL -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
force -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
fit -X- _ O
pseudo -X- _ O
supervision -X- _ O
generated -X- _ O
by -X- _ O
itself -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
use -X- _ O
noisy -X- _ O
data -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
regularization -X- _ O
for -X- _ O
our -X- _ O
feature -X- _ O
extractor -X- _ O
layer -X- _ O
, -X- _ O
thus -X- _ O
avoiding -X- _ O
bias -X- _ O
accumulation -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
standard -X- _ O
benchmarks -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
consistently -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O
Further -X- _ O
study -X- _ O
reveals -X- _ O
that -X- _ O
, -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
over -X- _ O
the -X- _ O
competitors -X- _ O
gets -X- _ O
even -X- _ O
more -X- _ O
significant -X- _ O
as -X- _ O
the -X- _ O
portion -X- _ O
of -X- _ O
noisy -X- _ O
data -X- _ O
rises -X- _ O
. -X- _ O

This -X- _ O
last -X- _ O
run -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
features -X- _ O
as -X- _ O
the -X- _ O
previous -X- _ O
run -X- _ O
( -X- _ O
assigning -X- _ O
higher -X- _ O
relevances -X- _ O
to -X- _ O
corresponding -X- _ O
corpora -X- _ O
) -X- _ O
but -X- _ O
this -X- _ O
time -X- _ O
our -X- _ O
bilingual -X- _ O
lexicon -X- _ O
and -X- _ O
named -X- _ O
entities -X- _ O
database -X- _ O
was -X- _ O
included -X- _ O
for -X- _ O
term -X- _ O
coverage -X- _ O
improvement -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
alignment -X- _ O
based -X- _ O
on -X- _ O
cognates -X- _ O
( -X- _ O
Gomes -X- _ O
and -X- _ O
Lopes -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
About -X- _ O
our -X- _ O
bilingual -X- _ O
lexicon -X- _ O
, -X- _ O
considering -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
built -X- _ O
mainly -X- _ O
from -X- _ O
the -X- _ O
European -X- _ O
legislation -X- _ O
, -X- _ O
it -X- _ O
was -X- _ O
given -X- _ O
a -X- _ O
lower -X- _ O
relevance -X- _ O
because -X- _ O
past -X- _ O
experiences -X- _ O
have -X- _ O
shown -X- _ O
us -X- _ O
that -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
domain -X- _ O
is -X- _ O
not -X- _ O
shared -X- _ O
with -X- _ O
the -X- _ O
texts -X- _ O
to -X- _ O
be -X- _ O
translated -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
relevance -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
using -X- _ O
inadequate -X- _ O
terms -X- _ O
for -X- _ O
the -X- _ O
intended -X- _ O
translation -X- _ O
domain -X- _ O
or -X- _ O
subject -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
situation -X- _ O
that -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
confirmed -X- _ O
and -X- _ O
noted -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
between -X- _ O
dev -X- _ B-DatasetName
- -X- _ I-DatasetName
europarl -X- _ I-DatasetName
and -X- _ O
deveuroparl -X- _ B-DatasetName
- -X- _ I-DatasetName
low -X- _ I-DatasetName
: -X- _ O
reducing -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
europarl -X- _ B-DatasetName
contributed -X- _ O
to -X- _ O
a -X- _ O
slight -X- _ O
score -X- _ O
increase -X- _ O
compared -X- _ O
to -X- _ O
when -X- _ O
the -X- _ O
relevance -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
side -X- _ O
note -X- _ O
, -X- _ O
translating -X- _ O
the -X- _ O
tests -X- _ O
took -X- _ O
nearly -X- _ O
14 -X- _ O
hours -X- _ O
for -X- _ O
each -X- _ O
run -X- _ O
6 -X- _ O
. -X- _ O
Had -X- _ O
we -X- _ O
included -X- _ O
europarl -X- _ B-DatasetName
, -X- _ O
judging -X- _ O
by -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
have -X- _ O
taken -X- _ O
nearly -X- _ O
200 -X- _ O
hours -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
than -X- _ O
a -X- _ O
week -X- _ O
, -X- _ O
expecting -X- _ O
to -X- _ O
simply -X- _ O
gain -X- _ O
0.75 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
, -X- _ O
on -X- _ O
average -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
had -X- _ O
no -X- _ O
other -X- _ O
option -X- _ O
than -X- _ O
leaving -X- _ O
it -X- _ O
out -X- _ O
. -X- _ O
Such -X- _ O
increase -X- _ O
in -X- _ O
translation -X- _ O
time -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
substantial -X- _ O
increase -X- _ O
of -X- _ O
translation -X- _ O
equivalents -X- _ O
available -X- _ O
for -X- _ O
decoding -X- _ O
from -X- _ O
such -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
. -X- _ O
The -X- _ O
decision -X- _ O
to -X- _ O
carry -X- _ O
out -X- _ O
the -X- _ O
alignment -X- _ O
based -X- _ O
on -X- _ O
cognates -X- _ O
was -X- _ O
taken -X- _ O
because -X- _ O
after -X- _ O
a -X- _ O
first -X- _ O
run -X- _ O
of -X- _ O
tests -X- _ O
we -X- _ O
realized -X- _ O
that -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
untranslated -X- _ O
terms -X- _ O
referred -X- _ O
to -X- _ O
medical -X- _ O
terms -X- _ O
and -X- _ O
diseases -X- _ O
, -X- _ O
which -X- _ O
shared -X- _ O
many -X- _ O
letters -X- _ O
between -X- _ O
both -X- _ O
languages -X- _ O
and -X- _ O
therefore -X- _ O
had -X- _ O
a -X- _ O
high -X- _ O
level -X- _ O
of -X- _ O
cognaticity -X- _ O
. -X- _ O
All -X- _ O
these -X- _ O
changes -X- _ O
allowed -X- _ O
a -X- _ O
significant -X- _ O
reduction -X- _ O
of -X- _ O
the -X- _ O
unique -X- _ O
untranslated -X- _ O
terms -X- _ O
to -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
4700 -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
reasons -X- _ O
in -X- _ O
this -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
considered -X- _ O
this -X- _ O
run -X- _ O
as -X- _ O
being -X- _ O
our -X- _ O
best -X- _ O
. -X- _ O

Since -X- _ O
no -X- _ O
development -X- _ O
data -X- _ O
was -X- _ O
supplied -X- _ O
, -X- _ O
we -X- _ O
took -X- _ O
the -X- _ O
initiative -X- _ O
to -X- _ O
prepare -X- _ O
some -X- _ O
development -X- _ O
sets -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
have -X- _ O
an -X- _ O
idea -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
promising -X- _ O
set -X- _ O
of -X- _ O
parameters -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
over -X- _ O
the -X- _ O
provided -X- _ O
data -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
intended -X- _ O
translations -X- _ O
. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
several -X- _ O
documents -X- _ O
were -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
composed -X- _ O
by -X- _ O
the -X- _ O
medlinepubmed -X- _ O
, -X- _ O
biological -X- _ O
and -X- _ O
health -X- _ O
sets -X- _ O
, -X- _ O
applying -X- _ O
the -X- _ O
training -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
remaining -X- _ O
documents -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
selected -X- _ O
ones -X- _ O
to -X- _ O
translate -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
translations -X- _ O
against -X- _ O
their -X- _ O
originals -X- _ O
by -X- _ O
determining -X- _ O
their -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
scores -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
clearer -X- _ O
picture -X- _ O
of -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
results -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
expected -X- _ O
, -X- _ O
some -X- _ O
additional -X- _ O
tests -X- _ O
were -X- _ O
carried -X- _ O
out -X- _ O
including -X- _ O
the -X- _ O
selected -X- _ O
set -X- _ O
of -X- _ O
documents -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
translation -X- _ O
model -X- _ O
supports -X- _ O
: -X- _ O
a -X- _ O
conservative -X- _ O
extraction -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
restrictive -X- _ O
, -X- _ O
allowing -X- _ O
fewer -X- _ O
translation -X- _ O
equivalents -X- _ O
, -X- _ O
having -X- _ O
a -X- _ O
lower -X- _ O
recall -X- _ B-MetricName
but -X- _ O
a -X- _ O
higher -X- _ O
precision -X- _ B-MetricName
; -X- _ O
and -X- _ O
a -X- _ O
flexible -X- _ O
extraction -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
permissive -X- _ O
, -X- _ O
allowing -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
equivalents -X- _ O
but -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
an -X- _ O
increase -X- _ O
of -X- _ O
incorrect -X- _ O
ones -X- _ O
. -X- _ O
We -X- _ O
were -X- _ O
interested -X- _ O
in -X- _ O
evaluating -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
both -X- _ O
approaches -X- _ O
on -X- _ O
results -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
average -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
translation -X- _ O
directions -X- _ O
of -X- _ O
those -X- _ O
preliminary -X- _ O
tests -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
conservative -X- _ O
( -X- _ O
cons -X- _ O
. -X- _ O
) -X- _ O
and -X- _ O
flexible -X- _ O
( -X- _ O
flex -X- _ O
. -X- _ O
) -X- _ O
approaches -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
times -X- _ O
taken -X- _ O
to -X- _ O
translate -X- _ O
the -X- _ O
documents -X- _ O
on -X- _ O
either -X- _ O
extraction -X- _ O
approaches -X- _ O
. -X- _ O
Those -X- _ O
results -X- _ O
concern -X- _ O
the -X- _ O
following -X- _ O
configurations -X- _ O
: -X- _ O
full -X- _ O
: -X- _ O
the -X- _ O
documents -X- _ O
used -X- _ O
for -X- _ O
testing -X- _ O
were -X- _ O
not -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
( -X- _ O
medlinepubmed -X- _ O
, -X- _ O
biological -X- _ O
and -X- _ O
health -X- _ O
) -X- _ O
; -X- _ O
dev -X- _ O
: -X- _ O
the -X- _ O
documents -X- _ O
used -X- _ O
for -X- _ O
testing -X- _ O
were -X- _ O
removed -X- _ O
form -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
; -X- _ O
dev -X- _ B-DatasetName
- -X- _ I-DatasetName
europarl -X- _ I-DatasetName
: -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
dev -X- _ O
, -X- _ O
but -X- _ O
including -X- _ O
the -X- _ O
europarl -X- _ B-DatasetName
corpus -X- _ O
; -X- _ O
and -X- _ O
dev -X- _ B-DatasetName
- -X- _ I-DatasetName
europarl -X- _ I-DatasetName
- -X- _ I-DatasetName
low -X- _ I-DatasetName
: -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
dev -X- _ B-DatasetName
- -X- _ I-DatasetName
europarl -X- _ I-DatasetName
, -X- _ O
but -X- _ O
assigned -X- _ O
a -X- _ O
lower -X- _ O
relevance -X- _ O
to -X- _ O
the -X- _ O
europarl -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O
These -X- _ O
preliminary -X- _ O
tests -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
flexible -X- _ O
extraction -X- _ O
approach -X- _ O
produced -X- _ O
on -X- _ O
average -X- _ O
better -X- _ O
translation -X- _ O
results -X- _ O
when -X- _ O
the -X- _ O
reference -X- _ O
documents -X- _ O
were -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
normal -X- _ O
testing -X- _ O
situation -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
flexible -X- _ O
approach -X- _ O
. -X- _ O
The -X- _ O
Europarl -X- _ B-DatasetName
corpus -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
significantly -X- _ O
larger -X- _ O
( -X- _ O
54 -X- _ O
, -X- _ O
543 -X- _ O
, -X- _ O
044 -X- _ O
words -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
60 -X- _ O
, -X- _ O
375 -X- _ O
, -X- _ O
477 -X- _ O
words -X- _ O
in -X- _ O
Portuguese -X- _ O
) -X- _ O
, -X- _ O
was -X- _ O
tested -X- _ O
as -X- _ O
a -X- _ O
source -X- _ O
of -X- _ O
additional -X- _ O
term -X- _ O
coverage -X- _ O
, -X- _ O
which -X- _ O
allowed -X- _ O
a -X- _ O
translation -X- _ O
quality -X- _ O
improvement -X- _ O
lower -X- _ O
than -X- _ O
1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
point -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
given -X- _ O
its -X- _ O
significant -X- _ O
increase -X- _ O
in -X- _ O
processing -X- _ O
time -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
large -X- _ O
size -X- _ O
, -X- _ O
a -X- _ O
time -X- _ O
increase -X- _ O
around -X- _ O
14 -X- _ O
times -X- _ O
larger -X- _ O
, -X- _ O
we -X- _ O
had -X- _ O
to -X- _ O
drop -X- _ O
it -X- _ O
from -X- _ O
the -X- _ O
submission -X- _ O
tests -X- _ O
due -X- _ O
to -X- _ O
deadline -X- _ O
constraints -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
assigning -X- _ O
a -X- _ O
lower -X- _ O
relevance -X- _ O
to -X- _ O
a -X- _ O
corpus -X- _ O
from -X- _ O
a -X- _ O
totally -X- _ O
different -X- _ O
domain -X- _ O
may -X- _ O
have -X- _ O
some -X- _ O
positive -X- _ O
impact -X- _ O
on -X- _ O
average -X- _ O
results -X- _ O
. -X- _ O
Once -X- _ O
we -X- _ O
have -X- _ O
decided -X- _ O
, -X- _ O
from -X- _ O
this -X- _ O
initial -X- _ O
testing -X- _ O
preparation -X- _ O
, -X- _ O
which -X- _ O
would -X- _ O
be -X- _ O
the -X- _ O
most -X- _ O
promising -X- _ O
and -X- _ O
interesting -X- _ O
features -X- _ O
to -X- _ O
use -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
runs -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
the -X- _ O
training -X- _ O
processes -X- _ O
again -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
documents -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
left -X- _ O
out -X- _ O
, -X- _ O
this -X- _ O
way -X- _ O
using -X- _ O
the -X- _ O
full -X- _ O
data -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
organizers -X- _ O
for -X- _ O
the -X- _ O
runs -X- _ O
to -X- _ O
be -X- _ O
submitted -X- _ O
. -X- _ O

Our -X- _ O
EN -X- _ O
- -X- _ O
PT -X- _ O
input -X- _ O
lexicon -X- _ O
has -X- _ O
931 -X- _ O
, -X- _ O
568 -X- _ O
manually -X- _ O
validated -X- _ O
translations -X- _ O
( -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
lexicon -X- _ O
has -X- _ O
been -X- _ O
compiled -X- _ O
in -X- _ O
a -X- _ O
long -X- _ O
term -X- _ O
effort -X- _ O
started -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
project -X- _ O
ISTRION -X- _ B-DatasetName
2 -X- _ O
. -X- _ O
The -X- _ O
translations -X- _ O
were -X- _ O
extracted -X- _ O
automatically -X- _ O
from -X- _ O
several -X- _ O
corpora -X- _ O
, -X- _ O
including -X- _ O
Europarl -X- _ B-DatasetName
( -X- _ O
Koehn -X- _ O
and -X- _ O
Monz -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
JRC -X- _ B-DatasetName
- -X- _ I-DatasetName
Acquis -X- _ I-DatasetName
( -X- _ O
Steinberger -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
OPUS -X- _ B-DatasetName
EMEA -X- _ I-DatasetName
( -X- _ O
Tiedemann -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
and -X- _ O
others -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
complementary -X- _ O
alignment -X- _ O
and -X- _ O
extraction -X- _ O
methods -X- _ O
: -X- _ O
GIZA -X- _ O
( -X- _ O
Och -X- _ O
and -X- _ O
Ney -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
Anymalign -X- _ O
( -X- _ O
Lardilleux -X- _ O
and -X- _ O
Lepage -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
spelling -X- _ O
similarity -X- _ O
measure -X- _ O
SpSim -X- _ O
( -X- _ O
Gomes -X- _ O
and -X- _ O
Lopes -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
combined -X- _ O
with -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
Dice -X- _ O
measure -X- _ O
, -X- _ O
and -X- _ O
others -X- _ O
. -X- _ O
The -X- _ O
automatically -X- _ O
extracted -X- _ O
word -X- _ O
and -X- _ O
phrasal -X- _ O
translations -X- _ O
were -X- _ O
automatically -X- _ O
classified -X- _ O
, -X- _ O
prior -X- _ O
to -X- _ O
human -X- _ O
validation -X- _ O
, -X- _ O
using -X- _ O
an -X- _ O
SVM -X- _ O
classifier -X- _ O
trained -X- _ O
on -X- _ O
previously -X- _ O
validated -X- _ O
translations -X- _ O
as -X- _ O
described -X- _ O
by -X- _ O
Mahesh -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
automatic -X- _ O
classification -X- _ O
speeds -X- _ O
up -X- _ O
human -X- _ O
validation -X- _ O
because -X- _ O
very -X- _ O
few -X- _ O
translations -X- _ O
( -X- _ O
less -X- _ O
than -X- _ O
5 -X- _ O
% -X- _ O
) -X- _ O
are -X- _ O
incorrectly -X- _ O
classified -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
those -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
manually -X- _ O
labeled -X- _ O
as -X- _ O
correct -X- _ O
or -X- _ O
incorrect -X- _ O
. -X- _ O
We -X- _ O
did -X- _ O
not -X- _ O
perform -X- _ O
any -X- _ O
extraction -X- _ O
or -X- _ O
validation -X- _ O
of -X- _ O
new -X- _ O
translations -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
provided -X- _ O
for -X- _ O
this -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
did -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
complement -X- _ O
our -X- _ O
lexicon -X- _ O
with -X- _ O
cognate -X- _ O
and -X- _ O
homograph -X- _ O
alignments -X- _ O
using -X- _ O
the -X- _ O
SpSim -X- _ B-MetricName
( -X- _ O
Gomes -X- _ O
and -X- _ O
Lopes -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
spelling -X- _ O
similarity -X- _ O
measure -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
knowledge -X- _ O
retrieval -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
retrieve -X- _ O
top -X- _ O
- -X- _ O
10 -X- _ O
related -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
KB -X- _ O
. -X- _ O
For -X- _ O
iterative -X- _ B-TaskName
entity -X- _ I-TaskName
retrieval -X- _ I-TaskName
, -X- _ O
we -X- _ O
set -X- _ O
T -X- _ B-MetricName
= -X- _ O
2 -X- _ B-MetricValue
. -X- _ O
In -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ O
rate -X- _ O
of -X- _ O
5 -X- _ O
× -X- _ O
10 -X- _ O
−5 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
NER -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ O
rate -X- _ O
of -X- _ O
5 -X- _ O
× -X- _ O
10 -X- _ O
−6 -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
embeddings -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.05 -X- _ B-HyperparameterValue
to -X- _ O
update -X- _ O
the -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
CRF -X- _ O
layer -X- _ O
following -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
NER -X- _ B-TaskName
model -X- _ O
built -X- _ O
by -X- _ O
our -X- _ O
system -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
and -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPU -X- _ O
with -X- _ O
16 -X- _ O
GB -X- _ O
memory -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
ensemble -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
about -X- _ O
10 -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
track -X- _ O
. -X- _ O
A. -X- _ O
( -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
ELMo -X- _ O
embeddings -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Che -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
embeddings -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
embeddings -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
data -X- _ O
by -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
finetuning -X- _ I-MethodName
. -X- _ O
We -X- _ O
only -X- _ O
feed -X- _ O
the -X- _ O
knowledge -X- _ O
- -X- _ O
based -X- _ O
input -X- _ O
into -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
embeddings -X- _ O
and -X- _ O
feed -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
into -X- _ O
other -X- _ O
embeddings -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
embeddings -X- _ O
( -X- _ O
especially -X- _ O
for -X- _ O
LSTM -X- _ O
- -X- _ O
based -X- _ O
embeddings -X- _ O
such -X- _ O
as -X- _ O
Flair -X- _ O
and -X- _ O
ELMo -X- _ O
) -X- _ O
to -X- _ O
encode -X- _ O
such -X- _ O
a -X- _ O
long -X- _ O
input -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Bi -X- _ O
- -X- _ O
LSTM -X- _ O
encoder -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
concatenated -X- _ O
embeddings -X- _ O
with -X- _ O
a -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
1 -X- _ O
, -X- _ O
000 -X- _ O
and -X- _ O
then -X- _ O
feed -X- _ O
the -X- _ O
output -X- _ O
token -X- _ O
representations -X- _ O
into -X- _ O
the -X- _ O
CRF -X- _ O
layer -X- _ O
. -X- _ O
Following -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
efforts -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
SGD -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
ACE -X- _ O
, -X- _ O
we -X- _ O
search -X- _ O
the -X- _ O
embedding -X- _ O
concatenation -X- _ O
for -X- _ O
30 -X- _ O
episodes -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
context -X- _ O
processing -X- _ O
options -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
matched -X- _ O
paragraph -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
matched -X- _ O
sentence -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
matched -X- _ O
sentence -X- _ O
but -X- _ O
remove -X- _ O
the -X- _ O
wiki -X- _ O
anchors -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
three -X- _ O
options -X- _ O
as -X- _ O
PARA -X- _ O
, -X- _ O
SENT -X- _ O
and -X- _ O
SENT -X- _ O
- -X- _ O
LINK -X- _ O
respectively -X- _ O
. -X- _ O
Entity -X- _ B-TaskName
Retrieval -X- _ I-TaskName
with -X- _ O
Gold -X- _ O
Entities -X- _ O
We -X- _ O
use -X- _ O
gold -X- _ O
entities -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
to -X- _ O
see -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
the -X- _ O
most -X- _ O
ideal -X- _ O
scenario -X- _ O
for -X- _ O
iterative -X- _ O
retrieval -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
this -X- _ O
process -X- _ O
as -X- _ O
ITER -X- _ B-MethodName
G -X- _ I-MethodName
and -X- _ O
use -X- _ O
PARA -X- _ B-MethodName
for -X- _ O
the -X- _ O
context -X- _ O
type -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
For -X- _ O
the -X- _ O
three -X- _ O
context -X- _ O
options -X- _ O
, -X- _ O
PARA -X- _ B-MethodName
is -X- _ O
the -X- _ O
best -X- _ O
option -X- _ O
for -X- _ O
EN -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
NL -X- _ O
, -X- _ O
RU -X- _ O
, -X- _ O
TR -X- _ O
, -X- _ O
KO -X- _ O
, -X- _ O
FA -X- _ O
, -X- _ O
MIX -X- _ O
and -X- _ O
MULTI -X- _ O
. -X- _ O
SENT -X- _ B-MethodName
- -X- _ I-MethodName
LINK -X- _ I-MethodName
is -X- _ O
the -X- _ O
best -X- _ O
option -X- _ O
for -X- _ O
HI -X- _ O
and -X- _ O
BN -X- _ O
. -X- _ O
For -X- _ O
DE -X- _ O
and -X- _ O
ZH -X- _ O
, -X- _ O
SENT -X- _ B-MethodName
and -X- _ O
SENT -X- _ B-MethodName
- -X- _ I-MethodName
LINK -X- _ I-MethodName
are -X- _ O
competitive -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
SENT -X- _ B-MethodName
for -X- _ O
the -X- _ O
two -X- _ O
languages -X- _ O
since -X- _ O
we -X- _ O
believe -X- _ O
the -X- _ O
wiki -X- _ O
anchors -X- _ O
from -X- _ O
the -X- _ O
Wikipedia -X- _ O
can -X- _ O
help -X- _ O
model -X- _ O
performance -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
Comparing -X- _ O
with -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
Google -X- _ O
Search -X- _ O
can -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
best -X- _ O
context -X- _ O
option -X- _ O
of -X- _ O
each -X- _ O
track -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
Wikipedia -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
online -X- _ O
search -X- _ O
engine -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
For -X- _ O
ITER -X- _ B-MethodName
G -X- _ I-MethodName
, -X- _ O
we -X- _ O
can -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
context -X- _ O
can -X- _ O
further -X- _ O
Iterative -X- _ B-TaskName
Entity -X- _ I-TaskName
Retrieval -X- _ I-TaskName
with -X- _ O
Predicted -X- _ O
Entities -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
analyze -X- _ O
how -X- _ O
the -X- _ O
predicted -X- _ O
entity -X- _ O
mentions -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
retrieval -X- _ O
quality -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
iterative -X- _ O
entity -X- _ O
retrieval -X- _ O
with -X- _ O
predicted -X- _ O
mentions -X- _ O
as -X- _ O
ITER -X- _ B-MethodName
P -X- _ I-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
T -X- _ B-HyperparameterName
= -X- _ O
2 -X- _ B-HyperparameterValue
. -X- _ O
12 -X- _ O
We -X- _ O
extract -X- _ O
the -X- _ O
predicted -X- _ O
mentions -X- _ O
of -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
from -X- _ O
the -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
best -X- _ O
context -X- _ O
option -X- _ O
for -X- _ O
each -X- _ O
track -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
the -X- _ O
experiments -X- _ O
over -X- _ O
HI -X- _ O
, -X- _ O
BN -X- _ O
and -X- _ O
MIX -X- _ O
which -X- _ O
have -X- _ O
significant -X- _ O
improvement -X- _ O
with -X- _ O
ITER -X- _ B-MethodName
G -X- _ I-MethodName
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
list -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ITER -X- _ B-MethodName
G -X- _ I-MethodName
for -X- _ O
reference -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
using -X- _ O
the -X- _ O
predicted -X- _ O
mentions -X- _ O
with -X- _ O
100 -X- _ O
% -X- _ O
accuracy -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
only -X- _ O
MIX -X- _ B-MethodName
can -X- _ O
be -X- _ O
improved -X- _ O
. -X- _ O
Since -X- _ O
iterative -X- _ O
entity -X- _ O
retrieval -X- _ O
uses -X- _ O
predicted -X- _ O
mentions -X- _ O
as -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
retrieval -X- _ O
query -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
mention -X- _ O
detection -X- _ O
directly -X- _ O
affects -X- _ O
the -X- _ O
retrieval -X- _ O
quality -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
observation -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
mention -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
with -X- _ O
sentence -X- _ O
retrieval -X- _ O
. -X- _ O
For -X- _ O
comparison -X- _ O
with -X- _ O
mention -X- _ O
detection -X- _ O
performance -X- _ O
of -X- _ O
NER -X- _ B-TaskName
models -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
train -X- _ O
mention -X- _ O
detection -X- _ O
models -X- _ O
by -X- _ O
discarding -X- _ O
the -X- _ O
entity -X- _ O
labels -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
suspect -X- _ O
the -X- _ O
low -X- _ O
mention -X- _ O
F1 -X- _ B-MetricName
introduces -X- _ O
noises -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
retrieval -X- _ O
module -X- _ O
for -X- _ O
BN -X- _ O
and -X- _ O
HI -X- _ O
, -X- _ O
which -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
decline -X- _ O
of -X- _ O
performance -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
mention -X- _ O
F1 -X- _ B-MetricName
of -X- _ O
mention -X- _ O
detection -X- _ O
models -X- _ O
( -X- _ O
second -X- _ O
row -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
only -X- _ O
outperform -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
( -X- _ O
first -X- _ O
row -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
moderate -X- _ O
scale -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
ITER -X- _ B-MethodName
models -X- _ O
only -X- _ O
for -X- _ O
the -X- _ O
code -X- _ O
- -X- _ O
mixed -X- _ O
track -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
with -X- _ O
sentence -X- _ O
retrieval -X- _ O
to -X- _ O
predict -X- _ O
mentions -X- _ O
. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
the -X- _ O
retrieval -X- _ O
results -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
character -X- _ B-MetricName
- -X- _ I-MetricName
level -X- _ I-MetricName
relevance -X- _ I-MetricName
metric -X- _ O
, -X- _ O
which -X- _ O
calculates -X- _ O
the -X- _ O
Intersectionover -X- _ O
- -X- _ O
Union -X- _ O
( -X- _ O
IoU -X- _ O
) -X- _ O
between -X- _ O
the -X- _ O
characters -X- _ O
of -X- _ O
query -X- _ O
and -X- _ O
result -X- _ O
. -X- _ O
Assuming -X- _ O
that -X- _ O
the -X- _ O
character -X- _ O
sets -X- _ O
11 -X- _ O
of -X- _ O
query -X- _ O
and -X- _ O
retrieval -X- _ O
result -X- _ O
are -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
respectively -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
IoU -X- _ O
is -X- _ O
A∩B -X- _ O
A∪B -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
the -X- _ O
character -X- _ B-MetricName
- -X- _ I-MetricName
level -X- _ I-MetricName
IoU -X- _ I-MetricName
of -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
its -X- _ O
top -X- _ O
- -X- _ O
1 -X- _ O
retrieval -X- _ O
result -X- _ O
on -X- _ O
all -X- _ O
tracks -X- _ O
, -X- _ O
and -X- _ O
plot -X- _ O
its -X- _ O
distribution -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
the -X- _ O
following -X- _ O
observations -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
IoU -X- _ B-MetricName
values -X- _ O
are -X- _ O
concentrated -X- _ O
around -X- _ O
1.0 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
of -X- _ O
EN -X- _ O
, -X- _ O
ES -X- _ O
, -X- _ O
NL -X- _ O
, -X- _ O
RU -X- _ O
, -X- _ O
TR -X- _ O
, -X- _ O
KO -X- _ O
, -X- _ O
FA -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
samples -X- _ O
were -X- _ O
derived -X- _ O
from -X- _ O
Wikipedia -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
by -X- _ O
retrieving -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
original -X- _ O
documents -X- _ O
for -X- _ O
these -X- _ O
samples -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
data -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
for -X- _ O
most -X- _ O
languages -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
TR -X- _ O
. -X- _ O
On -X- _ O
TR -X- _ O
, -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
IoU -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
samples -X- _ O
and -X- _ O
query -X- _ O
results -X- _ O
cluster -X- _ O
at -X- _ O
around -X- _ O
0.5 -X- _ B-MetricValue
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
TR -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
still -X- _ O
performs -X- _ O
strongly -X- _ O
on -X- _ O
this -X- _ O
language -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
mitigate -X- _ O
the -X- _ O
difficulties -X- _ O
caused -X- _ O
11 -X- _ O
The -X- _ O
sets -X- _ O
take -X- _ O
repeat -X- _ O
characters -X- _ O
as -X- _ O
different -X- _ O
characters -X- _ O
. -X- _ O
by -X- _ O
inconsistent -X- _ O
data -X- _ O
distribution -X- _ O
by -X- _ O
retrieving -X- _ O
the -X- _ O
context -X- _ O
from -X- _ O
Wikipedia -X- _ O
. -X- _ O

To -X- _ O
further -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
knowledgebased -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
relative -X- _ O
improvements -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
over -X- _ O
our -X- _ O
baseline -X- _ O
system -X- _ O
on -X- _ O
each -X- _ O
domain -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
sets -X- _ O
have -X- _ O
more -X- _ O
relative -X- _ O
improvements -X- _ O
than -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
Wikipedia -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
LOWNER -X- _ B-DatasetName
domain -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
domain -X- _ O
as -X- _ O
the -X- _ O
KB -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
has -X- _ O
very -X- _ O
strong -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Per -X- _ O
- -X- _ O
domain -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ I-MetricName
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
and -X- _ O
our -X- _ O
baseline -X- _ O
system -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
. -X- _ O
∆ -X- _ B-MetricName
represents -X- _ O
the -X- _ O
relative -X- _ O
improvements -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
system -X- _ O
. -X- _ O
transferability -X- _ O
to -X- _ O
other -X- _ O
domains -X- _ O
such -X- _ O
as -X- _ O
web -X- _ O
questions -X- _ O
and -X- _ O
user -X- _ O
queries -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
performance -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
domains -X- _ O
, -X- _ O
the -X- _ O
ORCAS -X- _ B-DatasetName
domain -X- _ O
has -X- _ O
the -X- _ O
lowest -X- _ O
score -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
challenges -X- _ O
in -X- _ O
recognizing -X- _ O
named -X- _ O
entities -X- _ O
in -X- _ O
user -X- _ O
queries -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
retrieved -X- _ O
documents -X- _ O
in -X- _ O
KB -X- _ O
can -X- _ O
significantly -X- _ O
ease -X- _ O
the -X- _ O
challenges -X- _ O
in -X- _ O
this -X- _ O
domain -X- _ O
and -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
highest -X- _ O
improvement -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
domains -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
55 -X- _ O
teams -X- _ O
that -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
limited -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
compare -X- _ O
our -X- _ O
system -X- _ O
with -X- _ O
the -X- _ O
systems -X- _ O
from -X- _ O
teams -X- _ O
USTC -X- _ O
- -X- _ O
NELSLIP -X- _ O
, -X- _ O
RACAI -X- _ O
and -X- _ O
Sliced -X- _ O
10 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
postevaluation -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
a -X- _ O
baseline -X- _ O
system -X- _ O
without -X- _ O
using -X- _ O
the -X- _ O
knowledge -X- _ B-TaskName
retrieval -X- _ I-TaskName
module -X- _ O
to -X- _ O
further -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
knowledgebased -X- _ O
system -X- _ O
. -X- _ O
The -X- _ O
official -X- _ O
results -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
baseline -X- _ O
system -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Our -X- _ O
system -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
10 -X- _ O
out -X- _ O
of -X- _ O
13 -X- _ O
tracks -X- _ O
and -X- _ O
is -X- _ O
competitive -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
3 -X- _ O
tracks -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
outperforms -X- _ O
our -X- _ O
baseline -X- _ O
by -X- _ O
14.39 -X- _ B-HyperparameterValue
F1 -X- _ B-MetricName
on -X- _ O
average -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
knowledge -X- _ O
retrieval -X- _ O
module -X- _ O
is -X- _ O
extremely -X- _ O
helpful -X- _ O
for -X- _ O
disambiguating -X- _ O
complex -X- _ O
entities -X- _ O
leading -X- _ O
to -X- _ O
significant -X- _ O
improvement -X- _ O
on -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

NER -X- _ B-TaskName
Model -X- _ O
Training -X- _ O
Before -X- _ O
building -X- _ O
the -X- _ O
final -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
these -X- _ O
variant -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
3 -X- _ O
times -X- _ O
each -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
averaged -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
dataset -X- _ O
sizes -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
multilingual -X- _ O
, -X- _ O
monolingual -X- _ O
and -X- _ O
code -X- _ O
- -X- _ O
mixed -X- _ O
models -X- _ O
respectively -X- _ O
. -X- _ O
Our -X- _ O
final -X- _ O
NER -X- _ B-TaskName
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
combined -X- _ O
dataset -X- _ O
including -X- _ O
both -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
on -X- _ O
each -X- _ O
track -X- _ O
to -X- _ O
fully -X- _ O
utilize -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
macro -X- _ O
F1 -X- _ B-MetricName
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
during -X- _ O
training -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
checkpoint -X- _ O
. -X- _ O
For -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
combined -X- _ O
dataset -X- _ O
, -X- _ O
Continue -X- _ O
Pretraining -X- _ O
To -X- _ O
make -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
learn -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
on -X- _ O
the -X- _ O
monolingual -X- _ O
tracks -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
corpus -X- _ O
to -X- _ O
continue -X- _ O
pretrain -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R. -X- _ I-MethodName
Specifically -X- _ O
, -X- _ O
we -X- _ O
collocate -X- _ O
all -X- _ O
sentences -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
languages -X- _ O
, -X- _ O
then -X- _ O
cut -X- _ O
the -X- _ O
text -X- _ O
into -X- _ O
chunks -X- _ O
of -X- _ O
fixed -X- _ O
length -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
text -X- _ O
chunks -X- _ O
using -X- _ O
the -X- _ O
Masked -X- _ B-MetricName
Language -X- _ I-MetricName
Modeling -X- _ I-MetricName
objective -X- _ I-MetricName
. -X- _ O
We -X- _ O
continue -X- _ O
pretrain -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
continue -X- _ O
pretrained -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
initialization -X- _ O
of -X- _ O
the -X- _ O
multilingual -X- _ O
7 -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
detailed -X- _ O
settings -X- _ O
. -X- _ O
models -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

Given -X- _ O
predictions -X- _ O
{ -X- _ O
ŷ -X- _ O
θ -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
ŷ -X- _ O
θm -X- _ O
} -X- _ O
from -X- _ O
m -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
majority -X- _ O
voting -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
final -X- _ O
predictionŷ -X- _ O
. -X- _ O
We -X- _ O
convert -X- _ O
the -X- _ O
label -X- _ O
sequences -X- _ O
into -X- _ O
entity -X- _ O
spans -X- _ O
to -X- _ O
perform -X- _ O
majority -X- _ O
voting -X- _ O
. -X- _ O
Following -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
module -X- _ O
ranks -X- _ O
all -X- _ O
spans -X- _ O
in -X- _ O
the -X- _ O
predictions -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
votes -X- _ O
in -X- _ O
descending -X- _ O
order -X- _ O
and -X- _ O
selects -X- _ O
the -X- _ O
spans -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
50 -X- _ O
% -X- _ O
votes -X- _ O
into -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
. -X- _ O
The -X- _ O
spans -X- _ O
with -X- _ O
more -X- _ O
votes -X- _ O
are -X- _ O
kept -X- _ O
if -X- _ O
the -X- _ O
selected -X- _ O
spans -X- _ O
have -X- _ O
overlaps -X- _ O
and -X- _ O
the -X- _ O
longer -X- _ O
spans -X- _ O
are -X- _ O
kept -X- _ O
if -X- _ O
the -X- _ O
spans -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
votes -X- _ O
. -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
containing -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
questions -X- _ O
; -X- _ O
ORCAS -X- _ B-DatasetName
( -X- _ O
Search -X- _ B-TaskName
Query -X- _ I-TaskName
NER -X- _ I-TaskName
) -X- _ O
contains -X- _ O
user -X- _ O
queries -X- _ O
from -X- _ O
Microsoft -X- _ O
Bing -X- _ O
( -X- _ O
Craswell -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
MSQ -X- _ B-DatasetName
and -X- _ O
ORCAS -X- _ B-DatasetName
samples -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
out -X- _ O
- -X- _ O
ofdomain -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
only -X- _ O
contain -X- _ O
a -X- _ O
small -X- _ O
collection -X- _ O
of -X- _ O
samples -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
domains -X- _ O
and -X- _ O
mainly -X- _ O
contain -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
LOWNER -X- _ B-DatasetName
domain -X- _ O
. -X- _ O
The -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
contains -X- _ O
much -X- _ O
more -X- _ O
MSQ -X- _ B-DatasetName
and -X- _ O
ORCAS -X- _ B-DatasetName
samples -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
are -X- _ O
evaluated -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
- -X- _ O
level -X- _ O
macro -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
, -X- _ O
which -X- _ O
treat -X- _ O
all -X- _ O
the -X- _ O
labels -X- _ O
equally -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
NER -X- _ B-TaskName
datasets -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CoNLL -X- _ B-DatasetName
2002CoNLL -X- _ B-DatasetName
, -X- _ O
2003 -X- _ O
are -X- _ O
evaluated -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
- -X- _ O
level -X- _ O
micro -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
, -X- _ O
which -X- _ O
emphasize -X- _ O
common -X- _ O
labels -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
large -X- _ I-MethodName
as -X- _ O
the -X- _ O
embedding -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
tracks -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
multilingual -X- _ O
model -X- _ O
and -X- _ O
is -X- _ O
applicable -X- _ O
to -X- _ O
all -X- _ O
tracks -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
x -X- _ O
and -X- _ O
the -X- _ O
retrieved -X- _ O
contexts -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
x -X- _ O
k -X- _ O
} -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
separator -X- _ O
token -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
" -X- _ O
< -X- _ O
/s -X- _ O
> -X- _ O
" -X- _ O
in -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
) -X- _ O
between -X- _ O
them -X- _ O
and -X- _ O
concatenated -X- _ O
them -X- _ O
together -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
inputx -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
module -X- _ O
. -X- _ O
We -X- _ O
chunk -X- _ O
retrieved -X- _ O
texts -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
subtoken -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
exceeding -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
subtoken -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
in -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
( -X- _ O
i.e. -X- _ O
, -X- _ O
512 -X- _ B-HyperparameterValue
in -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
) -X- _ O
. -X- _ O
Our -X- _ O
system -X- _ O
regards -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
labeling -X- _ O
problem -X- _ O
. -X- _ O
The -X- _ O
embedding -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
NER -X- _ B-TaskName
module -X- _ O
encode -X- _ O
the -X- _ O
concatenated -X- _ O
sequencẽ -X- _ O
x -X- _ O
and -X- _ O
output -X- _ O
the -X- _ O
corresponding -X- _ O
token -X- _ O
representa -X- _ O
- -X- _ O
tions -X- _ O
{ -X- _ O
v -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
v -X- _ O
n -X- _ O
, -X- _ O
} -X- _ O
. -X- _ O
The -X- _ O
module -X- _ O
then -X- _ O
feeds -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
{ -X- _ O
v -X- _ O
1 -X- _ O
, -X- _ O
, -X- _ O
v -X- _ O
n -X- _ O
} -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
linear -X- _ B-MethodName
- -X- _ I-MethodName
chain -X- _ I-MethodName
CRF -X- _ I-MethodName
layer -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
: -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
′ -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
W -X- _ O
T -X- _ O
y -X- _ O
v -X- _ O
i -X- _ O
+ -X- _ O
b -X- _ O
y -X- _ O
′ -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
y -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
n -X- _ O
i=1 -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
i−1 -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
) -X- _ O
y -X- _ O
′ -X- _ O
Y -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
n -X- _ O
i=1 -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
′ -X- _ O
i−1 -X- _ O
, -X- _ O
y -X- _ O
′ -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
) -X- _ O
where -X- _ O
θ -X- _ O
represents -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
and -X- _ O
Y -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
label -X- _ O
sequences -X- _ O
given -X- _ O
x. -X- _ O
In -X- _ O
the -X- _ O
potential -X- _ O
function -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
′ -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
W -X- _ O
T -X- _ O
y -X- _ O
v -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
emission -X- _ O
score -X- _ O
and -X- _ O
b -X- _ O
y -X- _ O
′ -X- _ O
, -X- _ O
y -X- _ O
is -X- _ O
the -X- _ O
transition -X- _ O
score -X- _ O
, -X- _ O
where -X- _ O
W -X- _ O
T -X- _ O
R -X- _ O
t×d -X- _ O
and -X- _ O
b -X- _ O
R -X- _ O
t×t -X- _ O
are -X- _ O
parameters -X- _ O
and -X- _ O
the -X- _ O
subscripts -X- _ O
y -X- _ O
′ -X- _ O
and -X- _ O
y -X- _ O
are -X- _ O
the -X- _ O
indices -X- _ O
of -X- _ O
the -X- _ O
matrices -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
negative -X- _ B-MetricName
log -X- _ I-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
loss -X- _ I-MetricName
L -X- _ O
NLL -X- _ B-MetricName
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
y -X- _ O
* -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
concatenated -X- _ O
input -X- _ O
sequence -X- _ O
with -X- _ O
gold -X- _ O
labels -X- _ O
y -X- _ O
* -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
predictionŷ -X- _ O
θ -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
Viterbi -X- _ O
decoding -X- _ O
. -X- _ O

NER -X- _ B-TaskName
( -X- _ O
Sundheim -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
fundamental -X- _ O
task -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
has -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
applications -X- _ O
in -X- _ O
various -X- _ O
domains -X- _ O
such -X- _ O
as -X- _ O
social -X- _ O
media -X- _ O
( -X- _ O
Derczynski -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
news -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
Ecommerce -X- _ O
( -X- _ O
Fetahu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
medical -X- _ O
domains -X- _ O
( -X- _ O
Dogan -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
pretrained -X- _ O
contextual -X- _ O
embeddings -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
and -X- _ O
LUKE -X- _ O
( -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
significantly -X- _ O
improved -X- _ O
the -X- _ O
NER -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
unlabeled -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
Wikipedia -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
contextual -X- _ O
representations -X- _ O
of -X- _ O
named -X- _ O
entities -X- _ O
. -X- _ O
Recent -X- _ O
efforts -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Straková -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
concatenate -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
pretrained -X- _ O
embeddings -X- _ O
to -X- _ O
form -X- _ O
stronger -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
over -X- _ O
long -X- _ O
documents -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
easily -X- _ O
model -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
to -X- _ O
disambiguate -X- _ O
complex -X- _ O
named -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
work -X- _ O
shows -X- _ O
that -X- _ O
utilizing -X- _ O
the -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
contexts -X- _ O
in -X- _ O
the -X- _ O
CoNLL -X- _ B-DatasetName
NER -X- _ B-TaskName
datasets -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
token -X- _ O
representations -X- _ O
and -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Luoma -X- _ O
and -X- _ O
Pyysalo -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
context -X- _ O
in -X- _ O
the -X- _ O
MultiCoNER -X- _ B-DatasetName
datasets -X- _ O
means -X- _ O
the -X- _ O
embeddings -X- _ O
can -X- _ O
not -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
for -X- _ O
entity -X- _ O
disambiguation -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
use -X- _ O
Google -X- _ O
search -X- _ O
to -X- _ O
retrieve -X- _ O
external -X- _ O
contexts -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
successfully -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
across -X- _ O
multiple -X- _ O
domains -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
this -X- _ O
idea -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
embeddings -X- _ O
can -X- _ O
utilize -X- _ O
the -X- _ O
related -X- _ O
knowledge -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
to -X- _ O
form -X- _ O
stronger -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O
Comparing -X- _ O
with -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
the -X- _ O
local -X- _ O
KB -X- _ O
based -X- _ O
on -X- _ O
Wikipedia -X- _ O
because -X- _ O
the -X- _ O
KB -X- _ O
matches -X- _ O
the -X- _ O
indomain -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
and -X- _ O
is -X- _ O
fast -X- _ O
enough -X- _ O
to -X- _ O
meet -X- _ O
the -X- _ O
time -X- _ O
requirement -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
phase -X- _ O
2 -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
pretrained -X- _ O
contextual -X- _ O
embeddings -X- _ O
is -X- _ O
a -X- _ O
useful -X- _ O
and -X- _ O
effective -X- _ O
approach -X- _ O
to -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
research -X- _ O
efforts -X- _ O
propose -X- _ O
to -X- _ O
further -X- _ O
train -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
embeddings -X- _ O
with -X- _ O
specific -X- _ O
training -X- _ O
data -X- _ O
or -X- _ O
in -X- _ O
a -X- _ O
larger -X- _ O
model -X- _ O
architecture -X- _ O
to -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Shi -X- _ O
and -X- _ O
Lee -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
which -X- _ O
first -X- _ O
trains -X- _ O
a -X- _ O
general -X- _ O
multilingual -X- _ O
Enhanced -X- _ O
Universal -X- _ O
Dependency -X- _ O
( -X- _ O
Bouma -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
parser -X- _ O
and -X- _ O
then -X- _ O
finetunes -X- _ O
on -X- _ O
each -X- _ O
specific -X- _ O
language -X- _ O
separately -X- _ O
. -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
train -X- _ O
models -X- _ O
through -X- _ O
concatenating -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
these -X- _ O
ideas -X- _ O
as -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
which -X- _ O
improves -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
monolingual -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
finetuned -X- _ O
multilingual -X- _ O
embeddings -X- _ O
as -X- _ O
initialization -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
stage -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
can -X- _ O
accelerate -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
in -X- _ O
system -X- _ O
building -X- _ O
. -X- _ O

The -X- _ O
instances -X- _ O
selected -X- _ O
or -X- _ O
generated -X- _ O
by -X- _ O
any -X- _ O
model -X- _ O
or -X- _ O
baseline -X- _ O
are -X- _ O
annotated -X- _ O
manually -X- _ O
by -X- _ O
one -X- _ O
human -X- _ O
coder -X- _ O
. -X- _ O
2 -X- _ O
Although -X- _ O
the -X- _ O
pool -X- _ O
data -X- _ O
has -X- _ O
labels -X- _ O
on -X- _ O
the -X- _ O
review -X- _ O
level -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
these -X- _ O
labels -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
Positive -X- _ O
reviews -X- _ O
can -X- _ O
include -X- _ O
negative -X- _ O
sentences -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
using -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
labels -X- _ O
would -X- _ O
introduce -X- _ O
noise -X- _ O
and -X- _ O
might -X- _ O
impair -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
During -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
experimental -X- _ O
runs -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
and -X- _ O
baselines -X- _ O
are -X- _ O
annotated -X- _ O
simultaneously -X- _ O
by -X- _ O
the -X- _ O
same -X- _ O
person -X- _ O
. -X- _ O
The -X- _ O
annotator -X- _ O
is -X- _ O
presented -X- _ O
with -X- _ O
one -X- _ O
instance -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
and -X- _ O
has -X- _ O
no -X- _ O
information -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
has -X- _ O
produced -X- _ O
each -X- _ O
particular -X- _ O
instance -X- _ O
. -X- _ O
Once -X- _ O
a -X- _ O
label -X- _ O
is -X- _ O
selected -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
transmitted -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
and -X- _ O
triggers -X- _ O
the -X- _ O
selection -X- _ O
/ -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
instance -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
at -X- _ O
any -X- _ O
given -X- _ O
time -X- _ O
there -X- _ O
is -X- _ O
one -X- _ O
unlabeled -X- _ O
instance -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
or -X- _ O
baseline -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
set -X- _ O
of -X- _ O
unlabeled -X- _ O
instances -X- _ O
, -X- _ O
one -X- _ O
instance -X- _ O
is -X- _ O
chosen -X- _ O
randomly -X- _ O
and -X- _ O
presented -X- _ O
to -X- _ O
the -X- _ O
annotator -X- _ O
. -X- _ O
This -X- _ O
procedure -X- _ O
is -X- _ O
repeated -X- _ O
until -X- _ O
500 -X- _ O
instances -X- _ O
are -X- _ O
labeled -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
or -X- _ O
baseline -X- _ O
. -X- _ O
Hiding -X- _ O
the -X- _ O
instance -X- _ O
source -X- _ O
from -X- _ O
the -X- _ O
annotator -X- _ O
is -X- _ O
intended -X- _ O
to -X- _ O
prevent -X- _ O
any -X- _ O
bias -X- _ O
during -X- _ O
the -X- _ O
annotation -X- _ O
process -X- _ O
. -X- _ O
6 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O
6.1 -X- _ O
Classification -X- _ O
Performance -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
annotated -X- _ O
instances -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
learning -X- _ O
curves -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
AL -X- _ B-TaskName
strategies -X- _ O
and -X- _ O
baselines -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
annotation -X- _ O
instances -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
random -X- _ B-MethodName
and -X- _ O
least -X- _ B-MethodName
conf -X- _ I-MethodName
baselines -X- _ O
perform -X- _ O
reasonably -X- _ O
well -X- _ O
. -X- _ O
Least -X- _ B-MethodName
conf -X- _ I-MethodName
struggles -X- _ O
in -X- _ O
the -X- _ O
beginning -X- _ O
, -X- _ O
likely -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
minimal -X- _ O
seed -X- _ O
set -X- _ O
. -X- _ O
Once -X- _ O
enough -X- _ O
instances -X- _ O
are -X- _ O
labeled -X- _ O
it -X- _ O
catches -X- _ O
up -X- _ O
. -X- _ O
Gen -X- _ O
uniform -X- _ O
has -X- _ O
a -X- _ O
strong -X- _ O
start -X- _ O
but -X- _ O
, -X- _ O
after -X- _ O
around -X- _ O
200 -X- _ O
instances -X- _ O
, -X- _ O
is -X- _ O
outperformed -X- _ O
by -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
approaches -X- _ O
which -X- _ O
yield -X- _ O
the -X- _ O
highest -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
. -X- _ O
Among -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
approaches -X- _ O
, -X- _ O
the -X- _ O
uniform -X- _ O
schedule -X- _ O
ranks -X- _ O
better -X- _ O
than -X- _ O
wang -X- _ B-MethodName
. -X- _ O
The -X- _ O
same -X- _ O
behaviour -X- _ O
is -X- _ O
observed -X- _ O
for -X- _ O
the -X- _ O
generation -X- _ O
methods -X- _ O
, -X- _ O
although -X- _ O
gen -X- _ B-MethodName
wang -X- _ I-MethodName
produces -X- _ O
the -X- _ O
worst -X- _ O
results -X- _ O
overall -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
gen -X- _ B-MethodName
uniform -X- _ I-MethodName
is -X- _ O
competitive -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
and -X- _ O
shows -X- _ O
that -X- _ O
sentences -X- _ O
generated -X- _ O
from -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
are -X- _ O
informative -X- _ O
and -X- _ O
useful -X- _ O
for -X- _ O
training -X- _ O
a -X- _ O
text -X- _ O
classifier -X- _ O
. -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
annotation -X- _ O
time -X- _ O
AL -X- _ B-TaskName
simulations -X- _ O
have -X- _ O
often -X- _ O
been -X- _ O
criticized -X- _ O
for -X- _ O
reporting -X- _ O
unrealistic -X- _ O
results -X- _ O
, -X- _ O
based -X- _ O
merely -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
annotated -X- _ O
instances -X- _ O
( -X- _ O
see -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Settles -X- _ O
( -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
pp -X- _ O
. -X- _ O
37 -X- _ O
ff -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
well -X- _ O
known -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
annotated -X- _ O
instances -X- _ O
is -X- _ O
often -X- _ O
not -X- _ O
a -X- _ O
good -X- _ O
predictor -X- _ O
for -X- _ O
the -X- _ O
real -X- _ O
annotation -X- _ O
costs -X- _ O
. -X- _ O
AL -X- _ B-TaskName
strategies -X- _ O
tend -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
hard -X- _ O
nuts -X- _ O
for -X- _ O
human -X- _ O
annotators -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
unreasonable -X- _ O
to -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
annotation -X- _ O
of -X- _ O
N -X- _ O
instances -X- _ O
in -X- _ O
an -X- _ O
AL -X- _ B-TaskName
setup -X- _ O
might -X- _ O
take -X- _ O
longer -X- _ O
and -X- _ O
thus -X- _ O
might -X- _ O
be -X- _ O
more -X- _ O
expensive -X- _ O
than -X- _ O
annotating -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
randomly -X- _ O
selected -X- _ O
instances -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
show -X- _ O
learning -X- _ O
curves -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
annotation -X- _ O
time -X- _ O
( -X- _ O
Figure -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
a -X- _ O
clear -X- _ O
advantage -X- _ O
for -X- _ O
the -X- _ O
generation -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
reduction -X- _ O
in -X- _ O
annotation -X- _ O
time -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
shorter -X- _ O
query -X- _ O
length -X- _ O
and -X- _ O
less -X- _ O
neutral -X- _ O
or -X- _ O
noisy -X- _ O
instances -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
This -X- _ O
speeds -X- _ O
up -X- _ O
the -X- _ O
annotation -X- _ O
by -X- _ O
a -X- _ O
significant -X- _ O
margin -X- _ O
while -X- _ O
providing -X- _ O
the -X- _ O
Learner -X- _ O
with -X- _ O
informative -X- _ O
instances -X- _ O
, -X- _ O
despite -X- _ O
their -X- _ O
short -X- _ O
length -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
generated -X- _ O
instances -X- _ O
increase -X- _ O
over -X- _ O
time -X- _ O
and -X- _ O
further -X- _ O
exploration -X- _ O
also -X- _ O
hints -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
length -X- _ O
is -X- _ O
correlated -X- _ O
with -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
seed -X- _ O
set -X- _ O
. -X- _ O
As -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
random -X- _ O
baseline -X- _ O
reveals -X- _ O
that -X- _ O
36.8 -X- _ O
percent -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pool -X- _ O
are -X- _ O
neutral -X- _ O
/ -X- _ O
artifacts -X- _ O
and -X- _ O
positive -X- _ O
sentences -X- _ O
outweigh -X- _ O
negative -X- _ O
ones -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
2.6 -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
random -X- _ O
sampling -X- _ O
results -X- _ O
in -X- _ O
unbalanced -X- _ O
datasets -X- _ O
with -X- _ O
far -X- _ O
more -X- _ O
positive -X- _ O
examples -X- _ O
. -X- _ O
Our -X- _ O
generation -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
show -X- _ O
this -X- _ O
disadvantage -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
instances -X- _ O
maintain -X- _ O
a -X- _ O
more -X- _ O
balanced -X- _ O
distribution -X- _ O
of -X- _ O
class -X- _ O
labels -X- _ O
and -X- _ O
are -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
skipped -X- _ O
. -X- _ O
These -X- _ O
are -X- _ O
indicators -X- _ O
that -X- _ O
the -X- _ O
selected -X- _ O
points -X- _ O
are -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
hyperplane -X- _ O
and -X- _ O
the -X- _ O
VAE -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
coherent -X- _ O
and -X- _ O
highly -X- _ O
informative -X- _ O
sentences -X- _ O
from -X- _ O
them -X- _ O
. -X- _ O

The -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
comes -X- _ O
from -X- _ O
two -X- _ O
sources -X- _ O
, -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
the -X- _ O
SST2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
SAR14 -X- _ B-DatasetName
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
limit -X- _ O
sentence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
15 -X- _ B-HyperparameterValue
words -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
motivated -X- _ O
by -X- _ O
lower -X- _ O
training -X- _ O
times -X- _ O
and -X- _ O
the -X- _ O
tendency -X- _ O
of -X- _ O
vanilla -X- _ O
VAEs -X- _ O
not -X- _ O
to -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
longer -X- _ O
sentences -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
with -X- _ O
size -X- _ O
512 -X- _ O
. -X- _ O
As -X- _ O
additional -X- _ O
regularization -X- _ O
we -X- _ O
set -X- _ O
weight -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
to -X- _ O
0.3 -X- _ B-HyperparameterValue
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Input -X- _ B-HyperparameterName
embeddings -X- _ I-HyperparameterName
are -X- _ O
also -X- _ O
of -X- _ O
size -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
share -X- _ O
the -X- _ O
embed -X- _ O
- -X- _ O
ding -X- _ O
weights -X- _ O
with -X- _ O
the -X- _ O
softmax -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
( -X- _ O
Press -X- _ O
and -X- _ O
Wolf -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
prevent -X- _ O
posterior -X- _ O
collapse -X- _ O
we -X- _ O
use -X- _ O
logistic -X- _ O
annealing -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
term -X- _ O
weight -X- _ O
and -X- _ O
weaken -X- _ O
the -X- _ O
decoder -X- _ O
by -X- _ O
applying -X- _ O
word -X- _ O
dropout -X- _ B-HyperparameterName
with -X- _ O
probability -X- _ O
0.5 -X- _ B-HyperparameterValue
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.005 -X- _ B-HyperparameterValue
. -X- _ O
Once -X- _ O
the -X- _ O
KL -X- _ O
term -X- _ O
weight -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ O
weight -X- _ O
is -X- _ O
linearly -X- _ O
decreased -X- _ O
to -X- _ O
0 -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
stops -X- _ O
after -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
has -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
50 -X- _ B-HyperparameterValue
dimensions -X- _ O
. -X- _ O
The -X- _ O
trained -X- _ O
VAE -X- _ O
achieves -X- _ O
a -X- _ O
reconstruction -X- _ B-MetricName
loss -X- _ I-MetricName
of -X- _ O
45.3 -X- _ B-MetricValue
and -X- _ O
KL -X- _ B-MetricName
divergence -X- _ I-MetricName
of -X- _ O
13.2 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
SST2 -X- _ B-DatasetName
training -X- _ O
set -X- _ O
. -X- _ O
Learner -X- _ O
The -X- _ O
Learner -X- _ O
is -X- _ O
an -X- _ O
SVM -X- _ O
1 -X- _ O
with -X- _ O
linear -X- _ O
kernel -X- _ O
. -X- _ O
Each -X- _ O
instance -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
autoencoder -X- _ O
. -X- _ O
The -X- _ O
latent -X- _ O
variable -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
with -X- _ O
50 -X- _ O
dimensions -X- _ O
and -X- _ O
the -X- _ O
SVM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
this -X- _ O
representation -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
classification -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
reduced -X- _ O
SST2 -X- _ B-DatasetName
test -X- _ O
set -X- _ O
and -X- _ O
report -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
. -X- _ O
Generator -X- _ O
The -X- _ O
generator -X- _ O
is -X- _ O
the -X- _ O
decoder -X- _ O
of -X- _ O
the -X- _ O
VAE -X- _ O
described -X- _ O
above -X- _ O
. -X- _ O
Once -X- _ O
a -X- _ O
point -X- _ O
z -X- _ O
in -X- _ O
feature -X- _ O
space -X- _ O
is -X- _ O
selected -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
x -X- _ O
= -X- _ O
dec -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
which -X- _ O
generates -X- _ O
the -X- _ O
human -X- _ O
readable -X- _ O
sentence -X- _ O
x -X- _ O
in -X- _ O
an -X- _ O
autoregressive -X- _ O
way -X- _ O
. -X- _ O

The -X- _ O
Variational -X- _ B-MethodName
Autoencoder -X- _ I-MethodName
is -X- _ O
a -X- _ O
generative -X- _ O
model -X- _ O
first -X- _ O
introduced -X- _ O
by -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Like -X- _ O
other -X- _ O
autoencoders -X- _ O
, -X- _ O
VAEs -X- _ O
learn -X- _ O
a -X- _ O
mapping -X- _ O
q -X- _ O
θ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
from -X- _ O
high -X- _ O
dimensional -X- _ O
input -X- _ O
x -X- _ O
to -X- _ O
a -X- _ O
low -X- _ O
dimensional -X- _ O
latent -X- _ O
variable -X- _ O
z. -X- _ O
Instead -X- _ O
of -X- _ O
doing -X- _ O
this -X- _ O
in -X- _ O
a -X- _ O
deterministic -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
encoder -X- _ O
learns -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
e.g. -X- _ O
a -X- _ O
normal -X- _ O
distribution -X- _ O
. -X- _ O
The -X- _ O
desired -X- _ O
effect -X- _ O
is -X- _ O
that -X- _ O
each -X- _ O
area -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
has -X- _ O
a -X- _ O
semantic -X- _ O
meaning -X- _ O
and -X- _ O
thus -X- _ O
samples -X- _ O
from -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
decoded -X- _ O
in -X- _ O
a -X- _ O
meaningful -X- _ O
way -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
also -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
dec -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
input -X- _ O
x -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
approximate -X- _ O
θ -X- _ O
via -X- _ O
gradient -X- _ O
descent -X- _ O
the -X- _ O
reparametrization -X- _ O
trick -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
was -X- _ O
introduced -X- _ O
. -X- _ O
This -X- _ O
trick -X- _ O
allows -X- _ O
the -X- _ O
gradient -X- _ O
to -X- _ O
flow -X- _ O
through -X- _ O
non -X- _ O
- -X- _ O
deterministic -X- _ O
z -X- _ O
by -X- _ O
separating -X- _ O
the -X- _ O
discrete -X- _ O
sampling -X- _ O
operation -X- _ O
. -X- _ O
Let -X- _ O
µ -X- _ O
and -X- _ O
σ -X- _ O
be -X- _ O
deterministic -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
q -X- _ O
θ -X- _ O
( -X- _ O
µ -X- _ O
, -X- _ O
σ -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
: -X- _ O
z -X- _ O
= -X- _ O
µ -X- _ O
+ -X- _ O
σ -X- _ O
where -X- _ O
∼ -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
product -X- _ O
. -X- _ O
To -X- _ O
prevent -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
pushing -X- _ O
σ -X- _ O
close -X- _ O
to -X- _ O
0 -X- _ O
and -X- _ O
thus -X- _ O
falling -X- _ O
back -X- _ O
to -X- _ O
a -X- _ O
deterministic -X- _ O
autoencoder -X- _ O
, -X- _ O
the -X- _ O
objective -X- _ O
is -X- _ O
extended -X- _ O
by -X- _ O
the -X- _ O
Kullback -X- _ B-MetricName
- -X- _ I-MetricName
Leibler -X- _ I-MetricName
( -X- _ I-MetricName
KL -X- _ I-MetricName
) -X- _ I-MetricName
diver -X- _ I-MetricName
- -X- _ I-MetricName
gence -X- _ I-MetricName
between -X- _ O
prior -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
q -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
−KL -X- _ O
( -X- _ O
q -X- _ O
θ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
| -X- _ O
| -X- _ O
p -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
E -X- _ O
q -X- _ O
θ -X- _ O
( -X- _ O
z -X- _ O
| -X- _ O
x -X- _ O
) -X- _ O
[ -X- _ O
logp -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
z -X- _ O
) -X- _ O
] -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
apply -X- _ O
this -X- _ O
idea -X- _ O
for -X- _ O
sentence -X- _ O
generation -X- _ O
using -X- _ O
an -X- _ O
RNN -X- _ O
as -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O
They -X- _ O
observe -X- _ O
that -X- _ O
a -X- _ O
strong -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
language -X- _ O
modeling -X- _ O
ability -X- _ O
in -X- _ O
the -X- _ O
decoder -X- _ O
reduces -X- _ O
the -X- _ O
information -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
, -X- _ O
right -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
complete -X- _ O
collapse -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
term -X- _ O
. -X- _ O
They -X- _ O
explore -X- _ O
different -X- _ O
techniques -X- _ O
to -X- _ O
weaken -X- _ O
the -X- _ O
decoder -X- _ O
, -X- _ O
like -X- _ O
word -X- _ O
dropout -X- _ O
or -X- _ O
KL -X- _ O
term -X- _ O
weight -X- _ O
annealing -X- _ O
, -X- _ O
as -X- _ O
possible -X- _ O
solutions -X- _ O
. -X- _ O
This -X- _ O
guarantees -X- _ O
a -X- _ O
semantically -X- _ O
rich -X- _ O
latent -X- _ O
variable -X- _ O
and -X- _ O
good -X- _ O
sentence -X- _ O
generation -X- _ O
ability -X- _ O
. -X- _ O
Below -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
how -X- _ O
to -X- _ O
combine -X- _ O
both -X- _ O
techniques -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
generate -X- _ O
meaningful -X- _ O
queries -X- _ O
for -X- _ O
Membership -X- _ B-TaskName
Query -X- _ I-TaskName
Synthesis -X- _ I-TaskName
. -X- _ O

We -X- _ O
run -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
NVIDIA -X- _ O
TI -X- _ O
- -X- _ O
TAN -X- _ O
RTX -X- _ O
with -X- _ O
24 -X- _ O
GB -X- _ O
GPU -X- _ O
memory -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
generators -X- _ O
for -X- _ O
2 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
as -X- _ O
we -X- _ O
have -X- _ O
done -X- _ O
on -X- _ O
our -X- _ O
preprocessed -X- _ O
PERSONACHAT -X- _ B-DatasetName
train -X- _ O
split -X- _ O
consumes -X- _ O
about -X- _ O
3 -X- _ O
- -X- _ O
4 -X- _ O
hours -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
our -X- _ O
critic -X- _ O
classifier -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
epoch -X- _ B-HyperparameterName
consumes -X- _ O
about -X- _ O
1 -X- _ O
hour -X- _ O
. -X- _ O
Our -X- _ O
RL -X- _ O
phase -X- _ O
consumes -X- _ O
about -X- _ O
15 -X- _ O
hours -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
validation -X- _ O
loss -X- _ O
before -X- _ O
being -X- _ O
early -X- _ O
stopped -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
averaged -X- _ O
results -X- _ O
from -X- _ O
3 -X- _ O
runs -X- _ O
for -X- _ O
our -X- _ O
dialogue -X- _ O
response -X- _ O
generation -X- _ O
and -X- _ O
partner -X- _ O
personas -X- _ O
generation -X- _ O
results -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
Table -X- _ O
4 -X- _ O
and -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
the -X- _ O
progressive -X- _ O
change -X- _ O
of -X- _ O
the -X- _ O
testing -X- _ O
perplexity -X- _ O
for -X- _ O
DRG -X- _ B-MethodName
and -X- _ O
PPG -X- _ B-MethodName
on -X- _ O
PERSONACHAT -X- _ B-DatasetName
- -X- _ I-DatasetName
ORI -X- _ I-DatasetName
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
4 -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
they -X- _ O
improve -X- _ O
D -X- _ O
Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName
Criteria -X- _ I-MetricName
( -X- _ O
Appropriateness -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Who -X- _ O
is -X- _ O
more -X- _ O
appropriate -X- _ O
given -X- _ O
the -X- _ O
previous -X- _ O
dialogue -X- _ O
context -X- _ O
? -X- _ O
" -X- _ O
( -X- _ O
Informativeness -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Who -X- _ O
is -X- _ O
more -X- _ O
diverse -X- _ O
instead -X- _ O
of -X- _ O
null -X- _ O
answers -X- _ O
such -X- _ O
as -X- _ O
I -X- _ O
do -X- _ O
not -X- _ O
know -X- _ O
? -X- _ O
" -X- _ O
( -X- _ O
Engagingness -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Who -X- _ O
would -X- _ O
you -X- _ O
prefer -X- _ O
to -X- _ O
talk -X- _ O
with -X- _ O
for -X- _ O
a -X- _ O
long -X- _ O
conversation -X- _ O
? -X- _ O
" -X- _ O
( -X- _ O
Human -X- _ O
- -X- _ O
likeness -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Which -X- _ O
speaker -X- _ O
do -X- _ O
you -X- _ O
think -X- _ O
sounds -X- _ O
more -X- _ O
like -X- _ O
a -X- _ O
real -X- _ O
person -X- _ O
? -X- _ O
" -X- _ O
( -X- _ O
Coherence -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Which -X- _ O
persona -X- _ O
contains -X- _ O
traits -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
coherent -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
? -X- _ O
" -X- _ O
( -X- _ O
Interestingness -X- _ O
) -X- _ O
: -X- _ O
" -X- _ O
Which -X- _ O
persona -X- _ O
is -X- _ O
more -X- _ O
interesting -X- _ O
and -X- _ O
diverse -X- _ O
? -X- _ O
" -X- _ O
The -X- _ O
first -X- _ O
four -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
existing -X- _ O
work -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
for -X- _ O
evaluating -X- _ O
PPG -X- _ B-MethodName
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
first -X- _ O
four -X- _ O
for -X- _ O
DRG -X- _ B-MethodName
, -X- _ O
and -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
last -X- _ O
four -X- _ O
for -X- _ O
PPG -X- _ B-MethodName
. -X- _ O

For -X- _ O
supervised -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
optimizer -X- _ O
, -X- _ O
with -X- _ O
hyperparameters -X- _ O
η -X- _ B-HyperparameterName
= -X- _ O
5e−4 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
ϵ -X- _ B-HyperparameterName
= -X- _ O
1e−8 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
models -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
2 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
For -X- _ O
RL -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
Adam -X- _ O
as -X- _ O
our -X- _ O
optimizer -X- _ O
, -X- _ O
with -X- _ O
η -X- _ B-HyperparameterName
= -X- _ O
5e−6 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
ϵ -X- _ O
= -X- _ O
1e−8 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
update -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
every -X- _ O
20 -X- _ O
training -X- _ O
instances -X- _ O
and -X- _ O
validate -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
every -X- _ O
50 -X- _ O
updates -X- _ O
. -X- _ O
DistilBERT -X- _ B-MethodName
is -X- _ O
used -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
critic -X- _ O
network -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
Adam -X- _ O
as -X- _ O
our -X- _ O
optimizer -X- _ O
, -X- _ O
with -X- _ O
hyperparameters -X- _ O
η -X- _ B-HyperparameterName
= -X- _ O
5e−6 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
ϵ -X- _ B-HyperparameterName
= -X- _ O
1e−8 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
critic -X- _ O
for -X- _ O
1 -X- _ O
epoch -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
we -X- _ O
freeze -X- _ O
it -X- _ O
empirically -X- _ O
during -X- _ O
RL -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
TRANSFORMERS -X- _ O
library -X- _ O
from -X- _ O
HUGGINGFACE -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
PERSONACHAT -X- _ B-DatasetName
, -X- _ O
the -X- _ O
most -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
multiturn -X- _ B-TaskName
dialogue -X- _ I-TaskName
dataset -X- _ O
conditioned -X- _ O
on -X- _ O
personas -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
valid -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
split -X- _ I-HyperparameterName
from -X- _ O
the -X- _ O
PARLAI -X- _ B-MethodName
platform -X- _ O
( -X- _ O
Miller -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
that -X- _ O
contains -X- _ O
about -X- _ O
65 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
000/7 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
800/7 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
500 -X- _ I-HyperparameterValue
instances -X- _ O
respectively -X- _ O
. -X- _ O
Each -X- _ O
instance -X- _ O
contains -X- _ O
about -X- _ O
8 -X- _ O
utterances -X- _ O
on -X- _ O
average -X- _ O
and -X- _ O
about -X- _ O
4 -X- _ O
traits -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
self -X- _ O
and -X- _ O
partner -X- _ O
personas -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
dataset -X- _ O
with -X- _ O
this -X- _ O
original -X- _ O
personas -X- _ O
as -X- _ O
PERSONACHAT -X- _ B-DatasetName
- -X- _ I-DatasetName
ORI -X- _ I-DatasetName
. -X- _ O
Later -X- _ O
the -X- _ O
original -X- _ O
personas -X- _ O
have -X- _ O
been -X- _ O
manually -X- _ O
scrutinized -X- _ O
by -X- _ O
rephrasing -X- _ O
, -X- _ O
generalizing -X- _ O
or -X- _ O
specializing -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
denote -X- _ O
as -X- _ O
PERSONACHAT -X- _ B-DatasetName
- -X- _ I-DatasetName
REV -X- _ I-DatasetName
. -X- _ O
We -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
preprocessing -X- _ O
operation -X- _ O
to -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
the -X- _ O
critic -X- _ O
for -X- _ O
RL -X- _ O
, -X- _ O
we -X- _ O
collected -X- _ O
about -X- _ O
130 -X- _ O
, -X- _ O
000 -X- _ O
instances -X- _ O
from -X- _ O
the -X- _ O
train -X- _ O
split -X- _ O
with -X- _ O
equally -X- _ O
distributed -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
During -X- _ O
early -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
feeding -X- _ O
all -X- _ O
traits -X- _ O
yields -X- _ O
lower -X- _ O
performance -X- _ O
. -X- _ O
Retrieving -X- _ O
Top -X- _ O
- -X- _ O
3 -X- _ O
relevant -X- _ O
partner -X- _ O
personas -X- _ O
using -X- _ O
BM25 -X- _ B-MethodName
( -X- _ O
Robertson -X- _ O
and -X- _ O
Walker -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
personas -X- _ O
. -X- _ O
GPT -X- _ B-MethodName
- -X- _ I-MethodName
2 -X- _ I-MethodName
This -X- _ O
is -X- _ O
a -X- _ O
comparison -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
GPT -X- _ B-MethodName
- -X- _ I-MethodName
2 -X- _ I-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
the -X- _ O
same -X- _ O
three -X- _ O
E2E -X- _ O
systems -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
is -X- _ O
selected -X- _ O
, -X- _ O
the -X- _ O
third -X- _ O
one -X- _ O
. -X- _ O
TRANSFERTRANSFO -X- _ B-MethodName
A -X- _ O
comparison -X- _ O
model -X- _ O
built -X- _ O
with -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
gen -X- _ O
- -X- _ O
eral -X- _ O
domain -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
PERSONACHAT -X- _ B-DatasetName
. -X- _ O
PERCVAE -X- _ B-MethodName
This -X- _ O
is -X- _ O
a -X- _ O
comparison -X- _ O
model -X- _ O
that -X- _ O
employs -X- _ O
a -X- _ O
memory -X- _ O
- -X- _ O
augmented -X- _ O
architecture -X- _ O
incorporated -X- _ O
with -X- _ O
conditional -X- _ O
variational -X- _ O
autoencoder -X- _ O
that -X- _ O
exploits -X- _ O
persona -X- _ O
information -X- _ O
. -X- _ O
PAML -X- _ B-MethodName
This -X- _ O
is -X- _ O
a -X- _ O
comparison -X- _ O
model -X- _ O
that -X- _ O
leverages -X- _ O
several -X- _ O
dialogues -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
speaker -X- _ O
to -X- _ O
enhance -X- _ O
response -X- _ O
personality -X- _ O
via -X- _ O
metalearning -X- _ O
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
authors -X- _ O
did -X- _ O
not -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
PERSONACHAT -X- _ B-DatasetName
- -X- _ I-DatasetName
REV -X- _ I-DatasetName
and -X- _ O
no -X- _ O
preprocessing -X- _ O
scripts -X- _ O
are -X- _ O
provided -X- _ O
for -X- _ O
the -X- _ O
revised -X- _ O
personas -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
their -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
PERSONACHAT -X- _ B-DatasetName
- -X- _ I-DatasetName
ORI -X- _ I-DatasetName
only -X- _ O
. -X- _ O
MTL -X- _ B-MethodName
w/ -X- _ I-MethodName
Personas -X- _ I-MethodName
Reconstruction -X- _ I-MethodName
This -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
( -X- _ O
MTL -X- _ O
) -X- _ O
comparison -X- _ O
model -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
trained -X- _ O
to -X- _ O
maximise -X- _ O
the -X- _ O
objective -X- _ O
: -X- _ O
αL -X- _ O
PPG -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
α -X- _ O
) -X- _ O
L -X- _ O
DRG -X- _ O
, -X- _ O
where -X- _ O
L -X- _ O
PPG -X- _ O
represents -X- _ O
the -X- _ O
auxiliary -X- _ B-MetricName
PPG -X- _ I-MetricName
likelihood -X- _ I-MetricName
, -X- _ O
and -X- _ O
L -X- _ O
DRG -X- _ O
represents -X- _ O
the -X- _ O
DRG -X- _ B-MetricName
likelihood -X- _ I-MetricName
. -X- _ O
α -X- _ B-HyperparameterName
is -X- _ O
weight -X- _ B-HyperparameterValue
tuned -X- _ O
over -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
both -X- _ O
tasks -X- _ O
condition -X- _ O
on -X- _ O
dialogue -X- _ O
context -X- _ O
and -X- _ O
self -X- _ O
personas -X- _ O
and -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

For -X- _ O
both -X- _ O
PPG -X- _ B-MethodName
and -X- _ O
DRG -X- _ B-MethodName
, -X- _ O
perplexity -X- _ B-MetricName
( -X- _ O
PPL -X- _ B-MetricName
) -X- _ O
is -X- _ O
reported -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
intrinsic -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
output -X- _ O
( -X- _ O
Roller -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
sequence -X- _ O
evaluation -X- _ O
metrics -X- _ O
weighted -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
and -X- _ O
Fmeasure -X- _ B-MetricName
for -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
extrinsic -X- _ O
evaluations -X- _ O
. -X- _ O
For -X- _ O
PPG -X- _ B-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
Distinct -X- _ B-MetricName
- -X- _ I-MetricName
N -X- _ I-MetricName
with -X- _ O
N= -X- _ B-HyperparameterName
{ -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
} -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
response -X- _ O
diversity -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
distinct -X- _ O
unigrams -X- _ O
/ -X- _ O
bigrams -X- _ O
against -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
unigrams -X- _ O
/ -X- _ O
bigrams -X- _ O
generated -X- _ O
. -X- _ O

Reinforcement -X- _ O
learning -X- _ O
( -X- _ O
RL -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
specifically -X- _ O
, -X- _ O
policy -X- _ O
gradient -X- _ O
methods -X- _ O
( -X- _ O
Williams -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
frequently -X- _ O
adopted -X- _ O
to -X- _ O
both -X- _ B-TaskName
task -X- _ I-TaskName
- -X- _ I-TaskName
oriented -X- _ I-TaskName
dialogue -X- _ I-TaskName
agents -X- _ O
( -X- _ O
Roman -X- _ O
Roman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
or -X- _ O
open -X- _ B-TaskName
- -X- _ I-TaskName
domain -X- _ I-TaskName
chitchat -X- _ I-TaskName
agents -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016c -X- _ O
; -X- _ O
Saleh -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
either -X- _ O
propagate -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
loss -X- _ O
( -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
or -X- _ O
optimize -X- _ O
an -X- _ O
expert -X- _ O
reward -X- _ O
such -X- _ O
as -X- _ O
ease -X- _ O
of -X- _ O
answering -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016c -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
adopts -X- _ O
a -X- _ O
scenario -X- _ O
where -X- _ O
a -X- _ O
user -X- _ O
simulator -X- _ O
and -X- _ O
a -X- _ O
dialogue -X- _ O
agent -X- _ O
interact -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
inference -X- _ O
flow -X- _ O
that -X- _ O
shows -X- _ O
the -X- _ O
generated -X- _ O
partner -X- _ O
personas -X- _ O
and -X- _ O
the -X- _ O
incorporation -X- _ O
of -X- _ O
partner -X- _ O
personas -X- _ O
generation -X- _ O
into -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
illustrated -X- _ O
reinforcement -X- _ O
learning -X- _ O
strategy -X- _ O
that -X- _ O
directly -X- _ O
backpropagates -X- _ O
the -X- _ O
response -X- _ O
- -X- _ O
related -X- _ O
rewards -X- _ O
from -X- _ O
the -X- _ O
critic -X- _ O
network -X- _ O
to -X- _ O
the -X- _ O
partner -X- _ O
personas -X- _ O
generator -X- _ O
and -X- _ O
the -X- _ O
dialogue -X- _ O
response -X- _ O
generator -X- _ O
. -X- _ O
expert -X- _ O
reward -X- _ O
function -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
to -X- _ O
assign -X- _ O
the -X- _ O
goodness -X- _ O
to -X- _ O
each -X- _ O
response -X- _ O
generated -X- _ O
( -X- _ O
Roman -X- _ O
Roman -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
knowledge -X- _ O
learned -X- _ O
through -X- _ O
model -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
RL -X- _ I-MethodName
is -X- _ O
contributed -X- _ O
to -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
many -X- _ O
tasks -X- _ O
. -X- _ O
So -X- _ O
our -X- _ O
KRR -X- _ B-MethodName
- -X- _ I-MethodName
RL -X- _ I-MethodName
framework -X- _ O
enables -X- _ O
a -X- _ O
robot -X- _ O
to -X- _ O
dynamically -X- _ O
generate -X- _ O
partial -X- _ O
world -X- _ O
models -X- _ O
for -X- _ O
tasks -X- _ O
under -X- _ O
settings -X- _ O
that -X- _ O
were -X- _ O
never -X- _ O
experienced -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
an -X- _ O
agent -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
the -X- _ O
current -X- _ O
time -X- _ O
is -X- _ O
morning -X- _ O
or -X- _ O
noon -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
possible -X- _ O
values -X- _ O
for -X- _ O
variable -X- _ O
" -X- _ O
time -X- _ O
" -X- _ O
. -X- _ O
Consider -X- _ O
that -X- _ O
our -X- _ O
agent -X- _ O
has -X- _ O
learned -X- _ O
world -X- _ O
dynamics -X- _ O
under -X- _ O
the -X- _ O
times -X- _ O
of -X- _ O
morning -X- _ O
and -X- _ O
noon -X- _ O
. -X- _ O
Our -X- _ O
KRR -X- _ B-MethodName
- -X- _ I-MethodName
RL -X- _ I-MethodName
framework -X- _ O
enables -X- _ O
the -X- _ O
robot -X- _ O
to -X- _ O
reason -X- _ O
about -X- _ O
the -X- _ O
two -X- _ O
transition -X- _ O
systems -X- _ O
under -X- _ O
the -X- _ O
two -X- _ O
settings -X- _ O
and -X- _ O
generate -X- _ O
a -X- _ O
new -X- _ O
transition -X- _ O
system -X- _ O
for -X- _ O
this -X- _ O
" -X- _ O
morning -X- _ O
- -X- _ O
or -X- _ O
- -X- _ O
noon -X- _ O
" -X- _ O
setting -X- _ O
. -X- _ O
Without -X- _ O
our -X- _ O
framework -X- _ O
, -X- _ O
an -X- _ O
agent -X- _ O
would -X- _ O
have -X- _ O
to -X- _ O
randomly -X- _ O
select -X- _ O
one -X- _ O
between -X- _ O
the -X- _ O
" -X- _ O
morning -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
noon -X- _ O
" -X- _ O
policies -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
our -X- _ O
policies -X- _ O
dynamically -X- _ O
constructed -X- _ O
via -X- _ O
KRR -X- _ B-MethodName
, -X- _ O
we -X- _ O
let -X- _ O
an -X- _ O
agent -X- _ O
learn -X- _ O
three -X- _ O
controllers -X- _ O
under -X- _ O
three -X- _ O
different -X- _ O
environment -X- _ O
settings -X- _ O
- -X- _ O
the -X- _ O
navigation -X- _ O
actions -X- _ O
have -X- _ O
decreasing -X- _ O
success -X- _ O
rates -X- _ O
under -X- _ O
the -X- _ O
settings -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
the -X- _ O
robot -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
which -X- _ O
setting -X- _ O
it -X- _ O
is -X- _ O
in -X- _ O
( -X- _ O
out -X- _ O
of -X- _ O
two -X- _ O
that -X- _ O
are -X- _ O
randomly -X- _ O
selected -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
baseline -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
KRR -X- _ B-MethodName
capability -X- _ O
of -X- _ O
merging -X- _ O
knowledge -X- _ O
learned -X- _ O
from -X- _ O
different -X- _ O
settings -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
only -X- _ O
randomly -X- _ O
select -X- _ O
a -X- _ O
policy -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
( -X- _ O
each -X- _ O
corresponding -X- _ O
to -X- _ O
a -X- _ O
setting -X- _ O
) -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
baseline -X- _ O
agent -X- _ O
achieved -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
26.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
success -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
navigation -X- _ O
tasks -X- _ O
, -X- _ O
whereas -X- _ O
our -X- _ O
KRR -X- _ B-MethodName
- -X- _ I-MethodName
RL -X- _ I-MethodName
agent -X- _ O
achieved -X- _ B-MetricValue
83.8 -X- _ I-MetricValue
% -X- _ I-MetricValue
success -X- _ B-MetricName
rate -X- _ I-MetricName
on -X- _ O
average -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
costs -X- _ B-MetricName
in -X- _ O
a -X- _ O
box -X- _ O
plot -X- _ O
( -X- _ O
including -X- _ O
min -X- _ O
- -X- _ O
max -X- _ O
, -X- _ O
25 -X- _ O
% -X- _ O
, -X- _ O
and -X- _ O
75 -X- _ O
% -X- _ O
values -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
KRR -X- _ B-MethodName
- -X- _ I-MethodName
RL -X- _ I-MethodName
enables -X- _ O
a -X- _ O
robot -X- _ O
to -X- _ O
effectively -X- _ O
apply -X- _ O
the -X- _ O
learned -X- _ O
knowledge -X- _ O
to -X- _ O
tasks -X- _ O
under -X- _ O
new -X- _ O
settings -X- _ O
. -X- _ O
Let -X- _ O
us -X- _ O
take -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
" -X- _ O
time -X- _ O
" -X- _ O
variable -X- _ O
T -X- _ O
. -X- _ O
If -X- _ O
T -X- _ O
is -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
T -X- _ O
, -X- _ O
the -X- _ O
RL -X- _ O
- -X- _ O
only -X- _ O
baseline -X- _ O
has -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
2 -X- _ O
| -X- _ O
T -X- _ O
| -X- _ O
world -X- _ O
models -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
all -X- _ O
possible -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
T -X- _ O
, -X- _ O
where -X- _ O
2 -X- _ O
| -X- _ O
T -X- _ O
| -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
subsets -X- _ O
of -X- _ O
T -X- _ O
. -X- _ O
If -X- _ O
there -X- _ O
are -X- _ O
N -X- _ O
such -X- _ O
variables -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
world -X- _ O
models -X- _ O
grows -X- _ O
exponentially -X- _ O
to -X- _ O
2 -X- _ O
| -X- _ O
T -X- _ O
| -X- _ O
N -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
KRR -X- _ B-MethodName
- -X- _ I-MethodName
RL -X- _ I-MethodName
agent -X- _ O
needs -X- _ O
to -X- _ O
compute -X- _ O
only -X- _ O
| -X- _ O
T -X- _ O
| -X- _ O
N -X- _ O
world -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
dramatically -X- _ O
reduces -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
that -X- _ O
must -X- _ O
be -X- _ O
learned -X- _ O
through -X- _ O
RL -X- _ O
while -X- _ O
retaining -X- _ O
policy -X- _ O
quality -X- _ O
. -X- _ O

In -X- _ O
Section -X- _ O
7.2 -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
our -X- _ O
probability -X- _ O
model -X- _ O
on -X- _ O
both -X- _ O
short -X- _ O
phrase -X- _ O
pairs -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
had -X- _ O
gold -X- _ O
probabilities -X- _ O
and -X- _ O
longer -X- _ O
SNLI -X- _ B-MethodName
sentence -X- _ O
pairs -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
estimated -X- _ O
probabilities -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
this -X- _ O
model -X- _ O
for -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
and -X- _ O
demonstrate -X- _ O
that -X- _ O
these -X- _ O
predicted -X- _ O
probabilities -X- _ O
are -X- _ O
informative -X- _ O
features -X- _ O
for -X- _ O
predicting -X- _ O
entailment -X- _ O
on -X- _ O
both -X- _ O
SICK -X- _ B-DatasetName
and -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O
Model -X- _ O
We -X- _ O
first -X- _ O
train -X- _ O
an -X- _ O
LSTM -X- _ B-MethodName
similar -X- _ O
to -X- _ O
the -X- _ O
100d -X- _ O
LSTM -X- _ B-MethodName
that -X- _ O
achieved -X- _ O
the -X- _ O
best -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
neural -X- _ O
models -X- _ O
in -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
takes -X- _ O
GloVe -X- _ O
word -X- _ O
vectors -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
produces -X- _ O
100d -X- _ O
sentence -X- _ O
vectors -X- _ O
for -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
. -X- _ O
200d -X- _ B-HyperparameterValue
tanh -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
and -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
for -X- _ O
3 -X- _ O
- -X- _ O
class -X- _ O
entailment -X- _ O
classification -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
on -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
training -X- _ O
data -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
512 -X- _ B-HyperparameterValue
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.85 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
output -X- _ O
vector -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
for -X- _ O
each -X- _ O
sentence -X- _ O
pair -X- _ O
and -X- _ O
append -X- _ O
our -X- _ O
predicted -X- _ O
P -X- _ O
( -X- _ O
h -X- _ O
| -X- _ O
p -X- _ O
) -X- _ O
value -X- _ O
( -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
hypothesis -X- _ O
given -X- _ O
the -X- _ O
premise -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
another -X- _ O
classifier -X- _ O
that -X- _ O
passes -X- _ O
this -X- _ O
201d -X- _ O
vector -X- _ O
through -X- _ O
two -X- _ O
tanh -X- _ O
layers -X- _ O
with -X- _ O
a -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ B-HyperparameterValue
0.5 -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
final -X- _ O
3 -X- _ O
- -X- _ O
class -X- _ O
softmax -X- _ O
classification -X- _ O
layer -X- _ O
. -X- _ O
Holding -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
fixed -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
training -X- _ O
data -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
512 -X- _ B-HyperparameterValue
. -X- _ O
Results -X- _ O
Table -X- _ O
2 -X- _ O
contains -X- _ O
our -X- _ O
results -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O
Our -X- _ O
baseline -X- _ O
LSTM -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
same -X- _ O
77.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
reported -X- _ O
by -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
a -X- _ O
classifier -X- _ O
that -X- _ O
combines -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
LSTM -X- _ B-MethodName
with -X- _ O
only -X- _ O
a -X- _ O
single -X- _ O
feature -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
our -X- _ O
probability -X- _ O
model -X- _ O
improves -X- _ O
to -X- _ O
78.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
approach -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
predictions -X- _ O
on -X- _ O
SICK -X- _ B-DatasetName
( -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
SICK -X- _ B-DatasetName
does -X- _ O
not -X- _ O
have -X- _ O
enough -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
an -X- _ O
LSTM -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
SICK -X- _ B-DatasetName
and -X- _ O
SNLI -X- _ B-DatasetName
training -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
both -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
and -X- _ O
the -X- _ O
final -X- _ O
model -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
predicted -X- _ O
conditional -X- _ O
probability -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
feature -X- _ O
for -X- _ O
each -X- _ O
SICK -X- _ B-DatasetName
sentence -X- _ O
pair -X- _ O
, -X- _ O
performance -X- _ O
increases -X- _ O
from -X- _ O
81.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
82.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O
This -X- _ O
approach -X- _ O
outperforms -X- _ O
the -X- _ O
transfer -X- _ O
learning -X- _ O
approach -X- _ O
of -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
also -X- _ O
trained -X- _ O
on -X- _ O
both -X- _ O
SICK -X- _ B-DatasetName
and -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
KL -X- _ B-MetricName
divergences -X- _ I-MetricName
D -X- _ O
KL -X- _ O
( -X- _ O
P -X- _ O
| -X- _ O
| -X- _ O
Q -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
individual -X- _ O
and -X- _ O
conditional -X- _ O
probabilities -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
against -X- _ O
the -X- _ O
corresponding -X- _ O
predicted -X- _ O
probabilities -X- _ O
Q -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
r -X- _ O
, -X- _ O
which -X- _ O
expresses -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
two -X- _ O
variables -X- _ O
( -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
item -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
probabilities -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
value -X- _ O
between -X- _ O
−1 -X- _ O
( -X- _ O
total -X- _ O
negative -X- _ O
correlation -X- _ O
) -X- _ O
and -X- _ O
1 -X- _ O
( -X- _ O
total -X- _ O
positive -X- _ O
correlation -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
KL -X- _ B-MetricName
divergence -X- _ I-MetricName
on -X- _ O
a -X- _ O
per -X- _ O
- -X- _ O
item -X- _ O
basis -X- _ O
, -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
over -X- _ O
all -X- _ O
items -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
trained -X- _ O
model -X- _ O
on -X- _ O
unseen -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
test -X- _ O
data -X- _ O
consists -X- _ O
of -X- _ O
4.6 -X- _ O
million -X- _ O
phrase -X- _ O
pairs -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
which -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
phrase -X- _ O
that -X- _ O
was -X- _ O
not -X- _ O
observed -X- _ O
in -X- _ O
either -X- _ O
the -X- _ O
training -X- _ O
or -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
does -X- _ O
reasonably -X- _ O
well -X- _ O
at -X- _ O
predicting -X- _ O
these -X- _ O
conditional -X- _ O
probabilities -X- _ O
, -X- _ O
reaching -X- _ O
a -X- _ O
correlation -X- _ B-MetricName
of -X- _ O
r -X- _ B-MetricName
= -X- _ O
0.949 -X- _ B-MetricValue
with -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
complete -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
123 -X- _ O
, -X- _ O
000 -X- _ O
test -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
both -X- _ O
phrases -X- _ O
are -X- _ O
previously -X- _ O
unseen -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
predictions -X- _ O
are -X- _ O
almost -X- _ O
as -X- _ O
good -X- _ O
at -X- _ O
r -X- _ B-MetricName
= -X- _ O
0.920 -X- _ B-MetricValue
. -X- _ O
On -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
3 -X- _ O
, -X- _ O
100 -X- _ O
test -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
at -X- _ O
We -X- _ O
also -X- _ O
analyze -X- _ O
our -X- _ O
model -X- _ O
's -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
the -X- _ O
gold -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
either -X- _ O
0 -X- _ B-MetricValue
or -X- _ O
1 -X- _ B-MetricValue
. -X- _ O
The -X- _ O
latter -X- _ O
case -X- _ O
reflects -X- _ O
an -X- _ O
important -X- _ O
property -X- _ O
of -X- _ O
the -X- _ O
denotation -X- _ O
graph -X- _ O
, -X- _ O
since -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
when -X- _ O
x -X- _ O
is -X- _ O
an -X- _ O
ancestor -X- _ O
of -X- _ O
y. -X- _ O
More -X- _ O
generally -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
interpret -X- _ O
P -X- _ O
( -X- _ O
h -X- _ O
| -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
as -X- _ O
a -X- _ O
confident -X- _ O
prediction -X- _ O
of -X- _ O
entailment -X- _ O
, -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
h -X- _ O
| -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
as -X- _ O
a -X- _ O
confident -X- _ O
prediction -X- _ O
of -X- _ O
contradiction -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
predicted -X- _ O
conditional -X- _ O
probabilities -X- _ O
for -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
gold -X- _ O
P -X- _ O
( -X- _ O
h -X- _ O
| -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
( -X- _ O
top -X- _ O
) -X- _ O
and -X- _ O
gold -X- _ O
P -X- _ O
( -X- _ O
h -X- _ O
| -X- _ O
p -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
( -X- _ O
bottom -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
's -X- _ O
predictions -X- _ O
on -X- _ O
unseen -X- _ O
phrase -X- _ O
pairs -X- _ O
( -X- _ O
gray -X- _ O
bars -X- _ O
) -X- _ O
are -X- _ O
nearly -X- _ O
as -X- _ O
accurate -X- _ O
as -X- _ O
its -X- _ O
predictions -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
test -X- _ O
data -X- _ O
( -X- _ O
black -X- _ O
bars -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
phrase -X- _ O
pairs -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
from -X- _ O
the -X- _ O
denotation -X- _ O
graph -X- _ O
generated -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
FLICKR30 -X- _ B-DatasetName
K -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Young -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
all -X- _ O
271 -X- _ O
, -X- _ O
062 -X- _ O
phrases -X- _ O
that -X- _ O
occur -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
10 -X- _ O
images -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
phrases -X- _ O
are -X- _ O
frequent -X- _ O
enough -X- _ O
that -X- _ O
their -X- _ O
computed -X- _ O
denotational -X- _ O
probabilities -X- _ O
are -X- _ O
reliable -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
FLICKR30 -X- _ B-DatasetName
K -X- _ I-DatasetName
captions -X- _ O
are -X- _ O
lemmatized -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
denotation -X- _ O
graph -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
phrases -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
described -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
are -X- _ O
lemmatized -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
all -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
the -X- _ O
two -X- _ O
phrases -X- _ O
have -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
image -X- _ O
in -X- _ O
common -X- _ O
. -X- _ O
These -X- _ O
constitute -X- _ O
45 -X- _ O
million -X- _ O
phrase -X- _ O
pairs -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
with -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
phrase -X- _ O
pairs -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
that -X- _ O
have -X- _ O
no -X- _ O
images -X- _ O
in -X- _ O
common -X- _ O
if -X- _ O
N -X- _ O
×P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
≥ -X- _ O
N -X- _ O
−1 -X- _ O
( -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
images -X- _ O
) -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
occur -X- _ O
frequently -X- _ O
enough -X- _ O
that -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
them -X- _ O
to -X- _ O
co -X- _ O
- -X- _ O
occur -X- _ O
at -X- _ O
least -X- _ O
once -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
yields -X- _ O
2 -X- _ O
million -X- _ O
pairs -X- _ O
where -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
. -X- _ O
For -X- _ O
additional -X- _ O
examples -X- _ O
of -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
phrase -X- _ O
pairs -X- _ O
that -X- _ O
have -X- _ O
an -X- _ O
ancestordescendant -X- _ O
relationship -X- _ O
in -X- _ O
the -X- _ O
denotation -X- _ O
graph -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
all -X- _ O
ancestor -X- _ O
- -X- _ O
descendant -X- _ O
pairs -X- _ O
where -X- _ O
each -X- _ O
phrase -X- _ O
occurs -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
2 -X- _ O
images -X- _ O
, -X- _ O
for -X- _ O
an -X- _ O
additional -X- _ O
3 -X- _ O
million -X- _ O
phrase -X- _ O
pairs -X- _ O
. -X- _ O
For -X- _ O
evaluation -X- _ O
purposes -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
assign -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
phrases -X- _ O
to -X- _ O
the -X- _ O
development -X- _ O
pool -X- _ O
and -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
to -X- _ O
the -X- _ O
test -X- _ O
pool -X- _ O
. -X- _ O
The -X- _ O
actual -X- _ O
test -X- _ O
data -X- _ O
then -X- _ O
consists -X- _ O
of -X- _ O
all -X- _ O
phrase -X- _ O
pairs -X- _ O
where -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
phrases -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
pool -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
test -X- _ O
data -X- _ O
contains -X- _ O
10.6 -X- _ O
% -X- _ O
unseen -X- _ O
phrases -X- _ O
by -X- _ O
type -X- _ O
and -X- _ O
51.2 -X- _ O
% -X- _ O
unseen -X- _ O
phrases -X- _ O
by -X- _ O
token -X- _ O
. -X- _ O
All -X- _ O
phrase -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
phrase -X- _ O
that -X- _ O
was -X- _ O
unseen -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
or -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
development -X- _ O
data -X- _ O
was -X- _ O
created -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
. -X- _ O
This -X- _ O
dataset -X- _ O
is -X- _ O
available -X- _ O
to -X- _ O
download -X- _ O
at -X- _ O
http://nlp.cs.illinois.edu/ -X- _ O
HockenmaierGroup -X- _ O
/ -X- _ O
data.html -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
42 -X- _ O
million -X- _ O
phrase -X- _ O
pairs -X- _ O
) -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
512 -X- _ B-HyperparameterValue
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
mean -X- _ B-MetricName
KL -X- _ I-MetricName
divergence -X- _ I-MetricName
on -X- _ O
the -X- _ O
conditional -X- _ O
probabilities -X- _ O
in -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
. -X- _ O
Since -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
Bernoulli -X- _ O
distribution -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
KL -X- _ B-MetricName
divergence -X- _ I-MetricName
for -X- _ O
each -X- _ O
phrase -X- _ O
pair -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
as -X- _ O
D -X- _ O
KL -X- _ O
( -X- _ O
P -X- _ O
| -X- _ O
| -X- _ O
Q -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
Q -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
1 -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
log -X- _ O
1 -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
1 -X- _ O
− -X- _ O
Q -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
where -X- _ O
Q -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
predicted -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

Predictions -X- _ O
trained -X- _ O
with -X- _ O
Cross -X- _ B-MetricName
Entropy -X- _ I-MetricName
Each -X- _ O
phrase -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
that -X- _ O
is -X- _ O
passed -X- _ O
through -X- _ O
an -X- _ O
LSTM -X- _ B-MethodName
to -X- _ O
produce -X- _ O
a -X- _ O
512d -X- _ O
vector -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
the -X- _ O
hypothesis -X- _ O
. -X- _ O
Both -X- _ O
vectors -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
predicted -X- _ O
conditional -X- _ O
probability -X- _ O
and -X- _ O
calculate -X- _ O
the -X- _ O
loss -X- _ B-MetricName
. -X- _ O
can -X- _ O
not -X- _ O
express -X- _ O
P -X- _ O
( -X- _ O
X -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
exactly -X- _ O
, -X- _ O
but -X- _ O
can -X- _ O
get -X- _ O
arbitrarily -X- _ O
close -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
phrase -X- _ O
that -X- _ O
is -X- _ O
extremely -X- _ O
unlikely -X- _ O
. -X- _ O
6 -X- _ O
Our -X- _ O
model -X- _ O
for -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
We -X- _ O
train -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
for -X- _ O
phrases -X- _ O
x -X- _ O
and -X- _ O
y. -X- _ O
This -X- _ O
model -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
LSTM -X- _ B-MethodName
that -X- _ O
outputs -X- _ O
a -X- _ O
512d -X- _ B-HyperparameterValue
vector -X- _ O
which -X- _ O
is -X- _ O
passed -X- _ O
through -X- _ O
an -X- _ O
additional -X- _ O
512d -X- _ B-HyperparameterValue
layer -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
300d -X- _ B-HyperparameterValue
GloVe -X- _ O
vectors -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
840B -X- _ O
tokens -X- _ O
as -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
to -X- _ O
represent -X- _ O
both -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
regardless -X- _ O
of -X- _ O
which -X- _ O
phrase -X- _ O
is -X- _ O
the -X- _ O
premise -X- _ O
or -X- _ O
the -X- _ O
hypothesis -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
pass -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
phrase -X- _ O
x -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
get -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
do -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
phrase -X- _ O
y -X- _ O
to -X- _ O
get -X- _ O
y. -X- _ O
As -X- _ O
previously -X- _ O
described -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
the -X- _ O
elements -X- _ O
of -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
predicted -X- _ O
denotational -X- _ O
probabilities -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
joint -X- _ O
vector -X- _ O
z -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
predicted -X- _ O
denotational -X- _ O
conditional -X- _ O
probability -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
equation -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
illustrates -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
training -X- _ O
data -X- _ O
consists -X- _ O
of -X- _ O
ordered -X- _ O
phrase -X- _ O
pairs -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
denotational -X- _ O
probabilities -X- _ O
of -X- _ O
each -X- _ O
phrase -X- _ O
( -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
Typically -X- _ O
the -X- _ O
pair -X- _ O
y -X- _ O
, -X- _ O
x -X- _ O
will -X- _ O
also -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
per -X- _ O
- -X- _ O
example -X- _ O
loss -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
losses -X- _ O
for -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
log -X- _ O
Q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
log -X- _ O
1−Q -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
log -X- _ O
Q -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
) -X- _ O
log -X- _ O
1−Q -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
− -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
log -X- _ O
Q -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
) -X- _ O
log -X- _ O
1−Q -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O
These -X- _ O
parameters -X- _ O
were -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
data -X- _ O
. -X- _ O
Numerical -X- _ O
issues -X- _ O
In -X- _ O
Section -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
described -X- _ O
the -X- _ O
probability -X- _ O
vectors -X- _ O
x -X- _ O
as -X- _ O
being -X- _ O
in -X- _ O
the -X- _ O
positive -X- _ O
orthant -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
implementation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
unnormalized -X- _ O
log -X- _ O
probabilities -X- _ O
. -X- _ O
This -X- _ O
puts -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
vectors -X- _ O
in -X- _ O
the -X- _ O
negative -X- _ O
orthant -X- _ O
instead -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
prevents -X- _ O
the -X- _ O
gradients -X- _ O
from -X- _ O
becoming -X- _ O
too -X- _ O
small -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
vectors -X- _ O
are -X- _ O
in -X- _ O
R -X- _ O
N -X- _ O
− -X- _ O
, -X- _ O
we -X- _ O
clip -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
elements -X- _ O
of -X- _ O
x -X- _ O
so -X- _ O
that -X- _ O
x -X- _ O
i -X- _ O
≤ -X- _ O
0 -X- _ O
. -X- _ O
To -X- _ O
compute -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
the -X- _ O
elements -X- _ O
of -X- _ O
x -X- _ O
and -X- _ O
clip -X- _ O
the -X- _ O
sum -X- _ O
to -X- _ O
the -X- _ O
range -X- _ O
( -X- _ O
log -X- _ O
( -X- _ O
10 -X- _ O
−10 -X- _ O
) -X- _ O
, -X- _ O
−0.0001 -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
avoid -X- _ O
errors -X- _ O
caused -X- _ O
by -X- _ O
passing -X- _ O
log -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
values -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
The -X- _ O
conditional -X- _ O
log -X- _ O
probability -X- _ O
is -X- _ O
simply -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
− -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
now -X- _ O
the -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
minimum -X- _ O
: -X- _ O
log -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
i -X- _ O
min -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
This -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
minimum -X- _ O
is -X- _ O
a -X- _ O
standard -X- _ O
pooling -X- _ O
operation -X- _ O
( -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
minimum -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
more -X- _ O
common -X- _ O
max -X- _ O
pooling -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
if -X- _ O
x -X- _ O
i -X- _ O
> -X- _ O
y -X- _ O
i -X- _ O
, -X- _ O
neither -X- _ O
element -X- _ O
x -X- _ O
i -X- _ O
nor -X- _ O
y -X- _ O
i -X- _ O
is -X- _ O
updated -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
| -X- _ O
y -X- _ O
) -X- _ O
loss -X- _ O
. -X- _ O
Both -X- _ O
x -X- _ O
i -X- _ O
and -X- _ O
y -X- _ O
i -X- _ O
will -X- _ O
always -X- _ O
be -X- _ O
updated -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
P -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
loss -X- _ O
. -X- _ O

Link -X- _ B-TaskName
prediction -X- _ I-TaskName
The -X- _ O
link -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
is -X- _ O
conducted -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Given -X- _ O
a -X- _ O
test -X- _ O
triple -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
queries -X- _ O
( -X- _ O
? -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
? -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
query -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
scores -X- _ O
candidate -X- _ O
head -X- _ O
( -X- _ O
tail -X- _ O
) -X- _ O
entitieŝ -X- _ O
h -X- _ O
( -X- _ O
t -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
its -X- _ O
belief -X- _ O
thatĥ -X- _ O
( -X- _ O
t -X- _ O
) -X- _ O
completes -X- _ O
the -X- _ O
triple -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
answers -X- _ O
the -X- _ O
query -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
is -X- _ O
of -X- _ O
link -X- _ B-TaskName
prediction -X- _ I-TaskName
is -X- _ O
to -X- _ O
rank -X- _ O
true -X- _ O
triples -X- _ O
( -X- _ O
ĥ -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
or -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
higher -X- _ O
than -X- _ O
false -X- _ O
and -X- _ O
unseen -X- _ O
triples -X- _ O
. -X- _ O
Link -X- _ B-TaskName
prediction -X- _ I-TaskName
performance -X- _ O
is -X- _ O
evaluated -X- _ O
with -X- _ O
mean -X- _ B-MetricName
reciprocal -X- _ I-MetricName
rank -X- _ I-MetricName
( -X- _ O
MRR -X- _ B-MetricName
) -X- _ O
and -X- _ O
hits@k -X- _ B-MetricName
. -X- _ O
MRR -X- _ B-MetricName
is -X- _ O
the -X- _ O
average -X- _ O
reciprocal -X- _ O
of -X- _ O
each -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
entity -X- _ O
's -X- _ O
rank -X- _ O
over -X- _ O
all -X- _ O
( -X- _ O
? -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
? -X- _ O
) -X- _ O
test -X- _ O
triples -X- _ O
. -X- _ O
Hits@k -X- _ B-MetricName
measures -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
test -X- _ O
triples -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
entity -X- _ O
is -X- _ O
ranked -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
predicted -X- _ O
entities -X- _ O
. -X- _ O
In -X- _ O
computing -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
predicted -X- _ O
entities -X- _ O
for -X- _ O
which -X- _ O
( -X- _ O
ĥ -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
G -X- _ O
or -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
G -X- _ O
so -X- _ O
that -X- _ O
known -X- _ O
positive -X- _ O
triples -X- _ O
do -X- _ O
not -X- _ O
artificially -X- _ O
lower -X- _ O
ranking -X- _ O
scores -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
called -X- _ O
" -X- _ O
filtering -X- _ O
" -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Triple -X- _ B-TaskName
classification -X- _ I-TaskName
Given -X- _ O
a -X- _ O
triple -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
triple -X- _ O
classification -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
corresponding -X- _ O
label -X- _ O
y -X- _ O
{ -X- _ O
−1 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
. -X- _ O
Since -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
models -X- _ O
output -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
scores -X- _ O
for -X- _ O
triples -X- _ O
, -X- _ O
we -X- _ O
convert -X- _ O
these -X- _ O
scores -X- _ O
into -X- _ O
labels -X- _ O
by -X- _ O
selecting -X- _ O
a -X- _ O
decision -X- _ O
threshold -X- _ O
per -X- _ O
relation -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
such -X- _ O
that -X- _ O
validation -X- _ O
accuracy -X- _ O
is -X- _ O
maximized -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
question -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
approach -X- _ O
was -X- _ O
used -X- _ O
by -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
sets -X- _ O
of -X- _ O
evaluation -X- _ O
negatives -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
generate -X- _ O
one -X- _ O
negative -X- _ O
per -X- _ O
positive -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
positive -X- _ O
triple -X- _ O
's -X- _ O
tail -X- _ O
entity -X- _ O
by -X- _ O
a -X- _ O
tail -X- _ O
entity -X- _ O
t -X- _ O
sampled -X- _ O
uniformly -X- _ O
at -X- _ O
random -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
generate -X- _ O
negatives -X- _ O
by -X- _ O
sampling -X- _ O
tail -X- _ O
entities -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
relative -X- _ O
frequency -X- _ O
in -X- _ O
the -X- _ O
tail -X- _ O
slot -X- _ O
of -X- _ O
all -X- _ O
triples -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
CODEX -X- _ O
hard -X- _ O
negatives -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O

To -X- _ O
pretrain -X- _ O
LAPT -X- _ B-MethodName
and -X- _ O
VA -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
code -X- _ O
of -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
modify -X- _ O
the -X- _ O
pretraining -X- _ O
code -X- _ O
of -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
masked -X- _ B-MetricName
language -X- _ I-MetricName
modeling -X- _ I-MetricName
( -X- _ I-MetricName
MLM -X- _ I-MetricName
) -X- _ I-MetricName
loss -X- _ I-MetricName
. -X- _ O
To -X- _ O
generate -X- _ O
VA -X- _ B-MethodName
vocabularies -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
new -X- _ O
vocabulary -X- _ O
of -X- _ O
size -X- _ B-HyperparameterName
5000 -X- _ B-HyperparameterValue
and -X- _ O
select -X- _ O
the -X- _ O
99 -X- _ O
wordpieces -X- _ O
that -X- _ O
replace -X- _ O
the -X- _ O
most -X- _ O
unknown -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
linear -X- _ O
warmup -X- _ B-HyperparameterName
of -X- _ O
1000 -X- _ B-HyperparameterValue
steps -X- _ O
. -X- _ O
To -X- _ O
pretrain -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
HuggingFace -X- _ O
Transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
Muller -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
half -X- _ O
- -X- _ O
sized -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
with -X- _ O
six -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
and -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
byte -X- _ O
- -X- _ O
pair -X- _ O
vocabulary -X- _ O
of -X- _ O
size -X- _ B-HyperparameterName
52000 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
linear -X- _ O
warmup -X- _ B-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
epoch -X- _ O
. -X- _ O
For -X- _ O
LAPT -X- _ B-MethodName
, -X- _ O
VA -X- _ B-MethodName
, -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
train -X- _ O
for -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
total -X- _ O
, -X- _ O
selecting -X- _ O
the -X- _ O
highest -X- _ O
- -X- _ O
performing -X- _ O
epoch -X- _ O
based -X- _ O
on -X- _ O
validation -X- _ O
masked -X- _ B-MetricName
language -X- _ I-MetricName
modeling -X- _ I-MetricName
loss -X- _ I-MetricName
. -X- _ O
FASTT -X- _ B-MethodName
models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
skipgram -X- _ O
model -X- _ O
for -X- _ O
five -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
the -X- _ O
default -X- _ O
hyperparameters -X- _ O
of -X- _ O
Bojanowski -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Training -X- _ O
of -X- _ O
downstream -X- _ O
parsers -X- _ O
and -X- _ O
taggers -X- _ O
follows -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Kondratyuk -X- _ O
and -X- _ O
Straka -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
inverse -X- _ O
square -X- _ O
- -X- _ O
root -X- _ O
learning -X- _ O
rate -X- _ O
decay -X- _ O
and -X- _ O
linear -X- _ O
warmup -X- _ O
, -X- _ O
and -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
gradual -X- _ O
unfreezing -X- _ O
and -X- _ O
discriminative -X- _ O
finetuning -X- _ O
. -X- _ O
Models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
AllenNLP -X- _ O
, -X- _ O
version -X- _ O
2.1.0 -X- _ O
, -X- _ O
for -X- _ O
up -X- _ O
to -X- _ O
200 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
early -X- _ O
stopping -X- _ O
based -X- _ O
on -X- _ O
validation -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
the -X- _ O
maximum -X- _ O
that -X- _ O
allows -X- _ O
for -X- _ O
successful -X- _ O
training -X- _ O
on -X- _ O
one -X- _ O
GPU -X- _ O
. -X- _ O

Following -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
how -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
pretrained -X- _ B-MethodName
multilingual -X- _ I-MethodName
BERT -X- _ I-MethodName
model -X- _ O
( -X- _ O
MBERT -X- _ B-MethodName
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
lowresource -X- _ O
language -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
both -X- _ O
labeled -X- _ O
and -X- _ O
unlabeled -X- _ O
data -X- _ O
is -X- _ O
scarce -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
has -X- _ O
produced -X- _ O
strong -X- _ O
CWRs -X- _ O
for -X- _ O
many -X- _ O
languages -X- _ O
( -X- _ O
Kondratyuk -X- _ O
and -X- _ O
Straka -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
starting -X- _ O
model -X- _ O
for -X- _ O
many -X- _ O
studies -X- _ O
on -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
Muller -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
MBERT -X- _ B-MethodName
covers -X- _ O
the -X- _ O
languages -X- _ O
with -X- _ O
the -X- _ O
104 -X- _ O
largest -X- _ O
Wikipedias -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
uses -X- _ O
this -X- _ O
data -X- _ O
to -X- _ O
con -X- _ O
- -X- _ O
struct -X- _ O
a -X- _ O
wordpiece -X- _ O
vocabulary -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
train -X- _ O
its -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
are -X- _ O
slightly -X- _ O
oversampled -X- _ O
, -X- _ O
high -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
still -X- _ O
dominate -X- _ O
both -X- _ O
the -X- _ O
final -X- _ O
pretraining -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
vocabulary -X- _ O
( -X- _ O
Ács -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
note -X- _ O
that -X- _ O
target -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
fall -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
MBERT -X- _ B-MethodName
's -X- _ O
pretraining -X- _ O
data -X- _ O
: -X- _ O
the -X- _ O
lowest -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
Type -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
completely -X- _ O
unseen -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
Type -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
resouce -X- _ O
languages -X- _ O
with -X- _ O
more -X- _ O
representation -X- _ O
( -X- _ O
Type -X- _ O
0 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
Due -X- _ O
to -X- _ O
their -X- _ O
poor -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
Type -X- _ O
1 -X- _ O
and -X- _ O
Type -X- _ O
2 -X- _ O
languages -X- _ O
achieve -X- _ O
suboptimal -X- _ O
tokenization -X- _ O
and -X- _ O
higher -X- _ O
rates -X- _ O
of -X- _ O
the -X- _ O
" -X- _ O
unknown -X- _ O
" -X- _ O
wordpiece -X- _ O
5 -X- _ O
when -X- _ O
using -X- _ O
MBERT -X- _ B-MethodName
out -X- _ O
of -X- _ O
the -X- _ O
box -X- _ O
. -X- _ O
This -X- _ O
hinders -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
meaningful -X- _ O
patterns -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
reduced -X- _ O
data -X- _ O
efficiency -X- _ O
and -X- _ O
degraded -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
this -X- _ O
challenge -X- _ O
is -X- _ O
exacerbated -X- _ O
when -X- _ O
modeling -X- _ O
languages -X- _ O
written -X- _ O
in -X- _ O
non -X- _ O
- -X- _ O
Latin -X- _ O
scripts -X- _ O
. -X- _ O
MBERT -X- _ B-MethodName
's -X- _ O
vocabulary -X- _ O
is -X- _ O
heavily -X- _ O
Latin -X- _ O
- -X- _ O
centric -X- _ O
( -X- _ O
Ács -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Muller -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
significantly -X- _ O
larger -X- _ O
portion -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
Latin -X- _ O
scripts -X- _ O
being -X- _ O
represented -X- _ O
with -X- _ O
" -X- _ O
unknown -X- _ O
" -X- _ O
tokens -X- _ O
( -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
and -X- _ O
further -X- _ O
limiting -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
generalize -X- _ O
. -X- _ O
In -X- _ O
effect -X- _ O
, -X- _ O
MBERT -X- _ B-MethodName
's -X- _ O
low -X- _ O
initial -X- _ O
performance -X- _ O
on -X- _ O
such -X- _ O
languages -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
its -X- _ O
inability -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
script -X- _ O
itself -X- _ O
. -X- _ O
To -X- _ O
alleviate -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
poor -X- _ O
tokenization -X- _ O
, -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
specialize -X- _ O
MBERT -X- _ B-MethodName
using -X- _ O
Vocabulary -X- _ O
Augmentation -X- _ O
( -X- _ O
VA -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
they -X- _ O
train -X- _ O
a -X- _ O
new -X- _ O
wordpiece -X- _ O
vocabulary -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
then -X- _ O
select -X- _ O
the -X- _ O
99 -X- _ O
most -X- _ O
common -X- _ O
wordpieces -X- _ O
in -X- _ O
the -X- _ O
new -X- _ O
vocabulary -X- _ O
that -X- _ O
replace -X- _ O
" -X- _ O
unknown -X- _ O
" -X- _ O
tokens -X- _ O
under -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
. -X- _ O
They -X- _ O
then -X- _ O
add -X- _ O
these -X- _ O
99 -X- _ O
wordpieces -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
and -X- _ O
continue -X- _ O
pretraining -X- _ O
MBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
for -X- _ O
additional -X- _ O
steps -X- _ O
. -X- _ O
They -X- _ O
further -X- _ O
describe -X- _ O
a -X- _ O
tiered -X- _ O
variant -X- _ O
( -X- _ O
TVA -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
larger -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
these -X- _ O
99 -X- _ O
new -X- _ O
wordpieces -X- _ O
. -X- _ O
VA -X- _ O
yields -X- _ O
strong -X- _ O
gains -X- _ O
over -X- _ O
unadapted -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
dependency -X- _ O
parsing -X- _ O
in -X- _ O
four -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
with -X- _ O
Latin -X- _ O
scripts -X- _ O
. -X- _ O
How -X- _ O
- -X- _ O
ever -X- _ O
, -X- _ O
no -X- _ O
evaluation -X- _ O
has -X- _ O
been -X- _ O
performed -X- _ O
on -X- _ O
other -X- _ O
tasks -X- _ O
or -X- _ O
on -X- _ O
languages -X- _ O
with -X- _ O
non -X- _ O
- -X- _ O
Latin -X- _ O
scripts -X- _ O
, -X- _ O
which -X- _ O
raises -X- _ O
our -X- _ O
first -X- _ O
research -X- _ O
question -X- _ O
: -X- _ O
RQ1 -X- _ O
: -X- _ O
Do -X- _ O
the -X- _ O
conclusions -X- _ O
of -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
hold -X- _ O
for -X- _ O
other -X- _ O
tasks -X- _ O
and -X- _ O
for -X- _ O
languages -X- _ O
with -X- _ O
non -X- _ O
- -X- _ O
Latin -X- _ O
scripts -X- _ O
? -X- _ O
We -X- _ O
can -X- _ O
view -X- _ O
VA -X- _ O
and -X- _ O
TVA -X- _ O
as -X- _ O
an -X- _ O
instantation -X- _ O
of -X- _ O
a -X- _ O
more -X- _ O
general -X- _ O
framework -X- _ O
of -X- _ O
vocabulary -X- _ O
augmentation -X- _ O
, -X- _ O
shared -X- _ O
by -X- _ O
other -X- _ O
approaches -X- _ O
to -X- _ O
using -X- _ O
MBERT -X- _ B-MethodName
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
new -X- _ O
vocabulary -X- _ O
V -X- _ O
, -X- _ O
number -X- _ O
of -X- _ O
wordpieces -X- _ O
n -X- _ O
, -X- _ O
and -X- _ O
learning -X- _ O
rate -X- _ O
multiplier -X- _ O
a -X- _ O
, -X- _ O
the -X- _ O
n -X- _ O
most -X- _ O
common -X- _ O
wordpieces -X- _ O
in -X- _ O
V -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
. -X- _ O
Additional -X- _ O
pretraining -X- _ O
is -X- _ O
then -X- _ O
performed -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
n -X- _ O
wordpieces -X- _ O
taking -X- _ O
on -X- _ O
a -X- _ O
learning -X- _ O
rate -X- _ O
a -X- _ O
times -X- _ O
greater -X- _ O
than -X- _ O
the -X- _ O
overall -X- _ O
learning -X- _ B-HyperparameterValue
rate -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
VA -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
99 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ B-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
while -X- _ O
we -X- _ O
treat -X- _ O
a -X- _ B-HyperparameterName
as -X- _ O
a -X- _ O
hyperparameter -X- _ O
for -X- _ O
TVA -X- _ O
. -X- _ O
The -X- _ O
related -X- _ O
E -X- _ B-MethodName
- -X- _ I-MethodName
MBERT -X- _ I-MethodName
method -X- _ O
of -X- _ O
sets -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
| -X- _ B-HyperparameterValue
V -X- _ I-HyperparameterValue
| -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ B-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
. -X- _ O
Investigating -X- _ O
various -X- _ O
other -X- _ O
instantiations -X- _ O
of -X- _ O
this -X- _ O
framework -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
research -X- _ O
direction -X- _ O
, -X- _ O
though -X- _ O
it -X- _ O
is -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
describes -X- _ O
CAS -X- _ O
IIE -X- _ O
's -X- _ O
submission -X- _ O
to -X- _ O
the -X- _ O
WMT20 -X- _ B-DatasetName
German↔French -X- _ B-TaskName
news -X- _ I-TaskName
translation -X- _ I-TaskName
task -X- _ I-TaskName
. -X- _ O
We -X- _ O
investigate -X- _ O
extremely -X- _ O
deep -X- _ O
models -X- _ O
( -X- _ O
with -X- _ O
48 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
) -X- _ O
and -X- _ O
exploit -X- _ O
effective -X- _ O
strategies -X- _ O
to -X- _ O
better -X- _ O
utilize -X- _ O
parallel -X- _ O
data -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
monolingual -X- _ O
data -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
our -X- _ O
German -X- _ O
French -X- _ O
system -X- _ O
achieved -X- _ O
35.0 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and -X- _ O
ranked -X- _ O
the -X- _ O
second -X- _ O
among -X- _ O
all -X- _ O
anonymous -X- _ O
submissions -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
French -X- _ O
German -X- _ O
system -X- _ O
achieved -X- _ O
36.6 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and -X- _ O
ranked -X- _ O
the -X- _ O
fourth -X- _ O
in -X- _ O
all -X- _ O
anonymous -X- _ O
submissions -X- _ O
. -X- _ O

Results -X- _ O
and -X- _ O
ablations -X- _ O
for -X- _ O
De -X- _ O
Fr -X- _ O
Fr -X- _ O
De -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
case -X- _ O
- -X- _ O
sensitive -X- _ O
SacreBLEU -X- _ B-MetricName
scores -X- _ O
using -X- _ O
Sacre -X- _ O
- -X- _ O
BLEU -X- _ O
( -X- _ O
Post -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
3 -X- _ O
, -X- _ O
using -X- _ O
international -X- _ O
tokenization -X- _ O
for -X- _ O
German↔French -X- _ O
. -X- _ O
German -X- _ O
French -X- _ O
For -X- _ O
De -X- _ O
Fr -X- _ O
, -X- _ O
iterative -X- _ B-MethodName
BT -X- _ I-MethodName
improves -X- _ O
our -X- _ O
baseline -X- _ O
performance -X- _ O
on -X- _ O
newstest -X- _ B-DatasetName
2019 -X- _ O
by -X- _ O
about -X- _ O
2.5 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
. -X- _ O
The -X- _ O
addition -X- _ O
of -X- _ O
KD -X- _ O
and -X- _ O
model -X- _ O
ensemble -X- _ O
improves -X- _ O
single -X- _ O
model -X- _ O
performance -X- _ O
by -X- _ O
0.8 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
, -X- _ O
but -X- _ O
combining -X- _ O
this -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
reranking -X- _ O
gives -X- _ O
us -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
. -X- _ O
Our -X- _ O
final -X- _ O
submission -X- _ O
for -X- _ O
WMT20 -X- _ B-DatasetName
achieves -X- _ O
35.0 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
for -X- _ O
German -X- _ B-TaskName
French -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
ranked -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
place -X- _ O
) -X- _ O
. -X- _ O
French -X- _ O
German -X- _ O
For -X- _ O
Fr -X- _ O
De -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
similar -X- _ O
improvements -X- _ O
with -X- _ O
iterative -X- _ B-MethodName
BT -X- _ I-MethodName
by -X- _ O
about -X- _ O
2.3 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
. -X- _ O
KD -X- _ O
, -X- _ O
ensembling -X- _ O
, -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
add -X- _ O
an -X- _ O
additional -X- _ O
1.4 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
, -X- _ O
with -X- _ O
reranking -X- _ O
contributing -X- _ O
0.9 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
. -X- _ O
Our -X- _ O
final -X- _ O
submission -X- _ O
for -X- _ O
WMT20 -X- _ B-DatasetName
achieves -X- _ O
36.6 -X- _ O
BLEU -X- _ B-MetricName
points -X- _ O
for -X- _ O
French -X- _ B-TaskName
German -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
ranked -X- _ O
in -X- _ O
the -X- _ O
fourth -X- _ O
among -X- _ O
anonymous -X- _ O
submissions -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
PyTorch -X- _ O
implementation -X- _ O
of -X- _ O
Transformer -X- _ B-MethodName
2 -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
base -X- _ O
setting -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
are -X- _ O
of -X- _ O
48 -X- _ B-HyperparameterValue
and -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
fixed -X- _ O
as -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
4096 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
parameter -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
update -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
freq -X- _ I-HyperparameterName
as -X- _ O
16 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
structure -X- _ O
of -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
has -X- _ O
evolved -X- _ O
quickly -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
RNN -X- _ O
- -X- _ O
based -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
CNN -X- _ O
- -X- _ O
based -X- _ O
( -X- _ O
Gehring -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
attentionbased -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
systems -X- _ O
. -X- _ O
Deep -X- _ O
neural -X- _ O
networks -X- _ O
have -X- _ O
revolutionized -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
in -X- _ O
various -X- _ O
communities -X- _ O
, -X- _ O
from -X- _ O
computer -X- _ O
vision -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
deep -X- _ B-MethodName
transformer -X- _ I-MethodName
model -X- _ O
proposed -X- _ O
by -X- _ O
our -X- _ O
work -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
relying -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
encoder -X- _ O
stack -X- _ O
to -X- _ O
directly -X- _ O
learn -X- _ O
a -X- _ O
desired -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
let -X- _ O
each -X- _ O
encoder -X- _ O
block -X- _ O
learn -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
representation -X- _ O
and -X- _ O
enhance -X- _ O
it -X- _ O
by -X- _ O
encoding -X- _ O
spatial -X- _ O
dependencies -X- _ O
using -X- _ O
a -X- _ O
bottom -X- _ O
- -X- _ O
up -X- _ O
network -X- _ O
. -X- _ O
For -X- _ O
coordination -X- _ O
, -X- _ O
we -X- _ O
attend -X- _ O
each -X- _ O
block -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
both -X- _ O
the -X- _ O
corresponding -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
with -X- _ O
spatial -X- _ O
dependencies -X- _ O
. -X- _ O
This -X- _ O
not -X- _ O
only -X- _ O
shortens -X- _ O
the -X- _ O
path -X- _ O
of -X- _ O
error -X- _ O
propagation -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
helps -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
lower -X- _ O
level -X- _ O
information -X- _ O
from -X- _ O
being -X- _ O
forgotten -X- _ O
or -X- _ O
diluted -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
details -X- _ O
( -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
figure -X- _ O
1 -X- _ O
) -X- _ O
of -X- _ O
our -X- _ O
deep -X- _ O
architectures -X- _ O
as -X- _ O
below -X- _ O
: -X- _ O
Block -X- _ B-MethodName
- -X- _ I-MethodName
Scale -X- _ I-MethodName
Collaboration -X- _ I-MethodName
. -X- _ O
An -X- _ O
intuitive -X- _ O
extension -X- _ O
of -X- _ O
naive -X- _ O
stacking -X- _ O
of -X- _ O
layers -X- _ O
is -X- _ O
to -X- _ O
group -X- _ O
few -X- _ O
stacked -X- _ O
layers -X- _ O
into -X- _ O
a -X- _ O
block -X- _ O
. -X- _ O
We -X- _ O
suppose -X- _ O
that -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
blocks -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
N -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
block -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
has -X- _ O
M -X- _ O
n -X- _ O
( -X- _ O
n -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
N -X- _ O
} -X- _ O
) -X- _ O
identical -X- _ O
layers -X- _ O
, -X- _ O
while -X- _ O
each -X- _ O
decoder -X- _ O
block -X- _ O
contains -X- _ O
one -X- _ O
layer -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
adjust -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
each -X- _ O
M -X- _ O
n -X- _ O
flexibly -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
depth -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
block -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
: -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
= -X- _ O
BLOCK -X- _ O
e -X- _ O
( -X- _ O
B -X- _ O
n−1 -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
BLOCK -X- _ O
e -X- _ O
( -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
block -X- _ O
function -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
layer -X- _ O
function -X- _ O
F -X- _ O
( -X- _ O
) -X- _ O
is -X- _ O
iterated -X- _ O
M -X- _ O
n -X- _ O
times -X- _ O
, -X- _ O
i.e. -X- _ O
where -X- _ O
l -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
M -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
l -X- _ O
e -X- _ O
and -X- _ O
Θ -X- _ O
n -X- _ O
, -X- _ O
l -X- _ O
e -X- _ O
are -X- _ O
the -X- _ O
representation -X- _ O
and -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
block -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
decoder -X- _ O
works -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
way -X- _ O
but -X- _ O
the -X- _ O
layer -X- _ O
function -X- _ O
G -X- _ O
( -X- _ O
) -X- _ O
is -X- _ O
iterated -X- _ O
only -X- _ O
once -X- _ O
in -X- _ O
each -X- _ O
block -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
d -X- _ O
= -X- _ O
BLOCK -X- _ O
d -X- _ O
( -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
) -X- _ O
= -X- _ O
G -X- _ O
( -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
; -X- _ O
Θ -X- _ O
n -X- _ O
d -X- _ O
) -X- _ O
+ -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Each -X- _ O
block -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
encoder -X- _ O
block -X- _ O
. -X- _ O
Contextual -X- _ O
Collaboration -X- _ O
. -X- _ O
To -X- _ O
model -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
spatial -X- _ O
dependencies -X- _ O
and -X- _ O
reuse -X- _ O
global -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
GRU -X- _ O
cell -X- _ O
Q -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
maps -X- _ O
a -X- _ O
hidden -X- _ O
state -X- _ O
c -X- _ O
and -X- _ O
an -X- _ O
additional -X- _ O
inputx -X- _ O
into -X- _ O
a -X- _ O
new -X- _ O
hidden -X- _ O
state -X- _ O
: -X- _ O
C -X- _ O
n -X- _ O
= -X- _ O
Q -X- _ O
( -X- _ O
C -X- _ O
n−1 -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
n -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
N -X- _ O
] -X- _ O
C -X- _ O
0 -X- _ O
= -X- _ O
E -X- _ O
e -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
E -X- _ O
e -X- _ O
is -X- _ O
the -X- _ O
embedding -X- _ O
matrix -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
input -X- _ O
x. -X- _ O
The -X- _ O
new -X- _ O
state -X- _ O
C -X- _ O
n -X- _ O
can -X- _ O
be -X- _ O
fused -X- _ O
with -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
subsequent -X- _ O
blocks -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
calculated -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
way -X- _ O
: -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
= -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
Mn -X- _ O
e -X- _ O
, -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
l -X- _ O
e -X- _ O
= -X- _ O
F -X- _ O
( -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
l−1 -X- _ O
e -X- _ O
, -X- _ O
C -X- _ O
n−1 -X- _ O
; -X- _ O
Θ -X- _ O
n -X- _ O
, -X- _ O
l -X- _ O
e -X- _ O
) -X- _ O
+ -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
l−1 -X- _ O
e -X- _ O
, -X- _ O
H -X- _ O
n -X- _ O
, -X- _ O
0 -X- _ O
e -X- _ O
= -X- _ O
B -X- _ O
n−1 -X- _ O
e -X- _ O
. -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Similarly -X- _ O
, -X- _ O
for -X- _ O
decoder -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
B -X- _ O
n -X- _ O
d -X- _ O
= -X- _ O
BLOCK -X- _ O
d -X- _ O
( -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
) -X- _ O
= -X- _ O
G -X- _ O
( -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
, -X- _ O
B -X- _ O
n -X- _ O
e -X- _ O
, -X- _ O
C -X- _ O
n -X- _ O
; -X- _ O
Θ -X- _ O
n -X- _ O
d -X- _ O
) -X- _ O
+ -X- _ O
B -X- _ O
n−1 -X- _ O
d -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
systems -X- _ O
IIE -X- _ O
submitted -X- _ O
for -X- _ O
the -X- _ O
WMT20 -X- _ B-DatasetName
shared -X- _ O
task -X- _ O
on -X- _ O
German↔French -X- _ O
news -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O
Our -X- _ O
systems -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
with -X- _ O
some -X- _ O
effective -X- _ O
improvements -X- _ O
. -X- _ O
Multiscale -X- _ O
collaborative -X- _ O
deep -X- _ O
architecture -X- _ O
, -X- _ O
data -X- _ B-TaskName
selection -X- _ I-TaskName
, -X- _ O
back -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
, -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
, -X- _ O
model -X- _ O
ensemble -X- _ O
and -X- _ O
re -X- _ B-TaskName
- -X- _ I-TaskName
ranking -X- _ I-TaskName
are -X- _ O
employed -X- _ O
and -X- _ O
proven -X- _ O
effective -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
Our -X- _ O
German -X- _ O
French -X- _ O
system -X- _ O
achieved -X- _ O
35.0 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and -X- _ O
ranked -X- _ O
the -X- _ O
second -X- _ O
among -X- _ O
all -X- _ O
anonymous -X- _ O
submissions -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
French -X- _ O
German -X- _ O
system -X- _ O
achieved -X- _ O
36.6 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and -X- _ O
ranked -X- _ O
the -X- _ O
fourth -X- _ O
in -X- _ O
all -X- _ O
anonymous -X- _ O
submissions -X- _ O
. -X- _ O

Sample -X- _ B-MethodName
Shielding -X- _ I-MethodName
, -X- _ O
an -X- _ O
intuitively -X- _ O
designed -X- _ O
defense -X- _ O
which -X- _ O
is -X- _ O
attacker -X- _ O
and -X- _ O
classifier -X- _ O
agnostic -X- _ O
, -X- _ O
protects -X- _ O
effectively -X- _ O
; -X- _ O
reducing -X- _ O
ASR -X- _ B-MetricName
from -X- _ B-MetricValue
90 -X- _ I-MetricValue
- -X- _ I-MetricValue
100 -X- _ I-MetricValue
% -X- _ I-MetricValue
down -X- _ O
to -X- _ O
14 -X- _ B-MetricName
- -X- _ I-MetricName
34 -X- _ I-MetricName
% -X- _ I-MetricName
with -X- _ O
minimal -X- _ O
accuracy -X- _ B-MetricName
loss -X- _ O
( -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
in -X- _ O
original -X- _ O
texts -X- _ O
. -X- _ O
The -X- _ O
randomness -X- _ O
( -X- _ O
through -X- _ O
sampling -X- _ O
) -X- _ O
provides -X- _ O
unreliable -X- _ O
feedback -X- _ O
for -X- _ O
attackers -X- _ O
, -X- _ O
thus -X- _ O
it -X- _ O
even -X- _ O
thwarts -X- _ O
attackers -X- _ O
who -X- _ O
have -X- _ O
query -X- _ O
access -X- _ O
to -X- _ O
classifiers -X- _ O
protected -X- _ O
with -X- _ O
Sample -X- _ B-MethodName
Shielding -X- _ I-MethodName
. -X- _ O
Attack -X- _ O
strategies -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
perturbation -X- _ O
to -X- _ O
make -X- _ O
sure -X- _ O
a -X- _ O
majority -X- _ O
of -X- _ O
samples -X- _ O
fail -X- _ O
at -X- _ O
classification -X- _ B-TaskName
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
will -X- _ O
risk -X- _ O
semantic -X- _ O
integrity -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
Sample -X- _ B-MethodName
Shielding -X- _ I-MethodName
to -X- _ O
cause -X- _ O
ripples -X- _ O
in -X- _ O
future -X- _ O
adversarial -X- _ O
attack -X- _ O
strategies -X- _ O
while -X- _ O
providing -X- _ O
text -X- _ O
classifiers -X- _ O
with -X- _ O
a -X- _ O
definite -X- _ O
advantage -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
strongest -X- _ O
classifier -X- _ O
achieving -X- _ O
91 -X- _ B-MetricValue
- -X- _ I-MetricValue
100 -X- _ I-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
original -X- _ O
datasets -X- _ O
. -X- _ O
Attacks -X- _ O
are -X- _ O
highly -X- _ O
successful -X- _ O
against -X- _ O
unshielded -X- _ O
texts -X- _ O
. -X- _ O
TextFooler -X- _ B-MethodName
and -X- _ O
Bert -X- _ B-MethodName
- -X- _ I-MethodName
Attack -X- _ I-MethodName
are -X- _ O
the -X- _ O
most -X- _ O
successful -X- _ O
, -X- _ O
dropping -X- _ O
accuracies -X- _ B-MetricName
to -X- _ O
0 -X- _ B-MetricValue
- -X- _ I-MetricValue
5 -X- _ I-MetricValue
% -X- _ I-MetricValue
generally -X- _ O
. -X- _ O
Attacks -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
strong -X- _ O
drops -X- _ O
with -X- _ O
minimal -X- _ O
amount -X- _ O
of -X- _ O
text -X- _ O
perturbed -X- _ O
( -X- _ O
about -X- _ O
10 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
percent -X- _ O
of -X- _ O
words -X- _ O
perturbed -X- _ O
across -X- _ O
datasets -X- _ O
for -X- _ O
each -X- _ O
attack -X- _ O
are -X- _ O
about -X- _ O
equal -X- _ O
in -X- _ O
the -X- _ O
mid -X- _ O
regions -X- _ O
of -X- _ O
the -X- _ O
plots -X- _ O
. -X- _ O
For -X- _ O
AG -X- _ B-DatasetName
News -X- _ I-DatasetName
, -X- _ O
attacks -X- _ O
are -X- _ O
less -X- _ O
successful -X- _ O
against -X- _ O
BERT -X- _ B-MethodName
; -X- _ O
accuracy -X- _ B-MetricName
drops -X- _ O
to -X- _ O
19 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
strongest -X- _ O
attack -X- _ O
( -X- _ O
TextFooler -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
to -X- _ O
49 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
weakest -X- _ O
( -X- _ O
TextBugger -X- _ B-MethodName

Increasing -X- _ O
p -X- _ B-HyperparameterName
raises -X- _ O
the -X- _ O
risk -X- _ O
of -X- _ O
samples -X- _ O
containing -X- _ O
increased -X- _ O
amounts -X- _ O
of -X- _ O
perturbed -X- _ O
text -X- _ O
. -X- _ O
Decreasing -X- _ O
k -X- _ B-HyperparameterName
raises -X- _ O
the -X- _ O
risk -X- _ O
of -X- _ O
not -X- _ O
covering -X- _ O
enough -X- _ O
of -X- _ O
the -X- _ O
unperturbed -X- _ O
portions -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O
While -X- _ O
our -X- _ O
settings -X- _ O
of -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.3 -X- _ B-HyperparameterValue
and -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
for -X- _ O
our -X- _ O
main -X- _ O
results -X- _ O
are -X- _ O
reasonable -X- _ O
values -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
optimal -X- _ O
. -X- _ O
Optimal -X- _ O
p. -X- _ B-HyperparameterName
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
com -X- _ O
- -X- _ O
binations -X- _ O
of -X- _ O
attacks -X- _ O
against -X- _ O
LSTM -X- _ B-MethodName
on -X- _ O
IMDB -X- _ B-DatasetName
with -X- _ O
word -X- _ O
shielding -X- _ O
as -X- _ O
the -X- _ O
defense -X- _ O
, -X- _ O
k -X- _ B-HyperparameterName
fixed -X- _ O
at -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O
As -X- _ O
we -X- _ O
increase -X- _ O
p -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
continued -X- _ O
drop -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
a -X- _ O
higher -X- _ O
p -X- _ B-HyperparameterName
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
capture -X- _ O
perturbed -X- _ O
text -X- _ O
. -X- _ O
The -X- _ O
optimal -X- _ O
value -X- _ O
range -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
in -X- _ O
0.2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
0.4 -X- _ I-HyperparameterValue
range -X- _ O
, -X- _ O
although -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
see -X- _ O
large -X- _ O
drops -X- _ O
until -X- _ O
0.6 -X- _ B-HyperparameterValue
onward -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
examined -X- _ O
the -X- _ O
same -X- _ O
combination -X- _ O
on -X- _ O
AG -X- _ B-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
since -X- _ O
it -X- _ O
's -X- _ O
texts -X- _ O
are -X- _ O
considerably -X- _ O
shorter -X- _ O
and -X- _ O
found -X- _ O
consistent -X- _ O
results -X- _ O
. -X- _ O
Optimal -X- _ O
k. -X- _ B-HyperparameterName
Figure -X- _ O
6 -X- _ O
shows -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
attacks -X- _ O
against -X- _ O
LSTM -X- _ B-MethodName
on -X- _ O
IMDB -X- _ B-DatasetName
with -X- _ O
word -X- _ O
sampling -X- _ O
as -X- _ O
the -X- _ O
defense -X- _ O
, -X- _ O
p -X- _ B-HyperparameterName
fixed -X- _ O
at -X- _ O
0.3 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
optimal -X- _ O
k -X- _ B-HyperparameterName
is -X- _ O
not -X- _ O
as -X- _ O
clear -X- _ O
as -X- _ O
p. -X- _ B-HyperparameterName
We -X- _ O
see -X- _ O
clear -X- _ O
increases -X- _ O
after -X- _ O
30 -X- _ O
samples -X- _ O
, -X- _ O
but -X- _ O
then -X- _ O
the -X- _ O
optimal -X- _ O
k -X- _ B-HyperparameterName
varies -X- _ O
depending -X- _ O
on -X- _ O
attack -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
leveling -X- _ O
off -X- _ O
around -X- _ O
90 -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
gives -X- _ O
some -X- _ O
credence -X- _ O
to -X- _ O
our -X- _ O
chosen -X- _ O
k -X- _ B-HyperparameterName
of -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
also -X- _ O
found -X- _ O
similar -X- _ O
results -X- _ O
when -X- _ O
examining -X- _ O
the -X- _ O
same -X- _ O
combination -X- _ O
on -X- _ O
AG -X- _ B-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Figure -X- _ O
7 -X- _ O
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
k -X- _ B-HyperparameterName
stabilized -X- _ O
lower -X- _ O
( -X- _ O
about -X- _ O
50 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O

