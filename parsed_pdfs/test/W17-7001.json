{"authors": "Enrique Valeriano; Arturo Oncevay-Marcos", "pub_date": "", "title": "Exploratory Analysis for Ontology Learning from Social Events on Social Media Streaming in Spanish", "abstract": "The problem of event analysis in Spanish social media streaming is that of difficulty on automatically processing the data as well as obtaining the most relevant information, such as mentioned by Derczynski et al. (2015). An event is defined as a real world occurrence that takes place in a specific time and space; Atefeh and Khreich (2013) identifies these occurrences by the entities that took part on it as well as the activities done in it. This project focuses on researching about the viability of modeling these events as ontologies using an automatic approach for entities and relationships extraction in order to obtain relevant information about the event in case. Spanish data from Twitter was used as a study case and tested with the developed application.", "sections": [{"heading": "Introduction", "text": "According to Lobzhanidze et al. (2013), globalization and the increased use of social networks has made it possible for news and events related information to be propagated in a much faster manner to every part of the world. It is in this context that event analysis is the most relevant since, as Valkanas and Gunopulos (2013) mention, now there is more data available to study and analyze than ever before.\nAn event is defined as a real world occurrence that takes place in a specific time and space; Atefeh and Khreich (2013) identifies these occurrences by the entities that took part on it as well as the activities done in it. Events will be the main study object in this paper and, more specifically, event data in Spanish obtained from Twitter will be used to test the different methods and techniques exposed on each Section.\nIn order to effectively analyze events there are two steps that need to be taken into consideration as mentioned in Kumbla (2016): (1) event data acquisition, and (2) event data processing.\nThe first step is the one that benefits the most by social media streaming since more data is available, though one of the downsides to this is that the data is usually not ready to be used right away and most of the times a preprocessing step needs to happen. This step is further explained on section Section 3.\nThe second step will be the main focus on this paper since the biggest problem on event data analysis in Spanish is this one. In particular, automatic approaches for entities and relationships extraction will be presented on Section 4.\nThe remainder of this paper is organized as follows. In Section 2 some relevant related work is exposed. Later, in Section 3 the event acquisition process is further expanded upon. The ontology structure used for the events representation as well as the algorithms employed in order to obtain entities and relationships between these are further explained on Section 4. Section 5 introduces a simple application developed in order to make use of the algorithms and techniques mentioned on the previous sections. On section 6 we compare the results obtained with manually created ontologies and obtain precision and recall values for each case. Finally, concluding remarks are provided in Section 7.\nIn Al-Smadi and Qawasmeh (2016) an unsupervised approach for event extraction from Arabic tweets is discussed. Entities appearing in the data are linked to corresponding entities found on Wikipedia and DBpedia through an ontology based knowledge base. The entities from the data are extracted based on rules related to the Arabic language.\nIn Derczynski et al. (2015) a comparative evaluation of different NER is done based on three different datasets. Also, some common challenges or errors when handling data from Twitter are presented as well as methods for reducing microblog noise through pre-processing such as language identification, POStagging and normalization.\nIn Ilknur et al. (2011) a framework for learning relations between entities in Twitter is presented. This framework allows for entities as well as entity types or topics to be detected, which results in a graph connecting semantically enriched resources to their respective entities. Then relation discovery strategies are employed to detect pair of entities that have a certain type of relationship in a specific period of time.\nIn Raimond and Abdallah (2007) an event ontology is described. This model also contains some key characteristics such as place, location, agents and products. On the other hand, event-subevent relationships are used to build the related ontologies. This model was developed for the Center for Digital Music and tested by structuring proceedings and concert descriptions.\nFinally, an ontology model for events is proposed in which entities are extracted using the CMU tweet analyzer and relationships are inferred from Wikipedia, DBpedia and Web data. This approach also uses a POS-tagging step in order to obtain the initial set of entities to process.", "n_publication_ref": 8, "n_figure_ref": 0}, {"heading": "Event data acquisition 3.1 Data retrieval", "text": "As it was mentioned before, nowadays there are numerous avenues for event data acquisition. For this paper Twitter was chosen as the social network to use for retrieving data since this data is easily available and a good amount of it is related to events of different categories.\nTwitter's REST API was used in order to retrieve data related to these events: Each dataset had a file per day with all the tweets from the day and contained only the text that represents a tweet per line.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Preprocessing", "text": "With the raw data ready to be used, the preprocessing step followed. The sequence followed is exposed below:\n1. Removing punctuation and unicode only characters except written accents.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Tokenizing the tweets for easier use in Section 4.", "text": "Each tokenized tweet also contains a reference to the original, unprocessed tweet, which will be used on Section 5.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Event data processing 4.1 Ontology learning overview", "text": "Ontology learning is defined by Cimiano (2006) as the automatic acquisition of a domain model from some dataset. In this paper we focus on applying ontology learning techniques for data represented as text.\nCimiano points towards two main approaches for ontology learning:\n1. Machine learning 2. Statistical approach Statistical based algorithms are further discussed on Sections 4.3 and 4.4.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Ontology structure", "text": "Before we start using different techniques in order to populate an ontology or to learn entities and relationships from the data that was retrieved previously, an ontology structure had to be defined.\nThe ontology structure that we define will point us towards different techniques depending on the information that must be retrieved to populate this particular structure. Therefore, the proposed ontology structure in this paper is defined on Figure 1. The ontology will be populated by such triples composed of (Entity, Temporal entity, object). Where Entity denotes a subject that interacts in the event, Temporal entity refers to the date when the particular activity takes place and object is the recipient of the activity.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Entities extraction", "text": "This was one of the main points of interest and research on this paper, how to select the most representative entities for the event in order to not overwhelm people analyzing the results but also to not present too little or irrelevant information.\nIn order to achieve this, two initial tools for entity retrieval were tested:\n1. Stanford NER: The Stanford NER used with a trained Spanish model from late 2016 was used in order to retrieve persons, entities and organizations and group them all together as entities.\n2. UDPipe: UDPipe allows to parse text in order to obtain the grammatical categories of the words in each sentence, as well as the syntactic dependencies or syntactic tree that envelops the whole sentence. The entities are obtained from the grammatical category PROPN.\nThese two approaches were then implemented and tested with each dataset and a manual comparison was made between the entities that each approach captured.\nThe results showed that, while the Stanford NER worked really well in the case where the tweets were news related or had a more formal undertone, such as in the case of the Australian Open, it failed to find a lot of basic entities in the other two datasets where the data was more unstructured as one would very likely find when working on social streaming. Also, the Stanford NER has heavily influenced by correct capitalization and punctuation, whereas UDPipe wasn't influenced by these factors as much.\nBecause of this, UDPipe was chosen as the main initial entity extraction tool moving forward.\nAfter having a set of initial entities, further processing steps were taken to ensure a better result.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Entity clustering", "text": "Entity clustering was done on two stages. First, an algorithm for entity clustering was devised based on two metrics:\n1. Normalized frequency of two entities appearing in a single tweet: The frequency of appearance between two specific entities in tweets.\n2. Average Entity to entity distance in a tweet (i.e. in the sentence \"Nadal venci\u00f3 a Federer\", if both Nadal and Federer are identified as entities, they would have a distance of 3 for this tweet)\nA threshold of 0.125 was set as the minimum normalized frequency for a pair of entities and a minimum average Entity to Entity distance of 1.65. These two values were set based on experimentation with the resulting clustered entities from each dataset.\nAfter that, an approach based on Levenshtein distance (minimum amount of additions, replacements or deletions needed to turn a word into another) was employed, where two entities were clustered together if their distance was more than 0.9 times the length of the longest entity from the two. An example of this distance can be seen on Figure 2.  FCA is one of the approaches for entity extraction detailed on Cimiano (2006). It is the one that garners the most focus on this book as the main set-theoretical approach based on verb-subject components.\nThis approach is based on obtaining the formal context for a specific domain or dataset and then proceed to use it to create a hierarchy ontology.\nAn example of how a formal context would look for a tourism domain knowledge can be seen on Table 1.  Cimiano (2006) bookable rentable rideable hotel X apartment X X bike X X X excursion X trip X\nIn this paper we use the created formal contexts to discriminate between entities based on three metrics:\nConditional(n, v) = P (n, v) = f (n, v) f (v)(1)\nP M I(n, v) = log 2 P (n|v) P (n)(2)\nResnik(n, v) = SR(v) * P (n|v)(3)\nWhere:\n1. f(n,v) => Frequency of apparition of entity n with verb v 2. f(v) => Frequency of apparition of verb v with any entity And:\nSR(v) = n P (n|v) * log 2 P (n|v) P (n)(4)\nA threshold of 0.1 as a minimum value is set for all of the three aforementioned metrics (Conditional, PMI and Resnik weights), meaning that the (entity,verb) pairs that not surpass this threshold for any of the three metrics are pruned.", "n_publication_ref": 2, "n_figure_ref": 1}, {"heading": "Relationships extraction", "text": "In this subsection UDPipe is also used in order to extract the syntactic dependencies, in particular, the focus is to obtain 'dobj' and 'iobj' objects, which refer to direct and indirect object respectively, and then obtain the root verb they stem from.\nBy doing this a verb can be linked to each object and furthermore, the entities related to verb, which were obtained from the Formal Context, can be linked to each object.\nDoing this allows us to add activities for each entity, as well as create a relationship between two entities where one of them appears as an object in the action of another.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Visualization", "text": "A desktop application was developed in order to allow for easier visualization of both the ontology and the resulting activities that each entity participated in, as well as the activities that create a relationship between two particular entities. ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Verification", "text": "In order to verify the approach applied for ontology extraction, we manually created ontologies for each test case where the most relevant entities and relationships are specified based on investigation related to these cases, these ontologies can be seen on Figures 5, 6 and 7.\nThese ontologies were then presented to colleagues with more profound knowledge on each of the events for validation and were redone based on their feedback until they were accepted by them.  From these ontologies we obtained precision and recall values for both entities and relationships for each case. These can be seen on Tables 2, 3 and 4:   The main point of interest in these metrics lies on the precision, where the precision on the Australian Open case in quite higher than on the other two cases. From further inspection on the corresponding data we could infer that this was the case because a big part of the tweets for the Australian Open where either formal tweets made by users representing news outlets or by the players themselves. As for the other two cases, most of the tweets where a mix of news and discussion from common people about these events.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Conclusions and future work", "text": "We conclude that, while the methods exposed on this paper work good enough on cases such as the Australian Open one, there is still work to be done when the general public is more engaged on the event such as the cases of the Puente Piedra toll and the March against the corruption. This paper's aim was to give a foundation and a initial stage of exploratory analysis on social media streaming in Spanish by using ontologies, after which future work could be based upon in order to expand the knowledge in the ontologies or use this analysis together with an event detection system in order to be able to both detect and analyze events in real time.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Knowledge-based approach for event extraction from arabic tweets", "journal": "International Journal of Advanced Computer Science and Applications", "year": "2016", "authors": "M Al-Smadi; O Qawasmeh"}, {"title": "A survey of techniques for event detection in twitter", "journal": "Computational Intelligence", "year": "2013", "authors": "F Atefeh; W Khreich"}, {"title": "Ontology Learning and Population from Text Algorithms, Evaluation and Applications. 223 Spring Street", "journal": "Springer Science+Business Media", "year": "2006", "authors": "P Cimiano"}, {"title": "Analysis of named entity recognition and linking for tweets", "journal": "Information Processing and Management", "year": "2015", "authors": "L Derczynski; D Maynard; G R ; M V E ; G G "}, {"title": "Learning semantic relations between entities in twitter", "journal": "Information Processing and Management", "year": "2011", "authors": "C Ilknur; A F ; H G "}, {"title": "Fast data: Powering real-time big data", "journal": "", "year": "2016", "authors": "S Kumbla"}, {"title": "Mainstream media vs. social media for trending topic prediction -an experimental study", "journal": "", "year": "2013", "authors": "A Lobzhanidze; W Zeng; P Gentry; A Taylor"}, {"title": "The event ontology", "journal": "", "year": "2007", "authors": "Y Raimond; S Abdallah"}, {"title": "Event detection from social media data", "journal": "", "year": "2013", "authors": "G Valkanas; D Gunopulos"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Entity structure", "figure_data": ""}, {"figure_label": "2", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Example of Levenshtein distance", "figure_data": ""}, {"figure_label": "3", "figure_type": "", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Resulting clusters for the Australian Open case", "figure_data": ""}, {"figure_label": "4", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 4 :4Figure 4: Timeline for the entity rafaelnadal", "figure_data": ""}, {"figure_label": "5", "figure_type": "", "figure_id": "fig_4", "figure_caption": "Figure 5 :5Figure 5: Ontology created for the Australian Open case", "figure_data": ""}, {"figure_label": "7", "figure_type": "", "figure_id": "fig_5", "figure_caption": "Figure 7 :7Figure 7: Ontology created for the March against the Corruption case", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Example of a tourism domain knowledge as a formal context", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Metrics for the Australian Open case", "figure_data": "Analyzed parameter MetricValueEntitiesPrecision 0.875EntitiesRecall1.0RelationshipsPrecision 0.952RelationshipsRecall1.0"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ": Metrics for the Puente Piedra's toll caseAnalyzed parameter MetricValueEntitiesPrecision 0.556EntitiesRecall1.0RelationshipsPrecision 0.333RelationshipsRecall1.0"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "", "figure_data": ": Metrics for the March against Corruption caseAnalyzed parameter MetricValueEntitiesPrecision 0.467EntitiesRecall1.0RelationshipsPrecision 0.333RelationshipsRecall0.667"}], "doi": ""}