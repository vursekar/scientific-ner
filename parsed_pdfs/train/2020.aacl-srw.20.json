{"authors": "Payal Khullar", "pub_date": "", "title": "Exploring Statistical and Neural Models for Noun Ellipsis Detection and Resolution in English", "abstract": "Computational approaches to noun ellipsis resolution has been sparse, with only a naive rulebased approach that uses syntactic feature constraints for marking noun ellipsis licensors and selecting their antecedents. In this paper, we further the ellipsis research by exploring several statistical and neural models for both the subtasks involved in the ellipsis resolution process and addressing the representation and contribution of manual features proposed in previous research. Using the best performing models, we build an end-to-end supervised Machine Learning (ML) framework for this task that improves the existing F1 score by 16.55% for the detection and 14.97% for the resolution subtask. Our experiments demonstrate robust scores through pretrained BERT (Bidirectional Encoder Representations from Transformers) embeddings for word representation, and more so the importance of manual features-once again highlighting the syntactic and semantic characteristics of the ellipsis phenomenon. For the classification decision, we notice that a simple Multilayar Perceptron (MLP) works well for the detection of ellipsis; however, Recurrent Neural Networks (RNN) are a better choice for the much harder resolution step.", "sections": [{"heading": "Introduction", "text": "Noun ellipsis is a linguistic phenomenon where the head noun of a noun phrase gets deleted, without making the sentence ungrammatical. For example in the sentence in (1) from (Lobeck, 1995), the noun presentation is elided at \"[e]\". 1. John's presentation on urban development was virtually ignored because [NP Mary's [e]] was so much more interesting.\nThe elided information can be retrieved from the previous context as in (1) or with the knowledge of idiomatic usage of language as in I will be back in two [e]. where two means two minutes. It is also possible that the reference of the elided information comes from extra-linguistic, situational context. For example, consider a speaker pointing towards the roses in a shop and saying an utterance as in I will take two [e]. While human interlocutors resolve any such elided information by disambiguating from context, cognitive commonsense extension and reasoning (Chen, 2016), ellipsis resolution can be a hard task for Natural Language Processing (NLP) systems (Hardt, 1999). Resolution of ellipsis comprises two tasks -detection of the elided material and antecedent selection (Liu et al., 2016b;Nielsen, 2003). Ellipses occur in the environment of certain syntactical structures or trigger words, also known as licensors or triggers of ellipses. They are useful syntactic cues for the detection of noun ellipsis. See Figure 1 for an example of the noun ellipsis resolution process.", "n_publication_ref": 9, "n_figure_ref": 1}, {"heading": "Related Work", "text": "Nominal ellipsis has been a topic of interest in theoretical linguistics for a very long time (Halliday and Hasan, 1976;Dalrymple et al., 1991;Lobeck, 1995;Lappin, 1996;Hobbs and Kehler, 1997;Hardt, 1999;Johnson, 2001;Wijnen et al., 2003;Merchant, 2004;Frazier, 2008;Chung et al., 2010;Mer-chant, 2010;Goksun et al., 2010;Gunther, 2011;Rouveret, 2012;Lindenbergh et al., 2015;van Craenenbroeck and Merchant, 2013;Park, 2017;Hyams et al., 2017;Kim et al., 2019). Computational approaches to the ellipsis phenomenon majorly focus on the Verb Phrase Ellipsis (VPE) along with a few related phenomenon such as gapping, sluicing and do-so anaphora, for instance, the detection of VPE in the Penn Treebank using pattern match (Hardt, 1992), a transformation learning-based approach to generated patterns for VPE resolution (Hardt, 1998), the domain independent VPE detection and resolution using machine learning (Nielsen, 2003), automatically parsed text (Nielsen, 2004b), sentence trimming methods (McShane et al., 2015), linguistic principles (McShane and Babkin, 2016), improved parsing techniques that encode elided material dependencies for reconstruction of sentences containing gapping (Schuster et al., 2018), discriminative and margin infused algorithms (Dean et al., 2016), Multilayer Perceptrons (MLP) and Transformers (Zhang et al., 2019). In recent times, there has been a surge in the computational research on nominal ellipsis and closely related phenomena (Khullar et al., 2020(Khullar et al., , 2019Lapshinova-Koltunski et al., 2018;Menzel, 2017;Menzel and Lapshinova-Koltunski, 2014). For the resolution process, we previously proposed a rule based system (Khullar et al., 2019) that detects noun ellipsis using syntactic constraints on licensors of ellipsis and resolves them by matching Part-of-Speech (POS) tag similarity between the licensor of ellipsis and the modifier of the antecedent. It later fine tunes these syntactic rules on a small curated dataset that contains 234 instances of noun ellipsis along with some negative samples (Khullar et al., 2019). For the present paper, we further the research on noun ellipses by using the NoEl corpus annotated by us previously (Khullar et al., 2020) to experiment with state-ofthe-art ML models.", "n_publication_ref": 37, "n_figure_ref": 0}, {"heading": "The Proposed Approach", "text": "Following the VPE resolution framework presented by (Zhang et al., 2019), we investigate a similar framework for noun ellipsis resolution in English and present alternative choices of the models at each step as shown in Figure 2. We use the NoEl corpus (Khullar et al., 2020) that marks noun ellipsis instances as a separate layer (using the stand-off annotation scheme) on the Cornell Movie Dialogs corpus (Danescu-Niculescu-Mizil and Lee, 2011).\nThe corpus marks a total of 946 annotations, of which 438 are described as endophoric, i.e. with a textual antecedent, and 508 exophoric, i.e. without a textual antecedent.", "n_publication_ref": 3, "n_figure_ref": 1}, {"heading": "Noun Ellipsis Detection", "text": "From a given sentence, we first select all words belonging to the syntactic categories that can license noun ellipsis in English, i.e. cardinal and ordinal numbers, determiners and adjectives (Ross, 1967;Lobeck, 1995;Mitkov, 1999;Saito et al., 2008;Kim et al., 2019;Khullar et al., 2019) using a POS tag filter. The POS tags are obtained from state-ofthe-art spaCy parser (Honnibal and Johnson, 2015).\nFor simplicity, we refer to words with these categories as noun modifiers (although in strict linguistic terms, this might be problematic). For each of these selected noun modifiers, we follow the task specification for VPE detection used by (Nielsen, 2004a;Bos and Spenader, 2011;Liu et al., 2016a;Dean et al., 2016) and present noun ellipsis detection as a binary classification task, where given a noun modifier and the sentence in which it occurs as the input, the goal of the classifier is to predict whether the noun modifier licenses a noun ellipsis or not. Formally, for a given licensor word l i is a licensor in a sentence s, the task is represented as follows:\nf (l i , s) \u2212 \u2192 {0, 1}\nwhere 1 denotes that l i is a licensor in s, and 0 otherwise. We experiment with both static and contextualised word embeddings for word and context representation. For the former, we choose pretrained fastText (FT) word embeddings (Bojanowski et al., 2016) as they provide representations for rare and unknown words that might be frequent in the movie dialogues. For the latter, we use pretrained BERT embeddings from the BERT base uncased wordpiece model for English (Devlin et al., 2019), as these currently offer the most powerful embeddings taking into account a large left and right context.\nfastText We take pretrained FT word embeddings for the noun modifier and sentence in which it is present and sum pool to obtain a single vector that we use to train our classifiers. For the statistical models, we choose Naive Bayes and Linear Support Vector Machine (SVM), and use scikit learn (Pedregosa et al., 2011) with 5-fold cross validation for training and testing. We choose a BERT We separate the sentence and the licensor with a [SEP] token and keep the sequence length to 300 as this is the maximum sentence length in the training data. After creating the concatenated set of tokens, if the number of tokens are greater than 300, we clip it to 300, otherwise we add [PAD] tokens which correspond to the embedding of 768 dimensional zero-vector. The [CLS] output of the BERT model (Devlin et al., 2019) is then fed into Naive Bayes, Linear SVM, MLP and bi-LSTM networks as above.\nManual Syntactic Features For each of these models, we additionally experiment with manual syntactic features. We use the lexical features proposed by (Dean et al., 2016) and extended lexical features by (Zhang et al., 2019), and take the five syntactic constraints on licensors of ellipsis explored by (Khullar et al., 2019) for their rulebased approach as our slot pattern features. We concatenate all these features to the embeddings from the previous step and check if they improve the classification decision.", "n_publication_ref": 19, "n_figure_ref": 0}, {"heading": "Noun Ellipsis Resolution", "text": "We define noun ellipsis resolution as a binary classification task where given a licensor, antecedent candidate and their context, the goal of the classifier is to predict whether the antecedent candidate is the resolution of the ellipsis licensed by the licensor. Formally, given a sentence s, the licensor l i from the detection step, and the antecedent candidate a j ; the noun ellipsis resolution task can be defined as follows:\nf (a j , l i , s) \u2212 \u2192 {0, 1}\nwhere 1 denotes that the antecedent candidate a j is the actual resolution of the ellipsis licensed by l i , and 0 otherwise.\nEmbeddings Similar to the detection step, we take pretrained fastText word embeddings for the licensor, antecedent candidate and context, and sum pool to obtain a single vector. In case of BERT, we separate the sentence, the licensor and the antecedent candidate with a [SEP] token and follow the same steps as in the detection step.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Manual Syntactic and Semantic Features", "text": "We use POS tags of the licensor and modifier of the antecedent as our syntactic features and cosine similarity between their POS tags as our semantic features, following (Khullar et al., 2019). We concatenate these features to the embeddings to explore the efficacy of adding manual features on resolution.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Experiments", "text": "We  detection task, we take the annotated 946 positive samples (exophoric) and randomly choose 946 negative samples. Similarly, for the resolution task, we take 438 positive samples (endophoric) and 438 randomly chosen negative samples. We perform a standard 70-10-20 split to obtain the train, development and test set respectively, and follow the 5-fold cross validation procedure to capture both classes properly in each case. For MLP, we take a simple, two-layer feedforward network (FFNN) or two layers of multiple computational units interconnected in a feed-forward way without loops. We have a single hidden layer with 768 neurons and a sigmoid function. A unidirectional weight connection exists between the two successive layers. The classification decision is made by turning the input vector representations of a word with its context into a score. The network has a softmax output layer. For bi-LSTM, we have embedding layer, time-distributed translate layer, Bi-LSTM (RNN) layer, batch normalization layer, dropout layer and prediction layer. The activation used is Softmax. The loss function is calculated with cross entropy. We train in batch sizes of 16 and early stopping with max epochs of 100. In early stopping the patience is kept to be 10 and the optimizer used is Adam. We use default values for the learning rate. We use Keras (Chollet et al., 2015) for coding the models.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Results", "text": "We evaluate the performance of our models in terms of F1-score, computed by taking an average F1-scores obtained from the 5-folds results. We experiment with sixteen models each for the noun ellipsis detection and resolution. The results on the testset for Precision, Recall and F1-Score values are presented in Table .2. As expected, the neural models perform significantly better than the statistical ones for both the subtasks. Our experiments show that for the detection task, BERT embeddings with a simple MLP gives best scores. This is expected because, BERT currently provides the most powerful contextual word representations, using 12 separate attention mechanism for each layer, where, at each layer, each token can focus on 12 distinct aspects of other tokens. Since Transformers (Vaswani et al., 2017) use many distinct attention heads (12*12=144 for the base BERT model), each head can focus on a different kind of constituent combinations, making BERT broadly attending over the whole sentence. In our task, the    (Khullar et al., 2019) and the neural model presented in this paper.\ninput and output, but they are not innately designed to capture temporal relationships within a sentence. Hence, although they perform well for a task like detection that needs local information, they are outperformed by bi-LSTMs on the resolution task that requires capturing a deeper relationship between the antecedent and the elided noun. We also note that manual feature addition boosts results greatly for all models, highlighting that ellipsis is a syntactically constrained phenomenon. We finally integrate the best models for each subtask into an end-to-end pipeline, as in Figure 2. Now, instead of the gold vectors (from the annotations), the resolution model is fed the ouput licensor vector from the detection model. This obviously results into error propagation into the second model, and lowers the precision value to 82.52%, recall to 78.66% and consequently, the F1-score to 80.55% of the final system. The error in the final system comes from failing to detect actual licensors, wrongly identifying non-licensor words and correct licensor detection but failed antecedent resolution. We run our final system on the curated dataset prepared by (Khullar et al., 2019) and compare the results with their rule-based approach. As expected, this model improves the F1-score by 16.55% for noun ellipsis detection and 14.97% for noun ellipsis res-olution. See Table 3. The even higher accuracy on the curated dataset can be explained by the nature of the sentences in this dataset which are from textbooks, and, hence, free of grammatical errors, etc. -resulting into improved parser performance in the pre-processing step. Although, the presented models achieve high scores on both the tasks separately and in the pipeline process, the results can be further improved with hyper-parameter tuning and additional regularization.", "n_publication_ref": 3, "n_figure_ref": 1}, {"heading": "Conclusion", "text": "We explored statistical and neural models for noun ellipsis detection and resolution, presenting a strong results for this task. As expected, neural classifiers perform significantly better than the statistical with the same input representation. As with several other NLP tasks, the contextual nature of BERT is useful for noun ellipsis resolution too, making robust predictions with simple neural classifiers. Finally, addition of manual features boosts the performance of all classifiers including those that use BERT, highlighting that ellipsis is a syntactically constrained phenomenon.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Enriching word vectors with subword information", "journal": "", "year": "2016", "authors": "Piotr Bojanowski; Edouard Grave; Armand Joulin; Tomas Mikolov"}, {"title": "An annotated corpus for the analysis of vp ellipsis. Language Resources and Evaluation", "journal": "", "year": "2011", "authors": "Johan Bos; Jennifer Spenader"}, {"title": "The motivation of ellipsis. Theory and Practice in Language Studies", "journal": "", "year": "2016", "authors": "Wei Chen"}, {"title": "", "journal": "", "year": "2015", "authors": "Fran\u00e7ois Chollet"}, {"title": "Sluicing (:) between structure and inference", "journal": "", "year": "2010", "authors": "Sandra Chung; William Ladusaw; James Mc-Closkey"}, {"title": "Ellipsis phenomena. In The Cambridge Handbook of Generative Syntax", "journal": "Cambridge University Press", "year": "2013", "authors": "Jason Jeroen Van Craenenbroeck;  Merchant"}, {"title": "Ellipsis and higher-order unification", "journal": "Linguistics and Philosophy", "year": "1991", "authors": "Mary Dalrymple; Stuart M Shieber; Fernando C N Pereira"}, {"title": "Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs", "journal": "", "year": "2011", "authors": "Cristian Danescu-Niculescu-Mizil; Lillian Lee"}, {"title": "Verb phrase ellipsis resolution using discriminative and margin-infused algorithms", "journal": "", "year": "2016", "authors": "Jackie Chi Kit Kian Kenyon Dean; Doina Cheung;  Precup"}, {"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"title": "Processing ellipsis: A processing solution to the undergeneration problem?", "journal": "", "year": "2008", "authors": "Lyn Frazier"}, {"title": "From nounphrase ellipsis to verbphrase ellipsis: The acquisition path from context to abstract reconstruction", "journal": "", "year": "2010", "authors": "Tilbe Goksun; Tom W Roeper; Kathy Hirsh-Pasek; Roberta Michnick Golinkoff"}, {"title": "Noun ellipsis in english: adjectival modifiers and the role of context. The structure of the noun phrase in English: synchronic and diachronic explorations", "journal": "", "year": "2011", "authors": "Christine Gunther"}, {"title": "Cohesion in english", "journal": "", "year": "1976", "authors": "Michael Alexander ; Kirkwood Halliday; Ruqaiya Hasan"}, {"title": "An algorithm for vp ellipsis", "journal": "", "year": "1992", "authors": "Daniel Hardt"}, {"title": "Improving ellipsis resolution with transformation-based learning. AAAI fall symposium", "journal": "", "year": "1998", "authors": "Daniel Hardt"}, {"title": "Dynamic interpretation of verb phrase ellipsis", "journal": "Linguistics and Philosophy", "year": "1999", "authors": "Daniel Hardt"}, {"title": "A theory of parallelism and the case of vp ellipsis", "journal": "Association for Computational Linguistics", "year": "1997", "authors": "Jerry R Hobbs; Andrew Kehler"}, {"title": "An improved non-monotonic transition system for dependency parsing", "journal": "", "year": "2015", "authors": "Matthew Honnibal; Mark Johnson"}, {"title": "Ellipsis meets wh-movement: sluicing in early grammar", "journal": "", "year": "2017", "authors": "Nina Hyams; Victoria Mateu; Lauren Winans"}, {"title": "What vp ellipsis can do, and what it can't, but not why", "journal": "", "year": "2001", "authors": "Kyle Johnson"}, {"title": "Using syntax to resolve npe in english", "journal": "", "year": "2019", "authors": "Payal Khullar; Allen Anthony; Manish Shrivastava"}, {"title": "Noel: An annotated corpus for noun ellipsis in english", "journal": "", "year": "2020", "authors": "Payal Khullar; Kushal Majmundar; Manish Shrivastava"}, {"title": "The online processing of noun phrase ellipsis and mechanisms of antecedent retrieval. Language", "journal": "Cognition and Neuroscience", "year": "2019", "authors": "Nayoun Kim; Laurel Brehm; Masaya Yoshida"}, {"title": "The interpretatin of ellipsis", "journal": "Blackwell", "year": "1996", "authors": "Shalom Lappin"}, {"title": "Parcorfull: a parallel corpus annotated with full coreference", "journal": "", "year": "2018-05-07", "authors": "Ekaterina Lapshinova-Koltunski; Christian Hardmeier; Pauline Krielke"}, {"title": "Extending ellipsis research: The acquisition of sluicing in dutch", "journal": "", "year": "2015", "authors": "Charlotte Lindenbergh; Bart Angeliek Van Hout;  Hollebrandse"}, {"title": "Speech intelligibility and the production of fricative and affricate among Mandarin-speaking children with cerebral palsy", "journal": "ACLCLP", "year": "2016", "authors": "Chin-Ting Liu; Li-Mei Chen; Yu-Ching Lin; Chia-Fang Cheng; Hui-Chen Chang"}, {"title": "Verb phrase ellipsis detection using automatically parsed text", "journal": "", "year": "2016", "authors": "Zhengzhong Liu; Edgar Gonzalez; Dan Gillick"}, {"title": "Functional Heads, Licensing, and Identification", "journal": "Oxford University Press", "year": "1995", "authors": "Anne Lobeck"}, {"title": "Detection and resolution of verb phrase ellipsis. Linguistic Issues in Language Technology", "journal": "", "year": "2016", "authors": "Marjorie Mcshane; Petr Babkin"}, {"title": "Sentence trimming in service of verb phrase ellipsis resolution", "journal": "", "year": "2015", "authors": "Marjorie Mcshane; Sergei Nirenburg; Petr Babkin"}, {"title": "Understanding English-German contrasts: a corpus-based comparative analysis of ellipses as cohesive devices", "journal": "", "year": "2017", "authors": "Katrin Menzel"}, {"title": "Kontrastive analyse deutscher und englischer koh\u00e4sionsmittel in verschiedenen diskurstypen. tekst i dyskurs -Text und Diskurs", "journal": "", "year": "2014", "authors": "Katrin Menzel; Ekaterina Lapshinova-Koltunski"}, {"title": "Fragments and ellipsis. Linguistics and Philosophy", "journal": "", "year": "2004", "authors": "Jason Merchant"}, {"title": "Three Kinds of Ellipsis: Syntactic", "journal": "", "year": "2010", "authors": "Jason Merchant"}, {"title": "Anaphora Resolution", "journal": "Oxford University Press", "year": "1999", "authors": "Ruslan Mitkov"}, {"title": "Using machine learning techniques for vpe detection", "journal": "", "year": "2003", "authors": "Leif Arda Nielsen"}, {"title": "Robust VPE detection using automatically parsed text", "journal": "Association for Computational Linguistics", "year": "2004", "authors": "Leif Arda Nielsen"}, {"title": "Verb phrase ellipsis detection using automatically parsed text", "journal": "", "year": "2004", "authors": "Leif Arda Nielsen"}, {"title": "When does ellipsis occur, and what is elided? PhD dissertation", "journal": "", "year": "2017", "authors": "Dongwoo Park"}, {"title": "Scikit-learn: Machine learning in Python", "journal": "Journal of Machine Learning Research", "year": "2011", "authors": "F Pedregosa; G Varoquaux; A Gramfort; V Michel; B Thirion; O Grisel; M Blondel; P Prettenhofer; R Weiss; V Dubourg; J Vanderplas; A Passos; D Cournapeau; M Brucher; M Perrot; E Duchesnay"}, {"title": "Constraints on variables in syntax", "journal": "", "year": "1967", "authors": "John Robert ; Ross "}, {"title": "Vp ellipsis, phases and the syntax of morphology. Natural Language & Linguistic Theory", "journal": "", "year": "2012", "authors": "Alain Rouveret"}, {"title": "Nominal-ellipsis and the structure of noun phrases in chinese and japanese", "journal": "Journal of East Asian Linguistics", "year": "2008", "authors": "Mamoru Saito; Jonah Lin; Keiko Murasugi"}, {"title": "Sentences with gapping: Parsing and reconstructing elided predicates", "journal": "", "year": "2018", "authors": "Sebastian Schuster; Joakim Nivre; Christopher D Manning"}, {"title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Lukasz Kaiser; Illia Polosukhin"}, {"title": "Discourse binding: Does it begin with nominal ellipsis?", "journal": "", "year": "2003", "authors": "Frank Wijnen; Tom W Roeper; Hiske Van Der Meulen"}, {"title": "", "journal": "", "year": "", "authors": "Wei-Nan Zhang; Yue Zhang; Yuanxing Liu; Donglin Di"}], "figures": [{"figure_label": "1", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: An example of the noun ellipsis resolution process from the dialogue L131377 of the m 44 movie of the Cornell Movie Dialogs dataset. Here, the nicest and girl denote the ellipsis licensor and antecedent respectively.", "figure_data": ""}, {"figure_label": "2", "figure_type": "", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: The proposed framework for noun ellipsis detection and resolution in English.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Precision, Recall and F1-Score values of different statistical and neural models on the noun ellipsis detection task. FT stands for fastText and +F denotes concatenation of manual features to the embeddings. Values in bold depict best performance.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Precision, Recall and F1-Score values of different statistical and neural models on the noun ellipsis resolution subtask. FT stands for fastText and +F denotes concatenation of manual features to the embeddings.", "figure_data": "BERT with MLP model is robust and efficientlymakes generalisations on the syntactic and seman-tic dependency between the elided noun and thepre-modifiers and modifiers (licensors). For the res-olution task, however, bi-LSTMs work better thanMLP. Unlike MLPs, Bi-LSTMs take into consider-ation left to right and right to left context, capturinglong range dependencies in a sentence and, hence,are better suited for handling the resolution of a co-hesive discourse device like ellipsis where the dis-tance between elided phrase and antecedent can beseveral words. The sufficient neurons in the hiddenlayer with sigmoidal function ensures the MLP ap-proximate the nonlinear relationships between theCurated DatasetPRFDetection(Khullar et al., 2019) 69.15 85.53 76.47MLP, BERT+F91.72 94.32 93.02Resolution(Khullar et al., 2019) 78.79 63.41 70.27bi-LSTM, BERT+F87.01 83.54 85.24"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "", "figure_data": ""}], "doi": "10.17507/tpls.0611.10"}