{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f59939c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f22d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e693d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ca8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f05ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_size, 128)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(128, 64)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(64, 64)\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "        self.drop = torch.nn.Dropout(.5)\n",
    "        self.droplast = torch.nn.Dropout(.3)\n",
    "        self.output_layer = torch.nn.Linear(64, output_size)\n",
    "        #no activation output layer\n",
    "\n",
    "        #initialization\n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.activation1(self.linear1(self.droplast(inputs)))\n",
    "        x = self.activation2(self.drop(self.linear2(x)))\n",
    "        x = self.activation3(self.droplast(self.linear3(x)))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8da82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(\"./final_train_data.pkl\", \"rb\"))\n",
    "val_data = pickle.load(open(\"./final_val_data.pkl\", \"rb\"))\n",
    "train_loader = DataLoader(train_data, batch_size = 128, shuffle = True)\n",
    "val_loader = DataLoader(val_data, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba01674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "val_X = []\n",
    "val_Y = []\n",
    "\n",
    "for X,Y in train_data:\n",
    "    train_X.append(X)\n",
    "    train_Y.append(Y)\n",
    "    \n",
    "for X,Y in val_data:\n",
    "    val_X.append(X)\n",
    "    val_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa641822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = torch.stack(train_X)\n",
    "train_Y = torch.stack(train_Y)\n",
    "val_X = torch.stack(val_X)\n",
    "val_Y = torch.stack(val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f169eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = torch.zeros(15).cuda()\n",
    "for i in range(len(train_Y)):\n",
    "    counts[train_Y[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07139db",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_weights = 1 / (torch.log(counts)/torch.mean(torch.log(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6db637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9748, 1.1019, 1.0765, 0.8777, 1.0216, 1.0438, 1.1223, 1.1446, 1.2101,\n",
       "        1.3750, 0.9523, 1.0806, 0.9798, 1.0695, 0.5519], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe318aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = FullyConnectedModel(768, 15).cuda()\n",
    "loss = torch.nn.CrossEntropyLoss(weight = count_weights)\n",
    "optimizer = Adam(fc_model.parameters(), lr = 1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea63d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0\n",
      "train accuracy: 0.9125291705131531\n",
      "train f1: 0.06361758780764237\n",
      "val accuracy: 0.9287457466125488\n",
      "val f1: 0.06420374703180108\n",
      "epoch time: 3.9809982776641846\n",
      "\n",
      "starting epoch 10\n",
      "train accuracy: 0.928019642829895\n",
      "train f1: 0.23498458170612982\n",
      "val accuracy: 0.9309049844741821\n",
      "val f1: 0.15816716731060404\n",
      "epoch time: 2.70182728767395\n",
      "\n",
      "starting epoch 20\n",
      "train accuracy: 0.9450591206550598\n",
      "train f1: 0.4701304102987126\n",
      "val accuracy: 0.9324070811271667\n",
      "val f1: 0.29393001262164464\n",
      "epoch time: 2.684265613555908\n",
      "\n",
      "starting epoch 30\n",
      "train accuracy: 0.9566267132759094\n",
      "train f1: 0.6268753112060784\n",
      "val accuracy: 0.9332519769668579\n",
      "val f1: 0.3689080253038367\n",
      "epoch time: 2.639676094055176\n",
      "\n",
      "starting epoch 40\n",
      "train accuracy: 0.9661020636558533\n",
      "train f1: 0.7316353709050915\n",
      "val accuracy: 0.9351295232772827\n",
      "val f1: 0.39153580844121916\n",
      "epoch time: 2.7793049812316895\n",
      "\n",
      "starting epoch 50\n",
      "train accuracy: 0.9718958735466003\n",
      "train f1: 0.7952101343934151\n",
      "val accuracy: 0.9305294752120972\n",
      "val f1: 0.41494194048056876\n",
      "epoch time: 2.6174862384796143\n",
      "\n",
      "starting epoch 60\n",
      "train accuracy: 0.9763619303703308\n",
      "train f1: 0.832128764520597\n",
      "val accuracy: 0.9294029474258423\n",
      "val f1: 0.4211743736763146\n",
      "epoch time: 2.5360445976257324\n",
      "\n",
      "starting epoch 70\n",
      "train accuracy: 0.9798020720481873\n",
      "train f1: 0.8605262372952462\n",
      "val accuracy: 0.930013120174408\n",
      "val f1: 0.4350183410413188\n",
      "epoch time: 2.8709933757781982\n",
      "\n",
      "starting epoch 80\n",
      "train accuracy: 0.9845699071884155\n",
      "train f1: 0.8883589645294266\n",
      "val accuracy: 0.9309988617897034\n",
      "val f1: 0.40957500572046784\n",
      "epoch time: 2.636190891265869\n",
      "\n",
      "starting epoch 90\n",
      "train accuracy: 0.9873461127281189\n",
      "train f1: 0.9040294435291324\n",
      "val accuracy: 0.9317029714584351\n",
      "val f1: 0.43994109578746965\n",
      "epoch time: 2.952986717224121\n",
      "\n",
      "starting epoch 100\n",
      "train accuracy: 0.9896998405456543\n",
      "train f1: 0.9231778619103955\n",
      "val accuracy: 0.9329233765602112\n",
      "val f1: 0.4394822451239143\n",
      "epoch time: 3.46395206451416\n",
      "\n",
      "starting epoch 110\n",
      "train accuracy: 0.9910075068473816\n",
      "train f1: 0.9319055422494078\n",
      "val accuracy: 0.93207848072052\n",
      "val f1: 0.4331099151972944\n",
      "epoch time: 2.975489377975464\n",
      "\n",
      "starting epoch 120\n",
      "train accuracy: 0.9921139478683472\n",
      "train f1: 0.9418214286900554\n",
      "val accuracy: 0.9308580756187439\n",
      "val f1: 0.4209588633073429\n",
      "epoch time: 2.674955368041992\n",
      "\n",
      "starting epoch 130\n",
      "train accuracy: 0.9930594563484192\n",
      "train f1: 0.9475828736051322\n",
      "val accuracy: 0.9304825663566589\n",
      "val f1: 0.42752749275104057\n",
      "epoch time: 2.622417449951172\n",
      "\n",
      "starting epoch 140\n",
      "train accuracy: 0.9943872094154358\n",
      "train f1: 0.9584663622356542\n",
      "val accuracy: 0.9325948357582092\n",
      "val f1: 0.4383387796226905\n",
      "epoch time: 2.4211580753326416\n",
      "\n",
      "starting epoch 150\n",
      "train accuracy: 0.9954132437705994\n",
      "train f1: 0.9648117214419583\n",
      "val accuracy: 0.9312335848808289\n",
      "val f1: 0.4245419510248288\n",
      "epoch time: 2.3537487983703613\n",
      "\n",
      "starting epoch 160\n",
      "train accuracy: 0.9958155751228333\n",
      "train f1: 0.9669151606963465\n",
      "val accuracy: 0.9335805177688599\n",
      "val f1: 0.40491835481358396\n",
      "epoch time: 2.389810085296631\n",
      "\n",
      "starting epoch 170\n",
      "train accuracy: 0.9965397715568542\n",
      "train f1: 0.971114972709198\n",
      "val accuracy: 0.9322193264961243\n",
      "val f1: 0.41106823304867723\n",
      "epoch time: 2.3958234786987305\n",
      "\n",
      "starting epoch 180\n",
      "train accuracy: 0.9957551956176758\n",
      "train f1: 0.9676544348282389\n",
      "val accuracy: 0.931656002998352\n",
      "val f1: 0.43207109126033555\n",
      "epoch time: 2.358069896697998\n",
      "\n",
      "starting epoch 190\n",
      "train accuracy: 0.9966001510620117\n",
      "train f1: 0.972707510291586\n",
      "val accuracy: 0.9331580996513367\n",
      "val f1: 0.42213942366042156\n",
      "epoch time: 2.4214727878570557\n",
      "\n",
      "starting epoch 200\n",
      "train accuracy: 0.9969220161437988\n",
      "train f1: 0.9749051560188131\n",
      "val accuracy: 0.932876467704773\n",
      "val f1: 0.42807059632949207\n",
      "epoch time: 2.3511016368865967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(201):\n",
    "    start_time = time.time()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"starting epoch {epoch}\")\n",
    "    fc_model.train()\n",
    "    b = 0\n",
    "    \n",
    "    for X, Y in train_loader:\n",
    "        b+=1\n",
    "        optimizer.zero_grad()\n",
    "        pred = fc_model(X)\n",
    "        batch_loss = loss(pred, Y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    fc_model.eval()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        val_pred = []\n",
    "        val_label = []\n",
    "        val_loss = 0\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_pred = []\n",
    "        train_label = []\n",
    "    \n",
    "        for X, Y in train_loader:\n",
    "            pred = fc_model(X)\n",
    "            train_pred.append(torch.argmax(pred, axis = 1))\n",
    "            train_label.append(Y)\n",
    "            train_loss += batch_loss\n",
    "            \n",
    "        for X, Y in val_loader:\n",
    "            pred = fc_model(X)\n",
    "            val_pred.append(torch.argmax(pred, axis = 1))\n",
    "            val_label.append(Y)\n",
    "            val_loss += loss(pred, Y)\n",
    "\n",
    "        train_pred = torch.cat(train_pred)\n",
    "        train_label = torch.cat(train_label)\n",
    "        val_pred = torch.cat(val_pred)\n",
    "        val_label = torch.cat(val_label)\n",
    "        \n",
    "        val_recall = cm(val_pred.detach().cpu().numpy(), val_label.detach().cpu().numpy(), normalize = \"true\").diagonal()\n",
    "        val_precision = cm(val_pred.detach().cpu().numpy(), val_label.detach().cpu().numpy(), normalize = \"pred\").diagonal()\n",
    "        train_recall = cm(train_pred.detach().cpu().numpy(), train_label.detach().cpu().numpy(), normalize = \"true\").diagonal()\n",
    "        train_precision = cm(train_pred.detach().cpu().numpy(), train_label.detach().cpu().numpy(), normalize = \"pred\").diagonal()\n",
    "    \n",
    "        print(f\"train accuracy: {torch.mean((train_pred == train_label).float())}\")\n",
    "        print(f\"train f1: {np.mean(2 * train_recall * train_precision / (train_recall + train_precision + 1e-6))}\")\n",
    "        #print(f\"train loss: {train_loss/len(train_data)}\")\n",
    "        print(f\"val accuracy: {torch.mean((val_pred == val_label).float())}\")\n",
    "        print(f\"val f1: {np.mean(2 * val_recall * val_precision / (val_recall + val_precision + 1e-6))}\")\n",
    "        #print(f\"val loss: {val_loss/len(val_data)}\")\n",
    "        print(f\"epoch time: {time.time() - start_time}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1737bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578210"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pickle.load(open(\"test_X.pkl\", \"rb\"))\n",
    "last_hidden_X = pickle.load(open(\"last_hidden_X.pkl\", \"rb\"))\n",
    "ind_converter = pickle.load(open(\"ind_converter.pkl\", \"rb\"))\n",
    "\n",
    "test_conll = open(\"../data/test_data/anlp-sciner-test-empty.conll\", \"rt\", encoding=\"utf-8\").read().split('\\n\\n')\n",
    "for i in range(len(test_conll)):\n",
    "    test_conll[i] = test_conll[i].split('\\n')\n",
    "    for j in range(len(test_conll[i])):\n",
    "        test_conll[i][j] = test_conll[i][j].split('\\t')\n",
    "\n",
    "ind_to_label = pickle.load(open(\"ind_to_label.pkl\", \"rb\"))\n",
    "\n",
    "test_conll[0]\n",
    "\n",
    "test_pred = torch.argmax(fc_model(test_X), axis = 1).detach().cpu().numpy()\n",
    "\n",
    "np.unique(test_pred, return_counts=True)\n",
    "\n",
    "fc_model.eval()\n",
    "for i in range(len(last_hidden_X)-1):\n",
    "    pred = torch.argmax(fc_model(last_hidden_X[i]), axis = 1).detach().cpu().numpy()\n",
    "    for token in range(len(test_conll[i])):\n",
    "        inds = ind_converter[i][token]\n",
    "        unique, counts = np.unique(pred[inds], return_counts=True)\n",
    "        #print(unique, counts, unique[np.argmax(counts)])\n",
    "        test_conll[i][token][1] = ind_to_label[unique[np.argmax(counts)]]\n",
    "\n",
    "output_conll = \"\"\n",
    "for i in range(len(test_conll)-1):\n",
    "    para_tag = \"\"\n",
    "    for j in range(len(test_conll[i])):\n",
    "        para_tag += test_conll[i][j][0] + '\\t' + test_conll[i][j][1] + '\\n'\n",
    "    output_conll += para_tag + '\\n'\n",
    "open(\"test_output.conll\", \"wt\", encoding='utf-8').write(output_conll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
