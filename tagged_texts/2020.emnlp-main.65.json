[{"text": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 904\u2013916 , November 16\u201320 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics904Will I Sound Like Me ?", "entities": []}, {"text": "Improving Persona Consistency in Dialogues through Pragmatic Self - Consciousness Hyunwoo Kim Byeongchang Kim Gunhee Kim Department of Computer Science and Engineering Seoul National University , Seoul , Korea fhyunw.kim , byeongchang.kim g@vl.snu.ac.kr gunhee@snu.ac.kr https://vl.snu.ac.kr/projects/consistency", "entities": []}, {"text": "Abstract We explore the task of improving persona consistency of dialogue agents .", "entities": []}, {"text": "Recent models tackling consistency often train with additional Natural Language Inference ( NLI ) labels or attach trained extra modules to the generative agent for maintaining consistency .", "entities": [[8, 11, "TaskName", "Natural Language Inference"], [23, 24, "DatasetName", "agent"]]}, {"text": "However , such additional labels and training can be demanding .", "entities": []}, {"text": "Also , we \ufb01nd even the bestperforming persona - based agents are insensitive to contradictory words .", "entities": []}, {"text": "Inspired by social cognition and pragmatics , we endow existing dialogue agents with public self - consciousness on the \ufb02y through an imaginary listener .", "entities": [[0, 1, "DatasetName", "Inspired"]]}, {"text": "Our approach , based on the Rational Speech Acts framework ( Frank and Goodman , 2012 ) , can enforce dialogue agents to refrain from uttering contradiction .", "entities": []}, {"text": "We further extend the framework by learning the distractor selection , which has been usually done manually or randomly .", "entities": []}, {"text": "Results on Dialogue NLI ( Welleck et al . , 2019 ) and PersonaChat ( Zhang et al . , 2018 ) dataset show that our approach reduces contradiction and improves consistency of existing dialogue models .", "entities": []}, {"text": "Moreover , we show that it can be generalized to improve contextconsistency beyond persona in dialogues .", "entities": []}, {"text": "1 Introduction In the study of dialogue agents , consistency has been a long - standing issue .", "entities": []}, {"text": "To resolve this , much research has been conducted to endow dialogue agents with personas .", "entities": []}, {"text": "Li et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2016 ) propose to encode persona in embeddings and Zhang et al .", "entities": []}, {"text": "( 2018 ) introduce a persona - conditioned dialogue dataset .", "entities": []}, {"text": "On top of these works , many efforts have been made to improve consistency .", "entities": []}, {"text": "In spite of such recent signi\ufb01cant progress , there is much room for improving persona - based dialogue agents .", "entities": []}, {"text": "We observe that even the best performing persona - based generative models ( See et al . , 2019 ; Wolf et al . , 2019b ; Roller et al . , 2020 )", "entities": []}, {"text": "I like to stay at home .", "entities": []}, {"text": "InterlocutorLiteral Agent : \ud835\udc46![Inconsistent]I like going outside .", "entities": [[1, 2, "DatasetName", "Agent"]]}, {"text": "InterlocutorSelf - Conscious Agent : \ud835\udc46\"[Consistent]I like going outside .", "entities": [[3, 4, "DatasetName", "Agent"]]}, {"text": "I love Disneyland!I go there every week .", "entities": []}, {"text": "\u2018 Will I sound like me?\u2019Figure 1 : Illustration of the consistency issue in dialogue .", "entities": []}, {"text": "While a literal dialogue agent ( S0 ) fails to deliver a consistent persona , our self - conscious agent ( S1 ) does so , by modeling an imaginary listener .", "entities": [[4, 5, "DatasetName", "agent"], [19, 20, "DatasetName", "agent"]]}, {"text": "Icons are designed by Nhor Phai and Vincent Le Moign . are highly insensitive to contradictory words , and thus fail to deliver consistent persona to the interlocutor ( Figure 1 ) .", "entities": []}, {"text": "Also , extra modules other than the generative model is often required for improving consistency .", "entities": []}, {"text": "Recent works on consistency in persona - based dialogue actively adopt the NLIbased approach ( Welleck et al . , 2019 ; Song et al . , 2019 ; Li et al . , 2020 ; Song et al . , 2020 ) , which have the following prerequisites .", "entities": []}, {"text": "First , they require labeled pairs of persona sentences and dialogue utterances with three categories : entailment , neutral , and contradiction .", "entities": []}, {"text": "Next , methods with NLI models for rating the agent \u2019s consistency also need to train them separately with those labels .", "entities": [[9, 10, "DatasetName", "agent"]]}, {"text": "In this work , we step back from this NLI - based supervised approach and ponder : how do humans maintain consistency ?", "entities": []}, {"text": "We humans never learn how to be consistent .", "entities": []}, {"text": "Instead , we have an innate drive for consistency to hold our beliefs and behavior in harmony ( Festinger , 1962 ) .", "entities": []}, {"text": "If so , how do we", "entities": []}, {"text": "905know we are consistent or not ?", "entities": []}, {"text": "We do not ask others .", "entities": []}, {"text": "We ask ourselves by predicting how we are perceived by others .", "entities": []}, {"text": "Public self - consciousness is this awareness of the self as a social object that can be observed and evaluated by others ( Fenigstein et al . , 1975 ) .", "entities": []}, {"text": "We particularly emphasize that public self - consciousness is not equivalent to the philosophical self - consciousness ( or self - awareness)1 .", "entities": []}, {"text": "Simply put , public self - consciousness is the concern about how oneself will be perceived by others , as opposed to the philosophical state of being conscious of self - existence .", "entities": []}, {"text": "According to Doherty and Schlenker ( 1991 ) , people with high public self - consciousness tend to act more consistent with known information about themselves .", "entities": []}, {"text": "They care deeply about how others will evaluate them and have a strong tendency to avoid negative evaluations ( Fenigstein et al . , 1975 ) .", "entities": []}, {"text": "Since inconsistency is condemned by others , one who has high public self - consciousness will try more to maintain consistency .", "entities": []}, {"text": "In order to predict how we are perceived , we rely on abstract models of others ( Gopnik and Wellman , 1992 ) and simulate others \u2019 reactions based on imagination ( Hassabis et al . , 2013 ) .", "entities": []}, {"text": "Inspired by this , our intuition is that self - consciousness through an imaginary listener will let dialogue agents better maintain consistency .", "entities": [[0, 1, "DatasetName", "Inspired"]]}, {"text": "Modeling a listener has been one of the main topics in computational pragmatics .", "entities": []}, {"text": "Our work extends this long line of work in cognitive science by making use of the Bayesian Rational Speech Acts framework ( Frank and Goodman , 2012 ) , which has been originally applied to improving informativeness of referring expressions .", "entities": []}, {"text": "Since personas ought to express who we are , we adopt this framework for dialogue agents by regarding personas as targets that should be conveyed to the interlocutor .", "entities": []}, {"text": "As the agent tries to generate tokens that help the imaginary listener identify the agent \u2019s persona , it can lastly generate more consistent utterances .", "entities": [[2, 3, "DatasetName", "agent"], [14, 15, "DatasetName", "agent"]]}, {"text": "In summary , we take inspiration from social cognition and pragmatics to endow generative agents with self - consciousness , which makes them imagine the listener \u2019s reaction and incorporate it to the generation process for improving consistency .", "entities": []}, {"text": "Our major contributions can be outlined as follows : ( 1 ) We propose an orthogonally applicable approach for any persona - based generative agents to improve consistency without the use of additional 1https://plato.stanford.edu/entries/ self - consciousness / consistency labels and training .", "entities": []}, {"text": "Moreover , it is even generalizable to improve context - consistency beyond persona in dialogue .", "entities": []}, {"text": "( 2 ) We extend the Rational Speech Acts framework ( Frank and Goodman , 2012 ) with two new technical features : ( i ) a learning method for distractor selection ( e.g. other samples different from the given target ( Andreas and Klein , 2016 ) ) , which has been usually done manually or randomly , and ( ii ) a different update for the listener \u2019s world prior that better preserves information of previous states .", "entities": []}, {"text": "( 3 ) Our approach improves consistency of three recent generative agents ( See et al . , 2019 ; Wolf et al . , 2019b ; Roller et al . , 2020 ) over Dialogue NLI ( Welleck et al . , 2019 ) and PersonaChat ( Zhang et al . , 2018 ) .", "entities": []}, {"text": "Along with large reduction in contradiction , the utterance accuracy signi\ufb01cantly increases too .", "entities": [[9, 10, "MetricName", "accuracy"]]}, {"text": "2 Related Work Persona & Consistency in Dialogue .", "entities": []}, {"text": "Li et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2016 ) learn personas in embeddings .", "entities": []}, {"text": "Zhang et al .", "entities": []}, {"text": "( 2018 ) release the PersonaChat dataset , a chitchat dialogue set involving two interlocutors each playing their given persona .", "entities": []}, {"text": "Madotto et al .", "entities": []}, {"text": "( 2019 ) use meta - learning to adapt to new personas with few dialogue samples .", "entities": [[4, 7, "TaskName", "meta - learning"]]}, {"text": "Liu et al .", "entities": []}, {"text": "( 2020 ) use reinforcement learning to enhance mutual persona perception .", "entities": []}, {"text": "Recent works use extra modules or NLI labels to improve consistency .", "entities": []}, {"text": "Shum et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) \ufb01ll generated templates , and rank with a language model .", "entities": []}, {"text": "Zhang et al .", "entities": []}, {"text": "( 2019 ) use self - supervised feature extractors for generation .", "entities": []}, {"text": "Welleck et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) annotate NLI labels to the PersonaChat dataset .", "entities": []}, {"text": "They train an NLI model and run pairwise comparison between candidates and persona to compute contradiction scores .", "entities": []}, {"text": "The NLI approach is applied for coherence evaluation ( Dziri et al . , 2019 ) , rewards to reinforcement learning agents ( Song et al . , 2019 ) , \ufb01nding inconsistent words ( Song et al . , 2020 ) , and unlikelihood training ( Li et al . , 2020 ) .", "entities": [[6, 8, "TaskName", "coherence evaluation"]]}, {"text": "They require NLI labels on the target dialogue dataset ; otherwise , sharp decrease in performance is observed , due to mismatch of data distribution ( Welleck et al . , 2019 ) .", "entities": []}, {"text": "Such dataset - speci\ufb01c NLI annotations and training NLI models can be costly and time - consuming .", "entities": []}, {"text": "Compared to previous methods , the novelty of our approach is to improve consistency without NLI labels and extra modules .", "entities": []}, {"text": "Pragmatics .", "entities": []}, {"text": "Our approach belongs to the general family of Bayesian Rational Speech Acts", "entities": []}, {"text": "906 0%20%40%60%80%100%BlenderTransferTransfoControlSeq2SeqHits@1Entail@1Neutral@1Contradict@1Figure 2 : Proportion of Hits@1 , Entail@1 , Neutral@1 and Contradict@1 in the top-1 candidates returned by the models on the Dialogue NLI dataset .", "entities": [[6, 7, "MetricName", "Hits@1"]]}, {"text": "ROUGE-1 ROUGE - L SPICE GT Utterance 15.7 14.6 10.6 Top Entail - Utt 15.3 14.5 7.1 Contradict@1 - Utt 16.3 15.9 6.6 Table 1 : Comparison between ground - truth utterances , top - ranked entailing candidates and Contradict@1 utterances in ROUGE and SPICE scores .", "entities": [[0, 1, "MetricName", "ROUGE-1"], [1, 4, "MetricName", "ROUGE - L"], [4, 5, "DatasetName", "SPICE"], [44, 45, "DatasetName", "SPICE"]]}, {"text": "( RSA ) frameworks ( Frank and Goodman , 2012 ) in pragmatics .", "entities": []}, {"text": "It has improved informativeness in a number of NLP tasks , including reference games ( Andreas and Klein , 2016 ) , image captioning ( Mao et al . , 2016 ;", "entities": [[22, 24, "TaskName", "image captioning"]]}, {"text": "Vedantam et al . , 2017 ; Cohn - Gordon et al . , 2018 ) , instruction following ( Fried et al . , 2017 ) , navigating ( Fried et al . , 2018 ) , translation ( Cohn - Gordon and Goodman , 2019 ) , summarization ( Shen et al . , 2019 ) and referring expression generation ( Zarrie\u00df and Schlangen , 2019 ) .", "entities": [[49, 50, "TaskName", "summarization"], [59, 61, "TaskName", "referring expression"]]}, {"text": "However , its application to the dialogue domain remains understudied .", "entities": []}, {"text": "In this work , we explore how the RSA framework can be adopted in dialogue agents to alleviate the inconsistency problem .", "entities": []}, {"text": "Also , we further extend the framework by making the distractor selection as a learnable process .", "entities": []}, {"text": "3 Insensitivity to Contradictory Words in Existing Persona - based Agents", "entities": []}, {"text": "Although conditional language generation has shown promising progress , maintaining consistency within the generation yet remains unsolved .", "entities": []}, {"text": "From quantitative evaluation , we reveal existing generative models for dialogues are highly insensitive to contradictory words .", "entities": []}, {"text": "Dialogue NLI Evaluation .", "entities": []}, {"text": "Welleck et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) introduce the Dialogue NLI dataset based on the PersonaChat dataset ( Zhang et al . , 2018 ) .", "entities": []}, {"text": "They collect entailing and contradictory utterances to the given persona , and release an evaluation set comprised of dialogues each with 31 utterance candidates : 10 entailing , 10 neutral , and 10 contradictory utterances with 1 ground - truth ( GT ) utterance .", "entities": []}, {"text": "On this evaluation set , we run three recent models ( See et al . , 2019 ; Wolf et al . , 2019b ; RollerPersonaI love wearing skinny jeans and shirts .", "entities": []}, {"text": "I am a blonde girl with short hair .", "entities": []}, {"text": "GT Utterance(I , 1.87 ) ( have , 51.42 ) ( really , 201.45 )", "entities": []}, {"text": "( short , 1.78 ) ( hair , 1.30 ) ( and , 2.81 ) ( it , 45.25 ) ( is , 2.19 ) ( blonde , 461.60 ) .", "entities": []}, {"text": "Contradict@1 - Utt(What , 60.89 ) ( color , 103.11 ) ( is , 1.99 ) ( your , 1.06 ) ( hair , 1.05 ) ( ? , 1.11 ) ( Mine , 3.57 ) ( is , 1.03 ) ( brown , 17.25 ) .", "entities": []}, {"text": "Table 2 : Example of a contradictory utterance returned by the model and its GT utterance with perplexity per token .", "entities": [[17, 18, "MetricName", "perplexity"]]}, {"text": "The words of entailment and contradiction to the persona are shown in blue and red , respectively .", "entities": []}, {"text": "et", "entities": []}, {"text": "al . , 2020 ) that achieve the best performance on PersonaChat .", "entities": []}, {"text": "We report four ranking metrics following Welleck et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ): Hits@1 , Entail@1 , Neutral@1 and Contradict@1 .", "entities": [[3, 4, "MetricName", "Hits@1"]]}, {"text": "Each metric is the proportion of GT , entailing , neutral and contradictory utterances in the top-1 candidates returned by the model , respectively .", "entities": []}, {"text": "The models rank the candidates by perplexity scores .", "entities": [[6, 7, "MetricName", "perplexity"]]}, {"text": "Figure 2 shows that all three models select contradictory candidates much more often than the GT utterances ( see further results in Table 3 ) .", "entities": []}, {"text": "Though models are conditioned on a given persona , they are highly insensitive to contradictions .", "entities": []}, {"text": "3.1 Analysis of Contradict@1 Utterances To investigate why insensitivity to contradiction prevails in the state - of - the - art models , we further analyze the contradictory utterances returned by the models ( Contradict@1 - Utt ) , comparing with the GT utterances and the top - ranked entailing candidates ( Top Entail - Utt ) .", "entities": []}, {"text": "Table 1 reports language metrics between the selected candidates and the given persona sentences using SPICE ( Anderson et al . , 2016 ) and ROUGE ( Lin , 2004 ) .", "entities": [[15, 16, "DatasetName", "SPICE"]]}, {"text": "SPICE metric measures semantic similarity and ROUGE metric measures n - gram overlaps between two sentences .", "entities": [[0, 1, "DatasetName", "SPICE"], [3, 5, "TaskName", "semantic similarity"]]}, {"text": "Contradict@1 - Utt shows lower SPICE scores and higher ROUGE scores than other utterances , implying that it may be different in semantics but similar in syntax to the given persona .", "entities": [[5, 6, "DatasetName", "SPICE"]]}, {"text": "To take a closer look , we extract the contradicting words from Contradict@1 - Utt and their counterparts from GT utterances to compare their average perplexity scores .", "entities": [[25, 26, "MetricName", "perplexity"]]}, {"text": "In the Dialogue NLI dataset , every utterance is labeled with a triple ( entity 1;relation;entity 2 ) , such as \u201c I just like to listen to rock music \u201d with ( i;likemusic;rock ) .", "entities": []}, {"text": "907By construction , Contradict@1 - Utt must contain words that are contradictory to the GT utterance and the given persona .", "entities": []}, {"text": "The perplexity scores of contradictory words ( 106.7 ) were considerably lower than those of the counterparts in GT utterances ( 280.1 ) .", "entities": [[1, 2, "MetricName", "perplexity"]]}, {"text": "Table 2 shows an example of such dialogue instance with perplexity per word .", "entities": [[10, 11, "MetricName", "perplexity"]]}, {"text": "If properly conditioned with the given persona , models should show lower perplexity for the words in the persona .", "entities": [[12, 13, "MetricName", "perplexity"]]}, {"text": "However , their perplexity scores are signi\ufb01cantly higher than those of contradictory words .", "entities": [[3, 4, "MetricName", "perplexity"]]}, {"text": "It reveals that models behave more as a plain language model rather than as a persona - conditioned model .", "entities": []}, {"text": "Thus , guarantee of consistency for each word generation step is required for persona - based dialogue agents to resolve such issue .", "entities": []}, {"text": "4 Approach We introduce how to endow dialogue agents with public self - consciousness , which helps them keep consistency in mind at each generation step by re\ufb02ecting an imaginary listener \u2019s distribution over personas .", "entities": []}, {"text": "Since the imaginary listener arises from the plain dialogue - agent , separate training is not needed .", "entities": [[10, 11, "DatasetName", "agent"]]}, {"text": "Figure 3 illustrates its overall structure .", "entities": []}, {"text": "We present how to model public selfconsciousness using the Rational Speech Acts ( RSA ) framework ( Frank and Goodman , 2012 ) in Section 4.1 .", "entities": []}, {"text": "We then discuss learning of distractor selection as our major novelty for the RSA in Section 4.2 .", "entities": []}, {"text": "4.1 Modeling the Public Self - Consciousness", "entities": []}, {"text": "We seek to build a dialogue agent who is selfconscious about its consistency without the need for training on NLI labels or rating consistency with NLI models .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "Given that modeling the interactions between listener and speaker is a main topic in pragmatics , we take advantage of the RSA framework ( Frank and Goodman , 2012 ) .", "entities": []}, {"text": "It treats language use as a recursive process where probabilistic speaker and listener reason about each other \u2019s intentions in a Bayesian fashion .", "entities": []}, {"text": "To apply the framework to sequence generation for dialogues , we extend the incremental approach proposed for image captioning ( Cohn - Gordon et al . , 2018 ) .", "entities": [[17, 19, "TaskName", "image captioning"]]}, {"text": "To generate an utterance , the agent computes the distribution of every next token utat timesteptin Bayesian fashion as follows .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "Base Speaker S0.We \ufb01rst assume persona iis given to the base speaker , along with the dialogue Self - ConsciousSpeaker : \ud835\udc46 ! \"", "entities": []}, {"text": "Persona : \ud835\udc56Dialogue History :", "entities": []}, {"text": "\u210eLearned Distractor Personas : \ud835\udc56\u2032Speaker \u2019s Next Token : \ud835\udc62\"\u221d\ud835\udc3f#\"\ud835\udc56\u210e,\ud835\udc62$\",\ud835\udc5d\"%\u00d7\ud835\udc46#\"\ud835\udc62\"\ud835\udc56,\u210e,\ud835\udc62&\")\ud835\udc5d\"'!(\ud835\udc56 ) Imaginary Listener : \ud835\udc3f#\"(\ud835\udc56|\ud835\udc62$\",\u210e,\ud835\udc5d \" ) Base Speaker:\ud835\udc46#\"\ud835\udc62\"\ud835\udc56,\u210e,\ud835\udc62&\")Figure 3 : The proposed self - conscious agent S1consists of base speaker S0and imaginary listener L0 .", "entities": [[26, 27, "DatasetName", "agent"]]}, {"text": "It recursively generates the next token utat every time t. historyhand partial utterance u < t , as shown in Figure 3 .", "entities": []}, {"text": "The base speaker St 0returns a distribution over the next token at timestep t : St 0(utji;h;u < t ) .", "entities": []}, {"text": "Any conditional dialogue agent can be used as a base speaker .", "entities": [[3, 4, "DatasetName", "agent"]]}, {"text": "See the details in Section 5.2 .", "entities": []}, {"text": "Imaginary Listener L0.While the base speaker generates each token one at a time , the imaginary listener reasons about the speaker \u2019s persona .", "entities": []}, {"text": "The imaginary listener Lt 0is the posterior distribution of the speaker \u2019s persona in terms of the base speaker and the world prior pt(i)over personas as follows , Lt 0(ijh;u\u0014t;pt ) /St 0(utji;h;u < t ) \f \u0002pt(i)P i02ISt 0(utji0;h;u < t ) \f \u0002pt(i0):(1 ) where \f onSt 0is the listener rationality coef\ufb01cient that controls the amount of information from the current timestep compared to the cumulative prior pt(i).L0returns a probability distribution over the personas in worldI , which is a \ufb01nite set ( jIj= 3 ) comprising the given persona iand distractor personas .", "entities": []}, {"text": "The distractors are different personas from other dialogue instances in the dataset .", "entities": []}, {"text": "We decide worldIper dialogue instance through learning , which will be elaborated in Section 4.2 .", "entities": []}, {"text": "Self - Conscious Speaker S1.WithSt 0andLt 0 , the self - conscious speaker St 1is de\ufb01ned as St 1(utji;h;u < t ) /Lt 0(ijh;u\u0014t;pt )", "entities": [[6, 7, "DatasetName", "0"]]}, {"text": "\u0002St 0(utji;h;u < t);(2 ) where \u000b is the speaker rationality coef\ufb01cient that determines how much the likelihood is considered .", "entities": []}, {"text": "By taking the listener \u2019s distribution into account , the speaker is now self - conscious about what persona it sounds like .", "entities": []}, {"text": "Especially , the agent seeks", "entities": [[3, 4, "DatasetName", "agent"]]}, {"text": "908to be perceived as the given persona irather than some other persona i0 .", "entities": []}, {"text": "The likelihood of each token being identi\ufb01ed as the persona iacts as a bonus added to the base speaker \u2019s token scores .", "entities": []}, {"text": "Hence , tokens that are consistent to the given persona are preferred to others .", "entities": []}, {"text": "The token with the highest probability is added to the partial utterance , becoming the next input u < t+1for the speaker .", "entities": []}, {"text": "Updating the world prior with L0.Starting from a uniform distribution as the initial prior p0(i ) , we update the world prior pt+1(i)according to S1 \u2019s outpututat every time step : pt+1(i )", "entities": []}, {"text": "= Lt 0(ijh;u\u0014t;pt ): ( 3 ) Hence , pt(i)represents the cumulative state of the partial utterance up to t. Cohn - Gordon et al .", "entities": []}, {"text": "( 2018 ) report the prior update with L1/ St 0(utji;h;u < t)\u0002Lt 0(ijh;u\u0014t;pt)makes little practical effect compared to a uniform prior .", "entities": []}, {"text": "We \ufb01nd that updating the prior with Eq .", "entities": []}, {"text": "( 3 ) instead is effective .", "entities": []}, {"text": "See the results in Section 5.6 .", "entities": []}, {"text": "4.2 Learning to Select Distractors Distractors ( Andreas and Klein , 2016 ) are samples ( e.g. other personas in the dataset ) which are different from the given target .", "entities": []}, {"text": "In previous works of RSA , the distractors to be included in world Iare selected manually or randomly from the dataset .", "entities": []}, {"text": "However , we \ufb01nd that performance variance is large according to the selected distractors .", "entities": []}, {"text": "We thus propose to learn distractor selection , especially based on the life - long memory network ( Kaiser et al . , 2017 ) .", "entities": [[15, 17, "MethodName", "memory network"]]}, {"text": "The life - long memory network is capable of implicitly clustering similar dialogue contexts into a few slots with associated persona .", "entities": [[4, 6, "MethodName", "memory network"]]}, {"text": "Therefore , it can ef\ufb01ciently memorize and retrieve distractor personas for each context .", "entities": []}, {"text": "In Appendix , we experiment that our approach outperforms other models including BERT - based algorithms .", "entities": [[12, 13, "MethodName", "BERT"]]}, {"text": "To better select useful distractor personas , supervised learning is desirable .", "entities": []}, {"text": "However , there is no explicit label indicating which distractors are helpful for each dialogue .", "entities": []}, {"text": "We select the persona that have the best Hits@1 as the distractor label per training dialogue .", "entities": [[8, 9, "MetricName", "Hits@1"]]}, {"text": "The Hits@1 is the score for favoring the ground - truth next utterance ( consistent and context - relevant ) over other candidate utterances which are just being consistent ( i.e. entailing ) or contradictory to the given persona .", "entities": [[1, 2, "MetricName", "Hits@1"]]}, {"text": "In other words , the score represents consistency and also appropriateness at the same time .", "entities": []}, {"text": "Thus , suchdistractors can help the self - conscious agent to generate responses which are context - relevant and allow the imaginary listener to identify the speaker \u2019s persona .", "entities": [[9, 10, "DatasetName", "agent"]]}, {"text": "Each training datapoint comprises a given persona , a distractor persona and dialogue context .", "entities": []}, {"text": "Memory Structure .", "entities": []}, {"text": "The memory consists of three types of information : M= ( K;v;a).K2 Rm\u0002dis a key matrix , where mis the number of memory slots and dis the dimension of the key vectors , which are the embedding of datapoints .", "entities": []}, {"text": "The value vector v2Rmstores the index of a persona .", "entities": []}, {"text": "a2Rmis an age vector , which is used for memory update .", "entities": []}, {"text": "We set m= 16;000andd= 768 .", "entities": []}, {"text": "Memory Addressing .", "entities": []}, {"text": "We construct the query vector qfor each datapoint with the BERTUncased - Base ( Devlin et al . , 2019 ) model .", "entities": []}, {"text": "We use the output embedding of BERT \u2019s", "entities": [[6, 7, "MethodName", "BERT"]]}, {"text": "[ CLS ] token , and normalize it to a unit length to build q2Rd .", "entities": []}, {"text": "Using the cosine similarity between qand each memory key , we can \ufb01nd the knearest neighbors : ( n1;n2;:::;nk ) = NNk(q;K ): ( 4 ) Memory Loss .", "entities": []}, {"text": "Suppose that the query datapoint has a distractor label l.", "entities": []}, {"text": "Among ( n1;:::;nk ) , we denote the positive neighbor npas the one withv[np ]", "entities": []}, {"text": "= land the negative neighbor nbwith v[nb]6 = l.", "entities": []}, {"text": "If there are multiple positive neighbors , we pick the one with the smallest memory index .", "entities": []}, {"text": "If no positive neighbor is found , we select a random key whose value is l. For the negative neighbor , we select one randomly from ( n1;:::;nk ) .", "entities": []}, {"text": "We set k= 2048 .", "entities": [[3, 4, "DatasetName", "2048"]]}, {"text": "Then , the loss is computed as L= max ( q\u0001K[nb]\u0000q\u0001K[np ] + \u000b ; 0);(5 ) where \u000b is a positive margin , which we set as 0:2 .", "entities": [[3, 4, "MetricName", "loss"]]}, {"text": "This loss maximizes the cosine similarity between the query qand the positive key K[np ] , while minimizing the similarity to the negative key K[nb ] .", "entities": [[1, 2, "MetricName", "loss"]]}, {"text": "We \ufb01netune the query network BERT with this loss .", "entities": [[5, 6, "MethodName", "BERT"], [8, 9, "MetricName", "loss"]]}, {"text": "Memory Update .", "entities": []}, {"text": "After computing the loss , memoryMis updated differently for two cases .", "entities": [[3, 4, "MetricName", "loss"]]}, {"text": "( 1 ) If the top-1 neighbor \u2019s value ( i.e. persona ) is correct ( v[n1 ] = l ) , the key vector is updated as : K[n1 ] q+K[n1 ] kq+K[n1]k : ( 6 ) ( 2 ) Otherwise ( v[n1]6 = l ) , we make a slot for the query ; we \ufb01nd the oldest memory slot n0according to the age vector aand write K[n0 ] q;v[n0 ] l;a[n0 ] 0:(7 )", "entities": []}, {"text": "909Training & Inference .", "entities": []}, {"text": "In our Distractor Memorynetwork , training corresponds to updating the memory and the parameters of the query network .", "entities": []}, {"text": "At inference , given a test example , we obtain the query by encoding the dialogue context and the persona using BERT .", "entities": [[21, 22, "MethodName", "BERT"]]}, {"text": "We \ufb01nd nnearest keys from the memory , and use their values ( i.e. persona indices ) as the distractor personas .", "entities": []}, {"text": "We set n= 2 . 5 Experiments We show that our self - conscious framework can signi\ufb01cantly improve consistency and accuracy of state - of - the - art persona - based agents on two benchmark datasets .", "entities": [[20, 21, "MetricName", "accuracy"]]}, {"text": "We prove its effectiveness using both automatic and human evaluations .", "entities": []}, {"text": "We also show our framework can be generalized to improve consistency of dialogue context beyond persona .", "entities": []}, {"text": "5.1 Datasets Dialogue NLI Evaluation Set ( Welleck et al . , 2019 ) .", "entities": []}, {"text": "This dataset is based on PersonaChat with additional NLI annotations .", "entities": []}, {"text": "Its main task is to rank next - utterance candidates given previous context .", "entities": []}, {"text": "For each dialogue , they collect 31 next - utterance candidates in respect to the given persona : 10 entailing , 10 neutral and 10 contradicting candidates with 1 ground - truth utterance .", "entities": []}, {"text": "In total , the evaluation set includes 542 instances .", "entities": []}, {"text": "PersonaChat dialogue ( Zhang et al . , 2018 ) .", "entities": []}, {"text": "This dataset involves two interlocutors who are each given a persona and asked to get to know each other while playing their roles .", "entities": []}, {"text": "This task was the subject of the ConvAI2 competition ( Dinan et al . , 2019 ) at NeurIPS 2018 .", "entities": [[7, 8, "DatasetName", "ConvAI2"]]}, {"text": "The competition version contains 17,878 chitchat conversations conditioned on 1,155 personas for training and 1,000 conversations conditioned on 100 personas for validation .", "entities": []}, {"text": "5.2 Experimental Setting Base Speakers .", "entities": []}, {"text": "We experiment on three pretrained models including ControlSeq2Seq ( See et al . , 2019 ) , TransferTransfo ( Wolf et al . , 2019b ) , and Blender ( Roller et al . , 2020 ) as base speakers ( S0 ) for our self - conscious agents ( S1 ) .", "entities": [[28, 29, "MethodName", "Blender"]]}, {"text": "The ControlSeq2Seq is a Seq2Seq model with attention trained on Twitter dataset ( Miller et al . , 2017 ) and \ufb01netuned on PersonaChat .", "entities": [[4, 5, "MethodName", "Seq2Seq"]]}, {"text": "TranferTransfo based on GPT ( Radford et al . , 2018 ) is the winner of the ConvAI2 competition in automatic evaluation .", "entities": [[3, 4, "MethodName", "GPT"], [17, 18, "DatasetName", "ConvAI2"]]}, {"text": "Blender , a recently released generative dialogue model , is the state - of - the - art open - domain chatbot .", "entities": [[0, 1, "MethodName", "Blender"], [21, 22, "TaskName", "chatbot"]]}, {"text": "Our approach improves these base speakers byModel Hits@1 \" Entail@1 \" Contradict@1 # ControlSeq2Seq ( See et al . , 2019 )", "entities": [[7, 8, "MetricName", "Hits@1"]]}, {"text": "S0 7.9 27.9 46.3 S1 10.5 36.4 34.0 S1+DM 13.1 40.8 24.5 TransferTransfo ( Wolf et al . , 2019b )", "entities": []}, {"text": "S0 11.1 26.4 46.5 S1 17.5 40.4 29.7 S1+DM 18.8 45.8 19.7 Blender ( Roller et al . , 2020 )", "entities": [[12, 13, "MethodName", "Blender"]]}, {"text": "S0 18.8 27.3 42.4 S1 21.8 38.0 30.6 S1+DM 22.5 44.1 19.6 Table 3 : Comparison of our approach ( S1)with base speakers ( S0)on the Dialogue NLI evaluation set ( Welleck et al . , 2019 ) .", "entities": []}, {"text": "+ DM is the Distractor Memory .", "entities": []}, {"text": "High scores in Hits@1 , Entail@1 and low scores in Contradict@1 imply better consistency .", "entities": [[3, 4, "MetricName", "Hits@1"]]}, {"text": "granting them the sense of self - consciousness .", "entities": []}, {"text": "We defer implementation details to Appendix .", "entities": []}, {"text": "Evaluation Metrics .", "entities": []}, {"text": "For Dialogue NLI , we report three ranking metrics introduced in the original paper : Hits@1 , Entail@1 , and Contradict@1 .", "entities": [[15, 16, "MetricName", "Hits@1"]]}, {"text": "Each metric is the proportion of GT , entailing , and contradictory utterances in the top-1 candidates returned by the model , respectively .", "entities": []}, {"text": "High scores in Entail@1 and low scores in Contradict@1 indicate better consistency with the persona .", "entities": []}, {"text": "For PersonaChat , we report Hits@1 , standard F1 score , perplexity and C score , following the ConvAI2 protocol .", "entities": [[5, 6, "MetricName", "Hits@1"], [8, 10, "MetricName", "F1 score"], [11, 12, "MetricName", "perplexity"], [18, 19, "DatasetName", "ConvAI2"]]}, {"text": "Hits@1 is the accuracy of choosing the ground - truth next - utterance among 20 candidates as the models rank the candidates by perplexity .", "entities": [[0, 1, "MetricName", "Hits@1"], [3, 4, "MetricName", "accuracy"], [23, 24, "MetricName", "perplexity"]]}, {"text": "The C score is a metric for dialogue consistency , introduced in Madotto et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "It computes pairwise comparison between utterance uand persona sentence pjwith a pretrained NLI model .", "entities": []}, {"text": "The NLI model returns 1 , 0 , -1 for entailment , neutrality , and contradiction , respectively .", "entities": [[6, 7, "DatasetName", "0"]]}, {"text": "We sum the NLI scores across persona sentences per dialogue instance : C ( u ) = P jNLI(u;pj ) .", "entities": []}, {"text": "5.3 Quantitative Results Results on Dialogue NLI .", "entities": []}, {"text": "Table 3 compares the performance of dialogue agents on the Dialogue NLI evaluation set .", "entities": []}, {"text": "Our self - conscious agent S1 signi\ufb01cantly reduces Contradict@1 scores and increases the Entail@1 along with the Hits@1 accuracy of the literal agents S0 .", "entities": [[4, 5, "DatasetName", "agent"], [17, 18, "MetricName", "Hits@1"], [18, 19, "MetricName", "accuracy"]]}, {"text": "We remind that each entailing candidate shares the same annotated triple as the GT utterance .", "entities": []}, {"text": "In other words , they have similar semantics to the GT utterance and follow the", "entities": []}, {"text": "910Model Hits@1 \" F1 \" Perplexity # C \" ControlSeq2Seq", "entities": [[1, 2, "MetricName", "Hits@1"], [3, 4, "MetricName", "F1"], [5, 6, "MetricName", "Perplexity"]]}, {"text": "( See et al . , 2019 ) S0 16.1 17.0 22.9 0.45 S1 16.4 16.9 23.9 0.54 S1+DM 16.7 17.1 23.9 0.55 TransferTransfo ( Wolf et al . , 2019b )", "entities": []}, {"text": "S0 16.2 19.2 17.6 0.86 S1 17.5 19.4 19.1 0.96 S1+DM 18.2 19.5 19.1 0.97 Blender ( Roller et al . , 2020 ) S0 27.6 19.5 12.0 0.85 S1 28.8 19.7 13.2 0.93 S1+DM 29.1 19.8 13.2 0.95 Table 4 : Comparison of our approach ( S1)with base speakers ( S0)on PersonaChat ( Zhang et al . , 2018 ) .", "entities": [[15, 16, "MethodName", "Blender"]]}, {"text": "C is the consistency score evaluated by a pretrained NLI model ( Madotto et al . , 2019 ) .", "entities": []}, {"text": "For TransferTransfo , we use the generative version to calculate Hits@1 .", "entities": [[10, 11, "MetricName", "Hits@1"]]}, {"text": "given persona .", "entities": []}, {"text": "Thus , Entail@1 is a lenient version of Hits@1 ( Welleck et al . , 2019 ) .", "entities": [[8, 9, "MetricName", "Hits@1"]]}, {"text": "The Distractor Memory ( DM ) is better than random distractor selection forS1across all metrics .", "entities": []}, {"text": "It concludes that learned distractors are more effective than random distractors for pragmatic agents .", "entities": []}, {"text": "Results on PersonaChat .", "entities": []}, {"text": "Table 4 compares the performance of different dialogue agents on the PersonaChat dataset .", "entities": []}, {"text": "Our model S1outperforms all other generative dialogue agents in terms of consistency related metrics , i.e. Hits@1 and C score .", "entities": [[16, 17, "MetricName", "Hits@1"]]}, {"text": "Since the posterior update of our self - conscious agent revises the distribution learned by the base speaker , the increase in perplexity is natural due to the effect of regularization .", "entities": [[9, 10, "DatasetName", "agent"], [22, 23, "MetricName", "perplexity"]]}, {"text": "Nevertheless , our approach improves the F1 score for TransferTransfo and Blender .", "entities": [[6, 8, "MetricName", "F1 score"], [11, 12, "MethodName", "Blender"]]}, {"text": "Thus , being consistent to the given persona can also help improve the generation performance of dialogue agents .", "entities": []}, {"text": "Comparison with agents that use NLI model .", "entities": []}, {"text": "We also test agents with pretrained NLI models attached ( Welleck et al . , 2019 ) , denoted by + NLI in Table 5 .", "entities": []}, {"text": "The NLI model computes contradiction scores of each candidate utterances , and penalize its rank accordingly .", "entities": []}, {"text": "Compared to base agents with no self - consciousness , our agents improve consistency in all three metrics even further when using additional NLI models .", "entities": []}, {"text": "Another notable result is that our agents without NLI ( S1+DM in Table 3 ) for ControlSeq2Seq and TransferTransfo even outperform the base agents with NLI ( S0+NLI ) on Hits@1 .", "entities": [[30, 31, "MetricName", "Hits@1"]]}, {"text": "That is , our self - conscious agents achieveModel Hits@1 \" Entail@1 \" Contradict@1 # ControlSeq2Seq", "entities": [[9, 10, "MetricName", "Hits@1"]]}, {"text": "( See et al . , 2019 ) S0+NLI 12.7 48.2 8.1", "entities": []}, {"text": "[ S1+DM]+NLI 14.4 51.7 7.0 TransferTransfo ( Wolf et al . , 2019b ) S0+NLI", "entities": []}, {"text": "17.2 44.4 9.8 [ S1+DM]+NLI 21.4 54.6 5.4 Blender ( Roller et al . , 2020 )", "entities": [[8, 9, "MethodName", "Blender"]]}, {"text": "S0+NLI 24.9 44.7 6.0 [ S1+DM]+NLI 26.6 52.0 5.7 Table 5 : Comparison of our approach ( S1)with base speakers ( S0)on the Dialogue NLI evaluation set ( Welleck et al . , 2019 ) with pretrained NLI model attached .", "entities": []}, {"text": "Raw Calibrated Model Consistent Engaging Consistent Engaging TransferTransfo ( Wolf et al . , 2019b ) S0 0.53 ( 0.02 ) 2.48 ( 0.03 ) 0.44 ( 0.01 ) 2.48 ( 0.01 ) S1+DM 0.61 ( 0.02 ) 2.55 ( 0.03 ) 0.52 ( 0.01 ) 2.52 ( 0.01 ) Table 6 : Human evaluation results comparing the consistency and engagingness of the base speaker ( S0 ) and our self - conscious agent ( S1 ) .", "entities": [[73, 74, "DatasetName", "agent"]]}, {"text": "Numbers in parentheses are the standard errors .", "entities": []}, {"text": "better GT accuracy even without the help of an NLI model trained on consistency labels .", "entities": [[2, 3, "MetricName", "accuracy"]]}, {"text": "5.4 Human Evaluation We perform human evaluation via Amazon Mechanical Turk .", "entities": []}, {"text": "We random sample 250 test examples , each is rated by three unique human judges in terms of ( i ) Consistency and ( ii ) Engagingness .", "entities": []}, {"text": "Turkers are shown a given persona , a dialogue context , and the model \u2019s generated utterance .", "entities": []}, {"text": "For consistency , we follow Madotto et al .", "entities": []}, {"text": "( 2019 ) and ask judges to assign 1,0,\u00001to the utterance for consistency , neutrality , and contradiction , respectively .", "entities": []}, {"text": "Following See et al .", "entities": []}, {"text": "( 2019 ) , we evaluate the engagingness of the utterance in a 4 - point scale , where higher scores are better .", "entities": []}, {"text": "To alleviate annotator bias and inter - annotator variability , we apply Bayesian calibration ( Kulikov et al . , 2019 ) to the scores .", "entities": []}, {"text": "Table 6 summarizes the human evaluation results .", "entities": []}, {"text": "The agent with our self - consciousness method S1 is rated as more consistent than the base agent S0 while maintaining a similar level of engagingness .", "entities": [[1, 2, "DatasetName", "agent"], [17, 18, "DatasetName", "agent"]]}, {"text": "While it can be trivial to increase consistency at the cost of engagingness ( e.g. perfect consistency can by generating boring utterances with very little variance ) , it is not the case for our agent .", "entities": [[35, 36, "DatasetName", "agent"]]}, {"text": "Since", "entities": []}, {"text": "911Model Hits@1 \" Entail@1 \" Contradict@1 # Dialogue NLI ( Welleck et al . , 2019 ) S0 18.8 27.3 42.4 S1(on context ) 32.7 27.7 26.4 Model Hits@1 \" F1\"Perplexity # C \" PersonaChat ( Zhang et al . , 2018 ) S0 27.6 19.5 12.0 0.57 S1(on context ) 30.5 19.9 13.5 0.58 EmpatheticDialogue ( Rashkin et", "entities": [[1, 2, "MetricName", "Hits@1"], [28, 29, "MetricName", "Hits@1"]]}, {"text": "al . , 2019 ) S0 32.6 20.5 14.7 0.47 S1(on context ) 34.2 20.6 15.4 0.50 Table 7 : Comparison of our approach ( S1)with base speaker Blender ( S0)when conditioned on dialogue context in three datasets .", "entities": [[28, 29, "MethodName", "Blender"]]}, {"text": "We compute the consistency score C respect to the dialogue context .", "entities": []}, {"text": "our agent seeks to be heard as the given persona to the listener , self - distinctive words tend to meld into generated responses ( see Figure 6 ) .", "entities": [[1, 2, "DatasetName", "agent"]]}, {"text": "Thus , the responses from self - conscious agents have their own color , which can help improving engagingness .", "entities": []}, {"text": "Figure 4 displays selected examples of utterance generation .", "entities": []}, {"text": "Each example is comprised of dialogue history , human response , and utterances generated by our method and baselines .", "entities": []}, {"text": "5.5 Consistency for Dialogue Context We demonstrate that our self - conscious agent can be generalized to generate context - consistent utterances beyond persona .", "entities": [[12, 13, "DatasetName", "agent"]]}, {"text": "We condition the agent with its previous responses in the dialogue history ; that is , iin Eq .", "entities": [[3, 4, "DatasetName", "agent"]]}, {"text": "( 2 ) is the agent \u2019s past responses instead of persona sentences .", "entities": [[5, 6, "DatasetName", "agent"]]}, {"text": "Hence , tokens that are inconsistent to the agent \u2019s past response would be less favored by the model .", "entities": [[8, 9, "DatasetName", "agent"]]}, {"text": "Table 7 reports the results of context conditioned self - conscious agents .", "entities": []}, {"text": "The EmpatheticDialogue ( Rashkin et al . , 2019 ) is an open - domain dialogue dataset where a speaker describes a past emotional experience and the listener responds accordingly .", "entities": []}, {"text": "Since the speaker \u2019s descriptions should be consistent to the experience and previous utterances , it is a suitable benchmark for consistency .", "entities": []}, {"text": "We model the speaker \u2019s utterances and measure its consistency .", "entities": []}, {"text": "OurS1agent outperforms other literal agents on all three datasets in terms of consistency .", "entities": []}, {"text": "Thus , our approach can also be applied to help agents stay more consistent to its context .", "entities": []}, {"text": "P1 \u2019s PersonaI own a house in Florida .", "entities": []}, {"text": "I work in it and have been at the same company for 15 years .", "entities": []}, {"text": "I enjoy American sportsI\u2019ve a children and a dogs .", "entities": []}, {"text": "Dialogue History[P2 ]", "entities": []}, {"text": "Hello , how are you today?[P1 ]", "entities": []}, {"text": "Hey !", "entities": []}, {"text": "Just watching a game of football with my children .", "entities": [[3, 6, "TaskName", "game of football"]]}, {"text": "You?[P2 ]", "entities": []}, {"text": "That \u2019s cool !", "entities": []}, {"text": "I am an alcoholic who is recovering.(S1+DM)iwork in a company and i \u2019m a workaholic.(S0)i\u2019msorry to hear that .", "entities": []}, {"text": "I \u2019m a retired professional athlete.(Human)ah man congrats for trying to get back on the road !", "entities": []}, {"text": "P1 \u2019s PersonaMy family does not support my career choices .", "entities": []}, {"text": "My dream car is a Rolls Royce ghost .", "entities": []}, {"text": "I often shop for shoes and watches .", "entities": []}, {"text": "I like shopping .", "entities": []}, {"text": "I currently work for a watch dealer .", "entities": []}, {"text": "Dialogue History[P1 ] I really enjoy shopping and my dream is to one day own a Rolls Royce ghost.[P2 ]", "entities": []}, {"text": "Wow .", "entities": []}, {"text": "I enjoy running over driving.[P1 ] Running is also quite lovely .", "entities": []}, {"text": "Breathing in the lovely outside air.[P2 ]", "entities": []}, {"text": "Yes it is .", "entities": []}, {"text": "It clears my head when I need to as well.(S1+DM)shopping is a great way to clear myhead.(S0)ilove to shop and watch movies.(Human)yes , and it also helps with depression ihave found.\u2022 \u2022 \u2022\u2022 \u2022 \u2022Figure 4 : Examples of generated responses by our selfconscious agent with Distractor Memory ( S1+DM ) on the PersonaChat dataset ( Zhang et al . , 2018 ) .", "entities": [[44, 45, "DatasetName", "agent"]]}, {"text": "We compare it with the base speaker ( S0 ) of TransferTransfo ( Wolf et al . , 2019b ) and the human response ( Human ) .", "entities": []}, {"text": "5.6 Controlling the Self - Conscious Agent To further analyze our self - conscious agent , we conduct experiments by controlling three features", "entities": [[6, 7, "DatasetName", "Agent"], [14, 15, "DatasetName", "agent"]]}, {"text": "912of our agent : world prior updates pt(i ) , listener rationality \f and speaker rationality \u000b .", "entities": [[2, 3, "DatasetName", "agent"]]}, {"text": "World Prior Update .", "entities": []}, {"text": "In the self - conscious agent , the world prior acts as a cumulative state over personas .", "entities": [[5, 6, "DatasetName", "agent"]]}, {"text": "We remind that we propose to update the world prior with Lt 0instead ofLt 1 in Eq .", "entities": []}, {"text": "( 3 ) .", "entities": []}, {"text": "As reported in Cohn - Gordon et al .", "entities": []}, {"text": "( 2018 ) , our experiments on the Dialogue NLI dataset con\ufb01rm the prior update with Lt 1makes little difference in performance compared with using a uniform distribution .", "entities": []}, {"text": "However , our approach with Lt 0makes signi\ufb01cant difference , as shown in Figure 5 .", "entities": []}, {"text": "The reason is that the pragmatic listener Lt 1 / St 0(utji;h;u < t)\u0002Lt 0(ijh;u\u0014t;pt)re\ufb02ects thecurrentSt 0twice", "entities": []}, {"text": "( i.e. inLt 0and in itself ) per time step .", "entities": []}, {"text": "Hence , the update with Lt 1becomes more of an instantaneous prior rather than a cumulative one .", "entities": []}, {"text": "On the other hand , Lt 0moderately combines the information from both St 0andpt(i ) , preserving better cumulative information .", "entities": []}, {"text": "Listener Rationality \f .We add \f inLt 0to control the amount of information incorporated to the world priorpt(i ) .", "entities": []}, {"text": "Figure 5 depicts that when \f is large , the Hits@1 scores ( i.e. the GT accuracy ) drop .", "entities": [[10, 11, "MetricName", "Hits@1"], [16, 17, "MetricName", "accuracy"]]}, {"text": "With a big \f , the information St 0at current time step overrides the cumulative prior pt(i ) .", "entities": []}, {"text": "That is , the utterance state evolves shortsightedly , ignoring the context information from the previous steps .", "entities": []}, {"text": "Therefore , setting of \f \u00141is advantageous for the self - conscious agent to incrementally decode .", "entities": [[12, 13, "DatasetName", "agent"]]}, {"text": "Speaker Rationality \u000b .Figure", "entities": []}, {"text": "6 shows an example of how generated responses vary according to the intensity of speaker rationality \u000b .", "entities": []}, {"text": "As \u000b increases , the self - conscious agent re\ufb02ects the listener \u2019s distribution ( i.e. the likelihood ) more into the posterior .", "entities": [[8, 9, "DatasetName", "agent"]]}, {"text": "When \u000b is too large , the posterior distribution is overwhelmed by the likelihood of the persona .", "entities": []}, {"text": "Then , the language model degenerates to favor uttering fragments of the given persona while even ignoring the syntax .", "entities": []}, {"text": "Hence , \u000b can control the degree of copying the given condition text .", "entities": []}, {"text": "An appropriate \u000b value allows the given persona condition to blend smoothly in the utterance .", "entities": []}, {"text": "6 Conclusion This work investigated how modeling public selfconsciousness can help dialogue agents improve persona - consistency .", "entities": []}, {"text": "We showed existing dialogue agents are highly insensitive to contradiction , and introduced an orthogonally applicable method using the RSA framework ( Frank and Goodman , 2012 ) to alleviate the issue .", "entities": []}, {"text": "We also designed a 0.00.51.01.52.02.53.03.54.0 \u03b28101214161820Hits@1 ( % ) L0(Ours )", "entities": []}, {"text": "L1 Uniform S0 0.00.51.01.52.02.53.03.54.0 \u03b21618202224 L0(Ours )", "entities": []}, {"text": "L1 Uniform S0Figure 5 : Performance variation of the self - conscious agent for TransferTransfo ( left ) and Blender ( right ) according to \f .", "entities": [[12, 13, "DatasetName", "agent"], [19, 20, "MethodName", "Blender"]]}, {"text": "We compare different methods of updating the world prior pt(i)withL0(Ours),L1and a uniform prior .", "entities": []}, {"text": "The dashed line is the base speaker S0 .", "entities": []}, {"text": "Figure 6 : An example of utterance changes by controlling the speaker rationality \u000b on the PersonaChat .", "entities": []}, {"text": "learning method for distractor selection , named Distractor Memory and proposed a better update for the listener \u2019s world prior .", "entities": []}, {"text": "Furthermore , we demonstrated how our approach can be generalized to improve dialogue context - consistency .", "entities": []}, {"text": "Our self - conscious agents improved the base agents on the Dialogue NLI ( Welleck et al . , 2019 ) and PersonaChat ( Zhang et al . , 2018 ) dataset , without consistency labels and NLI models .", "entities": []}, {"text": "An important future direction will be generating the distractors and learning the rationality coef\ufb01cients .", "entities": []}, {"text": "Acknowledgements We would like to thank Reuben Cohn - Gordon , Sean Welleck , Junhyug Noh and Jiwan Chung for their valuable comments .", "entities": []}, {"text": "We also thank the anonymous reviewers for their thoughtful suggestions on this work .", "entities": []}, {"text": "This research was supported by Brain Research Program by National Research Foundation of Korea ( NRF ) ( 2017M3C7A1047860 ) , Institute of Information & communications Technology Planning & Evaluation ( IITP ) grant funded by the Korea government ( MSIT ) ( No . 2017 - 001772 , Video Turing Test , No . 2019 - 0 - 01082 , SW StarLab ) , and Creative Pioneering Researchers Program through Seoul National University .", "entities": [[57, 58, "DatasetName", "0"]]}, {"text": "Gunhee Kim is the corresponding author .", "entities": []}, {"text": "913References Peter Anderson , Basura Fernando , Mark Johnson , and Stephen Gould . 2016 .", "entities": []}, {"text": "SPICE : Semantic Propositional Image Caption Evaluation .", "entities": [[0, 1, "DatasetName", "SPICE"]]}, {"text": "In ECCV , pages 382\u2013398 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Jacob Andreas and Dan Klein .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Reasoning about Pragmatics with Neural Listeners and Speakers .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Reuben Cohn - Gordon and Noah Goodman .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Lost in Machine Translation : A Method to Reduce Meaning Loss .", "entities": [[2, 4, "TaskName", "Machine Translation"]]}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Reuben Cohn - Gordon , Noah Goodman , and Christopher Potts .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Pragmatically Informative Image Captioning With Character - level Inference .", "entities": [[2, 4, "TaskName", "Image Captioning"]]}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "BERT : Pre - training of Deep Bidirectional Transformers for Language Understanding .", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Emily Dinan , Varvara Logacheva , Valentin Malykh , Alexander Miller , Kurt Shuster , Jack Urbanek , Douwe Kiela , Arthur Szlam , Iulian Serban , Ryan Lowe , et al . 2019 .", "entities": []}, {"text": "The Second Conversational Intelligence Challenge ( ConvAI2 ) .", "entities": [[6, 7, "DatasetName", "ConvAI2"]]}, {"text": "arXiv:1902.00098 .", "entities": []}, {"text": "Kevin Doherty and Barry R Schlenker .", "entities": []}, {"text": "1991 .", "entities": []}, {"text": "SelfConsciousness and Strategic Self - Presentation .", "entities": []}, {"text": "Journal of Personality , 59(1):1\u201318 .", "entities": []}, {"text": "Nouha Dziri , Ehsan Kamalloo , Kory W Mathewson , and Osmar Zaiane .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Evaluating Coherence in Dialogue Systems Using Entailment .", "entities": []}, {"text": "In NAACLHLT .", "entities": []}, {"text": "Allan Fenigstein , Michael F Scheier , and Arnold H Buss .", "entities": []}, {"text": "1975 .", "entities": []}, {"text": "Public and Private Self - Consciousness : Assessment and Theory .", "entities": []}, {"text": "Journal of Consulting and Clinical Psychology , 43(4):522 .", "entities": []}, {"text": "Leon Festinger .", "entities": []}, {"text": "1962 .", "entities": []}, {"text": "A Theory of Cognitive Dissonance , volume 2 .", "entities": []}, {"text": "Stanford University Press .", "entities": []}, {"text": "Michael C Frank and Noah D Goodman .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Predicting Pragmatic Reasoning in Language Games .", "entities": []}, {"text": "Science , 336(6084):998\u2013998 .", "entities": []}, {"text": "Daniel Fried , Jacob Andreas , and Dan Klein . 2017 .", "entities": []}, {"text": "Uni\ufb01ed Pragmatic Models for Generating and Following Instructions .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Daniel Fried , Ronghang Hu , V olkan Cirik , Anna Rohrbach , Jacob Andreas , Louis - Philippe Morency , Taylor Berg - Kirkpatrick , Kate Saenko , Dan Klein , and Trevor Darrell .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Speaker - follower models for vision - and - language navigation .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Alison Gopnik and Henry M Wellman .", "entities": []}, {"text": "1992 .", "entities": []}, {"text": "Why the Child \u2019s Theory of Mind Really is a Theory .", "entities": []}, {"text": "Mind & Language , 7(1 - 2):145\u2013171.Demis Hassabis , R Nathan Spreng , Andrei A Rusu , Clifford A Robbins , Raymond A Mar , and Daniel L Schacter .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Imagine All the People : How the Brain Creates and Uses Personality Models to Predict Behavior .", "entities": []}, {"text": "Cerebral Cortex , 24(8):1979\u20131987 .", "entities": []}, {"text": "\u0141ukasz Kaiser , O\ufb01r Nachum , Aurko Roy , and Samy Bengio . 2017 .", "entities": []}, {"text": "Learning to Remember Rare Events .", "entities": []}, {"text": "InICLR .", "entities": []}, {"text": "Diederik Kingma and Jimmy Ba . 2015 .", "entities": []}, {"text": "Adam : A Method for Stochastic Optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "Stochastic Optimization"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Ilia Kulikov , Alexander Miller , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Importance of Search and Evaluation Strategies in Neural Dialogue Modeling .", "entities": []}, {"text": "In INLG .", "entities": []}, {"text": "Jiwei Li , Michel Galley , Chris Brockett , Georgios P Spithourakis , Jianfeng Gao , and Bill Dolan .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "A Persona - Based Neural Conversation Model .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Margaret Li , Stephen Roller , Ilia Kulikov , Sean Welleck , Y - Lan Boureau , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Do n\u2019t Say That !", "entities": []}, {"text": "Making Inconsistent Dialogue Unlikely with Unlikelihood Training .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Chin - Yew Lin .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Rouge : A Package for Automatic Evaluation of Summaries .", "entities": []}, {"text": "In Text Summarization Branches Out , pages 74\u201381 .", "entities": [[1, 3, "TaskName", "Text Summarization"]]}, {"text": "Qian Liu , Yihong Chen , Bei Chen , Jian - Guang Lou , Zixuan Chen , Bin Zhou , and Dongmei Zhang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "You Impress Me : Dialogue Generation via Mutual Persona Perception .", "entities": [[4, 6, "TaskName", "Dialogue Generation"]]}, {"text": "In ACL .", "entities": []}, {"text": "Andrea Madotto , Zhaojiang Lin , Chien - Sheng Wu , and Pascale Fung .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Personalizing Dialogue Agents via Meta - Learning .", "entities": [[4, 7, "TaskName", "Meta - Learning"]]}, {"text": "In ACL .", "entities": []}, {"text": "Junhua Mao , Jonathan Huang , Alexander Toshev , Oana Camburu , Alan L Yuille , and Kevin Murphy .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Generation and Comprehension of Unambiguous Object Descriptions .", "entities": []}, {"text": "In CVPR .", "entities": []}, {"text": "A. H. Miller , W. Feng , A. Fisch , J. Lu , D. Batra , A. Bordes , D. Parikh , and J. Weston .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "ParlAI : A Dialog Research Software Platform .", "entities": []}, {"text": "arXiv:1705.06476 .", "entities": []}, {"text": "Alec Radford , Karthik Narasimhan , Tim Salimans , and Ilya Sutskever . 2018 .", "entities": []}, {"text": "Improving Language Understanding with Unsupervised Learning .", "entities": []}, {"text": "Technical report , Technical report , OpenAI .", "entities": []}, {"text": "Hannah Rashkin , Eric Michael Smith , Margaret Li , and Y - Lan Boureau .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Towards Empathetic Opendomain Conversation Models : A New Benchmark and Dataset .", "entities": [[9, 11, "DatasetName", "and Dataset"]]}, {"text": "In ACL .", "entities": []}, {"text": "Stephen Roller , Emily Dinan , Naman Goyal , Da Ju , Mary Williamson , Yinhan Liu , Jing Xu , Myle Ott , Kurt Shuster , Eric M Smith , et al . 2020 .", "entities": []}, {"text": "Recipes for Building an Open - Domain Chatbot .", "entities": [[7, 8, "TaskName", "Chatbot"]]}, {"text": "arXiv:2004.13637 .", "entities": []}, {"text": "914Abigail See , Stephen Roller , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "What Makes a Good Conversation ?", "entities": []}, {"text": "How Controllable Attributes Affect Human Judgments .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Sheng Shen , Daniel Fried , Jacob Andreas , and Dan Klein .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Pragmatically Informative Text Generation .", "entities": [[2, 4, "TaskName", "Text Generation"]]}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Michael Shum , Stephan Zheng , Wojciech Kry \u00b4 sci\u00b4nski , Caiming Xiong , and Richard Socher .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "SketchFill - AR : A Persona - Grounded Chit - Chat Generation Framework .", "entities": []}, {"text": "arXiv:1910.13008 .", "entities": []}, {"text": "Haoyu Song , Yan Wang , Wei - Nan Zhang , Xiaojiang Liu , and Ting Liu . 2020 .", "entities": []}, {"text": "Generate , Delete and Rewrite : A Three - Stage Framework for Improving Persona Consistency of Dialogue Generation .", "entities": [[16, 18, "TaskName", "Dialogue Generation"]]}, {"text": "In ACL .", "entities": []}, {"text": "Haoyu Song , Wei - Nan Zhang , Jingwen Hu , and Tiu Liu . 2019 .", "entities": []}, {"text": "Generating Persona Consistent Dialogues by Exploiting Natural Language Inference .", "entities": [[6, 9, "TaskName", "Natural Language Inference"]]}, {"text": "arXiv:1911.05889 .", "entities": []}, {"text": "Ramakrishna Vedantam , Samy Bengio , Kevin Murphy , Devi Parikh , and Gal Chechik . 2017 .", "entities": []}, {"text": "ContextAware Captions from Context - Agnostic Supervision .", "entities": []}, {"text": "InCVPR .", "entities": []}, {"text": "Sean Welleck , Jason Weston , Arthur Szlam , and Kyunghyun Cho . 2019 .", "entities": []}, {"text": "Dialogue Natural Language Inference .", "entities": [[1, 4, "TaskName", "Natural Language Inference"]]}, {"text": "In ACL .", "entities": []}, {"text": "Thomas Wolf , Lysandre Debut , Victor Sanh , Julien Chaumond , Clement Delangue , Anthony Moi , Pierric Cistac , Tim Rault , R \u00b4 emi Louf , Morgan Funtowicz , et al . 2019a .", "entities": []}, {"text": "Transformers : State - of - the - art Natural Language Processing .", "entities": []}, {"text": "arXiv:1910.03771 .", "entities": []}, {"text": "Thomas Wolf , Victor Sanh , Julien Chaumond , and Clement Delangue .", "entities": []}, {"text": "2019b .", "entities": []}, {"text": "TransferTransfo : A Transfer Learning Approach for Neural Network based Conversational Agents .", "entities": [[3, 5, "TaskName", "Transfer Learning"]]}, {"text": "arXiv:1901.08149 .", "entities": []}, {"text": "Sina Zarrie\u00df and David Schlangen . 2019 .", "entities": []}, {"text": "Know What You Do n\u2019t Know : Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Saizheng Zhang , Emily Dinan , Jack Urbanek , Arthur Szlam , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Personalizing Dialogue Agents : I Have a Dog , Do You Have Pets Too ?", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Yizhe Zhang , Xiang Gao , Sungjin Lee , Chris Brockett , Michel Galley , Jianfeng Gao , and Bill Dolan .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Consistent Dialogue Generation with Selfsupervised Feature Learning .", "entities": [[1, 3, "TaskName", "Dialogue Generation"]]}, {"text": "arXiv:1903.05759 .A", "entities": []}, {"text": "Results on Variants of Distractor Selection ( Section 4.2 ) Model Hits@1 \" Entail@1 \" Contradict@1 # ControlSeq2Seq ( See et al . , 2019 )", "entities": [[11, 12, "MetricName", "Hits@1"]]}, {"text": "Random 8.5 32.8 37.6 Nearest 7.6 32.8 36.5 Farthest 9.4 33.6 35.4 BERT - Classi\ufb01er 9.2 33.6 35.6 BERT - Ranker 9.6 33.3 35.1 DM 11.1 36.0 28.2 Table 8 : Quantitative results of the proposed Distractor Memory ( DM ) and other distractor selection methods on the Dialogue NLI evaluation set ( Welleck et al . , 2019 ) .", "entities": [[12, 13, "MethodName", "BERT"], [18, 19, "MethodName", "BERT"]]}, {"text": "We compare our proposed Distractor Memory ( DM ) with three heuristic methods , and two variants of the pretrained BERT model ( Devlin et al . , 2019 ) .", "entities": [[20, 21, "MethodName", "BERT"]]}, {"text": "As a straightforward baseline , we randomly selectkpersonas from training set and directly use it as distractors .", "entities": []}, {"text": "Second , we test the k - nearest search by speaker \u2019s persona , denoted by Nearest ; for a given persona descriptions , we \ufb01nd its closest training persona embedding using cosine similarity on average pooled BERT features .", "entities": [[37, 38, "MethodName", "BERT"]]}, {"text": "The third baseline denoted by Farthest is to \ufb01nd the k - farthest persona among the training personas .", "entities": []}, {"text": "We also compare with two variants of the BERT model .", "entities": [[8, 9, "MethodName", "BERT"]]}, {"text": "The \ufb01rst variant is BERT - Classi\ufb01er , which takes dialogue context as input and returns the index of persona from training set as output .", "entities": [[4, 5, "MethodName", "BERT"]]}, {"text": "The second variant is bi - encoder ranking model of Miller et al .", "entities": []}, {"text": "( 2017 ) , denoted by BERT - Ranker .", "entities": [[6, 7, "MethodName", "BERT"]]}, {"text": "It encodes dialogue context and candidate persona with separate BERT encoders measuring its ranking with cosine similarity .", "entities": [[9, 10, "MethodName", "BERT"]]}, {"text": "For both methods , we use top- k ranked personas as distractors and set k= 4 for all the methods .", "entities": []}, {"text": "We use Adam optimizer ( Kingma and Ba , 2015 ) with learning rate 2e-5 and \ufb01netune BERT - Uncased - Base up to 3 epochs .", "entities": [[2, 3, "MethodName", "Adam"], [3, 4, "HyperparameterName", "optimizer"], [12, 14, "HyperparameterName", "learning rate"], [17, 18, "MethodName", "BERT"]]}, {"text": "Table 8 compares the performance of different distractor selecting methods on the Dialogue NLI evaluation set ( Welleck et al . , 2019 ) .", "entities": []}, {"text": "We set \u000b = 8 , \f = 0:5 , andjIj= 5 .", "entities": []}, {"text": "The DM model outperforms all the baselines across all metrics .", "entities": []}, {"text": "The Farthest shows better performance than the Nearest .", "entities": []}, {"text": "It can be understood that dissimilar distractors are more effective in the Rational Speech Acts framework ( Frank and Goodman , 2012 ) .", "entities": []}, {"text": "The BERT - Ranker performs the best among baselines , but not as good as ours , which validates that memorization capability is effective for selecting useful distractors .", "entities": [[1, 2, "MethodName", "BERT"]]}, {"text": "915B Implementation Details Base Codes and Datasets .", "entities": []}, {"text": "We use the ParlAI framework2(Miller et", "entities": []}, {"text": "al . , 2017 ) and HuggingFace \u2019s Transformers3(Wolf et al . , 2019a ) to implement our models and baselines .", "entities": []}, {"text": "We use Dialogue NLI ( Welleck et al . , 2019 ) and PersonaChat ( Zhang et al . , 2018 ) datasets from the ParlAI framework as is .", "entities": []}, {"text": "We use the default preprocessing in ParlAI .", "entities": []}, {"text": "Training .", "entities": []}, {"text": "Our self - consciousness approach improves consistency for any pretrained dialogueagents without additional consistency labels and pretrained NLI models .", "entities": []}, {"text": "Since it post - processes the output probability of pretrained dialogue - agents in a Bayesian fashion , no additional model parameters are added to the dialogue agents .", "entities": []}, {"text": "Thus , it does not require any training .", "entities": []}, {"text": "In the case of using the Distractor Memory ( DM ) , \ufb01rst we initialize BERT - Uncased - Base with pretrained weights and \ufb01netune it up to 3 epochs with Adam optimizer with learning rate 2e-5 .", "entities": [[15, 16, "MethodName", "BERT"], [31, 32, "MethodName", "Adam"], [32, 33, "HyperparameterName", "optimizer"], [34, 36, "HyperparameterName", "learning rate"]]}, {"text": "Then we \ufb01nd the best distractor persona for each model and use those labels to train our DM .", "entities": []}, {"text": "We train our DM on one NVIDIA TITAN Xp GPU up to 7 epochs .", "entities": [[7, 8, "DatasetName", "TITAN"]]}, {"text": "Hyperparameters .", "entities": []}, {"text": "For Dialogue NLI evaluation , we set the speaker rationality \u000b = 8:0 , the listener rationality \f = 1:0 , and the cardinality of the worldIto 3 .", "entities": []}, {"text": "In PersonaChat evaluation , we set \u000b = 2:0 , \f = 0:3for ControlSeq2Seq", "entities": []}, {"text": "( See et al . , 2019 ) , \u000b = 2 , \f = 0:9for TransferTransfo ( Wolf et al . , 2019b ) , and \u000b = 2:0 , \f =", "entities": []}, {"text": "0:5for Blender 90 M ( Roller et al . , 2020 ) .", "entities": [[1, 2, "MethodName", "Blender"]]}, {"text": "We also set jIj= 3 .", "entities": []}, {"text": "We experiment \u000b = f1:0;2:0;4:0;8:0;16:0 g , \f = f0:3;0:5;0:9;1:0;2:0;4:0 g , andjIj = f2;3;5 g. We choose the hyper - parameter con\ufb01guration showing the best performance in Hits@1 for Dialogue NLI and F1 score for PersonaChat .", "entities": [[28, 29, "MetricName", "Hits@1"], [33, 35, "MetricName", "F1 score"]]}, {"text": "The posterior distribution of our self - conscious agents are computed deterministically .", "entities": []}, {"text": "For our Distractor Memory , we set the memory key matrix as K2Rm\u0002d , wherem= 16000 andd= 768 .", "entities": []}, {"text": "We set the number of nearest neighbor k= 2048 .", "entities": [[8, 9, "DatasetName", "2048"]]}, {"text": "Inference .", "entities": []}, {"text": "We use greedy decoding for all methods .", "entities": []}, {"text": "The average runtime for our self - conscious approach is dependent on the base dialogue agents and the cardinality of world Iwhich can be run in parallel like beam search .", "entities": []}, {"text": "Evaluation .", "entities": []}, {"text": "We follow the evaluation of the ParlAI framework .", "entities": []}, {"text": "Following Madotto et al .", "entities": []}, {"text": "( 2019 ) , 2https://parl.ai/ 3https://huggingface.co/transformers/we use the \ufb01netuned BERT - based NLI model4to compute the C score .", "entities": [[9, 10, "MethodName", "BERT"]]}, {"text": "C Dialogue Examples Figure 7 shows selected examples of generated responses .", "entities": []}, {"text": "In each set , we show given persona , dialogue context , human responses , and generated responses by our self - conscious agent and the base speaker .", "entities": [[23, 24, "DatasetName", "agent"]]}, {"text": "We use TransferTransfo ( Wolf et al . , 2019b ) as a base speaker . 4https://github.com/HLTCHKUST/PAML .", "entities": []}, {"text": "916 P1 \u2019s PersonaI\u2019ve 5 cats .", "entities": []}, {"text": "I am a construction worker .", "entities": []}, {"text": "My cats are very special to me .", "entities": []}, {"text": "I enjoy building houses .", "entities": []}, {"text": "Dialogue History[P2 ]", "entities": []}, {"text": "It is going very great .", "entities": []}, {"text": "I just have homework to do[P1 ]", "entities": []}, {"text": "Oh what are you in school for?[P2 ] High school .", "entities": []}, {"text": "On my sophomore year.[P1 ] Are you planning to go to college ?", "entities": []}, {"text": "[ P2 ] I am !", "entities": []}, {"text": "I want to be a professional soccer player.(S1+DM)i work construction .", "entities": []}, {"text": "i \u2019m a construction worker.(S0)i\u2019ma construction worker .", "entities": []}, {"text": "i\u2019mgoing to be a vet.(Human)exciting !", "entities": []}, {"text": "iplayed soccer in high school too , long ago\u2022 \u2022 \u2022P1 \u2019s PersonaI own a house in Florida .", "entities": []}, {"text": "I work in it and have been at the same company for 15 years .", "entities": []}, {"text": "I enjoy American sportsI\u2019ve a children and a dogs .", "entities": []}, {"text": "Dialogue History[P2 ]", "entities": []}, {"text": "Hello , how are you today?[P1 ]", "entities": []}, {"text": "Hey !", "entities": []}, {"text": "Just watching a game of football with my children .", "entities": [[3, 6, "TaskName", "game of football"]]}, {"text": "You?[P2 ]", "entities": []}, {"text": "That \u2019s cool !", "entities": []}, {"text": "I am an alcoholic who is recovering.(S1+DM)iwork in a company and i \u2019m a workaholic.(S0)i\u2019msorry to hear that .", "entities": []}, {"text": "I \u2019m a retired professional athlete.(Human)ah man congrats for trying to get back on the road !", "entities": []}, {"text": "P1 \u2019s PersonaI\u2019m a huge star wars fan .", "entities": []}, {"text": "I try various coffees as a hobby .", "entities": []}, {"text": "I enjoy poetry .", "entities": []}, {"text": "I played football for a   division a college .", "entities": []}, {"text": "Dialogue History[P1 ] I \u2019m good , taking a break from my assignments before heading to Europe.[P2 ] I went to Spain then , learned I love cooking paella .", "entities": []}, {"text": "What team are you for?[P1 ] I \u2019m with Ohio state .", "entities": []}, {"text": "Born and raised in Ohio.[P2 ]", "entities": []}, {"text": "Awesome .", "entities": []}, {"text": "What do you do for a living?(S1+DM)iplay football for a local college.(S0)i\u2019ma student .", "entities": []}, {"text": "i \u2019m a student(Human)i\u2019ma student , going to school for veterinary medicine .\u2022", "entities": []}, {"text": "\u2022 \u2022P1 \u2019s PersonaMy family does not support my career choices .", "entities": []}, {"text": "My dream car is a Rolls Royce ghost .", "entities": []}, {"text": "I often shop for shoes and watches .", "entities": []}, {"text": "I like shopping .", "entities": []}, {"text": "I currently work for a watch dealer .", "entities": []}, {"text": "Dialogue History[P1 ] I really enjoy shopping and my dream is to one day own a Rolls Royce ghost.[P2 ]", "entities": []}, {"text": "Wow .", "entities": []}, {"text": "I enjoy running over driving.[P1 ] Running is also quite lovely .", "entities": []}, {"text": "Breathing in the lovely outside air.[P2 ]", "entities": []}, {"text": "Yes it is .", "entities": []}, {"text": "It clears my head when I need to as well.(S1+DM)shopping is a great way to clear my head.(S0)i love to shop and watch movies.(Human)yes , and it also helps with depression ihave found.\u2022 \u2022 \u2022Figure 7 : Examples of generated responses by our self - conscious agent with Distractor Memory ( S1+DM ) on the PersonaChat dataset ( Zhang et al . , 2018 ) .", "entities": [[46, 47, "DatasetName", "agent"]]}, {"text": "We compare it with the base speaker ( S0 ) of TransferTransfo ( Wolf et al . , 2019b ) and the human response ( Human ) .", "entities": []}]