[{"text": "Exploratory Analysis for Ontology Learning from Social Events on Social Media Streaming in Spanish Enrique Valeriano Facultad de Ciencias e Ingenier \u00b4 \u0131a Ponti\ufb01cia Universidad Cat \u00b4 olica del Per \u00b4 u enrique.valeriano@pucp.peArturo Oncevay - Marcos Departamento de Ciencias", "entities": [[3, 4, "MethodName", "Ontology"]]}, {"text": "e Ingenier \u00b4 \u0131a Ponti\ufb01cia Universidad Cat \u00b4 olica del Per \u00b4 u arturo.oncevay@pucp.edu.pe", "entities": []}, {"text": "Abstract The problem of event analysis in Spanish social media streaming is that of dif\ufb01culty on automatically processing the data as well as obtaining the most relevant information , such as mentioned by Derczynski et", "entities": [[33, 34, "DatasetName", "Derczynski"]]}, {"text": "al . ( 2015 ) .", "entities": []}, {"text": "An event is de\ufb01ned as a real world occurrence that takes place in a speci\ufb01c time and space ; Atefeh and Khreich ( 2013 ) identi\ufb01es these occurrences by the entities that took part on it as well as the activities done in it .", "entities": []}, {"text": "This project focuses on researching about the viability of modeling these events as ontologies using an automatic approach for entities and relationships extraction in order to obtain relevant information about the event in case .", "entities": []}, {"text": "Spanish data from Twitter was used as a study case and tested with the developed application .", "entities": []}, {"text": "1 Introduction According to Lobzhanidze et al .", "entities": []}, {"text": "( 2013 ) , globalization and the increased use of social networks has made it possible for news and events related information to be propagated in a much faster manner to every part of the world .", "entities": []}, {"text": "It is in this context that event analysis is the most relevant since , as Valkanas and Gunopulos ( 2013 ) mention , now there is more data available to study and analyze than ever before .", "entities": []}, {"text": "An event is de\ufb01ned as a real world occurrence that takes place in a speci\ufb01c time and space ; Atefeh and Khreich ( 2013 ) identi\ufb01es these occurrences by the entities that took part on it as well as the activities done in it .", "entities": []}, {"text": "Events will be the main study object in this paper and , more speci\ufb01cally , event data in Spanish obtained from Twitter will be used to test the different methods and techniques exposed on each Section .", "entities": []}, {"text": "In order to effectively analyze events there are two steps that need to be taken into consideration as mentioned in Kumbla ( 2016 ): ( 1 ) event data acquisition , and ( 2 ) event data processing .", "entities": []}, {"text": "The \ufb01rst step is the one that bene\ufb01ts the most by social media streaming since more data is available , though one of the downsides to this is that the data is usually not ready to be used right away and most of the times a preprocessing step needs to happen .", "entities": []}, {"text": "This step is further explained on section Section 3 .", "entities": []}, {"text": "The second step will be the main focus on this paper since the biggest problem on event data analysis in Spanish is this one .", "entities": []}, {"text": "In particular , automatic approaches for entities and relationships extraction will be presented on Section 4 .", "entities": []}, {"text": "The remainder of this paper is organized as follows .", "entities": []}, {"text": "In Section 2 some relevant related work is exposed .", "entities": []}, {"text": "Later , in Section 3 the event acquisition process is further expanded upon .", "entities": []}, {"text": "The ontology structure used for the events representation as well as the algorithms employed in order to obtain entities and relationships between these are further explained on Section 4 .", "entities": [[1, 2, "MethodName", "ontology"]]}, {"text": "Section 5 introduces a simple application developed in order to make use of the algorithms and techniques mentioned on the previous sections .", "entities": []}, {"text": "On section 6 we compare the results obtained with manually created ontologies and obtain precision and recall values for each case .", "entities": []}, {"text": "Finally , concluding remarks are provided in Section 7 .", "entities": []}, {"text": "2 Related Work In Al - Smadi and Qawasmeh ( 2016 ) an unsupervised approach for event extraction from Arabic tweets is discussed .", "entities": [[16, 18, "TaskName", "event extraction"]]}, {"text": "Entities appearing in the data are linked to corresponding entities found on Wikipedia and DBpedia through an ontology based knowledge base .", "entities": [[14, 15, "DatasetName", "DBpedia"], [17, 18, "MethodName", "ontology"]]}, {"text": "The entities from the data are extracted based on rules related to the Arabic language .", "entities": []}, {"text": "In Derczynski et al . ( 2015 ) a comparative evaluation of different NER is done based on three different datasets .", "entities": [[1, 2, "DatasetName", "Derczynski"], [13, 14, "TaskName", "NER"]]}, {"text": "Also , some common challenges or errors when handling data from Twitter are presented as well as methods for reducing microblog noise through pre - processing such as language identi\ufb01cation , POStagging and normalization .", "entities": []}, {"text": "In Ilknur et al . ( 2011 ) a framework for learning relations between entities in Twitter is presented .", "entities": []}, {"text": "This framework allows for entities as well as entity types or topics to be detected , which results in a graph connecting semantically enriched resources to their respective entities .", "entities": []}, {"text": "Then relation discovery strategies are employed to detect pair of entities that have a certain type of relationship in a speci\ufb01c period of time .", "entities": []}, {"text": "In Raimond and Abdallah ( 2007 ) an event ontology is described .", "entities": [[9, 10, "MethodName", "ontology"]]}, {"text": "This model also contains some key characteristics such as place , location , agents and products .", "entities": []}, {"text": "On the other hand , event - subevent relationships are used to build the related ontologies .", "entities": []}, {"text": "This model was developed for the Center for Digital Music and tested by structuring proceedings and concert descriptions .", "entities": []}, {"text": "Finally , an ontology model for events is proposed in which entities are extracted using the CMU tweet analyzer and relationships are inferred from Wikipedia , DBpedia and Web data .", "entities": [[3, 4, "MethodName", "ontology"], [26, 27, "DatasetName", "DBpedia"]]}, {"text": "This approach also uses a POS - tagging step in order to obtain the initial set of entities to process .", "entities": []}, {"text": "3 Event data acquisition 3.1 Data retrieval As it was mentioned before , nowadays there are numerous avenues for event data acquisition .", "entities": []}, {"text": "For this paper Twitter was chosen as the social network to use for retrieving data since this data is easily available and a good amount of it is related to events of different categories .", "entities": []}, {"text": "Twitter \u2019s REST API was used in order to retrieve data related to these events : 1 . Australian Open : 2217 tweets from 21/01/2017 to 30/01/2017 2 . March against corruption in Peru : 1493 tweets from 11/02/2017 to 20/02/2017 3 .", "entities": []}, {"text": "Complaints about new toll in Puente Piedra : 3882 tweets from 08/01/2017 to 18/01/2017 Each dataset had a \ufb01le per day with all the tweets from the day and contained only the text that represents a tweet per line .", "entities": []}, {"text": "3.2", "entities": []}, {"text": "Preprocessing With the raw data ready to be used , the preprocessing step followed .", "entities": []}, {"text": "The sequence followed is exposed below : 1 .", "entities": []}, {"text": "Removing punctuation and unicode only characters except written accents .", "entities": []}, {"text": "2 . Tokenizing the tweets for easier use in Section 4 .", "entities": []}, {"text": "Each tokenized tweet also contains a reference to the original , unprocessed tweet , which will be used on Section 5 .", "entities": []}, {"text": "4 Event data processing 4.1 Ontology learning overview Ontology learning is de\ufb01ned by Cimiano ( 2006 ) as the automatic acquisition of a domain model from some dataset .", "entities": [[5, 6, "MethodName", "Ontology"], [8, 9, "MethodName", "Ontology"]]}, {"text": "In this paper we focus on applying ontology learning techniques for data represented as text .", "entities": [[7, 8, "MethodName", "ontology"]]}, {"text": "Cimiano points towards two main approaches for ontology learning : 1 . Machine learning 2 .", "entities": [[7, 8, "MethodName", "ontology"]]}, {"text": "Statistical approach Statistical based algorithms are further discussed on Sections 4.3 and 4.4 .", "entities": []}, {"text": "4.2 Ontology structure Before we start using different techniques in order to populate an ontology or to learn entities and relationships from the data that was retrieved previously , an ontology structure had to be de\ufb01ned .", "entities": [[1, 2, "MethodName", "Ontology"], [14, 15, "MethodName", "ontology"], [30, 31, "MethodName", "ontology"]]}, {"text": "The ontology structure that we de\ufb01ne will point us towards different techniques depending on the information that must be retrieved to populate this particular structure .", "entities": [[1, 2, "MethodName", "ontology"]]}, {"text": "Therefore , the proposed ontology structure in this paper is de\ufb01ned on Figure 1 .", "entities": [[4, 5, "MethodName", "ontology"]]}, {"text": "Figure 1 : Entity structure The ontology will be populated by such triples composed of ( Entity , Temporal entity , object ) .", "entities": [[6, 7, "MethodName", "ontology"]]}, {"text": "Where Entity denotes a subject that interacts in the event , Temporal entity refers to the date when the particular activity takes place and object is the recipient of the activity .", "entities": []}, {"text": "4.3 Entities extraction This was one of the main points of interest and research on this paper , how to select the most representative entities for the event in order to not overwhelm people analyzing the results but also to not present too little or irrelevant information .", "entities": []}, {"text": "In order to achieve this , two initial tools for entity retrieval were tested : 1 . Stanford NER : The Stanford NER used with a trained Spanish model from late 2016 was used in order to retrieve persons , entities and organizations and group them all together as entities .", "entities": [[10, 12, "TaskName", "entity retrieval"], [18, 19, "TaskName", "NER"], [22, 23, "TaskName", "NER"]]}, {"text": "2 . UDPipe : UDPipe allows to parse text in order to obtain the grammatical categories of the words in each sentence , as well as the syntactic dependencies or syntactic tree that envelops the whole sentence .", "entities": []}, {"text": "The entities are obtained from the grammatical category PROPN .", "entities": []}, {"text": "These two approaches were then implemented and tested with each dataset and a manual comparison was made between the entities that each approach captured .", "entities": []}, {"text": "The results showed that , while the Stanford NER worked really well in the case where the tweets were news related or had a more formal undertone , such as in the case of the Australian Open , it failed to \ufb01nd a lot of basic entities in the other two datasets where the data was more unstructured as one would very likely \ufb01nd when working on social streaming .", "entities": [[8, 9, "TaskName", "NER"]]}, {"text": "Also , the Stanford NER has heavily in\ufb02uenced by correct capitalization and punctuation , whereas UDPipe was n\u2019t in\ufb02uenced by these factors as much .", "entities": [[4, 5, "TaskName", "NER"]]}, {"text": "Because of this , UDPipe was chosen as the main initial entity extraction tool moving forward .", "entities": []}, {"text": "After having a set of initial entities , further processing steps were taken to ensure a better result .", "entities": []}, {"text": "4.3.1 Entity clustering Entity clustering was done on two stages .", "entities": []}, {"text": "First , an algorithm for entity clustering was devised based on two metrics : 1 . Normalized frequency of two entities appearing in a single tweet : The frequency of appearance between two speci\ufb01c entities in tweets .", "entities": []}, {"text": "2 . Average Entity to entity distance in a tweet ( i.e. in the sentence \u201d Nadal venci \u00b4 o a Federer \u201d , if both Nadal and Federer are identi\ufb01ed as entities , they would have a distance of 3 for this tweet )", "entities": []}, {"text": "A threshold of 0.125 was set as the minimum normalized frequency for a pair of entities and a minimum average Entity to Entity distance of 1.65 .", "entities": []}, {"text": "These two values were set based on experimentation with the resulting clustered entities from each dataset .", "entities": []}, {"text": "After that , an approach based on Levenshtein distance ( minimum amount of additions , replacements or deletions needed to turn a word into another ) was employed , where two entities were clustered together if their distance was more than 0.9 times the length of the longest entity from the two .", "entities": []}, {"text": "An example of this distance can be seen on Figure 2 .", "entities": []}, {"text": "Figure 2 : Example of Levenshtein distance", "entities": []}, {"text": "By applying this , resulting clusters such as the ones shown on Figure 3 were obtained .", "entities": []}, {"text": "Figure 3 : Resulting clusters for the Australian Open case 4.3.2 Formal Context Analysis ( FCA ) FCA is one of the approaches for entity extraction detailed on Cimiano ( 2006 ) .", "entities": []}, {"text": "It is the one that garners the most focus on this book as the main set - theoretical approach based on verb - subject components .", "entities": []}, {"text": "This approach is based on obtaining the formal context for a speci\ufb01c domain or dataset and then proceed to use it to create a hierarchy ontology .", "entities": [[25, 26, "MethodName", "ontology"]]}, {"text": "An example of how a formal context would look for a tourism domain knowledge can be seen on Table 1 . Table 1 : Example of a tourism domain knowledge as a formal context Cimiano ( 2006 ) bookable rentable rideable hotel X apartment X X bike X X X excursion X trip X In this paper we use the created formal contexts to discriminate between entities based on three metrics : Conditional ( n ; v )", "entities": []}, {"text": "= P(n ; v ) = f(n ; v ) f(v)(1 ) PMI ( n ; v ) = log2P(njv ) P(n)(2 ) Resnik ( n ; v )", "entities": []}, {"text": "= SR(v)\u0003P(njv ) ( 3 ) Where : 1 . f(n , v ) = > Frequency of apparition of entity n with verb v 2 . f(v )", "entities": []}, {"text": "= > Frequency of apparition of verb v with any entity", "entities": []}, {"text": "And : SR(v )", "entities": []}, {"text": "= X nP(njv)\u0003log2P(njv ) P(n)(4 )", "entities": []}, {"text": "A threshold of 0.1 as a minimum value is set for all of the three aforementioned metrics ( Conditional , PMI and Resnik weights ) , meaning that the ( entity , verb ) pairs that not surpass this threshold for any of the three metrics are pruned .", "entities": []}, {"text": "4.4 Relationships extraction In this subsection UDPipe is also used in order to extract the syntactic dependencies , in particular , the focus is to obtain \u2019 dobj \u2019 and \u2019 iobj \u2019 objects , which refer to direct and indirect object respectively , and then obtain the root verb they stem from .", "entities": []}, {"text": "By doing this a verb can be linked to each object and furthermore , the entities related to verb , which were obtained from the Formal Context , can be linked to each object .", "entities": []}, {"text": "Doing this allows us to add activities for each entity , as well as create a relationship between two entities where one of them appears as an object in the action of another .", "entities": []}, {"text": "5 Visualization A desktop application was developed in order to allow for easier visualization of both the ontology and the resulting activities that each entity participated in , as well as the activities that create a relationship between two particular entities .", "entities": [[17, 18, "MethodName", "ontology"]]}, {"text": "Figure 4 : Timeline for the entity rafaelnadal On Figure 4 a timeline was given for the entity rafaelnadal on the Australian Open case , where each day has tweets that represent activities that were extracted from the dataset .", "entities": []}, {"text": "6 Veri\ufb01cation In order to verify the approach applied for ontology extraction , we manually created ontologies for each test case where the most relevant entities and relationships are speci\ufb01ed based on investigation related to these cases , these ontologies can be seen on Figures 5 , 6 and 7 .", "entities": [[10, 11, "MethodName", "ontology"]]}, {"text": "These ontologies were then presented to colleagues with more profound knowledge on each of the events for validation and were redone based on their feedback until they were accepted by them .", "entities": []}, {"text": "Figure 5 : Ontology created for the Australian Open case Figure 6 : Ontology created for the Puente Piedra \u2019s toll case Figure 7 : Ontology created for the March against the Corruption case From these ontologies we obtained precision and recall values for both entities and relationships for each case .", "entities": [[3, 4, "MethodName", "Ontology"], [13, 14, "MethodName", "Ontology"], [25, 26, "MethodName", "Ontology"]]}, {"text": "These can be seen on Tables 2 , 3 and 4 :", "entities": []}, {"text": "Table 2 : Metrics for the Australian Open case Analyzed parameter Metric Value Entities Precision 0.875 Entities Recall 1.0 Relationships Precision 0.952", "entities": [[14, 15, "MetricName", "Precision"], [17, 18, "MetricName", "Recall"], [20, 21, "MetricName", "Precision"]]}, {"text": "Relationships Recall 1.0 Table 3 : Metrics for the Puente Piedra \u2019s toll case Analyzed parameter Metric Value Entities Precision 0.556 Entities Recall 1.0 Relationships Precision 0.333 Relationships Recall 1.0 Table 4 : Metrics for the March against Corruption case Analyzed parameter Metric Value Entities Precision 0.467 Entities Recall 1.0 Relationships Precision 0.333 Relationships Recall 0.667", "entities": [[1, 2, "MetricName", "Recall"], [19, 20, "MetricName", "Precision"], [22, 23, "MetricName", "Recall"], [25, 26, "MetricName", "Precision"], [28, 29, "MetricName", "Recall"], [45, 46, "MetricName", "Precision"], [48, 49, "MetricName", "Recall"], [51, 52, "MetricName", "Precision"], [54, 55, "MetricName", "Recall"]]}, {"text": "The main point of interest in these metrics lies on the precision , where the precision on the Australian Open case in quite higher than on the other two cases .", "entities": []}, {"text": "From further inspection on the corresponding data we could infer that this was the case because a big part of the tweets for the Australian Open where either formal tweets made by users representing news outlets or by the players themselves .", "entities": []}, {"text": "As for the other two cases , most of the tweets where a mix of news and discussion from common people about these events", "entities": []}, {"text": ".", "entities": []}, {"text": "7 Conclusions and future work We conclude that , while the methods exposed on this paper work good enough on cases such as the Australian Open one , there is still work to be done when the general public is more engaged on the event such as the cases of the Puente Piedra toll and the March against the corruption .", "entities": []}, {"text": "This paper \u2019s aim was to give a foundation and a initial stage of exploratory analysis on social media streaming in Spanish by using ontologies , after which future work could be based upon in order to expand the knowledge in the ontologies or use this analysis together with an event detection system in order to be able to both detect and analyze events in real time .", "entities": [[50, 52, "TaskName", "event detection"]]}, {"text": "References Al - Smadi , M. and O. Qawasmeh ( 2016 ) .", "entities": []}, {"text": "Knowledge - based approach for event extraction from arabic tweets .", "entities": [[5, 7, "TaskName", "event extraction"]]}, {"text": "International Journal of Advanced Computer Science and Applications 7 , 483\u2013490 .", "entities": []}, {"text": "Atefeh , F. and W. Khreich ( 2013 ) .", "entities": []}, {"text": "A survey of techniques for event detection in twitter .", "entities": [[5, 7, "TaskName", "event detection"]]}, {"text": "Computational Intelligence 0 ( 0 ) .", "entities": [[2, 3, "DatasetName", "0"], [4, 5, "DatasetName", "0"]]}, {"text": "Cimiano , P. ( 2006 ) .", "entities": []}, {"text": "Ontology Learning and Population from Text Algorithms , Evaluation and Applications .", "entities": [[0, 1, "MethodName", "Ontology"]]}, {"text": "223 Spring Street , New York , NY 10013 :", "entities": []}, {"text": "Springer Science+Business Media .", "entities": []}, {"text": "Derczynski , L. , D. Maynard , G. R. , M. v. E. , and G. G. ( 2015 ) .", "entities": [[0, 1, "DatasetName", "Derczynski"]]}, {"text": "Analysis of named entity recognition and linking for tweets .", "entities": [[2, 5, "TaskName", "named entity recognition"]]}, {"text": "Information Processing and Management 51 , 32\u201349 .", "entities": [[3, 4, "TaskName", "Management"]]}, {"text": "Ilknur , C. , A. F. , and H. G. ( 2011 ) .", "entities": []}, {"text": "Learning semantic relations between entities in twitter .", "entities": []}, {"text": "Information Processing and Management 51 , 32\u201349 .", "entities": [[3, 4, "TaskName", "Management"]]}, {"text": "Kumbla , S. ( 2016 ) .", "entities": []}, {"text": "Fast data : Powering real - time big data .", "entities": []}, {"text": "Lobzhanidze , A. , W. Zeng , P. Gentry , and A. Taylor ( 2013 ) .", "entities": []}, {"text": "Mainstream media vs. social media for trending topic prediction - an experimental study .", "entities": []}, {"text": "Consumer Communications and Networking Conference ( CNNC ) , 729\u2013732 .", "entities": []}, {"text": "Raimond , Y .", "entities": []}, {"text": "and S. Abdallah ( 2007 ) .", "entities": []}, {"text": "The event ontology .", "entities": [[2, 3, "MethodName", "ontology"]]}, {"text": "Valkanas , G. and D. Gunopulos ( 2013 ) .", "entities": []}, {"text": "Event detection from social media data .", "entities": [[0, 2, "TaskName", "Event detection"]]}]