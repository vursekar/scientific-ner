[{"text": "Proceedings of the 22nd Conference on Computational Natural Language Learning ( CoNLL 2018 ) , pages 562\u2013572 Brussels , Belgium , October 31 - November 1 , 2018 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2018 Association for Computational Linguistics562Neural Maximum Subgraph Parsing for Cross - Domain Semantic Dependency Analysis Yufei Chen\u007f , Sheng Huang\u007f , Fang Wang\u007f , Weiwei Sun\u007f~and Xiaojun Wan\u007f \u007fInstitute of Computer Science and Technology , Peking University \u007fThe MOE Key Laboratory of Computational Linguistics , Peking University ~Center for Chinese Linguistics , Peking University fyufei.chen , huangsheng , foundwang , ws , wanxiaojun g@pku.edu.cn Abstract", "entities": []}, {"text": "We present experiments for cross - domain semantic dependency analysis with a neural Maximum Subgraph parser .", "entities": []}, {"text": "Our parser targets 1 - endpoint - crossing , pagenumber-2 graphs which are a good \ufb01t to semantic dependency graphs , and utilizes an ef\ufb01cient dynamic programming algorithm for decoding .", "entities": []}, {"text": "For disambiguation , the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies .", "entities": [[8, 9, "MethodName", "BiLSTM"]]}, {"text": "We conduct experiments on the data sets from SemEval 2015 as well as Chinese CCGBank .", "entities": [[14, 15, "DatasetName", "CCGBank"]]}, {"text": "Our parser achieves very competitive results for both English and Chinese .", "entities": []}, {"text": "To improve the parsing performance on cross - domain texts , we propose a data - oriented method to explore the linguistic generality encoded in English Resource Grammar , which is a precisionoriented , hand - crafted HPSG grammar , in an implicit way .", "entities": []}, {"text": "Experiments demonstrate the effectiveness of our data - oriented method across a wide range of conditions .", "entities": []}, {"text": "1 Introduction Semantic Dependency Parsing ( SDP ) is de\ufb01ned as the task of recovering sentence - internal bilexical semantic dependency structures , which encode predicate \u2013 argument relationships for all content words .", "entities": [[3, 5, "TaskName", "Dependency Parsing"]]}, {"text": "Such sentence - level semantic analysis of text is concerned with the characterization of events and is therefore important to understand the essential meaning of a natural language sentence .", "entities": []}, {"text": "With the advent of many supporting resources , SDP has become a well - de\ufb01ned task with a substantial body of work and comparative evaluation .", "entities": []}, {"text": "( Almeida and Martins , 2015 ; Du et al . , 2015a ; Zhang et al . , 2016 ; Peng et al . , 2017 ; Wang et al . , 2018 ) .", "entities": []}, {"text": "Two SDP shared tasks have been run as part of the 2014 and 2015 International Workshops on Semantic Evaluation ( SemEval ) ( Oepen et al . , 2014 , 2015).There are two key dimensions of the data - driven dependency parsing approach : decoding and disambiguation .", "entities": [[40, 42, "TaskName", "dependency parsing"]]}, {"text": "Existing decoding approaches to syntactic or semantic analysis into bilexical dependencies can be categorized into two dominant types : transition - based ( Zhang et al . , 2016 ;", "entities": []}, {"text": "Wang et al . , 2018 ) and graph - based , i.e. , Maximum Subgraph ( Kuhlmann and Jonsson , 2015 ; Cao et al . , 2017a ) approaches .", "entities": []}, {"text": "For disambiguation , while early work on dependency parsing focused on global linear models , e.g. , structured perceptron ( Collins , 2002 ) , recent work shows that deep learning techniques , e.g. , LSTM ( Hochreiter and Schmidhuber , 1997 ) , is able to significantly advance the state - of - the - art of the parsing accuracy .", "entities": [[7, 9, "TaskName", "dependency parsing"], [35, 36, "MethodName", "LSTM"], [60, 61, "MetricName", "accuracy"]]}, {"text": "From the above two perspectives , i.e. , the decoding and disambiguation frameworks , we \ufb01nd that what is still underexploited is neural Maximum Subgraph parsing for highly constrained graph classes , e.g. , noncrossing graphs .", "entities": []}, {"text": "In this paper , we \ufb01ll this gap in the literature by developing a neural Maximum Subgraph parser .", "entities": []}, {"text": "Previous work showed that the 1 - endpointcrossing , pagenumber-2 ( 1 EC / P2 ) graphs are an appropriate graph class for modeling semantic dependency structures ( Cao et al . , 2017a ) .", "entities": [[12, 13, "DatasetName", "EC"]]}, {"text": "In this paper , we build a parser that targets 1 EC / P2 graphs .", "entities": [[11, 12, "DatasetName", "EC"]]}, {"text": "Based on an ef\ufb01cient \ufb01rst - order Maximum Subgraph decoder , we implement a data - driven parser that scores arcs based on stacked bidirectionalLSTM ( BiLSTM ) together with a multi - layer perceptron .", "entities": [[26, 27, "MethodName", "BiLSTM"]]}, {"text": "Using the benchmark data sets from the SemEval 2015 Task 18 ( Oepen et al . , 2015 ) , our parser gives very competitive results for English semantic parsing .", "entities": [[1, 3, "DatasetName", "the benchmark"], [28, 30, "TaskName", "semantic parsing"]]}, {"text": "To test the ability for crosslingual parsing , we also conduct experiments on the Chinese CCGBank ( Tse and Curran , 2010 ) and Enju HPSGBank ( Yu et al . , 2010 ) data .", "entities": [[15, 16, "DatasetName", "CCGBank"]]}, {"text": "Our parser plays equally well for Chinese , resulting in an error reduction of 23.5 % and 9.4 % over the best", "entities": []}, {"text": "563published result reported in Zhang et al .", "entities": []}, {"text": "( 2016 ) and Du et al .", "entities": []}, {"text": "( 2015b ) .", "entities": []}, {"text": "Most studies on semantic parsing focused on the in - domain setting , meaning that both training and testing data are drawn from the same domain .", "entities": [[3, 5, "TaskName", "semantic parsing"]]}, {"text": "Even a data - driven parsing system achieves a high in - domain accuracy , it usually performs rather poorly on the out - of - domain data ( Oepen et al . , 2015 ) .", "entities": [[13, 14, "MetricName", "accuracy"]]}, {"text": "How to build robust semantic dependency parsers that can learn across domains remains an under - addressed problem .", "entities": []}, {"text": "To improve the cross - domain parsing performance , we propose a data - oriented model to explore the linguistic generality encoded in a hand - crafted , domainindependent , linguistically - precise English grammar , namely English Resource Grammar ( ERG ; Flickinger , 2000 ) .", "entities": []}, {"text": "In particular , we introduce a cost - sensitive training model to learn crossdomain semantic information implicitly encoded in WikiWoods ( Flickinger et", "entities": []}, {"text": "al . , 2010 ) , i.e. , a corpus that collects the wikipedia1texts as well as their automatic syntactico - semantic annotations produced by ERG .", "entities": []}, {"text": "Evaluation demonstrates the usefulness of the imperfect annotations automatically created by ERG .", "entities": []}, {"text": "Our parser is available at https://github . com / draplater / msg - parser .", "entities": []}, {"text": "2 Semantic Dependency Parsing 2.1 Semantic Dependency Analysis SDP is the task of mapping a natural language sentence into a formal meaning representation in the form of a dependency graph .", "entities": [[2, 4, "TaskName", "Dependency Parsing"]]}, {"text": "Figure 1 shows an Minimal Recursion Semantics ( MRS ; Copestake et al . , 2005 ) reduced semantic dependency analysis ( Ivanova et al . , 2012 ) .", "entities": [[8, 9, "DatasetName", "MRS"]]}, {"text": "In this example , the semantic analysis is represented as a labeled directed graph in which the vertices are tokens in the sentence .", "entities": []}, {"text": "The graph abstracts away from syntactic analysis ( e.g. , the complementizer \u2014 that \u2014 and passive construction are excluded ) and includes most semantically relevant non - anaphoric local ( e.g. , from \u201c wants \u201d to \u201c Mark \u201d ) and longdistance ( e.g. , from \u201c buy \u201d to \u201c company \u201d ) dependencies .", "entities": []}, {"text": "The arc labels encode linguisticallymotivated , broadly - applicable semantic relations that are grounded under the type - driven semantics .", "entities": []}, {"text": "It is worth noting that semantic dependency graphs are not necessarily trees : ( 1 ) a token may be multiply headed because a word can be the arguments 1https://www.wikipedia.orgThe company that Mark wants tobuy isbrokenBVARG2 ARG1ARG1ARG2 topARG2 Figure 1 : A fragment of a semantic dependency graph .", "entities": []}, {"text": "of more than one predicate ; ( 2 ) cycles are allowed if the direction of arcs are not taken into account .", "entities": []}, {"text": "2.2 Previous Work Some recent work on parsing targets the graphstructured semantic representations that are more general than the tree representation .", "entities": []}, {"text": "Existing approaches can be categorized into two dominant types : the transition - based ( Zhang et al . , 2016 ; Wang et al . , 2018 ) and graph - based , i.e. , Maximum Subgraph ( Kuhlmann and Jonsson , 2015 ; Cao et al . , 2017a ) , approaches .", "entities": []}, {"text": "Previous investigations on transition - based string - to - semantic - graph parsing adopt many ideas from syntactic string - totree parsing , such as how to handle crossing arcs and how to perform neural disambiguation .", "entities": []}, {"text": "Zhang et al .", "entities": []}, {"text": "( 2016 ) introduced two transition systems that can generate arbitrary graphs and augmented them into practical semantic dependency parsers with a structured perceptron model .", "entities": []}, {"text": "Wang et al .", "entities": []}, {"text": "( 2018 ) evaluated the effectiveness of deep learning techniques for transition - based SDP .", "entities": []}, {"text": "Kuhlmann and Jonsson ( 2015 ) proposed to formulate SDP as the search for the maximum subgraphs for some particular graph classes .", "entities": []}, {"text": "This proposal is called Maximum Subgraph parsing , which is a generalization of the graph - based parsing framework for syntactic parsing .", "entities": []}, {"text": "For arbitrary graphs , Du et al .", "entities": []}, {"text": "( 2015a ) proved that the secondorder Maximum Subgraph problem is an NPhard problem .", "entities": []}, {"text": "Nevertheless , Almeida and Martins ( 2015 ) and Du et al . ( 2015a ) showed that dual decomposition is a practical technique to solve the problem .", "entities": []}, {"text": "Considering more restricted graph classes , Kuhlmann and Jonsson ( 2015 ) introduced a dynamic programming algorithem for parsing to noncrossing graphs .", "entities": []}, {"text": "Cao et al .", "entities": []}, {"text": "( 2017a ; 2017b ) showed that 1 EC / P2 graphs are more suitable for describing semantic graphs than the noncrossing graphs , and they also allow low - degree dynamic programming algorithms for decoding .", "entities": [[8, 9, "DatasetName", "EC"]]}, {"text": "5643 A Neural Maximum Subgraph Parser 3.1 Maximum Subgraph Parsing Usually , syntactic dependency analysis employs thetree - shaped representation .", "entities": []}, {"text": "Dependency parsing , thus , can be formulated as the search for a maximum spanning tree ( MST ) from an arcweighted ( complete ) graph .", "entities": [[0, 2, "TaskName", "Dependency parsing"]]}, {"text": "For SDP where the target representation are no longer trees , Kuhlmann and Jonsson ( 2015 ) proposed to generalize the MST model to other types of subgraphs .", "entities": []}, {"text": "In general , dependency parsing is formulated as the search for Maximum Subgraph regarding to a particular graph class , viz .", "entities": [[3, 5, "TaskName", "dependency parsing"]]}, {"text": "G : Given a graph G= ( V ; A ) , \ufb01nd a subset A0\u0012Awith maximum total weight such that the induced subgraph G0= ( V ; A0)belongs toG.", "entities": []}, {"text": "Formally , we have the following optimization problem : G0(s ) = arg max H2G(s;G)SCORE ( H ) = arg max H2G(s;G)X pinHSCORE PART(s ; p ) ( 1 ) Here , G(s ; G)is the set of all graphs that belong toGand are compatible with sandG. For parsing , Gis usually a complete graph .", "entities": []}, {"text": "S CORE PART(s ; p ) evaluates whether a small subgraph pof a candidate graph His a good partial analysis for sentence s.", "entities": []}, {"text": "For some graph classes and some types of score functions , there exists ef\ufb01cient algorithms for solving ( 1 ) .", "entities": []}, {"text": "For example , when Gis the set of noncrossing graphs and S CORE PART is limited to handle individual dependencies , ( 1 ) can be solved in cubic - time ( Kuhlmann and Jonsson , 2015 ) .", "entities": []}, {"text": "3.2 Parsing to 1 EC / P2 Graphs Previous work showed that the Maximum Subgraph framework is not only elegant in theory but also effective in practice ( Kuhlmann and Jonsson , 2015 ; Cao et al . , 2017a , b ) .", "entities": [[4, 5, "DatasetName", "EC"]]}, {"text": "In particular , 1EC / P2 graphs are an appropriate graph class for modeling semantic dependency structures ( Cao et al . , 2017a ) .", "entities": []}, {"text": "Figure 2 presents an example to illustrate the 1 - endpoint - crossing property , while Figure 3 shows a case for pagenumber-2 .", "entities": []}, {"text": "Below we present the formal description of the two properties that are adopted from Pitler et al .", "entities": []}, {"text": "( 2013 ) and Kuhlmann and Jonsson ( 2015 ) respectively.a b c d e Figure 2 :( a ; c ) \u2019s crossing edges ( b ; d)and ( b ; e)share an endpoint b. a b c d e fPage 1 Page 2 Figure 3 : A pagenumber-2 graph .", "entities": []}, {"text": "The upper and the lower \ufb01gures represent two half - planes respectively .", "entities": []}, {"text": "De\ufb01nition 1", "entities": []}, {"text": "A dependency graph is 1 - EndpointCrossing if for any edge e , all edges that cross e share an endpoint pnamed pencil point .", "entities": []}, {"text": "De\ufb01nition 2", "entities": []}, {"text": "A pagenumber- kgraph means it consists at most khalf - planes , and arcs on each half - plane are noncrossing .", "entities": []}, {"text": "IfGis the set of 1 - endpoint - crossing graphs or more restricted 1 EC / P2 graphs , the optimization problem ( 1 ) in the \ufb01rst - order case can be solved in quintic - time ( Cao et al . , 2017a ) by using dynamic programming .", "entities": [[14, 15, "DatasetName", "EC"]]}, {"text": "Furthermore , ignoring one linguistically - rare structure in 1 EC / P2 graphs descreases the complexity to O(n4)(Cao et al . , 2017a ) .", "entities": [[10, 11, "DatasetName", "EC"]]}, {"text": "In this paper , we implement Cao et", "entities": []}, {"text": "al .", "entities": []}, {"text": "Cao et al .", "entities": []}, {"text": "( 2017a ) \u2019s algorithm as the basis of our parser .", "entities": []}, {"text": "3.3 Disambiguation with an LSTM 3.3.1 The Architecture", "entities": [[4, 5, "MethodName", "LSTM"]]}, {"text": "A semantic graph mainly consists of two parts : the structural part and the label part .", "entities": []}, {"text": "The former describes the predicate \u2013 argument relation in the sentence , and the latter describes the type of this relation .", "entities": []}, {"text": "In our model , the structural part and the label part are regarded as independent of each other .", "entities": []}, {"text": "We use a coarse - to-\ufb01ne strategy : \ufb01nding the maximum unlabeled subgraph \ufb01rst and assigning a label for every edge in this subgraph then .", "entities": []}, {"text": "The motivation is to avoid the calculation of a number of unnecessary label scores in order to improve the processing ef\ufb01ciency .", "entities": []}, {"text": "Following Kiperwasser and Goldberg ( 2016 ) \u2019s successful experience on syntactic tree parsing and Peng et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2017 ) \u2019s experience on semantic graph parsing , we employ a stacked bidirectional - LSTM ( BiLSTM ) based model to assign scores .", "entities": [[16, 17, "MethodName", "LSTM"], [18, 19, "MethodName", "BiLSTM"]]}, {"text": "In our system , the BiLSTM vectors associated with the input words are utilized to calculate scores for the", "entities": [[5, 6, "MethodName", "BiLSTM"]]}, {"text": "565 ...", "entities": []}, {"text": "LSTM LSTM LSTM", "entities": [[0, 1, "MethodName", "LSTM"], [1, 2, "MethodName", "LSTM"], [2, 3, "MethodName", "LSTM"]]}, {"text": "He        PRP wants   VBZ go      VB ...", "entities": []}, {"text": "Figure 4 : The architecture of the network when processing He wants to go .", "entities": []}, {"text": "The upper - left nonlinear transform is used for edge scoring while the upper right one is used for label scoring .", "entities": []}, {"text": "candidate dependencies as well as their relation types .", "entities": []}, {"text": "Figure 4 shows the architecture of our system .", "entities": []}, {"text": "3.3.2 Dense Representations We use words as well as POS tags as clues for scoring an individual arc .", "entities": []}, {"text": "In particular , we transform all of them into continuous and dense vectors .", "entities": []}, {"text": "Inspired by Costa - juss ` a and Fonollosa ( 2016 ) \u2019s work , we utilize character - based embedding for low - frequency words , i.e. , words that appear more than ktimes in the training data , and word - based embeddings for other words .", "entities": [[0, 1, "DatasetName", "Inspired"]]}, {"text": "The word - based embedding module applies the common lookup - table mechanism , while the character - based word embedding wiis implemented by extracting the features ( denoted as c1;c2 ; : : : ; cn ) within a character - based BiLSTM : x1 : xn= BiLSTM ( c1 : cn ) wi = x1+xn 3.3.3 Lexical Feature Extractor The concatenation of word embedding wiand POS - tag embedding piof each word in speci\ufb01c sentence is used as the input of BiLSTMs to extract context - related feature vectors rifor each position i. ai = wi\bpi r1 : rn= BiLSTM ( a1 : an)3.3.4 Factorized Scoring In our \ufb01rst order model , the S CORE function evaluates the preference of a semantic dependency graph by considering every bilexical relation in this graph one by one .", "entities": [[43, 44, "MethodName", "BiLSTM"], [48, 49, "MethodName", "BiLSTM"], [101, 102, "MethodName", "BiLSTM"]]}, {"text": "In particular , the corresponding S CORE PART function assigns a score to a candidate arc between word iand word jusing a non - linear transform from the two feature vectors , viz.riandrj , associated to the two words : SCORE PART(i ; j ) = W2\u0001ReLU ( W1;1\u0001ri+W1;2\u0001rj+b ) The assignment task for dependency labels can be regarded as a classi\ufb01cation task .", "entities": []}, {"text": "Our label scoring process is similar to the prediction of dependencies : LABEL ( i ; j ) = arg max W2\u0001ReLU ( W1;1\u0001ri+W1;2\u0001rj+b ) + b2 We can see here the two local score functions explicitly utilize the positions of a semantic head and a semantic dependent .", "entities": []}, {"text": "It is similar to the \ufb01rstorder factorization as de\ufb01ned in a number of linear parsing models , e.g. , the models de\ufb01ned by Martins and Almeida ( 2014 ) and Cao et al . ( 2017a ) .", "entities": []}, {"text": "3.3.5 Training In order to update graphs which achieve high model scores but are actually wrong , we use a margin - based approach to compute loss from the gold graph G\u0003and the best prediction ^Gunder current model .", "entities": [[26, 27, "MetricName", "loss"]]}, {"text": "We de\ufb01ne the lossterm as : max(0 ; \u0001(G\u0003;^G)\u0000SCORE ( G\u0003 ) + SCORE ( ^G ) )", "entities": []}, {"text": "The margin objective \u0001measures the similarity between the gold graph G\u0003and the prediction ^G.", "entities": []}, {"text": "Follow Peng", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2017 ) \u2019s approach , we de\ufb01ne\u0001as weighted Hamming to trade off between precision and recall .", "entities": []}, {"text": "4 Cross - Domain Parsing with a Precision Grammar and a Data - Oriented Model 4.1 Precision Grammar - Guided Parsing Semantic dependency graphs like Minimal Recursion Semantics ( MRS ) reduced analysis ( dubbed DM ) and Head - driven Phrase Structure Grammar ( HPSG ) grounded predicate \u2013 argument analysis ( dubbed PAS ) are derived from the linguistic analysis licensed by a deep linguistic grammar .", "entities": [[7, 8, "MetricName", "Precision"], [16, 17, "MetricName", "Precision"], [29, 30, "DatasetName", "MRS"]]}, {"text": "566They are parallel with the deep syntactic analysis , and the semantic construction process of them is strictly compositional .", "entities": []}, {"text": "Another type of domainindependent , sentence - level semantic annotations are based on annotators \u2019 re\ufb02ection of the meanings of particular natural language sentences .", "entities": []}, {"text": "No syntactic constraints on linguistic signals are introduced explicitly introduced .", "entities": []}, {"text": "A representative example is Abstract Meaning Representation ( AMR ; Banarescu et al . , 2013 ) .", "entities": []}, {"text": "Different from data - driven syntactic parsing , semantic parsing for the \ufb01rst type of annotation can leverage a precision grammar - guided model .", "entities": [[8, 10, "TaskName", "semantic parsing"]]}, {"text": "Such a model applies a rich set of precise linguistic rules to constrain their search for a preferable syntactic or semantic analysis .", "entities": []}, {"text": "In recent years , several of these linguistically motivated parsing systems achieved high performances that are comparable or even superior to the treebank - based purely data - driven parsers .", "entities": []}, {"text": "For example , using ERG ( Flickinger , 2000 ) , which provides precise linguistic analyses for a broad range of phenomena , as the the core engine , PET2(Callmeier , 2000 ) and ACE3produce better results than all existing datadriven semantic parsers for sentences that can be parsed by ERG .", "entities": []}, {"text": "The main weakness of the precision grammarguided parsers is their robustness with respect to both coverage and ef\ufb01ciency .", "entities": []}, {"text": "Even for treebanking on the newswire data , i.e. , the Wall Street Journal data from Penn TreeBank , ERG lacks analyses for c.a . 11 % sentences ( Oepen et al . , 2015 ) .", "entities": [[16, 18, "DatasetName", "Penn TreeBank"]]}, {"text": "For the texts from the web , e.g. , tweets , this problem is much more serious .", "entities": []}, {"text": "Moreover , checking all linguistic constraints makes a grammar - guided parser too slow for many realistic NLP applications .", "entities": []}, {"text": "On the contrary , light - weight , data - driven parsers usually have complementary strengthes in terms of both coverage and ef\ufb01ciency .", "entities": []}, {"text": "4.2", "entities": []}, {"text": "The Parser - Oriented Model Intuitively , a hand - crafted precision grammar , e.g. , ERG , re\ufb02ects highly generalized properties of a particular language and is thus highly resilient to domain shifts .", "entities": []}, {"text": "Accordingly , one should expect that a precision grammar - guided parser which guarantees the a rich set of domain - independent linguistic constraints to be met can be more robust to domain shifts than a purely data - driven parser .", "entities": []}, {"text": "2http://pet.opendfki.de/ 3http://sweaglesw.org/linguistics/ace/In related work for syntactic parsing , Ivanova et al .", "entities": []}, {"text": "( 2013 ) showed that the ERG - based parser was more robust to domain variation than several representative data - driven parsers .", "entities": []}, {"text": "Zhang and Wang ( 2009 ) proposed to derive features from syntactic parses generated by PET to assist a data - driven dependency tree parser and observed some encouraging results for cross - domain evaluation .", "entities": [[15, 16, "DatasetName", "PET"]]}, {"text": "However , there are at least two drawbacks of their ERG - guided parser based method :", "entities": []}, {"text": "1 .", "entities": []}, {"text": "A considerable number of sentences can not bene\ufb01t from ERG since PET may produce no analysis .", "entities": [[11, 12, "DatasetName", "PET"]]}, {"text": "2 . This method fails to take parsing ef\ufb01ciency into account .", "entities": []}, {"text": "4.3 Our Data - Oriented Model", "entities": []}, {"text": "In this paper , we introduce a new data - oriented strategy to consume a precision grammar .", "entities": []}, {"text": "The key idea is to take a grammar as an imperfect annotator : We let a precision grammar - guided parser parse large - scale raw texts in an of\ufb02ine way , and then utilize the automatically generated analysis as imperfect training data .", "entities": []}, {"text": "Because we only need raw texts to be parsed once , even if this process takes much time , it is still reasonable .", "entities": []}, {"text": "A grammarguided parser can not parse a considerable portion of data , but this will not cause serious problems because we can take an enormous amount of sentences as annotation candidates .", "entities": []}, {"text": "Just considering the wikipedia , we can collect at least dozens of millions of comparatively high - quality sentences .", "entities": []}, {"text": "An essential problem of this method is that such imperfect annotations bring in annotation errors which may hurt parser training .", "entities": []}, {"text": "To deal with this problem , we adopted a cost - sensitive training method to train our model on the extended training data .", "entities": []}, {"text": "In each epoch , we trained on imperfect corpus \ufb01rst", "entities": []}, {"text": "and then on gold - standard corpus .", "entities": []}, {"text": "When processing an imperfect sentence , we do not take a loss into consideration if the loss of this sentence is too small .", "entities": [[11, 12, "MetricName", "loss"], [16, 17, "MetricName", "loss"]]}, {"text": "In particular , if a loss of a bilexical relation between two tokens is less than 0.05 , we would exclude the loss .", "entities": [[5, 6, "MetricName", "loss"], [22, 23, "MetricName", "loss"]]}, {"text": "As for label assigning , we exclude losses less than 0.5 .", "entities": []}, {"text": "These threshold numbers are tuned on the development data .", "entities": []}, {"text": "567System DM PAS PSD LP LR LF LP LR LF LP", "entities": []}, {"text": "LR LFIN - DOMAINDu et", "entities": []}, {"text": "al . ensemble 90.93 87.32 89.09 92.90 89.67 91.26 78.60 72.93 75.66 Almeida and Martins single 89.84 86.64 88.21 91.87 89.92 90.88 78.62 74.23 76.36 Peng et", "entities": []}, {"text": "al . single - - - - 89.4 - - - - 92.2 - - - - 77.6 Peng et al .", "entities": []}, {"text": "multitask - - - - 90.4 - - - - 92.7 - - - - 78.5 Wang et", "entities": []}, {"text": "al . single - - - - 89.3 - - - - 91.4 - - - - 76.1 Wang et al . ensemble - - - - 90.3 - - - - 91.7 - - - - 78.6 Ours single 90.74 90.40 90.57 92.26 92.43 92.35 76.42 76.33 76.38 Ours ( E[3 ] ) ensemble 92.17 91.35 91.76 93.50 92.98 93.24 78.83 77.07 77.95 Ours ( [ E10 ] ) ensemble 92.81 91.65 92.23 93.91 93.22 93.56 79.33 78.00 78.66OUT - OF - DOMAINDu et al . ensemble 84.29 79.53 81.84 89.47 85.10 87.23 77.36 69.61 73.28 Almeida and Martins single 84.81 78.90 81.75 88.52 85.30 86.88 78.68 71.31 74.82", "entities": []}, {"text": "Peng et al . single - - - - 84.5 - - - - 88.3 - - - - 75.3 Peng et", "entities": []}, {"text": "al .", "entities": []}, {"text": "multitask - - - - 85.3 - - - - 89.0 - - - - 76.4 Wang et", "entities": []}, {"text": "al . single - - - - 83.2 - - - - 87.2 - - - - 73.2 Wang et al .", "entities": []}, {"text": "ensemble - - - - 84.9 - - - - 87.6 - - - - 75.9 Ours single 85.70 85.02 85.37 89.11 88.85 88.98 73.54 73.19 73.36 Ours ( E[3 ] ) ensemble 87.65 86.24 86.94 90.72 89.31 90.01 76.10 73.83 74.95 Ours ( E[10 ] ) ensemble 88.13 86.37 87.24 91.19 89.50 90.34 76.75 74.48 75.60 Table 1 : Labeled F1on the test data from SemEval 2015 .", "entities": []}, {"text": "Hyper - parameter Val Randomly - initialized word embedding dimension 100 Pre - trained word embedding dimension 100 Randomly - initialized character embedding dimension 100 Character LSTM layers for each direction 2 Randomly - initialized POS - Tag embedding dimension 50 POS - Tag", "entities": [[7, 10, "HyperparameterName", "word embedding dimension"], [14, 17, "HyperparameterName", "word embedding dimension"], [22, 24, "HyperparameterName", "embedding dimension"], [26, 27, "MethodName", "LSTM"], [38, 40, "HyperparameterName", "embedding dimension"]]}, {"text": "dropout 0.5 Batch size 32 BiLSTM dimension for each direction 150 BiLSTM layers 5 MLP hidden layers 1 MLP hidden layer dimension 100 Table 2 : Hyper - parameter setting of our model .", "entities": [[2, 4, "HyperparameterName", "Batch size"], [5, 6, "MethodName", "BiLSTM"], [11, 12, "MethodName", "BiLSTM"], [14, 15, "DatasetName", "MLP"], [18, 19, "DatasetName", "MLP"]]}, {"text": "5 Experiments 5.1 Set - up for the Baseline System To evaluate neural Maximum Subgraph parsing in practice , we \ufb01rst conduct experiments on the three English data sets , namely DM , PAS andPSD4 , which are from the SemEval 2015 Task18 ( Oepen et al . , 2015 ) .", "entities": []}, {"text": "We use the \u201c standard \u201d training , validation , and test splits to facilitate comparisons .", "entities": []}, {"text": "In other words , the data splitting policy follows the shared task .", "entities": []}, {"text": "In addition to English parsing , we consider Chinese SDP and use two data sets : ( 1 ) Chinese PAS data provided by SemEval 2015 , and ( 2 ) Chinese CCGBank ( Tse and Curran , 2010 ) to evaluate the cross - lingual ability of our model .", "entities": [[32, 33, "DatasetName", "CCGBank"]]}, {"text": "All the SemEval data sets are publicly available from 4DM , PAS andPSD are short for DeepBank , Enju HPSGBank and Prague Dependency Treebank .", "entities": []}, {"text": "LDC ( Oepen et al . , 2016 ) .", "entities": []}, {"text": "We use DyNet5to implement our neural models .", "entities": []}, {"text": "We use the automatic batch technique ( Neubig et al . , 2017 ) in DyNet to perform mini - batch gradient descent training .", "entities": []}, {"text": "The batch size is 32 .", "entities": [[1, 3, "HyperparameterName", "batch size"]]}, {"text": "The detailed network hyper - parameters are summarized in Table 2 .", "entities": []}, {"text": "We use the same pre - trained word embedding as Kiperwasser and Goldberg ( 2016 ) .", "entities": []}, {"text": "5.2 Main Results of English Parsing Table 1 lists the parsing accuracy of our system as well as the best published results in the literature for comparison .", "entities": [[11, 12, "MetricName", "accuracy"]]}, {"text": "Results from other papers are of different yet representative decoding or disambiguation frameworks .", "entities": []}, {"text": "Du et al . ( 2015a ) \u2019s and Almeida and Martins ( 2015 ) \u2019s parsers use global linear models to perform disambiguation .", "entities": []}, {"text": "These systems obtained the best parsing accuracy for the SemEval 2015 shared task .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "Peng et al .", "entities": []}, {"text": "( 2017 ) \u2019s and", "entities": []}, {"text": "Wang et al .", "entities": []}, {"text": "( 2018 ) \u2019s parsers utilize neural models , LSTMs in particular , to score either arcs or transitions .", "entities": []}, {"text": "Our single models get the highest scores on not only in - domain but also out - ofdomain test sets for the DM andPAS data sets , and they obtain comparable results with the stateof - art parser on the PSD data set .", "entities": []}, {"text": "Comparing our results to the results obtained by parsers based on linear models , we can see the effectiveness of the BiLSTM based disambiguation model .", "entities": [[21, 22, "MethodName", "BiLSTM"]]}, {"text": "The preci5https://github.com/clab/dynet", "entities": []}, {"text": "568   78 80 82 84 86 88 90 92 94 DM PAS PSDLabeled F - scoreBaseline Vote(3 ) Vote(10 ) Average(3 ) Average(10)Figure 5 : Labeled F1relative to different ensemble methods .", "entities": []}, {"text": "Results are obtained on the development data .", "entities": []}, {"text": "sion of the two linear model - based parsers is comparable or even superior to our neural parser , but the recall is far behind .", "entities": []}, {"text": "5.3 Model Ensemble Ensemble methods have been shown very helpful to boost the accuracy of neural network based parsing .", "entities": [[13, 14, "MetricName", "accuracy"]]}, {"text": "We evaluate two ensemble methods , voting and score averaging .", "entities": []}, {"text": "In the voting method , each model parses the sentence to graph respectively .", "entities": []}, {"text": "An edge will exist on the combined graph only if more than half output graphs of these models contain this edge .", "entities": []}, {"text": "The label of this edge will be the most common label .", "entities": []}, {"text": "In the score averaging method , we use averaged score parts to get a maximum graph and classify labels .", "entities": []}, {"text": "We choose 3/10 kind of different initial parameters to train models for ensemble .", "entities": []}, {"text": "Figure 5 shows the result of the two ensemble methods .", "entities": []}, {"text": "The averaging method has slightly better performance on the 3 datasets .", "entities": []}, {"text": "The performance of this method on test data is shown on Table 1 . 5.4 Data for Cross - Domain Experiments Since around 2001 , the ERG has been accompanied by syntactico - semantic annotations , where for each sentence an annotator has selected the intended analysis among all alternatives licensed by the grammar .", "entities": []}, {"text": "This derived resource , namly Redwoods6(Oepen et al . , 2002 ;", "entities": []}, {"text": "Flickinger et al . , 2017 ) , is a collection of hand - annotated corpora and consists of data sets from several distinct domains .", "entities": []}, {"text": "Redwoods also includes ( re)treebanking results of the \ufb01rst 22 sections of the venerable Wall Street Journal ( WSJ ) text and the section of Brown Corpus in the Penn Treebank ( Marcus et al . , 1993 ) .", "entities": [[29, 31, "DatasetName", "Penn Treebank"]]}, {"text": "The WSJ part is also known as Deep6http://moin.delph-in.net/RedwoodsTopBank ( Flickinger et al . , 2012 ) .", "entities": []}, {"text": "The Brown corpus part is used as the out - of - domain test data by SemEval 2015 .", "entities": []}, {"text": "The DMdata sets for both SemEval 2014 and 2015 SDP shared tasks are based on the RedWoods corpus .", "entities": []}, {"text": "Besides gold standard annoations , Flickinger et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2010 ) built the WikiWoods corpus7 , which provides automatically created annotations for the texts from wikipedia .", "entities": []}, {"text": "The annotations are disambiguated using the MaxEnt model trained using redwoods without DeepBank .", "entities": []}, {"text": "We use a small portion of Wikiwoods , which contains 857,329 sentences in total .", "entities": []}, {"text": "To evaluate the ( positive ) impact of ERG on out - of - domain parsing , we conduct experiments on the DM data .", "entities": []}, {"text": "The \ufb01rst group of experiments are designed to be comparable with the results obtained by various participant systems of SemEval 2015 .", "entities": []}, {"text": "The detailed data set - up is as follows : \u000fTest Data .", "entities": []}, {"text": "We use the Brown corpus section which is provided by SemEval 2015 .", "entities": []}, {"text": "\u000fTraining Data .", "entities": []}, {"text": "We use three data sets for training : ( 1 ) DeepBank , ( 2 ) RedWoods and ( 3 ) a small portion of WikiWoods reparsed using the MaxEnt model trained on DeepBank .", "entities": []}, {"text": "We denote this reparsed WikiWoods as WikiWoods - ACE , since the HPSG analysis is provided by the ACE parser .", "entities": []}, {"text": "To extract the semantic dependency graph , we use the pydelphin tool8 .", "entities": []}, {"text": "For the second group of experiments , we use the section wsj21 from the DeepBank as test data , which is the of\ufb01cial in - domain test of the SemEval 2015 .", "entities": []}, {"text": "The training data includes the \u201c RedWoods minus DeepBank \u201d annotations ( RedwoodsWOD for short ) as well as the of\ufb01cial WikiWoods annotations .", "entities": []}, {"text": "Note that the MaxEnt model used to obtain the of\ufb01cial WikiWoods annotations are compatible with RedwoodswWOD .", "entities": []}, {"text": "Due to the diversity of the RedwoodsWOD and DeepBank sentences , this set - up can also be viewed as an outof - domain evaluation .", "entities": []}, {"text": "5.5 Results of Cross - Domain Parsing Table 3 summarizes experimental results for different cross - domain evaluation set - ups .", "entities": []}, {"text": "For the 7http://moin.delph-in.net/WikiWoods 8https://github.com/delph-in/pydelphin", "entities": []}, {"text": "569Training Data LP LR LF IN - DOMAIN ( SEMEVAL )", "entities": []}, {"text": "DeepBank S 90.74 90.40 90.57 Redwoods S 91.50 90.57 91.03 DeepBank+WikiWoods - ACE S 91.93 90.72 91.32 DeepBank+WikiWoods - ACE E[3 ] 92.73 91.48 92.11 OUT - OF - DOMAIN ( SEMEVAL )", "entities": []}, {"text": "DeepBank S 85.70 85.02 85.37 Redwoods S 86.28 84.85 85.56 DeepBank+WikiWoods - ACE S 88.30 86.42 87.35 DeepBank+WikiWoods - ACE E[3 ] 89.53 87.57 88.54 OUT - OF - DOMAIN ( REDWOODS WOD )", "entities": []}, {"text": "DeepBank S 90.74 90.40 90.57 RedwoodsWOD S 81.40 78.99 80.18 RedwoodsWOD+WikiWoods S 84.05 79.86 81.90 RedwoodsWOD+WikiWoods E[3 ] 84.84 81.02 82.88 Table 3 : Labeled F1on the DMtest sets .", "entities": []}, {"text": "\u201c S \u201d denotes single model , while \u201c E[3 ] \u201d denotes ensemble model with 3 sub - models .", "entities": []}, {"text": "\ufb01rst group of experiments , we test the parser using different training data sets .", "entities": []}, {"text": "The baseline utilizes the WSJ portion only .", "entities": []}, {"text": "While more reliable training data is added , the performances increase consistently .", "entities": []}, {"text": "We notice that the improvement extending the training data from DeepBank to Redwoods is quite limited for the out - of - domain evaluation .", "entities": []}, {"text": "One reason is that the amount of enlarged gold standard annotations is still limited : The DeepBank training data contains 35,656 sentences ( 838,374 tokens , i.e. , roughly words ) , while the additional training data contains 35,950 sentences ( 538,659 tokens ) .", "entities": []}, {"text": "For comparison , we select 480,564 sentences ( 5,346,703 tokens ) from WikiWoods to train another model , and leave out other parts of Redwoods .", "entities": []}, {"text": "The performance improvement is more remarkable when providing more data , even though such data contains annotation errors .", "entities": []}, {"text": "For the second group of experiments , we use the RedwoodsWOD sentences for training and the DeepBank WSJ sentences for evaluation .", "entities": []}, {"text": "For this set - up , consistent improvements of the parser quality are observed .", "entities": []}, {"text": "5.6 Results of Chinese Parsing To test the ability for cross - lingual parsing , we conduct experiments on HPSG and CCG grounded semantic analyses respectively .", "entities": []}, {"text": "The HPSG grounded analysis is provided by SemEval 2015 and the underlying framework is the same to the English PAS data .", "entities": []}, {"text": "The CCG grounded analysis is from Chinese CCGBank .", "entities": [[7, 8, "DatasetName", "CCGBank"]]}, {"text": "We use the sameset - up as Zhang et al . ( 2016 ) .", "entities": []}, {"text": "Both data sets are transformed from Chinese TreeBank with two rich sets of heuristic rules ( Yu et al . , 2010 ; Tse and Curran , 2010 ) .", "entities": [[6, 8, "DatasetName", "Chinese TreeBank"]]}, {"text": "Table 4 and 5 presents all results .", "entities": []}, {"text": "Our parser signi\ufb01cantly outperforms Zhang et al .", "entities": []}, {"text": "( 2016 ) \u2019s", "entities": []}, {"text": "Zhang et al .", "entities": []}, {"text": "( 2016 ) system on Chinese CCGBank , which achieved best reported performance .", "entities": [[6, 7, "DatasetName", "CCGBank"]]}, {"text": "Chinese POS tagging has a great impact on parsing .", "entities": []}, {"text": "In this paper , we consider two POS taggers : a symbol - re\ufb01ned generative HMM tagger ( SR - HMM ) ( Huang et al . , 2009 ) and a BiLSTMCRF model when assisting Chinese SDG .", "entities": []}, {"text": "For the neural tagging model , in addition to a BiLSTM layer for encoding words , we set a BiLSTM layer for encoding characters , which supports us to derive character - level representations for all words .", "entities": [[10, 11, "MethodName", "BiLSTM"], [19, 20, "MethodName", "BiLSTM"]]}, {"text": "In particular , vectors from the characterlevel LSTM is concatenated with the pre - trained word embedding before feeding into the other word - level BiLSTM network to capture contextual information .", "entities": [[7, 8, "MethodName", "LSTM"], [25, 26, "MethodName", "BiLSTM"]]}, {"text": "The \ufb01nal module of our CRF tagger is a linear chain CRF which scores the output sequence by factoring it in local tag bi - grams .", "entities": [[5, 6, "MethodName", "CRF"], [11, 12, "MethodName", "CRF"]]}, {"text": "From Table 5 , we can see that POS information is very important to Chinese SDP .", "entities": []}, {"text": "This phenomenon is consist with Chinese syntactic parsing , including both constituency and dependency parsing .", "entities": [[13, 15, "TaskName", "dependency parsing"]]}, {"text": "Mandarin Chinese is recognized as a morphology - poor language : POS tags are de\ufb01ned mainly according to words \u2019 distributional rather than morphological properties .", "entities": []}, {"text": "The LSTM - based tagger can leverage", "entities": [[1, 2, "MethodName", "LSTM"]]}, {"text": "570Model LP LR LF Peking 84.75 82.15 83.43", "entities": []}, {"text": "Ours 85.49 84.11 84.79 Table 4 : Labeled F1on the test set of SemEval 2015 for Chinese .", "entities": []}, {"text": "\u201c Peking \u201d is the participant system that obtained the best parsing accuracy for Chinese in SemEval 2015 .", "entities": [[12, 13, "MetricName", "accuracy"]]}, {"text": "Model POS LP LR", "entities": []}, {"text": "LF ZDSW Gold 82.09 81.81 81.95 Ours Gold 86.37 86.00 86.19 SR - HMM 80.19 80.53 80.37 BiLSTM - CRF 81.13 81.74 81.43 Table 5 : Labeled F1on the test set of Chinese CCGBank .", "entities": [[17, 18, "MethodName", "BiLSTM"], [19, 20, "MethodName", "CRF"], [33, 34, "DatasetName", "CCGBank"]]}, {"text": "\u201c ZDSW \u201d is the system that obtained the best parsing accuracy on the Chinese CCGBank data in the literature .", "entities": [[11, 12, "MetricName", "accuracy"], [15, 16, "DatasetName", "CCGBank"]]}, {"text": "the power of the RNN architecture to learn nonlocal dependencies and thus bene\ufb01t our semantic dependency parser a lot .", "entities": []}, {"text": "6 Conclusion Parsing sentences to linguistically - rich semantic representations is a key goal of Natural Language Understanding .", "entities": [[15, 18, "TaskName", "Natural Language Understanding"]]}, {"text": "We introduce a new parser for semantic dependency analysis , which combines two promising parsing techniques , i.e. , decoding based on Maximum Subgraph algorithms and disambiguation based on BiLSTMs .", "entities": []}, {"text": "To our knowledge , this is the \ufb01rst neural Maximum Subgraph parser .", "entities": []}, {"text": "Our parser signi\ufb01cantly improves state - ofthe - art accuracy on three out of total four data sets from SemEval 2015 for English / Chinese parsing and the CCGBank data for Chinese parsing .", "entities": [[9, 10, "MetricName", "accuracy"], [28, 29, "DatasetName", "CCGBank"]]}, {"text": "We also propose a new data - oriented method to leverage ERG , a linguistically - motivated , hand - crafted grammar , to improve cross - domain performance .", "entities": []}, {"text": "Experiments demonstrate the effectiveness of taking ERG as an imperfect annotator .", "entities": []}, {"text": "We think this method can be re - used for other types of datadriven semantic parsing models .", "entities": [[14, 16, "TaskName", "semantic parsing"]]}, {"text": "Acknowledgement This work was supported by the National Natural Science Foundation of China ( 61772036 , 61331011 ) and the Key Laboratory of Science , Technology and Standard in Press Industry ( Key Laboratory of Intelligent Press Media Technology ) .", "entities": []}, {"text": "We thank the anonymous reviewers for their helpful comments .", "entities": []}, {"text": "Weiwei Sun is the corresponding author .", "entities": []}, {"text": "References C. Mariana S. Almeida and T. Andr \u00b4 e F. Martins . 2015 .", "entities": []}, {"text": "Lisbon : Evaluating TurboSemanticParser on Multiple Languages and Out - of - Domain Data .", "entities": []}, {"text": "Proceedings of SemEval 2015 .", "entities": []}, {"text": "Laura Banarescu , Claire Bonial , Shu Cai , Madalina Georgescu , Kira Grif\ufb01tt , Ulf Hermjakob , Kevin Knight , Philipp Koehn , Martha Palmer , and Nathan Schneider .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Abstract Meaning Representation for Sembanking .", "entities": []}, {"text": "In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse , pages 178\u2013186 , So\ufb01a , Bulgaria .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ulrich Callmeier .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "Pet .", "entities": []}, {"text": "a platform for experimentation with ef\ufb01cient hpsg processing techniques .", "entities": []}, {"text": "Journal of Natural Language Engineering , 6(1):99 \u2013 108 .", "entities": []}, {"text": "Junjie Cao , Sheng Huang , Weiwei Sun , and Xiaojun Wan . 2017a .", "entities": []}, {"text": "Parsing to 1 - endpoint - crossing , pagenumber-2 graphs .", "entities": []}, {"text": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 2110\u20132120 , Vancouver , Canada . Association for Computational Linguistics .", "entities": []}, {"text": "Junjie Cao , Sheng Huang , Weiwei Sun , and Xiaojun Wan . 2017b .", "entities": []}, {"text": "Quasi - second - order parsing for 1endpoint - crossing , pagenumber-2 graphs .", "entities": []}, {"text": "In Proceedings of EMNLP 2017 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Michael Collins .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "Discriminative training methods for hidden markov models : Theory and experiments with perceptron algorithms .", "entities": []}, {"text": "In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing , pages 1\u20138 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ann Copestake , Dan Flickinger , Carl Pollard , and Ivan A. Sag . 2005 .", "entities": [[12, 13, "MethodName", "Sag"]]}, {"text": "Minimal Recursion Semantics : An introduction .", "entities": []}, {"text": "Research on Language and Computation , pages 281\u2013332 .", "entities": []}, {"text": "Marta R. Costa - juss ` a and Jos \u00b4 e A. R. Fonollosa . 2016 .", "entities": []}, {"text": "Character - based neural machine translation .", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Papers ) , pages 357\u2013361 , Berlin , Germany .", "entities": []}, {"text": "Yantao Du , Weiwei Sun , and Xiaojun Wan . 2015a .", "entities": []}, {"text": "A data - driven , factorization parser for CCG dependency structures .", "entities": []}, {"text": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Volume 1 : Long Papers ) , pages 1545\u20131555 , Beijing , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yantao Du , Fan Zhang , Xun Zhang , Weiwei Sun , and Xiaojun Wan . 2015b .", "entities": []}, {"text": "Peking : Building semantic", "entities": []}, {"text": "571dependency graphs with a hybrid parser .", "entities": []}, {"text": "In Proceedings of the 9th International Workshop on Semantic Evaluation ( SemEval 2015 ) , pages 927\u2013931 , Denver , Colorado .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Dan Flickinger .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "On building a more ef\ufb01cient grammar by exploiting types .", "entities": []}, {"text": "Nat .", "entities": []}, {"text": "Lang .", "entities": []}, {"text": "Eng . , 6(1):15\u201328 .", "entities": []}, {"text": "Dan Flickinger , Stephan Oepen , and Emily M. Bender .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Sustainable Development and Re\ufb01nement of Complex Linguistic Annotations at Scale .", "entities": []}, {"text": "Springer Netherlands , Dordrecht .", "entities": []}, {"text": "Dan Flickinger , Stephan Oepen , and Gisle Ytrest\u00f8l .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Wikiwoods : Syntacto - semantic annotation for English wikipedia .", "entities": []}, {"text": "In Proceedings of the Seventh International Conference on Language Resources and Evaluation ( LREC\u201910 ) , Valletta , Malta .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "Daniel Flickinger , Yi Zhang , and Valia Kordoni .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Deepbank :", "entities": []}, {"text": "A dynamically annotated treebank of the wall street journal .", "entities": []}, {"text": "In Proceedings of the Eleventh International Workshop on Treebanks and Linguistic Theories , pages 85\u201396 .", "entities": []}, {"text": "Sepp Hochreiter and J \u00a8urgen Schmidhuber .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Long Short - Term Memory .", "entities": [[0, 5, "MethodName", "Long Short - Term Memory"]]}, {"text": "Neural Comput . , 9(8):1735 \u2013 1780 .", "entities": []}, {"text": "Zhongqiang Huang , Vladimir Eidelman , and Mary Harper . 2009 .", "entities": []}, {"text": "Improving a simple bigram hmm part - of - speech tagger by latent annotation and selftraining .", "entities": [[5, 8, "DatasetName", "part - of"]]}, {"text": "In Proceedings of Human Language Technologies : The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics , Companion Volume : Short Papers , pages 213\u2013216 , Boulder , Colorado .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Angelina Ivanova , Stephan Oepen , Rebecca Dridan , Dan Flickinger , and Lilja \u00d8vrelid .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "On different approaches to syntactic analysis into bi - lexical dependencies .", "entities": []}, {"text": "an empirical comparison of direct , PCFG - based , and HPSG - based parsers .", "entities": []}, {"text": "In Proceedings of The 13th International Conference on Parsing Technologies ( IWPT-2013 ) , pages 63\u201372 , Nara , Japan .", "entities": []}, {"text": "Angelina Ivanova , Stephan Oepen , Lilja \u00d8vrelid , and Dan Flickinger .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Who did what to whom ?", "entities": []}, {"text": "A contrastive study of syntacto - semantic dependencies .", "entities": []}, {"text": "In Proceedings of the Sixth Linguistic Annotation Workshop , pages 2\u201311 , Jeju , Republic of Korea .", "entities": []}, {"text": "Eliyahu Kiperwasser and Yoav Goldberg . 2016 .", "entities": []}, {"text": "Simple and accurate dependency parsing using bidirectional LSTM feature representations .", "entities": [[3, 5, "TaskName", "dependency parsing"], [6, 8, "MethodName", "bidirectional LSTM"]]}, {"text": "Transactions of the Association for Computational Linguistics , 4:313\u2013327 .", "entities": []}, {"text": "Marco Kuhlmann and Peter Jonsson . 2015 .", "entities": []}, {"text": "Parsing to noncrossing dependency graphs .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics , 3:559 \u2013 570.Mitchell P. Marcus , Mary Ann Marcinkiewicz , and Beatrice Santorini . 1993 .", "entities": []}, {"text": "Building a large annotated corpus of English : the penn treebank .", "entities": [[9, 11, "DatasetName", "penn treebank"]]}, {"text": "Computational Linguistics , 19(2):313\u2013330 .", "entities": []}, {"text": "Andr \u00b4 e F. T. Martins and Mariana S. C. Almeida .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Priberam : A turbo semantic parser with second order features .", "entities": []}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation ( SemEval 2014 ) , pages 471\u2013476 , Dublin , Ireland .", "entities": []}, {"text": "Association for Computational Linguistics and Dublin City University .", "entities": []}, {"text": "Graham Neubig , Yoav Goldberg , and Chris Dyer . 2017 .", "entities": []}, {"text": "On - the-\ufb02y operation batching in dynamic computation graphs .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems .", "entities": []}, {"text": "Stephan Oepen , Marco Kuhlmann , Yusuke Miyao , Daniel Zeman , Silvie Cinkov \u00b4 a , Dan Flickinger , Jan Haji \u02c7c , Angelina Ivanova , and Zde \u02c7nka Ure \u02c7sov\u00b4a .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Semantic Dependency Parsing ( SDP ) graph banks release 1.0 LDC2016T10 .", "entities": [[1, 3, "TaskName", "Dependency Parsing"]]}, {"text": "Web Download .", "entities": []}, {"text": "Stephan Oepen , Marco Kuhlmann , Yusuke Miyao , Daniel Zeman , Silvie Cinkov \u00b4 a , Dan Flickinger , Jan Hajic , and Zdenka Uresov \u00b4 a. 2015 .", "entities": []}, {"text": "Semeval 2015 task 18 : Broad - coverage semantic dependency parsing .", "entities": [[9, 11, "TaskName", "dependency parsing"]]}, {"text": "In Proceedings of the 9th International Workshop on Semantic Evaluation ( SemEval 2015 ) .", "entities": []}, {"text": "Stephan Oepen , Marco Kuhlmann , Yusuke Miyao , Daniel Zeman , Dan Flickinger , Jan Hajic , Angelina Ivanova , and Yi Zhang .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Semeval 2014 task 8 : Broad - coverage semantic dependency parsing .", "entities": [[9, 11, "TaskName", "dependency parsing"]]}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation ( SemEval 2014 ) , pages 63\u201372 , Dublin , Ireland .", "entities": []}, {"text": "Association for Computational Linguistics and Dublin City University .", "entities": []}, {"text": "Stephan Oepen , Kristina Toutanova , Stuart Shieber , Christopher Manning , Dan Flickinger , and Thorsten Brants .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "The lingo redwoods treebank motivation and preliminary applications .", "entities": []}, {"text": "In Proceedings of the 19th International Conference on Computational Linguistics - Volume 2 , COLING \u2019 02 , pages 1\u20135 , Stroudsburg , PA , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Hao Peng , Sam Thomson , and Noah A. Smith .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Deep multitask learning for semantic dependency parsing .", "entities": [[5, 7, "TaskName", "dependency parsing"]]}, {"text": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 2037\u20132048 , Vancouver , Canada . Association for Computational Linguistics .", "entities": []}, {"text": "Emily Pitler , Sampath Kannan , and Mitchell Marcus .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Finding optimal 1 - endpoint - crossing trees .", "entities": []}, {"text": "TACL , 1:13\u201324 .", "entities": []}, {"text": "Daniel Tse and James R. Curran . 2010 .", "entities": []}, {"text": "Chinese CCGbank : extracting CCG derivations from the penn Chinese treebank .", "entities": [[1, 2, "DatasetName", "CCGbank"], [9, 11, "DatasetName", "Chinese treebank"]]}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics", "entities": []}, {"text": "572(Coling 2010 ) , pages 1083\u20131091 , Beijing , China .", "entities": []}, {"text": "Coling 2010 Organizing Committee .", "entities": []}, {"text": "Yuxuan Wang , Wanxiang Che , Jiang Guo , and Ting Liu .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A neural transition - based approach for semantic dependency graph parsing .", "entities": []}, {"text": "In Proceedings of the Thirty - Second AAAI Conference on Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Kun Yu , Miyao Yusuke , Xiangli Wang , Takuya Matsuzaki , and Junichi Tsujii .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Semiautomatically developing Chinese hpsg grammar from the penn Chinese treebank for deep parsing .", "entities": [[8, 10, "DatasetName", "Chinese treebank"]]}, {"text": "InColing 2010 :", "entities": []}, {"text": "Posters , pages 1417\u20131425 , Beijing , China .", "entities": []}, {"text": "Coling 2010 Organizing Committee .", "entities": []}, {"text": "Xun Zhang , Yantao Du , Weiwei Sun , and Xiaojun Wan . 2016 .", "entities": []}, {"text": "Transition - based parsing for deep dependency structures .", "entities": []}, {"text": "Computational Linguistics , 42(3):353\u2013389 .", "entities": []}, {"text": "Yi Zhang and Rui Wang .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Cross - domain dependency parsing using a deep linguistic grammar .", "entities": [[3, 5, "TaskName", "dependency parsing"]]}, {"text": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP , pages 378\u2013386 , Suntec , Singapore .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}]