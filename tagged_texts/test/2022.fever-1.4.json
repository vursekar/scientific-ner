[{"text": "Proceedings of the Fifth Fact Extraction and VERi\ufb01cation Workshop ( FEVER ) , pages 29 - 36 May 26 , 2022 \u00a9 2022 Association for Computational Linguistics Automatic Fake News Detection : Are current models \u201c fact - checking \u201d or \u201c gut - checking \u201d ?", "entities": [[10, 11, "DatasetName", "FEVER"], [28, 31, "TaskName", "Fake News Detection"]]}, {"text": "Ian Kelk Benjamin Basseri Wee Yi Lee Richard Qiu Chris Tanner Harvard University { iak415@g , basseri@cs50,wel390@g}.harvard.edu { rqiu@college , christanner@g}.harvard.edu", "entities": []}, {"text": "Abstract Automatic fake news detection models are ostensibly based on logic , where the truth of a claim made in a headline can be determined by supporting or refuting evidence found in a resulting web query .", "entities": [[2, 5, "TaskName", "fake news detection"]]}, {"text": "These models are believed to be reasoning in some way ; however , it has been shown that these same results , or better , can be achieved without considering the claim at all \u2013 only the evidence .", "entities": []}, {"text": "This implies that other signals are contained within the examined evidence , and could be based on manipulable factors such as emotion , sentiment , or part - of - speech ( POS ) frequencies , which are vulnerable to adversarial inputs .", "entities": [[21, 22, "DatasetName", "emotion"], [26, 29, "DatasetName", "part - of"]]}, {"text": "We neutralize some of these signals through multiple forms of both neural and non - neural pre - processing and style transfer , and find that this flattening of extraneous indicators can induce the models to actually require both claims and evidence to perform well .", "entities": [[20, 22, "TaskName", "style transfer"]]}, {"text": "We conclude with the construction of a model using emotion vectors built off a lexicon and passed through an \u201c emotional attention \u201d mechanism to appropriately weight certain emotions .", "entities": [[9, 10, "DatasetName", "emotion"]]}, {"text": "We provide quantifiable results that prove our hypothesis that manipulable features are being used for fact - checking .", "entities": []}, {"text": "1 Introduction Recent events such as the last two U.S. presidential elections have been greatly affected by fake news , defined as \u201c fabricated information that disseminates deceptive content , or grossly distort actual news reports , shared on social media platforms \u201d ( Allcott and Gentzkow , 2017 ) .", "entities": []}, {"text": "In fact , the World Economic Forum 2013 report designates massive digital misinformation as a major technological and geopolitical risk ( Bovet and Makse , 2019 ) .", "entities": []}, {"text": "As daily social media usage increases ( Statista Research Department , 2021 ) , manual fact - checking can not keep up with this deluge of information .", "entities": []}, {"text": "Automatic fact - checking models are therefore a necessity , and most of them function using a system of claims andevidence ( Hassan et al . , 2017).Given a specific claim , the models use external knowledge as evidence .", "entities": []}, {"text": "Typically , a web search query is treated as the claim , and a subset of the top search results is treated as the evidence .", "entities": []}, {"text": "There is an implicit assumption that the fact - checking models are reasoning in some way , using the evidence to confirm or refute the claim .", "entities": []}, {"text": "Recent research ( Hansen et al . , 2021 ) found this conclusion may be premature ; current models can show improved performance when considering evidence alone , essentially fact - checking an unasked question .", "entities": []}, {"text": "While this might seem reasonable given that the evidence is conditioned on the claims by the search engine , this can be exploited as illustrated in Figure 1 , which shows that evidence returned using a ridiculous claim can still appear reasonable if we view the evidence alone without the claim .", "entities": []}, {"text": "Furthermore , textual entailment requires both a text and a hypothesis ; if we have a result without a hypothesis , we are performing a different , unknown task .", "entities": []}, {"text": "This finding indicates a problem with current automatic fake news detection , signaling that the models rely on features in the evidence typical to fake news , rather than using entailment .", "entities": [[8, 11, "TaskName", "fake news detection"]]}, {"text": "Since most automated fact - checking research is primarily concerned with the accuracy of the results , rather than addressing how the results are achieved , we propose a novel investigation into these models and their evidence .", "entities": [[12, 13, "MetricName", "accuracy"]]}, {"text": "We use a variety of pre - processing steps , including neural and non - neural ones , to attempt to reduce the affectations common in evidence : \u2022Stemming , stopword removal , negation , and POS - filtering ( Babanejad et al . , 2020 ) .", "entities": []}, {"text": "\u2022Style transfer neural models using the Styleformer model to perform informal - to - formal andformal - to - informal paraphrasing methods ( Li et al . , 2018 ; Schmidt , 2020 ) .", "entities": []}, {"text": "We also develop our own BERT - based model as an extension of the EmoCred system ( Giachanou29", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "Figure 1 : An example of why evidence alone does not suffice in identifying fake news , despite the evidence being conditioned on the claim as a search - engine query .", "entities": []}, {"text": "Although the returned evidence appearing reputable , it is clear that it has little relevance to deciding the veracity of the claim that \" all Canadians have eaten at least one bear . \"", "entities": []}, {"text": "et al . , 2019 ) , adding an \u201c emotional attention \u201d layer to weight the most relevant emotional signals in a given evidence snippet .", "entities": []}, {"text": "We make our code publicly available.1", "entities": []}, {"text": "With each of these methods , we focus on scores where the models perform better using both the claims and the evidence combined , SC&E , rather than with the evidence alone , SE .", "entities": []}, {"text": "Going forward , we will refer to the difference between these dataset combinations as the delta of the pre - processing step , where delta = SC&E\u2212SE .", "entities": []}, {"text": "A positive delta score indicates that the claim was useful and helped yield an increase in performance .", "entities": []}, {"text": "Since we are removing indicators that the current models rely on , some of the models perform worse at the task than they did previously .", "entities": []}, {"text": "However , a surprising result is that many improved , and the need to consider the claim and the evidence together is a sign of using reasoning rather than manipulable indicators .", "entities": []}, {"text": "Under current fact - checking models , adversarial data can subvert these detectors .", "entities": []}, {"text": "Paraphrasing can be performed by inserting fictitious statements into otherwise truthful evidence with little effect on the model \u2019s output .", "entities": []}, {"text": "For example , an article titled \u201c Is the GOP losing Walmart ? \u201d , could have \u201c Walmart \u201d substituted with \u201c Apple , \u201d and the predictions are nearly identical despite the news now being fictitious ( Zhou et", "entities": []}, {"text": "al . , 2019 ) .", "entities": []}, {"text": "1GitHub repository link2", "entities": []}, {"text": "Related Work There has been significant work with automatic fact - checking models using RNNs and Transformers ( Shaar et al . , 2020a ; Alam et", "entities": []}, {"text": "al . , 2020 ; Shaar et al . , 2020b ) as well as non - neural machine learning using TF - IDF vectors ( Reddy et al . , 2018 ) .", "entities": []}, {"text": "Current fake news detection models that use a claim \u2019s search engine results as evidence may unintentionally use hidden signals that are not attributed to the claim ( Hansen et al . , 2021 ) .", "entities": [[1, 4, "TaskName", "fake news detection"]]}, {"text": "Additionally , models may in fact simply memorize biases within data ( Gururangan et al . , 2018 ) .", "entities": []}, {"text": "Improvements can be made when using human - identified justifications for fact - checking ( Alhindi et al . , 2018 ; V o and Lee , 2020 ) , and making use of textual entailment can offer improvements ( Saikh et al . , 2019 ) .", "entities": []}, {"text": "Emotional text can signal low credibility ( Rashkin et al . , 2017 ) , characterizing fake news as a task where pre - processing can be used effectively to diminish bias ( Giachanou et al . , 2019 ; Babanejad et al . , 2020 ) .", "entities": []}, {"text": "A framework to both categorize fake news and to identify features that differentiate fake news from real news has been described by Molina et al .", "entities": []}, {"text": "( 2021 ) , and debiasing inappropriate subjectivity in text can be accomplished by replacing a single biased word in each sentence ( Pryzant et al . , 2020 ) .", "entities": []}, {"text": "3 Datasets We use the MultiFC dataset ( Augenstein et al . , 2019 ) , which consists of political claims and associated truth labels from PolitiFact and Snopes.30", "entities": [[5, 6, "DatasetName", "MultiFC"], [26, 27, "DatasetName", "PolitiFact"]]}, {"text": "Figure 2 : Ablation studies where evidence was sequentially removed for training and evaluation of models .", "entities": []}, {"text": "On the far left , we show the most effective non - neural pre - processing compared to the baseline of none .", "entities": []}, {"text": "Performance generally worsens as the ablation increases .", "entities": []}, {"text": "Using the claim as a query , the top ten results from Google News ( \u201c snippets \u201d ) constitute the evidence ( Hansen et al . , 2021 ) .", "entities": [[12, 13, "DatasetName", "Google"]]}, {"text": "PolitiFact and Snopes use five labels ( False , Mostly False , Mixture , Mostly True , True ) , which we collapse to True , Mixture , and False .", "entities": [[0, 1, "DatasetName", "PolitiFact"], [2, 3, "DatasetName", "Snopes"]]}, {"text": "To construct the emotion vectors for our EmoAttention system , we use the NRC Affect Intensity Lexicon , which maps approximately 6,000 terms to values between 0 and 1 , representing the term \u2019s intensity along 8 different emotions ( Mohammad , 2017 ) .", "entities": [[3, 4, "DatasetName", "emotion"], [26, 27, "DatasetName", "0"]]}, {"text": "For example , \u201c interrupt \u201d and \u201c rage \u201d are both categorized as anger words , but with the respective intensity values of 0.333 and 0.911 .", "entities": []}, {"text": "4 Models The most common automatic fact - checking NLP models are based on term frequency , word embeddings , and contextualized word embeddings , using Random Forests , LSTMs , and BERT ( Hassan et al . , 2017 ) .", "entities": [[17, 19, "TaskName", "word embeddings"], [22, 24, "TaskName", "word embeddings"], [32, 33, "MethodName", "BERT"]]}, {"text": "We limit our experimentation to the BERT model , as it is the highest performing state - of - the - art model and was thoroughly tested in ( Hansen et al . , 2021 ) .", "entities": [[6, 7, "MethodName", "BERT"]]}, {"text": "This BERT model with no pre - processing is our baseline model .", "entities": [[1, 2, "MethodName", "BERT"]]}, {"text": "For the style transfer model we use the Styleformer model ( Li et al . , 2018 ; Schmidt , 2020 ) , a Transformer - based seq2seq model .", "entities": [[2, 4, "TaskName", "style transfer"], [24, 25, "MethodName", "Transformer"], [27, 28, "MethodName", "seq2seq"]]}, {"text": "We also develop our own BERT - based model using the EmoLexi andEmoInt implementation of the EmoCred system by adding an emotional attention layer to emphasize certain emotion representations for a given claim and its evidence ( Giachanou et al . , 2019 ) .", "entities": [[5, 6, "MethodName", "BERT"], [27, 28, "DatasetName", "emotion"]]}, {"text": "There is also a snippet attention layer at - tending to which evidence itself should be weighted most heavily for the given claim .", "entities": []}, {"text": "Figure 3 : The EmoAttention BERT model architecture using emotional- andsnippet attention 5 Experiments 5.1 Non - neural pre - processing Our goal is to separate affect - based properties from factual content of the text .", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "Toward this , we run a large number of permutations of the following four simple pre - processing steps ( see Figure 4 in Appendix B for results ) .", "entities": []}, {"text": "These steps were chosen as they have been shown to facilitate affective tasks such as sentiment analysis , emotion classification , and sarcasm detection ( Babanejad et al . , 2020 ) .", "entities": [[15, 17, "TaskName", "sentiment analysis"], [18, 20, "TaskName", "emotion classification"], [22, 24, "TaskName", "sarcasm detection"]]}, {"text": "In some cases we used a modified form \u2014 such as removing adverbs for POS pre - processing.31", "entities": []}, {"text": "\u2022Negation ( NEG ): A mechanism that transforms a negated statement into its inverse ( Benamara et al . , 2012 ) .", "entities": []}, {"text": "An example , \u201c I am not happy \u201d would have \u201c not \u201d removed and \u201c happy \u201d replaced by its antonym , forming the sentence \u201c I am sad . \u201d", "entities": []}, {"text": "\u2022Parts - of - Speech ( POS ): We keep only three parts of speech : nouns , verbs , and adjectives .", "entities": []}, {"text": "We initially included adverbs but found removing them improved results .", "entities": []}, {"text": "This could be due to some adverbs being emotionally charged .", "entities": []}, {"text": "\u2022Stopwords ( STOP ):", "entities": []}, {"text": "These are generally the most common words in a language , such as function words and prepositions .", "entities": []}, {"text": "We use the NLTK library .", "entities": []}, {"text": "\u2022Stemming ( STEM ): Reducing a word to its root form .", "entities": []}, {"text": "We use the NLTK Snowball Stemmer .", "entities": []}, {"text": "5.2 Neural formality style transfer We use the adversarial technique of generating paraphrases for all the claims and evidence through style transfer .", "entities": [[3, 5, "TaskName", "style transfer"], [20, 22, "TaskName", "style transfer"]]}, {"text": "The neural Transformer - based seq2seq model Styleformer changes the formality of the text , and it frequently changes the ordering of the sentence itself , too .", "entities": [[2, 3, "MethodName", "Transformer"], [5, 6, "MethodName", "seq2seq"]]}, {"text": "For example , the formal - to - informal model changes \u201c A photograph shows William Harley and Arthur Davidson unveiling their first motorcycle in 1914 \u201d to\u201cIn a 1914 photograph William Harley and Arthur Davidson unveil their first motorcycle . \u201d", "entities": []}, {"text": "As well , it removes punctuation and alters phrasing that might be understood as sarcasm , such as \u201c Melania Trump said that Native Americans upset about the Dakota Access Pipeline should \u2018 go back to India \u201d \u2019", "entities": []}, {"text": "to\u201cMelania", "entities": []}, {"text": "Trump told Native Americans that was upset by the Dakota Access Pipeline , that they should travel to India . \u201d", "entities": []}, {"text": "The informalto - formal model lowercases everything and also changes the text significantly .", "entities": []}, {"text": "We chose this paraphrasing model based on the idea that fake news \u2013 especially that which is frequently posted on social media \u2013 has a certain polarizing style that might be neutralized by altering the formality of the text .", "entities": []}, {"text": "Rather surprisingly , we received better results transforming the style from formal - to - informal than we did with informal - toformal.5.3 EmoCred emotion representations with emotional attention TheEmoCred systems of EmoLexi andEmoInt use a lexicon to determine emotional word counts and intensities , respectively ( Giachanou et al . , 2019 ) .", "entities": [[24, 25, "DatasetName", "emotion"]]}, {"text": "We use the NRC Affect Intensity Lexicon , a \u201c highcoverage lexicons that captures word \u2013 affect intensities \u201d for eight basic emotions , which were created using a technique called best \u2013 worst scaling ( Mohammad , 2017 ) .", "entities": []}, {"text": "These eight emotions can be used to create an emotion vector for a sentence , where each index corresponds to a score : [ anger , anticipation , disgust , fear , joy , sadness , surprise , trust ] .", "entities": [[9, 10, "DatasetName", "emotion"]]}, {"text": "As an example , a sentence that contains the word \u201c suffering \u201d conveys sadness with an NRC Affect Intensity Lexicon intensity of 0.844 , whereas the word \u201c affection \u201d indicates joywith an intensity of 0.647 .", "entities": []}, {"text": "We create the vector of length eight , and for each word associated with an emotion , the emotion \u2019s indexed value is either : ( 1 ) incremented by one for EmoLexi ; or , ( 2 ) incremented by its intensity for EmoInt .", "entities": [[15, 16, "DatasetName", "emotion"], [18, 19, "DatasetName", "emotion"]]}, {"text": "Thus , the sentence \u201c He had an affection for suffering \u201d would have an EmoLexi emotion vector of [ 0,0,0,0,1,1,0,0]and an EmoInt emotion vector of [ 0,0,0,0,0.647,0.844,0,0 ]", "entities": [[16, 17, "DatasetName", "emotion"], [23, 24, "DatasetName", "emotion"]]}, {"text": "We build on this EmoCred framework , adding an attention system for emotion that gives a weight to each emotion vector , just as the attention layer for each snippet gives a weight to each snippet .", "entities": [[12, 13, "DatasetName", "emotion"], [19, 20, "DatasetName", "emotion"]]}, {"text": "The end result is that two independent attention layers attend to the ten snippets and ten emotional representations independently , and we call the resulting system Emotional Attention ( see Figure 3 ) .", "entities": [[7, 9, "HyperparameterName", "attention layers"]]}, {"text": "6 Results Surprisingly , the four top - performing models with the Snopes dataset include two non - neural models and two neural models .", "entities": [[12, 13, "DatasetName", "Snopes"]]}, {"text": "All four achieve greater F1 Macro scores than the baseline BERT model without pre - processing ( see Figure 2 ) .", "entities": [[4, 6, "MetricName", "F1 Macro"], [10, 11, "MethodName", "BERT"]]}, {"text": "POS and STOP yield the biggest delta between SC&Evs .", "entities": []}, {"text": "SE , followed by EmoInt andInformal Style Transfer .", "entities": [[6, 8, "TaskName", "Style Transfer"]]}, {"text": "However , EmoInt yields the highest F1 Macro , followed by POS , Informal , and STOP .", "entities": [[6, 8, "MetricName", "F1 Macro"]]}, {"text": "In PolitiFact , none of the pre - processing steps achieve a delta greater than zero for SC&EversusSE .", "entities": [[1, 2, "DatasetName", "PolitiFact"]]}, {"text": "The combination of POS+STOP steps come closest to parity , followed by EmoInt , then POS and STOP .", "entities": []}, {"text": "For the best F1 Macro scores overall , EmoAttention \u2019s two forms ( i.e. , EmoInt and EmoLexi ) were the two best , followed by STOP32", "entities": [[3, 5, "MetricName", "F1 Macro"]]}, {"text": "Snopes PolitiFact Pre - processing SC&E\u0394vsSE SC&E\u0394vsSE ( Claim+Evidence ) ( Evidence ) ( Claim+Evidence ) ( Evidence ) F1 Macro F1 Macro F1 Macro F1 Macro", "entities": [[0, 1, "DatasetName", "Snopes"], [1, 2, "DatasetName", "PolitiFact"], [19, 21, "MetricName", "F1 Macro"], [21, 23, "MetricName", "F1 Macro"], [23, 25, "MetricName", "F1 Macro"], [25, 27, "MetricName", "F1 Macro"]]}, {"text": "None 0.295 -0.003 0.282 -0.038 POS 0.340 0.046 0.285 -0.022 STOP 0.304 0.043 0.303 -0.023 EmoAttention ( EmoInt ) 0.344 0.038 0.318 -0.015 EmoAttention ( EmoLexi ) 0.324 -0.003 0.310 -0.033 POS+STOP 0.312 0.012 0.290 -0.003", "entities": []}, {"text": "Formal to Informal 0.332 0.028 \u2013 \u2013 \u2013 \u2013 Table 1 : Top results from various pre - processing steps .", "entities": []}, {"text": "The top three steps are highlighted in blue .", "entities": []}, {"text": "The lowest F1 Macro scores and deltas are in red .", "entities": [[2, 4, "MetricName", "F1 Macro"]]}, {"text": "With the exception of EmoLexi tying for the lowest delta , the best pre - processing steps outperform the baseline BERT model from Hansen et al .", "entities": [[20, 21, "MethodName", "BERT"]]}, {"text": "( 2021 ) .", "entities": []}, {"text": "and POS .", "entities": []}, {"text": "All of these pre - processing steps achieve higher F1 Macro scores than the baseline BERT model .", "entities": [[9, 11, "MetricName", "F1 Macro"], [15, 16, "MethodName", "BERT"]]}, {"text": "Further , they yield better deltas for SC&E versus SE , implying that the model now requires the claims to reason .", "entities": []}, {"text": "7 Conclusion Many pre - processing steps increase both the model \u2019s F1 scores and its need for claims and evidence , validating our hypothesis that signals in style and tone have become a crutch for factchecking models .", "entities": [[12, 13, "MetricName", "F1"]]}, {"text": "Rather than doing entailment , they are leveraging other signals \u2013 perhaps similar to sentiment analysis \u2013 and relying on a \u201c gut feeling \u201d .", "entities": [[14, 16, "TaskName", "sentiment analysis"]]}, {"text": "EmoAttention generates our best predictions and deltas , confirming our suspicion that the models rely on emotionally charged style as a predictive feature .", "entities": []}, {"text": "This is further narrowed to emotional intensity : the EmoInt intensity score - based model performs much better than its count - based counterpartEmoLexi .", "entities": []}, {"text": "Thus , evidence containing emotions associated with fake news will be considered more when scoring the claim .", "entities": []}, {"text": "One surprising result is the effectiveness of the simple POS and STOP pre - processing steps .", "entities": []}, {"text": "POS only included nouns , verbs , and adjectives ( i.e. , a superset of STOP ) .", "entities": []}, {"text": "This could explain why it has the best delta between SC&Evs .", "entities": []}, {"text": "SE .", "entities": []}, {"text": "Future research could investigate if stopwords , which are often discarded , actually contain signals such as anaphora : a repetitive rhetoric style which can affect NLP analyses ( Liddy , 1990 ) .", "entities": []}, {"text": "As an example , Donald Trump makes heavy use of anaphora in his 2017 inauguration speech:\u201cTogether , we will make America strong again .", "entities": []}, {"text": "We will make America wealthy again .We will make America proud again .We will make America safe again .", "entities": []}, {"text": "And , yes , together , we will make america great again . \u201d", "entities": []}, {"text": "( Trump Inauguration Address , 2017 )", "entities": []}, {"text": "By removing stopwords \u201c we \u201d , \u201c will \u201d and \u201c again \u201d , the model relies less on the text \u2019s rhetoric style and more on the entailment we are seeking .", "entities": []}, {"text": "We propose further study on the effects of STOP and POS , as well as experimenting with different emotional vectors and EmoAttention to make factchecking models more robust .", "entities": []}, {"text": "Automatic Fake News detection remains a challenging problem , and unfortunately , current fact - checking models can be subverted by adversarial techniques that exploit emotionally charged writing .", "entities": [[1, 4, "TaskName", "Fake News detection"]]}, {"text": "A Impact Statement Disinformation is much more than just a mild inconvenience for society ; it has resulted in needless deaths in the COVID-19 pandemic , and has fomented violence and political instability all over the globe ( van der Linden et al . , 2020 ) .", "entities": []}, {"text": "Our goal in this paper is to discover exploitable weaknesses in current fact - checking models and recommend that such models not be relied upon in their current form .", "entities": []}, {"text": "We point out how the models are dependent on emotional signals in the texts instead of exclusively performing textual entailment , and that additional research needs to be done to ensure they are performing the proper task .", "entities": []}, {"text": "Harm Minimization Our quantifying of the effects of pre - processing on fact - checking models does not cause any harm to real - world users or33", "entities": []}, {"text": "companies .", "entities": []}, {"text": "Research has demonstrated that adversarial attacks could result in disinformation being labeled as factual news .", "entities": []}, {"text": "Disinformation has become increasingly present in global politics , as some nation - states with significant resources have disseminated propaganda to create political dissent in other countries ( Zhou et al . , 2019 ) .", "entities": []}, {"text": "Our research here has demonstrated potential risks : emotional writing could be used as an exploit to circumvent fact - checking models .", "entities": []}, {"text": "Thus , we urge others to further illuminate such vulnerabilities , to minimize potential harms , and to encourage improvements with new models .", "entities": []}, {"text": "Deployment Social media companies often deal with fake news by placing highly visible labels .", "entities": []}, {"text": "However , simply tagging stories as false can make readers more willing to believe and share other false , untagged stories .", "entities": []}, {"text": "This unintended consequence \u2013 in which the selective labeling of false news makes other news stories seem more legitimate \u2013 has been called the \u201c implied - truth effect \u201d ( Pennycook et al . , 2019 ) .", "entities": []}, {"text": "Thus , unless these models become so accurate that they catch allfake news presented to them , the entire basis of their use is called into question .", "entities": []}, {"text": "Despite the significant progress in developing models to correctly identify fake news , the real elephant in the room is that many people simply ignore the labels ( Molina et al . , 2021 ) .", "entities": []}, {"text": "There is , however , prior work supporting the idea that if people are warned that a headline is false , they will be less likely to believe it ( Ecker et al . , 2010 ; Lewandowsky et", "entities": []}, {"text": "al . , 2012 ) .", "entities": []}, {"text": "Because of this , we believe this research represents a net benefit for humanity .", "entities": []}, {"text": "Warning labels are just one way of dealing with properly identified fake news , and publishers can choose to simply not allow it on their platforms .", "entities": []}, {"text": "Of course , this issue leads to questions of censorship .", "entities": []}, {"text": "B Extended Results In Figure 4 , we report all results for each preprocessing step .", "entities": []}, {"text": "References Firoj Alam , Shaden Shaar , Alex Nikolov , Hamdy Mubarak , Giovanni Da San Martino , Ahmed Abdelali , Fahim Dalvi , Nadir Durrani , Hassan Sajjad , Kareem Darwish , and Preslav Nakov .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Fighting the COVID-19 infodemic : Modeling the perspective of journalists , fact - checkers , social mediaplatforms , policy makers , and the society .", "entities": []}, {"text": "CoRR , abs/2005.00033 .", "entities": []}, {"text": "Tariq Alhindi , Savvas Petridis , and Smaranda Muresan .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Where is your evidence : Improving factchecking by justification modeling .", "entities": []}, {"text": "In Proceedings of the First Workshop on Fact Extraction and VERification ( FEVER ) , pages 85\u201390 , Brussels , Belgium .", "entities": [[12, 13, "DatasetName", "FEVER"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Hunt Allcott and Matthew Gentzkow . 2017 .", "entities": []}, {"text": "Social media and fake news in the 2016 election .", "entities": []}, {"text": "Journal of Economic Perspectives , 31(2):211\u201336 .", "entities": []}, {"text": "Isabelle Augenstein , Christina Lioma , Dongsheng Wang , Lucas Chaves Lima , Casper Hansen , Christian Hansen , and Jakob Grue Simonsen . 2019 .", "entities": []}, {"text": "Multifc :", "entities": [[0, 1, "DatasetName", "Multifc"]]}, {"text": "A real - world multi - domain dataset for evidence - based fact checking of claims .", "entities": [[12, 14, "TaskName", "fact checking"]]}, {"text": "Nastaran Babanejad , Ameeta Agrawal , Aijun An , and Manos Papagelis .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "A comprehensive analysis of preprocessing for word representation learning in affective tasks .", "entities": [[7, 9, "TaskName", "representation learning"]]}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 5799\u20135810 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Farah Benamara , Baptiste Chardon , Yannick Mathieu , Vladimir Popescu , and Nicholas Asher .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "How do negation and modality impact on opinions ?", "entities": []}, {"text": "In Proceedings of the Workshop on Extra - Propositional Aspects of Meaning in Computational Linguistics , ExProM \u2019 12 , page 10\u201318 , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Alexandre Bovet and Hern\u00e1n A. Makse .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Influence of fake news in twitter during the 2016 us presidential election .", "entities": []}, {"text": "JournalNature Communications , 10(1 ) .", "entities": []}, {"text": "Ullrich Ecker , Stephan Lewandowsky , and David Tang .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Explicit warnings reduce but do not eliminate the continued influence of misinformation .", "entities": []}, {"text": "Memory and cognition , 38:1087\u2013100 .", "entities": []}, {"text": "Anastasia Giachanou , Paolo Rosso , and Fabio Crestani .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Leveraging emotional signals for credibility detection .", "entities": []}, {"text": "In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR\u201919 , page 877\u2013880 , New York , NY , USA .", "entities": [[6, 7, "DatasetName", "ACM"], [14, 16, "TaskName", "Information Retrieval"]]}, {"text": "Association for Computing Machinery .", "entities": []}, {"text": "Suchin Gururangan , Swabha Swayamdipta , Omer Levy , Roy Schwartz , Samuel Bowman , and Noah A. Smith .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Annotation artifacts in natural language inference data .", "entities": [[3, 6, "TaskName", "natural language inference"]]}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 2 ( Short Papers ) , pages 107\u2013112 , New Orleans , Louisiana . Association for Computational Linguistics .", "entities": []}, {"text": "Casper Hansen , Christian Hansen , and Lucas Chaves Lima .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Automatic fake news detection : Are models learning to reason?34", "entities": [[1, 4, "TaskName", "fake news detection"]]}, {"text": "Figure 4 : The full table of results for all pre - processing steps for the Snopes ( SNES ) and PolitiFact ( POMT ) datasets .", "entities": [[16, 17, "DatasetName", "Snopes"], [21, 22, "DatasetName", "PolitiFact"]]}, {"text": "Due to the high compute requirements of the formal and informal style transfer models , these datasets were only prepared for the Snopes dataset .", "entities": [[11, 13, "TaskName", "style transfer"], [22, 23, "DatasetName", "Snopes"]]}, {"text": "The darkest green colors indicate the best results , while the red indicates the worst .", "entities": []}, {"text": "Multiple pre - processing steps such as ( pos , stop ) were performed in the order written .", "entities": []}, {"text": "35", "entities": []}, {"text": "Naeemul Hassan , Fatma Arslan , Chengkai Li , and Mark Tremayne . 2017 .", "entities": []}, {"text": "Toward automated fact - checking : Detecting check - worthy factual claims by claimbuster .", "entities": [[13, 14, "DatasetName", "claimbuster"]]}, {"text": "In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD \u2019 17 , page 1803\u20131812 , New York , NY , USA . Association for Computing Machinery .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Stephan Lewandowsky , Ullrich K. H. Ecker , Colleen M. Seifert , Norbert Schwarz , and John Cook . 2012 .", "entities": []}, {"text": "Misinformation and its correction : Continued influence and successful debiasing .", "entities": [[0, 1, "TaskName", "Misinformation"]]}, {"text": "Psychological Science in the Public Interest , 13(3):106\u2013131 .", "entities": []}, {"text": "PMID : 26173286 .", "entities": []}, {"text": "Juncen Li , Robin Jia , He He , and Percy Liang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Delete , retrieve , generate : A simple approach to sentiment and style transfer .", "entities": [[12, 14, "TaskName", "style transfer"]]}, {"text": "CoRR , abs/1804.06437 .", "entities": []}, {"text": "Elizabeth DuRoss Liddy .", "entities": []}, {"text": "1990 .", "entities": []}, {"text": "Anaphora in natural language processing and information retrieval .", "entities": [[6, 8, "TaskName", "information retrieval"]]}, {"text": "Information Processing & Management , 26(1):39\u201352 .", "entities": [[3, 4, "TaskName", "Management"]]}, {"text": "Special Issue : Natural Language Processing and Information Retrieval .", "entities": [[7, 9, "TaskName", "Information Retrieval"]]}, {"text": "Saif M. Mohammad .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Word affect intensities .", "entities": []}, {"text": "CoRR , abs/1704.08798 .", "entities": []}, {"text": "Maria D. Molina , S. Shyam Sundar , Thai Le , and Dongwon Lee . 2021 .", "entities": []}, {"text": "\u201c fake news \u201d is not simply false information : A concept explication and taxonomy of online content .", "entities": []}, {"text": "American Behavioral Scientist , 65(2):180\u2013212 .", "entities": []}, {"text": "Gordon Pennycook , Adam Bear , and Evan Collins .", "entities": [[3, 4, "MethodName", "Adam"]]}, {"text": "2019 .", "entities": []}, {"text": "The implied truth effect : Attaching warnings to a subset of fake news headlines increases perceived accuracy of headlines without warnings .", "entities": [[16, 17, "MetricName", "accuracy"]]}, {"text": "Management Science , page 1 .", "entities": [[0, 1, "TaskName", "Management"]]}, {"text": "Reid Pryzant , Richard Martinez , Nathan Dass , Sadao Kurohashi , Dan Jurafsky , and Diyi Yang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Automatically neutralizing subjective bias in text .", "entities": []}, {"text": "Proceedings of the AAAI Conference on Artificial Intelligence , 34:480\u2013489 .", "entities": []}, {"text": "Hannah Rashkin , Eunsol Choi , Jin Yea Jang , Svitlana V olkova , and Yejin Choi . 2017 .", "entities": []}, {"text": "Truth of varying shades : Analyzing language in fake news and political fact - checking .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 2931\u20132937 , Copenhagen , Denmark . Association for Computational Linguistics .", "entities": []}, {"text": "Aniketh Janardhan Reddy , Gil Rocha , and Diego Esteves .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Defactonlp :", "entities": []}, {"text": "Fact verification using entity recognition , TFIDF vector comparison and decomposable attention .", "entities": [[0, 2, "TaskName", "Fact verification"]]}, {"text": "CoRR , abs/1809.00509 .", "entities": []}, {"text": "Tanik Saikh , Amit Anand , Asif Ekbal , and Pushpak Bhattacharyya . 2019 .", "entities": []}, {"text": "A Novel Approach Towards Fake News Detection :", "entities": [[4, 7, "TaskName", "Fake News Detection"]]}, {"text": "Deep Learning Augmented with Textual Entailment Features , pages 345\u2013358.Robert Schmidt .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Generative text style transfer for improved language sophistication .", "entities": [[1, 4, "TaskName", "text style transfer"]]}, {"text": "Stanford CS230 .", "entities": []}, {"text": "Shaden Shaar , Giovanni Da San Martino , Nikolay Babulkov , and Preslav Nakov .", "entities": []}, {"text": "2020a .", "entities": []}, {"text": "That is a known lie : Detecting previously fact - checked claims .", "entities": []}, {"text": "CoRR , abs/2005.06058 .", "entities": []}, {"text": "Shaden Shaar , Alex Nikolov , Nikolay Babulkov , Firoj Alam , Alberto Barr\u00f3n - Cede\u00f1o , Tamer Elsayed , Maram Hasanain , Reem Suwaileh , Fatima Haouari , Giovanni Da San Martino , and Preslav Nakov .", "entities": []}, {"text": "2020b .", "entities": []}, {"text": "Overview of checkthat !", "entities": []}, {"text": "2020 english : Automatic identification and verification of claims in social media .", "entities": []}, {"text": "In CLEF .", "entities": []}, {"text": "Sander van der Linden , Jon Roozenbeek , and Josh Compton .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Inoculating against fake news about covid-19 .", "entities": []}, {"text": "Frontiers in Psychology , 11:2928 .", "entities": []}, {"text": "Nguyen V o and Kyumin Lee .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Where are the facts ?", "entities": []}, {"text": "searching for fact - checked information to alleviate the spread of fake news .", "entities": []}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 7717\u20137731 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Zhixuan Zhou , Huankang Guan , Meghana Moorthy Bhat , and Justin Hsu . 2019 .", "entities": []}, {"text": "Fake news detection via NLP is vulnerable to adversarial attacks .", "entities": [[0, 3, "TaskName", "Fake news detection"]]}, {"text": "CoRR , abs/1901.09657.36", "entities": []}]