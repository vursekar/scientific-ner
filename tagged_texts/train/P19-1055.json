[{"text": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 579\u2013590 Florence , Italy , July 28 - August 2 , 2019 .", "entities": [[15, 16, "MethodName", "Florence"]]}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics579Sentiment Tagging with Partial Labels using Modular Architectures Xiao Zhang Purdue University zhang923@purdue.eduDan Goldwasser Purdue University dgoldwas@purdue.edu", "entities": []}, {"text": "Abstract Many NLP learning tasks can be decomposed into several distinct sub - tasks , each associated with a partial label .", "entities": []}, {"text": "In this paper we focus on a popular class of learning problems , sequence prediction applied to several sentiment analysis tasks , and suggest a modular learning approach in which different sub - tasks are learned using separate functional modules , combined to perform the \ufb01nal task while sharing information .", "entities": [[18, 20, "TaskName", "sentiment analysis"]]}, {"text": "Our experiments show this approach helps constrain the learning process and can alleviate some of the supervision efforts .", "entities": []}, {"text": "1 Introduction Many natural language processing tasks attempt to replicate complex human - level judgments , which often rely on a composition of several sub - tasks into a uni\ufb01ed judgment .", "entities": []}, {"text": "For example , consider the Targeted - Sentiment task ( Mitchell et al . , 2013 ) , assigning a sentiment polarity score to entities depending on the context that they appear in .", "entities": []}, {"text": "Given the sentence \u201c according to a CNN poll , Green Book will win the best movie award \u201d , the system has to identify both entities , and associate the relevant sentiment value with each one ( neutral with CNN , and positive with Green Book ) .", "entities": []}, {"text": "This task can be viewed as a combination of two tasks , entity identi\ufb01cation , locating contiguous spans of words corresponding to relevant entities , and sentiment prediction , speci\ufb01c to each entity based on the context it appears in .", "entities": []}, {"text": "Despite the fact that this form of functional task decomposition is natural for many learning tasks , it is typically ignored and learning is de\ufb01ned as a monolithic process , combining the tasks into a single learning problem .", "entities": []}, {"text": "Our goal in this paper is to take a step towards modular learning architectures that exploit the learning tasks \u2019 inner structure , and as a result simplify the learning process and reduce theannotation effort .", "entities": []}, {"text": "We introduce a novel task decomposition approach , learning with partial labels , in which the task output labels decompose hierarchically , into partial labels capturing different aspects , or sub - tasks , of the \ufb01nal task .", "entities": []}, {"text": "We show that learning with partial labels can help support weakly - supervised learning when only some of the partial labels are available .", "entities": []}, {"text": "Given the popularity of sequence labeling tasks in NLP , we demonstrate the strength of this approach over several sentiment analysis tasks , adapted for sequence prediction .", "entities": [[19, 21, "TaskName", "sentiment analysis"]]}, {"text": "These include target - sentiment prediction ( Mitchell et al . , 2013 ) , aspect - sentiment prediction ( Pontiki et al . , 2016 ) and subjective text span identi\ufb01cation and polarity prediction ( Wilson et al . , 2013 ) .", "entities": []}, {"text": "To ensure the broad applicability of our approach to other problems , we extend the popular LSTM - CRF ( Lample et al . , 2016 ) model that was applied to many sequence labeling tasks1 .", "entities": [[16, 17, "MethodName", "LSTM"], [18, 19, "MethodName", "CRF"]]}, {"text": "The modular learning process corresponds to a task decomposition , in which the prediction label , y , is deconstructed into a set of partial labelsfy0;::;ykg , each de\ufb01ning a sub - task , capturing a different aspect of the original task .", "entities": []}, {"text": "Intuitively , the individual sub - tasks are signi\ufb01cantly easier to learn , suggesting that if their dependencies are modeled correctly when learning the \ufb01nal task , they can constrain the learning problem , leading to faster convergence and a better overall learning outcome .", "entities": []}, {"text": "In addition , the modular approach helps alleviate the supervision problem , as often providing full supervision for the overall task is costly , while providing additional partial labels is signi\ufb01cantly easier .", "entities": []}, {"text": "For example , annotating entity segments syntactically is considerably easier than determining their associated sentiment , which requires understanding the nuances of the 1We also provide analysis for NER in the apendix", "entities": [[28, 29, "TaskName", "NER"]]}, {"text": "580context they appear in semantically .", "entities": []}, {"text": "By exploiting modularity , the entity segmentation partial labels can be used to help improve that speci\ufb01c aspect of the overall task .", "entities": []}, {"text": "Our modular task decomposition approach is partially inspired by \ufb01ndings in cognitive neuroscience , namely the two - streams hypothesis , a widely accepted model for neural processing of cognitive information in vision and hearing ( Eysenck and Keane , 2005 ) , suggesting the brain processes information in a modular way , split between a \u201c where \u201d ( dorsal ) pathway , specialized for locating objects and a \u201c what \u201d ( ventral ) pathway , associated with object representation and recognition ( Mishkin et al . , 1983 ;", "entities": []}, {"text": "Geschwind and Galaburda , 1987 ; Kosslyn , 1987 ; Rueckl et al . , 1989 ) .", "entities": []}, {"text": "Jacobs et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 1991 ) provided a computational perspective , investigating the \u201c what \u201d and \u201c where \u201d decomposition on a computer vision task .", "entities": []}, {"text": "We observe that this task decomposition naturally \ufb01ts many NLP tasks and borrow the notation .", "entities": []}, {"text": "In the target - sentiment tasks we address in this paper , the segmentation tagging task can be considered as a \u201c where\u201d-task ( i.e. , the location of entities ) , and the sentiment recognition as the \u201c what\u201d-task .", "entities": []}, {"text": "Our approach is related to multi - task learning ( Caruana , 1997 ) , which has been extensively applied in NLP ( Toshniwal et al . , 2017 ; Eriguchi et al . , 2017 ; Collobert et al . , 2011 ; Luong , 2016 ; Liu et al . , 2018 ) .", "entities": [[5, 9, "TaskName", "multi - task learning"]]}, {"text": "However , instead of simply aggregating the objective functions of several different tasks , we suggest to decompose a single task into multiple inter - connected sub - tasks and then integrate the representation learned into a single module for the \ufb01nal decision .", "entities": []}, {"text": "We study several modular neural architectures , which differ in the way information is shared between tasks , the learning representation associated with each task and the way the dependency between decisions is modeled .", "entities": []}, {"text": "Our experiments were designed to answer two questions .", "entities": []}, {"text": "First , can the task structure be exploited to simplify a complex learning task by using a modular approach ?", "entities": []}, {"text": "Second , can partial labels be used effectively to reduce the annotation effort ?", "entities": []}, {"text": "To answer the \ufb01rst question , we conduct experiments over several sequence prediction tasks , and compare our approach to several recent models for deep structured prediction ( Lample et al . , 2016 ; Ma and Hovy , 2016 ; Liu et al . , 2018 ) , and when available , previously published results ( Mitchellet al . , 2013 ; Zhang et al . , 2015 ; Li and Lu , 2017 ; Ma et al . , 2018 )", "entities": [[25, 27, "TaskName", "structured prediction"]]}, {"text": "We show that modular learning indeed helps simplify the learning task compared to traditional monolithic approaches .", "entities": []}, {"text": "To answer the second question , we evaluate our model \u2019s ability to leverage partial labels in two ways .", "entities": []}, {"text": "First , by restricting the amount of full labels , and observing the improvement when providing increasing amounts of partial labels for only one of the sub - tasks .", "entities": []}, {"text": "Second , we learn the sub - tasks using completely disjoint datasets of partial labels , and show that the knowledge learned by the sub - task modules can be integrated into the \ufb01nal decision module using a small amount of full labels .", "entities": []}, {"text": "Our contributions : ( 1 ) We provide a general modular framework for sequence learning tasks .", "entities": []}, {"text": "While we focus on sentiment analysis task , the framework is broadly applicable to many other tagging tasks , for example , NER ( Carreras et al . , 2002 ; Lample et al . , 2016 ) and SRL ( Zhou and Xu , 2015 ) , to name a few .", "entities": [[4, 6, "TaskName", "sentiment analysis"], [22, 23, "TaskName", "NER"]]}, {"text": "( 2 ) We introduce a novel weakly supervised learning approach , learning with partial labels , that exploits the modular structure to reduce the supervision effort .", "entities": []}, {"text": "( 3 ) We evaluated our proposed model , in both the fullysupervised and weakly supervised scenarios , over several sentiment analysis tasks .", "entities": [[20, 22, "TaskName", "sentiment analysis"]]}, {"text": "2 Related Works From a technical perspective , our task decomposition approach is related to multi - task learning ( Caruana , 1997 ) , speci\ufb01cally , when the tasks share information using a shared deep representation ( Collobert et al . , 2011 ; Luong , 2016 ) .", "entities": [[15, 19, "TaskName", "multi - task learning"]]}, {"text": "However , most prior works aggregate multiple losses on either different pre - de\ufb01ned tasks at the \ufb01nal layer ( Collobert et al . , 2011 ; Luong , 2016 ) , or on a language model at the bottom level ( Liu et al . , 2018 ) .", "entities": []}, {"text": "This work suggests to decompose a given task into sub - tasks whose integration comprise the original task .", "entities": []}, {"text": "To the best of our knowledge , Ma et al .", "entities": []}, {"text": "( 2018 ) , focusing on targeted sentiment is most similar to our approach .", "entities": []}, {"text": "They suggest a joint learning approach , modeling a sequential relationship between two tasks , entity identi\ufb01cation and target sentiment .", "entities": []}, {"text": "We take a different approach viewing each of the model components as a separate module , predicted independently and then integrated into the \ufb01nal decision module .", "entities": []}, {"text": "As we demonstrate in our experiments , this approach leads to better performance and increased \ufb02exibil-", "entities": []}, {"text": "581ity , as it allows us to decouple the learning process and learn the tasks independently .", "entities": []}, {"text": "Other modular neural architectures were recently studied for tasks combining vision and language analysis ( Andreas et al . , 2016 ;", "entities": []}, {"text": "Hu et al . , 2017 ; Yu et al . , 2018 ) , and were tailored for the grounded language setting .", "entities": []}, {"text": "To help ensure the broad applicability of our framework , we provide a general modular network formulation for sequence labeling tasks by adapting a neural - CRF to capture the task structure .", "entities": [[26, 27, "MethodName", "CRF"]]}, {"text": "This family of models , combining structured prediction with deep learning showed promising results ( Gillick et al . , 2015 ; Lample et al . , 2016 ;", "entities": [[6, 8, "TaskName", "structured prediction"]]}, {"text": "Ma and Hovy , 2016 ; Zhang et al . , 2015 ; Li and Lu , 2017 ) , by using rich representations through neural models to generate decision candidates , while utilizing an inference procedure to ensure coherent decisions .", "entities": []}, {"text": "Our main observation is that modular learning can help alleviate some of the dif\ufb01culty involved in training these powerful models .", "entities": []}, {"text": "3 Architectures for Sequence Prediction Using neural networks to generate emission potentials in CRFs was applied successfully in several sequence prediction tasks , such as word segmentation ( Chen et al . , 2017 ) , NER ( Ma and Hovy , 2016 ; Lample et al . , 2016 ) , chunking and PoS tagging ( Liu et al . , 2018 ; Zhang et al . , 2017 ) .", "entities": [[36, 37, "TaskName", "NER"], [52, 53, "TaskName", "chunking"]]}, {"text": "A sequence is represented as a sequence of Ltokens : x=", "entities": []}, {"text": "[ x1;x2;:::;x L ] , each token corresponds to a labely2Y , whereYis the set of all possible tags .", "entities": []}, {"text": "An inference procedure is designed to \ufb01nd the most probable sequence y\u0003=", "entities": []}, {"text": "[ y1;y2;:::;y L ] by solving , either exactly or approximately , the following optimization problem : y\u0003= arg max yP(yjx ): Despite the difference in tasks , these models follow a similar general architecture : ( 1 ) Characterlevel information , such as pre\ufb01x , suf\ufb01x and capitalization , is represented through a character embedding layer learned using a bi - directional LSTM ( BiLSTM ) .", "entities": [[63, 64, "MethodName", "LSTM"], [65, 66, "MethodName", "BiLSTM"]]}, {"text": "( 2 ) Word - level information is obtained through a word embedding layer .", "entities": []}, {"text": "( 3 ) The two representations are concatenated to represent an input token , used as input to a word - level BiLSTM which generates the emission potentials for a succeeding CRF .", "entities": [[22, 23, "MethodName", "BiLSTM"], [31, 32, "MethodName", "CRF"]]}, {"text": "( 4 ) The CRF is used as an inference layer to generate the globally - normalized probability of possible tag", "entities": [[4, 5, "MethodName", "CRF"]]}, {"text": "sequences.3.1 CRF Layer A CRF model describes the probability of predicted labels y , given a sequence xas input , as P\u0003(yjx )", "entities": [[1, 2, "MethodName", "CRF"], [4, 5, "MethodName", "CRF"]]}, {"text": "= e\b(x;y ) Z ; whereZ = P ~ye\b(x;~y)is the partition function that marginalize over all possible assignments to the predicted labels of the sequence , and \b(x;y)is the scoring function , which is de\ufb01ned as : \b(x;y )", "entities": []}, {"text": "= X t \u001e ( x;yt ) + ( yt\u00001;yt ):", "entities": []}, {"text": "The partition function Zcan be computed ef\ufb01ciently via the forward - backward algorithm .", "entities": []}, {"text": "The term \u001e ( x;yt)corresponds to the score of a particular tagytat positiontin the sequence , and   ( yt\u00001;yt)represents the score of transition from the tag at position t\u00001to the tag at position t. In the Neural CRF model , \u001e ( x;yt)is generated by the aforementioned Bi - LSTM while   ( yt\u00001;yt ) by a transition matrix .", "entities": [[38, 39, "MethodName", "CRF"], [50, 51, "MethodName", "LSTM"]]}, {"text": "4 Functional Decomposition of Composite Tasks To accommodate our task decomposition approach , we \ufb01rst de\ufb01ne the notion of partial labels , and then discuss different neural architectures capturing the dependencies between the modules trained over the different partial labels .", "entities": []}, {"text": "Partial Labels and Task Decomposition : Given a learning task , de\ufb01ned over an output space y2 Y , whereYis the set of all possible tags , each speci\ufb01c label yis decomposed into a set of partial labels , fy0;::;ykg .", "entities": []}, {"text": "We refer to yas the fulllabel .", "entities": []}, {"text": "According to this de\ufb01nition , a speci\ufb01c assignment to allkpartial labels de\ufb01nes a single full label .", "entities": []}, {"text": "Note the difference between partially labeled data ( Cour et al . , 2011 ) , in which instances can have more than a single full label , and our setup in which the labels are partial .", "entities": []}, {"text": "In all our experiments , the partial labels refer to two sub - tasks , ( 1 ) a segmentation task , identifying Beginning , Inside andOutside of an entity or aspect .", "entities": []}, {"text": "( 2 ) one or more type recognition tasks , recognizing the aspect type and/or the sentiment polarity associated with it .", "entities": []}, {"text": "Hence , a tag ytat locationtis divided into yseg tandytyp t , corresponding to segmentation and type ( sentiment type here ) respectively .", "entities": []}, {"text": "Fig .", "entities": []}, {"text": "1 provides an example of the", "entities": []}, {"text": "582target - sentiment task .", "entities": []}, {"text": "Note that the sentiment labels do not capture segmentation information .", "entities": []}, {"text": "TextABCNews'PresidentTagB - neuOOChristianeAmanpourExclusiveInterviewwithSegSentiMubarakE - neuB - neuE - neuB - neuE - neuOBOOEBEBEOneuOOneuneuneuneuneuO Figure 1 : Target - sentiment decomposition example .", "entities": []}, {"text": "Modular Learning architectures : We propose three different models , in which information from the partial labels can be used .", "entities": []}, {"text": "All the models have similar modules types , corresponding to the segmentation andtype sub - tasks , and the decision module for predicting the \ufb01nal task .", "entities": []}, {"text": "The modules are trained over the partial segmentation ( yseg ) and type ( ytyp ) labels , and the full label yinformation , respectively .", "entities": []}, {"text": "These three models differ in the way they share information .", "entities": []}, {"text": "Model 1 , denoted Twofold Modular , LSTM - CRF - T , is similar in spirit to multi - task learning ( Collobert et al . , 2011 ) with three separate modules .", "entities": [[7, 8, "MethodName", "LSTM"], [9, 10, "MethodName", "CRF"], [18, 22, "TaskName", "multi - task learning"]]}, {"text": "Model 2 , denoted Twofold modular Infusion , ( LSTM - CRF - TI ) and Model 3 , denoted Twofold modular Infusion with guided gating , ( LSTM - CRF - TI(g ) )", "entities": [[9, 10, "MethodName", "LSTM"], [11, 12, "MethodName", "CRF"], [28, 29, "MethodName", "LSTM"], [30, 31, "MethodName", "CRF"]]}, {"text": "both infuse information \ufb02ow from two sub - task modules into the decision module .", "entities": []}, {"text": "The difference is whether the infusion is direct or goes through a guided gating mechanism .", "entities": []}, {"text": "The three models are depicted in Fig .", "entities": []}, {"text": "2 and described in details in the following paragraphs .", "entities": []}, {"text": "In all of these models , underlying neural architecture are used for the emission potentials when CRF inference layers are applied on top .", "entities": [[16, 17, "MethodName", "CRF"]]}, {"text": "4.1 Twofold Modular Model", "entities": []}, {"text": "The twofold modular model enhances the original monolithic model by using multi - task learning with shared underlying representations .", "entities": [[11, 15, "TaskName", "multi - task learning"]]}, {"text": "The segmentation module and the type module are trained jointly with the decision module , and all the modules share information by using the same embedding level representation , as shown in Figure 2a .", "entities": []}, {"text": "Since the information above the embedding level is independent , the LSTM layers in the different modules do not share information , so we refer to these layers of each module as private .", "entities": [[11, 12, "MethodName", "LSTM"]]}, {"text": "The segmentation module predicts the segmentation BIO labels at position tof the sequence by using the representations extracted from its private word level bi - directional LSTM ( denoted as Hseg)as emission for a individual CRF : hseg t = Hseg(et;\u0000 ! hseg t\u00001;\u0000 ! hseg t+1 ) ; \u001e ( x;yseg t )", "entities": [[26, 27, "MethodName", "LSTM"], [35, 36, "MethodName", "CRF"]]}, {"text": "= Wseg|hseg t+bseg ; where Wsegandbsegdenote the parameters of the segmentation module emission layer , and Hsegdenotes its private LSTM layer .", "entities": [[19, 20, "MethodName", "LSTM"]]}, {"text": "This formulation allows the model to forge the segmentation path privately through backpropagation by providing the segmentation information ysegindividually , in addition to the complete tag information y.", "entities": []}, {"text": "The type module , using ytyp , is constructed in a similar way .", "entities": []}, {"text": "By using representations from the its own private LSTM layers , the type module predicts the sentiment ( entity ) type at position tof the sequence : htyp t = Htyp(et;\u0000 !", "entities": [[8, 9, "MethodName", "LSTM"]]}, {"text": "htyp t\u00001;\u0000 !", "entities": []}, {"text": "htyp t+1 ) ; \u001e ( x;ytyp t )", "entities": []}, {"text": "= Wtyp|htyp t+btyp : Both the segmentation information ysegand the type information ytypare provided together with the complete tag sequence y , enabling the model to learn segmentation and type recognition simultaneously using two different paths .", "entities": []}, {"text": "Also , the decomposed tags naturally augment more training data to the model , avoiding over-\ufb01tting due to more complicated structure .", "entities": []}, {"text": "The shared representation beneath the private LSTMs layers are updated via the back - propagated errors from all the three modules .", "entities": []}, {"text": "4.2 Two - fold Modular Infusion Model", "entities": []}, {"text": "The twofold modular infusion model provides a stronger connection between the functionalities of the two sub - tasks modules and the \ufb01nal decision module , differing from multi - task leaning .", "entities": []}, {"text": "In this model , instead of separating the pathways from the decision module as in the previous twofold modular model , the segmentation and the type representation are used as input to the \ufb01nal decision module .", "entities": []}, {"text": "The model structure is shown in Figure 2b , and can be described formally as :", "entities": []}, {"text": "Iseg t = Wseg|hseg t+bseg ; Ityp t = Wtyp|htyp t+btyp ; St = W|[ht;Iseg t;Ityp t ] + b ; whereStis the shared \ufb01nal emission potential to the CRF layer in the decision module , and ; is the", "entities": [[29, 30, "MethodName", "CRF"]]}, {"text": "583 SEGTYPDESEmbeddings(a ) LSTM - CRF - T SEGTYPDESEmbeddings ( b ) LSTM - CRF - TI SEGTYPDES\u03c3\u03c3\u00d7\u00d7Embeddings ( c ) LSTM - CRF - TI ( G ) Figure 2 : Three modular models for task decomposition .", "entities": [[3, 4, "MethodName", "LSTM"], [5, 6, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [21, 22, "MethodName", "LSTM"], [23, 24, "MethodName", "CRF"]]}, {"text": "In them , blue blocks are segmentation modules , detecting entity location and segmentation , and yellow blocks are the type modules , recognizing the entity type or sentiment polarity .", "entities": []}, {"text": "Green blocks are the \ufb01nal decision modules , integrating all the decisions .", "entities": []}, {"text": "( G ) refers to \u201c Guided Gating \u201d concatenation operator , combining the representation from the decision module and that from the type module and the segmentation module .", "entities": []}, {"text": "The term \u201c Infusion \u201d used for naming this module is intended to indicate that both modules actively participate in the \ufb01nal decision process , rather than merely form two independent paths as in the twofold modular model .", "entities": []}, {"text": "This formulation provides an alternative way of integrating the auxiliary sub - tasks back into the major task in the neural structure to help improve learning .", "entities": []}, {"text": "4.3 Guided Gating Infusion In the previous section we described a way of infusing information from other modules naively by simply concatenating them .", "entities": []}, {"text": "But intuitively , the hidden representation from the decision module plays an important role as it is directly related to the \ufb01nal task we are interested in .", "entities": []}, {"text": "To effectively use the information from other modules forming sub - tasks , we design a gating mechanism to dynamically control the amount of information \ufb02owing from other modules by infusing the expedient part while excluding the irrelevant part , as shown in Figure 2c .", "entities": []}, {"text": "This gating mechanism uses the information from the decision module to guide the information from other modules , thus we name it as guided gating infusion , which we describe formally as follows : Iseg t=\u001b(W1ht+b1 ) ( Wseg|hseg t+bseg ) ; Ityp t=\u001b(W2ht+b2 ) ( Wtyp|htyp t+btyp ) ;", "entities": []}, {"text": "St = W|[ht;Iseg t;Ityp t ] + b ; where\u001bis the logistic sigmoid function and   is the element - wise multiplication .", "entities": []}, {"text": "The fW1;W2;b1;b2gare the parameters of these guided gating , which are updated during the training to maximize the overall sequence labeling performance.5 Learning using Full and Partial Labels Our objective naturally rises from the model we described in the text .", "entities": []}, {"text": "Furthermore , as our experiments show , it is easy to generalize this objective , to a \u201c semi - supervised \u201d setting , in which the learner has access to only a few fully labeled examples and additional partially labeled examples .", "entities": []}, {"text": "E.g. , if only segmentation is annotated but the type information is missing .", "entities": []}, {"text": "The loss function is a linear combination of the negative log probability of each sub - tasks , together with the decision module :", "entities": [[1, 2, "MetricName", "loss"]]}, {"text": "J=\u0000NX ilogP(yijxi ) + \u000b logP(yseg ( i)jx(i ) )", "entities": []}, {"text": "+ \f logP(ytyp(i)jx(i ) ) ; ( 1 ) whereNis the number of examples in the training set , ysegandytypare the decomposed segmentation and type tags corresponding to the two sub - task modules , and \u000b and \f are the hyperparameters controlling the importance of the two modules contributions respectively .", "entities": []}, {"text": "If the training example is fully labeled with both segmentation and type annotated , training is straightforward ; if the training example is partially labeled , e.g. , only with segmentation but without type , we can set the log probability of the type module and the decision module 0and only train the segmentation module .", "entities": []}, {"text": "This formulation provides extra \ufb02exibility of using partially annotated corpus together with fully annotated corpus to improve the overall performance .", "entities": []}, {"text": "6 Experimental Evaluation Our experimental evaluation is designed to evaluate the two key aspects of our model : ( Q1 )", "entities": []}, {"text": "Can the modular architecture alleviate the dif\ufb01culty of learning the \ufb01nal task ?", "entities": []}, {"text": "To answer", "entities": []}, {"text": "584this question , we compare our modular architecture to the traditional neural - CRF model and several recent competitive models for sequence labeling combining inference and deep learning .", "entities": [[13, 14, "MethodName", "CRF"]]}, {"text": "The results are summarized in Tables 1 - 3 . ( Q2 ) Can partial labels be used effectively as a new form of weak - supervision ?", "entities": []}, {"text": "To answer this question we compared the performance of the model when trained using disjoint sets of partial and full labels , and show that adding examples only associated with partial labels , can help boost performance on the \ufb01nal task .", "entities": []}, {"text": "The results are summarized in Figures 3 - 5 . 6.1 Experimental Settings 6.1.1 Datasets We evaluated our models over three different sentiment analysis tasks adapted for sequence prediction .", "entities": [[22, 24, "TaskName", "sentiment analysis"]]}, {"text": "We included additional results for multilingual NER in the Appendix for reference .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "Target Sentiment Datasets We evaluated our models on the targeted sentiment dataset released by Mitchell et al .", "entities": []}, {"text": "( 2013 ) , which consists of entity and sentiment annotations on both English and Spanish tweets .", "entities": []}, {"text": "Similar to previous studies ( Mitchell et al . , 2013 ; Zhang et al . , 2015 ; Li and Lu , 2017 ) , our task focuses on people and organizations ( collapsed into volitional named entities tags ) and the sentiment associated with their description in tweets .", "entities": []}, {"text": "After this processing , the labels of each tweets are composed of both segmentation ( entity spans ) and types ( sentiment tags ) .", "entities": []}, {"text": "We used the original 10 - fold cross validation splits to calculate averaged F1 score , using 10 % of the training set for development .", "entities": [[13, 15, "MetricName", "F1 score"]]}, {"text": "We used the same metrics in Zhang et al . ( 2015 ) and Li and Lu ( 2017 ) for a fair comparison .", "entities": []}, {"text": "Aspect Based Sentiment Analysis Datasets We used the Restaurants dataset provided by SemEval", "entities": [[2, 4, "TaskName", "Sentiment Analysis"]]}, {"text": "2016 Task 5 subtask 1 , consisting of opinion target ( aspect ) expression segmentation , aspect classi\ufb01cation and matching sentiment prediction .", "entities": []}, {"text": "In the original task de\ufb01nition , the three tasks were designed as a pipeline , and assumed gold aspect labels when predicting the matching sentiment labels .", "entities": []}, {"text": "Instead , our model deals with the challenging end - to - end setting by casting the problem as a sequence labeling task , labeling each aspect segmentwith the aspect label and sentiment polarity2 .", "entities": []}, {"text": "Subjective Polarity Disambiguation Datasets We adapted the SemEval 2013 Task 2 subtask A as another task to evaluate our model .", "entities": [[7, 9, "DatasetName", "SemEval 2013"]]}, {"text": "In this task , the system is given a marked phrase inside a longer text , and is asked to label its polarity .", "entities": []}, {"text": "Unlike the original task , we did not assume the sequence is known , resulting in two decisions , identifying subjective expressions ( i.e. , a segmentation task ) and labeling their polarity , which can be modeled jointly as a sequence labeling task .", "entities": []}, {"text": "6.1.2 Input Representation and Model Architecture Following previous studies ( Ma and Hovy , 2016 ; Liu et", "entities": []}, {"text": "al . , 2018 ) showing that the word embedding choice can signi\ufb01cantly in\ufb02uence performance , we used the pre - trained GloVe 100 dimension Twitter embeddings only for all tasks in the main text .", "entities": [[22, 23, "MethodName", "GloVe"]]}, {"text": "All the words not contained in these embeddings ( OOV , out - of - vocabulary words ) are treated as an \u201c unknown \u201d word .", "entities": []}, {"text": "Our models were deployed with minimal hyper parameters tuning , and can be brie\ufb02y summarized as : the character embeddings has dimension 30 , the hidden layer dimension of the character level LSTM is 25 , and the hidden layer of the word level LSTM has dimension 300 .", "entities": [[32, 33, "MethodName", "LSTM"], [44, 45, "MethodName", "LSTM"]]}, {"text": "Similar to Liu et al .", "entities": []}, {"text": "( 2018 ) , we also applied highway networks ( Srivastava et al . , 2015 ) from the character level LSTM to the word level LSTM .", "entities": [[7, 9, "MethodName", "highway networks"], [21, 22, "MethodName", "LSTM"], [26, 27, "MethodName", "LSTM"]]}, {"text": "In our pilot study , we shrank the number of parameters in our modular architectures to around one third such that the total number of parameter is similar as that in the LSTM - CRF model , but we did not observe a signi\ufb01cant performance change so we kept them as denoted .", "entities": [[8, 11, "HyperparameterName", "number of parameters"], [32, 33, "MethodName", "LSTM"], [34, 35, "MethodName", "CRF"]]}, {"text": "The values of \u000b and \f in the objective function were always set to 1.0 .", "entities": []}, {"text": "6.1.3", "entities": []}, {"text": "Learning We used BIOES tagging scheme but only during the training and convert them back to BIO2 for evaluation for all tasks3 .", "entities": []}, {"text": "Our model was implemented using pytorch ( Paszke et al . , 2017 ) .", "entities": []}, {"text": "To help improve performance we parallelized the for2using only the subset of the data containing sequence information 3Using BIOES improves model complexity in Training , as suggested in previous studies .", "entities": []}, {"text": "But to make a fair comparison to most previous work , who used BIO2 for evaluation , we converted labels to BIO2 system in the testing stage .", "entities": []}, {"text": "( To be clear , using BIOES in the testing actually yields higher f1 scores in the testing stage , which some previous studies used unfairly )", "entities": []}, {"text": "585ward algorithm and the Viterbi algorithm on the GPU .", "entities": []}, {"text": "All the experiments were run on NVIDIA GPUs .", "entities": []}, {"text": "We used the Stochastic Gradient Descent ( SGD ) optimization of batch size 10 , with a momentum 0.9 to update the model parameters , with the learning rate 0.01 , the decay rate 0.05 ; The learning rate decays over epochs by \u0011=(1 + e\u0003\u001a ) , where\u0011is the learning rate , eis the epoch number , and\u001ais the decay rate .", "entities": [[3, 6, "MethodName", "Stochastic Gradient Descent"], [7, 8, "MethodName", "SGD"], [11, 13, "HyperparameterName", "batch size"], [27, 29, "HyperparameterName", "learning rate"], [32, 34, "HyperparameterName", "decay rate"], [37, 39, "HyperparameterName", "learning rate"], [50, 52, "HyperparameterName", "learning rate"], [55, 57, "HyperparameterName", "epoch number"], [60, 62, "HyperparameterName", "decay rate"]]}, {"text": "We used gradient clip to force the absolute value of the gradient to be less than 5.0 .", "entities": []}, {"text": "We used early - stop to prevent over-\ufb01tting , with a patience of 30 and at least 120 epochs .", "entities": []}, {"text": "In addition to dropout , we used Adversarial Training ( AT ) ( Goodfellow et", "entities": []}, {"text": "al . , 2014 ) , to regularize our model as the parameter numbers increase with modules .", "entities": []}, {"text": "AT improves robustness to small worst - case perturbations by computing the gradients of a loss function w.r.t .", "entities": [[15, 16, "MetricName", "loss"]]}, {"text": "the input .", "entities": []}, {"text": "In this study , \u000b and \f in Eq . 1 are both set to 1:0 , and we leave other tuning choices for future investigation .", "entities": []}, {"text": "6.2 Q1 :", "entities": []}, {"text": "Monolithic vs. Modular Learning Our \ufb01rst set of results are designed to compare our modular learning models , utilize partial labels decomposition , with traditional monolithic models , that learn directly over the full labels .", "entities": []}, {"text": "In all three tasks , we compare with strong sequence prediction models , including LSTM - CRF ( Lample et al . , 2016 ) , which is directly equivalent to our baseline model ( i.e. , \ufb01nal task decision without the modules ) , and LSTM - CNN - CRF ( Ma and Hovy , 2016 ) and LSTM - CRF - LM ( Liu et al . , 2018 ) which use a richer latent representation for scoring the emission potentials .", "entities": [[14, 15, "MethodName", "LSTM"], [16, 17, "MethodName", "CRF"], [46, 47, "MethodName", "LSTM"], [50, 51, "MethodName", "CRF"], [59, 60, "MethodName", "LSTM"], [61, 62, "MethodName", "CRF"]]}, {"text": "Target Sentiment task", "entities": []}, {"text": "The results are summarized in Tab .", "entities": []}, {"text": "1 .", "entities": []}, {"text": "We also compared our models with recently published state - of - the - art models on these datasets .", "entities": []}, {"text": "To help ensure a fair comparison with Ma et al .", "entities": []}, {"text": "which does not use inference , we also included the results of our model without the CRF layer ( denoted LSTM - Ti(g ) ) .", "entities": [[16, 17, "MethodName", "CRF"], [20, 21, "MethodName", "LSTM"]]}, {"text": "All of our models beat the state - of - the - art results by a large margin .", "entities": []}, {"text": "The source code and experimental setup are available online4 .", "entities": []}, {"text": "Aspect Based Sentiment We evaluated our models on two tasks : The \ufb01rst uses two modules , for identifying the position of the aspect in the text ( i.e. , chunking ) and the aspect category prediction 4https://github.com/cosmozhang/ Modular_Neural_CRFSystem Architecture Eng .", "entities": [[30, 31, "TaskName", "chunking"]]}, {"text": "Spa .", "entities": []}, {"text": "Zhang", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2015)Pipeline 40.06 43.04 Joint 39.67 43.02 Collapsed 38.36 40.00 Li and Lu ( 2017)SS 40.11 42.75 + embeddings 43.55 44.13 + POS tags 42.21 42.89 + semiMarkov 40.94 42.14 Ma et al .", "entities": []}, {"text": "( 2018 ) HMBi - GRU 42.87 45.61 baseline LSTM - CRF 49.89 48.84", "entities": [[5, 6, "MethodName", "GRU"], [9, 10, "MethodName", "LSTM"], [11, 12, "MethodName", "CRF"]]}, {"text": "This workLSTM - Ti(g ) 45.84 46.59 LSTM - CRF - T 51.34 49.47 LSTM - CRF - Ti 51.64 49.74 LSTM - CRF - Ti(g ) 52.15 50.50 Table 1 : Comparing our models with the competing models on the target sentiment task .", "entities": [[7, 8, "MethodName", "LSTM"], [9, 10, "MethodName", "CRF"], [14, 15, "MethodName", "LSTM"], [16, 17, "MethodName", "CRF"], [21, 22, "MethodName", "LSTM"], [23, 24, "MethodName", "CRF"]]}, {"text": "The results are on the full prediction of both segmentation and sentiment .", "entities": []}, {"text": "( denoted E+A ) .", "entities": []}, {"text": "The second adds a third module that predicts the sentiment polarity associated with the aspect ( denoted E+A+S ) .", "entities": []}, {"text": "I.e. , for a given sentence , label its entity span , the aspect category of the entity and the sentiment polarity of the entity at the same time .", "entities": []}, {"text": "The results over four languages are summarized in Tab .", "entities": []}, {"text": "2 . In all cases , our modular approach outperforms all monolithic approaches .", "entities": []}, {"text": "Subjective Phrase Identi\ufb01cation and Classi\ufb01cation", "entities": []}, {"text": "This dataset contains tweets annotated with sentiment phrases , used for training the models .", "entities": []}, {"text": "As in the original SemEval task , it is tested in two settings , in - domain , where the test data also consists of tweets , and out - of - domain , where the test set consists of SMS text messages .", "entities": []}, {"text": "We present the results of experiments on these data set in Table 3 . 6.3 Q2 : Partial Labels as Weak Supervision", "entities": []}, {"text": "Our modular architecture is a natural \ufb01t for learning with partial labels .", "entities": []}, {"text": "Since the modular architecture decomposes the \ufb01nal task into sub - tasks , the absence of certain partial labels is permitted .", "entities": []}, {"text": "In this case , only the module corresponding to the available partial labels will be updated while the other parts of the model stay \ufb01xed .", "entities": []}, {"text": "This property can be exploited to reduce the supervision effort by de\ufb01ning semi - supervised learning protocols that use partial - labels when the full labels are not available , or too costly to annotate .", "entities": []}, {"text": "E.g. , in the target sentiment task , segmentation labels are signi\ufb01cantly easier to annotate .", "entities": []}, {"text": "To demonstrate this property we conducted two sets of experiments .", "entities": []}, {"text": "The \ufb01rst investigates how the decision module can effectively integrate the knowledge independently learned by sub - tasks", "entities": []}, {"text": "586ModelsEnglish Spanish Dutch Russian E+A E+A+S E+A", "entities": []}, {"text": "E+A+S E+A E+A+S E+A", "entities": []}, {"text": "E+A+S LSTM - CNN - CRF(Ma and Hovy , 2016 ) 58.73 44.20 64.32 50.34 51.62 36.88 58.88 38.13 LSTM - CRF - LM(Liu et al . , 2018 ) 62.27 45.04 63.63 50.15 51.78 34.77 62.18 38.80 LSTM - CRF 59.11 48.67 62.98 52.10 51.35 37.30 63.41 42.47 LSTM - CRF - T 60.87 49.59 64.24 52.33 52.79 37.61 64.72 43.01 LSTM - CRF - TI 63.11 50.19 64.40 52.85 53.05 38.07 64.98 44.03 LSTM - CRF - TI(g ) 64.74 51.24 66.13 53.47 53.63 38.65 65.64 45.65 Table 2 : Comparing our models with recent results on the Aspect Sentiment datasets .", "entities": [[1, 2, "MethodName", "LSTM"], [19, 20, "MethodName", "LSTM"], [21, 22, "MethodName", "CRF"], [38, 39, "MethodName", "LSTM"], [40, 41, "MethodName", "CRF"], [49, 50, "MethodName", "LSTM"], [51, 52, "MethodName", "CRF"], [62, 63, "MethodName", "LSTM"], [64, 65, "MethodName", "CRF"], [75, 76, "MethodName", "LSTM"], [77, 78, "MethodName", "CRF"]]}, {"text": "Models Tweets SMS LSTM - CNN - CRF 35.82 23.23 LSTM - CRF - LM 35.67 23.25 LSTM - CRF 34.15 26.28 LSTM - CRF - T 35.37 27.11 LSTM - CRF - Ti 36.52 28.05 LSTM - CRF - Ti(g ) 37.71 29.24 Table 3 : Comparing our models with competing models on the subjective sentiment task .", "entities": [[3, 4, "MethodName", "LSTM"], [7, 8, "MethodName", "CRF"], [10, 11, "MethodName", "LSTM"], [12, 13, "MethodName", "CRF"], [17, 18, "MethodName", "LSTM"], [19, 20, "MethodName", "CRF"], [22, 23, "MethodName", "LSTM"], [24, 25, "MethodName", "CRF"], [29, 30, "MethodName", "LSTM"], [31, 32, "MethodName", "CRF"], [36, 37, "MethodName", "LSTM"], [38, 39, "MethodName", "CRF"]]}, {"text": "modules using different partial labels .", "entities": []}, {"text": "We quantify this ability by providing varying amounts of full labels to support the integration process .", "entities": []}, {"text": "The second set studies the traditional semi - supervised settings , where we have a handful of full labels , but we have a larger amount of partial labels .", "entities": []}, {"text": "Modular Knowledge Integration The modular architecture allows us to train each model using data obtained separately for each task , and only use a handful of examples annotated for the \ufb01nal task in order to integrate the knowledge learned by each module into a uni\ufb01ed decision .", "entities": []}, {"text": "We simulated these settings by dividing the training data into three folds .", "entities": []}, {"text": "We associated each one of the \ufb01rst two folds with the two sub - task modules .", "entities": []}, {"text": "Each one of the these folds only included the partial labels relevant for that sub - task .", "entities": []}, {"text": "We then used gradually increasing amounts of the third fold , consisting of the full labels , for training the decision module .", "entities": []}, {"text": "Fig .", "entities": []}, {"text": "3 describes the outcome for targetsentiment , comparing a non - modular model using only the full labels , with the modular approach , which uses the full labels for knowledge integration .", "entities": []}, {"text": "Results show that even when very little full data is available results signi\ufb01cantly improve .", "entities": []}, {"text": "Additional results show the same pattern for subjective phrase identi\ufb01cation and classi\ufb01cation are included in the Appendix .", "entities": []}, {"text": "Learning with Partially Labeled Data Partially - labeled data can be cheaper and easier to obtain , especially for low - resource languages .", "entities": []}, {"text": "In this set of experiments , we model these settings 2833384348 20%40%60%80%100 % Modularized non - Modularized(a )", "entities": []}, {"text": "Spanish 2833384348 20%40%60%80%100 % Modularized non - Modularized ( b ) English Figure 3 : Modular knowledge integration results on the Target Sentiment Datasets .", "entities": []}, {"text": "The x - axis is the amount of percentage of the third fold of full labels .", "entities": []}, {"text": "The \u201c nonmodularized \u201d means we only provide fully labeled data from the third fold .", "entities": []}, {"text": "384144475053 0%20%40%60%80 % LSTM - CRF - TI(g ) ( seg ) LSTM - CRF - TI(g ) ( typ ) LSTM - CRF LSTM - CRF - TI(g ) with fully labeled ( a )", "entities": [[3, 4, "MethodName", "LSTM"], [5, 6, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [21, 22, "MethodName", "LSTM"], [23, 24, "MethodName", "CRF"], [24, 25, "MethodName", "LSTM"], [26, 27, "MethodName", "CRF"]]}, {"text": "Spanish 3739.842.645.448.251", "entities": []}, {"text": "0%20%40%60%80 % LSTM - CRF - TI(g ) ( seg ) LSTM - CRF - TI(g ) ( typ ) LSTM - CRF LSTM - CRF - TI(g ) with fully labeled ( b ) English Figure 4 : The fully labeled data was \ufb01xed to 20 % of the whole training set , and gradually adding data with only segmentation information ( Magenta ) , or with only type information ( Orange ) , and test our model on the full prediction test .", "entities": [[2, 3, "MethodName", "LSTM"], [4, 5, "MethodName", "CRF"], [11, 12, "MethodName", "LSTM"], [13, 14, "MethodName", "CRF"], [20, 21, "MethodName", "LSTM"], [22, 23, "MethodName", "CRF"], [23, 24, "MethodName", "LSTM"], [25, 26, "MethodName", "CRF"]]}, {"text": "The LSTM - CRF model can only use fully labeled data as it does not decompose the task .", "entities": [[1, 2, "MethodName", "LSTM"], [3, 4, "MethodName", "CRF"]]}, {"text": "over the target - sentiment task .", "entities": []}, {"text": "The results are summarized in Fig .", "entities": []}, {"text": "4 .", "entities": []}, {"text": "We \ufb01xed the amount of full labels to 20 % of the training set , and gradually increased the amount of partially labeled data .", "entities": []}, {"text": "We studied adding segmentation and type separately .", "entities": []}, {"text": "After the model is trained in this routine , it was tested on predicting the full labels jointly on the test set .", "entities": []}, {"text": "Domain Transfer with Partially Labeled Data In our \ufb01nal analysis we considered a novel domain - adaptation settings , where we have a small amount of fully labeled in - domain data from aspect sentiment and more out - of - domain data", "entities": []}, {"text": "587 2026.53339.546 0%20%40 % SpanishEnglishFigure 5 : Domain Transfer experiments results with \ufb01xed 20 % in - domain data from aspect sentiment and varying amounts of out - of - domain data from target sentiment , shown on the x - axis .", "entities": []}, {"text": "from target sentiment .", "entities": []}, {"text": "However unlike the traditional domain - adaptation settings , the out - ofdomain data is labeled for a different task , and only shares one module with the original task .", "entities": []}, {"text": "In our experiments we \ufb01xed 20 % of the fully labeled data for the aspect sentiment task , and gradually added out - of - domain data , consisting of partial sentiment labels from the target sentiment task .", "entities": []}, {"text": "Our model successfully utilized the out - ofdomain data and improved performance on the indomain task .", "entities": []}, {"text": "The results are shown on Fig 5 . 7 Conclusions", "entities": []}, {"text": "We present and study several modular neural architectures designed for a novel learning scenario : learning from partial labels .", "entities": []}, {"text": "We experiment with several sentiment analysis tasks .", "entities": [[4, 6, "TaskName", "sentiment analysis"]]}, {"text": "Our models , inspired by cognitive neuroscience \ufb01ndings ( Jacobs et al . , 1991 ; Eysenck and Keane , 2005 ) and multitask learning , suggest a functional decomposition of the original task into two simpler sub - tasks .", "entities": []}, {"text": "We evaluate different methods for sharing information and integrating the modules into the \ufb01nal decision , such that a better model can be learned , while converging faster5 .", "entities": []}, {"text": "As our experiments show , modular learning can be used with weak supervision , using examples annotated with partial labels only .", "entities": []}, {"text": "The modular approach also provides interesting directions for future research , focusing on alleviating the supervision bottleneck by using large amount of partially labeled data that are cheaper and easy to obtain , together with only a handful amount of annotated data , a scenario especially suitable for low - resource languages .", "entities": []}, {"text": "5Convergence results are provided in the AppendixAcknowledgements We thank the reviewers for their insightful comments .", "entities": []}, {"text": "We thank the NVIDIA Corporation for their GPU donation , used in this work .", "entities": []}, {"text": "This work was partially funded by a Google Gift .", "entities": [[7, 8, "DatasetName", "Google"]]}, {"text": "References Rodrigo Agerri and German Rigau .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Robust multilingual named entity recognition with shallow semi - supervised features .", "entities": [[1, 5, "TaskName", "multilingual named entity recognition"]]}, {"text": "Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Jacob Andreas , Marcus Rohrbach , Trevor Darrell , and Dan Klein . 2016 .", "entities": []}, {"text": "Learning to compose neural networks for question answering .", "entities": [[6, 8, "TaskName", "question answering"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Meeting of the North American Association of Computational Linguistics ( NAACL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Xavier Carreras , Llu \u00b4 \u0131s M`arquez , and Llu \u00b4 \u0131s Padr \u00b4 o. 2002 .", "entities": []}, {"text": "Named entity extraction using adaboost .", "entities": []}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Conference on Computational Natural Language Learning ( CoNLL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Rich Caruana .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Multitask Learning .", "entities": []}, {"text": "Machine Learning , 28(1):41\u201375 .", "entities": []}, {"text": "Chen , Shi , Qiu , and Huang . 2017 .", "entities": []}, {"text": "Adversarial multicriteria learning for chinese word segmentation .", "entities": [[4, 7, "TaskName", "chinese word segmentation"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Meeting of the Association Computational Linguistics ( ACL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Ronan Collobert , Jason Weston , L \u00b4 eon Bottou , Michael Karlen , Koray Kavukcuoglu , and Pavel Kuksa . 2011 .", "entities": []}, {"text": "Natural Language Processing ( Almost ) from Scratch .", "entities": []}, {"text": "J. Mach .", "entities": []}, {"text": "Learn .", "entities": []}, {"text": "Res . , 12 .", "entities": []}, {"text": "Timothee Cour , Ben Sapp , and Ben Taskar .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Learning from partial labels .", "entities": []}, {"text": "Journal of Machine Learning Research , 12(May ) .", "entities": []}, {"text": "Eriguchi , Tsuruoka , and Cho . 2017 .", "entities": []}, {"text": "Learning to parse and translate improves neural machine translation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "InProc . of the Annual Meeting of the Association Computational Linguistics ( ACL ) .", "entities": []}, {"text": "M.W. Eysenck and M.T. Keane .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Cognitive Psychology : A Student \u2019s Handbook .", "entities": []}, {"text": "Psychology Press .", "entities": []}, {"text": "Norman .", "entities": []}, {"text": "Geschwind and Albert M. Galaburda . 1987 .", "entities": []}, {"text": "Cerebral lateralization : biological mechanisms , associations , and pathology .", "entities": []}, {"text": "MIT Press .", "entities": []}, {"text": "Gillick , Brunk , Vinyals , and Subramanya .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Multilingual Language Processing From Bytes .", "entities": []}, {"text": "ArXiv .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "I. J. Goodfellow , J. Shlens , and C. Szegedy .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Explaining and Harnessing Adversarial Examples .", "entities": []}, {"text": "ArXiv e - prints .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Ronghang Hu , Jacob Andreas , Marcus Rohrbach , Trevor Darrell , and Kate Saenko . 2017 .", "entities": []}, {"text": "Learning to reason : End - to - end module networks for visual question answering .", "entities": [[12, 15, "DatasetName", "visual question answering"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the International Conference on Computer Vision ( ICCV ) .", "entities": []}, {"text": "588Jacobs , Jordan , and Barto .", "entities": []}, {"text": "1991 .", "entities": []}, {"text": "Task decomposition through competition in a modular connectionist architecture : The what and where vision tasks .", "entities": []}, {"text": "Cognitive Science , 15(2 ) .", "entities": []}, {"text": "Stephen M. Kosslyn .", "entities": []}, {"text": "1987 .", "entities": []}, {"text": "Seeing and Imagining in the Cerebral Hemispheres : A Computational Approach .", "entities": []}, {"text": "Psychological Review , 94(2):148\u2013175 .", "entities": []}, {"text": "Guillaume Lample , Miguel Ballesteros , Kazuya Kawakami , Sandeep Subramanian , and Chris Dyer . 2016 .", "entities": []}, {"text": "Neural architectures for named entity recognition .", "entities": [[3, 6, "TaskName", "named entity recognition"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Meeting of the North American Association of Computational Linguistics ( NAACL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Hao Li and Wei Lu . 2017 .", "entities": []}, {"text": "Learning latent sentiment scopes for entity - level sentiment analysis .", "entities": [[8, 10, "TaskName", "sentiment analysis"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the National Conference on Arti\ufb01cial Intelligence ( AAAI )", "entities": []}, {"text": ".", "entities": []}, {"text": "Liyuan Liu , Jingbo Shang , Frank F. Xu , Xiang Ren , Huan Gui , Jian Peng , and Jiawei Han . 2018 .", "entities": []}, {"text": "Empower sequence labeling with task - aware neural language model .", "entities": []}, {"text": "In Proc .", "entities": []}, {"text": "of the National Conference on Arti\ufb01cial Intelligence ( AAAI )", "entities": []}, {"text": ".", "entities": []}, {"text": "Minh - Thang Luong .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Multi - Task Sequence To Sequence Learning .", "entities": [[3, 6, "MethodName", "Sequence To Sequence"]]}, {"text": "In Proc .", "entities": []}, {"text": "International Conference on Learning Representation ( ICLR ) .", "entities": []}, {"text": "Dehong Ma , Sujian Li , and Houfeng Wang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Joint learning for targeted sentiment analysis .", "entities": [[4, 6, "TaskName", "sentiment analysis"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Conference on Empirical Methods for Natural Language Processing ( EMNLP )", "entities": []}, {"text": ".", "entities": []}, {"text": "Xuezhe Ma and Eduard Hovy . 2016 .", "entities": []}, {"text": "End - to - end sequence labeling via bi - directional lstm - cnns - crf .", "entities": [[11, 12, "MethodName", "lstm"], [15, 16, "MethodName", "crf"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Meeting of the Association Computational Linguistics ( ACL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Mortimer Mishkin , Leslie G. Ungerleider , and Kathleen A. Macko .", "entities": []}, {"text": "1983 .", "entities": []}, {"text": "Object vision and spatial vision : two cortical pathways .", "entities": []}, {"text": "Margaret Mitchell , Jacqui Aguilar , Theresa Wilson , and Benjamin Van Durme .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Open domain targeted sentiment .", "entities": []}, {"text": "In Proc .", "entities": []}, {"text": "of the Conference on Empirical Methods for Natural Language Processing ( EMNLP )", "entities": []}, {"text": ".", "entities": []}, {"text": "Joel Nothman , Nicky Ringland , Will Radford , Tara Murphy , and James R. Curran .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Learning multilingual named entity recognition from wikipedia .", "entities": [[1, 5, "TaskName", "multilingual named entity recognition"]]}, {"text": "Artif .", "entities": []}, {"text": "Intell . , 194:151\u2013175 .", "entities": []}, {"text": "Adam Paszke , Sam Gross , Soumith Chintala , Gregory Chanan , Edward Yang , Zachary DeVito , Zeming Lin , Alban Desmaison , Luca Antiga , and Adam Lerer . 2017 .", "entities": [[0, 1, "MethodName", "Adam"], [28, 29, "MethodName", "Adam"]]}, {"text": "Automatic differentiation in pytorch .", "entities": []}, {"text": "InNIPS - W .", "entities": []}, {"text": "Maria Pontiki , Dimitris Galanis , Haris Papageorgiou , Ion Androutsopoulos , Suresh Manandhar , ALSmadi Mohammad , Mahmoud Al - Ayyoub , Yanyan Zhao , Bing Qin , Orph \u00b4 ee De Clercq , et al .", "entities": []}, {"text": "2016.Semeval-2016 task 5 : Aspect based sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 10th international workshop on semantic evaluation ( SemEval-2016 ) .", "entities": []}, {"text": "L. Ratinov and D. Roth . 2009 .", "entities": []}, {"text": "Design challenges and misconceptions in named entity recognition .", "entities": [[3, 4, "TaskName", "misconceptions"], [5, 8, "TaskName", "named entity recognition"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Conference on Computational Natural Language Learning ( CoNLL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Rueckl , Cave , and Kosslyn .", "entities": []}, {"text": "1989 .", "entities": []}, {"text": "Why are \u201d What \u201d and \u201d Where \u201d Processed by Separate Cortical Visual Systems ?", "entities": []}, {"text": "A Computational Investigation .", "entities": []}, {"text": "cognitive neuroscience .", "entities": []}, {"text": "Tjong Kim Sang and Erik F. 2002 .", "entities": []}, {"text": "Introduction to the conll-2002 shared task : Language - independent named entity recognition .", "entities": [[10, 13, "TaskName", "named entity recognition"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Conference on Computational Natural Language Learning ( CoNLL )", "entities": []}, {"text": ".", "entities": []}, {"text": "Tjong Kim Sang , Erik F. , and Fien De Meulder .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Introduction to the conll-2003 shared task : Language - independent named entity recognition .", "entities": [[3, 4, "DatasetName", "conll-2003"], [10, 13, "TaskName", "named entity recognition"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Conference on Computational Natural Language Learning ( CoNLL )", "entities": []}, {"text": ".", "entities": []}, {"text": "dos Santos and Guimar \u02dcaes .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Boosting named entity recognition with neural character embeddings .", "entities": [[1, 4, "TaskName", "named entity recognition"]]}, {"text": "InProc . of the Annual Meeting of the Association Computational Linguistics ( ACL ) .", "entities": []}, {"text": "Rupesh Kumar Srivastava , Klaus Greff , and J \u00a8urgen Schmidhuber .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "2015 .", "entities": []}, {"text": "Highway Networks .", "entities": [[0, 2, "MethodName", "Highway Networks"]]}, {"text": "ArXiv eprints .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Shubham Toshniwal , Hao Tang , Liang Lu , and Karen Livescu . 2017 .", "entities": []}, {"text": "Multitask learning with low - level auxiliary tasks for encoder - decoder based speech recognition .", "entities": [[13, 15, "TaskName", "speech recognition"]]}, {"text": "In INTERSPEECH .", "entities": []}, {"text": "Theresa Wilson , Zornitsa Kozareva , Preslav Nakov , Alan Ritter , Sara Rosenthal , and Stoyanov Veselin .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Semeval-2013 task 2 : Sentiment analysis in twitter .", "entities": [[0, 3, "DatasetName", "Semeval-2013 task 2"], [4, 6, "TaskName", "Sentiment analysis"]]}, {"text": "Licheng Yu , Zhe Lin , Xiaohui Shen , Jimei Yang , Xin Lu , Mohit Bansal , and Tamara L Berg .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Mattnet : Modular attention network for referring expression comprehension .", "entities": [[6, 9, "TaskName", "referring expression comprehension"]]}, {"text": "arXiv .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Meishan Zhang , Yue Zhang , and Duy Tin V o. 2015 .", "entities": []}, {"text": "Neural networks for open domain targeted sentiment .", "entities": []}, {"text": "In Proc .", "entities": []}, {"text": "of the Conference on Empirical Methods for Natural Language Processing ( EMNLP )", "entities": []}, {"text": ".", "entities": []}, {"text": "Xiao Zhang , Yong Jiang , Hao Peng , Kewei Tu , and Dan Goldwasser . 2017 .", "entities": []}, {"text": "Semi - supervised structured prediction with neural crf autoencoder .", "entities": [[3, 5, "TaskName", "structured prediction"], [7, 8, "MethodName", "crf"], [8, 9, "MethodName", "autoencoder"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Conference on Empirical Methods for Natural Language Processing ( EMNLP )", "entities": []}, {"text": ".", "entities": []}, {"text": "Jie Zhou and Wei Xu .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "End - to - end learning of semantic role labeling using recurrent neural networks .", "entities": [[7, 10, "TaskName", "semantic role labeling"]]}, {"text": "In Proc .", "entities": []}, {"text": "of the Annual Meeting of the Association Computational Linguistics ( ACL ) .", "entities": []}, {"text": "589A Examples of Task Decomposition In Figure 6 , we show an example of task decomposition for standard NER .", "entities": [[18, 19, "TaskName", "NER"]]}, {"text": "Figure 6 : An example of NER decomposition .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "In Figure 7 , we show another example of task decomposition for target sentiment , in addition to the one in the main text .", "entities": []}, {"text": "Figure 7 : An extra example of target sentiment decomposition .", "entities": []}, {"text": "B", "entities": []}, {"text": "Full Experimental Results on Target Sentiment The complete results of our experiments on the target sentiment task are summarized in Tab .", "entities": []}, {"text": "4 .", "entities": []}, {"text": "Our LSTM - CRF - TI(g ) model outperforms all the other competing models in Precision , Recall and the F1 score .", "entities": [[1, 2, "MethodName", "LSTM"], [3, 4, "MethodName", "CRF"], [15, 16, "MetricName", "Precision"], [17, 18, "MetricName", "Recall"], [20, 22, "MetricName", "F1 score"]]}, {"text": "C Experiments on Named Entity Recognition NER datasets We evaluated our models on three NER datasets , the English , Dutch and Spanish parts of the 2002 and 2003 CoNLL shared tasks ( Sang and F. , 2002 ; Sang et al . , 2003 ) .", "entities": [[3, 6, "TaskName", "Named Entity Recognition"], [6, 7, "TaskName", "NER"], [14, 15, "TaskName", "NER"]]}, {"text": "We used the original division of training , validation and test sets .", "entities": []}, {"text": "The task is de\ufb01ned over four different entity types : PERSON , LOCATION , ORGANIZATION , MISC .", "entities": []}, {"text": "We used the BIOES tagging scheme during the training , and convert them back to original tagging scheme in testing as previous studies show that using this tagging scheme instead of BIO2 can help improve performance ( Ratinov and Roth , 2009 ; Lample et al . , 2016 ; Ma and Hovy , 2016 ; Liu et al . , 2018 ) .", "entities": []}, {"text": "As a result , the segmentation module had 5output labels , and the entity module had 4 .", "entities": []}, {"text": "The \ufb01nal decision task , consisted of the Cartesian product of the segmentation set ( BIES)and the entity set , plus the \u201c O \u201d tag , resulting in 17 labels .", "entities": []}, {"text": "Results on NER We compared our models with the state - of - the - art systems on English6 , Dutch and Spanish .", "entities": [[2, 3, "TaskName", "NER"]]}, {"text": "For Dutch and Spanish , we used cross - lingual embedding as a way to exploit lexical information .", "entities": []}, {"text": "The results are shown in Tab . 5 and Tab .", "entities": []}, {"text": "67 .", "entities": []}, {"text": "Our best - performing model outperform all the competing systems .", "entities": []}, {"text": "D Additional Experiments on Knowledge Integration We conducted additional experiments on knowledge integration in the same setting as in the main text to investigate the properties of the modules .", "entities": []}, {"text": "Figure 8 shows the results for Dutch and Spanish NER datasets , while Figure 9 shows the results for the Subjective Polarity Disambiguation Datasets using the in - domain data .", "entities": [[9, 10, "TaskName", "NER"]]}, {"text": "5561.2567.573.7580 20%40%60%80%100 % Modularized non - Modularized ( a ) Dutch NER 5561.2567.573.7580 20%40%60%80%100 % Modularized non - Modularized ( b ) Spanish NER Figure 8 : Experimental results on modular knowledge integration on the Dutch and Spanish NER datasets .", "entities": [[11, 12, "TaskName", "NER"], [23, 24, "TaskName", "NER"], [38, 39, "TaskName", "NER"]]}, {"text": "E Convergence Analysis The proposed twofold modular infusion model ( with guided gating as an option ) breaks the complex learning problem into several sub - problems and then integrate them using joint training .", "entities": []}, {"text": "The process de\ufb01ned by this formulation has more parameters and requires learning multiple objectives jointly .", "entities": []}, {"text": "Our convergence analysis intends to evaluate whether the added complexity leads to a harder learning problem ( i.e. , slower to converge ) or whether the tasks constrain each other and as a result can be ef\ufb01ciently learned .", "entities": []}, {"text": "6Liu et al . \u2019s results are different since their implementation did not convert the predicted BIOES tags back to BIO2 during evaluation .", "entities": []}, {"text": "For fair comparison , we only report the results of the standard evaluation .", "entities": []}, {"text": "7We thank reviewers for pointing out a paper ( Agerri and Rigau , 2016 ) obtains the new state - of - the - art result on Dutch with comparable results on Spanish .", "entities": []}, {"text": "590System ArchitectureEnglish Spanish Pre Rec F1 Pre Rec F1 Zhang , Zhang and V o ( 2015)Pipeline 43.71 37.12 40.06 45.99 40.57 43.04 Joint 44.62 35.84 39.67 46.67 39.99 43.02 Collapsed 46.32 32.84 38.36 47.69 34.53 40.00 Li and Lu ( 2017)SS 44.57 36.48 40.11 46.06 39.89 42.75 + embeddings 47.30 40.36 43.55 47.14 41.48 44.13 + POS tags 45.96 39.04 42.21 45.92 40.25 42.89 + semiMarkov 44.49 37.93 40.94 44.12 40.34 42.14 Base Line LSTM - CRF 53.29 46.90 49.89 51.17 46.71 48.84", "entities": [[5, 6, "MetricName", "F1"], [8, 9, "MetricName", "F1"], [75, 76, "MethodName", "LSTM"], [77, 78, "MethodName", "CRF"]]}, {"text": "This workLSTM - CRF - T 54.21 48.77 51.34 51.77 47.37 49.47 LSTM - CRF - Ti 54.58 49.01 51.64 52.14 47.56 49.74 LSTM - CRF - Ti(g ) 55.31 49.36 52.15 52.82 48.41 50.50 Table 4 : Performance on the target sentiment task Model English LSTM - CRF ( Lample et al . , 2016 ) 90.94 LSTM - CNN - CRF ( Ma and Hovy , 2016 ) 91.21 LM - LSTM - CRF ( Liu et", "entities": [[3, 4, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [23, 24, "MethodName", "LSTM"], [25, 26, "MethodName", "CRF"], [46, 47, "MethodName", "LSTM"], [48, 49, "MethodName", "CRF"], [58, 59, "MethodName", "LSTM"], [62, 63, "MethodName", "CRF"], [73, 74, "MethodName", "LSTM"], [75, 76, "MethodName", "CRF"]]}, {"text": "al . , 2018 ) 91.06 LSTM - CRF - T 90.8 LSTM - CRF - TI 91.16 LSTM - CRF - TI(g ) 91.68 Table 5 : Comparing our models with several stateof - the - art systems on the CoNLL 2003 English NER dataset .", "entities": [[6, 7, "MethodName", "LSTM"], [8, 9, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [18, 19, "MethodName", "LSTM"], [20, 21, "MethodName", "CRF"], [41, 43, "DatasetName", "CoNLL 2003"], [44, 45, "TaskName", "NER"]]}, {"text": "Model Dutch Spanish Carreras et al .", "entities": []}, {"text": "( 2002 ) 77.05 81.39 Nothman et al .", "entities": []}, {"text": "( 2013 ) 78.60 N / A dos Santos and Guimar \u02dcaes ( 2015 )", "entities": []}, {"text": "N / A 82.21 Gillick et al . ( 2015 ) 82.84 82.95 Lample et al .", "entities": []}, {"text": "( 2016 )", "entities": []}, {"text": "81.74 85.75 LSTM - CRF - T 83.91 84.89 LSTM - CRF - TI 84.12 85.28 LSTM - CRF - TI(g ) 84.51 85.92 Table 6 : Comparing our models with recent results on the 2002 CoNLL Dutch and Spanish NER datasets .", "entities": [[2, 3, "MethodName", "LSTM"], [4, 5, "MethodName", "CRF"], [9, 10, "MethodName", "LSTM"], [11, 12, "MethodName", "CRF"], [16, 17, "MethodName", "LSTM"], [18, 19, "MethodName", "CRF"], [40, 41, "TaskName", "NER"]]}, {"text": "1017.52532.540 20%40%60%80%100 % Modularized non - Modularized Figure 9 : Experimental results on modular knowledge integration on the Subjective Polarity Disambiguation Datasets .", "entities": []}, {"text": "We compare between our LSTM - CRF - TI(g ) model and recent published top models on the English NER dataset in Figure 10 and on the subjec - tive polarity disambiguation datasets in Figure 11 .", "entities": [[4, 5, "MethodName", "LSTM"], [6, 7, "MethodName", "CRF"], [19, 20, "TaskName", "NER"]]}, {"text": "The curve compares convergence speed in terms of learning epochs .", "entities": []}, {"text": "Our LSTM - CRF - TI(g ) model has a much faster convergence rate compared to the other models .", "entities": [[1, 2, "MethodName", "LSTM"], [3, 4, "MethodName", "CRF"]]}, {"text": "48617487100 123456789101112 LSTM - CRF CNN - LSTM - CRF LM - LSTM - CRF LSTM - CRF - Ti(g ) Figure 10 : Comparing convergence over the development set on the English NER dataset .", "entities": [[2, 3, "MethodName", "LSTM"], [4, 5, "MethodName", "CRF"], [7, 8, "MethodName", "LSTM"], [9, 10, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [15, 16, "MethodName", "LSTM"], [17, 18, "MethodName", "CRF"], [33, 34, "TaskName", "NER"]]}, {"text": "The x - axis is number of epochs and the y - axis is the F1 - score .", "entities": [[5, 8, "HyperparameterName", "number of epochs"], [15, 18, "MetricName", "F1 - score"]]}, {"text": "06.2512.518.7525 123456789101112 LSTM - CRF CNN - LSTM - CRF LM - LSTM - CRF LSTM - CRF - Ti(g ) Figure 11 :", "entities": [[2, 3, "MethodName", "LSTM"], [4, 5, "MethodName", "CRF"], [7, 8, "MethodName", "LSTM"], [9, 10, "MethodName", "CRF"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "CRF"], [15, 16, "MethodName", "LSTM"], [17, 18, "MethodName", "CRF"]]}, {"text": "Comparing convergence over the development set on the subjective polarity disambiguation datasets .", "entities": []}, {"text": "The x - axis is number of epochs and the y - axis is the F1 - score .", "entities": [[5, 8, "HyperparameterName", "number of epochs"], [15, 18, "MetricName", "F1 - score"]]}]