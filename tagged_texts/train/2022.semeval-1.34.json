[{"text": "Proceedings of the 16th International Workshop on Semantic Evaluation ( SemEval-2022 ) , pages 266 - 270 July 14 - 15 , 2022 \u00a9 2022 Association for Computational Linguistics SPDB Innovation Lab at SemEval-2022 Task 3 : Recognize Appropriate Taxonomic Relations Between Two Nominal Arguments with ERNIE - M Model Yue Zhou , Bowei Wei , Jianyu Liu , Yang Yang Shanghai Pudong Development Bank { zhouy93 , weibw1 , liujy27 , yangy103 } @spdb.com.cn Abstract Synonyms and antonym practices are the most common practices in our early childhood .", "entities": []}, {"text": "It correlated our known words to a better place deep in our intuition .", "entities": []}, {"text": "At the beginning of life for a machine , we would like to treat the machine as a baby and build a similar training for it as well to present a qualified performance .", "entities": []}, {"text": "In this paper , we present an ensemble model for sentence logistics classification , which outperforms the state - of - art methods .", "entities": []}, {"text": "Our approach essentially builds on two models including ERNIE - M and DeBERTaV3 .", "entities": []}, {"text": "With crossvalidation and random seed tuning , we select the top performance models for the last soft ensemble and make them vote for the final answer , achieving the top 6 performance .", "entities": []}, {"text": "1 Introduction Synonym , antonym and their relations from unstructured text are fundamental problems in information classification field .", "entities": []}, {"text": "These problems can be decomposed into three subtasks : word extraction using regrex , relation extraction ( Zelenko et al . , 2003 ) , ( Bunescu and Mooney , 2005 ) , and classifying the logistics between them .", "entities": [[14, 16, "TaskName", "relation extraction"]]}, {"text": "However , an end - to - end model , i.e. ERNIE - M model ( Ouyang et al . , 2020 ) , is proposed to solve the three tasks .", "entities": []}, {"text": "Presupposed Taxonomies - Evaluating Neuralnetwork Semantics ( PreTENS ) ( Zamparelli et al . , 2022 ) is a task to predict the acceptability of simple sentences containing constructions whose two arguments are presupposed to be or not to be in an ordered taxonomic relation .", "entities": []}, {"text": "In this paper , we first present a simple approach with the ERNIE - M model to solve the task .", "entities": []}, {"text": "Although the ERNIEM model performs unexpectedly impressive , the model has poor robustness .", "entities": []}, {"text": "Hence , the additional pre - trained model is introduced to solve the robustness problem .", "entities": []}, {"text": "The latest model DeBERTaV3 ( He et al . , 2021 ) has outstanding performance oncross - linguistic tasks , which outperforms BERT and DeBERTa on many tasks .", "entities": [[22, 23, "MethodName", "BERT"], [24, 25, "MethodName", "DeBERTa"]]}, {"text": "The proposed model consists of two parts : the basic ERNIE - M model and the pre - trained model DeBERTaV3 .", "entities": []}, {"text": "The DeBERTaV3 model shares the same pre - trained data with ERNIE - M called XNLI ( Conneau et al . , 2018 ) , which can improve the performance and robustness as well .", "entities": [[15, 16, "DatasetName", "XNLI"]]}, {"text": "The DeBERTaV3 model is trained independently , which has significant improvement for English but somehow brought no improvement for other languages .", "entities": []}, {"text": "Based on the above conclusion , we employ the DeBERTaV3 model for English - task only .", "entities": []}, {"text": "To better understand the effectiveness of the proposed model , we started a bunch of analyses .", "entities": []}, {"text": "The first problem is the data - set limitation .", "entities": []}, {"text": "Two additional datasets were imported , i.e. , the translated dataset from Google translation which is translated from three languages , and the XNLI dataset .", "entities": [[12, 13, "DatasetName", "Google"], [23, 24, "DatasetName", "XNLI"]]}, {"text": "However , larger datasets do n\u2019t lead to better performance .", "entities": []}, {"text": "We compared the performance of the ERNIE - M model on four sets of data : the given data , the given data with translated data , the given data with XNLI augmentation , and the given data with both the translated data and XNLI data .", "entities": [[31, 32, "DatasetName", "XNLI"], [44, 45, "DatasetName", "XNLI"]]}, {"text": "We do the same experiments with the DeBERTaV3 model as well .", "entities": []}, {"text": "The results show that the combination of ERNIE - M with all the three datasets and DeBERTaV3 with the given English data perform the best .", "entities": []}, {"text": "2 Related Work Multilingual model ERNIE - M proposes a new training method that encourages the model to align the representation of multiple languages with monolingual corpora , to overcome the constraint that the parallel corpus size places on the model performance .", "entities": []}, {"text": "There are two models in ERNIE - M which are Cross - Attention masked language mod-266", "entities": []}, {"text": "eling ( CAMLM ) and Back - Translation masked language modeling ( BTMLM ) .", "entities": [[7, 8, "TaskName", "Translation"], [8, 11, "TaskName", "masked language modeling"]]}, {"text": "Cross - Attention masked language modeling ( CAMLM ) is to align cross - language semantic representations on parallel corpora .", "entities": [[3, 6, "TaskName", "masked language modeling"]]}, {"text": "Then , the multilingual representation is enhanced with transferability learned from parallel corpora .", "entities": []}, {"text": "Back - Translation masked language modeling ( BTMLM ) is trained to generate pseudo - parallel sentences from monolingual sentences .", "entities": [[2, 3, "TaskName", "Translation"], [3, 6, "TaskName", "masked language modeling"]]}, {"text": "The generated pairs are then used as the input of the model to further align the cross - lingual semantics , thus enhancing the multilingual representation .", "entities": []}, {"text": "DeBERTaV3 presents a new pre - trained language model , which improves the original DeBERTa model by replacing mask language modeling ( MLM ) with replaced token detection ( RTD ) , a more sample - efficient pre - training task .", "entities": [[14, 15, "MethodName", "DeBERTa"], [22, 23, "DatasetName", "MLM"]]}, {"text": "They all come from an important field , multilingual models .", "entities": []}, {"text": "Since the related paper was published at the end of 2021 , there are no similar tasks have been done and published .", "entities": []}, {"text": "3 Our Approach In this section , we first introduce the methods to solving the multi - language problem and then present our work about improving the performance on uni - language .", "entities": []}, {"text": "To extenuate over - fitting for a specific language , our team uses a multi - language ensemble learning strategy that includes a pre - trained language model and a multilingual language model .", "entities": [[17, 19, "TaskName", "ensemble learning"]]}, {"text": "Based on the approach above , it makes the learned representation generalizable across languages and improves the performance in finding the suitable taxonomic relations in two nominal arguments .", "entities": []}, {"text": "3.1 Multilingual Language Model Training Our key idea of solving multilingual language tasks is to learn the language invariant feature space shared among multiple languages .", "entities": []}, {"text": "We tried multilingual masked language modeling ( MMLM ) , translation language modeling ( TLM ) , and crossattention masked language modeling ( CAMLM ) have been tried .", "entities": [[3, 6, "TaskName", "masked language modeling"], [19, 22, "TaskName", "masked language modeling"]]}, {"text": "However , the scale of the parallel corpus is quite limited , which limits the performance of the model .", "entities": []}, {"text": "However , we found that using the transferability learned from parallel corpora to enhance the model \u2019s learning of large - scale monolingual corpora to enhance multilingual semantic representation can achieve a good effect .", "entities": []}, {"text": "ERNIE - M does thisby making the predictions of tokens depending on tokens in another language , but not on other tokens in this language .", "entities": []}, {"text": "Therefore , we choose ERNIE - M as the baseline model for this task and explore on this basis to improve the prediction effect .", "entities": []}, {"text": "In the process of using multilingual language models , we mainly adopt random search to finetune the ERNIE - M model and data augmentation methods are used for model training .", "entities": [[12, 14, "MethodName", "random search"], [22, 24, "TaskName", "data augmentation"]]}, {"text": "Cross - lingual natural language inference ( XNLI ) dataset is used and the English training set is translated to Italian ( E2I set ) .", "entities": [[0, 6, "TaskName", "Cross - lingual natural language inference"], [7, 8, "DatasetName", "XNLI"]]}, {"text": "Firstly , the English training set is combined with the French and E2I set .", "entities": []}, {"text": "Then , the model is fine - tuned with the combined training set .", "entities": []}, {"text": "Finally , the augmented task training set in three languages is adopted for fine - tune process .", "entities": []}, {"text": "3.2 Cross - validation To improve the robustness of our model , our team apply cross - validation for training .", "entities": []}, {"text": "Firstly , by using different random seeds , we divided the training set which included all three languages ten times .", "entities": [[6, 7, "DatasetName", "seeds"]]}, {"text": "Through this process , we obtained 10 folds of data , which contain 15768 training samples and 1751 validation samples in each fold .", "entities": []}, {"text": "During the finetuning process , we used random search to optimize hyper - parameters like epochs , learning rate , and batch size .", "entities": [[7, 9, "MethodName", "random search"], [17, 19, "HyperparameterName", "learning rate"], [21, 23, "HyperparameterName", "batch size"]]}, {"text": "By using F1 - Score as our evaluation metric , the best model at all the ten - fold of training is saved .", "entities": [[2, 5, "MetricName", "F1 - Score"]]}, {"text": "Finally , by making predictions on the test set , we save the mean of the probability of all ten best - saved models .", "entities": []}, {"text": "This result is our final output of ERNIE - M. Cross - validation process is shown in Figure 1 .", "entities": []}, {"text": "3.3 Pre - trained Language Model To enhance the effect in a single language subtask , we consider using an enhanced mask decoder and a disentangled attention mechanism to improve the effect .", "entities": [[25, 28, "MethodName", "disentangled attention mechanism"]]}, {"text": "DeBERTaV3 meets our needs by using Electra - style pre - training and gradient unwrapping embedding sharing .", "entities": [[6, 7, "MethodName", "Electra"]]}, {"text": "We have tried to use DeBERTaV3 for training in each single language subtask respectively .", "entities": []}, {"text": "3.4 Ensemble By using the multilingual language model and pretrained language model respectively , we have two groups of validation set results for each language .", "entities": []}, {"text": "We adopt the mean of the best - saved models from ERNIE - M and DeBERTaV3 after making predictions on the validation set .", "entities": []}, {"text": "After comparing the267", "entities": []}, {"text": "Figure 1 : The process of 10 - fold cross - validation and ensemble .", "entities": []}, {"text": "The training set which includes all three languages is divided randomly 10 times by setting different random seeds .", "entities": [[17, 18, "DatasetName", "seeds"]]}, {"text": "In each division , the training set is divided into 10 parts , of which 9 parts are respectively used as the training set and the remaining 1 part is used as the validation set .", "entities": []}, {"text": "And finally , the average of all saved best models predicted on the test set is the final results .", "entities": []}, {"text": "combination result , we finally used different strategies in different languages .", "entities": []}, {"text": "For the English subtask , we retain the strategy of merging the two types of models .", "entities": []}, {"text": "For French and Italian subtasks , the result from cross - validation of the multilingual language model is used directly .", "entities": []}, {"text": "3.5 Data Augmentations As the total number of labeled data in each language is only 5840 , it \u2019s liable to overfit the training data even with pre - trained models .", "entities": []}, {"text": "The overfitting phenomenon may be more significant than expected because the data is generated programmatically through manually verified templates .", "entities": []}, {"text": "To increase the size of training data , we use the following data augmentation methods : 1 ) translate English data into French and Italian by using Baidu translate 2 ) translate English data into French and Italian by using Google translate 3 ) translate French and Italian data into English by using Google translate .", "entities": [[12, 14, "TaskName", "data augmentation"], [40, 41, "DatasetName", "Google"], [53, 54, "DatasetName", "Google"]]}, {"text": "We find that the augmentation can help delay the overfitting occurrence slightly , especially for large models .", "entities": []}, {"text": "4 Experiments In this section , we first describe the dataset and our data preprocessing steps , and then we present the details of the experimental setup for subtask1 .", "entities": []}, {"text": "4.1 Dataset Our dataset comes from two parts .", "entities": []}, {"text": "The first part is the trial dataset released by organizers , which is composed of English , French andItalian .", "entities": []}, {"text": "Each language contains 5838 sentences .", "entities": []}, {"text": "Because the trail dataset provided by organizers is only 5838 in each language , to increase the amount of data and make the model better , we use Google translator and Baidu translator to translate the English dataset into French and Italian again .", "entities": [[28, 29, "DatasetName", "Google"]]}, {"text": "The use of two different translators also increases the diversity of data .", "entities": []}, {"text": "The other part is that we use the public dataset \u2013 XNLI .", "entities": [[11, 12, "DatasetName", "XNLI"]]}, {"text": "We use XNLI dataset because it is often used in similar cross - language tasks .", "entities": [[2, 3, "DatasetName", "XNLI"]]}, {"text": "The XNLI dataset contains a total of 15 languages , and each language contains 7500 pairs of data .", "entities": [[1, 2, "DatasetName", "XNLI"]]}, {"text": "We used the English and French datasets in this competition .", "entities": []}, {"text": "Because the XNLI dataset itself does not contain Italian datasets , we translated the English dataset into Italian and then used the three languages in ERNIE - M model training .", "entities": [[2, 3, "DatasetName", "XNLI"]]}, {"text": "4.2 Experiment Settings In this task , we mainly use the ERNIE - M model and DeBERTaV3 model .", "entities": []}, {"text": "The ERNIE - M model is composed of 24 layers , 1024 hidden , and 16 heads .", "entities": []}, {"text": "In terms of parameter selection , we set a set of parameters , as Table 2 shows .", "entities": []}, {"text": "We set up 10000 times of ERNIE - M model training , in which the specific values of the above parameters are randomly selected according to the table1 at each training .", "entities": []}, {"text": "And in each training process , the training method of 10 folds cross - validation is used .", "entities": []}, {"text": "The DeBERTaV3 model is composed of 12 layers and a hidden size of 768 .", "entities": []}, {"text": "It has only 86M268", "entities": []}, {"text": "Parameter Value1 Value2 Value3 Value4 batch size 8 16 32 lr decay 0.8 0.85 0.9 0.95 rdrop 1.0 3.0 5.0 7.0 epoch 2 4 learning rate 2e-5 3e-5 4e-5 5e-5 dropout 0.1 0.2 Table 1 : Parameter Setting .", "entities": [[5, 7, "HyperparameterName", "batch size"], [24, 26, "HyperparameterName", "learning rate"]]}, {"text": "We set different specific values of different parameters according to some previous experience .", "entities": []}, {"text": "Because the appropriate value is not fixed in different tasks , we choose to use the random combination of various values of the above parameters for model training , so as to find the most appropriate parameter value and obtain the optimal model result .", "entities": []}, {"text": "Training Methods Language Precesion Recall F1 ERNIE - M English 0.8240 0.9547 0.8846 ERNIE - M French 0.8185 0.9402 0.8751 ERNIE - M Italian 0.8163 0.9307 0.8698 Ensemble Model English 0.9266 0.9605 0.9432 Ensemble Model French 0.8125 0.9489 0.8754 Ensemble Model Italian 0.8081 0.9467 0.8719 Table 2 : Results of different models .", "entities": [[4, 5, "MetricName", "Recall"], [5, 6, "MetricName", "F1"]]}, {"text": "We select the best model from a large number of randomly generated parameter training models and compare it with the final best ensemble result .", "entities": []}, {"text": "And we can see that the performance of the three languages has been improved .", "entities": []}, {"text": "backbone parameters with a vocabulary containing 128 K tokens which introduces 98 M parameters in the Embedding layer .", "entities": []}, {"text": "And we set batch size to 8 , learning rate to 2e-5 , and epoch to 3 .", "entities": [[3, 5, "HyperparameterName", "batch size"], [8, 10, "HyperparameterName", "learning rate"]]}, {"text": "4.3 Main Results The best single model on the development set is the ERNIE - M LARGE .", "entities": []}, {"text": "And the model that uses DeBERTaV3 does n\u2019t perform well in French and Italian , so we just use the results on English data .", "entities": []}, {"text": "The best ensemble model on the test set is trained on both the XNLI dataset and the trial dataset .", "entities": [[13, 14, "DatasetName", "XNLI"]]}, {"text": "The ensemble model obtained English test set F1 scores of 94.325 , French test set F1 scores of 86.792 , and Italian test set F1 scores of 88.807 .", "entities": [[7, 8, "MetricName", "F1"], [15, 16, "MetricName", "F1"], [24, 25, "MetricName", "F1"]]}, {"text": "The ensemble model achieves the F1 score of 94.325 in English data , the F1 score of 86.792 in French data , and the F1 score of 88.807 in the Italian data .", "entities": [[5, 7, "MetricName", "F1 score"], [14, 16, "MetricName", "F1 score"], [24, 26, "MetricName", "F1 score"]]}, {"text": "The results are shown in Table 2 .", "entities": []}, {"text": "For the comparative analysis of the results of using only ERNIE - M as the baseline model and the ensemble model , we can see that the improvement of the ensemble model in English is relatively obvious , but the improvement in Italian and French is very weak .", "entities": []}, {"text": "We think this is due to the following reasons : Firstly , Italian is not included in the original XNLI dataset .", "entities": [[19, 20, "DatasetName", "XNLI"]]}, {"text": "In this task , we translateEnglish into Italian .", "entities": []}, {"text": "So to a certain extent , the understanding of English by the ERNIE - M model is increased .", "entities": []}, {"text": "Secondly , because DeBERTaV3 performs well in English , we only use its results in English , So the results for Italian and French did not get a big boost .", "entities": []}, {"text": "This also shows that using the ensemble model can indeed improve the prediction .", "entities": []}, {"text": "In the future , we will explore ensemble models that can improve predictions in Italian and French .", "entities": []}, {"text": "5 Conclusion To solve the problem of judging whether the meaning of a sentence is self - consistent in multilingual language tasks , that is , the problem raised in task 3 , we propose an ensemble model using ERNIEM and DeBERTaV3 , and regard this problem as a binary classification problem .", "entities": []}, {"text": "Furthermore , to solve the issue of the small dataset , we use various strategies , such as K - ford cross - validation , translating the dataset using different translators , and introducing an external dataset - XNLI , a dataset commonly used in multilingual problems .", "entities": [[38, 39, "DatasetName", "XNLI"]]}, {"text": "In future efforts , we plan to further improve our model from these aspects .", "entities": []}, {"text": "The first is to enrich the data , especially Italian and French , to help the model learn better .", "entities": []}, {"text": "The second is that we could train more models on standard fine - tuning , multi - step fine - tuning,269", "entities": []}, {"text": "multi - task learning , or adversarial training .", "entities": [[0, 4, "TaskName", "multi - task learning"]]}, {"text": "Then try to ensemble different models to gain a better performance .", "entities": []}, {"text": "References Razvan C. Bunescu and Raymond J. Mooney .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "A shortest path dependency kernel for relation extraction .", "entities": [[6, 8, "TaskName", "relation extraction"]]}, {"text": "In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing , HLT \u2019 05 , page 724\u2013731 , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Alexis Conneau , Ruty Rinott , Guillaume Lample , Adina Williams , Samuel R. Bowman , Holger Schwenk , and Veselin Stoyanov .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Xnli : Evaluating crosslingual sentence representations .", "entities": [[0, 1, "DatasetName", "Xnli"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing . Association for Computational Linguistics .", "entities": []}, {"text": "P. He , J. Gao , and W. Chen . 2021 .", "entities": []}, {"text": "Debertav3 : Improving deberta using electra - style pre - training with gradient - disentangled embedding sharing .", "entities": [[3, 4, "MethodName", "deberta"], [5, 6, "MethodName", "electra"]]}, {"text": "arXiv eprints .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "X. Ouyang , S. Wang , C. Pang , Y .", "entities": []}, {"text": "Sun , and H. Wang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Ernie - m : Enhanced multilingual representation by aligning cross - lingual semantics with monolingual corpora .", "entities": []}, {"text": "Roberto Zamparelli , Shammur A. Chowdhury , Dominique Brunato , Cristiano Chesi , Felice Dell \u2019 Orletta , Arid Hasan , and Giulia Venturi . 2022 .", "entities": [[18, 19, "DatasetName", "Arid"]]}, {"text": "Semeval2022 task3 ( pretens ): Evaluating neural networks on presuppositional semantic knowledge .", "entities": []}, {"text": "In Proceeding of SEMEVAL 2022 .", "entities": []}, {"text": "Dmitry Zelenko , Chinatsu Aone , and Anthony Richardella . 2003 .", "entities": []}, {"text": "Kernel methods for relation extraction .", "entities": [[3, 5, "TaskName", "relation extraction"]]}, {"text": "Journal of Machine Learning Research , 3(3):1083\u20131106.270", "entities": []}]