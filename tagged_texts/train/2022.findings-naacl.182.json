[{"text": "Findings of the Association for Computational Linguistics : NAACL 2022 , pages 2367 - 2387 July 10 - 15 , 2022 \u00a9 2022 Association for Computational Linguistics Am I Me or You ?", "entities": []}, {"text": "State - of - the - Art Dialogue Models Can not Maintain an Identity Kurt Shuster Jack Urbanek Arthur Szlam Jason Weston Facebook AI Research Abstract State - of - the - art dialogue models still often stumble with regards to factual accuracy and self - contradiction .", "entities": [[42, 43, "MetricName", "accuracy"]]}, {"text": "Anecdotally , they have been observed to fail to maintain character identity throughout discourse ; and more specifically , may take on the role of their interlocutor .", "entities": []}, {"text": "In this work we formalize and quantify this deficiency , and show experimentally through human evaluations that this is indeed a problem .", "entities": []}, {"text": "In contrast , we show that discriminative models trained specifically to recognize who is speaking can perform well ; and further , these can be used as automated metrics .", "entities": []}, {"text": "Finally , we evaluate a wide variety of mitigation methods , including changes to model architecture , training protocol , and decoding strategy .", "entities": []}, {"text": "Our best models reduce mistaken identity issues by nearly 65 % according to human annotators , while simultaneously improving engagingness .", "entities": []}, {"text": "Despite these results , we find that maintaining character identity still remains a challenging problem .", "entities": []}, {"text": "1 Introduction The exchange of stories from one \u2019s past , or descriptions of activities in one \u2019s present , are a fundamental part of human discourse .", "entities": []}, {"text": "Trustworthy human conversationalists keep their stories roughly straight within a conversation .", "entities": []}, {"text": "An interlocutor taking on your own stories and persona as theirs is especially jarring and unnatural .", "entities": []}, {"text": "However , despite the improvements in state - of - the - art open - domain dialogue modeling , both in terms of distributional accuracy metrics like perplexity , and subjectively in terms of human judgements ( Adiwardana et al . , 2020 ; Roller et al . , 2021 ) , interactions with those agents reveal that they can not keep their stories straight .", "entities": [[24, 25, "MetricName", "accuracy"], [27, 28, "MetricName", "perplexity"]]}, {"text": "In particular , they are likely to take on the role of their interlocutor ; for example , if an agent \u2019s partner says they are a software engineer , the agent is likely to say it is a software engineer too ( Roller et al . , 2021 ) , or worse , appropriate their partners just told tale of a trip to NAACL as their own .", "entities": [[20, 21, "DatasetName", "agent"], [31, 32, "DatasetName", "agent"]]}, {"text": "SomeSetting : Barn , Farm Partner : Thief Self : Guest Guest : Hail who goes there ? !", "entities": []}, {"text": "Thief :", "entities": []}, {"text": "Hello friend I mean you no harm Model Response Guest : I am not your friend , I am your thief !", "entities": []}, {"text": "I am here to steal from you !", "entities": []}, {"text": "Character Token Probabilities Thief : 0.39 Guest : 0.23 Setting : Castle Kitchens , Inside Palace Partner : Hunter Self : Helper Hunter :", "entities": []}, {"text": "Hi Helper : Hello .", "entities": []}, {"text": "What brings you to the kitchen ?", "entities": []}, {"text": "Hunter :", "entities": []}, {"text": "I am chopping some meat that is to be sold .", "entities": []}, {"text": "Helper : Could you spare me a piece ?", "entities": []}, {"text": "I \u2019m starving .", "entities": []}, {"text": "Hunter :", "entities": []}, {"text": "It \u2019s 3 cents a pound , if you have 3 cents then", "entities": []}, {"text": "yeah Model Response Helper : I do n\u2019t have any money .", "entities": []}, {"text": "I \u2019m just a poor hunter trying to make a living .", "entities": []}, {"text": "Character Token Probabilities Hunter : 0.39 Helper : 0.12 Table 1 : Failures of a 2.7B parameter transformer pretrained on 1.5B examples from a large dialogue corpus ( Roller et al . , 2021 ) and fine - tuned on LIGHT ( Urbanek et al . , 2019 ) .", "entities": []}, {"text": "The bold words in redhighlight the model mistaking its identity for its partner \u2019s .", "entities": []}, {"text": "( Top ) The model believes it is a thief , rather than a guest .", "entities": []}, {"text": "( Bottom )", "entities": []}, {"text": "The model believes it is a hunter rather than a helper .", "entities": []}, {"text": "Token probabilities are given at the position of the mistake for the two names .", "entities": []}, {"text": "example failure cases are given in Table 1 , where models incorrectly take on the name , role or activities of their partner instead of their assigned role .", "entities": []}, {"text": "These failures are related to the general problems of repetition in language models ( Holtzman et al . , 2020 ) , the weak influence of word order ( Sinha et al . , 2021 ) and inability to avoid contradictions ( Nie et al . , 2021 ) .", "entities": []}, {"text": "In this work we formalize and quantify this behavior , show that to some extent it can be detected automatically with a specifically trained classifier , and then study a wide variety of mitigations .", "entities": []}, {"text": "These include multi - objective training , unlikelihood training ( Li et al . , 2020 ; Welleck et", "entities": []}, {"text": "al . , 2020),2367", "entities": []}, {"text": "classifier - assisted re - ranking based generation , and several forms modifying the attention mechanisms of the decoder in a sequence to sequence model .", "entities": [[21, 24, "MethodName", "sequence to sequence"]]}, {"text": "Our best methods can reduce mistaken identity issues by 65 % , while simultaneously improving inconversation engagingness ; indeed , our models that can stick to their role in conversation are judged by humans to be significantly more engaging than their baseline counterparts .", "entities": []}, {"text": "Despite these advances , we find that there is still considerable space to improve these results further in future work .", "entities": []}, {"text": "We make publicly available both our trained models and code to reproduce results1 .", "entities": []}, {"text": "2 Related Work Role - Playing in Open - Domain Dialogue Much recent work has explored training open - domain dialogue models on large and small dialogue corpora , with the former imbuing raw conversational ability and the latter providing necessary conversational skills .", "entities": []}, {"text": "Most crowd - sourced datasets require acting out a role to some capacity in conversation ( though indeed Mazar\u00e9 et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) study extraction of roles from raw data ) .", "entities": []}, {"text": "Some involve providing persona lines that a model must assume throughout the conversation ( Zhang et al . , 2018 ; Dinan et al . , 2020 ;", "entities": []}, {"text": "Xu et", "entities": []}, {"text": "al . , 2021 ) ; others require more subtle \" roles \" , such as a listener ( Rashkin et al . , 2019 ) , or a teacher and student ( Dinan et al . , 2019b ; Gopalakrishnan et al . , 2019 ; Zhou et", "entities": []}, {"text": "al . , 2018 ; Komeili et al . , 2021 ) .", "entities": []}, {"text": "Zheng et al .", "entities": []}, {"text": "( 2020 ) explore using a discriminative model to predict whether model responses contain similarity with their persona , similar to methods we employ in our work .", "entities": []}, {"text": "Consistency in Open - Domain Dialogue A common paradigm in the state of the art of open - domain dialogue involves concatenating all relevant contextual information as input to a sequence to sequence neural model ( e.g. , transformers ( Vaswani et", "entities": [[30, 33, "MethodName", "sequence to sequence"]]}, {"text": "al . , 2017 ) ) to obtain a conditioned response .", "entities": []}, {"text": "Such models can yield human - like and engaging responses ( Adiwardana et al . , 2020 ;", "entities": []}, {"text": "Roller et al . , 2021 ) .", "entities": []}, {"text": "Nevertheless , various consistency issues still plague such models .", "entities": []}, {"text": "Recent studies have indicated that hallucination of incorrect knowledge is still far from a solved issue ( Shuster et al . , 2021 ; Santhanam et al . , 2021 ) , with some proposing specific datasets and tools for measuring precisely the levels of this undesired attribute ( Liu et al . , 2021 ) .", "entities": []}, {"text": "Another clear 1URL will appear here.example of failure is the short - term memory of state - of - the - art models ( Xu et", "entities": []}, {"text": "al . , 2021 ) , sometimes due to the lack of long - form training data or long - context models but often due to simply the modeling itself .", "entities": []}, {"text": "To address consistency issues , a variety of methods have been explored .", "entities": []}, {"text": "In the context of knowledge - grounded dialogue , different ways to attend most effectively over provided contextual information have been explored ( Zheng and Zhou , 2019 ; Ye et", "entities": []}, {"text": "al . , 2020 ; Prabhumoye et al . , 2021 ; Wang et al . , 2019 ) .", "entities": []}, {"text": "These works find that considering factual documents separately ( in some capacity ) improves model grounding .", "entities": []}, {"text": "We explore such methods , but in the context of character identity .", "entities": []}, {"text": "Another general problem is that of contradictions .", "entities": []}, {"text": "Nie et al .", "entities": []}, {"text": "( 2021 ) collect a dataset of contradictions in dialogue , and train classifiers that help re - rank model outputs at inference time ; Li et al .", "entities": []}, {"text": "( 2020 ) explore unlikelihood training ( Welleck et al . , 2020 ) to reduce repetition and contradiction , among other undesired traits , in model generations .", "entities": []}, {"text": "The character identity issue we study in this work can be seen as an important class of contradictions , but to the best of our knowledge , has not been explicitly focused on .", "entities": []}, {"text": "3 Methods 3.1 Problem", "entities": []}, {"text": "Setting We consider a two - party chat setting .", "entities": []}, {"text": "The context provided to a model includes : ( i ) the name of its character and the partner \u2019s character ; ( ii ) an extended description of its own character ; ( iii ) and , information about the area in which the conversation takes place .", "entities": []}, {"text": "The responsibility of the model is to engage its conversational partner , with no other goal prescribed ; however , it should stay within character and within the bounds of the defined setting .", "entities": []}, {"text": "We operate in the context of LIGHT ( Urbanek et al . , 2019 ) , consisting of grounded fantasy roleplaying game conversations .", "entities": []}, {"text": "The LIGHT environment involves humans and models interacting with thousands of objects in hundreds of locations , all while assuming the roles of one of hundreds of characters .", "entities": []}, {"text": "The dataset consists of roughly 8.5k dialogues spanning 111k utterances .", "entities": []}, {"text": "It is an ideal setting for this study because of the rich and varied personas with explicit backstories .", "entities": []}, {"text": "To quantify the character identity problem , we take a state - of - the - art dialogue agent ( specifically , BlenderBot ( Roller et al . , 2021 ) )", "entities": [[18, 19, "DatasetName", "agent"]]}, {"text": "fine - tuned on the2368", "entities": []}, {"text": "LIGHT dialogue dataset and ask human annotators if the agent mistakes its identity based on its utterances in context .", "entities": [[9, 10, "DatasetName", "agent"]]}, {"text": "The agent conditions its response on the LIGHT context and prior utterances in the dialogue history .", "entities": [[1, 2, "DatasetName", "agent"]]}, {"text": "We see in Table 4 that in roughly 6.5percent of utterances the model mistakes its identity ; this corresponds to a mistake in approximately 35percent of conversations .", "entities": []}, {"text": "BlenderBot uses a Byte - Level BPE tokenizer ( Radford et al . , 2019 ) ; an artifact from the BlenderBot pre - training is that it only considers 128 such tokens in the past , and thus has no mechanism for recovering truncated information about the LIGHT context in later conversational turns .", "entities": [[6, 7, "MethodName", "BPE"]]}, {"text": "Our second baseline lengthens the input context to 1024 BPE tokens , which allows the entire context for every example to fit into the truncation length of the model ; we follow methods employed in Xu et", "entities": [[9, 10, "MethodName", "BPE"]]}, {"text": "al . ( 2021 ) to extend the positional embeddings of the model .", "entities": []}, {"text": "We see in Table 4 that this actually makes the problem worse , resulting in 7.4percent of utterances with mistaken identity ( corresponding to a failure in approximately 38percent of conversations ) .", "entities": []}, {"text": "3.2 Measuring Role - Playing Accuracy : RPA We first define a metric , role - playing accuracy ( RPA ) , to denote how often a model \u2019s responses are \u201c in - character \u201d ; by this , we mean how often the model \u2019s response could feasibly be said by their character , given their assigned character identity .", "entities": [[5, 6, "MetricName", "Accuracy"], [17, 18, "MetricName", "accuracy"]]}, {"text": "Measuring RPA is a non - trivial task for a variety of reasons .", "entities": []}, {"text": "First , some conversations involve pairs that can reasonably say similar things ( priest vs. priestess , man vs. woman , wizard vs. witch ) .", "entities": []}, {"text": "Second , opening lines are often more generic ( \u201c hello \u201d , \u201c how fare your travels today \u201d ) , so either character can say it in conversation .", "entities": []}, {"text": "The third reason stems from the data that we study ; we are relying on crowdsourced data in which humans are required to portray their characters .", "entities": []}, {"text": "Some crowdworkers may be better than others , and there may be some noise in the dataset in which , e.g. , a horse may proclaim its love for a queen , or a knight may discuss at length the kingdom \u2019s tax collecting .", "entities": []}, {"text": "Given the difficulties above , our primary measure of RPA involves human annotation of model responses , specifically evaluating whether a candidate response fits a given model \u2019s character .", "entities": []}, {"text": "We thus have human crowdworkers chat with each model in a LIGHT setting ; each is given a character and asked to role - play , while the human an - notates each model response , determining whether the model is in character : we denote this metric as \u201c Mistaken Identity \u201d in our experiments , and other utterance - level annotations are collected .", "entities": []}, {"text": "Further details regarding human evaluation are outlined in Section 4.7 .", "entities": []}, {"text": "Despite the efficacy of human evaluation , it is both costly and slow ; as a proxy , we thus train models specifically designed to identify whether a candidate response from a model fits the model \u2019s role , and denote these as \u201c RPA Classifiers \u201d .", "entities": []}, {"text": "We employ poly - encoder transformers ( Humeau et al . , 2020 ) to learn this metric , and structure the task as a ranking one ; the model receives the LIGHT setting and prior utterances of dialogue as input , as well as the response currently under consideration , and the model must choose the correct character from a fixed set of candidates .", "entities": []}, {"text": "We also explore RPA classifiers trained on all partially complete sequences of labels , such that the classifiers can determine the character speaking without requiring the full utterance ; we call these left - to - right ( LTR ) RPA classifiers .", "entities": []}, {"text": "Further details about how our RPA classifiers are built are given in Appendix B. 3.3 Mitigations In this section we describe several strategies for improving the role - playing accuracy of dialogue agents , specifically ways to improve our transformer baselines .", "entities": [[29, 30, "MetricName", "accuracy"]]}, {"text": "3.3.1 Re - ranking Model Outputs via RPA We can employ an RPA classifier in response generation by using it to rank candidate model outputs .", "entities": [[15, 17, "TaskName", "response generation"]]}, {"text": "Utterance Re - ranking : Given a set of candidate responses , the RPA classifier can re - score the set and return the response yielding the highest probability of staying in character ( according to the RPA score on the complete candidate generations ) .", "entities": []}, {"text": "The dialogue models employ beam - search to generate responses , and the candidates for re - ranking are the beams within beam - search .", "entities": []}, {"text": "We also try nucleus sampling ( Holtzman et al . , 2020 ) and delayed beam - search ( Massarelli et al . , 2020 ) to see whether more diverse candidates have any effect .", "entities": []}, {"text": "Partial And Complete Efficient Re - ranking ( PACER ): Re - ranking only the final beam candidates may be suboptimal because it is well known that those candidates are not very diverse ( Kulikov et al . , 2019 ) , meaning there may not be any good candidates to choose from in this final set .", "entities": []}, {"text": "In order2369", "entities": []}, {"text": "to generate utterances that agree with our classifiers , a possible improvement is to generate the utterance such that partial generations also agree with the classifier when generating left - to - right , ensuring that good candidates are surfaced .", "entities": []}, {"text": "With access to LTR RPA classifiers , we can apply re - ranking to partial sequences .", "entities": []}, {"text": "Unfortunately , re - ranking at every step of beam search , for every token , requires significant computation , such as in the recent FUDGE method ( Yang and Klein , 2021 ) .", "entities": []}, {"text": "FUDGE re - scores tokens at each decoding step by multiplying the classifier probability with each token probability , and renormalizing , which is used for control tasks with lightweight classifiers in order to be tractable .", "entities": []}, {"text": "In our proposed approach , called PACER , we re - score candidate tokens , for each beam , according to the probability that their inclusion yields the appropriate character classification , and then finally re - rank the complete candidate beams .", "entities": []}, {"text": "To make this efficient , we crucially score only a small proportion of decoding steps ( e.g. , 5 % of token positions ) as well as for only a few candidate rescored tokens ( e.g. , top 10 only ) .", "entities": []}, {"text": "We can control these hyperparameters to explore the speed vs. accuracy trade - off .", "entities": [[10, 11, "MetricName", "accuracy"]]}, {"text": "3.3.2 Unlikelihood", "entities": []}, {"text": "We explore utilizing an unlikelihood ( UL ) loss ( Li et al . , 2020 ; Welleck et", "entities": [[8, 9, "MetricName", "loss"]]}, {"text": "al . , 2020 ) to force the model to stay in character during training .", "entities": []}, {"text": "Unlikelihood training works as a counter to the standard maximum likelihood ( MLE ) training of language models ; while MLE training pushes the model to generate the correct tokens , UL training pushes the model to notgenerate incorrect tokens .", "entities": []}, {"text": "While training on the LIGHT dataset with standard NLL loss , with some fixed probability we consider a candidate model generation for UL loss .", "entities": [[8, 9, "MetricName", "NLL"], [9, 10, "MetricName", "loss"], [23, 24, "MetricName", "loss"]]}, {"text": "The full generation is sent to the RPA classifier ; if the generation is classified as coming from the incorrect character , we examine each partial generated sequence of the output , and send these sequences to the LTR RPA classifier to determine whether the candidate partial sequences match the model \u2019s character .", "entities": []}, {"text": "We apply UL loss to tokens that yield the wrong character classification .", "entities": [[3, 4, "MetricName", "loss"]]}, {"text": "3.3.3 Multi - objective Training The RPA classifiers utilize the LIGHT setting and prior utterances of dialogue history to determine which character generates a candidate response .", "entities": []}, {"text": "We hypothesize that the generation models themselves should be able to pick out and utilize these components as well .", "entities": []}, {"text": "However , the RPA classifier models are trained explicitly for this task , whereas the seq2seq models are trained only to generate a plausible continuation of a dialogue history .", "entities": [[15, 16, "MethodName", "seq2seq"]]}, {"text": "We thus explore a setup in which the generation models are trained to identify the speaker of an utterance as well .", "entities": []}, {"text": "To do this , we use the output representations from the model ( either encoder + decoder , or decoder only ) as inputs to nMOadditional transformer layers , where we vary nMO\u2208 { 0,2 } .", "entities": []}, {"text": "The final outputs are used to compute a character score , similarly to the RPA classifier .", "entities": []}, {"text": "The model can then be trained piece - wise .", "entities": []}, {"text": "After initializing the model weights with those trained on the LIGHT response generation task , we then train only the extra layers with only the character classification objective ; once the classifier achieves suitable performance on the task , we can begin to back - propagate the character classification objective multi - tasking with the dialogue task itself to the generation model directly , in the hope that the model learns to update its internal representations of the context and/or the decoded response .", "entities": [[11, 13, "TaskName", "response generation"]]}, {"text": "3.3.4 Expanded Decoder Attention Maintaining identity relies on the model \u2019s capacity to understand which inputs from the conversational history are pertinent when generating a continuation of the preceding dialogue .", "entities": []}, {"text": "In a standard , opendomain chit - chat scenario , the model has free reign to decide which elements of the context it would like to condition on when generating a response , as we are dealing with a nearly unconstrained output space ( so long as the output follows plausibly from the input ) .", "entities": []}, {"text": "In LIGHT , however , we want to emphasize certain components of the context more so than others ; specifically , when role - playing as a character , we want the model to always be reminded of its role , so that it can conditionally generate an optimal response while staying in character .", "entities": []}, {"text": "In this lens , one can view the task as \u201c grounding \" on one \u2019s character information when conversing .", "entities": []}, {"text": "Profile Grounding Inspired by models demonstrating good performance in knowledge - grounded dialogue ( Zheng and Zhou , 2019 ; Ye et al . , 2020 ; Prabhumoye et al . , 2021 ; Wang et al . , 2019 ) , we propose a simple extension to the transformer seq2seq architecture , specifically the decoder , to ensure the model knows to condition on the pro-2370", "entities": [[2, 3, "DatasetName", "Inspired"], [50, 51, "MethodName", "seq2seq"]]}, {"text": "file .", "entities": []}, {"text": "The standard transformer decoder first uses self - attention over the decoded response , and then cross - attention over the encoder outputs .", "entities": [[2, 4, "MethodName", "transformer decoder"]]}, {"text": "We add a third attention step , expanded attention , that attends again over an extracted subset of the input context ( encoded separately from the normal context ) .", "entities": []}, {"text": "We explore various subsets of the context to determine which are most important for both RPA and other automated metrics , and call this method \u201c Profile \u201d grounding as the subsets generally include the character and role description .", "entities": []}, {"text": "We utilize the exact same ( shared ) parameters for both the normal cross - attention and the expanded attention ; thus , model size is not affected .", "entities": []}, {"text": "Automated Grounding Instead of directly telling the model what to re - attend to , we also explore whether the model can learn to do this automatically , based on its own ( or other ) representations of the context .", "entities": []}, {"text": "The first method we consider is examining the decoder attention weights .", "entities": []}, {"text": "Specifically , we use the attention weights from the decoder over the full context to choose ktokens to re - attend to .", "entities": []}, {"text": "This operation is done on a per - layer basis , and thus allows different decoder layers to re - attend to ( potentially different ) components of the input .", "entities": []}, {"text": "The second method we consider is a trainable mask ; this involves feeding the encoded context through a \u201c mask \u201d layer to select various tokens to re - attend to .", "entities": []}, {"text": "Specifically , we feed the context through a linear projection layer followed by a softmax to select the top- ktokens .", "entities": [[14, 15, "MethodName", "softmax"]]}, {"text": "This set of tokens is then re - encoded by the encoder and fed to the decoder as the expanded attention context .", "entities": []}, {"text": "Finally , we explore using the classifier attention weights over the context from the RPA classifier itself .", "entities": []}, {"text": "Intuitively , the RPA classifier has learned what components of the input are necessary for determining which character is speaking ; if we look at these attention weights when considering the model \u2019s character , we know what the classifier thinks is important to use .", "entities": []}, {"text": "Combined Methods We also consider combining expanded attention with re - ranking methods , or with multi - objective training , to see if the combination can improve results .", "entities": []}, {"text": "For the latter we use the automated grounding trainable mask method .", "entities": []}, {"text": "Train Ranking Accuracy ( Hits@1/427 ) split # Eval Contextual Utterances Full Datasplit LTR Datasplit 0 4 All 0 4 All LTR 64.8 84.3 83.9 61.7 80.5 80.5 Full 31.0 86.5 84.9 27.8 75.3 74.9 Table 2 : RPA classifier performance on the validation set , comparing a partial - sequence trained model ( \u201c LTR \u201d ) to one trained only on full sequences ( \u201c Full \u201d ) .", "entities": [[2, 3, "MetricName", "Accuracy"], [15, 16, "DatasetName", "0"], [18, 19, "DatasetName", "0"]]}, {"text": "Models were trained with 4 prior utterances of context .", "entities": []}, {"text": "Re - ranker Params F1 RPA Cost # Toks Freq .", "entities": [[3, 4, "MetricName", "Params"], [4, 5, "MetricName", "F1"]]}, {"text": "None 0 0 15.8 88.4 1x Complete - only 0 0 16.0 93.0 1.1x Partial - only 10 5 % 15.9 88.6 1.3x Partial - only 10 33 % 158 91.1 4.2x Partial - only 10 100 % 15.6 93.6 11.2x Partial - only 50 5 % 15.9 88.9 3.0x PACER 10 5 % 16.1 93.3 1.2x PACER 10 33 % 15.9 94.6 3.8x PACER 10 100 % 15.8 96.3 11.5x Table 3 : Models ( 128 - truncated ) evaluated with various re - ranking schemes on the validation set .", "entities": [[1, 2, "DatasetName", "0"], [2, 3, "DatasetName", "0"], [9, 10, "DatasetName", "0"], [10, 11, "DatasetName", "0"]]}, {"text": "Cost is relative speed compared to no re - ranking at all .", "entities": []}, {"text": "4 Experimental Results 4.1 RPA Classifiers We first assess the quality of our RPA classifiers .", "entities": []}, {"text": "We measure hits@1/427 , where the model must correctly identify the character speaking out of 427 characters from the validation set , comparing the standard and left - to - right ( LTR ) models in Table 2 .", "entities": []}, {"text": "We experiment with either 0 , 4 , or All prior context utterances .", "entities": [[4, 5, "DatasetName", "0"]]}, {"text": "The LTR classifiers perform nearly as well as the full classifiers on the full datasplit , and outperform them on the LTR split .", "entities": []}, {"text": "Given the robustness of the LTR RPA classifiers , we use this model for computing RPA throughout the remaining results , unless otherwise specified .", "entities": []}, {"text": "Further results are given in Appendix Table 10 .", "entities": []}, {"text": "4.2 Baseline Generation Performance We next train baseline models for the dialogue generation task itself .", "entities": [[11, 13, "TaskName", "dialogue generation"]]}, {"text": "Performance on the LIGHT dataset test split for our baseline models can be found in Table 4 , with results on the validation set in Table 17 in the Appendix .", "entities": []}, {"text": "While lengthening the context from 128 to 1024 tokens yields better perplexity , the model obtains worse F1 scores and does not improve much if at all on role playing ability , both when measured by the RPA classifiers and in human evaluations ( see also Table 19 ) .", "entities": [[11, 12, "MetricName", "perplexity"], [17, 18, "MetricName", "F1"]]}, {"text": "Further2371", "entities": []}, {"text": "Automatic Metrics Human Evaluations Model PPL\u2193", "entities": []}, {"text": "F1\u2191RPA\u2191Mistaken All - Good \u2191", "entities": []}, {"text": "Mis .", "entities": []}, {"text": "Id. Engaging \u2191 Identity \u2193 in Conv .", "entities": []}, {"text": "\u2193", "entities": []}, {"text": "Human - - 92.68 1.34 % - 5.0 % Baselines 128 - Truncate Vanilla Baseline 12.64 15.69 87.61 6.45 % 76.0 % 35.1 % 4.04 1024 - Truncate Vanilla Baseline 12.43 15.68 87.71 7.35 % 75.0 % 38.4 % 4.16 Re - rankers 128 - Truncate Baseline + RPA Re - ranker - 15.87 92.09 5.56 % 80.3 % 34.7 % 4.14 128 - Truncate Baseline + PACER - 15.85 92.78 4.27 % 73.9 % 33.7 % 3.96 Modified Training Objectives RPA Unlikelihood ( Top-1 Token ) 13.10 15.18 87.48 7.13 % 72.8 % 39.4 % 3.87 RPA Unlikelihood ( All Tokens ) 13.31 14.77 88.07 10.51 % 67.7 % 43.0 % 3.87 Multi - Objective ( Vanilla , Dec. Only ) 12.86 15.67 87.67 10.00 % 74.8 % 49.0 % 4.21 Expanded Attention Methods Profile ( 128 , 2 rounds over ABC ) 12.37 15.74 91.70 4.82 % 81.6 % 28.4 % 4.18 Profile ( 1024 , 2 rounds over ABCD )", "entities": [[142, 143, "MethodName", "ABC"], [161, 162, "DatasetName", "ABCD"]]}, {"text": "12.23 15.66 92.18 4.00 % 83.8 % 23.8 % 4.34 Automated ( 1024 , Classifier Attn ) 12.27 15.75 90.93 5.51 % 76.0 % 29.1 % 4.04 Automated + MO ( 1024 , Dec. Only ) 13.01 15.52 88.95 4.43 % 78.6 % 23.0 % 4.12 Expanded Attention + Re - ranker Methods Profile ( 128 ) + RPA Re - ranker -15.88 95.16 2.23 % 84.4 % 14.7 % 4.24 Profile ( 128 ) + PACER - 15.79 95.31 4.07 % 85.7 % 24.5 % 4.32 Table 4 : Automated metrics and human evaluations for various models considered throughout the paper on the LIGHT testset .", "entities": []}, {"text": "RPA ( Role - Playing Accuracy ) is measured by the 4 - utterance LTR classifier , see Sec . 3.2 .", "entities": [[5, 6, "MetricName", "Accuracy"]]}, {"text": "The human evaluations are per utterance , except for Engaging and Mistaken Identity in Conversation ( with the latter indicating % of conversations with mistaken identity ) .", "entities": []}, {"text": "detailed training and optimization specifications are given in Appendix A. 4.3 RPA Re - ranker Performance Table 4 gives results for RPA - based re - ranking of generation models .", "entities": []}, {"text": "Automated results show a slight bump in F1 on the LIGHT valid set , and indeed a bump in RPA .", "entities": [[7, 8, "MetricName", "F1"]]}, {"text": "Including the intra - generation re - ranking with PACER yields an even higher RPA score .", "entities": []}, {"text": "Table 3 contains the results of varying the candidate tokens re - ranked per intra - generation step ( # Toks ) and number of partial re - ranking steps ( Freq ) , both in terms of generation metrics / RPA and relative computational cost compared to reranking .", "entities": []}, {"text": "Increasing # of toks or increasing the frequency can lead to improved F1 and RPA , but with significant latency increase for too high values ( e.g. over 11x when applying re - ranking for every partial step using the top 10 tokens each time ) .", "entities": [[12, 13, "MetricName", "F1"]]}, {"text": "Applying both partial and final complete ranking helps performance .", "entities": []}, {"text": "Note that re - ranker models use the same model to re - rank that is being used to measure RPA afterwards , making that metric biased .", "entities": []}, {"text": "Hence , human evaluations are required for this model , which will be detailed in Section 4.7 , and which will indicate that re - ranking does in fact help.4.4 Unlikelihood Results of unlikelihood ( UL ) training are also given in Table 4 .", "entities": []}, {"text": "We apply UL loss to the 128 - truncation model in two different ways : ( 1 ) Top-1 : apply the loss on the token that yields the most incorrect partial sequence RPA classification ; ( 2 ) All : apply the loss to all tokens that yield an incorrect RPA classification on partial sequences .", "entities": [[3, 4, "MetricName", "loss"], [22, 23, "MetricName", "loss"], [43, 44, "MetricName", "loss"]]}, {"text": "The RPA UL methods suffer compared to the baselines in terms of PPL and F1 , yet they retain similar RPA metrics .", "entities": [[14, 15, "MetricName", "F1"]]}, {"text": "We hypothesize that while the UL loss can adjust the model to refrain from generating outof - character responses , there are still far too many other tokens that may yield similar outcomes that are not penalized .", "entities": [[6, 7, "MetricName", "loss"]]}, {"text": "Table 12 in Appendix D includes similar results with the 1024 - truncation model .", "entities": []}, {"text": "4.5 Multi - Objective Training Multi - objective training results are in Table 5 , where the base model is a 1024 - truncation model .", "entities": []}, {"text": "We measure generation metrics in terms of RPA ( with PPL and F1 in Table 13 in Appendix E ) , and classification metrics in terms of Hits@1/427 as before .", "entities": [[12, 13, "MetricName", "F1"]]}, {"text": "The model is able to predict the appropriate character using either the decoder outputs or the encoder+decoder outputs .", "entities": []}, {"text": "For each case , nMO = 2 yielded better results than nMO = 0 .", "entities": [[13, 14, "DatasetName", "0"]]}, {"text": "Interestingly , despite the relatively strong performance of the model in classifying the right character ( 87.422372", "entities": []}, {"text": "Input nMO Stage RPA Hits@1 Human N / A - 92.8 None 0 0 88.4 Multi - Objective Dec. only 2 1 88.4 39.3 Dec. only 2 2 87.7 87.4 Enc+Dec 2 1 88.4 70.9 Enc+Dec 2 2 88.8 71.6 Multi - Objective + Automated Expanded Attention Dec.", "entities": [[4, 5, "MetricName", "Hits@1"], [12, 13, "DatasetName", "0"], [13, 14, "DatasetName", "0"]]}, {"text": "Only 0 1 89.1 86.4 Dec. Only 0 2 89.1 89.1 Enc+Dec 2 1 88.4 83.3 Enc+Dec 2 2 89.1 88.5 Table 5 : Models trained with varying multi - objective setups , evaluated on the valid set .", "entities": [[1, 2, "DatasetName", "0"], [7, 8, "DatasetName", "0"]]}, {"text": "Models are initialized from a ( 1024 - truncation ) model fine - tuned on LIGHT .", "entities": []}, {"text": "hits@1 for the best model ) , this does not translate to substantial RPA improvements over the baseline .", "entities": [[0, 1, "MetricName", "hits@1"]]}, {"text": "4.6 Expanded Attention Profile Grounding Expanding the decoder attention yields significant gains across all automated metrics , as seen in Table 6 for a 1024 - truncate model ( and in Table 15 in Appendix F for a 128truncate model ) .", "entities": []}, {"text": "As a baseline we explore simply re - attending to the full context again ; this indeed improves metrics across the board for the shortcontext model , but the long - context model actually suffers .", "entities": []}, {"text": "However , both models improve substantially over the baseline when including the full LIGHT context without the dialogue history , and attention over sub - components of the LIGHT context still yields strong improvements .", "entities": []}, {"text": "To see how much this expanded attention matters , we explored varying the number of rounds r\u2208 { 1,2,3}of expanded attention , i.e. , how many times the model attends to this additional context .", "entities": []}, {"text": "In Table 6 , we also see that a second expanded attention round yields even better results , but performance drops off after applying a third round .", "entities": []}, {"text": "Automated Grounding We show results for the automated grounding of expanded attention in Table 7 .", "entities": []}, {"text": "Attempting to use the decoder attention weights to select expanded attention context yields no additional benefits , which is not surprising : if the model could identify the pertinent components of the input beforehand , it would not require a reattention .", "entities": []}, {"text": "The trainable mask does not yield any benefits either .", "entities": []}, {"text": "However , using the RPA classifier attention weights to inform the model which tokens to re - attend to yields improved performance across all three metrics compared to the baseline , and PPLExpanded Attention r 1024 - Truncate Model PPL F1 RPA Human 0 - - 92.80 None 0 12.35 15.85 88.42 ABCD + Dialogue Hist .", "entities": [[40, 41, "MetricName", "F1"], [43, 44, "DatasetName", "0"], [48, 49, "DatasetName", "0"], [52, 53, "DatasetName", "ABCD"]]}, {"text": "1 12.47 15.82 88.34 ABCD 1 12.18 16.01 91.82 ABCD 2 12.17 15.95 92.60 ABCD 3 12.19 15.99 91.73 ABC 1 12.22 15.94 91.83 ABC 2 12.24 15.99 92.24 ABC 3 12.25 15.93 92.25 AB 1 12.27 15.87 90.97 A 1 12.30 15.80 89.13 B 1 12.34 15.76 89.46 Table 6 : Models trained with expanded attention ( profile grounding ) , evaluated on the valid set .", "entities": [[4, 5, "DatasetName", "ABCD"], [9, 10, "DatasetName", "ABCD"], [14, 15, "DatasetName", "ABCD"], [19, 20, "MethodName", "ABC"], [24, 25, "MethodName", "ABC"], [29, 30, "MethodName", "ABC"]]}, {"text": "Expanded attention input : A = Self Persona , B = Self Name , C = Partner Name , D = Setting Description .", "entities": []}, {"text": "We also vary the number of rounds rof expanded attention .", "entities": []}, {"text": "Exp .", "entities": []}, {"text": "Attn .", "entities": []}, {"text": "Grounding PPL F1 RPA Human - - 92.80 None 12.35 15.85 88.42 Profile Ground Best ( 2 rounds ) 12.17 15.95 92.60 Profile Ground Best ( 1 round ) 12.18 16.08 91.79 Profile Ground Random 12.43 15.74 87.62 Decoder Attn .", "entities": [[2, 3, "MetricName", "F1"]]}, {"text": "12.39 15.40 87.59 Trainable Mask 12.40 15.75 88.43 Classifier Attn .", "entities": []}, {"text": "( top- k ) 12.19 15.90 91.11 Classifier Attn .", "entities": []}, {"text": "( bottom- k ) 12.31 15.89 88.71 Table 7 : Models trained with expanded attention ( automated grounding ) , evaluated on the valid set .", "entities": []}, {"text": "We vary the method for selecting the extra context to re - attend to .", "entities": []}, {"text": "All models are long - truncation ( 1024 ) .", "entities": []}, {"text": "is nearly the same as profile grounding ( 12.19 vs. 12.18 ) , while RPA trails slightly behind ( 91.11 vs. 91.79 ) .", "entities": []}, {"text": "We also include the usage of the bottom- k tokens from the classifier weights to emphasize that there is indeed signal from the top- k , as using the bottom tokens does not help .", "entities": []}, {"text": "Automated Grounding + Multi - Objective Table 5 shows that combining automated grounding with the multi - objective task yields higher hits@1 compared to not using the trainable mask , especially in the first stage of multi - objective training .", "entities": [[21, 22, "MetricName", "hits@1"]]}, {"text": "However , RPA scores are only fractionally better than the baseline .", "entities": []}, {"text": "Appendix E includes results across more settings ( see Table 13 and Table 14 ) .", "entities": []}, {"text": "Expanded Attention + RPA Re - ranking The expanded attention and RPA re - ranker methods can also both be applied to obtain effective models .", "entities": []}, {"text": "Results are in Table 4 ; indeed , the combination yields the highest F1 and RPA scores.2373", "entities": [[13, 14, "MetricName", "F1"]]}, {"text": "4.7 Human Evaluations We performed human evaluation on our models .", "entities": []}, {"text": "For each model we collected 100 human - model conversations , set up similarly to the original LIGHT dataset conversations .", "entities": []}, {"text": "During the conversation , crowdworkers were asked to annotate the model \u2019s response for the following attributes : 1 ) Mistaken Identity : your partner says something that would imply they believe they \u2019re someone other than who they \u2019re noted to be ; 2 ) Contradiction : your partner says something that contradicts something they \u2019ve said before ; 3 ) Wrong Location : your partner says something that would imply they believe they are in a different location than the provided one ; 4 ) Unrelated : your partner says something that does n\u2019t follow the previous turns ; and 5 ) Repetitive : your partner says something they \u2019ve already said , or are driving the conversation in circles .", "entities": []}, {"text": "Utterances that do not contain any of the negative attributes are denoted \u201c all good \u201d .", "entities": []}, {"text": "Finally , we collect an engagingness score on a scale of 1 - 5 at the end of the conversation .", "entities": []}, {"text": "More details in Appendix I. Results are given in Table 4 , with more details results ( and comparison with a retrieval baseline ) in Table 19 in the Appendix .", "entities": []}, {"text": "The baseline model displays mistaken identity 6.45 % of the time , and has an average engagingness score of 4.04 .", "entities": []}, {"text": "Longer context increases engagingness to 4.16 but also increases mistaken identity .", "entities": []}, {"text": "Unlikelihood and multiobjective training similarly increase mistaken identity .", "entities": []}, {"text": "The successful methods , then , are the beam reranking methods and the expanded attention models .", "entities": []}, {"text": "The long - context beam re - ranker decreases mistaken identity to 4.81 % , while the profile expanded attention model improves to 4 % , and has the best engagingness of 4.34 .", "entities": []}, {"text": "Combining RPA Reranking with expanded attention yields the lowest mistaken identity ( 2.38 % ) , while adding PACER leads to the highest all - good percentage ( 85.7 % ) .", "entities": []}, {"text": "Correlations between automatic metrics and human evaluations are measured in Appendix K , where we find that RPA and mistaken identity are indeed strongly correlated .", "entities": []}, {"text": "5 Qualitative Analysis 5.1 Re - rankers & Generation Settings", "entities": []}, {"text": "We further explored three decoding settings : standard beam - search , delayed beam search ( Massarelli et al . , 2020 ) and nucleus sampling ( Holtzman et al . , 2020 ) , both in a re - ranking setting and not .", "entities": []}, {"text": "When considering performance on automated metrics(provided in Table 20 in the Appendix ) , we see that generation settings other than beam search , when using a re - ranker , yield lower F1 scores but higher RPA scores , as the RPA re - ranker has more diversity of candidate responses from which to choose ; however , these methods perform worse in human evaluations , with nucleus sampling reranking yielding far more problems and far lower engagingness ratings .", "entities": [[33, 34, "MetricName", "F1"]]}, {"text": "Qualitative analysis of outputs on the test set are in Appendix J.1 .", "entities": []}, {"text": "5.2 Classifier Failure Modes We note that the human dialogue data is classified as being \u201c in character \u201d only 92.8 % of the time on the validation set by the LTR RPA classifier .", "entities": []}, {"text": "We examine the scenarios in which the classifier is incorrect , with example input / output pairs in Table 21 in the Appendix .", "entities": []}, {"text": "First , there are instances where either character could have said the output response ( row 1 ) .", "entities": []}, {"text": "Second , there are instances where there are not enough clues in the context to provide an estimation of who said the response , for example at the beginning of the conversation ( row 2 ) .", "entities": []}, {"text": "And , there are still some small amount of instances that the classifier simply fails ( row 3 ) .", "entities": []}, {"text": "5.3 Model Failure Modes We analyze the results of turn annotation to understand what failure modes contribute to mistaken identity .", "entities": []}, {"text": "A full list of such modes is in Table 16 ; the baseline model most often mistakes its partner for itself ( i.e. , the model thinks it is talking to itself ) .", "entities": []}, {"text": "Other common failures include the model thinking that it is its partner \u2019s character , or emulating irrelevant characteristics .", "entities": []}, {"text": "5.4 Per - Turn Character Accuracy Analysis We consider the RPA of various models when evaluated across the turns of conversation .", "entities": [[5, 6, "MetricName", "Accuracy"]]}, {"text": "Intuitively , baseline models would suffer as the conversation goes on for a variety of reasons ( character roles are truncated out of context , more input yields noisier outputs , etc . ) .", "entities": []}, {"text": "Appendix Figure 1 shows the perturn results for a set of representative models .", "entities": []}, {"text": "The human outputs are most often correct on the first turn , with gradual RPA decay throughout the conversation .", "entities": []}, {"text": "The 128 - truncate baseline , as expected , suffers a dramatic performance drop after the first couple of turns .", "entities": []}, {"text": "Meanwhile , with the profile expanded attention , we see near - human performance , with better RPA in later turns .", "entities": []}, {"text": "Including RPA reranking improves dramatically over all turns.2374", "entities": []}, {"text": "5.5 Expanded Attention Visualization To gain some insight into what is happening with the expanded attention , we mapped out the attention between context and response tokens for both a baseline model with no expanded attention , and a model with profile expanded attention .", "entities": []}, {"text": "Figures 4 and 5 in the Appendix display the heat maps for an example context and response , with details on heat map construction given in Appendix M.", "entities": []}, {"text": "We find that the baseline model spreads its attention out across both the LIGHT context and the dialogue history , with the majority of the attention looking at overlapping words in the context and the response and almost no attention on the character names .", "entities": []}, {"text": "The expanded attention model concentrates on the recent dialogue history heavily in the first level of attention , and then concentrates on pertinent words in the context related to the character information ( i.e. , the character names ) in the second round of attention .", "entities": []}, {"text": "6 Conclusion In this work we explored the problem of maintaining one \u2019s character in open dialogue , and showed that state - art - of - the - art models have a fundamental weakness in this regard .", "entities": []}, {"text": "We provided a clear framing of the problem and showed one can build automatic metrics ( RPA ) that evaluate models using a classifier .", "entities": []}, {"text": "We then explored a variety of methods throughout this paper .", "entities": []}, {"text": "While a wide variety of well - known techniques , such as multi - objective or unlikelihood training , have little impact , we found that expanded attention and re - ranking are two approaches that can help to a degree , and their combination also improves results .", "entities": []}, {"text": "Our introduced method PACER performs well and may be suitable for other tasks beyond the focus of this paper .", "entities": []}, {"text": "Nevertheless , our best methods still lag behind human ( crowdworker ) performance in several regards , e.g. 1.34 % vs. 2.23 % in terms of mistaken identity per turn , or 5 % vs. 14.7 % per conversation .", "entities": []}, {"text": "Therefore considerable progress still has to be made on this challenging problem .", "entities": []}, {"text": "7 Ethical Considerations Limitations We note in the conclusion that the problem is not solved ; our best models still lag behind human performance in maintaining character identity .", "entities": []}, {"text": "All results are tested in the LIGHT environment , comprising open - domain dialoguewithin constrained settings with assigned characters .", "entities": []}, {"text": "The application of these methods to other role - playing ( or otherwise ) settings is left for future work , though we believe that such methods could be beneficial outside of LIGHT .", "entities": []}, {"text": "Potential Risks We provide methods for mitigating mistaken identity in dialogue models .", "entities": []}, {"text": "It follows that such methods yield models that are more convincingly role - playing as a given character .", "entities": []}, {"text": "With more convincingly in - character models , someone with bad intentions could have a model imitate realworld people without consent , or worse , can say negative / harmful things while impersonating someone else .", "entities": []}, {"text": "We note that our methods are orthogonal to improvements in dialogue safety ( Xu et al . , 2020 ; Dinan et al . , 2019a ) , and so can be used in tandem to mitigate these potential risks .", "entities": []}, {"text": "Scientific Artifacts", "entities": []}, {"text": "We make use of LIGHT in this work ( Urbanek et al . , 2019 ) ( released under CC - BY license ) , an English - language crowdsourced dataset .", "entities": []}, {"text": "We also plan to release the code and models ( will be released under MIT license ) , with the intended use being for others ( and ourselves ) to reproduce and build upon the research discussed in this paper .", "entities": []}, {"text": "References Daniel Adiwardana , Minh - Thang Luong , David R", "entities": []}, {"text": "So , Jamie Hall , Noah Fiedel , Romal Thoppilan , Zi Yang , Apoorv Kulshreshtha , Gaurav Nemade , Yifeng Lu , et al . 2020 .", "entities": []}, {"text": "Towards a human - like open - domain chatbot .", "entities": [[8, 9, "TaskName", "chatbot"]]}, {"text": "arXiv preprint arXiv:2001.09977 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jason Baumgartner , Savvas Zannettou , Brian Keegan , Megan Squire , and Jeremy Blackburn .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "The pushshift reddit dataset .", "entities": [[1, 3, "DatasetName", "pushshift reddit"]]}, {"text": "arXiv preprint arXiv:2001.08435 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Emily Dinan , Samuel Humeau , Bharath Chintagunta , and Jason Weston . 2019a .", "entities": []}, {"text": "Build it break it fix it for dialogue safety : Robustness from adversarial human attack .", "entities": []}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 4537\u20134546 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Emily Dinan , Varvara Logacheva , Valentin Malykh , Alexander Miller , Kurt Shuster , Jack Urbanek , Douwe Kiela , Arthur Szlam , Iulian Serban , Ryan Lowe , Shrimai Prabhumoye , Alan W. Black , Alexander Rudnicky , Jason Williams , Joelle Pineau , Mikhail Burtsev , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "The second conversational intelligence challenge ( ConvAI2 ) .", "entities": [[6, 7, "DatasetName", "ConvAI2"]]}, {"text": "In The2375", "entities": []}, {"text": "NeurIPS \u2019 18 Competition , pages 187\u2013208 , Cham .", "entities": []}, {"text": "Springer International Publishing .", "entities": []}, {"text": "Emily Dinan , Stephen Roller , Kurt Shuster , Angela Fan , Michael Auli , and Jason Weston .", "entities": []}, {"text": "2019b .", "entities": []}, {"text": "Wizard of wikipedia : Knowledge - powered conversational agents .", "entities": [[0, 3, "DatasetName", "Wizard of wikipedia"]]}, {"text": "In 7th International Conference on Learning Representations , ICLR 2019 , New Orleans , LA , USA , May 6 - 9 , 2019 .", "entities": []}, {"text": "OpenReview.net .", "entities": []}, {"text": "Karthik Gopalakrishnan , Behnam Hedayatnia , Qinglang Chen , Anna Gottardi , Sanjeev Kwatra , Anu Venkatesh , Raefer Gabriel , Dilek Hakkani - T\u00fcr , and Amazon Alexa AI . 2019 .", "entities": []}, {"text": "Topical - chat : Towards knowledge - grounded open - domain conversations .", "entities": [[0, 3, "DatasetName", "Topical - chat"]]}, {"text": "In INTERSPEECH , pages 1891\u20131895 .", "entities": []}, {"text": "Ari Holtzman , Jan Buys , Li Du , Maxwell Forbes , and Yejin Choi .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "The curious case of neural text degeneration .", "entities": []}, {"text": "In 8th International Conference on Learning Representations , ICLR 2020 , Addis Ababa , Ethiopia , April 26 - 30 , 2020 .", "entities": []}, {"text": "OpenReview.net .", "entities": []}, {"text": "Samuel Humeau , Kurt Shuster , Marie - Anne Lachaux , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Poly - encoders : Architectures and pre - training strategies for fast and accurate multi - sentence scoring .", "entities": []}, {"text": "In 8th International Conference on Learning Representations , ICLR 2020 , Addis Ababa , Ethiopia , April 26 - 30 , 2020 .", "entities": []}, {"text": "OpenReview.net .", "entities": []}, {"text": "Diederik P. Kingma and Jimmy Ba . 2015 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "In 3rd International Conference on Learning Representations , ICLR 2015 , San Diego , CA , USA , May 7 - 9 , 2015 , Conference Track Proceedings .", "entities": []}, {"text": "Mojtaba Komeili , Kurt Shuster , and Jason Weston .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Internet - augmented dialogue generation .", "entities": [[3, 5, "TaskName", "dialogue generation"]]}, {"text": "Ilia Kulikov , Alexander Miller , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Importance of search and evaluation strategies in neural dialogue modeling .", "entities": []}, {"text": "In Proceedings of the 12th International Conference on Natural Language Generation , pages 76\u201387 , Tokyo , Japan .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Margaret Li , Stephen Roller , Ilia Kulikov , Sean Welleck , Y - Lan Boureau , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Do n\u2019t say that !", "entities": []}, {"text": "making inconsistent dialogue unlikely with unlikelihood training .", "entities": []}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 4715\u20134728 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chia - Wei Liu , Ryan Lowe , Iulian Serban , Mike Noseworthy , Laurent Charlin , and Joelle Pineau .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "How not to evaluate your dialogue system : An empirical study of unsupervised evaluation metrics for dialogue response generation .", "entities": [[17, 19, "TaskName", "response generation"]]}, {"text": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Tianyu Liu , Yizhe Zhang , Chris Brockett , Yi Mao , Zhifang Sui , Weizhu Chen , and Bill Dolan .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "A token - level reference - free hallucination detection benchmark for free - form text generation .", "entities": [[14, 16, "TaskName", "text generation"]]}, {"text": "Ilya Loshchilov and Frank Hutter .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Decoupled weight decay regularization .", "entities": [[1, 3, "MethodName", "weight decay"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Luca Massarelli , Fabio Petroni , Aleksandra Piktus , Myle Ott , Tim Rockt\u00e4schel , Vassilis Plachouras , Fabrizio Silvestri , and Sebastian Riedel .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "How decoding strategies affect the verifiability of generated text .", "entities": []}, {"text": "In Findings of the Association for Computational Linguistics : EMNLP 2020 , pages 223\u2013235 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Pierre - Emmanuel Mazar\u00e9 , Samuel Humeau , Martin Raison , and Antoine Bordes .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Training millions of personalized dialogue agents .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2775\u20132779 , Brussels , Belgium . Association for Computational Linguistics .", "entities": []}, {"text": "Alexander Miller , Will Feng , Dhruv Batra , Antoine Bordes , Adam Fisch , Jiasen Lu , Devi Parikh , and Jason Weston . 2017 .", "entities": [[12, 13, "MethodName", "Adam"]]}, {"text": "ParlAI : A dialog research software platform .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing : System Demonstrations , pages 79\u201384 , Copenhagen , Denmark .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yixin Nie , Mary Williamson , Mohit Bansal , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "I like fish , especially dolphins : Addressing contradictions in dialogue modeling .", "entities": []}, {"text": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing ( Volume 1 : Long Papers ) , pages 1699\u20131713 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Shrimai Prabhumoye , Kazuma Hashimoto , Yingbo Zhou , Alan W Black , and Ruslan Salakhutdinov .", "entities": [[14, 15, "DatasetName", "Ruslan"]]}, {"text": "2021 .", "entities": []}, {"text": "Focused attention improves documentgrounded generation .", "entities": []}, {"text": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 4274\u20134287 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 .", "entities": []}, {"text": "Language models are unsupervised multitask learners .", "entities": []}, {"text": "OpenAI Blog , 1(8 ) .", "entities": []}, {"text": "Hannah Rashkin , Eric Michael Smith , Margaret Li , and Y - Lan Boureau .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Towards empathetic opendomain conversation models : A new benchmark and dataset .", "entities": [[9, 11, "DatasetName", "and dataset"]]}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 5370\u20135381 , Florence , Italy . Association for Computational Linguistics .", "entities": [[17, 18, "MethodName", "Florence"]]}, {"text": "Stephen Roller , Emily Dinan , Naman Goyal , Da Ju , Mary Williamson , Yinhan Liu , Jing Xu , Myle Ott , Eric Michael Smith , Y - Lan Boureau , and Jason Weston .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Recipes for building an open - domain chatbot .", "entities": [[7, 8, "TaskName", "chatbot"]]}, {"text": "In Proceedings of the 16th Conference of2376", "entities": []}, {"text": "the European Chapter of the Association for Computational Linguistics : Main Volume , pages 300\u2013325 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Sashank Santhanam , Behnam Hedayatnia , Spandana Gella , Aishwarya Padmakumar , Seokhwan Kim , Yang Liu , and Dilek Hakkani - Tur . 2021 .", "entities": []}, {"text": "Rome was built in 1776 : A case study on factual correctness in knowledge - grounded response generation .", "entities": [[16, 18, "TaskName", "response generation"]]}, {"text": "Kurt Shuster , Spencer Poff , Moya Chen , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Retrieval augmentation reduces hallucination in conversation .", "entities": []}, {"text": "In Findings of the Association for Computational Linguistics : EMNLP 2021 , pages 3784\u20133803 , Punta Cana , Dominican Republic .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Koustuv Sinha , Robin Jia , Dieuwke Hupkes , Joelle Pineau , Adina Williams , and Douwe Kiela . 2021 .", "entities": []}, {"text": "Masked language modeling and the distributional hypothesis : Order word matters pre - training for little .", "entities": [[0, 3, "TaskName", "Masked language modeling"]]}, {"text": "InProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages 2888\u20132913 , Online and Punta Cana , Dominican Republic .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Jack Urbanek , Angela Fan , Siddharth Karamcheti , Saachi Jain , Samuel Humeau , Emily Dinan , Tim Rockt\u00e4schel , Douwe Kiela , Arthur Szlam , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Learning to speak and act in a fantasy text adventure game .", "entities": []}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLPIJCNLP ) , pages 673\u2013683 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N. Gomez , Lukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems 30 : Annual Conference on Neural Information Processing Systems 2017 , December 4 - 9 , 2017 , Long Beach , CA , USA , pages 5998\u20136008 .", "entities": []}, {"text": "Xinyi Wang , Jason Weston , Michael Auli , and Yacine Jernite .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Improving conditioning in contextaware sequence to sequence models .", "entities": [[4, 7, "MethodName", "sequence to sequence"]]}, {"text": "Sean Welleck , Ilia Kulikov , Stephen Roller , Emily Dinan , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Neural text generation with unlikelihood training .", "entities": [[1, 3, "TaskName", "text generation"]]}, {"text": "In 8th International Conference on Learning Representations , ICLR 2020 , Addis Ababa , Ethiopia , April 26 - 30 , 2020 .", "entities": []}, {"text": "OpenReview.net .", "entities": []}, {"text": "Jing Xu , Da Ju , Margaret Li , Y - Lan Boureau , Jason Weston , and Emily Dinan . 2020 .", "entities": []}, {"text": "Recipes for safety in open - domain chatbots .", "entities": []}, {"text": "arXiv preprint arXiv:2010.07079 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jing Xu , Arthur Szlam , and Jason Weston .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Beyond goldfish memory : Long - term open - domain conversation .", "entities": []}, {"text": "Kevin Yang and Dan Klein .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "FUDGE :", "entities": []}, {"text": "Controlled text generation with future discriminators .", "entities": [[1, 3, "TaskName", "text generation"]]}, {"text": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 3511\u20133535 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Hao - Tong Ye , Kai - Lin Lo , Shang - Yu Su , and Yun - Nung Chen .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Knowledge - grounded response generation with deep attentional latent - variable model .", "entities": [[3, 5, "TaskName", "response generation"]]}, {"text": "Computer Speech & Language , 63:101069 .", "entities": []}, {"text": "Saizheng Zhang , Emily Dinan , Jack Urbanek , Arthur Szlam , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Personalizing dialogue agents : I have a dog , do you have pets too ?", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 2204\u20132213 , Melbourne , Australia .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Wen Zheng and Ke Zhou .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Enhancing conversational dialogue models with grounded knowledge .", "entities": []}, {"text": "In Proceedings of the 28th ACM International Conference on Information and Knowledge Management , CIKM \u2019 19 , page 709\u2013718 , New York , NY , USA .", "entities": [[5, 6, "DatasetName", "ACM"], [12, 13, "TaskName", "Management"]]}, {"text": "Association for Computing Machinery .", "entities": []}, {"text": "Yinhe Zheng , Rongsheng Zhang , Minlie Huang , and Xiaoxi Mao . 2020 .", "entities": []}, {"text": "A pre - training based personalized dialogue generation model with persona - sparse data .", "entities": [[6, 8, "TaskName", "dialogue generation"]]}, {"text": "Proceedings of the AAAI Conference on Artificial Intelligence , 34(05):9693\u20139700 .", "entities": []}, {"text": "Kangyan Zhou , Shrimai Prabhumoye , and Alan W Black .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A dataset for document grounded conversations .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 708\u2013713 , Brussels , Belgium . Association for Computational Linguistics.2377", "entities": []}, {"text": "A Training Details All models are trained with the ParlAI2framework ( Miller et al . , 2017 ) .", "entities": []}, {"text": "Due to the large number of experimental setups and computational cost , we do not consider multiple training runs .", "entities": []}, {"text": "Base Models RPA classifier Poly - encoders are initialized with the 622 M parameter models from Roller et al .", "entities": []}, {"text": "( 2021 ) ; we also use this architecture for dialogue response ( retrieval ) models which we also evaluate ( see Table 19 ) .", "entities": []}, {"text": "All generative models are initialized with BlenderBot , also from Roller et al .", "entities": []}, {"text": "( 2021 ) , a 2.7B parameter transformer encoder / decoder model .", "entities": []}, {"text": "Each model was pre - trained on 1.5B training examples from pushshift.io Reddit ( Baumgartner et al . , 2020 ) , with BlenderBot additionally fine - tuned on the BST tasks ( see Roller et", "entities": [[12, 13, "DatasetName", "Reddit"]]}, {"text": "al . ( 2021 ) for more details ) , before training on LIGHT .", "entities": []}, {"text": "RPA Classifiers The RPA classifier models are trained with a cross - entropy loss over the correct label , with 99 random negatives chosen from the training set ; we ensured that each character in conversation showed up in the set of candidate labels .", "entities": [[13, 14, "MetricName", "loss"]]}, {"text": "The models were trained with a batch size of 16 on 4 32 GB GPUs , with early stopping on the validation set according to valid accuracy .", "entities": [[6, 8, "HyperparameterName", "batch size"], [17, 19, "MethodName", "early stopping"], [26, 27, "MetricName", "accuracy"]]}, {"text": "We used the Adam optimizer ( Kingma and Ba , 2015 ) with weight decay ( Loshchilov and Hutter , 2019 ) , sweeping over learning rates { 1e\u22125,5e\u22126 } .", "entities": [[3, 4, "MethodName", "Adam"], [4, 5, "HyperparameterName", "optimizer"], [13, 15, "MethodName", "weight decay"]]}, {"text": "Generative Models All variants of generative models were trained using 8 32 GB GPUs , with early stopping on perplexity on the validation set .", "entities": [[16, 18, "MethodName", "early stopping"], [19, 20, "MetricName", "perplexity"]]}, {"text": "We used the Adam optimizer , sweeping over learning rates { 1e\u22125,7e\u22126 } , training with a batch size of 128 for the short - truncation models , and 32 for the long - truncation models .", "entities": [[3, 4, "MethodName", "Adam"], [4, 5, "HyperparameterName", "optimizer"], [17, 19, "HyperparameterName", "batch size"]]}, {"text": "For the multiobjective models , we used the same loss ( and negative - sampling ) setup as the RPA classifiers for the character accuracy objective .", "entities": [[9, 10, "MetricName", "loss"], [24, 25, "MetricName", "accuracy"]]}, {"text": "During inference , unless otherwise specified , we generated using beam - search with beam size of 10 , enforcing a minimum length of 20 , and with tri - gram blocking with respect to both the context and the current generation .", "entities": []}, {"text": "B RPA Classifier Training We build the training data for the RPA classifiers from the LIGHT dataset .", "entities": []}, {"text": "The input is a concate2https://parl.aiDataset Train Valid Test LIGHT ( Urbanek et al . , 2019 ) 111k 6k 13k RPA , 0 - Utterance 212k 12k 26k", "entities": [[22, 23, "DatasetName", "0"]]}, {"text": "RPA , 4 - Utterance 748k 45k 90k RPA , All - Utterance 34k 2k 4k RPA LTR , 0 - Utterance 3.3 M 205k 414k RPA LTR , 4 - Utterance 12 M 747k 1.5 M RPA LTR , All - Utterance 516k 31k 64k Table 8 : Number of training , valid , and test examples for the LIGHT dataset , as well as the RPA training splits ( both normal and LTR ) .", "entities": [[19, 20, "DatasetName", "0"]]}, {"text": "nation of ( 1 ) the LIGHT context ( set of characters , setting , etc . ) ; ( 2 ) a fixed number of previous utterances in the conversation ; and ( 3 ) a candidate utterance from any point later in the conversation ( a special token separates the candidate utterance from the prior context ) .", "entities": []}, {"text": "We experiment with either 0 , 4 , or N\u22122prior utterances ( dubbed \u201c All \u201d in relevant tables ) , where Nis the total number of utterances ( N\u22122allows the last turn for each speaker to be a candidate utterance ) .", "entities": [[4, 5, "DatasetName", "0"]]}, {"text": "The left - toright ( LTR ) data split is built similarly , except each example ibecomes wiexamples , where wiis the number of tokens in the candidate utterance for example i. Statistics of the training dataset are given in Table 8 .", "entities": []}, {"text": "Suppose we choose nas the number of prior utterances to include in the input , and let us denote D= 8538 to represent all the dialogues in the LIGHT train split , and U= 110877 to represent all the utterances in those dialogues .", "entities": []}, {"text": "For the RPA classification dataset , each dialogue is presented twice , once from each character \u2019s POV .", "entities": []}, {"text": "When n= N\u22121 , where Nis the length of a conversation , then we have roughly 2Dtraining examples .", "entities": []}, {"text": "When n= 0 , we have roughly 2Utraining examples .", "entities": [[2, 3, "DatasetName", "0"]]}, {"text": "For any value 0 < n < N \u22121 , we build out several examples from several slices of each conversation .", "entities": [[3, 4, "DatasetName", "0"]]}, {"text": "Suppose we have dialogue diwithN utterances { u0 , u1 , ... , u N } .", "entities": []}, {"text": "To build the training data from dialogue di , we select all continuous subsets of nutterances within di , forming contexts ci={ui , ... , u i+n } \u2200 0\u2264i\u2264N\u2212i Then , we look at all N\u2212iutterances following utterance ui+n , and use these as target utterances in the task .", "entities": []}, {"text": "The goal of this is to build the model to be robust to dataset artifacts ; without this modification , the model could trivially pick out the character just by looking at the number of alternating utterances.2378", "entities": []}, {"text": "# Prior No LIGHT Context LIGHT Context Utterances", "entities": []}, {"text": "H@1/427 H@1/2", "entities": []}, {"text": "H@1/427 H@1/2 0 10.4 60.3 77.6 77.7 4 87.3 87.4 86.5 86.5 All 85.7 86.7 89.3 89.8 Table 9 : RPA classifier performance on the validation set , as measured by Hits@1/427 and Hits@1/2 ( all characters and participant characters as candidates , respectively ) .", "entities": [[2, 3, "DatasetName", "0"]]}, {"text": "Each model is trained and evaluated with that # of prior utterances .", "entities": []}, {"text": "# Train - time Hits@1/427 Prior Utterances # Eval Prior Utterances 0 4 All Without LIGHT Context 0 10.35 18.58 17.71 4 2.10 87.31 84.35 All 7.02 81.26 85.70 With LIGHT Context 0", "entities": [[11, 12, "DatasetName", "0"], [17, 18, "DatasetName", "0"], [32, 33, "DatasetName", "0"]]}, {"text": "77.64 66.20 58.61 4 31.04 86.48 84.90 All 32.54 82.73 89.26 Table 10 : RPA classifier performance on the validation set , as measured by hits@1/427 .", "entities": []}, {"text": "Highlighted numbers indicate models evaluated on the split on which they were trained .", "entities": []}, {"text": "These measures force the model to fully understand the task and react accordingly .", "entities": []}, {"text": "C RPA Classifier Performance : Additional Results In Table 10 , we see how each RPA classifier performs on the various datasplits , varying the number of prior utterances used during training and evaluation .", "entities": []}, {"text": "Each model performs best on the split on which it was trained ( the highlighted numbers ) .", "entities": []}, {"text": "C.1 Left - to - Right Dynamic Classification We find that the left - to - right RPA classifiers are correctly sensitive to per - token perturbations in the input , and can accurately predict the speaker at the token level .", "entities": [[7, 8, "TaskName", "Classification"]]}, {"text": "In Table 11 , we give an example where the classifier changes its character prediction , depending on the candidate utterance .", "entities": []}, {"text": "D Unlikelihood : Additional Results In Table 12 , we compare UL models across different truncation lengths ; the same story applies to the 1024 - truncation models .", "entities": []}, {"text": "We additionally include a third method , Random-3 , where we apply the loss randomly to 3 tokens that yield incorrect RPA classifications .", "entities": [[13, 14, "MetricName", "loss"]]}, {"text": "This method performs about thesame as the Top-1 method , but the RPA is lower , indicating that the Top-1 method at least is providing some signal .", "entities": []}, {"text": "E Multi - Objective : Additional Results E.1 Perplexity & F1", "entities": [[8, 9, "MetricName", "Perplexity"], [10, 11, "MetricName", "F1"]]}, {"text": "Table 13 displays full PPL and F1 scores corresponding to the models in Table 5 .", "entities": [[6, 7, "MetricName", "F1"]]}, {"text": "E.2 Multi - Objective + Automated Grounding In Table 14 , we see how , when using either the encoder+decoder or just the decoder outputs , we do not require additional multi - objective layers ( as we did in the non - automated - grounding case ) .", "entities": []}, {"text": "F Expanded Attention : Additional Results We provide results for both the 128 - truncate and 1024 - truncate models with profile grounding in Table 15 .", "entities": []}, {"text": "Trends remain the same for both models .", "entities": []}, {"text": "G Full Valid Results Table 17 includes results on the LIGHT validation set for models in Table 4 .", "entities": []}, {"text": "H Retrieval Re - rankers We evaluated a Poly - encoder baseline model with an RPA re - ranker as well .", "entities": []}, {"text": "The Poly - encoder scores utterances from the full training set as candidates , and the candidates for re - ranking are the top- k ranked utterances ; results are in Table 18 .", "entities": []}, {"text": "Retrieval models benefit dramatically from the re - ranking , improving to almost 99 % RPA as measured by the LTR classifier .", "entities": []}, {"text": "As the candidate responses for retrieval models come from the set of all training utterances , and due to overlap between the set of characters appearing in the train and valid sets , we can examine how often the model output was originally spoken by its partner \u2019s character ; this can be seen as a proxy for mistaken identity .", "entities": []}, {"text": "We find that the re - ranker reduces the amount of time that the model returns a message its partner said , indicating some viable and promising results .", "entities": []}, {"text": "I Full Human Evaluation Results In Table 19 , we display the full results of human evaluations across all dimensions .", "entities": []}, {"text": "We note that the Poly - encoder model is best at not mistaking location or being repetitive , but this is expected given its retrieving over human - written utterances .", "entities": []}, {"text": "In2379", "entities": []}, {"text": "Figure 1 : Per - turn RPA classifications , for a variety of models .", "entities": []}, {"text": "Error bars show the difference between the model \u2019s RPA value and the human \u2019s RPA value.2380", "entities": [[0, 1, "MetricName", "Error"]]}, {"text": "Setting : Turquoise Shore , Shore A beautiful turquoise color water by the shore .", "entities": []}, {"text": "It is filled with many gems and gold .", "entities": []}, {"text": "Character 1 : Sea Witch .", "entities": []}, {"text": "I am a sea witch .", "entities": []}, {"text": "I pray on young sailors who hope to find adventure and treasures on the open sea .", "entities": []}, {"text": "I lure them in with magic spells and promise of riches .", "entities": []}, {"text": "Character 2 : Mermaid .", "entities": []}, {"text": "I am one of the most beautiful mermaids to live in the sea .", "entities": []}, {"text": "I like to watch the other sea creatures swim by me , including dolphins , who are my favorite creatures because they are so friendly .", "entities": []}, {"text": "I fear the people who live on land because they hunt my kind Classified Utterance : Hey there Mermaid !", "entities": []}, {"text": "Long time , no see .", "entities": []}, {"text": "Classified Utterance : Hey there Sea Witch !", "entities": []}, {"text": "Long time , no see .", "entities": []}, {"text": "Correct Speaker : Sea Witch Correct Speaker : Mermaid Word Predicted Speaker Confidence Word Predicted Speaker Confidence Hey sea witch 0.5156", "entities": []}, {"text": "Hey sea witch 0.5156 there sea witch 0.5467 there sea witch 0.5467 Mermaid !", "entities": []}, {"text": "sea witch 0.9978 sea mermaid 0.9968 witch mermaid 1.000 Long sea witch 0.9981 Long mermaid 1.000 time , sea witch 0.9979 Time mermaid 1.000 no sea witch 0.9982 no mermaid 1.000 see .", "entities": []}, {"text": "sea witch 0.9985 see .", "entities": []}, {"text": "mermaid 1.000 Table 11 : Left - to - right dynamic classification examples .", "entities": []}, {"text": "A candidate utterance is shown , along with the classifier \u2019s predictions at each partial decoded sequence .", "entities": []}, {"text": "Left : The true next utterance in the dialogue , with the RPA classifier \u2019s predictions and confidence token by token .", "entities": []}, {"text": "Right : A perturbed utterance .", "entities": []}, {"text": "If we switch the name being addressed , the model switches its predictions immediately .", "entities": []}, {"text": "Unlikelihood Method PPL F1 RPA Human - - 92.80 None ( 128 ) 12.54 15.80 88.54 None ( 1024 ) 12.35 15.85 88.42 128 - Truncation RPA UL : Top-1 Token 13 15.35 88.54 RPA UL : All tokens 12.86 15.28 88.86 RPA UL : Random-3 12.99 15.37 87.85 1024 - Truncation RPA UL : Top-1 Token 12.49 15.66 88.12 RPA UL : All tokens 12.57 15.83 88.06 Table 12 : Models trained with unlikelihood loss , evaluated on the valid set .", "entities": [[3, 4, "MetricName", "F1"], [75, 76, "MetricName", "loss"]]}, {"text": "We vary the tokens to which we apply UL loss .", "entities": [[9, 10, "MetricName", "loss"]]}, {"text": "Input nMO Stage PPL F1 RPA Hits@1 Human N / A - - 92.8 None 0 0 12.4 15.9 88.4 Multi - Objective Dec. only 2 1 12.4 15.9 88.4 39.3 Dec. only 2 2 12.8 16.0 87.7 87.4 Enc+Dec 2 1 12.4 15.9 88.4 70.9 Enc+Dec 2 2 12.5 15.8 88.8 71.6 Multi - Objective + Automated Expanded Attention Dec.", "entities": [[4, 5, "MetricName", "F1"], [6, 7, "MetricName", "Hits@1"], [15, 16, "DatasetName", "0"], [16, 17, "DatasetName", "0"]]}, {"text": "Only 0 1 13.2 15.7 89.1", "entities": [[1, 2, "DatasetName", "0"]]}, {"text": "86.4 Dec. Only 0 2 12.9 15.9 89.1 89.1 Enc+Dec 2 1 12.9 15.8 88.4 83.3 Enc+Dec 2 2 12.7 15.8 89.1 88.5 Table 13 : Models trained with varying multi - objective setups , evaluated on the valid set .", "entities": [[3, 4, "DatasetName", "0"]]}, {"text": "Models are initialized from a ( 1024 - truncation ) model fine - tuned on LIGHT.Input nMO Stage PPL F1 RPA Hits@1/427 Human 0 - - 92.80 None 0 0 12.35 15.85 88.42 Dec.", "entities": [[19, 20, "MetricName", "F1"], [23, 24, "DatasetName", "0"], [28, 29, "DatasetName", "0"], [29, 30, "DatasetName", "0"]]}, {"text": "Only 0 1 13.22 15.66 89.08 86.37 Dec. Only 0 2 12.92 15.88 89.10 89.10 Enc+Dec 0 1 13.24 15.55 88.83 85.78 Enc+Dec 0 2 13.44 15.61 89.29 89.22 Enc+Dec 2 1 12.94 15.80 88.39 83.25 Enc+Dec 2 2 12.69 15.77 89.05 88.49 Table 14 :", "entities": [[1, 2, "DatasetName", "0"], [9, 10, "DatasetName", "0"], [16, 17, "DatasetName", "0"], [23, 24, "DatasetName", "0"]]}, {"text": "Models trained with varying multi - objective + automated grounding setups , evaluated on the valid set .", "entities": []}, {"text": "The base model in all cases is initialized from a generation model fine - tuned on LIGHT .", "entities": []}, {"text": "Exp .", "entities": []}, {"text": "r 128 - Truncate Model 1024 - Truncate Model Attn .", "entities": []}, {"text": "PPL F1 RPA PPL F1 RPA Human 0 - - 92.80 - - 92.80 None 0 12.59 15.80 88.28 12.35 15.85 88.42 ABCD+ 1 12.23 15.87 90.59 12.47 15.82 88.34 ABCD 1 12.25 15.97 90.94 12.18 16.01 91.82 ABCD 2 12.23 15.89 90.83 12.17 15.95 92.60 ABCD 3 12.26 15.81 90.44 12.19 15.99 91.73 ABC 1 12.33 15.82 91.50 12.22 15.94 91.83 ABC 2 12.31 16.03 92.03 12.24 15.99 92.24 ABC 3 12.33 15.90 91.59 12.25 15.93 92.25 AB 1 12.42 15.92 90.31 12.27 15.87 90.97 A 1 12.46 16.05 90.22 12.30 15.80 89.13 B 1 12.53 15.85 89.85 12.34 15.76 89.46 Table 15 : Models trained with expanded attention ( profile grounding ) , evaluated on the valid set .", "entities": [[1, 2, "MetricName", "F1"], [4, 5, "MetricName", "F1"], [7, 8, "DatasetName", "0"], [15, 16, "DatasetName", "0"], [30, 31, "DatasetName", "ABCD"], [38, 39, "DatasetName", "ABCD"], [46, 47, "DatasetName", "ABCD"], [54, 55, "MethodName", "ABC"], [62, 63, "MethodName", "ABC"], [70, 71, "MethodName", "ABC"]]}, {"text": "Expanded attention input : A = Self Persona , B = Self Name , C = Partner Name , D = Setting Description , + = dialogue history .", "entities": []}, {"text": "We also vary the number of rounds rof expanded attention.2381", "entities": []}, {"text": "Percentage Model : Beam Baseline Delayed Beam Baseline Delayed Beam with Re - ranker thinks it is someone else / partner 0 % 13.04 % 19.23 % Thinks partner \u2019s character is its character ( i.e. , thinks it is talking to itself )", "entities": [[21, 22, "DatasetName", "0"]]}, {"text": "57.69 % 56.52 % 11.54 % emulates partner \u2019s characteristic 0 % 4.35 % 0 % incorrectly identifies partner 19.23 % 17.39 % 30.77 % talks about its character in the 3rd person 0 % 4.35 % 0 % emulates irrelevant characteristic 3.85 % 0 % 7.69 % combines self and partner persona 7.69 % 0 % 9.62 % incorrectly identifies 3rd party character 0 % 0 % 1.92 % claims it does not know who it is 0 % 0 % 1.92 % noise 11.54 % 4.35 % 17.31 % Table 16 : Turn annotation analysis of RPA Re - rankers .", "entities": [[10, 11, "DatasetName", "0"], [14, 15, "DatasetName", "0"], [33, 34, "DatasetName", "0"], [37, 38, "DatasetName", "0"], [44, 45, "DatasetName", "0"], [55, 56, "DatasetName", "0"], [64, 65, "DatasetName", "0"], [66, 67, "DatasetName", "0"], [78, 79, "DatasetName", "0"], [80, 81, "DatasetName", "0"]]}, {"text": "Model PPL F1 RPA Human - - 92.80 Baselines 128 - Truncate Vanilla Baseline 12.54 15.80 88.54 1024 - Truncate Vanilla Baseline 12.35 15.85 88.42 Re - rankers 128 - Truncate Baseline + Re - ranker - 16.14 92.99 128 - Truncate Baseline + PACER - 16.13 93.31 RPA UL ( Top-1 Token ) 13.00 15.35 88.54 RPA UL ( All Tokens ) 12.86 15.28 88.86 Multi - Objective ( Vanilla , Dec. Only ) 12.78 16.00 87.71 Expanded Attention Methods Profile Grounding ( 128 , 2 Rounds over ABC ) 12.31 16.03 92.03 Profile Grounding ( 1024 , 2 Rounds over ABCD ) 12.17 15.95 92.60 Automated Grounding ( 1024 , Classifier Attn . )", "entities": [[2, 3, "MetricName", "F1"], [89, 90, "MethodName", "ABC"], [102, 103, "DatasetName", "ABCD"]]}, {"text": "12.19 15.90 91.11 Automated Grounding + MO ( 1024 Dec. Only ) 12.92 15.88 89.10 Expanded Attention + Re - ranker Methods Profile ( 128 ) + RPA Re - ranker - 16.21 95.62 Profile ( 128 ) + PACER - 16.18 95.82 Table 17 : Validation statistics for various models considered throughout the paper .", "entities": []}, {"text": "Metric Baseline Re - ranker RPA ( normal ) 85.47 94.29 RPA ( LTR ) 86.31 99.76 % Partner Said Response 3.20 2.02 Table 18 : Retrieval models with character output rerankers ; performance on the validation set .", "entities": []}, {"text": "Figure 2 , we show a screenshot of the instructions for the evaluation task provided to crowdworkers on Amazon Mechanical Turk .", "entities": []}, {"text": "J Generation Settings J.1 Test Output Analysis We provide qualitative analysis of the various generation methods below .", "entities": []}, {"text": "No Re - ranking When examining the baseline with no re - ranking , we found that nucleus sampling can help when beam search does not work ; however , both can go out of character the farther one goes in conversation .", "entities": []}, {"text": "Beam Search Re - rankers The beam outputs in standard beam search are at times too similar , inwhich case re - ranking does next to nothing , unless a viable response is available .", "entities": []}, {"text": "Nucleus Sampling Re - rankers Using nucleus setting in a re - ranking setup yields more diverse choices to choose from ; however , sometimes the model simply does not address * any * character within the conversation .", "entities": []}, {"text": "Delayed Beam Search Re - rankers This strikes a nice balance between sensible outputs from beam search and diversity from nucleus sampling .", "entities": []}, {"text": "Mixed - Decoding Re - ranker Using mixed decoding ( re - ranking several decoding schemes ) can work quite well , as it is a nice blend of different generation methods .", "entities": []}, {"text": "J.1.1 Turn Annotation Analysis Qualitative analysis of the turn annotation results are in Table 16 .", "entities": []}, {"text": "We generally found that beam search fails the vast majority of the time when the model thinks that it is talking to itself ; i.e. , it confuses its partner for its own character .", "entities": []}, {"text": "The rerankers can help shift the hallucination away from this regime.2382", "entities": []}, {"text": "Figure 2 : Instructions provided to annotators in human evaluations .", "entities": []}, {"text": "Model Contradiction Mistaken Mistaken Off - Topic Repetitive All - Good Clean Mistaken Avg .", "entities": []}, {"text": "Identity Location Convo Identity Engagingness In Convo Human - 1.34 % - - - - - 5 % Baselines Poly - Encoder 5.50 % 6.14 % 0.77 % 12.02 % 1.92 % 75.45 % 16.33 % 34.69 % 3.42 128 - Truncate Vanilla Baseline 8.26 % 6.45 % 2.71 % 4.26 % 4.00 % 76.00 % 26.80 % 35.05 % 4.04 1024 - Truncate Vanilla Baseline 7.48 % 7.35 % 2.66 % 6.21 % 4.31 % 75.03 % 22.22 % 38.38 % 4.16 Re - rankers 128 - Truncate Baseline + RPA Re - ranker ( Beam ) 4.83 % 5.56 % 3.62 % 4.35 % 3.26 % 80.31 % 20.19 % 34.65 % 4.14 128 - Truncate Baseline + RPA Re - ranker ( Nucleus ) 9.07 % 8.68 % 2.33 % 5.31 % 3.89 % 73.70 % 31.96 % 37.11 % 3.83 1024 - Truncate Baseline + RPA Re - ranker ( Beam ) 5.55 % 4.81 % 1.60 % 3.45 % 2.71 % 82.98 % 33.33 % 24.45 % 4.14 128 - Truncate Baseline + PACER 8.28 % 4.27 % 4.89 % 3.14 % 3.14 % 73.90 % 21.78 % 33.66 % 3.96 1024 - Truncate Baseline + PACER 7.63 % 7.13 % 2.38 % 3.63 % 3.75 % 79.25 % 28.00 % 36.00 % 4.18 Modified Training Objectives RPA Unlikelihood ( Top-1 Token ) 8.70 % 7.13 % 3.38 % 7.25 % 3.74 % 72.83 % 14.42 % 39.40 % 3.87 RPA Unlikelihood ( All Tokens ) 11.64 % 10.51 % 3.13 % 4.88 % 5.38 % 67.71 % 19.00 % 43.00 % 3.87 Multi - Objective ( Vanilla , Dec - Only ) 8.13 % 10.00 % 1.88 % 5.63 % 2.63 % 74.75 % 18.00 % 49.00 % 4.21 Expanded Attention Methods Profile Grounding ( 128 , 2 Rounds over ABC ) 5.32 % 4.82 % 3.21 % 4.45 % 2.84 % 81.58 % 27.45 % 28.43 % 4.18 Profile Grounding ( 1024 , 2 Rounds over ABCD ) 4.13 % 4.00 % 3.38 % 3.13 % 3.25 % 83.75 % 36.63 % 23.76 % 4.34 Automated Grounding ( Classifier Attn . )", "entities": [[306, 307, "MethodName", "ABC"], [333, 334, "DatasetName", "ABCD"]]}, {"text": "10.17 % 5.51 % 2.57 % 6.13 % 2.33 % 75.98 % 24.27 % 29.13 % 4.04 Automated Grounding + MO ( Dec. Only ) 8.23 % 4.43 % 2.03 % 3.80 % 5.19 % 78.61 % 38.00 % 23.00 % 4.12 Expanded Attention + Re - ranker Methods Profile Grounding ( 128 ) + RPA Re - ranker 5.33 % 2.23 % 1.61 % 4.22 % 2.98 % 84.37 % 36.27 % 14.71 % 4.25 Profile Grounding ( 1024 ) + RPA Re - ranker 6.00 % 3.60 % 1.20 % 0.42 % 0.30 % 85.25 % 40.00 % 21.90 % 4.35 Profile Grounding ( 128 ) + PACER 5.43 % 4.07 % 2.84 % 2.47 % 1.23 % 85.70 % 41.18 % 24.51 % 4.32 Profile Grounding ( 1024 ) + PACER 6.21 % 4.38 % 1.10 % 3.65 % 2.56 % 83.56 % 40.78 % 22.33 % 4.13 Table 19 : Human evaluations .", "entities": []}, {"text": "Annotators chatting with models were asked to annotate whether model utterances contained any of the problem attributes listed , with \u201c All - Good \u201d indicating that there were no issues .", "entities": []}, {"text": "\u201c Clean Convo \u201d is the percentage of conversations without any issues .", "entities": []}, {"text": "J.2 Automated Metrics We experiment with various generation settings , with or without re - rankers ; results are in Table 20 .", "entities": []}, {"text": "For the baseline and re - ranker models , beam search yields the highest F1 scores ; RPA can be improved with the other inference methods when combined with a re - ranker .", "entities": [[14, 15, "MetricName", "F1"]]}, {"text": "We believe this may be due to the higher diversity of candidate responses generated from those methods .", "entities": []}, {"text": "K Human + Automatic Eval Correlation We analyze the correlation between human annotations and the automatic metrics collected on the LIGHT validation set , as shown in Figure 3 ; we note some interesting trends : Perplexity perplexity appears to be positively correlated with mistaken identity , and negatively correlated with engagingness .", "entities": [[36, 37, "MetricName", "Perplexity"], [37, 38, "MetricName", "perplexity"]]}, {"text": "So , perplexity is2383", "entities": [[2, 3, "MetricName", "perplexity"]]}, {"text": "Normal Re - ranking Generation Setting F1 RPA F1 RPA Human - 92.80 - 128 - Truncation Model Beam Search 15.80 88.54 16.14 92.99 Delayed Beam Search 15.46", "entities": [[6, 7, "MetricName", "F1"], [8, 9, "MetricName", "F1"]]}, {"text": "88.74 15.48 93.18 Nucleus Sampling 15.70 89.25 15.44 97.12 Top - K Sampling 14.47 88.16 14.14 97.01 1024 - Truncation Model Beam Search 15.85 88.42 16.08 92.92 Delayed Beam Search 15.03 88.00 15.39 92.89", "entities": []}, {"text": "Nucleus Sampling 15.42 88.22 15.25 97.24 Top - K Sampling 14.45 86.91 14.06 97.15 Table 20 : Performance on the LIGHT valid set for the baseline models with different generation settings , with or without re - rankers .", "entities": []}, {"text": "All settings use tri - gram blocking with respect to the context and current generation , and have a minimum length of 20 .", "entities": []}, {"text": "We set topp", "entities": []}, {"text": "= 0.3for Nucleus sampling , topk = 50 for Top - K sampling , and use a beam - delay of 10 with topk = 10 for delayed beam search .", "entities": []}, {"text": "Figure 3 : Correlation between human evaluations and automated metrics computed on the test set .", "entities": []}, {"text": "a good indicator of how fluent and engaging the model is in conversation , and can indirectly point to a better understanding of the role - playing task .", "entities": []}, {"text": "An important note is that we only tested this amongst models of the same size , and only for the models we tested , so it is not clear that larger models will necessarily bring improvements .", "entities": []}, {"text": "F1 F1 word overlap is positively correlated with engagingness as well , so F1 may be a good proxy of model performance .", "entities": [[0, 1, "MetricName", "F1"], [1, 2, "MetricName", "F1"], [13, 14, "MetricName", "F1"]]}, {"text": "Correlation with mistaken identity is negative here , implying that better F1 corresponds with better role - playing ability .", "entities": [[11, 12, "MetricName", "F1"]]}, {"text": "However , we note that F1 is not a catch - all metric ( Liu et al . , 2016 ) .", "entities": [[5, 6, "MetricName", "F1"]]}, {"text": "RPA RPA appears to be strongly negatively correlated with mistaken identity , indicating that it is indeed a good measure of the model \u2019s ability to stay in character .", "entities": []}, {"text": "It is weakly negatively correlated with the other issues , and is somewhat positively correlated with engagingness as well .", "entities": []}, {"text": "These correlations give us confidence that our RPA classifiers are adequately measuring role - playing ability within models .", "entities": []}, {"text": "L Per - Turn Analysis , Expanded In Figure 1 , we see RPA results across turns of conversation for a wider variety of models .", "entities": []}, {"text": "Human The human outputs are most often correct on the first turn , with gradual decay of accuracy throughout the conversation ( according to RPA ) .", "entities": [[17, 18, "MetricName", "accuracy"]]}, {"text": "Vanilla & Long Context", "entities": []}, {"text": "The vanilla baseline suffers a pretty dramatic drop off after the first couple of turns ; the long - context model achieves slightly higher character accuracy overall", "entities": [[25, 26, "MetricName", "accuracy"]]}, {"text": "but we see similar drop offs farther down the conversation .", "entities": []}, {"text": "RPA UL", "entities": []}, {"text": "The unlikelihood models seem to recover somewhat in the initial turns of conversation , however later turns still yield sharp drop offs in RPA .", "entities": []}, {"text": "Multi - objective Similarly to the UL case , we see the most gains in initial turns compare to the vanilla baselines ; however , we see even more dramatic drop offs towards the end of the conversation .", "entities": []}, {"text": "Expanded Attention With profile grounding , we see near - human performance , with even better performance towards the end of the conversation .", "entities": []}, {"text": "The automatic grounding improves over the baseline but is slightly worse than profile grounding .", "entities": []}, {"text": "Combining automated grounding with multi - objective training leads to some benefits in earlier turns , but later turns still suffer .", "entities": []}, {"text": "Re - ranking Although we \u2019re using the same RPA classifier to both re - ranker and score the model outputs , it is still interesting to examine on which turns the re - ranker benefits the model the most .", "entities": []}, {"text": "We see in the last set of graphs that beam re - ranking2384", "entities": []}, {"text": "Context : _ setting_name Turquoise Shore , Shore _ setting_desc", "entities": []}, {"text": "A beautiful turquoise color water by the shore .", "entities": []}, {"text": "It is filled with many gems and gold .", "entities": []}, {"text": "_ partner_name sea witch _ self_name mermaid _ self_persona", "entities": []}, {"text": "I am one of the most beautiful mermaids to live in the sea .", "entities": []}, {"text": "I like to watch the other sea creatures swim by me , including dolphins , who are my favorite creatures because they are so friendly .", "entities": []}, {"text": "I fear the people who live on land because they hunt my kind .", "entities": []}, {"text": "Dialogue History :", "entities": []}, {"text": "Hey there Mermaid !", "entities": []}, {"text": "Long time , no see .", "entities": []}, {"text": "Long time indeed !", "entities": []}, {"text": "How have you been keeping ?", "entities": []}, {"text": "Pretty good , You know how it goes .", "entities": []}, {"text": "Just trying to find some unwitting victims .", "entities": []}, {"text": "What are you doing in the Turquoise Shore ?", "entities": []}, {"text": "I \u2019ve been catching waves with the dolphins all morning .", "entities": []}, {"text": "I thought I would come and get some sunshine .", "entities": []}, {"text": "What kind of victims do you expect to find in a tranquil place like this ?", "entities": []}, {"text": "What do you know about that knight standing over there ?", "entities": []}, {"text": "His armor is particularly garrish .", "entities": []}, {"text": "You know I do n\u2019t fraternize with land dwellers .", "entities": []}, {"text": "I do n\u2019t know , I like when they \u2019re shiny like that .", "entities": []}, {"text": "He looks like a giant fishing lure .", "entities": []}, {"text": "Classified Utterance : I suppose the only thing left to complete the illusion is for him to get wet .", "entities": []}, {"text": "Correct Label : Mermaid Prediction : Sea Witch Context : _ setting_name Outside tower , Outside Tower _ setting_desc", "entities": []}, {"text": "Moss grows from the tall stoic like structure adding to its mysterious presence .", "entities": []}, {"text": "The stone walls appear insuperable like a mountain .", "entities": []}, {"text": "The top is a pointed dome .", "entities": []}, {"text": "_ partner_name enemy _ self_name horse _ self_persona", "entities": []}, {"text": "We have hooves .", "entities": []}, {"text": "four of them .", "entities": []}, {"text": "and you can ride us .", "entities": []}, {"text": "Oats please !", "entities": []}, {"text": "Dialogue History :", "entities": []}, {"text": "hello hello there Classified Utterance : What brings you here ?", "entities": []}, {"text": "Correct Label : Horse Prediction : Enemy Context : Context : _ setting_name Royal Gardens , Outside Palace _ setting_desc Lined with rose bushes that look as if they have been watered by the God \u2019s , the Royal Gardens is a beauty to behold .", "entities": []}, {"text": "An intricate labyrinth made of shrubs is at the center ending with a fountain .", "entities": []}, {"text": "There are various benches on the sides of the rose bushes and a small lake in the back drop .", "entities": []}, {"text": "_ partner_name king _ self_name a gardener pulling weeds _ self_persona", "entities": []}, {"text": "I am the gardener of the castle .", "entities": []}, {"text": "I plant thickets and plants .", "entities": []}, {"text": "My work is beautiful .", "entities": []}, {"text": "Dialogue History :", "entities": []}, {"text": "Hi Classified Utterance : Why hello there , your majesty !", "entities": []}, {"text": "Correct Label : a gardner Prediction : king Table 21 : Left - to - right dynamic classifier failure modes ; see discussion in Section 5.2 . seems to be most helpful in later turns , where other models generally drop off in efficacy .", "entities": []}, {"text": "M Expanded Attention Visualization To build the heat maps in Figures 4 and 5 , we look at the maximum attention applied per - head , and the maximum weight applied across the model decoder layers ; other combinations were considered ( mean per - head , mean over layers or last layer ) and yielded similar findings .", "entities": []}, {"text": "The speaker is the mermaid , whose partner is a sea - witch .", "entities": []}, {"text": "The last utterance from the sea - witch is , \u201c What are you doing on the turquoise shore ? \u201d .", "entities": []}, {"text": "The mermaid responds , \u201c I \u2019ve been catching waves with the dolphins all morning .", "entities": []}, {"text": "What kind of victims do you expect to find in a tranquil place like this?\u201d2385", "entities": []}, {"text": "Figure 4 : Vanilla Attention .", "entities": []}, {"text": "The speaker here is the mermaid , whose partner is a sea - witch .", "entities": []}, {"text": "The last utterance from the sea - witch is , \u201c What are you doing on the turquoise shore ? \u201d .", "entities": []}, {"text": "The mermaid responds , \u201c I \u2019ve been catching waves with the dolphins all morning .", "entities": []}, {"text": "What kind of victims do you expect to find in a tranquil place like this ? \u201d .", "entities": []}, {"text": "The vanilla model spreads its attention across the whole context ; blue boxes at the top are attentions over the character descriptions , while the bottom box is attention over the word \u201c victims\u201d.2386", "entities": []}, {"text": "Figure 5 : Profile Expanded Attention .", "entities": []}, {"text": "The speaker here is the mermaid , whose partner is a sea - witch .", "entities": []}, {"text": "The last utterance from the sea - witch is , \u201c What are you doing on the turquoise shore ? \u201d .", "entities": []}, {"text": "The mermaid responds , \u201c I \u2019ve been catching waves with the dolphins all morning .", "entities": []}, {"text": "What kind of victims do you expect to find in a tranquil place like this ? \u201d .", "entities": []}, {"text": "Left original attention over the full context ; Right expanded attention over the additional context .", "entities": []}, {"text": "The top two boxes are the partner name and self name ; the bottom box on the left refers to \u201c victims \u201d , and on the right refers to the \u201c dolphins\u201d.2387", "entities": []}]