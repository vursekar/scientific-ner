[{"text": "A Report on the 2020 VUA and TOEFL Metaphor Detection Shared Task Chee Wee Leong1 , Beata Beigman Klebanov1 , Chris Hamill1 , Egon Stemle2;3\u0003 , Rutuja Ubale1yand Xianyang Chen1 1Educational Testing Service 2Eurac Research , Institute for Applied Linguistics 3Masaryk University , Faculty of Informatics fcleong , bbeigmanklebanov , chamill , xchen002 g@ets.org yrubale@etscanada.ca \u0003egon.stemle@eurac.edu", "entities": []}, {"text": "Abstract", "entities": []}, {"text": "In this paper , we report on the shared task on metaphor identi\ufb01cation on VU Amsterdam Metaphor Corpus and on a subset of the TOEFL Native Language Identi\ufb01cation Corpus .", "entities": []}, {"text": "The shared task was conducted as apart of the ACL 2020 Workshop on Processing Figurative Language .", "entities": []}, {"text": "1 Introduction Metaphor use in everyday language is a way to relate our physical and familiar social experiences to a multitude of other subjects and contexts ( Lakoff and Johnson , 2008 ) ; it is a fundamental way to structure our understanding of the world even without our conscious realization of its presence as we speak and write .", "entities": []}, {"text": "It highlights the unknown using the known , explains the complex using the simple , and helps us to emphasize the relevant aspects of meaning resulting in effective communication .", "entities": []}, {"text": "Metaphor has been studied in the context of political communication , marketing , mental health , teaching , assessment of English pro\ufb01ciency , among others ( Beigman Klebanov et al . , 2018 ; Gutierrez et al . , 2017 ;", "entities": []}, {"text": "Littlemore et al . , 2013 ; Thibodeau and Boroditsky , 2011 ; Kaviani and Hamedi , 2011 ; Kathpalia and Carmel , 2011 ; Landau et al . , 2009 ; Beigman Klebanov et al . , 2008 ; Zaltman and Zaltman , 2008 ; Littlemore and Low , 2006 ; Cameron , 2003 ; Lakoff , 2010 ; Billow et al . , 1997 ; Bosman , 1987 ) ; see chapter 7 in Veale et", "entities": []}, {"text": "al . ( 2016 ) for a recent review .", "entities": []}, {"text": "We report on the second shared task on automatic metaphor detection , following up on the \ufb01rst shared task held in 2018 ( Leong et al . , 2018 ) .", "entities": []}, {"text": "We present the shared task and provide a brief description of each of the participating systems , a comparative evaluation of the systems , and our observations about trends in designs and performance of the systems that participated in the shared task.2 Related Work Over the last decade , automated detection of metaphor has become an popular topic , which manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied .", "entities": []}, {"text": "In terms of methods , approaches based on feature - engineering in a supervised machine learning paradigm explored features based on concreteness and imageability , semantic classi\ufb01cation using WordNet , FrameNet , VerbNet , SUMO ontology , property norms , and distributional semantic models , syntactic dependency patterns , sensorial and vision - based features ( Bulat et al . , 2017 ; K \u00a8oper and i m Walde , 2017 ; Gutierrez et al . , 2016 ; Shutova et al . , 2016 ; Beigman Klebanov et al . , 2016 ; Tekiroglu et al . , 2015 ; Tsvetkov et al . , 2014 ; Beigman Klebanov et", "entities": [[30, 31, "DatasetName", "FrameNet"], [35, 36, "MethodName", "ontology"]]}, {"text": "al . , 2014 ; Dunn , 2013 ; Neuman et al . , 2013 ; Mohler et al . , 2013 ; Hovy et al . , 2013 ; Tsvetkov et al . , 2013 ; Turney et al . , 2011 ; Shutova et al . , 2010 ; Gedigian et al . , 2006 ) ; see Shutova et al .", "entities": []}, {"text": "( 2017 ) and Veale et", "entities": []}, {"text": "al . ( 2016 ) for reviews of supervised as well as semi - supervised and unsupervised approaches .", "entities": []}, {"text": "Recently , deep learning methods have been explored for token - level metaphor detection ( Mao et al . , 2019 ;", "entities": []}, {"text": "Dankers et al . , 2019 ; Gao et al . , 2018 ; Wu et al . , 2018 ; Rei et al . , 2017 ; Gutierrez et al . , 2017 ; Do Dinh and Gurevych , 2016 ) .", "entities": []}, {"text": "In terms of data , researchers used specially constructed or selected sets , such as adjective noun pairs ( Gutierrez et al . , 2016 ;", "entities": []}, {"text": "Tsvetkov et al . , 2014 ) , WordNet synsets and glosses ( Mohammad et al . , 2016 ) , annotated lexical items ( from a range of word classes ) in sentences sampled from corpora ( \u00a8Ozbal et al . , 2016 ; Jang et al . , 2015 ;", "entities": []}, {"text": "Hovy et al . , 2013 ; Birke and Sarkar , 2006 ) , all the way to annotation of all words in running text for metaphoricity ( Beigman Klebanov et al . , 2018 ; Steen et al . , 2010 ) ; Veale et al . ( 2016 ) review various annotated datasets .", "entities": []}, {"text": "3 Task Description The goal of this shared task is to detect , at the word level , all content word metaphors in a given text .", "entities": []}, {"text": "We are using two datasets \u2013 VUA and TOEFL , to be described shortly .", "entities": []}, {"text": "There are two tracks for each dataset , for a total of four tracks : VUA All POS , VUA Verbs , TOEFL All POS , andTOEFL Verbs .", "entities": []}, {"text": "The AllPOS track is concerned with the detection of all content words , i.e. , nouns , verbs , adverbs and adjectives that are labeled as metaphorical while the Verbs track is concerned only with verbs that are metaphorical .", "entities": []}, {"text": "We excluded all forms of be , do , and have for both tracks .", "entities": []}, {"text": "For each dataset , each participating individual or team can elect to compete in the All POS track , Verbs track , or both .", "entities": []}, {"text": "The competition is organized into two phases : training and testing .", "entities": []}, {"text": "3.1 Datasets 3.1.1 VUA corpus We use the VU Amsterdam Metaphor Corpus ( VUA ) ( Steen et al . , 2010 ) .", "entities": []}, {"text": "The dataset consists of 117 fragments sampled across four genres from the British National Corpus : Academic , News , Conversation , and Fiction .", "entities": []}, {"text": "The data is annotated using the MIPVU procedure with a strong interannotator reliability of \u0014>0.8 ( Steen et al . , 2010 ) .", "entities": []}, {"text": "The VUA dataset and annotations is the same as the one used in the \ufb01rst shared task on metaphor detection ( Leong et al . , 2018 ) , where the reader is referred for further details .", "entities": []}, {"text": "3.1.2 TOEFL corpus This data labeled for metaphor was sampled from the publicly available ETS Corpus of Non - Native Written English1and was \ufb01rst introduced by ( Beigman Klebanov et al . , 2018 ) .", "entities": []}, {"text": "The annotated data comprises essay responses to eight persuasive / argumentative prompts , for three native languages of the writer ( Japanese , Italian , Arabic ) , and for two pro\ufb01ciency levels \u2013 medium and high .", "entities": []}, {"text": "The data was annotated using the protocol in Beigman Klebanov and Flor ( 2013 ) , that emphasized argumentation - relevant metaphors : \u201c Argumentation - relevant metaphors are , brie\ufb02y , those that help the author advance her argument .", "entities": []}, {"text": "For example , if you are arguing against some action because it would drain resources , drain 1https://catalog.ldc.upenn.edu/LDC2014T06is a metaphor that helps you advance your argument , because it presents the expenditure in a very negative way , suggesting that resources would disappear very quickly and without control . \u201d", "entities": []}, {"text": "Beigman Klebanov and Flor ( 2013 ) Average inter - annotator agreement was \u0014= 0.56 - 0.62 , for multiple passes of the annotation ( see ( Beigman Klebanov et al . , 2018 ) for more details ) .", "entities": []}, {"text": "We use the data partition from Beigman Klebanov et al .", "entities": []}, {"text": "( 2018 ) , with 180 essays as training data and 60 essays as testing data .", "entities": []}, {"text": "Tables 1 and 2 show some descriptive characteristics of the data : the number of texts , sentences , tokens , and class distribution information for Verbs and AllPOS tracks for the two datasets .", "entities": []}, {"text": "Datasets VUA TOEFL Train Test Train Test # texts 90 27 180 60 # sents 12,123 4,081 2,741 968 Table 1 : Number of texts and sentences for both VUA and TOEFL datasets .", "entities": []}, {"text": "To facilitate the use of the datasets and evaluation scripts beyond this shared task in future research , the complete set of task instructions and scripts are published on Github2 .", "entities": []}, {"text": "We also provide a set of features used to construct one of the baseline classi\ufb01cation models for prediction of metaphor / non - metaphor classes at the word level , and instructions on how to replicate that baseline .", "entities": []}, {"text": "3.2 Training phase In this \ufb01rst phase , data is released for training and/or development of metaphor detection models .", "entities": []}, {"text": "Participants can elect to perform crossvalidation on the training data , or partition the training data further to have a held - out set for preliminary evaluations , and/or set apart a subset of the data for development / tuning of hyperparameters .", "entities": []}, {"text": "However the training data is used , the goal is to have N\ufb01nal systems ( or versions of a system ) ready for evaluation when the test data is released .", "entities": []}, {"text": "2https://github.com/EducationalTestingService/metaphor /tree / master / NAACL - FLP - shared - task , https://github.com/EducationalTestingService/metaphor/ /tree / master / TOEFL - release", "entities": []}, {"text": "Datasets VUA TOEFL Verbs All POS Verbs All POS Train Test Train Test Train Test Train Test # tokens 17,240 5,873 72,611 22,196 7,016 2,301 26,737 9,014 % M 29%\u0000 18%\u0000 13%\u0000 7%\u0000 Table 2 : Number of tokens and percentage of metaphors breakdown for VUA and TOEFL datasets .", "entities": []}, {"text": "3.3 Testing phase In this phase , instances for evaluation are released.3Each participating system generated predictions for the test instances , for up to N models.4Predictions are submitted to CodaLab5 and evaluated automatically against the goldstandard labels .", "entities": []}, {"text": "Submissions were anonymized .", "entities": []}, {"text": "The only statistics displayed were the highest score of all systems per day .", "entities": []}, {"text": "The total allowable number of system submissions per day was limited to 5 per team per track .", "entities": []}, {"text": "The metric used for evaluation is the F1 score ( least frequent class / label , which is \u201c metaphor \u201d ) with Precision and Recall also available via the detailed results link in CodaLab .", "entities": [[7, 9, "MetricName", "F1 score"], [23, 24, "MetricName", "Precision"], [25, 26, "MetricName", "Recall"]]}, {"text": "The shared task started on January 12 , 2020 when the training data was made available to registered participants .", "entities": []}, {"text": "On February 14 , 2020 , the testing data was released .", "entities": []}, {"text": "Submissions were accepted until April 17 , 2020 .", "entities": []}, {"text": "Table 3 shows the submission statistics for systems with a system paper .", "entities": []}, {"text": "Generally , there were more participants in the VUA tracks than in TOEFL tracks , and in All POS tracks than in Verbs tracks .", "entities": []}, {"text": "In total , 13 system papers were submitted describing methods for generating metaphor / non - metaphor predictions .", "entities": []}, {"text": "# teams # submissions VUA - AllPOS 13 210 VUA - Verbs 11 167 TOEFL - AllPOS 9 247 TOEFL - Verbs 9 181 Table 3 : Participation statistics for all tracks .", "entities": []}, {"text": "3In principle , participants could have access to the test data by independently obtaining the VUA corpus .", "entities": []}, {"text": "The shared task was based on a presumption of fair play by participants .", "entities": []}, {"text": "4We setN=12 .", "entities": []}, {"text": "5https://competitions.codalab.org/competitions/221884 Systems", "entities": []}, {"text": "We \ufb01rst describe the baseline systems .", "entities": []}, {"text": "Next , we brie\ufb02y describe the general approach taken by every team .", "entities": []}, {"text": "Interested readers can refer to the teams \u2019 papers for more details .", "entities": []}, {"text": "4.1 Baseline Classi\ufb01ers We make available to shared task participants a number of features from prior published work on metaphor detection , including unigram features , features based on WordNet , VerbNet , and those derived from a distributional semantic model , POS - based , concreteness and difference in concreteness , as well as topic models .", "entities": [[55, 57, "TaskName", "topic models"]]}, {"text": "We adopted three informed baselines from prior work .", "entities": []}, {"text": "As Baseline 1 : UL + WordNet + CCDB , we use the best system from Beigman Klebanov et al .", "entities": []}, {"text": "( 2016 )", "entities": []}, {"text": ".", "entities": []}, {"text": "The features are : lemmatized unigrams , generalized WordNet semantic classes , and difference in concreteness ratings between verbs / adjectives and nouns ( UL + WN + CCDB).6Baseline 2 : bot.zen is one of the top - ranked systems in the \ufb01rst metaphor", "entities": []}, {"text": "shared task in 2018 by Stemle and Onysko ( 2018 ) that uses a bi - directional recursive neural network architecture with long - term short - term memory ( LSTM BiRNN ) and implements a \ufb02at sequenceto - sequence neural network with one hidden layer using TensorFlow and Keras in Python .", "entities": [[30, 31, "MethodName", "LSTM"]]}, {"text": "The system uses fastText word embeddings from different corpora , including learner corpus and BNC data .", "entities": [[3, 4, "MethodName", "fastText"], [4, 6, "TaskName", "word embeddings"]]}, {"text": "Finally , Baseline 3 : BERT is constructed by \ufb01netuning the BERT model ( Devlin et al . , 2018 ) in a standard token classi\ufb01cation task : After obtaining the contextualized embeddings of a sentence , we apply a linear layer followed by softmax on each token to predict whether it is metaphorical or not .", "entities": [[5, 6, "MethodName", "BERT"], [11, 12, "MethodName", "BERT"], [40, 42, "MethodName", "linear layer"], [44, 45, "MethodName", "softmax"]]}, {"text": "Chen et al .", "entities": []}, {"text": "( 2020 ) gives more details about the architecture of this baseline .", "entities": []}, {"text": "For Verbs tracks , we tune the system on All POS data and test on Verbs , 6Baseline 1 is \u201c all-16 \u201d in Beigman Klebanov et al .", "entities": []}, {"text": "( 2018 )", "entities": []}, {"text": "as this produced better results during preliminary experimentation than training on Verbs only .", "entities": []}, {"text": "4.2 System Descriptions illiniMet : RoBERTa embedding + Linguistic features + Ensemble Gong et al .", "entities": [[5, 6, "MethodName", "RoBERTa"]]}, {"text": "( 2020 ) used RoBERTa to obtain a contextualized embedding of a word and concatenate it with features extracted from linguistic resources ( e.g. WordNet , VerbNet ) as well as other features ( e.g. POS , topicality , concreteness ) previously used in the \ufb01rst shared task ( Leong et al . , 2018 ) before feeding them into a fully - connected Feedforward network to generate predictions .", "entities": [[4, 5, "MethodName", "RoBERTa"], [64, 66, "MethodName", "Feedforward network"]]}, {"text": "During inference , an ensemble of three independently trained models using different train / development splits is proposed to yield a \ufb01nal prediction based on majority vote .", "entities": []}, {"text": "Using just RoBERTa without linguistic features in an ensemble also generates competitive performance .", "entities": [[2, 3, "MethodName", "RoBERTa"]]}, {"text": "DeepMet : Global and local text information + Transformer stacks Su et al .", "entities": [[8, 9, "MethodName", "Transformer"]]}, {"text": "( 2020 ) proposed a reading comprehension paradigm for metaphor detection , where the system seeks to understand the metaphoricity role of each word token in a shorter sequence within a given sentence .", "entities": [[5, 7, "TaskName", "reading comprehension"]]}, {"text": "Features belonging to \ufb01ve different categories are provided as inputs to the network i.e. global text context , local text context , query word , general POS , \ufb01negrained POS .", "entities": []}, {"text": "The features are then mapped onto embeddings before going into Transformer stacks and ensemble for inference .", "entities": [[10, 11, "MethodName", "Transformer"]]}, {"text": "An ablation experiment was also performed with the observation that \ufb01ne - grained POS and global text features are the most helpful for detecting metaphors .", "entities": []}, {"text": "umd bilstm : Bi - LSTM + Embeddings + Unigram Lemmas + Spell Correction Kuo and Carpuat ( 2020 ) explored the effectiveness of additional features by augmenting the basic contextual metaphor detection system developed by Gao et al .", "entities": [[1, 2, "MethodName", "bilstm"], [5, 6, "MethodName", "LSTM"]]}, {"text": "( 2018 ) with one - hot unigram lemma features in addition to GloVe and ELMo embeddings .", "entities": [[8, 9, "DatasetName", "lemma"], [13, 14, "MethodName", "GloVe"], [15, 16, "MethodName", "ELMo"]]}, {"text": "The authors also experimented with a spell - corrected version of TOEFL data and found it further improves the performance of the Bi - LSTM system .", "entities": [[24, 25, "MethodName", "LSTM"]]}, {"text": "atr2112 :", "entities": []}, {"text": "Residual Bi - LSTM + Embeddings + CRF + POS + WN Rivera et al .", "entities": [[3, 4, "MethodName", "LSTM"], [7, 8, "MethodName", "CRF"]]}, {"text": "( 2020 ) proposed a deep architecture that takes as inputs ELMo embeddings that represent words and lemmas , along with POS labels and WordNet synsets .", "entities": [[11, 12, "MethodName", "ELMo"]]}, {"text": "The inputs are processed by a residual Bi - LSTM , then by a number of additional layers , with a \ufb01nal CRF se - quence labeling step to generate predictions .", "entities": [[9, 10, "MethodName", "LSTM"], [22, 23, "MethodName", "CRF"]]}, {"text": "Zenith :", "entities": []}, {"text": "Character embeddings + Similarity Networks + Bi - LSTM + Transformer Kumar and Sharma ( 2020 ) added lexical and orthographic information via character embeddings in addition to GloVe and ELMo embeddings for an enriched input representation .", "entities": [[8, 9, "MethodName", "LSTM"], [10, 11, "MethodName", "Transformer"], [11, 12, "DatasetName", "Kumar"], [28, 29, "MethodName", "GloVe"], [30, 31, "MethodName", "ELMo"]]}, {"text": "The authors also constructed a similarity metric between the literal and contextual representations of a word as another input component .", "entities": []}, {"text": "A Bi - LSTM network and Transformer network are trained independently and combined in an ensemble .", "entities": [[3, 4, "MethodName", "LSTM"], [6, 7, "MethodName", "Transformer"]]}, {"text": "Eventually , adding both character - based information and similarity network are the most helpful , as evidenced by results obtained using cross - validation on the training datasets .", "entities": []}, {"text": "rowanhm : Static and contextual embeddings + concreteness + Multi - layer Perceptron Maudslay et al .", "entities": []}, {"text": "( 2020 ) created a system that combines the concreteness of a word , its static embedding and its contextual embedding before providing them as inputs into a deep Multi - layer Perceptron network which predicts word metaphoricity .", "entities": []}, {"text": "Speci\ufb01cally , the concreteness value of a word is formulated as a linear interpolation between two reference vectors ( concrete and abstract ) which were randomly initialized and learned from data .", "entities": []}, {"text": "iiegn : LSTM BiRNN + metadata ; combine TOEFL and VUA data Stemle and Onysko ( 2020 ) used an LSTM BiRNN classi\ufb01er to study the relationship between the metadata in the TOEFL corpus ( pro\ufb01ciency , L1 of the author , and the prompt to which the essay is responding ) and classi\ufb01er performance .", "entities": [[2, 3, "MethodName", "LSTM"], [20, 21, "MethodName", "LSTM"]]}, {"text": "The system is an extension of the authors \u2019 system for the 2018 shared task ( Stemle and Onysko , 2018 ) that served as one of the baseline in the current shared task ( see section 4.1 ) .", "entities": []}, {"text": "Analyzing the training data , the authors observed that essays written by more pro\ufb01cient users had signi\ufb01cantly more metaphors , and that essays responding to some of the prompts had signi\ufb01cantly more metaphors than other prompts ; however , using pro\ufb01ciency and prompt metadata explicitly in the classi\ufb01er did not improve performance .", "entities": []}, {"text": "The authors also experimented with combining VUA and TOEFL data .", "entities": []}, {"text": "Duke Data Science : BERT , XNET language models + POS tags as features for a Bi - LSTM classi\ufb01er", "entities": [[4, 5, "MethodName", "BERT"], [18, 19, "MethodName", "LSTM"]]}, {"text": "Liu et al .", "entities": []}, {"text": "( 2020 ) use pre - trained BERT and XLNet language models to create contextualized embeddings , which are combined with", "entities": [[7, 8, "MethodName", "BERT"], [9, 10, "MethodName", "XLNet"]]}, {"text": "POS tags to generate features for a Bi - LSTM for token - level metaphor classi\ufb01cation .", "entities": [[9, 10, "MethodName", "LSTM"]]}, {"text": "For the testing phase , the authros used an ensemble strategy , training four copies of the Bi - LSTM with different initializations and averaging their predictions .", "entities": [[19, 20, "MethodName", "LSTM"]]}, {"text": "To increase the likelihood of prediction of a metaphor label , a token is declared a metaphor if : ( 1 ) its predicted probability is higher than the threshold , or ( 2 ) if its probability is three orders of magnitude higher than the median predicted probability for that word in the evaluation set .", "entities": []}, {"text": "chasingkangaroos : RNN + BiLSTM + Attention + Ensemble Brooks and Youssef ( 2020 ) use an ensemble of RNN models with Bi - LSTMs and bidirectional attention mechanisms .", "entities": [[4, 5, "MethodName", "BiLSTM"]]}, {"text": "Each word was represented by an 11 - gram and appeared at the center of the 11 - gram ; each word in the 11 - gram was represented by a 1,324 dimensional word embedding ( concatenation of ELMo and GloVe embeddings ) .", "entities": [[38, 39, "MethodName", "ELMo"], [40, 42, "MethodName", "GloVe embeddings"]]}, {"text": "The authors experimented with ensembles of models that implement somewhat different architecture ( in terms of attention ) and models trained on all POS and on a speci\ufb01c POS .", "entities": []}, {"text": "Go Figure ! :", "entities": []}, {"text": "BERT + multi - task + spell correction + idioms + domain adaptation Chen et al .", "entities": [[0, 1, "MethodName", "BERT"], [11, 13, "TaskName", "domain adaptation"]]}, {"text": "( 2020 ) baseline system ( also one of the shared task baselines , see section 4.1 ) uses BERT \u2013 after obtaining the contextualized embeddings of a sentence , a linear layer is applied followed by softmax on each token to predict whether it is metaphorical or not .", "entities": [[19, 20, "MethodName", "BERT"], [31, 33, "MethodName", "linear layer"], [37, 38, "MethodName", "softmax"]]}, {"text": "The authors spell - correct the TOEFL data , which improves performance .", "entities": []}, {"text": "Chen et al . ( 2020 ) present two multi - task settings :", "entities": []}, {"text": "In the \ufb01rst , metaphor detection on out - of - domain data is treated as an auxiliary task ; in the second , idiom detection on in - domain data is the auxiliary task .", "entities": []}, {"text": "Performance on TOEFL is helped by the \ufb01rst multi - task setting ; performance on VUA is helped by the second .", "entities": []}, {"text": "UoB team : Bi - LSTM + GloVe embeddings + concreteness Alnafesah et", "entities": [[5, 6, "MethodName", "LSTM"], [7, 9, "MethodName", "GloVe embeddings"]]}, {"text": "al .", "entities": []}, {"text": "( 2020 ) explore ways of using concreteness information in a neural metaphor detection context .", "entities": []}, {"text": "GloVe embeddings are used as features to an SVM classi\ufb01er to learn concreteness values , training it using human labels of concreteness .", "entities": [[0, 2, "MethodName", "GloVe embeddings"], [8, 9, "MethodName", "SVM"]]}, {"text": "Then , for metaphor detection , every input word is represented as a 304 - dimensional vector \u2013 300 dimensions are GloVe pre - trained embeddings , plus probabilities for the four concreteness classes .", "entities": [[21, 22, "MethodName", "GloVe"]]}, {"text": "These representations of words are given as input to a Bi - LSTM which outputs asequence of labels .", "entities": [[12, 13, "MethodName", "LSTM"]]}, {"text": "Results suggest that explicit concreteness information helps improve metaphor detection , relative to a baseline that uses GloVe embeddings only .", "entities": [[17, 19, "MethodName", "GloVe embeddings"]]}, {"text": "zhengchang :", "entities": []}, {"text": "ALBERT + BiLSTM Li et al .", "entities": [[0, 1, "MethodName", "ALBERT"], [2, 3, "MethodName", "BiLSTM"]]}, {"text": "( 2020 ) use a sequence labeling model based on ALBERT - LSTM - Softmax .", "entities": [[10, 11, "MethodName", "ALBERT"], [12, 13, "MethodName", "LSTM"], [14, 15, "MethodName", "Softmax"]]}, {"text": "Embeddings produced by BERT serve as input to BiLSTM , as well as to the \ufb01nal softmax layer .", "entities": [[3, 4, "MethodName", "BERT"], [8, 9, "MethodName", "BiLSTM"], [16, 17, "MethodName", "softmax"]]}, {"text": "The authors report on experiments with inputs to BERT ( single - sentence vs pairs ; variants using BERT tokenization ) , spellcorrection of the TOEFL data , and CRF vs softmax at the classi\ufb01cation layer .", "entities": [[8, 9, "MethodName", "BERT"], [18, 19, "MethodName", "BERT"], [29, 30, "MethodName", "CRF"], [31, 32, "MethodName", "softmax"]]}, {"text": "PolyU - LLT : Sensorimotor and embodiment features + embeddings + n - grams + logistic regression classi\ufb01er Wan et al .", "entities": [[15, 17, "MethodName", "logistic regression"]]}, {"text": "( 2020 ) use sensorimotor and embodiment features .", "entities": []}, {"text": "They use the Lancaster Sensorimotor norms ( Lynott et al . , 2019 ) that include measures of sensorimotor strength for about 40 K English words across six perceptual modalities ( e.g. , touch , hearing , smell ) , and \ufb01ve action effectors ( mouth / throat , hand / arm , etc ) , and embodiment norms from Sidhu et al .", "entities": []}, {"text": "( 2014 ) .", "entities": []}, {"text": "The authors also use word , lemma , and POS n - grams ; word2vec and GloVe word embeddings , as well as cosine distance measurements using the embeddings .", "entities": [[6, 7, "DatasetName", "lemma"], [16, 17, "MethodName", "GloVe"], [17, 19, "TaskName", "word embeddings"]]}, {"text": "The different features are combined using logistic regression and other classi\ufb01ers .", "entities": [[6, 8, "MethodName", "logistic regression"]]}, {"text": "5 Results and Discussion Table 4 present the results for All POS and Verbs tracks for VUA data .", "entities": []}, {"text": "Table 5 present the results for All POS and Verbs tracks for TOEFL data .", "entities": []}, {"text": "5.1 Trends in system design The clearest trend in the 2020 submissions is the use of deep learning architectures based on BERT ( Devlin et al . , 2018 ) \u2013 more than half of the participating systems used BERT or its variant .", "entities": [[21, 22, "MethodName", "BERT"], [39, 40, "MethodName", "BERT"]]}, {"text": "The usefulness of BERT for metaphor detection has been shown by Mao et al .", "entities": [[3, 4, "MethodName", "BERT"]]}, {"text": "( 2019 ) , where a BERT - based system posted F1 = 0.717 on VUA AllPOS , hence our use of a BERT - based system as Baseline 3 .", "entities": [[6, 7, "MethodName", "BERT"], [11, 12, "MetricName", "F1"], [23, 24, "MethodName", "BERT"]]}, {"text": "Beyond explorations of neural architectures , we also observe usage of new lexical , grammatical , and morphological information , such as \ufb01negrained POS , spell - corrected variants of words ( for TOEFL data ) , sub - word level information ( e.g. , character embeddings ) , idioms , sensorimotor and embodiment - related information .", "entities": []}, {"text": "Rank Team P R F 1 All POS 1 DeepMet .756 .783 .769 2 Go Figure !", "entities": []}, {"text": ".721 .748 .734 3 illiniMet .746 .715 .730 4 rowanhm .727 .709 .718 5Baseline 3 : BERT .712 .725 .718 6 zhengchang .696 .729 .712 7 chasingkangaroos .702 .704 .703 8 Duke Data Science .662 .699 .680 9 Zenith .630 .716 .670 10 umd bilstm .733 .601 .660 11 atr2112 .599 .672 .633 12 PolyU - LLT .556 .660 .603 13 iiegn .601 .591 .596 14 UoB team .653 .548 .596 15 Baseline 2 : bot.zen .612 .575 .593 16 Baseline 1 : UL + .510 .696 .589 + WN + CCDB Verbs 1 DeepMet .789 .819 .804 2 Go Figure !", "entities": [[16, 17, "MethodName", "BERT"], [44, 45, "MethodName", "bilstm"]]}, {"text": ".732 .823 .775 3 illiniMet .761 .781 .771 4Baseline 3 : BERT .725 .789 .756 5 zhengchang .706 .811 .755 6 rowanhm .734 .779 .755 7 Duke Data Science .712 .749 .730 8 Zenith .667 .775 .717 9 umd bilstm .597 .806 .686 10 atr2112 .652 .718 .683 11 PolyU - LLT .608 .703 .652 12 iiegn .587 .691 .635 13 Baseline 2 : bot.zen .605 .666 .634 14 Baseline 1 : UL + .527 .698 .600 + WN + CCDB Table 4 : VUA Dataset : Performance and ranking of the best system per team and baselines , for All POS track ( top panel ) and for Verbs track ( bottom panel ) .", "entities": [[11, 12, "MethodName", "BERT"], [39, 40, "MethodName", "bilstm"]]}, {"text": "5.2 Performance wrt 2018 shared task Since the same VUA dataset was used in 2020 shared task as in the 2018 shared task , we can directly compare the performance of the best systems to observe the extent of the improvement .", "entities": []}, {"text": "The best system in 2018 performed at F1 = 0.651 ; the best performance in 2020 is more than 10 points better \u2013 F1 = 0.769 .", "entities": [[7, 8, "MetricName", "F1"], [23, 24, "MetricName", "F1"]]}, {"text": "Indeed , the 2018 best performing system would have earned the rank of 11 in the 2020 All POS track , suggesting that the \ufb01eld has generally moved to more effective models than those proposed for the 2018 competitions .", "entities": []}, {"text": "The best results posted for the 2020 shared task are the new state - of - the - art for both VUA7and TOEFL corpora .", "entities": []}, {"text": "7While a number of recent systems were evaluted on VUA data ( Le et al . , 2020 ;", "entities": []}, {"text": "Dankers et al . , 2019 ; Mao et al . , 2019 ; Gao et al . , 2018 ) , their results are not directly comparable to the shared task , since they evaluated on all parts of speech , including function words .", "entities": []}, {"text": "See Dankers et al .", "entities": []}, {"text": "( 2020 ) for a discussion .", "entities": []}, {"text": "Rank Team P R F 1 All POS 1 DeepMet .695 .735 .715 2 zhengchang .755 .666 .707 3 illiniMet .709 .697 .703 4 Go Figure !", "entities": []}, {"text": ".669 .717 .692 5 Duke Data Science .688 .651 .669 6Baseline 3 : BERT .701 .563 .624 7 Zenith .607 .634 .620 8 umd bilstm .629 .593 .611 9 iiegn .596 .579 .587 10 PolyU - LLT .523 .602 .560 11 Baseline 2 : bot.zen .590 .517 .551 12 Baseline 1 : UL + .488 .576 .528 + WN + CCDB Verbs 1 DeepMet .733 .766 .749 2 zhengchang .735 .720 .728 3 illiniMet .731 .707 .719 4 Go Figure !", "entities": [[13, 14, "MethodName", "BERT"], [24, 25, "MethodName", "bilstm"]]}, {"text": ".747 .661 .702 5 Duke Data Science .687 .707 .697 6Baseline 3 : BERT .624 .694 .657 7 Zenith .669 .638 .653 8 umd bilstm .668 .562 .611 9 PolyU - LLT .584 .609 .596 10 Baseline 2 : bot.zen .566 .595 .580 11 Baseline 1 : UL + .504 .641 .564 + WN + CCDB 12 iiegn .622 .487 .546 Table 5 : TOEFL Dataset : Performance and ranking of the best system per team and baselines , for All POS track ( top panel ) and for Verbs track ( bottom panel ) .", "entities": [[13, 14, "MethodName", "BERT"], [24, 25, "MethodName", "bilstm"]]}, {"text": "5.3 Performance across genres : VUA Table 6 shows performance by genre for the VUA data All POS track .", "entities": []}, {"text": "The patterns are highly consistent across systems , and replicate those observed for the 2018 shared task \u2013 Academic and News genres are substantially easier to handle than Fiction and Conversation .", "entities": []}, {"text": "The gap between the best and worst performance across genres for the same system remains wide \u2013 between 11.4 F1 points and 24.3 F1 points .", "entities": [[19, 20, "MetricName", "F1"], [23, 24, "MetricName", "F1"]]}, {"text": "Somewhat encouragingly , the gap is narrower for the better performing systems \u2013 the top 6 systems show the smallest gaps between best and worst genres ( 11.4 - 14.0 ) .", "entities": []}, {"text": "5.4 Performance on VUA vs TOEFL data Table 7 shows performance and ranks of the best systems for teams that participated in both VUA and TOEFL AllPOS tracks , along with baselines .", "entities": []}, {"text": "Overall , the relative performance rankings are consistent \u2013 F1 scores are correlated at r= .92 and team ranks are correlated at r= 0.95 across the two datasets .", "entities": [[9, 10, "MetricName", "F1"]]}, {"text": "All teams posted better performance on the VUA data than on the TOEFL data ; the difference ( see column 4 in Table 7 ) averaged 4 F1 points , ranging from just half a", "entities": [[27, 28, "MetricName", "F1"]]}, {"text": "Team All Acad .", "entities": []}, {"text": "Conv .", "entities": []}, {"text": "Fiction News Best to VUA Worst atr2112 .633 .716 ( 1 ) .510 ( 4 ) .558 ( 3 ) .641 ( 2 ) .206 chasingkangaroos .703 .761 ( 1 ) .599 ( 4 ) .651 ( 3 ) .714 ( 2 ) .162 PolyU - LLT .603 .719 ( 1 ) .482 ( 3 ) .476 ( 4 ) .634 ( 2 ) .243", "entities": []}, {"text": "DeepMet .769 .810 ( 1 ) .681 ( 4 ) .718 ( 3 ) .790 ( 2 ) .129 UoB team .596 .686 ( 1 ) .485 ( 4 ) .511 ( 3 ) .582 ( 2 ) .201 iiegn .596 .669 ( 1 ) .521 ( 3 ) .500 ( 4 ) .626 ( 2 ) .169 umd bilstm .660 .724 ( 1 ) .537 ( 4 ) .606 ( 3 ) .670 ( 2 ) .187 illiniMet .730 .768 ( 1 ) .654 ( 4 ) .688 ( 3 ) .743 ( 2 ) .114 rowanhm .718 .760 ( 1 ) .631 ( 4 ) .678 ( 3 ) .730 ( 2 ) .129 Zenith .670 .730 ( 1 ) .566 ( 4 ) .583 ( 3 ) .697 ( 2 ) .164 Duke Data Science .680 .742 ( 1 ) .572 ( 4 ) .617 ( 3 ) .697 ( 2 ) .170", "entities": [[59, 60, "MethodName", "bilstm"]]}, {"text": "Go Figure !", "entities": []}, {"text": ".734 .784 ( 1 ) .644 ( 4 ) .692 ( 3 ) .741 ( 2 ) .140 zhengchang .712 .752 ( 1 ) .634 ( 4 ) .669 ( 3 ) .723 ( 2 ) .118 Baseline 3 : BERT .718 .767 ( 1 ) .640 ( 4 ) .684 ( 3 ) .719 ( 2 ) .127 Baseline 2 : bot.zen .593 .673 ( 1 ) .487 ( 4 ) .521 ( 3 ) .602 ( 2 ) .186", "entities": [[40, 41, "MethodName", "BERT"]]}, {"text": "Baseline 1 : UL+ .589 .721 ( 1 ) .472 ( 3 ) .458 ( 4 ) .606 ( 2 ) .263", "entities": []}, {"text": "+ WN+CCDB Av .", "entities": []}, {"text": "rank among genres \u2013 1.00 3.81 3.19 2.00 .169 Table 6 : VUA Dataset : Performance ( F1 - score ) of the best systems submitted to All - POS track by genre subsets of the test data .", "entities": [[17, 20, "MetricName", "F1 - score"]]}, {"text": "In parentheses , we show the rank of the given genre within all genres for the system .", "entities": []}, {"text": "The last column shows the overall drop in performance from best genre ( ranked 1 ) to worst ( ranked 4 ) .", "entities": []}, {"text": "The top three performances for a given genre are boldfaced .", "entities": []}, {"text": "Team VUA TOEFL Diff .", "entities": []}, {"text": "( rank ) ( rank ) Baseline 1 : UL+ .59 ( 12 ) .53 ( 12 )", "entities": []}, {"text": ".06", "entities": []}, {"text": "+ WN+CCDB Baseline 2 : bot.zen .59 ( 11 ) .55 ( 11 ) .04 Baseline 3 : BERT .72 ( 4 ) .62 ( 6 ) .09", "entities": [[18, 19, "MethodName", "BERT"]]}, {"text": "PolyU - LLT .60 ( 9 ) .56 ( 10 ) .04 DeepMet .77 ( 1 ) .72 ( 1 ) .05 iiegn .60 ( 10 ) .59 ( 9 ) .01 umd bilstm .66 ( 8) .61 ( 8) .05 illiniMet .73 ( 3 ) .70 ( 3 ) .03 Zenith .67 ( 7 ) .62 ( 7 ) .05", "entities": [[33, 34, "MethodName", "bilstm"]]}, {"text": "Duke Data Science .68 ( 6 ) .67 ( 5 ) .01", "entities": []}, {"text": "Go Figure !", "entities": []}, {"text": ".73 ( 2 ) .69 ( 4 ) .04 zhengchang .71", "entities": []}, {"text": "( 5 ) .71 ( 2 )", "entities": []}, {"text": ".01 Table 7 : VUA vs TOEFL : Performance ( F1 scores ) and rankings of participants in both VUA and TOEFL All POS competitions .", "entities": [[10, 11, "MetricName", "F1"]]}, {"text": "Column 4 shows the difference in F1 performance between VUA and TOEFL data .", "entities": [[6, 7, "MetricName", "F1"]]}, {"text": "F1 point ( zhengchang ) to 5 F1 points ( DeepMet , umd bilstm , Zenith ) .", "entities": [[0, 1, "MetricName", "F1"], [7, 8, "MetricName", "F1"], [13, 14, "MethodName", "bilstm"]]}, {"text": "The BERT baseline posted a relatively large difference of 9 F1 points ; this could be because BNC data is more similar to the data on which BERT has been pre - trained than TOEFL data .", "entities": [[1, 2, "MethodName", "BERT"], [10, 11, "MetricName", "F1"], [27, 28, "MethodName", "BERT"]]}, {"text": "We note , however , that participating systems that used BERT showed a smaller performance gap between VUA and TOEFL data ; in zhengchang the gap is all but eliminated .", "entities": [[10, 11, "MethodName", "BERT"]]}, {"text": "This suggests that a BERT - based system with parameters optimized for performance on TOEFL data can close this gap .", "entities": [[4, 5, "MethodName", "BERT"]]}, {"text": "Considering TOEFL data as an additionalgenre , along with the four genres represented in VUA , we observe that it is generally harder than Academic and News , and is commensurate with Fiction in terms of performance , for the three systems with best VUA All POS performance ( DeepMet : 0.72 both , Go Figure ! : 0.69 both , illiniMet : 0.69 for VUA Fiction , .70 for TOEFL ) ; a caveat to this observation is that the difference between VUA and TOEFL is not only in genre but in the metaphor annotation guidelines as well .", "entities": []}, {"text": "5.5 Performance by pro\ufb01ciency : TOEFL Table 8 shows performance for All POS track on the TOEFL data by the writer \u2019s pro\ufb01ciency level \u2013 high or medium .", "entities": []}, {"text": "We note that the quality of the human annotations does not appear to differ substantially by pro\ufb01ciency : The average inter - annotator agreement for the high pro\ufb01ciency essays was \u0014= 0.619 , while it was \u0014= 0.613 for the medium pro\ufb01ciency essays .", "entities": []}, {"text": "We observe that generally systems tend to perform better on the higher pro\ufb01ciency essays , although two of the 12 systems posted better performance on the medium pro\ufb01ciency data .", "entities": []}, {"text": "However , even though the medium pro\ufb01ciency essays might have de\ufb01ciencies in grammar , spelling , coherence and other properties of the essay that could interfere with metaphor detection , we generally observe relatively small differences in performance by pro\ufb01ciency \u2013 up to 3.5 F1 points , with a few ex-", "entities": [[44, 45, "MetricName", "F1"]]}, {"text": "ceptions ( zhengchang , Go Figure ! ) .", "entities": []}, {"text": "Interestingly , automatic correction of spelling errors does not seem to guarantee a smaller gap in performance ( see Chen et al .", "entities": []}, {"text": "( 2020 )", "entities": []}, {"text": ", Go Figure ! ) .", "entities": []}, {"text": "Team All High Med . Diff .", "entities": []}, {"text": "PolyU - LLT .560 .567 ( 1 ) .552 ( 2 ) .015 DeepMet .715 .724 ( 1 ) .706 ( 2 ) .018 iiegn .587 .592 ( 1 ) .583 ( 2 ) .009 umd bilstm .611 .620 ( 1 ) .601 ( 2 ) .019 illiniMet .703 .717 ( 1 ) .690 ( 2 ) .027 Zenith .620 .637 ( 1 ) .604 ( 2 ) .033 Duke Data .669 .660 ( 2 ) .677 ( 1 ) .017 Science Go Figure !", "entities": [[36, 37, "MethodName", "bilstm"]]}, {"text": ".692 .713 ( 1 ) .671 ( 2 ) .042 zhengchang .707 .741 ( 1 ) .674 ( 2 ) .067 Baseline 3 : BERT .624 .636 ( 1 ) .612 ( 2 ) .024 Baseline 2 : bot.zen .551 .535 ( 2 ) .567 ( 1 ) .032 Baseline 1 : UL+ .528 .533 ( 1 ) .524 ( 2 ) .009 WordNet+CCDB", "entities": [[24, 25, "MethodName", "BERT"]]}, {"text": "Av .", "entities": []}, {"text": "rank \u2013 1.16 1.83 .03 Table 8 : TOEFL Dataset : Performance ( F1 - score ) of the best systems submitted to All - POS track by pro\ufb01ciency level ( high , medium ) subsets of the test data .", "entities": [[13, 16, "MetricName", "F1 - score"]]}, {"text": "In parentheses , we show the rank of the given pro\ufb01ciency level within all levels for the system .", "entities": []}, {"text": "The last column shows the overall drop in performance from best pro\ufb01ciency level ( ranked 1 ) to worst ( ranked 4 ) .", "entities": []}, {"text": "The top three performances for a given genre are boldfaced .", "entities": []}, {"text": "5.6 Part of Speech Table 9 shows the performance of the systems submitted to the All POS tracks for VUA and TOEFL data broken down by part of speech ( Verbs , Nouns , Adjectives , Adverbs ) .", "entities": []}, {"text": "As can be observed both from the All POS vs Verbs tracks ( Tables 4 and 5 ) and from Table 9 , performance on Verbs is generally better than on All POS.8 For VUA data , all but one systems perform best on Verbs , followed by Adjectives and Nouns , with the worst performance generally observed for Adverbs .", "entities": []}, {"text": "These results replicate the \ufb01ndings from the 2018 shared task and follow the proportions of metaphors in the respective parts of speech , led by Verbs ( 30 % ) , Adjectives ( 18 % ) , Nouns ( 13 % ) , Adverbs ( 8 % ) .", "entities": []}, {"text": "The average gap between best and worst POS performance has also stayed similar \u2013 11 F1 points ( it was 9 % in 2018 ) .", "entities": [[15, 16, "MetricName", "F1"]]}, {"text": "For the TOEFL data , the situation is quite different .", "entities": []}, {"text": "Adjectives lead the scoreboard for all but 8Performance on Verbs track and performance on Verbs as part of All POS track might differ , since for Verbs track , participants could train their system on verbs - only data , whereas we took submissions to All POS track and analyzed by POS for Table 9.3 systems , with Adverbs and Verbs coming next , while Nouns proved to be the most challenging category for all participating systems .", "entities": []}, {"text": "Furthermore , the gap between best and worst POS performance is large \u2013 17 F1 points on average , ranging between 11 and 22 points .", "entities": [[14, 15, "MetricName", "F1"]]}, {"text": "The best performance on Nouns is only F1 = 0.641 ; it would have ranked 10th out of 12 on Adjectives .", "entities": [[7, 8, "MetricName", "F1"]]}, {"text": "The proportions of metaphorically used Verbs ( 13 % ) , Adjectives ( 8 % ) , Nouns ( 4 % ) , and Adverbs ( 3 % ) ( based on training data ) perhaps offer some explanation of the dif\ufb01culty with nouns , since nominal metaphors seem to be quite rare .", "entities": []}, {"text": "Stemle and Onysko ( 2020 ) observed that metaphors occur more frequently in responses to some essay prompts that to others among the 8 prompts covered in the TOEFL dataset ; moreover , for some prompts , a metaphor is suggested in the prompt itself and occurs frequently in responses ( e.g. whether broad knowledge is better than specialized knowledge ) .", "entities": []}, {"text": "It is possible that prompt - based patterns interact with POS patterns in ways that affect relative ease or dif\ufb01culty of POS for metaphor identi\ufb01cation .", "entities": []}, {"text": "6 Acknowledgements As organizers of the shared task , we would like to thank all the teams for their interest and participation .", "entities": []}, {"text": "We would also like to thank Ton Veale , Eyal Sagi , Debanjan Ghosh , Xinhao Wang , and Keelan Evanini for their helpful comments on the paper , and Verna Dankers for pointing out an error in the original paper that has since been \ufb01xed .", "entities": []}, {"text": "Team All - POS Verbs Adjectives", "entities": []}, {"text": "Nouns Adverbs Best to Worst VUA Dataset atr2112 .633 .683 ( 1 ) .602 ( 2 ) .595 ( 3 ) .560 ( 4 ) .12 chasingkangaroos .703 .737 ( 1 ) .678 ( 2 ) .678 ( 2 ) .648 ( 4 ) .09", "entities": []}, {"text": "PolyU - LLT .603 .625 ( 1 ) .595 ( 2 ) .581 ( 3 ) .552 ( 4 ) .07", "entities": []}, {"text": "DeepMet .769 .800 ( 1 ) .733 ( 3 ) .749 ( 2 ) .732 ( 4 ) .07", "entities": []}, {"text": "UoB team .596 .626 ( 1 ) .587 ( 2 ) .569 ( 3 ) .506 ( 4 ) .12 iiegn .596 .635 ( 1 ) .581 ( 2 ) .558 ( 3 ) .513 ( 4 ) .12 umd bilstm .660 .700 ( 1 ) .642 ( 2 ) .630 ( 3 ) .514 ( 4 ) .19 illiniMet .730 .770 ( 1 ) .693 ( 3 ) .705 ( 2 ) .633 ( 4 ) .14 rowanhm .718 .753 ( 1 ) .660 ( 3 ) .706 ( 2 ) .644 ( 4 ) .11 Zenith .670 .715 ( 1 ) .621 ( 3 ) .637 ( 2 ) .612 ( 4 )", "entities": [[40, 41, "MethodName", "bilstm"]]}, {"text": ".10", "entities": []}, {"text": "Duke Data Science .680 .724 ( 1 ) .614 ( 4 ) .654 ( 2 ) .625 ( 3 ) .11", "entities": []}, {"text": "Go Figure !", "entities": []}, {"text": ".734 .775 ( 1 ) .683 ( 3 ) .708 ( 2 ) .681 ( 4 ) .09", "entities": []}, {"text": "zhengchang .712 .755 ( 1 ) .655 ( 4 ) .684 ( 2 ) .659 ( 3 ) .10 Baseline 3 : BERT .718 .756 ( 1 ) .672 ( 3 ) .695 ( 2 ) .672 ( 3 ) .08 Baseline 2 : bot.zen .593 .637 ( 1 ) .564 ( 2 ) .553 ( 3 ) .513 ( 4 ) .12 Baseline 1 : UL + .589 .616 ( 1 ) .557 ( 3 ) .564 ( 2 ) .542 ( 4 ) .07", "entities": [[22, 23, "MethodName", "BERT"]]}, {"text": "WN + CCDB Av .", "entities": []}, {"text": "rank among POS \u2013 1.00 2.69 2.38 3.81 .11", "entities": []}, {"text": "TOEFL Dataset PolyU - LLT .560 .587 ( 2 ) .630 ( 1 ) .462 ( 4 ) .517 ( 3 ) .17", "entities": []}, {"text": "DeepMet .715 .749 ( 3 ) .757 ( 2 ) .610 ( 4 ) .800 ( 1 ) .19 iiegn .587 .617 ( 3 ) .667 ( 1 ) .465 ( 4 ) .632 ( 2 ) .20 umd bilstm .611 .652 ( 2 ) .693 ( 1 ) .478 ( 4 ) .627 ( 3 ) .22 illiniMet .703 .718 ( 3 ) .770 ( 2 ) .609 ( 4 ) .786 ( 1 ) .18", "entities": [[39, 40, "MethodName", "bilstm"]]}, {"text": "Zenith .620 .650 ( 2 ) .703 ( 1 ) .505 ( 4 ) .600 ( 3 ) .20", "entities": []}, {"text": "Duke Data Science .669 .697 ( 3 ) .725 ( 2 ) .555 ( 4 ) .741 ( 1 ) .19 Go Figure !", "entities": []}, {"text": ".692 .697 ( 2 ) .749 ( 1 ) .641 ( 4 ) .691 ( 3 ) .11 zhengchang .707 .728 ( 3 ) .759 ( 1 ) .620 ( 4 ) .731 ( 2 )", "entities": []}, {"text": ".14 Baseline 3 : BERT .624 .644 ( 2 ) .689 ( 1 ) .541 ( 4 ) .583 ( 3 ) .15 Baseline 2 : bot.zen .551 .565 ( 2 ) .611 ( 1 ) .485 ( 4 ) .490 ( 3 ) .13", "entities": [[4, 5, "MethodName", "BERT"]]}, {"text": "Baseline 1 : UL + .528 .543 ( 2 ) .618 ( 1 ) .415 ( 4 ) .531 ( 3 ) .20", "entities": []}, {"text": "WN + CCDB Av .", "entities": []}, {"text": "rank among POS \u2013 2.42 1.25 4.00 2.33 .17 Table 9 : VUA and TOEFL Datasets by POS : Performance ( F1 - score ) of the best systems submitted to All - POS track by POS subsets of the test data .", "entities": [[21, 24, "MetricName", "F1 - score"]]}, {"text": "In parentheses , we show the rank of the given POS within all POS for the system .", "entities": []}, {"text": "The last column shows the overall drop in performance from best POS ( ranked 1 ) to worst ( ranked 4 ) .", "entities": []}, {"text": "References Ghadi Alnafesah , Harish Tayyar Madabushi , and Mark Lee . 2020 .", "entities": []}, {"text": "Augmenting neural metaphor detection with concreteness .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Beata Beigman Klebanov , Daniel Diermeier , and Eyal Beigman . 2008 .", "entities": []}, {"text": "Lexical cohesion analysis of political speech .", "entities": []}, {"text": "Political Analysis , 16(4):447\u2013463 .", "entities": []}, {"text": "Beata Beigman Klebanov and Michael Flor .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Argumentation - relevant metaphors in test - taker essays .", "entities": []}, {"text": "In Proceedings of the First Workshop on Metaphor in NLP , pages 11\u201320 .", "entities": []}, {"text": "Beata Beigman Klebanov , Chee Wee Leong , and Michael Flor .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A corpus of non - native written English annotated for metaphor .", "entities": []}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 2 ( Short Papers ) , pages 86\u201391 , New Orleans , Louisiana .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Beata Beigman Klebanov , Chee Wee Leong , E Dario Gutierrez , Ekaterina Shutova , and Michael Flor .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Semantic classi\ufb01cations for detection of verb metaphors .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Papers ) , volume 2 , pages 101\u2013106 .", "entities": []}, {"text": "Beata Beigman Klebanov , Chee Wee Leong , Michael Heilman , and Michael Flor .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Different texts , same metaphors : Unigrams and beyond .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Metaphor in NLP , pages 11\u201317 .", "entities": []}, {"text": "Richard M Billow , Jeffrey Rossman , Nona Lewis , Deberah Goldman , and Charles Raps . 1997 .", "entities": []}, {"text": "Observing expressive and deviant language in schizophrenia .", "entities": []}, {"text": "Metaphor and Symbol , 12(3):205\u2013216 .", "entities": []}, {"text": "Julia Birke and Anoop Sarkar .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "A clustering approach for nearly unsupervised recognition of nonliteral language .", "entities": []}, {"text": "In 11th Conference of the European Chapter of the Association for Computational Linguistics .", "entities": []}, {"text": "Jan Bosman .", "entities": []}, {"text": "1987 .", "entities": []}, {"text": "Persuasive effects of political metaphors .", "entities": []}, {"text": "Metaphor and Symbol , 2(2):97\u2013113 .", "entities": []}, {"text": "Jennifer Brooks and Abdou Youssef .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Metaphor detection using ensembles of bidirectional recurrent neural networks .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Luana Bulat , Stephen Clark , and Ekaterina Shutova . 2017 .", "entities": []}, {"text": "Modelling metaphor with attribute - based semantics .", "entities": []}, {"text": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics : Volume 2 , Short Papers , volume 2 , pages 523\u2013528.Lynne Cameron .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Metaphor in educational discourse .", "entities": []}, {"text": "A&C Black .", "entities": []}, {"text": "Xianyang Chen , Chee Wee Leong , Michael Flor , and Beata Beigman Klebanov . 2020 .", "entities": []}, {"text": "Go \ufb01gure !", "entities": []}, {"text": "multitask transformer - based architecture for metaphor detection using idioms : Ets team in 2020 metaphor shared task .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Verna Dankers , Karan Malhotra , Gaurav Kudva , V olodymyr Medentsiy , and Ekaterina Shutova .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Being neighbourly : Neural metaphor identi\ufb01cation in discourse .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , pages 227\u2013234 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Verna Dankers , Marek Rei , Martha Lewis , and Ekaterina Shutova .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Modelling the interplay of metaphor and emotion through multitask learning .", "entities": [[6, 7, "DatasetName", "emotion"]]}, {"text": "InProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 2218 \u2013 2229 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2018 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "arXiv preprint arXiv:1810.04805 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Erik - L \u02c6an Do Dinh and Iryna Gurevych .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Tokenlevel metaphor detection using neural networks .", "entities": []}, {"text": "In Proceedings of the Fourth Workshop on Metaphor in NLP , pages 28\u201333 .", "entities": []}, {"text": "Jonathan Dunn .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "What metaphor identi\ufb01cation systems can tell us about metaphor - in - language .", "entities": []}, {"text": "In Proceedings of the First Workshop on Metaphor in NLP , pages 1\u201310 .", "entities": []}, {"text": "Ge Gao , Eunsol Choi , Yejin Choi , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Neural metaphor detection in context .", "entities": []}, {"text": "In Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Matt Gedigian , John Bryant , Srini Narayanan , and Branimir Ciric .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Catching metaphors .", "entities": []}, {"text": "In Proceedings of the Third Workshop on Scalable Natural Language Understanding , pages 41\u201348 .", "entities": [[8, 11, "TaskName", "Natural Language Understanding"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Hongyu Gong , Kshitij Gupta , Akriti Jain , and Suma Bhat .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Illinimet : Illinois system for metaphor detection with contextual and linguistic information .", "entities": []}, {"text": "InProceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "E Dario Gutierrez , Guillermo Cecchi , Cheryl Corcoran , and Philip Corlett . 2017 .", "entities": []}, {"text": "Using automated metaphor identi\ufb01cation to aid in detection and prediction of \ufb01rst - episode schizophrenia .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 2923\u20132930 .", "entities": []}, {"text": "E Dario Gutierrez , Ekaterina Shutova , Tyler Marghetis , and Benjamin Bergen . 2016 .", "entities": []}, {"text": "Literal and metaphorical senses in compositional distributional semantic models .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , volume 1 , pages 183\u2013193 .", "entities": []}, {"text": "Dirk Hovy , Shashank Shrivastava , Sujay Kumar Jauhar , Mrinmaya Sachan , Kartik Goyal , Huying Li , Whitney Sanders , and Eduard Hovy .", "entities": [[7, 8, "DatasetName", "Kumar"]]}, {"text": "2013 .", "entities": []}, {"text": "Identifying metaphorical word use with tree kernels .", "entities": []}, {"text": "In Proceedings of the First Workshop on Metaphor in NLP , pages 52\u201357 .", "entities": []}, {"text": "Hyeju Jang , Seungwhan Moon , Yohan Jo , and Carolyn Rose . 2015 .", "entities": []}, {"text": "Metaphor detection in discourse .", "entities": []}, {"text": "InProceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue , pages 384\u2013392 .", "entities": []}, {"text": "Sujata S Kathpalia and Heah Lee Hah Carmel .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Metaphorical competence in esl student writing .", "entities": []}, {"text": "RELC Journal , 42(3):273\u2013290 .", "entities": []}, {"text": "Hossein Kaviani and Robabeh Hamedi .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "A quantitative / qualitative study on metaphors used by persian depressed patients .", "entities": []}, {"text": "Archives of Psychiatry and Psychotherapy , 4(5 - 13):110 .", "entities": []}, {"text": "Maximilian K \u00a8oper and Sabine Schulte i m Walde .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Improving verb metaphor detection by propagating abstractness to words , phrases and individual senses .", "entities": []}, {"text": "InProceedings of the 1st Workshop on Sense , Concept and Entity Representations and their Applications , pages 24\u201330 .", "entities": []}, {"text": "Tarun Kumar and Yashvardhan Sharma .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "2020 .", "entities": []}, {"text": "Character aware models with similarity learning for metaphor detection .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Kevin Kuo and Marine Carpuat .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Evaluating a bilstm model for metaphor detection in toe\ufb02 essays .", "entities": [[2, 3, "MethodName", "bilstm"]]}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "George Lakoff .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Moral politics : How liberals and conservatives think .", "entities": []}, {"text": "University of Chicago Press .", "entities": []}, {"text": "George Lakoff and Mark Johnson .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Metaphors we live by .", "entities": []}, {"text": "University of Chicago press .", "entities": []}, {"text": "Mark J Landau , Daniel Sullivan , and Jeff Greenberg .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Evidence that self - relevant motives and metaphoric framing interact to in\ufb02uence political and social attitudes .", "entities": []}, {"text": "Psychological Science , 20(11):1421\u20131427 .", "entities": []}, {"text": "Duong Le , My Thai , and Thien Nguyen .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Multitask learning for metaphor detection with graph convolutional neural networks and word sense disambiguation .", "entities": [[11, 14, "TaskName", "word sense disambiguation"]]}, {"text": "In The Thirty - Fourth AAAI Conferenceon Arti\ufb01cial Intelligence , AAAI 2020 , The ThirtySecond Innovative Applications of Arti\ufb01cial Intelligence Conference , IAAI 2020 , The Tenth AAAI Symposium on Educational Advances in Arti\ufb01cial Intelligence , EAAI 2020 , New York , NY , USA , February 7 - 12 , 2020 , pages 8139\u20138146 .", "entities": []}, {"text": "AAAI Press .", "entities": []}, {"text": "Chee Wee Leong , Beata Beigman Klebanov , and Ekaterina Shutova .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A report on the 2018 vua metaphor detection shared task .", "entities": []}, {"text": "In Proceedings of the Workshop on Figurative Language Processing , pages 56\u201366 .", "entities": []}, {"text": "Shuqun Li , Jingjie Zeng , Jinhui Zhang , Tao Peng , Liang Yang , and Hongfei Lin .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "AlbertBiLSTM for sequential metaphor detection .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Jeannette Littlemore , Tina Krennmayr , James Turner , and Sarah Turner .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "An investigation into metaphor use at different levels of second language writing .", "entities": []}, {"text": "Applied linguistics , 35(2):117\u2013144 .", "entities": []}, {"text": "Jeannette Littlemore and Graham Low . 2006 .", "entities": []}, {"text": "Metaphoric competence , second language learning , and communicative language ability .", "entities": []}, {"text": "Applied linguistics , 27(2):268\u2013294 .", "entities": []}, {"text": "Jerry Liu , Nathan O \u00b4 Hara , Alex Rubin , Rachel Draelos , and Cynthia Rudin . 2020 .", "entities": []}, {"text": "Metaphor detection using contextual word embeddings from transformers .", "entities": [[4, 6, "TaskName", "word embeddings"]]}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Dermot Lynott , Louise Connell , Marc Brysbaert , James Brand , and James Carney .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The Lancaster sensorimotor norms : multidimensional measures of perceptual and action strength for 40,000 English words .", "entities": []}, {"text": "Behavior Research Methods , pages 1\u201321 .", "entities": []}, {"text": "Rui Mao , Chenghua Lin , and Frank Guerin . 2019 .", "entities": []}, {"text": "End - to - end sequential metaphor identi\ufb01cation inspired by linguistic theories .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 3888\u20133898 , Florence , Italy . Association for Computational Linguistics .", "entities": [[17, 18, "MethodName", "Florence"]]}, {"text": "Rowan Hall Maudslay , Tiago Pimentel , Ryan Cotterell , and Simone Teufel .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Metaphor detection using context and concreteness .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Saif Mohammad , Ekaterina Shutova , and Peter Turney .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Metaphor as a medium for emotion : An empirical study .", "entities": [[5, 6, "DatasetName", "emotion"]]}, {"text": "In Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics , pages 23\u201333 .", "entities": []}, {"text": "Michael Mohler , David Bracewell , Marc Tomlinson , and David Hinote .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Semantic signatures for example - based linguistic metaphor detection .", "entities": []}, {"text": "In Proceedings of the First Workshop on Metaphor in NLP , pages 27\u201335 .", "entities": []}, {"text": "Yair Neuman , Dan Assaf , Yohai Cohen , Mark Last , Shlomo Argamon , Newton Howard , and Ophir Frieder .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Metaphor identi\ufb01cation in large texts corpora .", "entities": []}, {"text": "PloS one , 8(4):e62343 .", "entities": [[0, 1, "DatasetName", "PloS"]]}, {"text": "G\u00a8ozde \u00a8Ozbal , Carlo Strapparava , and Serra Sinem Tekiroglu .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Prometheus : A corpus of proverbs annotated with metaphors .", "entities": []}, {"text": "In LREC .", "entities": []}, {"text": "Marek Rei , Luana Bulat , Douwe Kiela , and Ekaterina Shutova . 2017 .", "entities": []}, {"text": "Grasping the \ufb01ner point : A supervised similarity network for metaphor detection .", "entities": []}, {"text": "InProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 1537\u20131546 .", "entities": []}, {"text": "Andr \u00b4 es Torres Rivera , Antoni Oliver , Salvador Climent , and Marta Coll - Florit .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Neural metaphor detection with a residual bilstm - crf model .", "entities": [[6, 7, "MethodName", "bilstm"], [8, 9, "MethodName", "crf"]]}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Ekaterina Shutova , Douwe Kiela , and Jean Maillard .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Black holes and white rabbits : Metaphor identi\ufb01cation with visual features .", "entities": []}, {"text": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 160\u2013170 .", "entities": []}, {"text": "Ekaterina Shutova , Lin Sun , Elkin Dar \u00b4 \u0131o Guti \u00b4 errez , Patricia Lichtenstein , and Srini Narayanan . 2017 .", "entities": []}, {"text": "Multilingual metaphor processing : Experiments with semi - supervised and unsupervised learning .", "entities": []}, {"text": "Computational Linguistics , 43(1):71\u2013123 .", "entities": []}, {"text": "Ekaterina Shutova , Lin Sun , and Anna Korhonen .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Metaphor identi\ufb01cation using verb and noun clustering .", "entities": []}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics , pages 1002\u20131010 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "David Sidhu , Rachel Kwan , Penny Pexman , and Paul Siakaluk . 2014 .", "entities": []}, {"text": "Effects of relative embodiment in lexical and semantic processing of verbs .", "entities": []}, {"text": "Acta psychologica , 149:32\u201339 .", "entities": []}, {"text": "Gerard J Steen , Aletta G Dorst , J Berenike Herrmann , Anna Kaal , Tina Krennmayr , and Trijntje Pasma . 2010 .", "entities": []}, {"text": "A method for linguistic metaphor identi\ufb01cation : From MIP to MIPVU , volume 14 .", "entities": []}, {"text": "John Benjamins Publishing .", "entities": []}, {"text": "Egon Stemle and Alexander Onysko .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Using language learner data for metaphor detection .", "entities": []}, {"text": "In Proceedings of the Workshop on Figurative Language Processing , New Orleans , LA .", "entities": []}, {"text": "Egon Stemle and Alexander Onysko .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Testing the role of metadata in metaphor identi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA.Chuandong Su , Fumiyo Fukumoto , Xiaoxi Huang , Jiyi Li , Rongbo Wang , and Zhiqun Chen . 2020 .", "entities": []}, {"text": "Deepmet : A reading comprehension paradigm for tokenlevel metaphor detection .", "entities": [[3, 5, "TaskName", "reading comprehension"]]}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Serra Sinem Tekiroglu , G \u00a8ozde \u00a8Ozbal , and Carlo Strapparava .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Exploring sensorial features for metaphor identi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the Third Workshop on Metaphor in NLP , pages 31\u201339 .", "entities": []}, {"text": "Paul H Thibodeau and Lera Boroditsky .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Metaphors we think with : The role of metaphor in reasoning .", "entities": []}, {"text": "PloS one , 6(2):e16782 .", "entities": [[0, 1, "DatasetName", "PloS"]]}, {"text": "Yulia Tsvetkov , Leonid Boytsov , Anatole Gershman , Eric Nyberg , and Chris Dyer . 2014 .", "entities": []}, {"text": "Metaphor detection with cross - lingual model transfer .", "entities": []}, {"text": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , volume 1 , pages 248\u2013258 .", "entities": []}, {"text": "Yulia Tsvetkov , Elena Mukomel , and Anatole Gershman .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Cross - lingual metaphor detection using common semantic features .", "entities": []}, {"text": "In Proceedings of the First Workshop on Metaphor in NLP , pages 45\u201351 .", "entities": []}, {"text": "Peter D Turney , Yair Neuman , Dan Assaf , and Yohai Cohen . 2011 .", "entities": []}, {"text": "Literal and metaphorical sense identi\ufb01cation through concrete and abstract context .", "entities": []}, {"text": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 680 \u2013 690 . Association for Computational Linguistics .", "entities": []}, {"text": "Tony Veale , Ekaterina Shutova , and Beata Beigman Klebanov . 2016 .", "entities": []}, {"text": "Metaphor : A computational perspective .", "entities": []}, {"text": "Synthesis Lectures on Human Language Technologies , 9(1):1\u2013160 .", "entities": []}, {"text": "Mingyu Wan , Kathleen Ahrens , Emmanuele Chersoni , Menghan Jiang , Qi Su , Rong Xiang , and Chu - Ren Huang . 2020 .", "entities": []}, {"text": "Using conceptual norms for metaphor detection .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Figurative Language Processing , Seattle , WA .", "entities": []}, {"text": "Chuhan Wu , Fangzhao Wu , Yubo Chen , Sixing Wu , Zhigang Yuan , and Yongfeng Huang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Thu ngn at naacl-2018 metaphor shared task :", "entities": []}, {"text": "Neural metaphor detecting with cnn - lstm model .", "entities": [[6, 7, "MethodName", "lstm"]]}, {"text": "In Proceedings of the Workshop on Figurative Language Processing , New Orleans , LA .", "entities": []}, {"text": "Gerald Zaltman and Lindsay H Zaltman .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Marketing metaphoria : What deep metaphors reveal about the minds of consumers .", "entities": [[0, 1, "TaskName", "Marketing"]]}, {"text": "Harvard Business Press .", "entities": []}]