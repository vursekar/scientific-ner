[{"text": "Proceedings of the 4thSocial Media Mining for Health Applications ( # SMM4H ) Workshop & Shared Task , pages 120\u2013122 Florence , Italy , August 2 , 2019 .", "entities": [[11, 12, "DatasetName", "SMM4H"], [20, 21, "MethodName", "Florence"]]}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics120 Detection of Adverse Drug Reaction mentions in tweets using ELMo      Sarah Sarabadani Klick Health , Toronto , Canada .", "entities": [[14, 15, "MethodName", "ELMo"]]}, {"text": "ssarabadani@klick.com", "entities": []}, {"text": "Abstract", "entities": []}, {"text": "This paper describes the models used by our team in SMM4H 2019 shared task ( Weissenbacher et al . , 2019 ) .", "entities": [[10, 11, "DatasetName", "SMM4H"]]}, {"text": "We submitted results for subtasks 1 and 2 .", "entities": []}, {"text": "For task 1 which aims to detect tweets with Adverse Drug Reaction ( ADR ) mentions we used ELMo embeddings which is a deep contextualized word representation able to capture both syntactic and semantic characteristics .", "entities": [[18, 19, "MethodName", "ELMo"]]}, {"text": "For task 2 , which focuses on extraction of ADR mentions , first the same architecture as task 1 was used to identify whether or not a tweet contains ADR .", "entities": []}, {"text": "Then , for tweets positively classified as mentioning ADR , the relevant text span was identified by similarity matching with 3 different lexicon sets .", "entities": []}, {"text": "1 Introduction and task description Twitter is an ever - growing store of daily generated data .", "entities": []}, {"text": "Given the huge number of tweets talking about drug - related issues , social media mining is applicable to areas such as pharmacovigilance ( Lee et al . , 2017 ; Nikfarjam et al . , 2015 ;   Ginn et al . , 2014 ; Freifeld et al . , 2014 ; Bian et", "entities": []}, {"text": "al . , 2012 ) .", "entities": []}, {"text": "Tasks 1 and 2 focuses on detecting tweets with ADR and identifying location of mentions .", "entities": []}, {"text": "We are provided with 25,672 tweets ( 2,374 positive and 23,298 negative ) and approximately 5,000 unlabeled tweets as a validation set .", "entities": []}, {"text": "For the second task , a subset of 2,367 tweets from the first task was provided ( 1,212 positive and 1,155 negative ) .", "entities": []}, {"text": "The evaluation data comprises 1,000 tweets ( ~500 positive , ~500 negative ) .", "entities": []}, {"text": "1 https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-data-files    2", "entities": []}, {"text": "Preprocessing Stop words and punctuations were removed from tweets and all drug names found in the FDA \u2019s Approved Drug Products list1 were replaced by the word \u201c drug \u201d .", "entities": []}, {"text": "Word stemming and tokenization were performed using nltk python library .", "entities": []}, {"text": "3 Methods   3.1 task 1 For this task , we used 4 deep learning models .", "entities": []}, {"text": "The architecture of the first 3 models were relatively similar , differing in the embedding layer .", "entities": []}, {"text": "The first model involves character embedding with dimension equal to the total number of unique characters in training set including emojis .", "entities": []}, {"text": "The output of this layer is fed to a series of 6 convolutional neural network layers ( CNNs ) with ReLU activation .", "entities": [[20, 21, "MethodName", "ReLU"]]}, {"text": "Each CNN used 256 filters , with a filter size of 7 for the first two layers and 3 for the rest .", "entities": []}, {"text": "Max pooling with size 3 was used for the first two and last CNNs .", "entities": [[0, 2, "MethodName", "Max pooling"]]}, {"text": "The CNNs \u2019 output was fed into a bidirectional LSTM ( Bi - LSTM ) with 2 * 200 units , whose output was flattened to feed into two dense layers .", "entities": [[8, 10, "MethodName", "bidirectional LSTM"], [13, 14, "MethodName", "LSTM"]]}, {"text": "We used two fully connected layers with 1024 units each , ReLU activation , and dropout of 0.5 .", "entities": [[11, 12, "MethodName", "ReLU"]]}, {"text": "Finally , we used a dense layer with size two and softmax activation .", "entities": [[11, 12, "MethodName", "softmax"]]}, {"text": "We used Adam as the optimizer and binary cross - entropy as the loss function .", "entities": [[2, 3, "MethodName", "Adam"], [5, 6, "HyperparameterName", "optimizer"], [13, 14, "MetricName", "loss"]]}, {"text": "The model was trained with 10 epochs and batch size of 128 .", "entities": [[8, 10, "HyperparameterName", "batch size"]]}, {"text": "The second architecture was identical to the first , except the first layer was a word embedding using GloVe2 pre - trained on Twitter data with embedding dimension of 100 .", "entities": [[26, 28, "HyperparameterName", "embedding dimension"]]}, {"text": "2 https://nlp.stanford.edu/projects/glove/", "entities": []}, {"text": "121The third model was a concatenation of word and character embeddings .", "entities": []}, {"text": "We combined the Bi - LSTM output of the first and second models and then applied dense layers as before .", "entities": [[5, 6, "MethodName", "LSTM"]]}, {"text": "After building the above models , we tried to improve the outcomes by adding layers and features .", "entities": []}, {"text": "We used a multi - head self - attention with an attention width of 15 and ReLU activation .", "entities": [[16, 17, "MethodName", "ReLU"]]}, {"text": "We also explored the effect of sentiment features .", "entities": []}, {"text": "Since the data classes were imbalanced , we tried to make class sizes equal by downsampling and upsampling .", "entities": []}, {"text": "In downsampling , samples from the majority class ( tweets without ADR mentions ) were randomly sampled without replacement .", "entities": []}, {"text": "In upsampling we did the opposite , adding samples from the minority class with replacement .", "entities": []}, {"text": "None of these strategies substantially altered our baseline results .", "entities": []}, {"text": "In our final model , we used ELMo ( Peters et al . , 2018 ) ( Embeddings from Language Models ) with 1024 dimensions .", "entities": [[7, 8, "MethodName", "ELMo"]]}, {"text": "In contrast to traditional word embeddings such as GloVe and word2vec , ELMo assigns each word to a vector as a function of the entire sentence containing that word .", "entities": [[4, 6, "TaskName", "word embeddings"], [8, 9, "MethodName", "GloVe"], [12, 13, "MethodName", "ELMo"]]}, {"text": "Therefore , the same word can have different embeddings depending on its context .", "entities": []}, {"text": "Since ELMo already captures character - level information under the hood , we decided to encircle the complexity inside the embedding layer and used only two additional dense layers with 256 and 2 units , using ReLU and softmax activations , respectively .", "entities": [[1, 2, "MethodName", "ELMo"], [36, 37, "MethodName", "ReLU"], [38, 39, "MethodName", "softmax"]]}, {"text": "3.2 Methods for task 2   To identify the text spans of ADR mentions , first the model developed for task 1 was used to determine whether each tweet mentions an ADR .", "entities": []}, {"text": "Then the similarity between each tweet and 3 different lexicon sets ( Nikfarjam et al.3 , MedDRA ( Medical Dictionary for Regulatory Activities)4 , and CHV ( Consumer Health V ocabulary ) 5 ) was measured .", "entities": []}, {"text": "To calculate similarity , each tweet and lexicon was converted to a set of word stems .", "entities": []}, {"text": "Since similarity measures such as cosine or Jaccard are highly affected by other non - ADR words , we defined similarity as the percent of word stems of a lexicon that exist in a tweet .", "entities": []}, {"text": "For each tweet , only lexicons with a 100 % match were kept .", "entities": []}, {"text": "", "entities": []}, {"text": "3   http://diego.asu.edu/Publications/ADRMine.html 4 https://www.meddra.org/how-to-use/support-documentation/english   4 Results , discussion , and next steps Among all architectures , the best results came from ELMo embedding ( F1 = 0.64 ) .", "entities": [[23, 24, "MethodName", "ELMo"], [26, 27, "MetricName", "F1"]]}, {"text": "Therefore , we only submitted ELMo results with 5 , 10 , and 15 epochs .", "entities": [[5, 6, "MethodName", "ELMo"]]}, {"text": "The model performed less well for the validation set ( F1 = 0.41 ) , below the average F1 score of 0.50 among all teams , which might result from overfitting .", "entities": [[10, 11, "MetricName", "F1"], [17, 19, "MetricName", "average F1"]]}, {"text": "Using more sophisticated architecture after the embedding layer might improve performance .", "entities": []}, {"text": "Since task 2 \u2019s performance depends strongly on task 1 , we also scored lower on this task compared to the team average ( 0.40 vs. 0.54 ) .", "entities": []}, {"text": "Since ADR phrases and tweets do not always lexically match , approaches such as named entity recognition ( NER ) might perform better .", "entities": [[14, 17, "TaskName", "named entity recognition"], [18, 19, "TaskName", "NER"]]}, {"text": "Other approaches to improve performance : Task 1 : \u2022 Try other embeddings such as BERT \u2022 Experiment with more complex architectures after the ELMo layer \u2022 Add part of speech ( POS ) tags   \u2022 Add topic modeling and tweet cluster features Task 2 : \u2022 Search Twitter for keywords from lexicon sets to augment the training set with new tweets which mention ADRs \u2022 Try NER Acknowledgment I would like to thank Maheedhar Kolla who provided insight and expertise that significantly assisted this work .", "entities": [[15, 16, "MethodName", "BERT"], [24, 25, "MethodName", "ELMo"], [68, 69, "TaskName", "NER"]]}, {"text": "I would also like to show my gratitude to Peter Leimbigler for comments that greatly improved the manuscript .", "entities": []}, {"text": "Finally , special thanks go to Alfred Whitehead for supporting me to participate in this challenge .", "entities": []}, {"text": "5https://www.nlm.nih.gov/research/umls/sourcereleasedocs/current/CHV/", "entities": []}, {"text": "122References Jiang Bian , Umit Topaloglu , and Fan Yu .", "entities": []}, {"text": "( 2012 , October ) .", "entities": []}, {"text": "Towards large - scale twitter mining for drug - related adverse events .", "entities": []}, {"text": "In Proceedings of the 2012 international workshop on Smart health and wellbeing ( pp . 25 - 32 ) . ACM .", "entities": [[20, 21, "DatasetName", "ACM"]]}, {"text": "Clark C. Freifeld , John S. Brownstein , Christopher M.        Menone , Wenjie Bao , Ross Filice , Taha Kass - Hout , and Nabarun Dasgupta .", "entities": []}, {"text": "( 2014 ) .", "entities": []}, {"text": "Digital drug safety surveillance : monitoring pharmaceutical products in twitter .", "entities": []}, {"text": "Drug safety , 37(5 ) , 343 - 350 .", "entities": []}, {"text": "Rachel Ginn , Pranoti Pimpalkhute , Azadeh     Nikfarjam , Apurv Patki , Karen O\u2019Connor , Abeed Sarker , Karen Smith , and Graciela Gonzalez .", "entities": []}, {"text": "( 2014 , May ) .", "entities": []}, {"text": "Mining Twitter for adverse drug reaction mentions : a corpus and classification benchmark .", "entities": []}, {"text": "In Proceedings of the fourth workshop on building and evaluating resources for health and biomedical text processing ( pp . 1 - 8) .", "entities": []}, {"text": "Kathy Lee , Ashequl Qadir , Sadid A. Hasan , Vivek Datla , Aaditya Prakash , Joey Liu , and Oladimeji Farri .", "entities": []}, {"text": "( 2017 , April )", "entities": []}, {"text": ".", "entities": []}, {"text": "Adverse drug event detection in tweets with semi - supervised convolutional neural networks .", "entities": [[2, 4, "TaskName", "event detection"]]}, {"text": "In Proceedings of the 26th International Conference on World Wide Web ( pp . 705 - 714 ) .", "entities": []}, {"text": "International World Wide Web Conferences Steering Committee .", "entities": []}, {"text": "Azadeh Nikfarjam , Abeed Sarker , Karen O\u2019connor , Rachel Ginn , and Graciela Gonzalez . ( 2015 ) .", "entities": []}, {"text": "Pharmacovigilance from social media : mining adverse drug reaction mentions using sequence labeling with word embedding cluster features .", "entities": []}, {"text": "Journal of the American Medical Informatics Association , 22(3 ) , 671 - 681 .", "entities": []}, {"text": "Matthew E. Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer .", "entities": []}, {"text": "( 2018 ) .", "entities": []}, {"text": "Deep contextualized word representations .", "entities": []}, {"text": "arXiv preprint arXiv:1802.05365 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Davy Weissenbacher , Abeed Sarker , Arjun Magge , Ashlynn Daughton , Karen O'Connor , Michael Paul , Graciela Gonzalez - Hernandez .", "entities": []}, {"text": "Overview of the Fourth Social Media Mining for Health ( SMM4H ) Shared Task at ACL 2019 .", "entities": [[10, 11, "DatasetName", "SMM4H"]]}, {"text": "In Proceedings of the 2019 ACL Workshop SMM4H : The 4th Social Media Mining for Health Applications Workshop & Shared Task", "entities": [[7, 8, "DatasetName", "SMM4H"]]}]