[{"text": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 4881\u20134892 June 6\u201311 , 2021 .", "entities": []}, {"text": "\u00a9 2021 Association for Computational Linguistics4881Multitask Learning for Emotionally Analyzing Sexual Abuse Disclosures Ramit Sawhneyy , Puneet Mathurz , Taru Jainy , Akash Kumar Gautamy , Rajiv Ratn Shahy yDepartment of Computer Engineering , IIIT - Delhi { ramits , akash15011 , rajivratn}@iiitd.ac.in zUniversity of Maryland ,", "entities": [[23, 24, "DatasetName", "Kumar"]]}, {"text": "College Park puneetm@cs.umd.edu Abstract The # MeToo movement on social media platforms initiated discussions over several facets of sexual harassment in our society .", "entities": []}, {"text": "Prior work by the NLP community for automated identi\ufb01cation of the narratives related to sexual abuse disclosures barely explored this social phenomenon as an independent task .", "entities": []}, {"text": "However , emotional attributes associated with textual conversations related to the # MeToo social movement are complexly intertwined with such narratives .", "entities": []}, {"text": "We formulate the task of identifying narratives related to the sexual abuse disclosures in online posts as a joint modeling task that leverages their emotional attributes through multitask learning .", "entities": []}, {"text": "Our results demonstrate that positive knowledge transfer via context - speci\ufb01c shared representations of a \ufb02exible cross - stitched parameter sharing model helps establish the inherent bene\ufb01t of jointly modeling tasks related to sexual abuse disclosures with emotion classi\ufb01cation from the text in homogeneous and heterogeneous settings .", "entities": [[37, 38, "DatasetName", "emotion"]]}, {"text": "We show how for more domain - speci\ufb01c tasks related to sexual abuse disclosures such as sarcasm identi\ufb01cation and dialogue act ( refutation , justi\ufb01cation , allegation ) classi\ufb01cation , homogeneous multitask learning is helpful , whereas for more general tasks such as stance and hate speech detection , heterogeneous multitask learning with emotion classi\ufb01cation works better.1 1 Introduction The # MeToo movement2was started as an initiative to empower women against long - standing issues related to sexual abuse at workplaces , public spaces , and private organizations ( McKenna and Chughtai , 2020 ) .", "entities": [[45, 48, "TaskName", "hate speech detection"], [53, 54, "DatasetName", "emotion"]]}, {"text": "The usage of a dedicated hashtag#MeToo on media platforms signi\ufb01ed a social support system for women from different sections 1Code & Implementation : https://github.com/ midas - research / metoo - mtl - naacl 2https://metoomvmt.org/ Figure 1 : Examples showing the relationship between tweets annotated for sexual harassment disclosure ( top ) and emotion recognition ( bottom ) .", "entities": [[52, 54, "TaskName", "emotion recognition"]]}, {"text": "Colors highlight token level attention assigned by BERTweet . of society .", "entities": []}, {"text": "The movement initiated discussions on many socially stigmatized issues that were missing from the virtual space ( Clark - Parsons , 2019 ) .", "entities": []}, {"text": "Such conversations invited various reactions on the web , involving support to the cause of the movement and even outright bullying .", "entities": []}, {"text": "While many users took part in the vili\ufb01cation of the survivors , the movement also saw opposition by factions of the society that felt threatened by the impact of social media in raising awareness about the scale of everyday sexual harassment faced by women in workplaces and institutions ( Tambe , 2018 ) .", "entities": []}, {"text": "In many instances , the public disclosures of survivor - narrated incidents involved widespread use of hate - language and online trolling , both against the victims and alleged oppressors ( Franks , 2019 ) .", "entities": []}, {"text": "The # MeToo movement also led to people coming out with allegations , refutations , and justi\ufb01cations about traumatic experiences as they transitioned to active participants in the mainstream conversation ( Gautam et al . , 2020 ) .", "entities": []}, {"text": "A closer look at the online posts about the # MeToo movement revealed that sarcasm was often used as a thin veil in such discussions to humorously mask disapproval , wit , and personal attacks ( Sandhu et al . , 2019 ) .", "entities": []}, {"text": "The complex narratives present in the conversations on stigmatized issues like sexual abuse create an opportunity for researchers to study how people", "entities": []}, {"text": "4882express their opinions on a sensitive topic in an informal social setting .", "entities": []}, {"text": "It also offers a chance to social media regulators for fostering social inclusion , community integration , and improving the individual perception of being supported by others .", "entities": []}, {"text": "This paper aims at categorizing the posts related to the # MeToo movement on the basis of stance ( support or opposition ) , hate - speech , sarcasm , and dialogue acts ( allegation , refutation , or justi\ufb01cation of sexual misconduct ) .", "entities": []}, {"text": "We focus our analysis on a publicly available dataset that is created in the backdrop of mass instances of sexual harassment disclosures and includes nuanced labels to identify accompanying linguistic behaviors .", "entities": []}, {"text": "Existing literature has emphasized that the text \u2019s emotional attributes have a high correlation with dialogue narratives describing instances of sexual harassment ( Lane and Hedin , 2020 ) .", "entities": []}, {"text": "Prior works ( Anzovino et al . , 2018 ; Shari\ufb01rad et al . , 2018 ) have mostly focused on label speci\ufb01c detection of linguistic narratives related to sexual harassment disclosures in isolation by exploiting lexical features ( Chowdhury et al . , 2019 ; Karlekar and Bansal , 2018 ) .", "entities": []}, {"text": "However , subtle intricacies present in the discussion of sexual abuse disclosures often re\ufb02ect the speaker \u2019s affective and psychological state , which are overlooked by feature - engineered models .", "entities": []}, {"text": "For instance , part ( a ) of Figure 1 shows a tweet expressing support towards the # MeToo movement but in a tone that might be dif\ufb01cult for naive neural learning models to capture without context .", "entities": []}, {"text": "Part ( b ) of Figure 1 presents a tweet in which the author has an initial positive outlook , which later reverses to disgust for the subject .", "entities": []}, {"text": "The lack of context about the event and contrasting quali\ufb01cations describing the oppressor makes the correct classi\ufb01cation of the sexual harassment disclosure label extremely challenging for traditional classi\ufb01ers without emotional labels \u2019 additional supervision .", "entities": []}, {"text": "Moreover , apart from their inherent complexity , conversations related to the # MeToo movement also pose a challenge of emotional ambiguity .", "entities": []}, {"text": "This work is the \ufb01rst attempt at joint modeling of narratives related to sexual abuse disclosures and emotion classi\ufb01cation to learn the patterns of their interaction via parameter sharing techniques offered by Multitask Learning ( MTL ) .", "entities": [[17, 18, "DatasetName", "emotion"]]}, {"text": "The affective features , which result from a joint learning setup through shared parameters , will encompass the text \u2019s emotional content that is likely to be predictive of narratives corresponding to sexual abuse disclo - sures .", "entities": []}, {"text": "More speci\ufb01cally , we formulate an MTL framework for multi - label classi\ufb01cation of narratives related to sexual abuse disclosures ( stance , hate - speech , sarcasm , dialogue acts ) and emotional classi\ufb01cation in the context of the # MeToo movement .", "entities": []}, {"text": "MTL ( Caruana , 1997 ) allows two or more related tasks to be learned jointly .", "entities": []}, {"text": "This facilitates the transfer of inductive bias and better generalization across related tasks on account of shared representations of linguistic features .", "entities": []}, {"text": "Contributions We experiment with MTL architectures employing a \ufb02exible cross - stitched parameter sharing method that bene\ufb01ts from both hard - parameter sharing and soft parameter sharing through a gated mechanism using a weighted summation ( Section 4 ) .", "entities": []}, {"text": "Hard parameter sharing allows for sharing lower - level word representations , and soft parameter sharing permits the sharing of task - speci\ufb01c networks .", "entities": []}, {"text": "We explore two \ufb02avors of multitask learning : ( i ) Homogeneous MTL - Intradomain MTL between related tasks of sexual abuse disclosure narratives , and ( ii ) Heterogeneous MTL - cross - domain MTL between pairs of tasks in emotion classi\ufb01cation and narratives of sexual abuse disclosure ( Section 5.2 ) .", "entities": [[41, 42, "DatasetName", "emotion"]]}, {"text": "Our results demonstrate that both Homogeneous and Heterogeneous MTL setups outperform the Single Task Learning ( STL ) technique across various tasks ( Section 6 ) .", "entities": []}, {"text": "Further , we conduct a qualitative analysis of several samples to analyze the bene\ufb01t of joint training of related tasks ( Section 6.4 ) , keeping in mind the ethical concerns of communities affected by this research ( Section 7 ) .", "entities": []}, {"text": "2 Related Work Sexual Harassment Disclosures on Social Media Several works have focused on identifying sexual violence ( Leatherman , 2011 ) , harassment and sexism ( Wekerle et al . , 2018 ;", "entities": []}, {"text": "Manikonda et al . , 2018b ) in social media posts by analyzing factors such as linguistic themes , social engagement , and lexical attributes .", "entities": []}, {"text": "Jha and Mamidi ( 2017 ) experimented with algorithms such as SVM and BiLSTM along with fastText to categorize hostility of sexist posts .", "entities": [[11, 12, "MethodName", "SVM"], [13, 14, "MethodName", "BiLSTM"], [16, 17, "MethodName", "fastText"]]}, {"text": "( Parikh et al . , 2019 ) proposed a multi - label CNN - based neural architecture along with word and sentence level embeddings for identifying variants of sexism present in online social platforms .", "entities": []}, {"text": "Chowdhury et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) emphasized the use of linguistic themes , contextual meta - data , and semantic cues for evaluating human behaviors related to sex-", "entities": []}, {"text": "4883ual abuse disclosures .", "entities": []}, {"text": "All of these works have dealt with modeling sexual disclosure narratives as single - task learning problems and were restricted to label speci\ufb01c detection ( Marwa et al . , 2018 ; Sawhney et al . , 2020 ) .", "entities": []}, {"text": "Multitask Learning Frameworks for learning representations across two different sources within the same domain follow multitask learning ( Caruana , 1997 ) .", "entities": []}, {"text": "The ability to utilize knowledge from various sources compensates for missing data and complements existing meta - data ( Tan et al . , 2013 ; Ding et al . , 2014 ) , thus allowing for effective sharing of task - invariant features ( Caruana , 1997 ; Zhang and Wang , 2016 ; Zhang et al . , 2018 ) .", "entities": []}, {"text": "MTL has been utilized for name error recognition ( Cheng et al . , 2015 ) , tagging - chunking ( Collobert et al . , 2011 ) , machine translation ( Luong et al . , 2015 ) and relation extraction ( Gupta et al . , 2016 ) .", "entities": [[19, 20, "TaskName", "chunking"], [29, 31, "TaskName", "machine translation"], [40, 42, "TaskName", "relation extraction"]]}, {"text": "Liu et al .", "entities": []}, {"text": "( 2017 ) used shared and private latent features leveraging multitask learning for different text classi\ufb01cation tasks .", "entities": []}, {"text": "Rajamanickam et", "entities": []}, {"text": "al . ( 2020 ) ; Duong et", "entities": []}, {"text": "al . ( 2016 ) ; Liu et al .", "entities": []}, {"text": "( 2016 ) proposed a joint framework for modeling abuse and emotion detection and showed improvements over STL and transfer learning .", "entities": [[11, 12, "DatasetName", "emotion"], [19, 21, "TaskName", "transfer learning"]]}, {"text": "Akhtar et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) proposed a multitask ensemble architecture for jointly modeling emotion , sentiment , and intensity , which gave improvements over single - label classi\ufb01cation .", "entities": [[11, 12, "DatasetName", "emotion"]]}, {"text": "3 Problem Description We aim to analyze different perspectives of the complex narratives pertaining to the # MeToo movement on social media platforms .", "entities": []}, {"text": "Speci\ufb01cally , given a tweet text , we formulate for it a multi - label multiclass classi\ufb01cation problem with de\ufb01nitions taken from previous works ( ElSherief et al . , 2018 )", "entities": []}, {"text": "\u2022Stance Detection : Determining the opinion of the author of a tweet , regarding a particular target of interest ( Augenstein et al . , 2016 ) .", "entities": []}, {"text": "Stance detection is categorized into three classes : Support for when the author favors the # MeToo movement or it \u2019s cause ; Opposition , representing opposing stance or indifference towards the movement ; or Neither , when the text does not have a clear viewpoint ( Mohammad and Turney , 2013 ) .", "entities": [[0, 2, "TaskName", "Stance detection"]]}, {"text": "\u2022Hate Speech Identi\ufb01cation : Detection of hate speech involves labeling the tweets as Directed Hate if the comment is targeted towards an individual or an entity , Generalized Hate ifit is targeted towards a community or a section of people or Neither otherwise ( Basile et al . , 2019 ) .", "entities": [[6, 8, "DatasetName", "hate speech"]]}, {"text": "\u2022Sarcasm Detection : Given a tweet ti , we aim to map it to either be Sarcastic orNot Sarcasticbased on the presence of implicit sarcastic tone of the post ( Bamman and Smith , 2015 ) .", "entities": []}, {"text": "\u2022Dialogue Act Classi\ufb01cation : These are a function of a speaker \u2019s utterance during a conversation , for example , question , answer , suggestion , etc . , and are classi\ufb01ed into three classes , namely Allegation ( when the author intends to allege an individual or group of sexual misconduct ) ( Hutchings , 2012 ) , Justi\ufb01cation ( tweets where the author is justifying their actions ) , and Refutation ( for when the author refutes any accusation with or without evidence ) ( Gautam et al . , 2020 ) .", "entities": []}, {"text": "Modeling Settings To validate MTL \u2019s performance across different domains , we also experiment with emotion detection as the auxiliary task .", "entities": [[15, 16, "DatasetName", "emotion"]]}, {"text": "We aim to predict one or more of the several emotions representing the affective state of the authors -(anger , disgust , anticipation , fear , joy , love , optimism , pessimism , sadness , surprise andtrust ) .", "entities": []}, {"text": "We conceptualize three diverse problem settings and compare them to analyze MTL within andacross domains .", "entities": []}, {"text": "These are ( i ) Single Task Learning : Independent optimization of the four mentioned tasks associated with sexual abuse disclosure narrative classi\ufb01cation , ( ii ) Homogeneous Multitask Learning : Simultaneous optimization of a pair selected from the four tasks associated with the sexual abuse disclosure posts , and ( iii ) Heterogeneous Multitask Learning : Classi\ufb01cation of narratives associated with sexual abuse disclosure as the primary task and emotion detection as the auxiliary task .", "entities": [[70, 71, "DatasetName", "emotion"]]}, {"text": "4 Methodology 4.1 Text Encoding Building on the success of transformer - based models in NLP , we chose BERTweet ( Dat Quoc Nguyen and Nguyen , 2020 ) , a pre - trained language model trained on 850million English tweets .", "entities": []}, {"text": "BERTweet has been trained with the same training procedure as RoBERTa ( Liu et al . , 2019 ) and has the same model con\ufb01guration as the BERT base architecture ( Devlin et al . , 2019 ) .", "entities": [[10, 11, "MethodName", "RoBERTa"], [27, 28, "MethodName", "BERT"]]}, {"text": "The key component in", "entities": []}, {"text": "4884Task Label # Samples Text Relevance Relevant 7,249Guys are pissed off at [ name ] for affecting the credibility of a sexual assault survivor .", "entities": []}, {"text": "Only men and r*p * enablers are questioning the movement in today \u2019s times .", "entities": []}, {"text": "# Attack # BringTheChange .", "entities": []}, {"text": "StanceSupport 3,074Thank", "entities": []}, {"text": "you", "entities": []}, {"text": "[ name ] for your courage passion and \ufb01ght for # MeToo .", "entities": []}, {"text": "It gives [ name ] strength to overcoming all this in front of people .", "entities": []}, {"text": "Hope this inspires others as well to bring more stories .", "entities": []}, {"text": "# Survivor .", "entities": []}, {"text": "Opposition 743The progressive video by [ user ] shows the lady as a stripper , but are upset when [ name ] calls this movement bogus .", "entities": []}, {"text": "Ca n\u2019t believe lies especially when so much has happened .", "entities": []}, {"text": "# Fake # MeToo .", "entities": []}, {"text": "Hate SpeechDirected 419Life comes hard at [ name ] .", "entities": []}, {"text": "Desperate for [ name ] approval , she tries to subvert the risk of her tawdry dating habits [ URL ] and disgusted company .", "entities": []}, {"text": "Did n\u2019t even \ufb02inch once before saying this .", "entities": []}, {"text": "# Fake .", "entities": []}, {"text": "Generalized 281These are not involved at all in this .....", "entities": []}, {"text": "# MeToo has nothing with hating people .", "entities": []}, {"text": "Its just a strategy by feminist h*e to get their a**es rich by manipulating people and asking for money .", "entities": []}, {"text": "# Feminists Sarcasm Sarcastic 220Thankfully the # HimToo movement will encourage [ name ] to put his d*c * inside his pant , out of the fear of getting publicly criticized by others .", "entities": []}, {"text": "# MeToo .", "entities": []}, {"text": "Is this really story of the decade , LOL ! ! !", "entities": [[8, 9, "DatasetName", "LOL"]]}, {"text": "# SpeakOut Dialogue ActsAllegation 578Shut up now , [ name ] , you said nothing when 10 women accused [ name ] of sexual harassment", "entities": []}, {"text": "[ URL ] in the premises .", "entities": []}, {"text": "Instead [ name ] remained silent among all this with eyes wide out .", "entities": []}, {"text": "# IBelieveSurvivors [ URL ] Justi\ufb01cation 292[name ] embodies # MeToo movement , writing and spreading fake message loud and clear .", "entities": []}, {"text": "Push false narrative and wrong ideology among the youth .", "entities": []}, {"text": "This would get the job done .", "entities": []}, {"text": "# BringOutTheTruth Refutation 216[name ] says # MeToo is a trap , set by left wingers .", "entities": []}, {"text": "Do n\u2019t take the bait at all .", "entities": []}, {"text": "The right should n\u2019t worry least , especially because of the involvement of [ name ] .", "entities": []}, {"text": "This has happened far too many times in the past .", "entities": []}, {"text": "Table 1 : Distribution of labels and examples for all tasks in # MeTooMA dataset .", "entities": [[12, 14, "DatasetName", "# MeTooMA"]]}, {"text": "The tweets have been paraphrased for anonymity reasons and personally identi\ufb01able information has been censored .", "entities": []}, {"text": "We want to caution the readers that examples in this paper , though censored for profanity might contain offensive language .", "entities": []}, {"text": "transformer - based models is the token level selfattention ( Vaswani et al . , 2017 ) that enables them to generate dynamic contextualized embeddings as opposed to static embeddings of GloVe ( Pennington et al . , 2014 ) .", "entities": [[31, 32, "MethodName", "GloVe"]]}, {"text": "Let ( w1;w2;:::;wn)represent the sequence of tokens from a given tweet t.", "entities": []}, {"text": "These tokens are pre - processed and passed through BERTweet3 .", "entities": []}, {"text": "We consider embeddings from the last layer of BERTweet and obtain an embedding eifor a given tweet ti .", "entities": []}, {"text": "Embedding for each tweet is of dimensionm\u0002k , wherekrepresents the dimension size of BERT based model and mrepresents the maximum length for the tweets .", "entities": [[13, 14, "MethodName", "BERT"]]}, {"text": "ei = BERTweet ( ti ) ( 1 ) These representations from Equation 1 are passed through a stacked BiLSTM encoder .", "entities": [[19, 20, "MethodName", "BiLSTM"]]}, {"text": "Dropout is then applied to these encoded representations h(t ) ( Equation 4 represents general formulation for both the tasks ) .", "entities": [[0, 1, "MethodName", "Dropout"]]}, {"text": "These are then passed to a BiLSTM decoder , followed by a dropout layer and then a linear output layer to get output o(p)(prepresenting primary task ) oro(a)(arepresenting auxiliary task ) .", "entities": [[6, 7, "MethodName", "BiLSTM"]]}, {"text": "\u0000\u0000 ! h(f ) t = BiLSTM(f)(et;h(f ) t\u00001 ) ( 2 )   \u0000\u0000 h(b ) t = BiLSTM(b)(et;h(b ) t+1 ) ( 3 ) ht=", "entities": []}, {"text": "[ \u0000\u0000 ! h(f ) t ; \u0000\u0000 h(b ) T\u0000t ]", "entities": []}, {"text": "( 4 ) 4.2 Single Task Learning We treat the task of categorizing narratives related to sexual abuse disclosure \u2013 Stance , Hate Speech , 3Implementation used for BERTweet is available hereSarcasm andDialogue Acts , independently .", "entities": [[22, 24, "DatasetName", "Hate Speech"]]}, {"text": "Each STL model is given an input representation e(Equation 1 ) .", "entities": []}, {"text": "Within the proposed tasks for classifying sexual abuse disclosure narrative for the tweets related to the # MeToo movement ( Section 3 ) , we use sigmoid activation for Sarcasm detection ( whose classi\ufb01cation outputs are binary ) and softmax activation for all other tasks for the \ufb01nal output layer .", "entities": [[26, 28, "MethodName", "sigmoid activation"], [29, 31, "TaskName", "Sarcasm detection"], [39, 40, "MethodName", "softmax"]]}, {"text": "Model Optimization To account for the imbalance present among the labels , we use classbalanced focal loss as the optimization loss function ( Cui et al . , 2019 ) , as formulated in Equation 5 .", "entities": [[15, 17, "MethodName", "focal loss"], [20, 21, "MetricName", "loss"]]}, {"text": "Given a sample class icontainingnisamples in total , it adds a weighting factor of(1\u0000 \f ) ( 1\u0000 \f ni)with parameters \f 2[0;1 ) , wherenyis the number of samples in the ground truth class", "entities": [[27, 30, "HyperparameterName", "number of samples"]]}, {"text": "y.", "entities": []}, {"text": "The proposed class - balanced term is model agnostic .", "entities": []}, {"text": "prepresents predicted class probabilities and Lrepresents the choice of the loss function ( binary cross entropy for Sarcasm and categorical cross entropy for others ) .", "entities": [[10, 11, "MetricName", "loss"]]}, {"text": "CB(p;y )", "entities": []}, {"text": "= 1\u0000 \f  1\u0000 \f nyL(p;y ) ( 5 ) As for the multilabel emotion classi\ufb01cation task , the unnormalized output ( assuming one or more of 11 different emotions ) is subjected to a Sigmoid activation , and the network is optimized using binary cross - entropy ( BCE ) as : LBCE = \u00001 NNX i=1yi : log(p(yi ) )", "entities": [[14, 15, "DatasetName", "emotion"], [35, 37, "MethodName", "Sigmoid activation"]]}, {"text": "+ ( 1 \u0000yi):log(1 \u0000p(yi ) ) ( 6 ) whereNis the number of training samples , yand p(y)denotes true and predicted labels respectively .", "entities": []}, {"text": "48854.3 Multitask Learning For our MTL approach , we use two optimization objectives : one for the primary task , which can be any of the proposed tasks for classifying tweets related to # MeToo movement ( Section 3 ) , and other for the auxiliary task , which can be either a task related to classifying sexual abuse disclosure for # MeToo movement ( Homogeneous MTL ) or emotion classi\ufb01cation task ( Heterogeneous MTL ) .", "entities": [[69, 70, "DatasetName", "emotion"]]}, {"text": "The two objectives are weighted by a parameter", "entities": []}, {"text": ", which controls the importance placed on the auxiliary task ( 1\u0000", "entities": []}, {"text": "for the primary task ) .", "entities": []}, {"text": "Multitask learning frameworks are generally built using either of these two approaches : hard parameter sharing orsoft parameter sharing .", "entities": []}, {"text": "In a hard parameter sharing model ( Caruana , 1997 ) , both the primary and auxiliary tasks have a shared encoder followed by separate task - speci\ufb01c network branches , and the shared encoder is updated by both the tasks alternately .", "entities": []}, {"text": "On the other hand , in the soft parameter sharing approach , tasks have different encoders with independent parameters , and the distance between their parameters is regularized using a regularization constraint ( Duong et", "entities": []}, {"text": "al . , 2015 ; Yang and Hospedales , 2016 ) , to encourage the parameters to be similar .", "entities": []}, {"text": "Flexible Cross - Stitched Parameter Sharing Architecture :", "entities": []}, {"text": "We design our model so that the task - agnostic textual feature representations bene\ufb01t from hard sharing while the regularization of the task - speci\ufb01c features can be learned according to task pair settings .", "entities": []}, {"text": "We call our approach \ufb02exible cross - stitched parameter sharing , presented in Figure 2 .", "entities": []}, {"text": "Speci\ufb01cally , we train two separate models ( one for each task ) in tandem while also having a shared encoder that is updated by both of them and weighted joint learning of primary task decoder parameters that are tuned speci\ufb01cally for the task .", "entities": []}, {"text": "This allows both the models to have their own set of parameters while also encouraging knowledge transfer via the shared encoder weights .", "entities": []}, {"text": "For each training pass of the primary task , the input representation e(p)is passed through ( a ) stacked BiLSTM encoder and(b ) stacked shared BiLSTM encoder .", "entities": [[19, 20, "MethodName", "BiLSTM"], [25, 26, "MethodName", "BiLSTM"]]}, {"text": "This results in two contextualized word representations ( h(p ) 1;h(p ) 2;:::h(p ) n ) and ( h(s ) 1;h(s ) 2;:::h(s ) n ) , where superscript ( p ) is used to denote the representations resulting from encoder in the primary task model and superscript ( s ) is used to denote the ones from shared encoder .", "entities": []}, {"text": "Wecalculate the weighted summation of these two representations - ~h(p ) , using two learnable parameters , \u000b ( p)and \u000b ( s)(where \u000b ( p)+ \u000b ( s)= 1 ) , as formulated in Equation 7 to regulate the information resulting from the two encoders ( Figure 2 ) .", "entities": []}, {"text": "~h(p)= \u000b ( p)h(p)+ \u000b ( s)h(s)(7 ) Such an approach to aggregate information \ufb02ow from two encoders has facilitated success in prior Multitask learning settings as well ( Rajamanickam et al . , 2020 ;", "entities": []}, {"text": "Dankers et al . , 2019 ) .", "entities": []}, {"text": "As for our auxiliary task , we pass the embeddings e(a)through only the shared encoder ( h(a)=h(s ) ) , followed by a dropout layer .", "entities": []}, {"text": "We use this architecture for Heterogeneous MTL experiments .", "entities": []}, {"text": "For Homogeneous MTL ones , we employ hard parameter sharing model due to statistical out - performance in this scenario .", "entities": []}, {"text": "This technique consists of a single stacked encoder that is shared and updated by both tasks related to identifying narratives related to sexual abuse disclosures within # MeToo movement , followed by task - speci\ufb01c branches .", "entities": []}, {"text": "The shared representations from the encoder are passed through the dropout layer .", "entities": []}, {"text": "These output representations ( in the case of both Homogeneous andHeterogeneous experiments ) are passed through respective BiLSTM decoders and dropout layers to get the \ufb01nal representation m(p ) andm(a ) , respectively for both the tasks .", "entities": [[17, 18, "MethodName", "BiLSTM"]]}, {"text": "The auxiliarynetwork branch is optimized using either Equation 5 ( Class Balanced Focal Loss ) or Equation 6 ( Binary Cross Entropy ) , depending upon whether theauxiliary task is associated with identifying sexual abuse disclosure narratives or emotions .", "entities": [[12, 14, "MethodName", "Focal Loss"]]}, {"text": "These output representations m(p)andm(a)are passed through a linear output layer to get unnormalized outputso(p)ando(a)respectively .", "entities": []}, {"text": "Sigmoid activation function is used for Sarcasm detection and the emotion classi\ufb01cation task , and Softmax activation for others .", "entities": [[0, 2, "MethodName", "Sigmoid activation"], [6, 8, "TaskName", "Sarcasm detection"], [10, 11, "DatasetName", "emotion"], [15, 16, "MethodName", "Softmax"]]}, {"text": "5 Experiments 5.1 Data MTL framework traditionally improves generalization by leveraging the domain - speci\ufb01c information due to the relatedness of the tasks present in the training signals ( Caruana , 1997 ) ; hence we use two publicly available datasets mined from Twitter :", "entities": []}, {"text": "4886 Figure 2 : Flexible Cross - stitched Parameter Sharing Architecture .", "entities": []}, {"text": "The embedding representations ( e(p ) 1;e(p ) 2;::;e(p ) n)and(e(a ) 1;e(a ) 2;::;e(a ) n)identify BERTweet word - level embeddings for the primary andauxiliary task respectively .", "entities": []}, {"text": "The different arrows are used to indicate the alternate passes of the primary task ( solid arrows ) andauxiliary task ( dotted arrows ) .", "entities": []}, {"text": "Two controllable parameters \u000b ( p)and \u000b ( s)are used to control information \ufb02ow from task - speci\ufb01c and shared encoder respectively , for the primary task .", "entities": []}, {"text": "Sexual Abuse Disclosures - # MeTooMA This dataset4has 9,973 tweets and covers different mutually non - exclusive linguistic annotations related to the # MeToo movement ( Gautam et al . , 2020 ) .", "entities": [[4, 6, "DatasetName", "# MeTooMA"]]}, {"text": "The distribution and statistics about various labels are present in Table 1 and Section 3 .", "entities": []}, {"text": "We present an instance associated with each of the proposed tasks in Table 1 .", "entities": []}, {"text": "For our experiments , we focus only on tweets that are annotated as relevant to the # MeToo movement .", "entities": []}, {"text": "Emotions - SemEval18", "entities": []}, {"text": "This dataset5has been taken from SemEval-2018 Task-1 ( Mohammad et al . , 2018 ) and covers emotion - speci\ufb01c labels representing the mental state of the authors of the tweets .", "entities": [[17, 18, "DatasetName", "emotion"]]}, {"text": "It consists of 10,986 tweets distributed across 11 emotion labels \u2013 ( anger , disgust , anticipation , fear , joy , love , optimism , pessimism , sadness , surprise andtrust ) , each being a binary label to indicate the presence of a particular emotion .", "entities": [[8, 9, "DatasetName", "emotion"], [46, 47, "DatasetName", "emotion"]]}, {"text": "5.2 Task Speci\ufb01c Setting Single Task Learning STL experiments optimize each of the tasks associated with identifying narratives related to sexual abuse disclosures within # MeToo movement ( Section 3 ) and emotion 4The publicly available dataset can be found at https : //doi.org/10.7910 / DVN / JN4EYU .", "entities": [[32, 33, "DatasetName", "emotion"]]}, {"text": "5https://competitions.codalab.org/ competitions/17751detection , independently .", "entities": []}, {"text": "We experiment with two distinct embedding spaces \u2013 GloVe - Twitter and BERTweet .", "entities": [[8, 9, "MethodName", "GloVe"]]}, {"text": "Based on the superior performance of BERTweet with respect to GloVe - Twitter , we preferred it for further experimentation and studies .", "entities": [[10, 11, "MethodName", "GloVe"]]}, {"text": "Homogeneous Multitask Learning For this setup , we test the simultaneous optimization of two different tasks - both related to sexual harassment disclosure narratives , with one of them being primary and another coupled as the auxiliary .", "entities": []}, {"text": "The results were obtained for a total of 12pairs .", "entities": []}, {"text": "Heterogeneous Multitask Learning In these sets of experiments , we evaluate the positive transfer of representations across datasets by considering the identi\ufb01cation of narratives associated with sexual abuse disclosure as the primary task and emotion detection as the auxiliary task .", "entities": [[34, 35, "DatasetName", "emotion"]]}, {"text": "5.3 Experimental Setup Preprocessing We pre - process tweet text by ( i ) normalizing user mentions andURLs , and ( ii ) translating the emoticon into text ( Hutto and Gilbert , 2014 ) .", "entities": []}, {"text": "For tokenization , we use Tweet Tokenizer from NLTK.6 6https://www.nltk.org/", "entities": []}, {"text": "4887Hyperparameters For our model7hyperparameters were tuned on the validation set to \ufb01nd the best con\ufb01gurations .", "entities": []}, {"text": "We use a pre - trained BERTweet model to extract 768 - dimensional token - level embeddings .", "entities": []}, {"text": "Grid search was performed to \ufb01nd the optimal value of hyperparameters and their range is summarized as : size of BiLSTM and dense layers f128;256;512 g , embedding size d2 f100;200;300 g , dropout \u000e2", "entities": [[20, 21, "MethodName", "BiLSTM"]]}, {"text": "f0:1;0:2;0:3;0:4;0:5:0:6 g , learning rate \u00152", "entities": [[3, 5, "HyperparameterName", "learning rate"]]}, {"text": "f 10\u00005;10\u00004;10\u00003;10\u00002;10\u00001 g , weight decay!2f10\u00006;10\u00005;10\u00004;10\u00003 g , optimizer fAdam;Adadeltag , batch sizeb2f32;64;128 g and epochs ( < 100 ) .", "entities": [[8, 9, "HyperparameterName", "optimizer"]]}, {"text": "For the MTL experiments , we tune the weightage of the auxiliary task (", "entities": []}, {"text": "2[0:1;0:9]with intervals of 0:1 ) for each task pair .", "entities": []}, {"text": "For each task associated with identifying narratives pertaining to the # MeToo movement in the MTL setup , its value is considered as the one where the model performance improved the most and for both the tasks .", "entities": []}, {"text": "For instance , we \ufb01nd the optimal value of", "entities": []}, {"text": "for hate speech ( as the auxiliary task ) to be0:4 in all Homogeneous task cases and of emotion detection to be 0:2for the Heterogeneous tasks .", "entities": [[1, 3, "DatasetName", "hate speech"], [18, 19, "DatasetName", "emotion"]]}, {"text": "For the MTL experiments , \u000b pand \u000b sare learnable and tuned on the validation loss .", "entities": [[15, 16, "MetricName", "loss"]]}, {"text": "The encoders consist of two stacked BiLSTM \u2019s with hidden size = 128 .", "entities": [[6, 7, "MethodName", "BiLSTM"]]}, {"text": "BiLSTM classi\ufb01er has hidden size = 256 , and the number of units in the penultimate dense layer is128 .", "entities": [[0, 1, "MethodName", "BiLSTM"], [10, 13, "HyperparameterName", "number of units"]]}, {"text": "Dropout is set to 0:3 .", "entities": [[0, 1, "MethodName", "Dropout"]]}, {"text": "For all our experiments , we use Adam optimizer ( Kingma and Ba , 2014 ) and initialize model weights using Xavier initialization ( Glorot and Bengio , 2010 ) .", "entities": [[7, 8, "MethodName", "Adam"], [8, 9, "HyperparameterName", "optimizer"], [21, 23, "MethodName", "Xavier initialization"]]}, {"text": "We set the batch size to 128and the learning rate to 1e\u00003 .", "entities": [[3, 5, "HyperparameterName", "batch size"], [8, 10, "HyperparameterName", "learning rate"]]}, {"text": "Training All models were trained until convergence for both primary andauxiliary tasks .", "entities": []}, {"text": "For our MTL experiments , the training process involves alternating between primary andauxiliary task steps , with each task having its own loss function .", "entities": [[22, 23, "MetricName", "loss"]]}, {"text": "All experiments are run using strati\ufb01ed 5 - fold crossvalidation .", "entities": []}, {"text": "We report the average macro F1 scores across the 5folds to account for imbalance , as previously used in multi - label settings ( Zhang and Zhou , 2013 ) .", "entities": [[4, 6, "MetricName", "macro F1"]]}, {"text": "7We used Keras with Tensor\ufb02ow backend for implementing the models .", "entities": []}, {"text": "Task ST HS SA DI ST 31.80 31.67 32.41 32.20 HS 31.82 31.78 31.64 31.80 SA 49.63 49.69 49.16 49.79 DI 23.54 23.42 23.20 23.41 Table 2 : F1 macro score for pair - wise MTL ( nondiagonal elements ) and STL ( diagonal elements - top left corner to bottom right corner ) .", "entities": [[28, 30, "MetricName", "F1 macro"]]}, {"text": "Rows denote the primary task and columns denote the auxiliary task in case of MTL .", "entities": []}, {"text": "ST = Stance ; HS = Hate Speech ; SA = Sarcasm ; DI = Dialogue .", "entities": [[6, 8, "DatasetName", "Hate Speech"]]}, {"text": "Bold denotes the highest score for that task .", "entities": []}, {"text": "Task Homogeneous Heterogeneous Stance 32.41 \u00060.01 ( SA ) 32.62 \u00060.03 Hate Speech 31.82 \u00060.02 ( ST ) 32.01 \u00060.01", "entities": [[11, 13, "DatasetName", "Hate Speech"]]}, {"text": "Sarcasm 49.79 \u00060.03 ( DI ) 49.50 \u00060.04 Dialogue 23.54 \u00060.03 ( ST ) 23.16 \u00060.06 Table 3 : Best F1 - scores obtained for Homogeneous MTL ( Table 2 ) and Heterogeneous MTL experiments .", "entities": [[20, 21, "MetricName", "F1"]]}, {"text": "Heterogeneous MTL experiments represent multitask learning performed with emotion identi\ufb01cation as the auxiliary task .", "entities": [[8, 9, "DatasetName", "emotion"]]}, {"text": "The best results highlighted in bold .", "entities": []}, {"text": "6 Results and Discussion 6.1 Single Task Learning", "entities": []}, {"text": "The aim of this paper is not limited to achieving the state of the art performance in terms of evaluation metrics but rather to conduct a thorough study to compare and contrast different methodologies for the bene\ufb01t of the research community .", "entities": []}, {"text": "As per our hypothesis and preliminary results on STL experiments on the # MeTooMA dataset , models trained using BERTweet embeddings perform far better than GloVe - Twitter .", "entities": [[12, 14, "DatasetName", "# MeTooMA"], [25, 26, "MethodName", "GloVe"]]}, {"text": "This is largely true because BERTweet is speci\ufb01cally pre - trained on English tweets and is better suited to handle Twitter - speci\ufb01c data , typically having a short length , informal grammar , and irregular vocabulary ( e.g. , abbreviations and typographical errors ) ( Kireyev et al . , 2009 ) .", "entities": []}, {"text": "6.2 Single Task Learning vis - a - vis", "entities": []}, {"text": "Homogeneous Multitask Learning Learning the affective states in the # MeTooMA dataset is challenging due to the inherently subjective nature of the tweets coupled with limitations on the data \u2019s size .", "entities": [[9, 11, "DatasetName", "# MeTooMA"]]}, {"text": "Multitask learning achieves signi\ufb01cant performance gains in terms of macro F1 score , as shown in Table 2 for all task pairs .", "entities": [[9, 11, "MetricName", "macro F1"]]}, {"text": "The diagonal results represented in green denote thebaseline STL results whereas ones highlighted in shades of blue represent results for pair - wise", "entities": []}, {"text": "4888Tweet Text STL Homogeneous MTLHeterogeneous MTL T1 \u2013 [ name ] says that nobody should be ashamed .", "entities": []}, {"text": "Do n\u2019t be scared and let it bury and corrode your soul .", "entities": []}, {"text": "It gives hope through the pain , please visit [ URL ] .", "entities": []}, {"text": "Lets speak up .", "entities": []}, {"text": "# FightBackSupport Support Support T2 \u2013 Saying that # MeToo movement could save lives , would be a grave mistake , those individuals deserve it , such swindling .", "entities": []}, {"text": "This is the proof of a disabled mindset among those guys .", "entities": []}, {"text": "# Resist # RiseUp .", "entities": []}, {"text": "Neither Support Oppose T3 \u2013 When I ran my side production for the movie , people said that only p*nsi*s and h*m*s worked there because I had zero tolerance for sexual harassment in my unit .", "entities": []}, {"text": "This is for all screeching people .", "entities": []}, {"text": "Neither Gen Hate Gen Hate T4 \u2013 Ibelieve that this ideology must be broken !", "entities": []}, {"text": "Society now has created stigma and its time we move forward to a new way of thinking for all girls .", "entities": []}, {"text": "Please spread the word .", "entities": []}, {"text": "# metoo # Healing .", "entities": []}, {"text": "Neither Support Support T5 \u2013 [ name ] says # MeToo is a trap , set by the left wingers .", "entities": [[3, 4, "MethodName", "T5"]]}, {"text": "Do n\u2019t take the bait .", "entities": []}, {"text": "The right should n\u2019t worry least - bit , especially because of the involvement of [ name ] in these circumstances .", "entities": []}, {"text": "# BringTheTruthNeither Refutation Neither T6 \u2013 [ name ] embodies # MeToo movement today , writing and spreading fake messages loud and clear .", "entities": []}, {"text": "Push false narrative and wrong ideology among the youth .", "entities": []}, {"text": "See this [ URL ] .", "entities": []}, {"text": "# Liar # YesAllWomen .", "entities": []}, {"text": "Neither Justi\ufb01cation Neither Table 4 : Qualitative analysis of the performance obtained by MTL architecture on some samples .", "entities": []}, {"text": "The color intensity of each word corresponds to the token - level attention score given by BERTweet .", "entities": []}, {"text": "Green denotes correct prediction and Yellow denotes incorrect prediction .", "entities": []}, {"text": "Tweets have been paraphrased to prevent user identi\ufb01cation .", "entities": []}, {"text": "Homogeneous MTL with row identifying primary task and columns denoting auxiliary task .", "entities": []}, {"text": "The higher performance of Homogeneous MTL can be inferred to be indicative of better generalization when pairs of tasks are jointly modeled .", "entities": []}, {"text": "Interestingly , these tasks show their best performance with the selective counterparts in the Homogeneous MTL setup .", "entities": []}, {"text": "Stance detection is strongly coupled with Sarcasm labeling , and the same is seen to be true for Hate Speech classi\ufb01cation and Stance identi\ufb01cation .", "entities": [[0, 2, "TaskName", "Stance detection"], [18, 20, "DatasetName", "Hate Speech"]]}, {"text": "This selective out - performance of speci\ufb01c pairs of tasks can be attributed to the high correlation between the tasks themselves ( Frenda , 2018 ; Gautam et al . , 2020 ) .", "entities": []}, {"text": "For instance , the offensive text is often strongly coupled with sarcasm , as witis a common linguistic denominator for understanding the intended meaning of phrases related to anger ( Badlani et al . , 2019 ) .", "entities": []}, {"text": "We further detail this through examples in Section 6.4 .", "entities": []}, {"text": "6.3 Heterogeneous Multitask Learning Results in Table 3 demonstrate that the Heterogeneous MTL setup achieves higher performance than Homogeneous MTL under similar settings in two out of four task pairs8 - Stance andHate Speech detection by the margins of +0.21 and+0.19 respectively .", "entities": []}, {"text": "For the other two tasks , the performance of Heterogeneous MTL is very close if not better than Homogeneous MTL .", "entities": []}, {"text": "These \ufb01ndings are in line with the claim supporting the generalizability across tasks in the # MeTooMA dataset , which is 8We show only the best combinations of the Homogeneous task in the table for brevity.highly correlated to emotion recognition .", "entities": [[15, 17, "DatasetName", "# MeTooMA"], [38, 40, "TaskName", "emotion recognition"]]}, {"text": "This is indicative of positive knowledge transfer between the two domains .", "entities": []}, {"text": "Such joint optimization boosts the overall performance of both primary andauxiliary tasks through parameter sharing to learn common representations that may be mutually bene\ufb01cial to both related tasks .", "entities": []}, {"text": "6.4 Qualitative Analysis To emphasize our proposed approach , we perform a qualitative study by handpicking examples from the dataset .", "entities": []}, {"text": "We analyze token - level attention assigned to individual terms by BERTweet , where color intensity corresponds to the attention score .", "entities": []}, {"text": "These results are shown in Table 4 .", "entities": []}, {"text": "We infer that Homogeneous and Heterogeneous multitask learning shows superior performance in every instance compared to STL .", "entities": []}, {"text": "Learning effective features across the joint formulation of pair - wise tasks in Homogeneous MTL is evident from T4 , where BERT \u2019s self - attention allots a higher weight to words such asideology , stigma , and forward in line with the actual label as Support .", "entities": [[21, 22, "MethodName", "BERT"]]}, {"text": "Similarly for T5 , highlighted terms such as trap andbait are indicative of the opposing nature of the tweets , hence identi\ufb01ed as belonging to Refutation .", "entities": [[2, 3, "MethodName", "T5"]]}, {"text": "On the other hand , due to positive knowledge transfer from the emotion recognition task , Heterogeneous MTL obtains better performance in several cases .", "entities": [[12, 14, "TaskName", "emotion recognition"]]}, {"text": "Words such as grave , mistake andswindling inT2connoted a negative emotion , hence accordingly being identi\ufb01ed as belonging to the Oppose category .", "entities": [[10, 11, "DatasetName", "emotion"]]}, {"text": "Similarly , terms such as", "entities": []}, {"text": "4889hope andpain were given higher token - level attention inT1emphasizing a positive emotion and thus can be correlated with belonging to the Support category .", "entities": [[12, 13, "DatasetName", "emotion"]]}, {"text": "An interesting observation is the presence of named entities in T5andT6 , resulting in the incorrect prediction via Heterogeneous MTL .", "entities": []}, {"text": "Therefore , a limitation of the single task learning and Heterogeneous MTL is the inability to mitigate the effect of named entities or speci\ufb01c events in the text to in\ufb02uence the knowledge transfer and create negative shared representations .", "entities": []}, {"text": "7 Ethical Concerns and Discussion Analyzing social media data of individuals discussing sexual harassment disclosures and exploitation in public spheres necessitates the need to safeguard the ethics and privacy of individuals ( Tusinski Berg , 2019 ) .", "entities": []}, {"text": "We address these : Generalization We acknowledge that the limitations of the experiments might get ampli\ufb01ed due to the highly subjective nature of this challenging problem .", "entities": []}, {"text": "Therefore it would not be fair to conduct a population - centric analysis based on inferences from this work .", "entities": []}, {"text": "Con\ufb01dentiality Individual consent was not sought from social media users as the data was publicly available .", "entities": []}, {"text": "Disclosure of sexual harassment information on public forums may have been met with public backlash and apathy .", "entities": []}, {"text": "Therefore the social reputation of the accuser and the accused would be at a peril ( McDonald , 2019 ) .", "entities": []}, {"text": "Hence , the authors were aware not to make any automated interventions , as any attempts to contact individuals could be seen as personally intrusive and might also repeal their social information ( Fiesler and Proferes , 2018 ) .", "entities": []}, {"text": "Bias & Discrimination Social support discussions on social media platforms gave victims the liberty to describe their instances of sexual exploitation and abuse ( Manikonda et al . , 2018a ) .", "entities": []}, {"text": "The authors are aware of the potential inevitable sampling biases that may be present in the data .", "entities": []}, {"text": "Importance has to be placed on mitigating the bias against certain minority groups , which might get ampli\ufb01ed due to the sensitive nature of social discussions ( Hellwig and Sinno , 2017 ) .", "entities": []}, {"text": "8 Conclusion In this work , we have proposed a \ufb02exible crossstitched multitask learning framework for the de - tection of narratives linked with sexual abuse disclosure on social media .", "entities": []}, {"text": "Our methodology takes advantage of the affective features from emotions and related tasks to encourage knowledge transfer and attain auxiliary knowledge .", "entities": []}, {"text": "Qualitative and quantitative results demonstrate how joint optimization of Stance detection and Sarcasm identi\ufb01cation bene\ufb01t each other , indicating their relatedness and dependence on each other .", "entities": [[9, 11, "TaskName", "Stance detection"]]}, {"text": "Similarly , we observe that tasks like Hate - Speech classi\ufb01cation andStance labeling bene\ufb01t from each other and from emotion detection , thus reinforcing the bene\ufb01t of joint linguistic learning between the related tasks .", "entities": [[19, 20, "DatasetName", "emotion"]]}, {"text": "In the future , we aim to explore how this joint learning paradigm can be effectively leveraged for improving performance on downstream tasks like emotion analysis , identifying suicidal tendencies among abuse survivors .", "entities": [[24, 25, "DatasetName", "emotion"]]}, {"text": "Application from this work also has utility for problems such as identi\ufb01cation of patterns of reported sexual harassment narratives , hate speech detection , the spread of rumors and fake news , and entity extraction for digital vigilantism ( Yuce et al . , 2014 ; Hosterman et al . , 2018 ) .", "entities": [[20, 23, "TaskName", "hate speech detection"]]}, {"text": "Acknowledgments Rajiv Ratn Shah is partly supported by the Infosys Center for AI and Center for Design and New Media at IIIT Delhi .", "entities": []}, {"text": "References Md Shad Akhtar , Deepanway Ghosal , Asif Ekbal , Pushpak Bhattacharyya , and Sadao Kurohashi .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A multi - task ensemble framework for emotion , sentiment and intensity prediction .", "entities": [[7, 8, "DatasetName", "emotion"]]}, {"text": "arXiv preprint arXiv:1808.01216 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Maria Anzovino , Elisabetta Fersini , and Paolo Rosso .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Automatic identi\ufb01cation and classi\ufb01cation of misogynistic language on twitter .", "entities": []}, {"text": "In International Conference on Applications of Natural Language to Information Systems , pages 57\u201364 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Isabelle Augenstein , Tim Rockt\u00e4schel , Andreas Vlachos , and Kalina Bontcheva . 2016 .", "entities": []}, {"text": "Stance detection with bidirectional conditional encoding .", "entities": [[0, 2, "TaskName", "Stance detection"]]}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 876\u2013885 , Austin , Texas .", "entities": [[19, 20, "DatasetName", "Texas"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Rohan Badlani , Nishit Asnani , and Manan Rai . 2019 .", "entities": []}, {"text": "Disambiguating sentiment : An ensemble of humour , sarcasm , and hate speech features for sentiment classi\ufb01cation .", "entities": [[11, 13, "DatasetName", "hate speech"]]}, {"text": "W - NUT 2019 , page 337 .", "entities": []}, {"text": "4890David Bamman and Noah A Smith . 2015 .", "entities": []}, {"text": "Contextualized sarcasm detection on twitter .", "entities": [[1, 3, "TaskName", "sarcasm detection"]]}, {"text": "In Ninth International AAAI Conference on Web and Social Media .", "entities": []}, {"text": "Valerio Basile , Cristina Bosco , Elisabetta Fersini , Debora Nozza , Viviana Patti , Francisco Manuel Rangel Pardo , Paolo Rosso , and Manuela Sanguinetti .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "SemEval-2019 task 5 : Multilingual detection of hate speech against immigrants and women in twitter .", "entities": [[7, 9, "DatasetName", "hate speech"]]}, {"text": "In Proceedings of the 13th International Workshop on Semantic Evaluation , pages 54\u201363 , Minneapolis , Minnesota , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Rich Caruana .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Multitask learning .", "entities": []}, {"text": "Machine learning , 28(1):41\u201375 .", "entities": []}, {"text": "Hao Cheng , Hao Fang , and Mari Ostendorf . 2015 .", "entities": []}, {"text": "Open - domain name error detection using a multitask rnn .", "entities": []}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 737\u2013746 .", "entities": []}, {"text": "Arijit Ghosh Chowdhury , Ramit Sawhney , Rajiv Shah , and Debanjan Mahata .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "# youtoo ?", "entities": []}, {"text": "detection of personal recollections of sexual harassment on social media .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 2527\u20132537 .", "entities": []}, {"text": "Rosemary Clark - Parsons .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "\u201c i see you , i believe you , i stand with you \u201d : # metoo and the performance of networked feminist visibility .", "entities": []}, {"text": "Feminist Media Studies , pages 1\u201319 .", "entities": []}, {"text": "Ronan Collobert , Jason Weston , L\u00e9on Bottou , Michael Karlen , Koray Kavukcuoglu , and Pavel Kuksa . 2011 .", "entities": []}, {"text": "Natural language processing ( almost ) from scratch .", "entities": []}, {"text": "Journal of machine learning research , 12(ARTICLE):2493\u20132537 .", "entities": []}, {"text": "Yin Cui , Menglin Jia , Tsung - Yi Lin , Yang Song , and Serge Belongie . 2019 .", "entities": []}, {"text": "Class - balanced loss based on effective number of samples .", "entities": [[3, 4, "MetricName", "loss"], [7, 10, "HyperparameterName", "number of samples"]]}, {"text": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 9268\u20139277 .", "entities": []}, {"text": "Verna Dankers , Marek Rei , Martha Lewis , and Ekaterina Shutova .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Modelling the interplay of metaphor and emotion through multitask learning .", "entities": [[6, 7, "DatasetName", "emotion"]]}, {"text": "InProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 2218 \u2013 2229 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Thanh Vu Dat Quoc Nguyen and Anh Tuan Nguyen .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "BERTweet :", "entities": []}, {"text": "A pre - trained language model for English Tweets .", "entities": []}, {"text": "arXiv preprint , arXiv:2005.10200 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association forComputational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 .", "entities": []}, {"text": "Zhengming Ding , Shao Ming , and Yun Fu . 2014 .", "entities": []}, {"text": "Latent low - rank transfer subspace learning for missing modality recognition .", "entities": []}, {"text": "In Twenty - eighth AAAI conference on arti\ufb01cial intelligence .", "entities": []}, {"text": "Long Duong , Trevor Cohn , Steven Bird , and Paul Cook . 2015 .", "entities": []}, {"text": "Low resource dependency parsing : Crosslingual parameter sharing in a neural network parser .", "entities": [[2, 4, "TaskName", "dependency parsing"]]}, {"text": "InProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Volume 2 : Short Papers ) , pages 845\u2013850 , Beijing , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Long Duong , Hiroshi Kanayama , Tengfei Ma , Steven Bird , and Trevor Cohn . 2016 .", "entities": []}, {"text": "Learning crosslingual word embeddings without bilingual corpora .", "entities": [[2, 4, "TaskName", "word embeddings"]]}, {"text": "arXiv preprint arXiv:1606.09403 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Mai ElSherief , Vivek Kulkarni , Dana Nguyen , William Yang Wang , and Elizabeth Belding .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Hate lingo :", "entities": []}, {"text": "A target - based linguistic analysis of hate speech in social media .", "entities": [[7, 9, "DatasetName", "hate speech"]]}, {"text": "arXiv preprint arXiv:1804.04257 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Casey Fiesler and Nicholas Proferes .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "\u201c participant \u201d perceptions of twitter research ethics .", "entities": []}, {"text": "Social Media+ Society , 4(1):2056305118763366 .", "entities": []}, {"text": "Mary Anne Franks .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Witch hunts : Free speech , # metoo , and the fear of women \u2019s words .", "entities": []}, {"text": "U. Chi .", "entities": []}, {"text": "Legal F .", "entities": []}, {"text": ", page 123 .", "entities": []}, {"text": "Simona Frenda .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "The role of sarcasm in hate speech .", "entities": [[5, 7, "DatasetName", "hate speech"]]}, {"text": "a multilingual perspective .", "entities": []}, {"text": "In e Doctoral Symposium of the XXXIVInternational Conference of the Spanish Society for Natural Language Processing ( SEPLN 2018 ) , pages 13\u201317 .", "entities": []}, {"text": "Lloret , E. ; Saquete , E. ; Mart \u0131nez - Barco , P. ; Moreno , I. Akash Gautam , Puneet Mathur , Rakesh Gosangi , Debanjan Mahata , Ramit Sawhney , and Rajiv Ratn Shah . 2020 .", "entities": []}, {"text": "# metooma : Multi - aspect annotations of tweets related to the metoo movement .", "entities": [[0, 2, "DatasetName", "# metooma"]]}, {"text": "In Proceedings of the International AAAI Conference on Web and Social Media , volume 14 , pages 209\u2013216 .", "entities": []}, {"text": "Xavier Glorot and Y . Bengio .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Understanding the dif\ufb01culty of training deep feedforward neural networks .", "entities": []}, {"text": "Journal of Machine Learning Research - Proceedings Track , 9:249\u2013256 .", "entities": []}, {"text": "Pankaj Gupta , Hinrich Sch\u00fctze , and Bernt Andrassy .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Table \ufb01lling multi - task recurrent neural network for joint entity and relation extraction .", "entities": [[9, 14, "TaskName", "joint entity and relation extraction"]]}, {"text": "In Proceedings of COLING 2016 , the 26th International Conference on Computational Linguistics : Technical Papers , pages 2537\u20132547 .", "entities": []}, {"text": "4891Timothy Hellwig and Abdulkader Sinno .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Different groups , different threats : public attitudes towards immigrants .", "entities": []}, {"text": "Journal of Ethnic and Migration Studies , 43(3):339\u2013358 .", "entities": []}, {"text": "Alec R Hosterman , Naomi R Johnson , Ryan Stouffer , and Steven Herring .", "entities": [[13, 14, "MethodName", "Herring"]]}, {"text": "2018 .", "entities": []}, {"text": "Twitter , social support messages , and the # metoo movement .", "entities": []}, {"text": "The Journal of Social Media in Society , 7(2):69\u201391 .", "entities": []}, {"text": "Chris Hutchings .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Commercial use of facebook and twitter \u2013 risks and rewards .", "entities": []}, {"text": "Computer Fraud & Security , 2012(6):19\u201320 .", "entities": []}, {"text": "Clayton J Hutto and Eric Gilbert .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Vader : A parsimonious rule - based model for sentiment analysis of social media text .", "entities": [[9, 11, "TaskName", "sentiment analysis"]]}, {"text": "In Eighth international AAAI conference on weblogs and social media .", "entities": []}, {"text": "Akshita Jha and Radhika Mamidi .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "When does a compliment become sexist ?", "entities": []}, {"text": "analysis and classi\ufb01cation of ambivalent sexism using twitter data .", "entities": []}, {"text": "In Proceedings of the second workshop on NLP and computational social science , pages 7\u201316 .", "entities": []}, {"text": "Sweta Karlekar and Mohit Bansal .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Safecity : Understanding diverse forms of sexual harassment personal stories .", "entities": []}, {"text": "arXiv preprint arXiv:1809.04739 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Diederik Kingma and Jimmy Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "International Conference on Learning Representations .", "entities": []}, {"text": "Kirill Kireyev , Leysia Palen , and Kenneth Anderson .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Applications of topics models to analysis of disaster - related twitter data .", "entities": []}, {"text": "In NIPS workshop on applications for topic models : text and beyond , volume 1 .", "entities": [[6, 8, "TaskName", "topic models"]]}, {"text": "Canada : Whistler .", "entities": []}, {"text": "Linda Lane and Ulla - Carin Hedin . 2020 .", "entities": []}, {"text": "The promise of the # metoo movement for preventing and reporting sexual harassment .", "entities": []}, {"text": "Available at SSRN .", "entities": []}, {"text": "Janie Leatherman .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Sexual violence and armed con\ufb02ict .", "entities": []}, {"text": "Polity .", "entities": []}, {"text": "Pengfei Liu , Xipeng Qiu , and Xuanjing Huang . 2016 .", "entities": []}, {"text": "Recurrent neural network for text classi\ufb01cation with multi - task learning .", "entities": [[7, 11, "TaskName", "multi - task learning"]]}, {"text": "arXiv preprint arXiv:1605.05101 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Pengfei Liu , Xipeng Qiu , and Xuanjing Huang . 2017 .", "entities": []}, {"text": "Adversarial multi - task learning for text classi\ufb01cation .", "entities": [[1, 5, "TaskName", "multi - task learning"]]}, {"text": "arXiv preprint arXiv:1704.05742 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Yinhan Liu , Myle Ott , Naman Goyal , Jingfei Du , Mandar Joshi , Danqi Chen , Omer Levy , Mike Lewis , Luke Zettlemoyer , and Veselin Stoyanov .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Roberta : A robustly optimized bert pretraining approach .", "entities": []}, {"text": "Minh - Thang Luong , Quoc V Le , Ilya Sutskever , Oriol Vinyals , and Lukasz Kaiser .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Multi - task sequence to sequence learning .", "entities": [[3, 6, "MethodName", "sequence to sequence"]]}, {"text": "arXiv preprint arXiv:1511.06114 .Lydia", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Manikonda , Ghazaleh Beigi , Subbarao Kambhampati , and Huan Liu . 2018a .", "entities": []}, {"text": "# metoo through the lens of social media .", "entities": []}, {"text": "In International conference on social computing , behavioral - cultural modeling and prediction and behavior representation in modeling and simulation , pages 104\u2013110 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Lydia Manikonda , Ghazaleh Beigi , Huan Liu , and Subbarao Kambhampati .", "entities": []}, {"text": "2018b .", "entities": []}, {"text": "Twitter for sparking a movement , reddit for sharing the moment : # metoo through the lens of social media .", "entities": [[6, 7, "DatasetName", "reddit"]]}, {"text": "arXiv preprint arXiv:1803.08022 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Tolba Marwa , Ouadfel Salima , and Meshoul Souham .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Deep learning for online harassment detection in tweets .", "entities": []}, {"text": "In 2018 3rd International Conference on Pattern Analysis and Intelligent Systems ( PAIS ) , pages 1\u20135 .", "entities": []}, {"text": "IEEE .", "entities": []}, {"text": "Aubri F McDonald .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Framing # metoo : Assessing the power and unintended consequences of a social media movement to address sexual assault .", "entities": []}, {"text": "In Handbook of Sexual Assault and Sexual Assault Prevention , pages 79\u2013107 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Brad McKenna and Hameed Chughtai .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Resistance and sexuality in virtual worlds : An lgbt perspective .", "entities": []}, {"text": "Computers in Human Behavior , 105:106199 .", "entities": []}, {"text": "Saif Mohammad , Felipe Bravo - Marquez , Mohammad Salameh , and Svetlana Kiritchenko .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Semeval2018 task 1 : Affect in tweets .", "entities": []}, {"text": "In Proceedings of the 12th international workshop on semantic evaluation , pages 1\u201317 .", "entities": []}, {"text": "Saif M. Mohammad and Peter D. Turney .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Crowdsourcing a word - emotion association lexicon .", "entities": [[4, 5, "DatasetName", "emotion"]]}, {"text": "29(3):436\u2013465 .", "entities": []}, {"text": "Pulkit Parikh , Harika Abburi , Pinkesh Badjatiya , Radhika Krishnan , Niyati Chhaya , Manish Gupta , and Vasudeva Varma . 2019 .", "entities": []}, {"text": "Multi - label categorization of accounts of sexism using a neural framework .", "entities": []}, {"text": "arXiv preprint arXiv:1910.04602 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jeffrey Pennington , Richard Socher , and Christopher Manning .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "GloVe : Global vectors for word representation .", "entities": [[0, 1, "MethodName", "GloVe"]]}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1532\u20131543 , Doha , Qatar .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Santhosh Rajamanickam , Pushkar Mishra , Helen Yannakoudakis , and Ekaterina Shutova .", "entities": [[6, 7, "DatasetName", "Helen"]]}, {"text": "2020 .", "entities": []}, {"text": "Joint modelling of emotion and abusive language detection .", "entities": [[3, 4, "DatasetName", "emotion"], [5, 7, "TaskName", "abusive language"]]}, {"text": "arXiv preprint arXiv:2005.14028 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Mannila Sandhu , C Danielle Vinson , Vijay K Mago , and Philippe J Giabbanelli .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "From associations to sarcasm : Mining the shift of opinions regarding the supreme court on twitter .", "entities": []}, {"text": "Online Social Networks and Media , 14:100054 .", "entities": []}, {"text": "4892Ramit Sawhney , Akash Kumar Gautam , and Rajiv Ratn Shah . 2020 .", "entities": [[4, 5, "DatasetName", "Kumar"]]}, {"text": "Bmgc 2020 grand challenge : Multiaspect analysis of the metoo movement on twitter .", "entities": []}, {"text": "In 2020 IEEE Sixth International Conference on Multimedia Big Data ( BigMM ) , pages 481\u2013484 .", "entities": []}, {"text": "IEEE .", "entities": []}, {"text": "Sima Shari\ufb01rad , Borna Jafarpour , and Stan Matwin .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Boosting text classi\ufb01cation performance on sexist tweets by text augmentation and text generation using a combination of knowledge graphs .", "entities": [[11, 13, "TaskName", "text generation"], [17, 19, "TaskName", "knowledge graphs"]]}, {"text": "In Proceedings of the 2nd workshop on abusive language online ( ALW2 ) , pages 107\u2013114 .", "entities": [[7, 9, "TaskName", "abusive language"]]}, {"text": "Ashwini Tambe .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Reckoning with the silences of # metoo .", "entities": []}, {"text": "Feminist Studies , 44(1):197\u2013203 .", "entities": []}, {"text": "Ben Tan , Erheng Zhong , Evan Wei Xiang , and Qiang Yang .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Multi - transfer : Transfer learning with multiple views and multiple sources .", "entities": [[4, 6, "TaskName", "Transfer learning"]]}, {"text": "In Proceedings of the 2013 SIAM International Conference on Data Mining , pages 243\u2013251 .", "entities": []}, {"text": "SIAM .", "entities": []}, {"text": "Kati Tusinski Berg .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The ethics of exploring gender issues in a time of # metoo .", "entities": []}, {"text": "Journal of Media Ethics , 34(1):52\u201356 .", "entities": [[3, 4, "DatasetName", "Ethics"]]}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N. Gomez , unde\ufb01nedukasz Kaiser , and Illia Polosukhin .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Proceedings of the 31st International Conference on Neural Information Processing Systems , NIPS\u201917 , page 6000\u20136010 , Red Hook , NY , USA .", "entities": []}, {"text": "Curran Associates Inc.", "entities": []}, {"text": "Christine Wekerle , Negar Vakili , Sherry H Stewart , and Tara Black .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "The utility of twitter as a tool for increasing reach of research on sexual violence .", "entities": []}, {"text": "Child abuse & neglect , 85:220\u2013228 .", "entities": []}, {"text": "Yongxin Yang and Timothy M. Hospedales .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Trace norm regularised deep multi - task learning .", "entities": [[4, 8, "TaskName", "multi - task learning"]]}, {"text": "Serpil T Yuce , Nitin Agarwal , Rolf T Wigand , Merlyna Lim , and Rebecca S Robinson .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Bridging women rights networks : Analyzing interconnected online collective actions .", "entities": []}, {"text": "Journal of Global Information Management ( JGIM ) , 22(4):1\u201320 .", "entities": [[4, 5, "TaskName", "Management"]]}, {"text": "Min - Ling Zhang and Zhi - Hua Zhou .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "A review on multi - label learning algorithms .", "entities": [[3, 7, "TaskName", "multi - label learning"]]}, {"text": "IEEE transactions on knowledge and data engineering , 26(8):1819\u20131837 .", "entities": []}, {"text": "Xiaodong Zhang and Houfeng Wang .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "A joint model of intent determination and slot \ufb01lling for spoken language understanding .", "entities": [[10, 13, "TaskName", "spoken language understanding"]]}, {"text": "In IJCAI , volume 16 , pages 2993\u20132999 .", "entities": []}, {"text": "Yuxiang Zhang , Jiamei Fu , Dongyu She , Ying Zhang , Senzhang Wang , and Jufeng Yang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Text emotion distribution learning via multi - task convolutional neural network .", "entities": [[1, 2, "DatasetName", "emotion"]]}, {"text": "In IJCAI , pages 4595\u20134601 .", "entities": []}]