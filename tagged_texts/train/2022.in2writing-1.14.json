[{"text": "Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants ( In2Writing 2022 ) , pages 96 - 108 May 26 , 2022 \u00a9 2022 Association for Computational Linguistics Read , Revise , Repeat : A System Demonstration for Human - in - the - loop Iterative Text Revision Wanyu Du1\u2217 , Zae Myung Kim2 * , Vipul Raheja3 , Dhruv Kumar3 , Dongyeop Kang2 1University of Virginia,2University of Minnesota,3Grammarly wd5jq@virginia.edu , { kim01756,dongyeop}@umn.edu { vipul.raheja,dhruv.kumar}@grammarly.com Abstract Revision is an essential part of the human writing process .", "entities": []}, {"text": "It tends to be strategic , adaptive , and , more importantly , iterative in nature .", "entities": []}, {"text": "Despite the success of large language models on text revision tasks , they are limited to non - iterative , one - shot revisions .", "entities": []}, {"text": "Examining and evaluating the capability of large language models for making continuous revisions and collaborating with human writers is a critical step towards building effective writing assistants .", "entities": []}, {"text": "In this work , we present a human - inthe - loop iterative text revision system , Read , Revise , Repeat ( R3 ) , which aims at achieving high quality text revisions with minimal human efforts by reading model - generated revisions and user feedbacks , revising documents , and repeating human - machine interactions .", "entities": []}, {"text": "In R3 , a text revision model provides text editing suggestions for human writers , who can accept or reject the suggested edits .", "entities": []}, {"text": "The accepted edits are then incorporated into the model for the next iteration of document revision .", "entities": []}, {"text": "Writers can therefore revise documents iteratively by interacting with the system and simply accepting / rejecting its suggested edits until the text revision model stops making further revisions or reaches a prede\ufb01ned maximum number of revisions .", "entities": []}, {"text": "Empirical experiments show thatR3can generate revisions with comparable acceptance rate to human writers at early revision depths , and the human - machine interaction can get higher quality revisions with fewer iterations and edits .", "entities": []}, {"text": "The collected human - model interaction dataset and system code are available at https://github . com / vipulraheja / IteraTeR .", "entities": [[5, 7, "DatasetName", "interaction dataset"]]}, {"text": "Our system demonstration is available at https:// youtu.be/lK08tIpEoaE .", "entities": []}, {"text": "1 Introduction Text revision is a crucial part of writing .", "entities": []}, {"text": "Speci\ufb01cally , text revision involves identifying discrepan\u2217Equal contributions .", "entities": []}, {"text": "Source Doc   Dt-1 \u211b3 :", "entities": []}, {"text": "Text Revision   System   Source Doc Source Doc Edit   Suggestions   Revised Doc", "entities": []}, {"text": "Dt Final   Revised Doc   DfinalStop   Revision Accept   Edits   Review \u2705    \u274c", "entities": []}, {"text": "Yes Not+1User Figure 1 : System overview for R3human - in - the - loop iterative text revision .", "entities": []}, {"text": "cies between intended and instantiated text , deciding what edits to make , and how to make those desired edits ( Flower and Hayes , 1981 ; Faigley and Witte , 1981 ; Fitzgerald , 1987 ) .", "entities": []}, {"text": "It enables writers to deliberate over and organize their thoughts , \ufb01nd a better line of argument , learn afresh , and discover what was not known before ( Sommers , 1980 ; Scardamalia , 1986 ) .", "entities": []}, {"text": "Previous studies ( Flower , 1980 ; Collins and Gentner , 1980 ; Vaughan and McDonald , 1986 ) have shown that text revision is an iterative process since human writers are unable to simultaneously comprehend multiple demands and constraints of the task when producing well - written texts \u2013 for instance , covering the content , following linguistic norms and discourse conventions of written prose , etc .", "entities": []}, {"text": "Therefore , writers resort to performing text revisions on their drafts iteratively to96", "entities": []}, {"text": "reduce the number of considerations at each time .", "entities": []}, {"text": "Computational modeling of the iterative text revision process is essential for building intelligent and interactive writing assistants .", "entities": []}, {"text": "Most prior works on the development of neural text revision systems ( Faruqui et al . , 2018 ; Botha et al . , 2018 ; Ito et al . , 2019 ;", "entities": []}, {"text": "Faltings et al . , 2021 ) do not take the iterative nature of text revision and human feedback on suggested revisions into consideration .", "entities": []}, {"text": "The direct application of such revision systems in an iterative way , however , could generate some \u201c noisy \u201d edits and require much burden on human writers to \ufb01x the noise .", "entities": []}, {"text": "Therefore , we propose to collect human feedback at each iteration of revision to \ufb01lter out those harmful noisy edits and produce revised documents of higher quality .", "entities": []}, {"text": "In this work , we present a novel human - in - theloop iterative text revision system , Read , Revise , Repeat ( R3 ) , which reads model - generated revisions and user feedbacks , revises documents , and repeats human - machine interactions in an iterative way , as depicted in Figure 1 .", "entities": []}, {"text": "First , users write a document as input to the system or choose one from a candidate document set to edit .", "entities": []}, {"text": "Then , the text revision system provides multiple editing suggestions with their edits and intents .", "entities": []}, {"text": "Users can accept or reject the editing suggestions in an iterative way and stop revision when no editing suggestions are provided or the model reaches the maximum revision limit .", "entities": []}, {"text": "The overall model performance can be estimated by calculating the acceptance rate throughout all editing suggestions .", "entities": []}, {"text": "R3provides numerous bene\ufb01ts over existing writing assistants for text revision .", "entities": []}, {"text": "First , R3improves the overall writing experience for writers by making it more interpretable , controllable , and productive : on the one hand , writers do n\u2019t have to ( re-)read the parts of the text that are already high quality , and this , in turn , helps them focus on larger writing goals ( \u00a7 4.2 ) ; on the other hand , by showing edit intentions for every suggested edit , which users can further decide to accept or reject , R3provides them with more \ufb01ne - grained control over the text revision process compared to other one - shot based text revision systems ( Lee et al . , 2022 ) , and are limited in both interpretability and controllability .", "entities": []}, {"text": "Second , R3improves the revision ef\ufb01ciency .", "entities": []}, {"text": "The human - machine interaction can help the system produce higher quality revisions with fewer iterations and edits , and the empirical experiments in \u00a7 4.2 validate this claim .", "entities": []}, {"text": "To thebest of our knowledge , R3is the \ufb01rst text revision system in literature that can perform iterative text revision in collaboration by human writers and revision models .", "entities": []}, {"text": "In this paper , we make three major contributions : \u2022We present a novel human - in - the - loop text revision systemR3to make text revision models more accessible ; and to make the process of iterative text revision ef\ufb01cient , productive , and cognitively less challenging .", "entities": []}, {"text": "\u2022From an HCI perspective , we conduct experiments to measure the effectiveness of the proposed system for the iterative text revision task .", "entities": []}, {"text": "Empirical experiments show that R3can generate edits with comparable acceptance rate to human writers at early revision depths .", "entities": []}, {"text": "\u2022We analyze the data collected from humanmodel interactions for text revision and provide insights and future directions for building high - quality and ef\ufb01cient human - in - the - loop text revision systems .", "entities": []}, {"text": "We release our code , revision interface , and collected human - model interaction dataset to promote future research on collaborative text revision .", "entities": [[13, 15, "DatasetName", "interaction dataset"]]}, {"text": "2 Related Work Previous works on modeling text revision ( Faruqui et al . , 2018 ; Botha et al . , 2018 ;", "entities": []}, {"text": "Ito et al . , 2019 ; Faltings et al . , 2021 ) have ignored the iterative nature of the task , and simpli\ufb01ed it into a one - shot \" original - to-\ufb01nal \" sentence - to - sentence generation task .", "entities": []}, {"text": "However , in practice , at every revision step , multiple edits happen at the document - level which also play an important role in text revision .", "entities": []}, {"text": "For instance , reordering and deleting sentences to improve the coherence .", "entities": []}, {"text": "More importantly , performing multiple highquality edits at once is very challenging .", "entities": []}, {"text": "Continuing the previous example , document readability can degrade after reordering sentences , and further adding transitional phrases is often required to make the document more coherent and readable .", "entities": []}, {"text": "Therefore , one - shot sentence - to - sentence text revision formulation is not suf\ufb01cient to deal with real - world challenges in text revision tasks .", "entities": []}, {"text": "While some prior works on text revision ( Coenen et al . , 2021 ; Padmakumar and He , 2021 ; Gero et al . , 2021 ; Lee et al . , 2022 ) have proposed humanmachine collaborative writing interfaces , they are97", "entities": []}, {"text": "mostly focused on collecting human - machine interaction data for training better neural models , rather than understanding the iterative nature of the text revision process , or the model \u2019s ability to adjust editing suggestions according to human feedback .", "entities": []}, {"text": "Another line of work by Sun et al . ( 2021 ) ; Singh et al . ( 2022 ) on creative writing designed humanmachine interaction interfaces to encourage new content generation .", "entities": []}, {"text": "However , text revision focuses on improving the quality of existing writing and keeping the original content as much as possible .", "entities": []}, {"text": "In this work , we provide a human - in - the - loop text revision system to make helpful editing suggestions by interacting with users in an iterative way .", "entities": []}, {"text": "3 System Overview Figure 1 shows the general pipeline of R3humanin - the - loop iterative text revision system .", "entities": []}, {"text": "In this section , we will describe the development details of the text revision models and demonstrate our user interfaces .", "entities": []}, {"text": "We \ufb01rst formulate an iterative text revision process : given a source document1Dt\u22121 , at each revision depth t , a text revision system will apply a set of edits to get the revised document", "entities": []}, {"text": "Dt .", "entities": []}, {"text": "The system will continue iterating revision until the revised documentDtsatis\ufb01es a set of prede\ufb01ned stopping criteria , such as reaching a prede\ufb01ned maximum revision depth tmax , or making no edits between Dt\u22121andDt .", "entities": []}, {"text": "3.1 Text Revision System We follow the prior work of Du et al .", "entities": []}, {"text": "( 2022 ) to build our text revision system .", "entities": []}, {"text": "The system is composed of edit intention identi\ufb01cation models and a text revision generation model .", "entities": []}, {"text": "We follow the same data collection procedure in Du et al .", "entities": []}, {"text": "( 2022 ) to collect the iterative revision data.2Then , we train the three models on the collected revision dataset .", "entities": []}, {"text": "Edit Intention Identi\ufb01cation Models .", "entities": []}, {"text": "Following Du et al .", "entities": []}, {"text": "( 2022 ) , our edit intentions have four categories : FLUENCY , COHERENCE , CLARITY , and STYLE .", "entities": []}, {"text": "We build our edit intention identi\ufb01cation models at each sentence of the source documentDt\u22121to capture the more \ufb01ne - grained edits .", "entities": []}, {"text": "Speci\ufb01cally , given a source sentence , the system will make two - step predictions : ( 1 ) whether 1The source document can be chosen by a user in the candidate set of documents or written from scratch by a user .", "entities": []}, {"text": "2See", "entities": []}, {"text": "\u00a7 4.1 for the detailed data collection.or not to edit , and ( 2 ) which edit intention to apply .", "entities": []}, {"text": "The decision whether or not to edit is taken by an edit - prediction classi\ufb01er that predicts a binary label of whether to edit a sentence or not .", "entities": []}, {"text": "The second model , called the edit - intention classi\ufb01er , predicts which edit intention to apply to the sentence .", "entities": []}, {"text": "If the edit - prediction model predicts \u201c not to edit \u201d in the \ufb01rst step , the source sentence will be kept unchanged at the current revision depth .", "entities": []}, {"text": "Text Revision Generation Model .", "entities": []}, {"text": "We \ufb01ne - tune a large pre - trained language model like PEGASUS(Zhang et al . , 2020 ) on our collected revision dataset to build the text revision generation model .", "entities": []}, {"text": "Given a source sentence and its predicted edit intention , the model will generate a revised sentence , conditioned on the predicted edit intention .", "entities": []}, {"text": "Then , we concatenate all un - revised and revised sentences to get the model - revised document Dt , and extract all its edits using latexdiff3anddif\ufb02ib .4", "entities": []}, {"text": "In summary , at each revision depth t , given a source documentDt\u22121 , the text revision system \ufb01rst predicts the need for revising a sentence , and for the ones that need revision , it predicts the corresponding \ufb01ne - grained edit intentions \u2013 thus , generating the revised document Dtbased on the source document and the predicted edit decisions and intentions .", "entities": []}, {"text": "3.2 Human - in - the - loop Revision In practice , not all model - generated edits are equally impactful towards improving the document quality ( Du et al . , 2022 ) .", "entities": []}, {"text": "Therefore , we enable user interaction in the iterative text revision process to achieve high quality of text revisions along with a productive writing experience .", "entities": []}, {"text": "At each revision depth t , our system provides the user with suggested edits , and their corresponding edit intentions .", "entities": []}, {"text": "The user can interact with the system by choosing to accept or reject the suggested edits .", "entities": []}, {"text": "Figure 2 illustrates the details of R3 \u2019s user interface .", "entities": []}, {"text": "First , a user enters their i d to login to the web interface as shown in Figure 2a .", "entities": []}, {"text": "Then , the user is instructed with a few guidelines on how to operate the revision as demonstrated in Figure 2b .", "entities": []}, {"text": "After getting familiar with the interface , the user can select a source document from the left dropdown menu in Figure 2c .", "entities": []}, {"text": "By clicking the source document , all the edits predicted by the text re3https://ctan.org/pkg/latexdiff 4https://docs.python.org/3/library/", "entities": []}, {"text": "difflib.html98", "entities": []}, {"text": "( a ) Login   ( b ) Read guidelines   ( c )", "entities": []}, {"text": "Select doc Interaction   panel   Editing   suggestions   Edit Intentions   (", "entities": []}, {"text": "d ) Editing suggestions and interaction panel Figure 2 : User interface demonstration for R3 .", "entities": []}, {"text": "Anonymized version available at https://youtu.be/ lK08tIpEoaE .", "entities": []}, {"text": "vision model , as well as their corresponding edit intentions will show up in the main page as illustrated in Figure 2d ( left panel ) .", "entities": []}, {"text": "The user is guided to go through each suggested edits , and choose to accept or reject the current edit by clicking the Con\ufb01rmbutton in Figure 2d ( right panel ) .", "entities": []}, {"text": "After going through all the suggested edits , the user is guided to click the Submit button to save their decisions on the edits .", "entities": []}, {"text": "Then , the user is guided to click the Next Iteration !", "entities": []}, {"text": "button to proceed to the next revision depth and check the next round of edits suggested by the system .", "entities": []}, {"text": "This interactive process continues until the system does not generate further edits or reaches the maximum revision depth tmax.4 Experiments We conduct experiments to answer the following research questions : RQ1 How likely are users to accept the editing suggestions predicted by our text revision system ?", "entities": []}, {"text": "This question is designed to evaluate whether our text revision system can generate high quality edits .", "entities": []}, {"text": "RQ2 Which types of edit intentions are more likely to be accepted by users ?", "entities": []}, {"text": "This question is aimed to identify which types of edits are more favored by users .", "entities": []}, {"text": "RQ3 Does user feedback in R3help produce higher quality of revised documents ?", "entities": []}, {"text": "This question is proposed to validate the effectiveness of human - in - the - loop component in R3.99", "entities": []}, {"text": "4.1 Experimental Setups Iterative Revision Systems .", "entities": []}, {"text": "We prepare three types of iterative revision systems to answer the above questions :", "entities": []}, {"text": "1.HUMAN -HUMAN : We ask users to accept or reject text revisions made by human writers , which are directly sampled from our collected iterative revision dataset .", "entities": []}, {"text": "This serves as the baseline to measure the gap between our text revision system and human writers .", "entities": []}, {"text": "2.SYSTEM", "entities": []}, {"text": "-HUMAN : We ask users to accept or reject text revisions made by our system .", "entities": []}, {"text": "Then , we incorporate user accepted edits to the system to generate the next iteration of revision .", "entities": []}, {"text": "This is the standard human - in - the - loop process of R3 .", "entities": []}, {"text": "3.SYSTEM -ONLY : We conduct an ablation study by removing user interaction in reviewing the model - generated edits .", "entities": []}, {"text": "Then , we compare the overall quality of \ufb01nal revised documents with and without the human - in - the - loop component .", "entities": []}, {"text": "In both HUMAN -HUMAN andSYSTEM -HUMAN setups where users interacted with the system , they were not informed whether the revisions were sampled from our collected iterative revision dataset , or generated by the underlying text revision models .", "entities": []}, {"text": "User Study Design .", "entities": []}, {"text": "We hired three linguistic experts ( English L1 , bachelor \u2019s or higher degree in Linguistics ) to interact with our text revision system .", "entities": []}, {"text": "Each user was presented with a text revision ( as shown in Figure 2d ) and asked to accept or reject each edit in the current revision ( users were informed which revision depth they were looking at ) .", "entities": []}, {"text": "For a fair comparison , users were not informed about the source of the edits ( human - written vs. model - generated ) , and the experiments were conducted separately one after the other .", "entities": []}, {"text": "Note that the users were only asked to accept or reject edits , and they had control neither over the number of iterations , nor over the stopping criteria .", "entities": [[20, 23, "HyperparameterName", "number of iterations"]]}, {"text": "The stopping criteria for the experiment were set by us and designed as : ( 1 ) no new edits were made at the following revision depth , or ( 2 ) the maximum revision depth tmax = 3was reached .", "entities": []}, {"text": "Data Details .", "entities": []}, {"text": "We followed the prior work ( Du et al . , 2022 ) to collect the text revision data across three domains : ArXiv , Wikipedia and Wikinews .", "entities": [[23, 24, "DatasetName", "ArXiv"]]}, {"text": "This data was then used to train both the edit intention identi\ufb01cation models and the text revision generation model .", "entities": []}, {"text": "We split the data into training , validation and test set according to their document # Docs Avg .", "entities": []}, {"text": "Depths # Edits Training 44,270 6.63 292,929 Validation 5,152 6.60 34,026 Test 6,226 6.34 39,511 Table 1 : Statistics for our collected revision data which has been used to train the edit intention identi\ufb01cation model and the text revision generation model .", "entities": []}, {"text": "# Docs means the total number of unique documents , Avg . Depths indicates the average revision depth per document ( for the human - generated training data ) , and # Editsstands for the total number of edits ( sentence pairs ) across the corpus .", "entities": []}, {"text": "ids with a ratio of 8:1:1 .", "entities": []}, {"text": "The detailed data statistics are included in Table 1 .", "entities": []}, {"text": "Note that our newly collected revision dataset is larger than the previously proposed dataset in Du et al .", "entities": []}, {"text": "( 2022 ) with around 24 K more unique documents and 170 K more edits ( sentence pairs ) .", "entities": []}, {"text": "For the human evaluation data , we randomly sampled 10 documents with a maximum revision depth of 3 from each domain in the test set in Table 1 .", "entities": []}, {"text": "For the evaluation of text revisions made by human writers ( HUMAN -HUMAN ) , we presented the existing ground - truth references from our collected dataset to users .", "entities": []}, {"text": "Since we do not hire additional human writers to perform continuous revisions , we just presented the static human revisions from the original test set to users at each revision depth , and collected the user acceptance statistics as a baseline for our system .", "entities": []}, {"text": "For the evaluation of text revisions made by our system ( SYSTEM -HUMAN ) , we only presented the original source document at the initial revision depth ( D0 ) to our system , and let the system generate edits in the following revision depths , while incorporating the accept / reject decisions on modelgenerated edit suggestions by the users .", "entities": []}, {"text": "Note that at each revision depth , the system will only incorporate the edits accepted by users and pass them to the next revision iteration .", "entities": []}, {"text": "For text revisions made by our system without human - in - the - loop ( SYSTEM -ONLY ) , we let the system generate edits in an iterative way and accepted all model - generated edits at each revision depth .", "entities": []}, {"text": "Model Details .", "entities": []}, {"text": "For both edit intention identi\ufb01cation models , we \ufb01ne - tuned the RoBERTa - large ( Liu et al . , 2020 ) pre - trained checkpoint from HuggingFace ( Wolf et al . , 2020 ) for 2 epochs with a learning rate of 1\u00d710\u22125and batch size of 16 .", "entities": [[12, 13, "MethodName", "RoBERTa"], [42, 44, "HyperparameterName", "learning rate"], [46, 48, "HyperparameterName", "batch size"]]}, {"text": "The edit-100", "entities": []}, {"text": "HUMAN -HUMAN SYSTEM -HUMAN ( ours ) t # Docs Avg .", "entities": []}, {"text": "Edits Avg .", "entities": []}, {"text": "Accepts % Accepts # Docs Avg .", "entities": []}, {"text": "Edits Avg .", "entities": []}, {"text": "Accepts % Accepts 1 30 5.37 2.77 51.66 30 5.90 2.90 49.15 2 30 4.83 3.00 62.06 24 3.83 2.57 67.02 3 20 3.80 2.67 70.39 20 3.43 1.94 56.71 Table 2 : Human - in - the - loop iterative text revision evaluation results .", "entities": []}, {"text": "tstands for the revision depth , # Docs shows the total number of revised documents at the current revision depth , Avg . Edits indicates the average number of applied edits per document , Avg . Accepts means the average number of edits accepted by users per document , and % Accepts is calculated by dividing the total accepted edits with the total applied edits .", "entities": []}, {"text": "prediction classi\ufb01er is binary classi\ufb01cation model that predicts whether to edit a given sentence or not .", "entities": []}, {"text": "It achieves an F1 score of 67.33 for the edit label and 79.67 for the not - edit label .", "entities": [[3, 5, "MetricName", "F1 score"]]}, {"text": "The edit - intention classi\ufb01er predicts the speci\ufb01c intent for a sentence that requires editing .", "entities": []}, {"text": "It achieves F1 scores of 67.14 , 70.27 , 57.0 , and 3.215for CLARITY , FLUENCY , COHERENCE and STYLE intent labels respectively .", "entities": [[2, 3, "MetricName", "F1"]]}, {"text": "For the text revision generation model , we \ufb01netuned the PEGASUS -LARGE ( Zhang et al . , 2020 ) pre - trained checkpoint from HuggingFace .", "entities": []}, {"text": "We set the edit intentions as new special tokens ( e.g. , < STYLE > , < FLUENCY > ) , and concatenated the edit intention and source sentence together as the input to the model .", "entities": []}, {"text": "The output of the model is the revised sentence , and we trained the model with cross - entropy loss .", "entities": [[19, 20, "MetricName", "loss"]]}, {"text": "We \ufb01ne - tuned the model for 5 epochs with a learning rate of 3\u00d710\u22125and batch size of 4 .", "entities": [[11, 13, "HyperparameterName", "learning rate"], [15, 17, "HyperparameterName", "batch size"]]}, {"text": "Finally , our text revision generation model achieves 41.78 SARI score ( Xu et al . , 2016 ) , 81.11 BLEU score ( Papineni et al . , 2002 ) and 89.08 ROUGE - L score ( Lin , 2004 ) on the test set .", "entities": [[21, 23, "MetricName", "BLEU score"], [33, 36, "MetricName", "ROUGE - L"]]}, {"text": "4.2 Result Analysis Iterativeness .", "entities": []}, {"text": "The human - in - the - loop iterative text revision evaluation results are reported in Table 2 .", "entities": []}, {"text": "Each document is evaluated by at least 2 users .", "entities": []}, {"text": "We \ufb01nd thatR3achieves comparable performances with ground - truth human revisions at revision depth 1 and 2 , and tends to generate less favorable edits at revision depth 3 .", "entities": []}, {"text": "At revision depth 1,R3is able to generate more edits than ground - truth human edits for each document , and gets more edits accepted by users on average .", "entities": []}, {"text": "This shows the potential of R3 in generating appropriate text revisions that are more favorable to users .", "entities": []}, {"text": "At revision depth 2 , while R3generates less edits than human writers on average , it gets a higher 5We note that the F1 score for STYLE is low as the number of training samples for that intent is particularly small.acceptance rate than human writers .", "entities": [[23, 25, "MetricName", "F1 score"]]}, {"text": "This result suggests that for the end users , more edits may not necessarily lead to a higher acceptance ratio , and shows thatR3is able to make high - quality edits for effective iterative text revisions .", "entities": []}, {"text": "At revision depth 3,R3generates even less edits compared both to human writers and its previous revision depths .", "entities": []}, {"text": "This result can be attributed to the fact that our models are only trained on static human revision data , while at testing time they have to make predictions conditioned on their revisions generated at the previous depth , which may have a very different distribution of edits than the training data .", "entities": []}, {"text": "Table 7 shows an example of iterative text revision in ArXiv domain generated by R3 .", "entities": [[10, 11, "DatasetName", "ArXiv"]]}, {"text": "We also provide some other iterative revision examples generated byR3 in Appendix A. Edit Intentions .", "entities": []}, {"text": "Table 3 demonstrates the distribution of different edit intentions , which can help us further analyze the which type of edits are more likely to be accepted by end users .", "entities": []}, {"text": "For humangenerated revisions , we \ufb01nd that FLUENCY edits are most likely to be accepted since they are mainly \ufb01xing grammatical errors .", "entities": []}, {"text": "For system - generated revisions , we observe that C LARITY edits are the most frequent edits but end users only accept 58.73 % of them , which suggests that our system needs further improvements in learning CLARITY edits .", "entities": []}, {"text": "Another interesting observation is that STYLE edits are rarely generated by human writers ( 1.2 % ) and also gets the lowest acceptance rate ( 33.33 % ) than other intentions , while they are frequently generated by our system ( 16.7 % ) and surprisingly gets the highest acceptance rate ( 64.6 % ) than other intentions .", "entities": []}, {"text": "This observation indicates that R3is capable for generating favorable stylistic edits .", "entities": []}, {"text": "Table 4 shows some examples of edit suggestions generated by R3 .", "entities": []}, {"text": "Role of Human Feedback in Revision Quality .", "entities": []}, {"text": "Table 5 illustrates the quality comparison results of101", "entities": []}, {"text": "HUMAN -HUMAN SYSTEM -HUMAN ( ours ) # Edits # Accepts % Accepts # Edits # Accepts % Accepts CLARITY 197 119 60.40 332 195 58.73 FLUENCY 178 146 82.02 91 41 45.05 COHERENCE 103 41 39.80 141", "entities": []}, {"text": "68 48.22 STYLE 6 2 33.33 113 73 64.60 Table 3 : The distribution of different edit intentions .", "entities": []}, {"text": "# Edits indicates the total number of applied edits under the current edit intention , # Accepts means the total number of edits accepted by users under the current edit intention , and% Accepts is calculated by dividing the total accepted edits with the total applied edits .", "entities": []}, {"text": "Edit Intention Edit Suggestion CLARITY Emerging new test procedures , such asantigen orRT - LAMP tests , might enable us to protect nursing home residents .", "entities": []}, {"text": "FLUENCY", "entities": []}, {"text": "For Radar tracking , we show how a model can reduce the tracking errors .", "entities": []}, {"text": "COHERENCE However , weshow thateven a small violation can signi\ufb01cantly modify the effective noise .", "entities": []}, {"text": "STYLE", "entities": []}, {"text": "There has been numerous extensive research focusing on neural coding .", "entities": []}, {"text": "Table 4 : Edit suggestion examples generated by R3 .", "entities": []}, {"text": "\ufb01nal revised documents with and without humanin - the - loop forR3 .", "entities": []}, {"text": "We asked another group of three annotators ( English L2 , bachelor \u2019s or higher degree in Computer Science ) to judge whether the overall quality of system - generated \ufb01nal document is better than the ground - truth reference \ufb01nal document .", "entities": []}, {"text": "The quality score ranges between 0 and 1 .", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "We evaluated 10 unique documents in ArXiv domain , and took the average score from all 3 annotators .", "entities": [[6, 7, "DatasetName", "ArXiv"]]}, {"text": "As shown in Table 5 , SYSTEM -HUMAN produces better overall quality score for the \ufb01nal system - generated documents with fewer iterations of revision and fewer edits , which validates the effectiveness of the human - machine interaction proposed inR3 .", "entities": []}, {"text": "User Feedback .", "entities": []}, {"text": "We also collected qualitative feedback aboutR3from the linguistic experts through a questionnaire .", "entities": []}, {"text": "The \ufb01rst part of our questionnaire asks participants to recall their experience with the system , and evaluate various aspects of the system ( in Table 6 ) .", "entities": []}, {"text": "They were asked to rate how easy it was to get onboarded and use the system ( convenience ) , whether they were satis\ufb01ed with the system ( revision quality and usage experience ) ( satisfaction ) , whether they felt it improved their productivity for text revision ( productivity ) , andAvg .", "entities": []}, {"text": "Depths # Edits Quality SYSTEM -HUMAN ( ours ) 2.5 148 0.68 SYSTEM -ONLY 2.8 175 0.28 Table 5 : Quality comparison results of \ufb01nal revised documents with and without human - in - the - loop .", "entities": []}, {"text": "Avg .", "entities": []}, {"text": "Depths indicates the average number of iterations conducted by the system , # Edits means the total number of accepted edits by the system , and Quality represents the human judgements of the overall quality of systemrevised \ufb01nal documents .", "entities": [[4, 7, "HyperparameterName", "number of iterations"]]}, {"text": "whether they would like to use the system again ( retention ) for performing revisions on their documents .", "entities": []}, {"text": "In general , the users gave positive feedback towards the ease of use of the system .", "entities": []}, {"text": "However , they were neutral on the potential productivity impact , owing to the lack of domain knowledge of the documents they were evaluating .", "entities": []}, {"text": "This issue could be mitigated by asking users to revise their own documents of interest .", "entities": []}, {"text": "The retention and satisfaction scores were leaning slightly negative , which was explained as primarily attributed to gaps in the user interface design ( eg . improperly aligned diffs , suboptimal presentation of word - level edits , etc . ) .", "entities": []}, {"text": "We also asked them to provide detailed comments on their experience , and the potential impact of the system on their text revision experience .", "entities": []}, {"text": "Speci\ufb01cally , upon asking the users whether using the system to evaluate the model - suggested edits would be more time - ef\ufb01cient compared to actually revising the document themselves , we received many useful insights that help better design better interfaces and features of our system in future work , as some users noted : I think it would be faster using the system , but I would still be checking the text myself in case edits were missed .", "entities": []}, {"text": "The system made some edits where there were letters and parts of words being added / re-102", "entities": []}, {"text": "Criterion Avg .", "entities": []}, {"text": "Score Std .", "entities": [[0, 1, "MetricName", "Score"]]}, {"text": "Deviation Convenience 3.66 0.58 Satisfaction 2.33 0.58 Productivity 3.00 1.00 Retention 2.66 0.58 Table 6 : User feedback survey ratings .", "entities": []}, {"text": "Ratings are on 5 - point Likert scale with 5 being strongly positive experience , 3 being neutral , and 1 being strongly negative .", "entities": []}, {"text": "However , we \u2019d like to point out that as the number of users ( linguists ) who participated in the study is small , the statistical signi\ufb01cance of the results should be taken lightly .", "entities": []}, {"text": "moved / replaced , which sometimes took some time to \ufb01gure out .", "entities": []}, {"text": "That would n\u2019t be the case if I were editing a document .", "entities": []}, {"text": "Ultimately , I would use the system for grammar / coherence / clarity edits , and then still research ( a lot ) to ensure that meaning was preserved throughout the document .", "entities": []}, {"text": "For topics that I was more familiar with / more general topics , using the system would probably reduce my time by a third or so .", "entities": []}, {"text": "For topics that required more in - depth research for me , the time saved by using the system might be minimal .", "entities": []}, {"text": "5 Discussion and Future Directions WhenR3generates revisions at deeper depths , we observe a decrease in the acceptance ratio by human users .", "entities": []}, {"text": "It is crucial to create a text revision system that can learn different revision strategies at each iteration and generate high quality edits at deeper revision levels .", "entities": []}, {"text": "Editing suggestions provided by our text revision generation models could be improved .", "entities": []}, {"text": "Particularly , FLUENCY edits show a huge gap between human and system revisions ( 45.05 % and 82.02 % ) .", "entities": []}, {"text": "Future work could focus on developing more powerful text revision generation models .", "entities": []}, {"text": "In our human - machine interaction , we restrict the users \u2019 role to accept or reject the model \u2019s predictions .", "entities": []}, {"text": "Even with minimal human interaction , our experiment shows comparable or even better revision quality as compared to human writers at early revision depths .", "entities": []}, {"text": "A potential future direction for human - machine collaborative text revision would be to develop advanced human - machine interaction interfaces , such as asking users to re - write the machine - revised text .", "entities": []}, {"text": "Also , a larger - scale user study could be carried out to derive more meaningful statistics ( e.g. optimal number of revision depths and edit suggestions ) and investigate if there is any intriguing user behavior in the iterative revision process .", "entities": []}, {"text": "For example , as mentioned in the users \u2019 feedback , it would be interesting to check if users behave differently when they are asked to accept / reject edit suggestions provided for their own texts as opposed to the texts written by a third party .", "entities": []}, {"text": "6 Conclusion In this work , we develop an interactive iterative text revision system R3that is able to effectively assist users to make revisions and improve the quality of existing documents .", "entities": []}, {"text": "R3can generate higher quality revisions while minimizing the human efforts .", "entities": []}, {"text": "Users are provided with a reviewing interface to accept or reject system suggesting edits .", "entities": []}, {"text": "The user - validated edits are then propagated to the next revision depth to get further improved revisions .", "entities": []}, {"text": "Empirical results show that R3can generate iterative text revisions with acceptance rates comparable or even better than human writers at early revision depths .", "entities": []}, {"text": "Acknowledgments We thank all linguistic expert annotators at Grammarly for participating in the user study and providing us with valuable feedback during the process .", "entities": []}, {"text": "We also thank Karin de Langis at University of Minnesota for narrating the video of our system demonstration .", "entities": []}, {"text": "We would like to extend our gratitude to the anonymous reviewers for their helpful comments .", "entities": []}, {"text": "References Jan A. Botha , Manaal Faruqui , John Alex , Jason Baldridge , and Dipanjan Das . 2018 .", "entities": []}, {"text": "Learning to split and rephrase from Wikipedia edit history .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 732\u2013737 , Brussels , Belgium . Association for Computational Linguistics .", "entities": []}, {"text": "Andy Coenen , Luke Davis , Daphne Ippolito , Emily Reif , and Ann Yuan .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Wordcraft : a human - ai collaborative editor for story writing .", "entities": []}, {"text": "arXiv preprint arXiv:2107.07430 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Allan Collins and Dedre Gentner .", "entities": []}, {"text": "1980 .", "entities": []}, {"text": "A framework for a cognitive theory of writing .", "entities": []}, {"text": "In Cognitive processes in writing , pages 51\u201372 .", "entities": []}, {"text": "Erlbaum.103", "entities": []}, {"text": "tHUMAN -HUMAN", "entities": []}, {"text": "SYSTEM -HUMAN ( ours ) 0Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID-19 storm .", "entities": []}, {"text": "Emerging new test procedures , such as antigen or RT - LAMP tests , might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategiesto curb this spread .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "The model is microscopically calibrated to high - resolution data from actual nursing homes in Austria , including the detailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID-19 storm .", "entities": []}, {"text": "Emerging new test procedures , such as antigen or RT - LAMP tests , might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel agent - based epidemiological model for the spread of SARSCoV-2 in nursing homes to identify optimal preventive testing strategiesto curb this spread .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "The model is microscopically calibrated to high - resolution data from actual nursing homes in Austria , including the detailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "1Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID19 storm .", "entities": []}, {"text": "Emerging new With test procedures becoming available at scale , such as antigen or RTLAMP tests , might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategiesto curb thisspread prevention strategies .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "The model is microscopically calibrated to high - resolution data from actual nursing homes in Austria , including the detailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID-19 storm .", "entities": []}, {"text": "Emerging new test procedures , such asantigen orRT - LAMP tests , might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategies tocurb thisspread .Themodel", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "is microscopically .", "entities": []}, {"text": "The model is calibrated to high - resolution data from actual nursing homes in Austria , including the detailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "2Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID-19 storm pandemic .", "entities": []}, {"text": "Emerging new test procedures , such as antigen or RTLAMP tests , might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel detailed agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategiesto curb this spread .", "entities": [[7, 8, "DatasetName", "agent"]]}, {"text": "The model is microscopically calibrated to high - resolution data from actual nursing homes in Austria , including thedetailed networks ofsocial contacts oftheir resident detailed social contact networks and information on past outbreaks .", "entities": []}, {"text": "Due toitshigh lethality amongst theelderly , n Nursing homes are in the eye of the COVID-19 storm .", "entities": []}, {"text": "Emerging new test procedures might enable us to protect nursing home residents by means of preventive screening strategies .", "entities": []}, {"text": "Here , we develop a novel agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategies .", "entities": [[6, 7, "DatasetName", "agent"]]}, {"text": "The model is calibrated to high - resolution data from actual nursing homes in Austria , including thedetailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "3- Due to its high lethality amongst the elderly , nursing homes are in the eye of the COVID-19 storm .", "entities": []}, {"text": "Emerging new test procedures might enable us to protect nursing home residents by means of preventive screening .", "entities": []}, {"text": "Here , we develop a novel n agent - based epidemiological model for the spread of SARS - CoV-2 in nursing homes to identify optimal preventive testing strategies .", "entities": [[7, 8, "DatasetName", "agent"]]}, {"text": "The model is calibrated to high - resolution data from actual nursing homes in Austria , including detailed networks of social contacts of their residents and information on past outbreaks .", "entities": []}, {"text": "Table 7 : A sample snippet of iterative text revisions in ArXiv domain generated by R3 , where tis the revision depth and t= 0indicates", "entities": [[11, 12, "DatasetName", "ArXiv"]]}, {"text": "the original input text .", "entities": []}, {"text": "Note that text represents user accepted deletions , text represents user accepted insertions , and text represents user rejected edits .", "entities": []}, {"text": "Wanyu Du , Vipul Raheja , Dhruv Kumar , Zae Myung Kim , Melissa Lopez , and Dongyeop Kang .", "entities": [[7, 8, "DatasetName", "Kumar"]]}, {"text": "2022.Understanding Iterative Revision from HumanWritten Text .", "entities": []}, {"text": "In Proceedings of the 60th Annual104", "entities": []}, {"text": "Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Lester Faigley and Stephen Witte .", "entities": []}, {"text": "1981 .", "entities": []}, {"text": "Analyzing revision .", "entities": []}, {"text": "College composition and communication , 32(4):400\u2013414 .", "entities": []}, {"text": "Felix Faltings , Michel Galley , Gerold Hintz , Chris Brockett , Chris Quirk , Jianfeng Gao , and Bill Dolan .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Text editing by command .", "entities": []}, {"text": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 5259\u20135274 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Manaal Faruqui , Ellie Pavlick , Ian Tenney , and Dipanjan Das . 2018 .", "entities": []}, {"text": "WikiAtomicEdits : A multilingual corpus of Wikipedia edits for modeling language and discourse .", "entities": [[0, 1, "DatasetName", "WikiAtomicEdits"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 305\u2013315 , Brussels , Belgium . Association for Computational Linguistics .", "entities": []}, {"text": "Jill Fitzgerald .", "entities": []}, {"text": "1987 .", "entities": []}, {"text": "Research on revision in writing .", "entities": []}, {"text": "Review of Educational Research , 57(4):481\u2013506 .", "entities": []}, {"text": "Linda Flower .", "entities": []}, {"text": "1980 .", "entities": []}, {"text": "The dynamics of composing : Making plans and juggling constraints .", "entities": []}, {"text": "Cognitive processes in writing , pages 31\u201350 .", "entities": []}, {"text": "Linda Flower and John R. Hayes .", "entities": []}, {"text": "1981 .", "entities": []}, {"text": "A cognitive process theory of writing .", "entities": []}, {"text": "College Composition and Communication , 32(4):365\u2013387 .", "entities": []}, {"text": "Katy Ilonka Gero , Vivian Liu , and Lydia B Chilton . 2021 .", "entities": []}, {"text": "Sparks : Inspiration for science writing using language models .", "entities": []}, {"text": "arXiv preprint arXiv:2110.07640 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Takumi Ito , Tatsuki Kuribayashi , Hayato Kobayashi , Ana Brassard , Masato Hagiwara , Jun Suzuki , and Kentaro Inui .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Diamonds in the rough : Generating \ufb02uent sentences from early - stage drafts for academic writing assistance .", "entities": []}, {"text": "In Proceedings of the 12th International Conference on Natural Language Generation , pages 40\u201353 , Tokyo , Japan .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Mina Lee , Percy Liang , and Qian Yang . 2022 .", "entities": []}, {"text": "Coauthor : Designing a human - ai collaborative writing dataset for exploring language model capabilities .", "entities": [[0, 1, "DatasetName", "Coauthor"]]}, {"text": "arXiv preprint arXiv:2201.06796 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Chin - Yew Lin .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "ROUGE :", "entities": []}, {"text": "A package for automatic evaluation of summaries .", "entities": []}, {"text": "In Text Summarization Branches Out , pages 74\u201381 , Barcelona , Spain . Association for Computational Linguistics .", "entities": [[1, 3, "TaskName", "Text Summarization"]]}, {"text": "Yinhan Liu , Myle Ott , Naman Goyal , Jingfei Du , Mandar Joshi , Danqi Chen , Omer Levy , Mike Lewis , Luke Zettlemoyer , and Veselin Stoyanov .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "RoBERTa : A robustly optimized BERT pretraining approach .", "entities": [[0, 1, "MethodName", "RoBERTa"], [5, 6, "MethodName", "BERT"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Vishakh Padmakumar and He He . 2021 .", "entities": []}, {"text": "Machinein - the - loop rewriting for creative image captioning .", "entities": [[8, 10, "TaskName", "image captioning"]]}, {"text": "arXiv preprint arXiv:2111.04193 .Kishore", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .", "entities": []}, {"text": "Bleu : a method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics , pages 311\u2013318 , Philadelphia , Pennsylvania , USA . Association for Computational Linguistics . M. Scardamalia .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "Research on written composition .", "entities": []}, {"text": "Handbook of reserch on teaching .", "entities": []}, {"text": "Nikhil Singh , Guillermo Bernal , Daria Savchenko , and Elena L. Glassman . 2022 .", "entities": []}, {"text": "Where to hide a stolen elephant : Leaps in creative writing with multimodal machine intelligence .", "entities": []}, {"text": "ACM Trans . Comput.-Hum .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Interact .", "entities": []}, {"text": "Nancy Sommers .", "entities": []}, {"text": "1980 .", "entities": []}, {"text": "Revision strategies of student writers and experienced adult writers .", "entities": []}, {"text": "College composition and communication , 31(4):378\u2013388 .", "entities": []}, {"text": "Simeng Sun , Wenlong Zhao , Varun Manjunatha , Rajiv Jain , Vlad Morariu , Franck Dernoncourt , Balaji Vasan Srinivasan , and Mohit Iyyer . 2021 .", "entities": []}, {"text": "IGA : An intent - guided authoring assistant .", "entities": []}, {"text": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages 5972\u20135985 , Online and Punta Cana , Dominican Republic .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Marie M. Vaughan and David D. McDonald .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "A model of revision in natural language generation .", "entities": []}, {"text": "In 24th Annual Meeting of the Association for Computational Linguistics , pages 90\u201396 , New York , New York , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Thomas Wolf , Lysandre Debut , Victor Sanh , Julien Chaumond , Clement Delangue , Anthony Moi , Pierric Cistac , Tim Rault , Remi Louf , Morgan Funtowicz , Joe Davison , Sam Shleifer , Patrick von Platen , Clara Ma , Yacine Jernite , Julien Plu , Canwen Xu , Teven Le Scao , Sylvain Gugger , Mariama Drame , Quentin Lhoest , and Alexander Rush . 2020 .", "entities": []}, {"text": "Transformers : State - of - the - art natural language processing .", "entities": []}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing : System Demonstrations , pages 38\u201345 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Wei Xu , Courtney Napoles , Ellie Pavlick , Quanze Chen , and Chris Callison - Burch . 2016 .", "entities": []}, {"text": "Optimizing statistical machine translation for text simpli\ufb01cation .", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "Transactions of the Association for Computational Linguistics , 4:401\u2013415 .", "entities": []}, {"text": "Jingqing Zhang , Yao Zhao , Mohammad Saleh , and Peter Liu . 2020 .", "entities": []}, {"text": "PEGASUS :", "entities": []}, {"text": "Pre - training with extracted gap - sentences for abstractive summarization .", "entities": [[10, 11, "TaskName", "summarization"]]}, {"text": "InProceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of Machine Learning Research , pages 11328\u201311339 .", "entities": []}, {"text": "PMLR.105", "entities": []}, {"text": "AR3Iterative Revision Samples We present more iterative revision examples generated byR3 in Table 8 and Table 9.106", "entities": []}, {"text": "tHUMAN -HUMAN", "entities": []}, {"text": "SYSTEM -HUMAN ( ours ) 0Corporal Nathan Hornburg .", "entities": []}, {"text": "A Reserve soldier serving with Canadian Forces in Afghanistanwas killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "A Canadian Forces statement said Cpl .", "entities": []}, {"text": "Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) approximately 47 kilometres west of Kandahar City in Panjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "Corporal Nathan Hornburg .", "entities": []}, {"text": "A Reserve soldier serving with Canadian Forces in Afghanistanwas killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "A Canadian Forces statement said Cpl .", "entities": []}, {"text": "Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) approximately 47 kilometres west of Kandahar City in Panjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "1 Corporal Nathan Hornburg .", "entities": []}, {"text": "AReserve soldier serving with Canadian Forces inAfghanistanwas killed onSeptember 24,2007 On MOnday , a 24 - year old Calgary Reservist became the 71st Canadian soldier killed in Afghanistan .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg ofCalgary , Alberta .", "entities": []}, {"text": "ACanadian Forces statement saidCpl .", "entities": []}, {"text": "Hornbur waskilled during , who was operating as part of Operation Sadiq Sarbaaz ( Honest Soldier ) approximately 47 kilometres west of Kandahar City in Panjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "Corporal Nathan Hornburg .", "entities": []}, {"text": "AReserve A Canadian soldier serving with Canadian Forces in Afghanistanwas killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "ACanadian Forces statement saidCpl .", "entities": []}, {"text": "Nathan Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) approximately 47 kilometres west of Kandahar City in Panjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "2Corporal Nathan Hornburg .", "entities": []}, {"text": "A Reserve soldier serving with Canadian Forces in Afghanistanwas killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "A Canadian Forces statement said Cpl .", "entities": []}, {"text": "Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) approximately 47kilometres west of Kandahar City inPanjwaii District , a joint Afghan - NATO mission designed to \" set the conditions for a continuous security presence and the establishment of a new police sub - station in the northern part of ( Panjwaii ) . \" .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "A Canadian soldier serving with the Canadian Forces in Afghanistanwas killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "Nathan Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) , approximately 47 kilometres west of Kandahar City in Panjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "3-", "entities": []}, {"text": "A Canadian soldier serving with the Canadian Forces in Afghanistan was killed on September 24 , 2007 .", "entities": []}, {"text": "Four others were injured in the incident which killed 24 - year - old Corporal Cpl .", "entities": []}, {"text": "Nathan Hornburg of Calgary , Alberta .", "entities": []}, {"text": "Nathan Hornburg was killed during Operation Sadiq Sarbaaz ( Honest Soldier ) , approximately 47 kilometres west of Kandahar City in thePanjwaii District .", "entities": []}, {"text": "Media reports indicated he died from mortar \ufb01re at around 4 : 30 p.m. local time ( 12:00 UTC ) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad .", "entities": []}, {"text": "Table 8 : A sample snippet of iterative text revisions in Wikinews domain generated by R3 , where tis the revision depth and t= 0indicates", "entities": []}, {"text": "the original input text .", "entities": []}, {"text": "Note that text represents user accepted deletions , text represents user accepted insertions , and text represents user rejected edits.107", "entities": []}, {"text": "tHUMAN -HUMAN", "entities": []}, {"text": "SYSTEM -HUMAN ( ours ) 0Jecon", "entities": []}, {"text": "Gregory is or was a nomadic artist , whose autobiographical fragments and poems , dictated to an acquaintance , were published as the book \" History of a Nation of One \" ( Harcourt Brace , New York , 1969 , and", "entities": []}, {"text": "Michael Joseph , London , 1971 ) .", "entities": []}, {"text": "Jecon apparently did not know his place , date , language or even name of birth , began his wanderings as a child in Malta ; walked through many lands , barefoot , tall and thin , pulling all his possessions in a basket on wheels , sleeping on the ground , and making a living by drawing portraits .", "entities": []}, {"text": "Jecon Gregory is or was a nomadic artist , whose autobiographical fragments and poems , dictated to an acquaintance , were published as the book \" History of a Nation of One \" ( Harcourt Brace , New York , 1969 , and", "entities": []}, {"text": "Michael Joseph , London , 1971 ) .", "entities": []}, {"text": "Jecon apparently did not know his place , date , language or even name of birth , began his wanderings as a child in Malta ; walked through many lands , barefoot , tall and thin , pulling all his possessions in a basket on wheels , sleeping on the ground , and making a living by drawing portraits .", "entities": []}, {"text": "1Jecon Gregory is or was a nomadic artist , whose autobiographical fragments and poems , dictated to an acquaintance , were published as the book \" History of a Nation of One : An Unlikely Memoir \" ( Harcourt Brace , New York , 1969 , and Michael Joseph , London , 1971 ) .", "entities": []}, {"text": "..", "entities": []}, {"text": "Jecon apparently did not know his place , date , language or even name of birth , began his wanderings as a child in Malta ; walked through many lands , barefoot , tall and thin , pulling all his possessions in a basket on wheels , sleeping on the ground , and making a living by drawing portraits .", "entities": []}, {"text": "Jecon Gregory is or was a nomadic artist , whose autobiographical fragments and poems , dictated to an acquaintance , were published as the book \" History of a Nation of One \" ( Harcourt Brace , New York , 1969 , and", "entities": []}, {"text": "Michael Joseph , London , 1971 ) .", "entities": []}, {"text": "Jecon apparently did not know his place , date , language or even name of birth , began his wanderings as a child in Malta ; walked through many lands , barefoot , tall and thin , pulling all his possessions in a basket on wheels , sleeping on the ground , and making aliving by drawing portraits .", "entities": []}, {"text": "2-", "entities": []}, {"text": "Jecon Gregory is or was a nomadic artist , whose autobiographical fragments and poems , dictated to an acquaintance , were published as the book \" History of a Nation of One \" ( Harcourt Brace , New York , 1969 , and", "entities": []}, {"text": "Michael Joseph , London , 1971 ) .", "entities": []}, {"text": "Jecon apparently did not know his place , date , language or even name of birth , began his wanderings as a child in Malta ; walked through many lands , barefoot , tall and thin , pulling all his possessions in a basket on wheels , sleeping on the ground , and making aliving by drawing portraits .", "entities": []}, {"text": "3- Table 9 : A sample snippet of iterative text revisions in Wikipedia domain generated by R3 , where tis the revision depth and t= 0indicates", "entities": []}, {"text": "the original input text .", "entities": []}, {"text": "Note that text represents user accepted deletions , text represents user accepted insertions , and text represents user rejected edits.108", "entities": []}]