[{"text": "Findings of the Association for Computational Linguistics : EMNLP 2020 , pages 3829\u20133839 November 16 - 20 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics3829Reevaluating Adversarial Examples in Natural Language John X. Morris \u21e4 , Eli Li\ufb02and \u21e4 , Jack Lanchantin , Yangfeng Ji , Yanjun Qi Department of Computer Science , University of Virginia { jm8wx , edl9cy , jjl5sw , yj3fs , yq2h }", "entities": []}, {"text": "@virginia.edu", "entities": []}, {"text": "Abstract State - of - the - art attacks on NLP models lack a shared de\ufb01nition of what constitutes a successful attack .", "entities": []}, {"text": "These differences make the attacks dif\ufb01cult to compare and hindered the use of adversarial examples to understand and improve NLP models .", "entities": []}, {"text": "We distill ideas from past work into a uni\ufb01ed framework : a successful natural language adversarial example is a perturbation that fools the model and follows four proposed linguistic constraints .", "entities": []}, {"text": "We categorize previous attacks based on these constraints .", "entities": []}, {"text": "For each constraint , we suggest options for human and automatic evaluation methods .", "entities": []}, {"text": "We use these methods to evaluate two state - of - the - art synonym substitution attacks .", "entities": []}, {"text": "We \ufb01nd that perturbations often do not preserve semantics , and 38 % introduce grammatical errors .", "entities": []}, {"text": "Next , we conduct human studies to \ufb01nd a threshold for each evaluation method that aligns with human judgment .", "entities": []}, {"text": "Human surveys reveal that to successfully preserve semantics , we need to signi\ufb01cantly increase the minimum cosine similarities between the embeddings of swapped words and between the sentence encodings of original and perturbed sentences .", "entities": []}, {"text": "With constraints adjusted to better preserve semantics and grammaticality , the attack success rate drops by over 70 percentage points.1 1Introduction One way to evaluate the robustness of a machine learning model is to search for inputs that produce incorrect outputs .", "entities": []}, {"text": "Inputs intentionally designed to fool deep learning models are referred to as adversarial examples ( Goodfellow et", "entities": []}, {"text": "al . , 2017 )", "entities": []}, {"text": ".", "entities": []}, {"text": "Adversarial examples have successfully tricked deep neural networks for image classi\ufb01cation : two images that look exactly the same to a human receive \u21e4 * Equal contribution 1Our code and datasets are available here .", "entities": []}, {"text": "\u0010-$\"$ ) \u001c ' \u03f6\u0003\u0014&$+\u0001/ # \u0001!$'(\u0001 \u001c )", "entities": []}, {"text": "\u0001 \u001d 04\u0001/ # \u0001+#$'$+\u0001 \" ' \u001c .. \u0001.*0 ) \u001f /- \u001c\u001e & \u0001 \u001e\u001f \u03f4\u0011- \u001f $ \u001e /$*)\u03f6\u0001\u000f", "entities": []}, {"text": "\" \u001c /$1 \u0001\u4623\u0001\u0002 \u001f 1 - .", "entities": []}, {"text": "-$ \u001c ' \u03f6\u0003\u0014&$+\u0001/ # \u0001!$'(.\u0001 \u001c ) \u001f \u0001", "entities": []}, {"text": "04\u0001/ # \u0001+#$'$+\u0001 \" ' \u001c .. \u0001.*0 ) \u001f /- \u001c\u001e & \u0001 \u001e\u001f \u03f4\u0011- \u001f $ \u001e /$*)\u03f6\u0011*.$/$1", "entities": []}, {"text": "\u0001\u04f0\u0001Figure 1 : An adversarial example generated by TFA DJUSTED for BERT \ufb01ne - tuned on the Rotten Tomatoes sentiment analysis dataset .", "entities": [[11, 12, "MethodName", "BERT"], [19, 21, "TaskName", "sentiment analysis"]]}, {"text": "Swapping a single word causes the prediction to change from positive to negative .", "entities": []}, {"text": "completely different predictions from the classi\ufb01er ( Goodfellow et al . , 2014 ) .", "entities": []}, {"text": "While applicable in the image case , the idea of an indistinguishable change lacks a clear analog in text .", "entities": []}, {"text": "Unlike images , two different sequences of text are never entirely indistinguishable .", "entities": []}, {"text": "This raises the question : if indistinguishable perturbations are not possible , what are adversarial examples in text ?", "entities": []}, {"text": "The literature contains many potential answers to this question , proposing varying de\ufb01nitions for successful adversarial examples ( Zhang et al . , 2019 ) .", "entities": []}, {"text": "Even attacks with similar de\ufb01nitions of success often measure it in different ways .", "entities": []}, {"text": "The lack of a consistent de\ufb01nition and standardized evaluation has hindered the use of adversarial examples to understand and improve NLP models.2 Therefore , we propose a uni\ufb01ed de\ufb01nition for successful adversarial examples in natural language : perturbations that both fool the model and ful\ufb01ll a set of linguistic constraints .", "entities": []}, {"text": "In Section 2 , we present four categories of constraints NLP adversarial examples may follow , depending on the context : semantics , grammaticality , overlap , and non - suspicion to human readers .", "entities": []}, {"text": "2We use \u2018 adversarial example generation methods \u2019 and \u2018 adversarial attacks \u2019 interchangeably in this paper .", "entities": []}, {"text": "3830By explicitly laying out categories of constraints adversarial examples may follow , we introduce a shared vocabulary for discussing constraints on adversarial attacks .", "entities": []}, {"text": "In Section 4 , we suggest options for human and automatic evaluation methods for each category .", "entities": []}, {"text": "We use these methods to evaluate two SOTA synonym substitution attacks :", "entities": []}, {"text": "GENETIC ATTACK byAlzantot et al .", "entities": []}, {"text": "( 2018 ) and TEXTFOOLER byJin", "entities": []}, {"text": "et al . ( 2019 ) .", "entities": []}, {"text": "Human surveys show that the perturbed examples often fail to ful\ufb01ll semantics and non - suspicion constraints .", "entities": []}, {"text": "Additionally , a grammar checker detects 39 % more errors in the perturbed examples than in the original inputs , including many types of errors humans almost never make .", "entities": []}, {"text": "In Section 5 , we produce TFA DJUSTED , an attack with the same search process as TEXTFOOLER , but with constraint enforcement tuned to generate higher quality adversarial examples .", "entities": []}, {"text": "To enforce semantic preservation , we tighten the thresholds on the cosine similarity between embeddings of swapped words and between the sentence encodings of original and perturbed sentences .", "entities": []}, {"text": "To enforce grammaticality , we validate perturbations with a grammar checker .", "entities": []}, {"text": "As inTEXTFOOLER , these constraints are applied at each step of the search .", "entities": []}, {"text": "Human evaluation shows thatTFA DJUSTED generates perturbations that better preserve semantics and are less noticeable to human judges .", "entities": []}, {"text": "However , with stricter constraints , the attack success rate decreases from over 80 % to under 20 % .", "entities": []}, {"text": "When used for adversarial training , TEXTFOOLER \u2019s examples decreased model accuracy , but TFA DJUSTED \u2019s examples did not .", "entities": [[11, 12, "MetricName", "accuracy"]]}, {"text": "Without a shared vocabulary for discussing constraints , past work has compared the success rate of search methods with differing constraint application techniques .", "entities": []}, {"text": "Jin et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) reported a higher attack success rate for TEXTFOOLER thanAlzantot et al .", "entities": []}, {"text": "( 2018 ) did for GENETIC ATTACK , but it was not clear whether the improvement was due to a better search method3or more lenient constraint application4 .", "entities": []}, {"text": "In Section 6we compare the search methods with constraint application held constant .", "entities": []}, {"text": "We \ufb01nd that GENETIC ATTACK \u2019s search method is more successful than TEXTFOOLER \u2019s , contrary to 3TEXTFOOLER uses a greedy search method with word importance ranking .", "entities": []}, {"text": "GENETIC ATTACK uses a genetic algorithm .", "entities": []}, {"text": "4For example , TEXTFOOLER applies a minimum cosine distance of .5 between embeddings of swapped words .", "entities": []}, {"text": "GENETIC ATTACK uses a threshold of .75.the implications of Jin et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "The \ufb01ve main contributions of this paper are : \u2022A de\ufb01nition for constraints on adversarial perturbations in natural language and suggest evaluation methods for each constraint .", "entities": []}, {"text": "\u2022Constraint evaluations of two SOTA synonymsubstitution attacks , revealing that their perturbations often do not preserve semantics , grammaticality , or non - suspicion .", "entities": []}, {"text": "\u2022Evidence that by aligning automatic constraint application with human judgment , it is possible for attacks to produce successful , valid adversarial examples .", "entities": []}, {"text": "\u2022Demonstration that reported differences in attack success between TEXTFOOLER andGENET ICATTACK are the result of more lenient constraint enforcement .", "entities": []}, {"text": "\u2022Our framework enables fair comparison between attacks , by separating effects of search methods from effects of loosened constraints .", "entities": []}, {"text": "2Constraints on Adversarial Examples in Natural Language We de\ufb01ne F : X!Y as a predictive model , for example , a deep neural network classi\ufb01er .", "entities": []}, {"text": "Xis the input space and Yis the output space .", "entities": []}, {"text": "We focus on adversarial perturbations which perturb a correctly predicted input , x2X , into an input xadv .", "entities": []}, {"text": "The boolean goal function G(F , xadv)represents", "entities": []}, {"text": "whether the goal of the attack has been met .", "entities": []}, {"text": "We de\ufb01ne C1 ... C nas a set of boolean functions indicating whether the perturbation satis\ufb01es a certain constraint .", "entities": []}, {"text": "Adversarial attacks search for a perturbation from xtoxadvwhich fools Fby both achieving some goal , as represented by G(F , xadv ) , and ful\ufb01lling each constraint Ci(x , xadv ) .", "entities": []}, {"text": "The de\ufb01nition of the goal function Gdepends on the purpose of the attack .", "entities": []}, {"text": "Attacks on classi\ufb01cation frequently aim to either induce any incorrect classi\ufb01cation ( untargeted ) or induce a particular classi\ufb01cation ( targeted ) .", "entities": []}, {"text": "Attacks on other types of models may have more sophisticated goals .", "entities": []}, {"text": "For example , attacks on translation may attempt to change every word of a translation , or introduce targeted keywords into the translation ( Cheng et al . , 2018 ) .", "entities": []}, {"text": "In addition to de\ufb01ning the goal of the attack , the attacker must decide the constraints perturbations must meet .", "entities": []}, {"text": "Different use cases require different", "entities": []}, {"text": "3831Input , x : \u201d Shall I compare thee to a summer \u2019s day ? \u201d \u2013 William Shakespeare , Sonnet XVIIIConstraintPerturbation , xadvExplanationSemanticsShall I compare thee to awinter\u2019sday?xadvhas a different meaning thanx .", "entities": []}, {"text": "GrammaticalityShall Icomparesthee to a summer \u2019s day?xadvis less grammatically correct thanx .", "entities": []}, {"text": "Edit DistanceSha1li conpp$haaare thee to a5umm3r \u2019s day?xandxadvhave a large edit distance .", "entities": []}, {"text": "Non - suspicionAm I gonnacompare thee to a summer \u2019s", "entities": []}, {"text": "day?A human reader may suspect thissentence to have been modi\ufb01ed.11Shakespeare never used the word \u201c gon na \u201d .", "entities": []}, {"text": "Its \ufb01rst recorded usage was n\u2019t until 1806 , and it did n\u2019t become popular until the 20th century .", "entities": []}, {"text": "Table 1 : Adversarial Constraints and Violations .", "entities": []}, {"text": "For each of the four proposed constraints , we show an example for which violates the speci\ufb01ed constraint .", "entities": []}, {"text": "constraints .", "entities": []}, {"text": "We build on the categorization of attack spaces introduced by Gilmer et al .", "entities": []}, {"text": "( 2018 ) to introduce a categorization of constraints for adversarial examples in natural language .", "entities": []}, {"text": "In the following , we de\ufb01ne four categories of constraints on adversarial perturbations in natural language : semantics , grammatically , overlap , and non - suspicion .", "entities": []}, {"text": "Table 1provides examples of adversarial perturbations that violate each constraint .", "entities": []}, {"text": "2.1 Semantics Semantics constraints require the semantics of the input to be preserved between xandxadv .", "entities": []}, {"text": "Many attacks include constraints on semantics as a way to ensure the correct output is preserved ( Zhang et al . , 2019 ) .", "entities": []}, {"text": "As long as the semantics of an input do not change , the correct output will stay the same .", "entities": []}, {"text": "There are exceptions : one could imagine tasks for which preserving semantics does not necessarily preserve the correct output .", "entities": []}, {"text": "For example , consider the task of classifying passages as written in either Modern or Early Modern English .", "entities": []}, {"text": "Perturbing \u201c why \u201d to \u201c wherefore \u201d may retain the semantics of the passage , but change the correct label from Modern to Early Modern English5 2.2 Grammaticality Grammaticality constraints place restrictions on the grammaticality of xadv .", "entities": []}, {"text": "For example , an adversary attempting to generate a plagiarised paper which fools a plagiarism checker would need to ensure that the paper remains grammatically correct .", "entities": []}, {"text": "Grammatical errors do n\u2019t necessarily change semantics , as illustrated in Table 1 . 2.3 Overlap Overlap constraints restrict the similarity between xandxadvat the character level .", "entities": []}, {"text": "This in5Wherefore is a synonym for why , but was used much more often centuries ago.cludes constraints like Levenshtein distance as well as n - gram based measures such as BLEU , METEOR and chRF ( Papineni et al . , 2002 ; Denkowski and Lavie , 2014 ; Popovi \u00b4 c,2015 ) .", "entities": [[30, 31, "MetricName", "BLEU"], [32, 33, "DatasetName", "METEOR"]]}, {"text": "Setting a maximum edit distance is useful when the attacker is willing to introduce misspellings .", "entities": []}, {"text": "Additionally , the edit distance constraint is sometimes used when improving the robustness of models .", "entities": []}, {"text": "For example , Huang et al .", "entities": []}, {"text": "( 2019 ) uses Interval Bound Propagation to ensure model robustness to perturbations within some edit distance of the input .", "entities": []}, {"text": "2.4 Non - suspicion Non - suspicion constraints specify that xadvmust appear to be unmodi\ufb01ed .", "entities": []}, {"text": "Consider the example in Table 1 .", "entities": []}, {"text": "While the perturbation preserves semantics and grammar , it switches between Modern and Early Modern English and thus may seem suspicious to readers .", "entities": []}, {"text": "Note that the de\ufb01nition of the non - suspicious constraint is context - dependent .", "entities": []}, {"text": "A sentence that is non - suspicious in the context of a kindergartner \u2019s homework assignment might be suspicious in the context of an academic paper .", "entities": []}, {"text": "An attack scenario where non - suspicion constraints do not apply is illegal PDF distribution , similar to a case discussed byGilmer et al .", "entities": []}, {"text": "( 2018 ) .", "entities": []}, {"text": "Consumers of an illegal PDF may tacitly collude with the person uploading it .", "entities": []}, {"text": "They know the document has been altered , but do not care as long as semantics are preserved .", "entities": []}, {"text": "3Review and Categorization of SOTA :", "entities": []}, {"text": "Attacks by Paraphrase : Some studies have generated adversarial examples through paraphrase .", "entities": []}, {"text": "Iyyer et al .", "entities": []}, {"text": "( 2018 ) used neural machine translation systems to generate paraphrases .", "entities": [[5, 7, "TaskName", "machine translation"]]}, {"text": "Ribeiro et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) proposed semantically - equivalent adversarial rules .", "entities": []}, {"text": "By de\ufb01nition , paraphrases preserve semantics .", "entities": []}, {"text": "Since the systems aim to generate perfect", "entities": []}, {"text": "3832paraphrases , they implicitly follow constraints of grammaticality and non - suspicion .", "entities": []}, {"text": "Attacks by Synonym Substitution : Some works focus on an easier way to generate a subset of paraphrases : replacing words from the input with synonyms ( Alzantot et al . , 2018 ; Jin et al . , 2019 ; Kuleshov et al . , 2018 ; Papernot et al . , 2016 ; Ren et al . , 2019 ) .", "entities": []}, {"text": "Each attack applies a search algorithm to determine which words to replace with which synonyms .", "entities": []}, {"text": "Like the general paraphrase case , they aim to create examples that preserve semantics , grammaticality , and non - suspicion .", "entities": []}, {"text": "While not all have an explicit edit distance constraint , some limit the number of words perturbed .", "entities": []}, {"text": "Attacks by Character Substitution : Some studies have proposed to attack natural language classi\ufb01cation models by deliberately misspelling words ( Ebrahimi et al . , 2017 ; Gao et al . , 2018 ; Li et al . , 2018 ) .", "entities": []}, {"text": "These attacks use character replacements to change a word into one that the model does n\u2019t recognize .", "entities": []}, {"text": "The replacements are designed to create character sequences that a human reader would easily correct into the original words .", "entities": []}, {"text": "If there are n\u2019t many misspellings , non - suspicion may be preserved .", "entities": []}, {"text": "Semantics are preserved as long as human readers can correct the misspellings .", "entities": []}, {"text": "Attacks by Word Insertion or Removal : Liang et al .", "entities": []}, {"text": "( 2017 ) and Samanta and Mehta ( 2017 ) devised a way to determine the most important words in the input and then used heuristics to generate perturbed inputs by adding or removing important words .", "entities": []}, {"text": "In some cases , these strategies are combined with synonym substitution .", "entities": []}, {"text": "These attacks aim to follow all constraints .", "entities": []}, {"text": "Using constraints de\ufb01ned in Section 2we categorize a sample of current attacks in Table 2 . 4Constraint Evaluation Methods and Case Study For each category of constraints introduced in Section 2 , we discuss best practices for both human and automatic evaluation .", "entities": []}, {"text": "We leave out overlap due to ease of automatic evaluation .", "entities": []}, {"text": "Additionally , we perform a case study , evaluating how well black - box synonym substitution attacks GENETIC ATTACK andTEXTFOOLER ful\ufb01ll constraints .", "entities": []}, {"text": "Both attacks \ufb01nd adversarial examples by swapping out words for their synonyms until the classi\ufb01er is fooled .", "entities": []}, {"text": "GENETIC ATTACKuses a genetic algorithm to attack an LSTM trained on the IMDB6document - level sentiment classi\ufb01cation dataset .", "entities": [[8, 9, "MethodName", "LSTM"]]}, {"text": "TEXTFOOLER uses a greedy approach to attack an LSTM , CNN , and BERT trained on \ufb01ve classi\ufb01cation datasets .", "entities": [[8, 9, "MethodName", "LSTM"], [13, 14, "MethodName", "BERT"]]}, {"text": "We chose these attacks because : \u2022They claim to create perturbations that preserve semantics , maintain grammaticality , and are not suspicious to readers .", "entities": []}, {"text": "However , our inspection of the perturbations revealed that many violated these constraints .", "entities": []}, {"text": "\u2022They report high attack success rates.7 \u2022They successfully attack two of the most effective models for text classi\ufb01cation : LSTM and BERT .", "entities": [[19, 20, "MethodName", "LSTM"], [21, 22, "MethodName", "BERT"]]}, {"text": "To generate examples for evaluation , we attacked BERT using TEXTFOOLER and attacked an LSTM using GENETIC ATTACK .", "entities": [[8, 9, "MethodName", "BERT"], [14, 15, "MethodName", "LSTM"]]}, {"text": "We evaluate both methods on the IMDB dataset .", "entities": [[6, 7, "DatasetName", "IMDB"]]}, {"text": "In addition , we evaluate TEXTFOOLER on the Yelp polarity document - level sentiment classi\ufb01cation dataset and the Movie Review ( MR ) sentence - level sentiment classi\ufb01cation dataset ( Pang and Lee , 2005 ; Zhang et al . , 2015 ) .", "entities": [[21, 22, "DatasetName", "MR"]]}, {"text": "We use 1,000examples from each dataset .", "entities": []}, {"text": "Table 3 shows example violations of each constraint .", "entities": []}, {"text": "4.1 Evaluation of Semantics 4.1.1 Human Evaluation A few past studies of attacks have included human evaluation of semantic preservation ( Ribeiro et al . ,2018 ; Iyyer et al . , 2018 ;", "entities": []}, {"text": "Alzantot et", "entities": []}, {"text": "al . , 2018 ; Jin et al . , 2019 ) .", "entities": []}, {"text": "However , studies often simply ask users to simply rate the \u201c similarity \u201d of xand xadv .", "entities": []}, {"text": "We believe this phrasing does not generate an accurate measure of semantic preservation , as users may consider two sentences with different semantics \u201c similar \u201d if they only differ by a few words .", "entities": []}, {"text": "Instead , users should be explicitly asked whether changes between xandxadvpreserve the meaning of the original passage .", "entities": []}, {"text": "We propose to ask human judges to rate if meaning is preserved on a Likert scale of 1 - 5 , where 1 is \u201c Strongly Disagree \u201d and 5 is \u201c Strongly Agree \u201d ( Likert,1932 ) .", "entities": []}, {"text": "A perturbation is semantics - preserving if the average score is at least \u270f sem .", "entities": []}, {"text": "We propose 6https://datasets.imdbws.com/ 7We use \u201c attack success rate \u201d to mean the percentage of the time that an attack can \ufb01nd a successful adversarial example by perturbing a given input .", "entities": []}, {"text": "\u201c After - attack accuracy \u201d or \u201c accuracy after attack \u201d is the accuracy the model achieves after all successful perturbations have been applied .", "entities": [[4, 5, "MetricName", "accuracy"], [8, 9, "MetricName", "accuracy"], [14, 15, "MetricName", "accuracy"]]}, {"text": "3833Selected Attacks Generating Adversarial Examples inNatural LanguageSemantics Grammaticality EditDistanceNon - SuspicionSynonym Substitution.(Alzantot et", "entities": []}, {"text": "al . ,2018;Kuleshovet al . ,2018;Jin et", "entities": []}, {"text": "al . ,2019;Ren et al . ,2019)333", "entities": []}, {"text": "3Character Substitution.(Ebrahimi et", "entities": []}, {"text": "al . ,2017;Gao et", "entities": []}, {"text": "al . ,2018;Li et", "entities": []}, {"text": "al . ,2018)353 3Word Insertion or Removal.(Liang et", "entities": []}, {"text": "al . ,2017;Samantaand", "entities": []}, {"text": "Mehta,2017)333 3General Paraphrase.(Zhao et", "entities": []}, {"text": "al . ,2017;Ribeiro et al . ,2018;Iyyer et", "entities": []}, {"text": "al . ,2018)335 3Table 2 : Summary of Constraints and Attacks .", "entities": []}, {"text": "This table shows a selection of prior work ( rows ) categorized by constraints ( columns ) .", "entities": []}, {"text": "A \u201c 3 \u201d indicates that the respective attack is supposed to meet the constraint , and a \u201c 5 \u201d means the attack is not supposed to meet the constraint .", "entities": []}, {"text": "Constraint Violated Input , x Perturbation , xadv Semantics Jagger , Stoppard and director Michael Apted deliver a riveting and surprisingly romantic ride .Jagger ,", "entities": []}, {"text": "Stoppard and director Michael Apted deliver a baf\ufb02ing and surprisingly sappy motorbike .", "entities": []}, {"text": "Grammaticality Agrating , emaciated \ufb02ick .", "entities": []}, {"text": "Agrates , lanky \ufb02ick .", "entities": []}, {"text": "Non - suspicion Great character interaction .", "entities": []}, {"text": "Gargantuan character interaction .", "entities": []}, {"text": "Table 3 : Real World Constraint Violation Examples .", "entities": []}, {"text": "Perturbations by T EXTFOOLER against BERT \ufb01ne - tuned on the MR dataset .", "entities": [[5, 6, "MethodName", "BERT"], [11, 12, "DatasetName", "MR"]]}, {"text": "Each xis classi\ufb01ed as positive , and each xadvis classi\ufb01ed as negative .", "entities": []}, {"text": "\u270f sem=4 as a general rule : on average , humans should at least \u201c Agree \u201d that xandxadvhave the same meaning .", "entities": []}, {"text": "4.1.2 Automatic Evaluation Automatic evaluation of semantic similarity is a well - studied NLP task .", "entities": [[6, 8, "TaskName", "semantic similarity"]]}, {"text": "The STS Benchmark is used as a common measurement ( Cer et al . , 2017 ) .", "entities": [[1, 3, "DatasetName", "STS Benchmark"]]}, {"text": "Michel et al .", "entities": []}, {"text": "( 2019 ) explored the use of common evaluation metrics for machine translation as a proxy for semantic similarity in the attack setting .", "entities": [[11, 13, "TaskName", "machine translation"], [17, 19, "TaskName", "semantic similarity"]]}, {"text": "While n - gram overlap based approaches are computationally cheap and work well in the machine translation setting , they do not correlate with human judgment as well as sentence encoders ( Wieting and Gimpel , 2018 ) .", "entities": [[15, 17, "TaskName", "machine translation"]]}, {"text": "Some attacks have used sentence encoders to encode two sentences into a pair of \ufb01xed - length vectors , then used the cosine distance between the vectors as a proxy for semantic similarity .", "entities": [[31, 33, "TaskName", "semantic similarity"]]}, {"text": "TEXTFOOLER uses the Universal Sentence Encoder ( USE ) , which achieved a Pearson correlation score of 0.782on the STS benchmark ( Cer et al . , 2018 ) .", "entities": [[7, 8, "MethodName", "USE"], [13, 15, "MetricName", "Pearson correlation"], [19, 21, "DatasetName", "STS benchmark"]]}, {"text": "Another option is BERT \ufb01ne - tuned for semantic similarity , which achieved a score of 0.865 ( Devlin et al . , 2018 ) .", "entities": [[3, 4, "MethodName", "BERT"], [8, 10, "TaskName", "semantic similarity"]]}, {"text": "Additionally , synonym substitution methods , including TEXTFOOLER andGENETIC ATTACK , often require that words be substituted only with neighbors in the counter-\ufb01tted embedding space , which is designed to push synonyms together and antonyms apart ( Mrksic et al . , 2016 ) .", "entities": []}, {"text": "These automatic metrics of similarity produce a score that represents the similarity between xandxadv .", "entities": []}, {"text": "Attacks depend on a minimum threshold value for each metric to determine whether the changes between xandxadvpreserve semantics .", "entities": []}, {"text": "Human evaluation is needed to \ufb01nd threshold values such that people generally \u201d agree \u201d that semantics is preserved .", "entities": []}, {"text": "4.1.3 Case Study To quantify semantic similarity of xandxadv , we asked users whether they agreed that the changes between the two passages preserved meaning on a scale of 1 ( Strongly Disagree ) to 5 ( Strongly Agree ) .", "entities": [[5, 7, "TaskName", "semantic similarity"]]}, {"text": "We averaged scores for each attack method to determine if the method generally preserves semantics .", "entities": []}, {"text": "Perturbations generated by TEXTFOOLER were rated an average of 3.28 , while perturbations generated by GENETIC ATTACK were rated on average 2.70.8The average rating given for both methods was signi\ufb01cantly less than our proposed \u270f semof4 .", "entities": []}, {"text": "Using a clear survey question illustrates that humans , on average , do n\u2019t assess these perturbations as semantics - preserving .", "entities": []}, {"text": "8We hypothesize that TEXTFOOLER achieved higher scores due to its use of USE .", "entities": [[12, 13, "MethodName", "USE"]]}, {"text": "38344.2 Evaluation of Grammaticality 4.2.1 Human Evaluation Both Jin et al .", "entities": []}, {"text": "( 2019 ) and Iyyer et al .", "entities": []}, {"text": "( 2018 ) reported a human evaluation of grammaticality , but neither study clearly asked if any errors were introduced by a perturbation .", "entities": []}, {"text": "For human evaluation of the grammaticality constraint , we propose presenting xandxadvtogether and asking judges if grammatical errors were introduced by the changes made .", "entities": []}, {"text": "However , due to the rule - based nature of grammar , automatic evaluation is preferred .", "entities": []}, {"text": "4.2.2 Automatic Evaluation The simplest way to automatically evaluate grammatical correctness is with a rule - based grammar checker .", "entities": []}, {"text": "Free grammar checkers are available online in many languages .", "entities": []}, {"text": "One popular checker is LanguageTool , an open - source proofreading tool ( Naber , 2003 ) .", "entities": []}, {"text": "LanguageTool ships with thousands of human - curated rules for the English language and provides an interface for identifying grammatical errors in sentences .", "entities": []}, {"text": "LanguageTool uses rules to detect grammatical errors , statistics to detect uncommon sequences of words , and language model perplexity to detect commonly confused words .", "entities": [[19, 20, "MetricName", "perplexity"]]}, {"text": "4.2.3 Case Study We ran each of the generated ( x , xadv)pairs through LanguageTool to count grammatical errors .", "entities": []}, {"text": "LanguageTool detected more grammatical errors inxadvthan xfor50 % of perturbations generated byTEXTFOOLER , and 32 % of perturbations generated by G ENETIC ATTACK .", "entities": []}, {"text": "Additionally , perturbations often contain errors that humans rarely make .", "entities": []}, {"text": "LanguageTool detected 6 categories for which errors in the perturbed samples appear at least 10 times more frequently than in the original content .", "entities": []}, {"text": "Details regarding these error categories and examples of violations are shown in Table 4 . 4.3 Evaluation of Non - suspicion 4.3.1 Human Evaluation We propose evaluation of non - suspicion by having judges view a shuf\ufb02ed mix of real and adversarial inputs and guess whether each is real or computer - altered .", "entities": []}, {"text": "This is similar to the human evaluation done by Ren et al .", "entities": []}, {"text": "( 2019 )", "entities": []}, {"text": ", but we formulate it as a binary classi\ufb01cation task rather than on a 1 - 5 scale .", "entities": []}, {"text": "A perturbed example xadvis notsuspicious if the percentage of judges who identifyxadvas computer - altered is at most \u270f ns , where 0\uf8ff \u270f ns\uf8ff1 .", "entities": []}, {"text": "4.3.2 Automatic Evaluation Automatic evaluation may be used to guess whether or not an adversarial example is suspicious .", "entities": []}, {"text": "Models can be trained to classify passages as real or perturbed , just as human judges do .", "entities": []}, {"text": "For example , Warstadt et al .", "entities": []}, {"text": "( 2018 ) trained sentence encoders on a real / fake task as a proxy for evaluation of linguistic acceptability .", "entities": [[18, 20, "TaskName", "linguistic acceptability"]]}, {"text": "Recently , Zellers et al .", "entities": []}, {"text": "( 2019 ) demonstrated that GROVER , a transformer - based text generation model , could classify its own generated news articles as human or machine - written with high accuracy .", "entities": [[11, 13, "TaskName", "text generation"], [30, 31, "MetricName", "accuracy"]]}, {"text": "4.3.3 Case Study We presented a shuf\ufb02ed mix of real and perturbed examples to human judges and asked if they were real or computer - altered .", "entities": []}, {"text": "As this is a time - consuming task for long documents , we only evaluated adversarial examples generated by TEXTFOOLER on the sentence - level MR dataset .", "entities": [[25, 26, "DatasetName", "MR"]]}, {"text": "If all generated examples were non - suspicious , judges would average 50 % accuracy , as they would not be able to distinguish between real and perturbed examples .", "entities": [[14, 15, "MetricName", "accuracy"]]}, {"text": "In this case , judges achieved 69.2 % accuracy .", "entities": [[8, 9, "MetricName", "accuracy"]]}, {"text": "5Producing Higher Quality Adversarial Examples In Section 4 , we evaluated how well generated examples met constraints .", "entities": []}, {"text": "We found that although attacks in NLP aspire to meet linguistic constraints , in practice , they frequently violate them .", "entities": []}, {"text": "Now , we adjust automatic constraints applied during the course of the attack to produce better quality adversarial examples .", "entities": []}, {"text": "We set out to \ufb01nd if a set of constraint application methods with appropriate thresholds could produce adversarial examples that are semanticspreserving , grammatical and non - suspicious .", "entities": []}, {"text": "We modi\ufb01ed TEXTFOOLER to produce TFA DJUSTED , a new attack with stricter constraint application .", "entities": []}, {"text": "To enforce grammaticality , we added LanguageTool .", "entities": []}, {"text": "To enforce semantic preservation , we tuned two thresholds which \ufb01lter out invalid word substitutions : ( a ) minimum cosine similarity between counter-\ufb01tted word embeddings and ( b ) minimum", "entities": [[24, 26, "TaskName", "word embeddings"]]}, {"text": "3835GrammarRule IDxxadvExplanation ContextTONONBASE2 123", "entities": []}, {"text": "Did you mean \u201c know \u201d ?", "entities": []}, {"text": "\u2014 \u2014 Replace with one of [ know ] ... ees at person they do n\u2019t really want toknewPRPVBG3 112 Did you mean \u201c we \u2019re wanting \u201d , \u201c we are wanting \u201d , or \u201c wewere wanting \u201d ? \u2014 \u2014 Replace with one of [ we\u2019rewanting , we are wanting , we were wanting]whilewe wantingmacdowell \u2019s character to retrieveher h ...", "entities": []}, {"text": "APLURAL20 294 Do n\u2019t use inde\ufb01nite articles with plural words .", "entities": []}, {"text": "Did youmean \u201c a grate \u201d , \u201c a gratis \u201d or simply \u201c grates \u201d ? \u2014 \u2014 Replace with one of [ a grate , a gratis , grates]agrates , lanky \ufb02ickDIDBASEFORM25 328The verb \u2018 ca n\u2019t \u2019 requires base form of this verb : \u201c compare \u201d \u2014 \u2014 Replace with one of [ compare] ... \ufb01rst two cinema in the series , i can\u2019tcomparesfriday after next to them , but nothing ...", "entities": []}, {"text": "PRPVB6 73 Do not use a noun immediately after the pronoun \u2018 it \u2019 .", "entities": []}, {"text": "Usea verb or an adverb , or possibly some other part of speech . \u2014 \u2014 Replace game with one of [ ] ... ble of being gravest , so thick with wry itgamelikea readings from bartlett \u2019s familia ... PRPMDNN4 46", "entities": []}, {"text": "It seems that a verb or adverb has been misspelled or ismissing here .", "entities": []}, {"text": "\u2014 \u2014 Replace with one of [ can beappreciative , can have appreciative] ... y bit as awful as borchardt \u2019s coven , we canappreciativeit anywayNON3PRSVERB7 78", "entities": []}, {"text": "The pronoun \u2019 they \u2019 must be used with a non - third - personform of a verb : \u201c do \u201d \u2014 \u2014 Replace with one of [ do]theydoesa ok operating of painting this family ... Table 4 : Adversarial Examples Contain Uncommon Grammatical Errors .", "entities": []}, {"text": "This table shows grammatical errors detected by LanguageTool that appeared far more often in the perturbed samples .", "entities": []}, {"text": "xandxadvdenote the numbers of errors detected in xandxadvacross 3,115 examples generated by T EXTFOOLER and G ENETIC ATTACK .", "entities": []}, {"text": "cosine similarity between sentence embeddings .", "entities": [[3, 5, "TaskName", "sentence embeddings"]]}, {"text": "Through human studies , we found threshold values of0.9for ( a ) and 0.98for ( b)9 .", "entities": []}, {"text": "We implemented TFA DJUSTED using TextAttack , a Python framework for implementing adversarial attacks in NLP ( Morris et al . , 2020 ) .", "entities": []}, {"text": "5.1 With Adjusted Constraint Application We tested TFA DJUSTED to determine the effect of tightening constraint application .", "entities": []}, {"text": "We used the IMDB , Yelp , and MR datasets for classifcation as in Section 4 .", "entities": [[3, 4, "DatasetName", "IMDB"], [8, 9, "DatasetName", "MR"]]}, {"text": "We added the SNLI and MNLI entailment datasets ( Bowman et al . , 2015 ; Williams et al . , 2018 ) for the portions not requring human evaluation .", "entities": [[3, 4, "DatasetName", "SNLI"], [5, 6, "DatasetName", "MNLI"]]}, {"text": "Table 5shows the results .", "entities": []}, {"text": "Semantics .", "entities": []}, {"text": "TEXTFOOLER generates perturbations for which human judges are on average \u201c Not sure \u201d if semantics are preserved .", "entities": []}, {"text": "With perturbations generated by TFA DJUSTED , human judges on average \u201c Agree \u201d that semantics are preserved .", "entities": []}, {"text": "Grammaticality .", "entities": []}, {"text": "Since all examples produced by TFA DJUSTED are checked with LanguageTool , no perturbation can introduce", "entities": []}, {"text": "grammatical errors.10 Non", "entities": []}, {"text": "-", "entities": []}, {"text": "suspicion .", "entities": []}, {"text": "We repeated the non - suspicion study from Section 4.3with the examples generated by TFA DJUSTED .", "entities": []}, {"text": "Participants were able to guess with 58.8%accuracy whether inputs were computer - altered .", "entities": []}, {"text": "The accuracy is over 10 % lower than the accuracy on the examples generated by 9Details in the appendix , Section A.2.2 .", "entities": [[1, 2, "MetricName", "accuracy"], [9, 10, "MetricName", "accuracy"]]}, {"text": "10Since the MR dataset is already lowercased and tokenized , it is dif\ufb01cult for a rule - based grammar checker like LanguageTool to parse some inputs .", "entities": [[2, 3, "DatasetName", "MR"]]}, {"text": "TEXTFOOLER .", "entities": []}, {"text": "Attack success .", "entities": []}, {"text": "For each of the three datasets , the attack success rate decreased by at least 71 percentage points ( see last row of Table 5 ) .", "entities": []}, {"text": "5.2 Adversarial Training With Higher Quality Examples Using the 9,595samples in the MR training set as seed inputs , TEXTFOOLER generated 7,382 adversarial examples , while TFA DJUSTED generated just825 .", "entities": [[12, 13, "DatasetName", "MR"]]}, {"text": "We append each set of adversarial examples to a copy of the original MR training set and \ufb01ne - tuned a pre - trained BERT model for 10 epochs .", "entities": [[13, 14, "DatasetName", "MR"], [24, 25, "MethodName", "BERT"]]}, {"text": "Figure 2plots the test accuracy over 10 training epochs , averaged over 5 random seeds per dataset .", "entities": [[4, 5, "MetricName", "accuracy"], [14, 15, "DatasetName", "seeds"]]}, {"text": "While neither training method strongly impacts accuracy , the augmentation using TFA DJUSTED has a better impact than that of T EXTFOOLER .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "We then re - ran the two attacks using 1000 examples from the MR test set as seeds .", "entities": [[13, 14, "DatasetName", "MR"], [17, 18, "DatasetName", "seeds"]]}, {"text": "Again averaging over 5 random seeds , we found no signi\ufb01cant change in robustness .", "entities": [[5, 6, "DatasetName", "seeds"]]}, {"text": "That is , models trained on the original MR dataset were approximately as robust as those trained on the datasets augmented with TEXTFOOLER andTFA DJUSTED examples .", "entities": [[8, 9, "DatasetName", "MR"]]}, {"text": "This corroborates the \ufb01ndings of Alzantot et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) and contradicts those of Jin", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "We include further analysis along with some hypotheses for the discrepancies in adversarial training results in A.4 .", "entities": []}, {"text": "3836Datasets\u0000!IMDB Yelp MR SNLI MNLINoteSemantic Preservation ( before)3.41 3.05 3.37\u0000\u0000Semantic Preservation ( after)4.06 3.94 4.18\u0000\u0000Higher value : more preservedGrammatical Error % ( before)52.8 61.2 28.3 26.7 20.1Grammatical Error % ( after)00 0 00Lower value : less mistakesNon - suspicion % ( before)\u0000\u000069.2\u0000\u0000Non - suspicion % ( after)\u0000\u000058.8\u0000\u0000Lower value : less suspiciousAttack Success % ( before)85.0 93.2 86.6 94.5 95.1Attack Success % ( after)13.95.3 10.67.2 14.8Difference ( before - after)71.1 87.9 76.0 87.3 80.3Table 5 : Results from running T EXTFOOLER ( before ) and TFA DJUSTED ( after ) .", "entities": [[2, 3, "DatasetName", "MR"], [3, 4, "DatasetName", "SNLI"], [19, 20, "MetricName", "Error"], [27, 28, "MetricName", "Error"], [31, 32, "DatasetName", "0"]]}, {"text": "Attacks are on BERT classi\ufb01cation models \ufb01ne - tuned for \ufb01ve respective NLP datasets .", "entities": [[3, 4, "MethodName", "BERT"]]}, {"text": "Figure 2 : Accuracy of adversarially trained models on the MR test set .", "entities": [[3, 4, "MetricName", "Accuracy"], [10, 11, "DatasetName", "MR"]]}, {"text": "Augmentation with adversarial examples generated by T EXTFOOLER ( blue ) , although higher in quantity , decreases the overall test accuracy while examples generated by TFA DJUSTED ( orange ) have a small positive effect .", "entities": [[21, 22, "MetricName", "accuracy"]]}, {"text": "Constraint Removed Yelp IMDB MR MNLI SNLI ( Original - all used )", "entities": [[3, 4, "DatasetName", "IMDB"], [4, 5, "DatasetName", "MR"], [5, 6, "DatasetName", "MNLI"], [6, 7, "DatasetName", "SNLI"]]}, {"text": "5.3 13.9 10.6 14.3 7.2 Sentence Encoding 22.9 45.0 28.7 44.4 31.2 Word Embedding 74.6 87.1 52.9 82.7 69.8 Grammar Checking 5.8 15.0 11.6 15.4 9.0 Table 6 : Ablation study : effect of removal of a single constraint on TFA DJUSTED attack success rate .", "entities": []}, {"text": "Attacks against BERT \ufb01ne - tuned on each dataset .", "entities": [[2, 3, "MethodName", "BERT"]]}, {"text": "5.3 Ablation of TFA DJUSTED Constraints TFA DJUSTED generated better quality adversarial examples by constraining its search to exclude examples that fail to meet three constraints : word embedding distance , sentence encoder similarity , and grammaticality .", "entities": []}, {"text": "We performed an ablation study to understand the relative impact of each on attack success rate .", "entities": []}, {"text": "We reran three TFA DJUSTED attacks ( one for each constraint removed ) on each dataset .", "entities": []}, {"text": "Table 6 shows attack success rate after individually removing each constraint .", "entities": []}, {"text": "The word embedding distance constraint was the greatest inhibitor of attack success rate , followed by the sentence encoder.6Comparing Search Methods When an attack \u2019s success rate improves , it may be the result of either ( a ) improvement of the search method for \ufb01nding adversarial perturbations or ( b ) more lenient constraint de\ufb01nitions or constraint application .", "entities": []}, {"text": "TEXTFOOLER achieves a higher success rate than GENETIC ATTACK , but Jin et al .", "entities": []}, {"text": "( 2019 ) did not identify whether the improvement was due to ( a ) or ( b ) .", "entities": []}, {"text": "Since TEXTFOOLER uses both a different search method and different constraint application methods than GENETIC ATTACK , the source of the difference in attack success rates is unclear .", "entities": []}, {"text": "To determine which search method is more effective , we used TextAttack to compose attacks from the search method of GENETIC ATTACK and the constraint application methods of each of TEXTFOOLER andTFA DJUSTED ( Morris et al . , 2020 ) .", "entities": []}, {"text": "With the constraint application held constant , we can identify the source of the difference in attack success rate .", "entities": []}, {"text": "Table 7reveals that the genetic algorithm of GENETIC ATTACK is more successful than the greedy search of TEXTFOOLER at both constraint application levels .", "entities": []}, {"text": "This reveals the source of improvement in attack success rate between GENETIC ATTACK andTEXTFOOLER to be more lenient constraint application .", "entities": []}, {"text": "However , GENETIC ATTACK \u2019s genetic algorithm is far more computationally expensive , requiring over 40x more model queries .", "entities": []}, {"text": "7Discussion Tradeoff between attack success and example quality .", "entities": []}, {"text": "TFA DJUSTED made semantic constraints more selective , which helped attacks generate examples that scored above 4 on the Likert scale for preservation of semantics .", "entities": []}, {"text": "However , this led to a steep drop in attack success rate .", "entities": []}, {"text": "This indicates that , when only allowing adversarial perturbations", "entities": []}, {"text": "3837ConstraintsTFADJUSTEDTEXTFOOLERSearch MethodTEXTFOOLERGENETICATTACKTEXTFOOLERGENETICATTACKSemantic Preservation4.06 4.11 - -Grammatical Error % 00 - -Non - suspicion Score58.8 56.9 - -Attack Success % 10.612.091.195.0Perturbed Word % 11.1 11.018.9 17.2Num", "entities": [[6, 7, "MetricName", "Error"]]}, {"text": "Queries27.14431.677.03225.7Table 7 : Comparison of the search methods from G ENETIC ATTACK and T EXTFOOLER with two sets of constraints ( TEXTFOOLER and TFA DJUSTED ) .", "entities": []}, {"text": "Attacks were run on 1000 samples against BERT \ufb01ne - tuned on the MR dataset .", "entities": [[7, 8, "MethodName", "BERT"], [13, 14, "DatasetName", "MR"]]}, {"text": "GENETIC ATTACK \u2019s genetic algorithm is more successful than T EXTFOOLER \u2019s greedy strategy , albeit much less ef\ufb01cient .", "entities": []}, {"text": "that preserve semantics and grammaticality , NLP models are relatively robust to current synonym substitution attacks .", "entities": []}, {"text": "Note that our set of constraints is n\u2019t necessarily optimal for every attack scenario .", "entities": []}, {"text": "Some contexts may require fewer constraints or less strict constraint application .", "entities": []}, {"text": "Decoupling search methods and constraints .", "entities": []}, {"text": "It is critical that researchers decouple new search methods from new constraint evaluation and constraint application methods .", "entities": []}, {"text": "Demonstrating the performance of a new attack that simultaneously introduces a new search method and new constraints makes it unclear whether empirical gains indicate a more effective attack or a more relaxed set of constraints .", "entities": []}, {"text": "This mirrors a broader trend in machine learning where researchers report differences that come from changing multiple independent variables , making the sources of empirical gains unclear ( Lipton and Steinhardt , 2018 ) .", "entities": []}, {"text": "This is especially relevant in adversarial NLP , where each experiment depends on many parameters .", "entities": []}, {"text": "Towards improved methods for generating textual adversarial examples .", "entities": []}, {"text": "As models improve at paraphrasing inputs , we will be able to explore the space of adversarial examples beyond synonym substitutions .", "entities": []}, {"text": "As models improve at measuring semantic similarity , we will be able to more rigorously ensure that adversarial perturbations preserve semantics .", "entities": [[5, 7, "TaskName", "semantic similarity"]]}, {"text": "It remains to be seen how robust BERT is when subject to paraphrase attacks that rigorously preserve semantics and grammaticality .", "entities": [[7, 8, "MethodName", "BERT"]]}, {"text": "8Related Work The goal of creating adversarial examples that preserve semantics and grammaticality is common in the NLP attack literature ( Zhang et al . , 2019 ) .", "entities": []}, {"text": "However , previous works use different de\ufb01nitions of adversarial examples , making it dif\ufb01cult to compare methods .", "entities": []}, {"text": "We provide a uni\ufb01ed de\ufb01nition ofan adversarial example based on a goal function and a set of linguistic constraints .", "entities": []}, {"text": "Gilmer et al .", "entities": []}, {"text": "( 2018 ) laid out a set of potential constraints for the attack space when generating adversarial examples , which are each useful in different real - world scenarios .", "entities": []}, {"text": "However , they did not discuss NLP attacks in particular .", "entities": []}, {"text": "Michel et al .", "entities": []}, {"text": "( 2019 ) de\ufb01ned a framework for evaluating attacks on machine translation models , focusing on meaning preservation constraints , but restricted their definitions to sequence - to - sequence models .", "entities": [[10, 12, "TaskName", "machine translation"]]}, {"text": "Other research on NLP attacks has suggested various constraints but has not introduced a shared vocabulary and categorization that allows for effective comparisons between attacks .", "entities": []}, {"text": "9Conclusion We showed that two state - of - the - art synonym substitution attacks , TEXTFOOLER andGENETI CATTACK , frequently violate the constraints they claim to follow .", "entities": []}, {"text": "We created TFA DJUSTED , which applies constraints that produce adversarial examples judged to preserve semantics and grammaticality .", "entities": []}, {"text": "Due to the lack of a shared vocabulary for discussing NLP attacks , the source of improvement in attack success rate between TEXTFOOLER and GENETIC ATTACK was unclear .", "entities": []}, {"text": "Holding constraint application constant revealed that the source of TEXTFOOLER \u2019s improvement was lenient constraint application ( rather than a better search method ) .", "entities": []}, {"text": "With a shared framework for de\ufb01ning and applying constraints , future research can focus on developing better search methods and better constraint application techniques for preserving semantics and grammaticality .", "entities": []}, {"text": "3838References Moustafa Alzantot , Yash Sharma , Ahmed Elgohary , Bo - Jhang Ho , Mani Srivastava , and Kai - Wei Chang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Generating natural language adversarial examples .", "entities": []}, {"text": "arXiv preprint arXiv:1804.07998 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Samuel R. Bowman , Gabor Angeli , Christopher Potts , and Christopher D. Manning .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "A large annotated corpus for learning natural language inference .", "entities": [[6, 9, "TaskName", "natural language inference"]]}, {"text": "CoRR , abs/1508.05326 .", "entities": []}, {"text": "Daniel Cer , Mona Diab , Eneko Agirre , I \u02dcnigo LopezGazpio , and Lucia Specia .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "SemEval-2017 task 1 : Semantic textual similarity multilingual and crosslingual focused evaluation .", "entities": [[4, 7, "TaskName", "Semantic textual similarity"]]}, {"text": "In Proceedings of the 11th International Workshop on Semantic Evaluation ( SemEval-2017 ) , pages 1\u201314 , Vancouver , Canada .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Daniel Cer , Yinfei Yang , Sheng yi Kong , Nan Hua , Nicole Limtiaco , Rhomni St. John , Noah Constant , Mario Guajardo - Cespedes , Steve Yuan , Chris Tar , Yun - Hsuan Sung , Brian Strope , and Ray Kurzweil .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Universal sentence encoder .", "entities": []}, {"text": "ArXiv , abs/1803.11175 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Minhao Cheng , Jinfeng Yi , Huan Zhang , Pin - Yu Chen , and Cho - Jui Hsieh . 2018 .", "entities": []}, {"text": "Seq2sick : Evaluating the robustness of sequence - to - sequence models with adversarial examples .", "entities": []}, {"text": "arXiv preprint arXiv:1803.01128 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Michael Denkowski and Alon Lavie .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Meteor universal : Language speci\ufb01c translation evaluation for any target language .", "entities": [[0, 1, "DatasetName", "Meteor"]]}, {"text": "In Proceedings of the Ninth Workshop on Statistical Machine Translation , pages 376\u2013380 , Baltimore , Maryland , USA . Association for Computational Linguistics .", "entities": [[8, 10, "TaskName", "Machine Translation"]]}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2018 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding.arXiv preprint arXiv:1810.04805 .", "entities": []}, {"text": "Javid Ebrahimi , Anyi Rao , Daniel Lowd , and Dejing Dou . 2017 .", "entities": []}, {"text": "Hot\ufb02ip : White - box adversarial examples for text classi\ufb01cation .", "entities": []}, {"text": "arXiv preprint arXiv:1712.06751 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Ji Gao , Jack Lanchantin , Mary Lou Soffa , and Yanjun Qi . 2018 .", "entities": []}, {"text": "Black - box generation of adversarial text sequences to evade deep learning classi\ufb01ers", "entities": [[5, 7, "TaskName", "adversarial text"]]}, {"text": ".", "entities": []}, {"text": "In IEEE Security and Privacy Workshops ( SPW ) .", "entities": []}, {"text": "Justin Gilmer , Ryan P. Adams , Ian J. Goodfellow , David Andersen , and George E. Dahl . 2018 .", "entities": []}, {"text": "Motivating the rules of the game for adversarial example research .CoRR , abs/1807.06732 .", "entities": []}, {"text": "Ian Goodfellow , Nicolas Papernot , Sandy Huang , Rocky Duan , Pieter Abbeel , and Jack Clark .", "entities": []}, {"text": "Attacking machine learning with adversarial examples [ online ] .", "entities": []}, {"text": "2017.Ian J Goodfellow , Jonathon Shlens , and Christian Szegedy .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Explaining and harnessing adversarial examples .", "entities": []}, {"text": "arXiv preprint arXiv:1412.6572 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Po - Sen Huang , Robert Stanforth , Johannes Welbl , Chris Dyer , Dani Yogatama , Sven Gowal , Krishnamurthy Dvijotham , and Pushmeet Kohli .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Achieving veri\ufb01ed robustness to symbol substitutions via interval bound propagation .", "entities": []}, {"text": "ArXiv , abs/1909.01492 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Mohit Iyyer , John Wieting , Kevin Gimpel , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Adversarial example generation with syntactically controlled paraphrase networks .", "entities": []}, {"text": "CoRR , abs/1804.06059 .", "entities": []}, {"text": "Di Jin , Zhijing Jin , Joey Tianyi Zhou , and Peter Szolovits . 2019 .", "entities": []}, {"text": "Is BERT Really Robust ?", "entities": [[1, 2, "MethodName", "BERT"]]}, {"text": "A Strong Baseline for Natural Language Attack on Text Classi\ufb01cation and Entailment .arXiv e - prints , page arXiv:1907.11932 .", "entities": []}, {"text": "V olodymyr Kuleshov , Shantanu Thakoor , Tingfung Lau , and Stefano Ermon .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Adversarial examples for natural language classi\ufb01cation problems .", "entities": []}, {"text": "Jinfeng Li , Shouling Ji , Tianyu Du , Bo Li , and Ting Wang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Textbugger : Generating adversarial text against real - world applications .", "entities": [[3, 5, "TaskName", "adversarial text"]]}, {"text": "arXiv preprint arXiv:1812.05271 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Bin Liang , Hongcheng Li , Miaoqiang Su , Pan Bian , Xirong Li , and Wenchang Shi . 2017 .", "entities": []}, {"text": "Deep text classi\ufb01cation can be fooled .", "entities": []}, {"text": "arXiv preprint arXiv:1704.08006 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "R. Likert . 1932 .", "entities": []}, {"text": "A Technique for the Measurement of Attitudes .", "entities": []}, {"text": "Number nos .", "entities": []}, {"text": "136 - 165 in A Technique for the Measurement of Attitudes .", "entities": []}, {"text": "publisher not identi\ufb01ed .", "entities": []}, {"text": "Zachary Chase Lipton and Jacob Steinhardt .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Troubling trends in machine learning scholarship .", "entities": []}, {"text": "ArXiv , abs/1807.03341 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Paul Michel , Xian Li , Graham Neubig , and Juan Miguel Pino . 2019 .", "entities": []}, {"text": "On evaluation of adversarial perturbations for sequence - to - sequence models .CoRR , abs/1903.06620 .", "entities": []}, {"text": "John X. Morris , Eli Li\ufb02and , Jin Yong Yoo , and Yanjun Qi . 2020 .", "entities": []}, {"text": "Textattack : A framework for adversarial attacks in natural language processing .", "entities": []}, {"text": "Nikola Mrksic , Diarmuid \u00b4 OS\u00b4eaghdha , Blaise Thomson , Milica Gasic , Lina Maria Rojas - Barahona , Pei hao Su , David Vandyke , Tsung - Hsien Wen , and Steve J. Young .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Counter-\ufb01tting word vectors to linguistic constraints .", "entities": []}, {"text": "In HLT - NAACL .", "entities": []}, {"text": "Daniel Naber .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "A rule - based style and grammar checker .", "entities": []}, {"text": "Bo Pang and Lillian Lee . 2005 .", "entities": []}, {"text": "Seeing stars : Exploiting class relationships for sentiment categorization with respect to rating scales .", "entities": []}, {"text": "In Proceedings of the 43rd Annual Meeting of the Association", "entities": []}, {"text": "3839for Computational Linguistics ( ACL\u201905 ) , pages 115 \u2013 124 , Ann Arbor , Michigan .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nicolas Papernot , Patrick McDaniel , Ananthram Swami , and Richard Harang . 2016 .", "entities": []}, {"text": "Crafting adversarial input sequences for recurrent neural networks .", "entities": []}, {"text": "InMilitary Communications Conference , MILCOM 2016 - 2016 IEEE , pages 49\u201354 .", "entities": []}, {"text": "IEEE .", "entities": []}, {"text": "Kishore Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .", "entities": []}, {"text": "Bleu : a method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics , pages 311\u2013318 , Philadelphia , Pennsylvania , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Maja Popovi \u00b4 c. 2015 .", "entities": []}, {"text": "chrF : character n - gram f - score for automatic MT evaluation .", "entities": []}, {"text": "InProceedings of the Tenth Workshop on Statistical Machine Translation , pages 392\u2013395 , Lisbon , Portugal .", "entities": [[7, 9, "TaskName", "Machine Translation"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nils Reimers and Iryna Gurevych .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Sentencebert : Sentence embeddings using siamese bertnetworks .", "entities": [[2, 4, "TaskName", "Sentence embeddings"]]}, {"text": "InProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Shuhuai Ren , Yihe Deng , Kun He , and Wanxiang Che . 2019 .", "entities": []}, {"text": "Generating natural language adversarial examples through probability weighted word saliency .", "entities": []}, {"text": "InProceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 1085\u20131097 , Florence , Italy .", "entities": [[16, 17, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Marco Tulio Ribeiro , Sameer Singh , and Carlos Guestrin .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Semantically equivalent adversarial rules for debugging nlp models .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 856\u2013865 .", "entities": []}, {"text": "Suranjana Samanta and Sameep Mehta . 2017 .", "entities": []}, {"text": "Towards crafting text adversarial samples .", "entities": []}, {"text": "arXiv preprint arXiv:1707.02812 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Alex Warstadt , Amanpreet Singh , and Samuel R. Bowman .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Neural network acceptability judgments .", "entities": []}, {"text": "CoRR , abs/1805.12471 .", "entities": []}, {"text": "John Wieting and Kevin Gimpel .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Paranmt-50 m : Pushing the limits of paraphrastic sentence embeddings with millions of machine translations .", "entities": [[0, 2, "DatasetName", "Paranmt-50 m"], [8, 10, "TaskName", "sentence embeddings"]]}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 451\u2013462 .", "entities": []}, {"text": "Adina Williams , Nikita Nangia , and Samuel Bowman .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A broad - coverage challenge corpus for sentence understanding through inference .", "entities": []}, {"text": "InProceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume1 ( Long Papers ) , pages 1112\u20131122 , New Orleans , Louisiana . Association for Computational Linguistics .", "entities": []}, {"text": "Rowan Zellers , Ari Holtzman , Hannah Rashkin , Yonatan Bisk , Ali Farhadi , Franziska Roesner , and Yejin Choi .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Defending against neural fake news .CoRR , abs/1905.12616 .", "entities": []}, {"text": "Wei Emma Zhang , Quan Z. Sheng , and Ahoud Abdulrahmn F. Alhazmi .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Generating textual adversarial examples for deep learning models : A survey .", "entities": []}, {"text": "CoRR , abs/1901.06796 .", "entities": []}, {"text": "Xiang Zhang , Junbo Zhao , and Yann LeCun . 2015 .", "entities": []}, {"text": "Character - level convolutional networks for text classi\ufb01cation .", "entities": []}, {"text": "In Advances in neural information processing systems , pages 649\u2013657 .", "entities": []}, {"text": "Zhengli Zhao , Dheeru Dua , and Sameer Singh . 2017 .", "entities": []}, {"text": "Generating natural adversarial examples .", "entities": []}, {"text": "arXiv preprint arXiv:1710.11342 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}]