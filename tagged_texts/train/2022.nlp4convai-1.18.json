[{"text": "Proceedings of the 4th Workshop on NLP for Conversational AI , pages 218 - 230 May 27 , 2022 \u00a9 2022 Association for Computational Linguistics Understanding and Improving the Exemplar - based Generation for Open - domain Conversation Seungju Han\u2020 , Beomsu Kim\u2020 , Seokjun Seo\u2020 , Enkhbayar Erdenee\u2020 , Buru Chang\u2217 Hyperconnect { seungju.han,beomsu.kim,seokjun.seo,enkhbayar.erdenee,buru.chang}@hpcnt.com", "entities": []}, {"text": "Abstract Exemplar - based generative models for opendomain conversation produce responses based on the exemplars provided by the retriever , taking advantage of generative models and retrieval models .", "entities": []}, {"text": "However , due to the oneto - many problem of the open - domain conversation , they often ignore the retrieved exemplars while generating responses or produce responses over - fitted to the retrieved exemplars .", "entities": []}, {"text": "To address these advantages , we introduce a training method selecting exemplars that are semantically relevant to the gold response but lexically distanced from the gold response .", "entities": []}, {"text": "In the training phase , our training method first uses the gold response instead of dialogue context as a query to select exemplars that are semantically relevant to the gold response .", "entities": []}, {"text": "And then , it eliminates the exemplars that lexically resemble the gold responses to alleviate the dependency of the generative models on that exemplars .", "entities": []}, {"text": "The remaining exemplars could be irrelevant to the given context since they are searched depending on the gold response .", "entities": []}, {"text": "Thus , our training method further utilizes the relevance scores between the given context and the exemplars to penalize the irrelevant exemplars .", "entities": []}, {"text": "Extensive experiments demonstrate that our proposed training method alleviates the drawbacks of the existing exemplar - based generative models and significantly improves the performance in terms of appropriateness and informativeness .", "entities": []}, {"text": "1 Introduction Exemplar - based generative models ( Wu et al . , 2019 ; Weston et al . , 2018 ; Cai et al . , 2019b ; Gupta et al . , 2021 ) for open - domain conversation combine a retrieval model ( Humeau et al . , 2019 ; Mazare et", "entities": []}, {"text": "al . , 2018 ; Kim et al . , 2021 ) and a generative model ( Adiwardana et al . , 2020 ; Roller et al . , 2021 ; \u2020Equal contribution \u2217Corresponding author Given context A : Do you ever feel like time is just going by way too fast ?", "entities": []}, {"text": "Retrieved exemplar B : It 's hard to get anything done with coworkers around .", "entities": []}, {"text": "Generated responses B : Do you have any hobbies that you like to do   while you 're at work ?", "entities": []}, {"text": "like gardening?(a ) RetNRef ( Weston et al , 2018 ) B :", "entities": []}, {"text": "It 's hard to get things done with coworkers   when you 're busy all the time .(c )", "entities": []}, {"text": "RetNRef w/ CORGE ( Ours)B : OMG ! especially recently .", "entities": []}, {"text": "a week seems like one day .", "entities": []}, {"text": "A :", "entities": []}, {"text": "Yes !", "entities": []}, {"text": "Time especially goes by fast when I 'm working at my job .", "entities": []}, {"text": "I 'm constantly busy .", "entities": []}, {"text": "B :", "entities": []}, {"text": "It 's hard to get around .", "entities": []}, {"text": "anything done with coworkers   gets to get done with anything .(b )", "entities": []}, {"text": "RetNRef ( Roller et al , 2021)\ud835\udefcFigure 1 : Responses generated by the three exemplarbased generative models .", "entities": []}, {"text": "RetNRef ignores the exemplar during response generation , RetNRef \u03b1generates the response highly over - fitted to the exemplar , and RetNRef trained with our training method ( CORGE ) well utilizes the exemplar to produce a more fluent response than that of the others .", "entities": [[5, 7, "TaskName", "response generation"]]}, {"text": "Zhang", "entities": []}, {"text": "et al . , 2020 ; Brown et al . , 2020 ) into a single framework to generate responses in two steps : ( 1 ) the retriever searches an exemplar using the given context as a query , and ( 2 ) the generator produces a response based on the given context and the retrieved exemplar .", "entities": []}, {"text": "Exemplar - based generative models produce more specific responses than vanilla generative models while being more fluent than retrieval models .", "entities": []}, {"text": "Despite their success , exemplar - based generative models have two major shortcomings .", "entities": []}, {"text": "Primitive exemplar - based generative models ( Weston et al . , 2018 ; Cai et al . , 2019a ) tend to entirely ignore the exemplars and produce responses similar to those of vanilla generative models .", "entities": []}, {"text": "This is due to the one - to - many problem ( Li et al . , 2016 ) where there are many possible responses for each dialogue context .", "entities": []}, {"text": "During the training phase , the retrieved exemplar is not helpful for generating the gold response when the exemplar retrieved for the given context is significantly different from the gold response.218", "entities": []}, {"text": "This leads exemplar - based generative models to ignore the exemplar while generating responses , as shown in Figure 1(a ) .", "entities": []}, {"text": "To address this issue , recent exemplar - based generative models utilize the gold response ( Roller et al . , 2021 ) or the slightly perturbed gold response ( Cai et al . , 2019b ) as an exemplar in the training phase .", "entities": []}, {"text": "However , these training methods cause the generator to rely heavily on the retrieved exemplar , i.e. the generator resorts to copying the provided tokens , as shown in Figure 1(b ) .", "entities": []}, {"text": "These two disadvantages of existing exemplar - based generative models can adversely affect the quality of the generated response .", "entities": []}, {"text": "Therefore , we introduce CORGE ( COnnecting Retriever and GEnerator ) , a simple training method of exemplar - based generative models considering the one - to - many problem of the open - domain conversation .", "entities": []}, {"text": "As inspired by Wu et al . ( 2019 ) , CORGE first utilizes the gold response instead of dialogue context as the query for the retriever to select exemplars that are similar to the gold response .", "entities": []}, {"text": "The retrieved exemplars ensure that exemplar - based generative models utilize their semantics while generating the gold response at the training phase .", "entities": []}, {"text": "Since the exemplars are retrieved by the gold response , some of them are lexically identical or too similar to the gold response .", "entities": []}, {"text": "These exemplars lead exemplar - based generative models to be trained to depend on the exemplar heavily .", "entities": []}, {"text": "Thus , CORGE then eliminates the exemplars based on the distance between the exemplars and the gold response to alleviate the dependency of the generative models on the exemplars .", "entities": []}, {"text": "Here , we employ Jaccard similarity to measure the distance ( Guu et al . , 2018 ; Cai et al . , 2019a ; Wu et al . , 2019 ) .", "entities": []}, {"text": "However , as the selected exemplars solely depend on the gold response , some of them may be irrelevant to the given context , which results in exemplar - based generative models still ignoring the retrieved exemplar .", "entities": []}, {"text": "To solve this , CORGE utilizes the relevance scores between the context and the exemplar to weight the relevant exemplars and penalizes irrelevant exemplars to the given context .", "entities": []}, {"text": "Extensive experiments show that CORGE is generally applicable to the existing exemplar - based generative models and improves the quality of generated responses regarding appropriateness and informativeness .", "entities": []}, {"text": "Our main contributions : ( 1 ) We analyze the shortcomings of existing exemplar - based generative models derived from the nature of the opendomain conversation , the one - to - many problem.(2 ) We introduce a training method ( CORGE ) to improve the quality of generated responses by selecting useful exemplars and weighting the exemplars by relevance scores assessed by the retriever .", "entities": []}, {"text": "( 3 ) Through the human evaluation , we demonstrate that CORGE significantly improves the performance of exemplar - based generative models in terms of appropriateness and informativeness .", "entities": []}, {"text": "2 Related Work 2.1 Exemplar - based Generation While generative models have shown remarkable performance on the open - domain conversation , it is well - known that generative models tend to yield uninformative and bland responses ( Li et", "entities": []}, {"text": "al . , 2016 ; Liu et al . , 2016 ; Serban et al . , 2017 ; Li et", "entities": []}, {"text": "al . , 2020 ; Holtzman et al . , 2019 ; Welleck et al . , 2019 ) .", "entities": []}, {"text": "Exemplar - based generative models are introduced to overcome the aforementioned problem generative models suffer .", "entities": []}, {"text": "Wu et al .", "entities": []}, {"text": "( 2019 ) introduce an exemplar - based generative model for open - domain conversation , which retrieves a context - exemplar pair conditioned by the input context and encodes the lexical difference between the input context and the retrieved context to the edit vector .", "entities": []}, {"text": "The response is produced by feeding the exemplar and the edit vector to the generator .", "entities": []}, {"text": "Weston et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) ;", "entities": []}, {"text": "Roller et al . ( 2021 ) also retrieve the exemplar using the given context as a query and concatenate the exemplar with the context , then feed the concatenated exemplar into the generator to produce the final response for the open - domain conversation .", "entities": []}, {"text": "Cai et al .", "entities": []}, {"text": "( 2019a , b ) propose a method that removes the irrelevant information from the exemplar , then uses the masked exemplar to inform the generator to produce the response .", "entities": []}, {"text": "Gupta et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2021 ) condition the generator with the retrieved exemplars and the extracted semantic frames of the exemplars , which improves the coherence of generated responses .", "entities": []}, {"text": "We do not consider this model as a baseline because their model requires an additional semantic frame extractor , and it can be mutually complemented with our proposed training method .", "entities": []}, {"text": "2.2 Knowledge - grounded Generation Knowledge - grounded generation models that utilize retrieved results ( e.g. , relevant documents from Wikipedia ) to generate informative responses have been proposed to perform knowledge - intensive NLP tasks ( e.g. , open - domain question answering ) .", "entities": [[39, 44, "TaskName", "open - domain question answering"]]}, {"text": "The knowledge - grounded generation has a219", "entities": []}, {"text": "Embedding Space Given context \ud835\udc84 Gold response \ud835\udc93 Exemplars \ud835\udc9b \u25cf Where do you live ?", "entities": []}, {"text": "I live in Dallas .", "entities": []}, {"text": "\u2605 Wow , do you live there ?", "entities": []}, {"text": "I live in California .", "entities": []}, {"text": "( b ) Slightly perturbed gold response \ud835\udc9b\ud835\udfd0 \u2660 Wow , do [ MASK ] live there ?", "entities": []}, {"text": "I live in [ MASK ] ( a ) Significantly different response \ud835\udc9b\ud835\udfcffrom\ud835\udc93 \u2665 Dallas is nice to live ! \u2605 \u2660 \u2665 \u25cf Generator Over -fitGeneratorIgnore \u2660 \u25cb Figure 2 : Illustration of the drawbacks of existing exemplar - based generative models .", "entities": []}, {"text": "The black dotted line indicates the boundary of the relevant exemplars to the given context .", "entities": []}, {"text": "similar form with the exemplar - based generation .", "entities": []}, {"text": "However , the main difference is that knowledgegrounded generative models extract the knowledge from external resources to generate the informative response .", "entities": []}, {"text": "Guu et al .", "entities": []}, {"text": "( 2020 ) show the effectiveness of pre - training a knowledge retriever with the largescale language model for open - domain question answering , and Lewis et al .", "entities": [[19, 24, "TaskName", "open - domain question answering"]]}, {"text": "( 2020 ) demonstrate that knowledge - grounded generative models produce more informative and diverse sentences than vanilla generative models on a wide range of knowledgeintensive NLP tasks .", "entities": []}, {"text": "Fan et al .", "entities": []}, {"text": "( 2021 ) similarly propose a knowledge - grounded generative model for response generation , but they do not focus on the open - domain conversation .", "entities": [[12, 14, "TaskName", "response generation"]]}, {"text": "In Method Section , we demonstrate the difference between our approach and knowledge - grounded generative models , and we show that existing knowledge - grounded generative models are not directly applicable to the open - domain conversation in Experiments Section .", "entities": []}, {"text": "3 Preliminaries 3.1 Exemplar - based Generation LetD={(ci , ri)|1\u2264i\u2264n}denote the dialogue dataset , which consists of npairs of context c and response r. Exemplar - based generative models are composed of two components : a retriever R and a generator G.", "entities": []}, {"text": "For a given context ci , the retriever finds the top - scoring exemplar based on the relevance score SR(z , ci)of the exemplar z\u2208R , where Ris a pre - defined response set .", "entities": []}, {"text": "The generator computes the probability of the response for the context ciwhile utilizing the exemplar zas PG(r|ci , z ) .", "entities": []}, {"text": "3.2 Drawbacks of Existing Exemplar - based Generative models As mentioned in Roller et al . ( 2021 ) , the primitive exemplar - based generative model ( Weston et al . , 2018 ) tends to ignore the retrieved exemplar dur - ing response generation due to the one - to - many problem in open - domain conversation ( Li et al . , 2016 ) .", "entities": [[44, 46, "TaskName", "response generation"]]}, {"text": "Since its retriever searches an exemplar based on a given context , the retrieved exemplar is often significantly different from a gold response of the generator , although both of the retrieved exemplar and gold response are relevant to the given context , which is shown in Figure 2(a ) .", "entities": []}, {"text": "As the retrieved exemplar is not helpful for generating the gold response , the generator is trained to ignore the retrieved exemplar and to produce a response using only the given context .", "entities": []}, {"text": "To induce the generator to utilize retrieved exemplars more actively , Roller et al .", "entities": []}, {"text": "( 2021 ) make use of the gold response , and Cai et al .", "entities": []}, {"text": "( 2019b ) use perturbed gold response as an exemplar rather than using retrieved exemplars during the model training .", "entities": []}, {"text": "However , since the exemplar ziand the gold response riare too similar ( as shown in Figure 2(b ) ) , the exemplar - based generative model learns to rely overly on the exemplar .", "entities": []}, {"text": "Eventually , the generator produces a highly over - fitted response to the exemplar by directly copying the tokens of the exemplar .", "entities": []}, {"text": "4 Method We hypothesize that selecting semantically relevant but lexically distanced exemplars from the gold response could solve the drawbacks above .", "entities": []}, {"text": "To validate this hypothesis , we introduce a training method of exemplar - based generative models , called CORGE .", "entities": []}, {"text": "Our proposed training method is illustrated in Figure 3 , and the illustrative examples about the exemplars selected by CORGE are described in Table 1 .", "entities": []}, {"text": "4.1 Selecting Exemplars Semantically Relevant but Lexically Distanced to the Gold Response We describe how CORGE selects semantically relevant but lexically distanced exemplars to the gold220", "entities": []}, {"text": "response .", "entities": []}, {"text": "Conventionally , the retriever selects the exemplars zbased on the relevance score SR(z , ci ) for the given context ci .", "entities": []}, {"text": "However , this searching process could return a significantly different exemplarzfrom the gold response ri , and it induces the generator Gto ignore the retrieved exemplar during response generation .", "entities": [[27, 29, "TaskName", "response generation"]]}, {"text": "Therefore , we select exemplars based on the gold response rito ensure that the generator Gutilizes the exemplars inspired by Wu", "entities": []}, {"text": "et", "entities": []}, {"text": "al ..", "entities": []}, {"text": "We select top- kscoring exemplars based on the score SR\u2032(z , ri ) , which we call kNearest Exemplars ( kNE).1These kNE are more semantically related to the gold response rithan the exemplar obtained by using SR(z , ci ) .", "entities": []}, {"text": "However , some of the selected kNE are lexically identical or too close to the gold response runintentionally since the retriever searches the exemplars based on the gold response .", "entities": []}, {"text": "We observe that using these exemplars also causes the overfitting problem of generated responses ; therefore , the generator excessively copies tokens from the exemplars .", "entities": []}, {"text": "From this , we are motivated to filter out the exemplars which are lexically too close to the gold response and preserve the exemplars properly distanced to the gold response to mitigate the over - fitting problem .", "entities": []}, {"text": "Here , we employ Jaccard similarity to measure the lexical similarity ( Guu et al . , 2018 ; Cai et al . , 2019a ; Wu et al . , 2019 ) between the exemplar and the gold response .", "entities": []}, {"text": "Exemplars are filtered out when their Jaccard distance with the gold response ris larger than 0.6 , and we replace them with the randomly chosen responses from the pre - defined response set R. The threshold of filtering is empirically chosen as 0.6 .", "entities": []}, {"text": "The set of the final exemplars zobtained through these steps is referred to as Zi={zi,1 , zi,2 , \u00b7 \u00b7 \u00b7 , zi , k } .", "entities": []}, {"text": "4.2 Weighting the Selected Exemplars based on the Relevance Score As we select the exemplar totally based on the gold response , some of kNE could be relevant to the gold response ribut irrelevant to the given context ci .", "entities": [[9, 10, "MetricName", "Score"]]}, {"text": "Therefore , we condition the generator with the relevance score of kNE to reward the relevant exemplars and penalize irrelevant exemplars .", "entities": []}, {"text": "Using the retriever R , we calculate the relevance score SR(zi , j , ci)per each selected exemplar zi , j , then apply the softmax function to the relevance score to 1Note that SR(z , c)andSR\u2032(z , ri)use the same retriever , but they are computed differently .", "entities": [[25, 26, "MethodName", "softmax"]]}, {"text": "Please refer to how we calculate the score SR\u2032(z , ri)andSR(z , c)in the Supplementary Materials .", "entities": []}, {"text": "\u2660 \u2660 \u2660 \u2660 \u2660 \u2605 \u2605 \u2605 \u25cf Embedding spacekNEBoundary Jaccard Filter Boundary \u25cf Given Context \u2605 Gold Response \u2660 Selected Exemplars(a ) kNE ( b ) Jaccard filter ( c ) Relevance Score \u25cf \u25cf \u2660 \u2660 \u2660 \u2660 Figure 3 : The procedure of our proposed training method , CORGE .", "entities": [[34, 35, "MetricName", "Score"]]}, {"text": "( a ): Selecting kNE of the gold response rbased on SR\u2032(z , r ) .", "entities": []}, {"text": "( b ): Filtering out the exemplars which are too close to the gold response r. ( c ): Weighting the exemplars zdepending on their normalized relevance scores PR(z , c ) .", "entities": []}, {"text": "obtain the normalized relevance score PR(zi , j , ci ) .", "entities": []}, {"text": "Then we replace the traditional likelihood with the weighted likelihood using the normalized score .", "entities": []}, {"text": "Our final training objective is to minimize the loss function L=/summationtextn i=1L(ri , ci)where : L(ri , ci ) = \u2212log / summationdisplay z\u2208ZiPR(z , ci)PG(ri|ci , z ) ( 1 ) The gradient of the generator Gis calculated as follows : \u2207GL(ri , ci )", "entities": [[8, 9, "MetricName", "loss"]]}, {"text": "= \u2212\u03b1\u00b7/summationdisplay z\u2208ZiPR(z , ci)\u2207G(PG(ri|ci , z)),(2 ) where \u03b1\u22121=/summationtext z\u2208ZiPR(z , ci)PG(ri|ci , z ) .", "entities": []}, {"text": "This equation demonstrates that the gradient of the generatorGis scaled by the normalized relevance score PR(z , ci ) , which indicates that the generator is less updated when the retrieved exemplar zis not relevant to the given context ci .", "entities": []}, {"text": "This procedure helps the model ignore the irrelevant exemplars .", "entities": []}, {"text": "Thus , the generator learns to fetch tokens from the exemplar more easily , which is relevant to the gold response .", "entities": []}, {"text": "Difference between CORGE and Knowledgegrounded generative models The way of leveraging the relevance scores is already employed by knowledge - grounded generative models ( Lewis et al . , 2020 ; Sachan et al . , 2021 ) in open - domain question answering .", "entities": [[39, 44, "TaskName", "open - domain question answering"]]}, {"text": "However , there is a significant difference between our CORGE and knowledgegrounded generative models .", "entities": []}, {"text": "CORGE uses the relevance score PR(z , ci)to penalize the irrelevant exemplars zto the given context cisince the exemplars are retrieved by SR\u2032(z , ri ) .", "entities": []}, {"text": "Knowledgegrounded generative models use it as the latent variable to jointly train the retriever Rand generator", "entities": []}, {"text": "G. Especially , knowledge - grounded generative models also tend to ignore the retrieved exemplars due221", "entities": []}, {"text": "Input Context What kind of animals you take care of ?", "entities": []}, {"text": "Gold Response I work with a variety of animals .", "entities": []}, {"text": "I sometimes work with lions and monkeys .", "entities": []}, {"text": "Context Retrieval Sim PR(z , c ) I raise two dogs .", "entities": []}, {"text": "0.1 0.9 kNE Sim PR(z , c ) I work with a variety of animals .", "entities": []}, {"text": "0.9 0.2 He works with various people .", "entities": []}, {"text": "0.3 0.0 I work with lots of different animals .", "entities": []}, {"text": "0.5 0.3 I do some work with animals they \u2019re amazing creatures.0.3 0.3 Table 1 : Samples of the exemplars selected by CORGE .", "entities": []}, {"text": "Context Retrieval indicates the exemplar retrieved by using the context as a query , and kNEshows the exemplars selected by using the gold response as a query .", "entities": []}, {"text": "Sim measures the lexical similarity between the gold response and the exemplar and PR(z , c)indicates the normalized relevance score calculated by retriever .", "entities": []}, {"text": "to the one - to - many nature in open - domain conversation when the retriever and generator are jointly trained .", "entities": []}, {"text": "On the other hand , we do not perform the joint learning of the retriever and the generator , but freeze the retriever while training the generator .", "entities": []}, {"text": "5 Experiments 5.1 Dataset We utilize the following four datasets used in Roller et al .", "entities": []}, {"text": "( 2021 ) , which are Blended Skill Talk ( BST ) ( Smith et", "entities": [[6, 9, "DatasetName", "Blended Skill Talk"]]}, {"text": "al . , 2020 ) , ConvAI2 ( Zhang et al . , 2018 ) , Empathetic Dialogues ( ED ) ( Rashkin et al . , 2019 ) , and Wizard of Wikipedia ( WoW ) ( Dinan et al . , 2018 ) .", "entities": [[6, 7, "DatasetName", "ConvAI2"], [31, 34, "DatasetName", "Wizard of Wikipedia"]]}, {"text": "To simplify the notation , we denote the concatenated version of these four datasets as BST+ .", "entities": []}, {"text": "We split BST + into train , validation , and test sets following Smith et al .", "entities": []}, {"text": "( 2020 ) .", "entities": []}, {"text": "5.2 Baselines Retrieval and Generative Models Bi - encoder 256 M ( Mazare et", "entities": []}, {"text": "al . , 2018 ) and Blender 90 M ( Roller et al . , 2021 ) are considered as a baseline retrieval model and a baseline generative model .", "entities": [[6, 7, "MethodName", "Blender"]]}, {"text": "Further , they are also employed as a retriever and a generator of the following exemplarbased generative baselines , respectively .", "entities": []}, {"text": "Exemplar - based Generative Models Since our proposed training method is for training exemplar - based generation models , we first consider recent exemplar - based generation models , RetNRef", "entities": []}, {"text": "( Weston et al . , 2018 ) , RetNRef \u03b1(Roller et al . , 2021 ) , andMatToGen ( Cai et al . , 2019b ) , as baselines .", "entities": []}, {"text": "RetNRef concatenates the retrieved exemplar with the given context as the input of the generator to produce the response .", "entities": []}, {"text": "RetNRef \u03b1is the dialogue retrieval version of RetNRef , which adopts \u03b1 - blending to escape from simply ignoring the retrieved exemplars ( \u03b1= 0.5).MatToGen extracts the meaningful tokens from the exemplar to provide them to the generator .", "entities": [[11, 12, "HyperparameterName", "\u03b1"]]}, {"text": "To verify the effectiveness of our training method , we apply CORGE to RetNRef andMatToGen instead of their training method .", "entities": []}, {"text": "They are denoted as RetNRef + CORGE and MatToGen+CORGE , respectively .", "entities": []}, {"text": "Knowledge - grounded Generative Models", "entities": []}, {"text": "Although RAG ( Lewis et al . , 2020 ) and KIF ( Fan et al . , 2021 ) are proposed to perform knowledgegrounded generation tasks , we employ RAG and KIF as baselines since they have a similar form with exemplar - based generative models .", "entities": [[1, 2, "MethodName", "RAG"], [30, 31, "MethodName", "RAG"]]}, {"text": "Our experiments demonstrate that these knowledge - grounded generative models can not be directly applied to the open - domain conversation .", "entities": []}, {"text": "5.3 Evaluation Metrics To verify the effectiveness of our training method CORGE , we conduct a pair - wise comparison through the human evaluation following Weston et al .", "entities": []}, {"text": "( 2018 ) .", "entities": []}, {"text": "We use two criteria : Appropriateness andInformativeness .", "entities": []}, {"text": "Appropriateness measures how the generated response is fluent , logical , and appropriate to the given context .", "entities": []}, {"text": "Informativeness measures how the generated response has meaningful information relevant to the given context .", "entities": []}, {"text": "We use Amazon Mechanical Turk to collect the annotations , and more details are described in the Supplementary Material .", "entities": [[17, 19, "DatasetName", "Supplementary Material"]]}, {"text": "We also employ the automatic evaluation metrics , Perplexity ( PPL ) , Dist - n , and BLEU ( Papineni et", "entities": [[8, 9, "MetricName", "Perplexity"], [18, 19, "MetricName", "BLEU"]]}, {"text": "al . , 2002 ) , to analyze the generated responses of each model .", "entities": []}, {"text": "PPL measures how well the model predicts a response based on the given input context , and lower PPL indicates that the model predicts the response better .", "entities": []}, {"text": "To analyze how much the exemplar - based generative model leverages the retrieved exemplar , we introduce two variants of PPL by utilizing conditional probability when exemplars are given : ( 1 ) PPL golduses the222", "entities": []}, {"text": "Model Names ( A vs. B)Appropriateness ( % ) Informativeness ( % )", "entities": []}, {"text": "Win Rate A win Tie B win Win Rate A win Tie B win RetNRef \u03b1vs .", "entities": []}, {"text": "Bi - encoder 256 M 44.9 32.0 28.7 39.3 47.5 31.3 34.0 34.7 RetNRef \u03b1vs .", "entities": []}, {"text": "Blender 90 M 50.2 37.3 25.7 37.0 53.3 40.3 24.3 35.4 RetNRef + CORGE vs. Bi - encoder 256 M 52.6 34.0 35.3 30.7 51.9 35.7 31.3 33.0 RetNRef + CORGE vs. Blender 90 M 57.7\u221733.7\u221741.7\u221724.6\u221754.6 30.0 45.0 25.0 RetNRef + CORGE vs. RetNRef \u03b1 53.2 30.3 43.0 26.7 51.6 27.7 46.3 26.0 RetNRef + CORGE vs. RetNRef 54.4 41.0 24.7 34.3 53.4 37.0 30.7 32.3 RetNRef + CORGE vs. KIF 57.5\u221737.0\u221735.7\u221727.3\u221750.0 30.0 40.0 30.0 RetNRef + CORGE vs. RAG 53.5 37.7 29.7 32.6 52.1 29.7 43.0 27.3 MatToGen vs. Bi - encoder 256 M 47.1 33.3 29.3 37.4 50.9 36.7 28.0 35.3 MatToGen vs. Blender 90 M 48.1 34.0 29.3 36.7 46.3 31.6 31.7 36.7 MatToGen + CORGE vs. Bi - encoder 256 M 54.2 43.0 20.7 36.3 54.4 41.3 24.0 34.7 MatToGen + CORGE vs. Blender 90 M 58.0\u221735.0\u221739.7\u221725.3\u221758.1\u221736.0\u221738.0\u221726.0\u2217 MatToGen + CORGE vs. MatToGen 52.6 33.3 36.7 30.0 53.3 32.7 38.7 28.6 MatToGen + CORGE vs. KIF 57.1\u221744.0\u221723.0\u221733.0\u221752.5 39.0 25.7 35.3 MatToGen + CORGE vs. RAG 51.6 38.3 25.7 36.0 55.6 41.3 25.7 33.0 Table 2 : Pair - wise human evaluation results show that our proposed training method improves the performance against the existing exemplar - based generation approaches in terms of appropriateness and informativeness .", "entities": [[0, 1, "MethodName", "Blender"], [32, 33, "MethodName", "Blender"], [44, 45, "HyperparameterName", "\u03b1"], [79, 80, "MethodName", "RAG"], [105, 106, "MethodName", "Blender"], [137, 138, "MethodName", "Blender"], [167, 168, "MethodName", "RAG"]]}, {"text": "The win rate is calculated by excluding the tie.\u2217indicates statistical significance ( two - tailed binomial test , p < 0.05 ) .", "entities": []}, {"text": "conditional probability PG(r|c , r ) , which assumes the situation when the gold response is given as an exemplar , and ( 2 ) PPL retuses the conditional probability PG(r|c , z)where zis the retrieved exemplar by using SR\u2032(z , r ) .", "entities": []}, {"text": "Lower PPL golddenotes that the exemplar - based generative model predicts the gold response well when the gold response is given as an exemplar .", "entities": []}, {"text": "Lower PPL retindicates that the exemplar - based generative model well leverages the provided exemplar to predict the gold response .", "entities": []}, {"text": "Dist - n(Li et", "entities": []}, {"text": "al . , 2016 ) is the ratio of distinct ngrams to a total number of n - grams for all the generated responses , which measures the degree of the diversity of the generated responses .", "entities": []}, {"text": "BLEU ( z , r)is adopted to measure the degree of the token overlap between the provided exemplar and the generated response pair ( z , r ) .", "entities": [[0, 1, "MetricName", "BLEU"]]}, {"text": "A higher BLEU ( z , r)score indicates that the generator copies more from the provided exemplar while generating the response .", "entities": [[2, 3, "MetricName", "BLEU"]]}, {"text": "5.4 Implementation Details We provide the details of our implementation in the Supplementary Material .", "entities": [[12, 14, "DatasetName", "Supplementary Material"]]}, {"text": "We will the source codes of CORGE for the reproducibility of the conducted experiments .", "entities": []}, {"text": "6 Experimental Results 6.1 Pair - wise Comparison Results Table 2 shows the pair - wise comparison results through the human evaluation .", "entities": []}, {"text": "When RetNRef and MatToGen adopt our proposed CORGE as theirtraining method , they outperform all baselines except for a case of RetNRef + CORGE vs. KIFon the informativeness .", "entities": []}, {"text": "In detail , RetNRef + CORGE and MatToGen + CORGE show better performance than RetNRef \u03b1andMatToGen , respectively , in both metrics .", "entities": []}, {"text": "Especially , MatToGen + CORGE outperforms Bi - encoder 256 M and exceeds Blender 90 M , while MatToGen performs worse than Bi - encoder 256 M andBlender 90 M .", "entities": [[13, 14, "MethodName", "Blender"]]}, {"text": "Furthermore , CORGE enlarges the win rate of RetNRef \u03b1forBlender 90 M .", "entities": []}, {"text": "These evaluation results demonstrate that CORGE leads the existing exemplar - based generative models to produce more fluent and informative responses .", "entities": []}, {"text": "6.2 Investigating the Exemplar - based Generative Models with Automatic Metrics Through the automatic evaluation , we verify that existing exemplar - based generative models ignore the provided exemplar or generate responses overfitted to the provided exemplar .", "entities": []}, {"text": "As shown in Table 3 , RetNRef", "entities": []}, {"text": "+", "entities": []}, {"text": "CORGE andMatToGen", "entities": []}, {"text": "+ CORGE show lower PPL retthan Blender 90 M , which means that the exemplar - based generative models trained with CORGE make a better prediction of the gold response than Blender 90 M by utilizing the provided exemplar .", "entities": [[6, 7, "MethodName", "Blender"], [31, 32, "MethodName", "Blender"]]}, {"text": "RetNRef + CORGE has a smaller degree of PPL goldand PPL retthan those of RetNRef , which infers RetNRef + CORGE leverages the provided exemplar better than RetNRef .RetNRef", "entities": []}, {"text": "\u03b1has lower PPL gold than RetNRef + CORGE , however , RetNRef \u03b1has higher223", "entities": []}, {"text": "Models PPL gold PPL ret Dist-2 Dist-3 BLEU ( z , r)-2 BLEU ( z , r)-3 Blender 90 M 13.79 13.79 0.236 0.372 - Bi - encoder 256 M - - 0.681 0.881 - RetNRef 8.518 13.37 0.256 0.386 0.030 0.009 RetNRef \u03b1 3.061 16.99 0.530 0.778 0.319 0.201 RetNRef + CORGE 4.863 11.53 0.349 0.520 0.102 0.048 MatToGen 5.291 17.71 0.362 0.567 0.169 0.095 MatToGen + CORGE 5.651 13.45 0.313 0.474 0.069 0.028 RAG 11.84 14.91 0.257 0.390 0.015 0.003 KIF 12.11 15.18 0.238", "entities": [[7, 8, "MetricName", "BLEU"], [12, 13, "MetricName", "BLEU"], [17, 18, "MethodName", "Blender"], [43, 44, "HyperparameterName", "\u03b1"], [75, 76, "MethodName", "RAG"]]}, {"text": "0.363 0.002 0.000 Table 3 : Automatic evaluation results .", "entities": []}, {"text": "Since Blender 90 M can not utilize the exemplar , we report PPL calculated from PG(r|c)in the place of PPL goldand PPL ret .", "entities": [[1, 2, "MethodName", "Blender"]]}, {"text": "PPL retthan RetNRef + CORGE .", "entities": []}, {"text": "This result demonstrates that RetNRef \u03b1does not make good use of the retrieved exemplar except when the gold response is given as the retrieved exemplar .", "entities": []}, {"text": "From this observation , we claim that RetNRef \u03b1generates a response highly over - fitted to the selected exemplar , which is caused by utilizing the gold response as an exemplar in the training phase .", "entities": []}, {"text": "The same goes for MatToGen , where applying CORGE mitigates the over - fitting issue .", "entities": []}, {"text": "Higher Dist- nofRetNRef + CORGE andMatToGen + CORGE compared to Blender 90 M shows that our exemplar - based generative models produce more diverse responses than the vanilla generative model .", "entities": [[10, 11, "MethodName", "Blender"]]}, {"text": "Moreover , RetNRef + CORGE has higher Dist - nthan RetNRef , which shows that utilizing the exemplars helps the generator diversify the responses .", "entities": []}, {"text": "Although RetNRef \u03b1is the only one that achieves comparable Dist- nto that of the vanilla retrieval model , Bi - encoder 256 M , it is derived from an over - fitting to the exemplar considering the gap between PPL goldand PPL ret , resulting in the degradation of appropriateness and informativeness in human evaluation .", "entities": []}, {"text": "Average BLEU ( z , r)scores implicitly measure the overlap between the retrieved exemplar and the generated response ; thus , a higher degree of BLEU ( z , r)indicates that the generator depends more on the retrieved exemplar .", "entities": [[1, 2, "MetricName", "BLEU"], [25, 26, "MetricName", "BLEU"]]}, {"text": "RetNRef shows a negligible BLEU ( z , r)score , which reaffirms that the model is almost not utilizing the retrieved exemplar .", "entities": [[4, 5, "MetricName", "BLEU"]]}, {"text": "RetNRef \u03b1and MatToGen have higher BLEU ( z , r)scores compared to RetNRef + CORGE andMatToGen", "entities": [[5, 6, "MetricName", "BLEU"]]}, {"text": "+ CORGE , respectively , which verifies that the former depends more on the retrieved exemplar than the latter.0 50 100 150 2000.10.20.3 Train stepsStd .", "entities": []}, {"text": "of Relevance ScoresOurs", "entities": []}, {"text": "Ours + joint RAG Figure 4 : The standard deviation of the normalized retriever score gets smaller when we jointly train the retriever for exemplar - based generative models .", "entities": [[3, 4, "MethodName", "RAG"]]}, {"text": "Ours stands for RetNRef + CORGE , and joint indicates jointly training the retriever with the generator .", "entities": []}, {"text": "6.3 Incapability of Knowledge - grounded Generative Models in Open - domain Conversation The automatic evaluation results in Table 3 confirm that knowledge - grounded generative models are ignoring the exemplar .", "entities": []}, {"text": "PPL gold , PPL ret , and Dist- n ofRAG andKIF have a similar degree to those of Blender 90 M , which implies that the exemplars are not providing useful information while generating the response .", "entities": [[18, 19, "MethodName", "Blender"]]}, {"text": "The average BLEU ( z , r)score also has a poor degree , indicating almost no overlap between the retrieved exemplars and the generated responses .", "entities": [[2, 3, "MetricName", "BLEU"]]}, {"text": "We explain that these results are originated from the difference between the open - domain conversation and knowledge - grounded generation tasks .", "entities": []}, {"text": "While training knowledge - grounded generative models , they use PR(z , c)to fetch the external knowledge .", "entities": []}, {"text": "However , the generator also ignores the retrieved exemplar due to the one - to - many nature of the open - domain conversation .", "entities": []}, {"text": "In addition , we observe that jointly training the retriever with the generator causes the retriever stuck in the local minima .", "entities": []}, {"text": "As shown in Figure 4 , the standard deviation of normalized relevance scores PR(z , c)computed by the retriever224", "entities": []}, {"text": "Input ContextA : No way i do it a lot , at least when i am feeling well enough .", "entities": []}, {"text": "B : Awesome .", "entities": []}, {"text": "That \u2019s the only thing i \u2019ll never do .", "entities": []}, {"text": "I do like the outdoors though .", "entities": []}, {"text": "A : I \u2019m a thrill seaker .", "entities": []}, {"text": "Do you like extreme sports ?", "entities": []}, {"text": "Bi - encoder 256 M", "entities": []}, {"text": "I love extreme sports .", "entities": []}, {"text": "Its the only real way I can get the adrenaline boost I need .", "entities": []}, {"text": "Blender 90 M No , I don \u2019 t think I \u2019 ve ever done that .", "entities": [[0, 1, "MethodName", "Blender"]]}, {"text": "I \u2019", "entities": []}, {"text": "d love to though .", "entities": []}, {"text": "Exemplar I love extreme sports .", "entities": []}, {"text": "Its the only real way I can get the adrenaline boost I need .", "entities": []}, {"text": "RetNRef I don \u2019 t really have a lot of time for sports .", "entities": []}, {"text": "I spend most of my free time working .", "entities": []}, {"text": "Exemplar I love extreme sports .", "entities": []}, {"text": "Its the only real way I can get the adrenaline boost I need .", "entities": []}, {"text": "RetNRef \u03b1 I love extreme sports I need the adrenaline boost .", "entities": [[1, 2, "HyperparameterName", "\u03b1"]]}, {"text": "Its the only way I can get the real adrenaline .", "entities": []}, {"text": "Exemplar I love extreme sports .", "entities": []}, {"text": "Its the only real way I can get the adrenaline boost I need .", "entities": []}, {"text": "RetNRef + CORGE I love extreme sports as well .", "entities": []}, {"text": "It \u2019 s a great way to get out and enjoy life .", "entities": []}, {"text": "Exemplar nicde .", "entities": []}, {"text": "KIF I don \u2019 t really have a lot of time for sports .", "entities": []}, {"text": "I spend most of my time working .", "entities": []}, {"text": "Exemplar Do you like sports ?", "entities": []}, {"text": "RAG I don \u2019 t really have a lot of time for sports .", "entities": [[0, 1, "MethodName", "RAG"]]}, {"text": "I spend most of my time working .", "entities": []}, {"text": "Table 4 : Examples for model responses and provided exemplars corresponding to given input contexts .", "entities": []}, {"text": "Models PPL gold PPL ret Dist-2 Dist-3 BLEU ( z , r)-2 BLEU ( z , r)-3 RetNRef + CORGE 4.863 11.53 0.349 0.520 0.102 0.048 RetNRef + CORGE \u2212RS 6.482 11.75 0.316 0.478 0.074 0.031 RetNRef + CORGE \u2212kNE", "entities": [[7, 8, "MetricName", "BLEU"], [12, 13, "MetricName", "BLEU"]]}, {"text": "8.657 13.82 0.250 0.380 0.034 0.010 RetNRef + CORGE \u2212JF 1.698 32.91 0.537 0.785 0.332 0.207 Table 5 : Results of the ablation study .", "entities": []}, {"text": "\u2212RS,\u2212kNE , and \u2212JF denote that relevance score ( RS ) , kNE , and Jaccard filter ( JF ) are removed from CORGE , respectively .", "entities": []}, {"text": "almost gets near zero when the retriever of RAG is jointly trained .", "entities": [[8, 9, "MethodName", "RAG"]]}, {"text": "A smaller standard deviation means the relevance scores are getting flattened .", "entities": []}, {"text": "Although knowledge - grounded generative models empirically have shown that jointly training the retriever and generator improves the performance in knowledge - intensive NLP tasks ( Lewis et al . , 2020 ) , in open - domain conversation , the retrieved exemplars are ignored .", "entities": []}, {"text": "Thus , the retriever learns to produce an uninformative relevance score .", "entities": []}, {"text": "As a result , the retriever collapses , which means the retriever may return inappropriate exemplars to the generator ( also shown in the example of KIF and RAG in Table 4 ) .", "entities": [[28, 29, "MethodName", "RAG"]]}, {"text": "Intriguingly , jointly training the retriever with CORGE also causes the retriever scores to be flattened , as shown in Figure 4 , and we empirically observe the minor collapse of the retriever as we experienced in RAG as well .", "entities": [[37, 38, "MethodName", "RAG"]]}, {"text": "Thus , CORGE does not jointly train the retriever .", "entities": []}, {"text": "6.4 Ablation Study To verify the effectiveness of each component in CORGE , we conduct the ablation study .", "entities": []}, {"text": "In Table 5 , PPL retfrom RetNRef + CORGE is lower than any other ablation counterparts , which confirms each component contributes to predicting the responses .", "entities": []}, {"text": "RetNRef + CORGE \u2212RS and RetNRef + CORGE \u2212kNE have a higher degree ofPPL retand PPL gold , which indicates RSandkNE help the generator to utilize the exemplar while generating the response .", "entities": []}, {"text": "RetNRef + CORGE \u2212JF provides a strong signal of over - fitting , where it has extremely low PPL goldbut exceptionally high PPLret .", "entities": []}, {"text": "Dist- nshows our model produces the most diverse responses among the models except RetNRef + CORGE \u2212JF , where RetNRef + CORGE \u2212JF excessively copies the tokens from the retrieved exemplar .", "entities": []}, {"text": "The average BLEU ( z , r)scores also show the same trend , where reaffirms the effect of the components of CORGE .", "entities": [[2, 3, "MetricName", "BLEU"]]}, {"text": "7 Conclusion In this paper , we introduce a generally applicable training method for exemplar - based generative models to alleviate their disadvantages derived from the one - to - many problem .", "entities": []}, {"text": "Our training method selects exemplars that are semantically relevant but lexically distanced from the gold response and weights those exemplars with the relevance score measured by the retriever .", "entities": []}, {"text": "Through the extensive analysis , including pair - wise human evaluation , we verify that our method improves the performance of existing exemplar - based generative models in terms of appropriateness and informativeness.225", "entities": []}, {"text": "References Daniel Adiwardana , Minh - Thang Luong , David R", "entities": []}, {"text": "So , Jamie Hall , Noah Fiedel , Romal Thoppilan , Zi Yang , Apoorv Kulshreshtha , Gaurav Nemade , Yifeng Lu , et al . 2020 .", "entities": []}, {"text": "Towards a human - like open - domain chatbot .", "entities": [[8, 9, "TaskName", "chatbot"]]}, {"text": "arXiv preprint arXiv:2001.09977 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert - V oss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel Ziegler , Jeffrey Wu , Clemens Winter , Chris Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Language models are few - shot learners .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems , volume 33 , pages 1877\u20131901 .", "entities": []}, {"text": "Curran Associates , Inc.", "entities": []}, {"text": "Deng Cai , Yan Wang , Wei Bi , Zhaopeng Tu , Xiaojiang Liu , Wai Lam , and Shuming Shi . 2019a .", "entities": []}, {"text": "Skeletonto - response : Dialogue generation guided by retrieval memory .", "entities": [[4, 6, "TaskName", "Dialogue generation"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 1219\u20131228 .", "entities": []}, {"text": "Deng Cai , Yan Wang , Wei Bi , Zhaopeng Tu , Xiaojiang Liu , and Shuming Shi . 2019b .", "entities": []}, {"text": "Retrievalguided dialogue response generation via a matchingto - generation framework .", "entities": [[2, 4, "TaskName", "response generation"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 1866\u20131875 .", "entities": []}, {"text": "Emily Dinan , Stephen Roller , Kurt Shuster , Angela Fan , Michael Auli , and Jason Weston .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Wizard of wikipedia : Knowledge - powered conversational agents .", "entities": [[0, 3, "DatasetName", "Wizard of wikipedia"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Angela Fan , Claire Gardent , Chlo\u00e9 Braud , and Antoine Bordes .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Augmenting transformers with knnbased composite memory for dialog .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics , 9:82 \u2013 99 .", "entities": []}, {"text": "Alex Graves . 2012 .", "entities": []}, {"text": "Sequence transduction with recurrent neural networks .", "entities": []}, {"text": "arXiv preprint arXiv:1211.3711 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Prakhar Gupta , Jeffrey P Bigham , Yulia Tsvetkov , and Amy Pavel . 2021 .", "entities": []}, {"text": "Controlling dialogue generation with semantic exemplars .", "entities": [[1, 3, "TaskName", "dialogue generation"]]}, {"text": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 3018\u20133029 .", "entities": []}, {"text": "Kelvin Guu , Tatsunori B Hashimoto , Yonatan Oren , and Percy Liang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Generating sentences byediting prototypes .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics , 6:437\u2013450 .", "entities": []}, {"text": "Kelvin Guu , Kenton Lee , Zora Tung , Panupong Pasupat , and Ming - Wei Chang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Realm : Retrievalaugmented language model pre - training .", "entities": []}, {"text": "arXiv preprint arXiv:2002.08909 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Ari Holtzman , Jan Buys , Li Du , Maxwell Forbes , and Yejin Choi .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The curious case of neural text degeneration .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Samuel Humeau , Kurt Shuster , Marie - Anne Lachaux , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Poly - encoders : Architectures and pre - training strategies for fast and accurate multi - sentence scoring .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Beomsu Kim , Seokjun Seo , Seungju Han , Enkhbayar Erdenee , and Buru Chang .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Distilling the knowledge of large - scale generative models into retrieval models for efficient open - domain conversation .", "entities": []}, {"text": "In Findings of the Association for Computational Linguistics : EMNLP 2021 , pages 3357\u20133373 .", "entities": []}, {"text": "Patrick Lewis , Ethan Perez , Aleksandra Piktus , Fabio Petroni , Vladimir Karpukhin , Naman Goyal , Heinrich K\u00fcttler , Mike Lewis , Wen - tau", "entities": []}, {"text": "Yih , Tim Rockt\u00e4schel , Sebastian Riedel , and Douwe Kiela . 2020 .", "entities": []}, {"text": "Retrieval - augmented generation for knowledgeintensive nlp tasks .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems , volume 33 , pages 9459 \u2013 9474 .", "entities": []}, {"text": "Curran Associates , Inc.", "entities": []}, {"text": "Jiwei Li , Michel Galley , Chris Brockett , Jianfeng Gao , and William B Dolan . 2016 .", "entities": []}, {"text": "A diversity - promoting objective function for neural conversation models .", "entities": []}, {"text": "InProceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 110\u2013119 .", "entities": []}, {"text": "Margaret Li , Stephen Roller , Ilia Kulikov , Sean Welleck , Y - Lan Boureau , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Do n\u2019t say that !", "entities": []}, {"text": "making inconsistent dialogue unlikely with unlikelihood training .", "entities": []}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 4715\u20134728 .", "entities": []}, {"text": "Raymond Li , Samira Kahou , Hannes Schulz , Vincent Michalski , Laurent Charlin , and Chris Pal . 2018 .", "entities": []}, {"text": "Towards deep conversational recommendations .", "entities": []}, {"text": "arXiv preprint arXiv:1812.07617 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Chia - Wei Liu , Ryan Lowe , Iulian Vlad Serban , Mike Noseworthy , Laurent Charlin , and Joelle Pineau .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "How not to evaluate your dialogue system : An empirical study of unsupervised evaluation metrics for dialogue response generation .", "entities": [[17, 19, "TaskName", "response generation"]]}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 2122\u20132132 .", "entities": []}, {"text": "Edward Loper and Steven Bird .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "Nltk : The natural language toolkit .", "entities": []}, {"text": "In In Proceedings of the ACL Workshop on Effective Tools and Methodologies for226", "entities": []}, {"text": "Teaching Natural Language Processing and Computational Linguistics .", "entities": []}, {"text": "Philadelphia : Association for Computational Linguistics .", "entities": []}, {"text": "Pierre - Emmanuel Mazare , Samuel Humeau , Martin Raison , and Antoine Bordes .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Training millions of personalized dialogue agents .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2775\u20132779 .", "entities": []}, {"text": "A. H. Miller , W. Feng , A. Fisch , J. Lu , D. Batra , A. Bordes , D. Parikh , and J. Weston .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Parlai : A dialog research software platform .", "entities": []}, {"text": "arXiv preprint arXiv:1705.06476 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Kishore Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .", "entities": []}, {"text": "Bleu : a method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th annual meeting of the Association for Computational Linguistics , pages 311\u2013318 .", "entities": []}, {"text": "Hannah Rashkin , Eric Michael Smith , Margaret Li , and Y - Lan Boureau .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Towards empathetic opendomain conversation models : A new benchmark and dataset .", "entities": [[9, 11, "DatasetName", "and dataset"]]}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 5370\u20135381 .", "entities": []}, {"text": "Stephen Roller , Emily Dinan , Naman Goyal , Da Ju , Mary Williamson , Yinhan Liu , Jing Xu , Myle Ott , Eric Michael Smith , Y - Lan Boureau , et al . 2021 .", "entities": []}, {"text": "Recipes for building an open - domain chatbot .", "entities": [[7, 8, "TaskName", "chatbot"]]}, {"text": "In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics : Main Volume , pages 300\u2013325 .", "entities": []}, {"text": "Devendra Singh Sachan , Mostofa Patwary , Mohammad Shoeybi , Neel Kant , Wei Ping , William L Hamilton , and Bryan Catanzaro .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "End - to - end training of neural retrievers for open - domain question answering .", "entities": [[10, 15, "TaskName", "open - domain question answering"]]}, {"text": "arXiv preprint arXiv:2101.00408 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Iulian Serban , Tim Klinger , Gerald Tesauro , Kartik Talamadupula , Bowen Zhou , Yoshua Bengio , and Aaron Courville .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Multiresolution recurrent neural networks : An application to dialogue response generation .", "entities": [[9, 11, "TaskName", "response generation"]]}, {"text": "In Proceedings of the AAAI Conference on Artificial Intelligence , volume 31 .", "entities": []}, {"text": "Eric Michael Smith , Mary Williamson , Kurt Shuster , Jason Weston , and Y - Lan Boureau .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Can you put it all together : Evaluating conversational agents \u2019 ability to blend skills .", "entities": []}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 2021\u20132030 .", "entities": []}, {"text": "Sean Welleck , Ilia Kulikov , Stephen Roller , Emily Dinan , Kyunghyun Cho , and Jason Weston .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Neural text generation with unlikelihood training .", "entities": [[1, 3, "TaskName", "text generation"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Jason Weston , Emily Dinan , and Alexander Miller .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Retrieve and refine : Improved sequence generation models for dialogue .", "entities": []}, {"text": "In Proceedings of the 2018 EMNLP Workshop SCAI : The 2nd InternationalWorkshop on Search - Oriented Conversational AI , pages 87\u201392 .", "entities": []}, {"text": "Yu Wu , Furu Wei , Shaohan Huang , Yunli Wang , Zhoujun Li , and Ming Zhou .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Response generation by context - aware prototype editing .", "entities": [[0, 2, "TaskName", "Response generation"]]}, {"text": "In Proceedings of the AAAI Conference on Artificial Intelligence , volume 33 , pages 7281\u20137288 .", "entities": []}, {"text": "Saizheng Zhang , Emily Dinan , Jack Urbanek , Arthur Szlam , Douwe Kiela , and Jason Weston .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Personalizing dialogue agents : I have a dog , do you have pets too ?", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 2204\u20132213 .", "entities": []}, {"text": "Yizhe Zhang , Siqi Sun , Michel Galley , Yen - Chun Chen , Chris Brockett , Xiang Gao , Jianfeng Gao , Jingjing Liu , and William B Dolan .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Dialogpt : Largescale generative pre - training for conversational response generation .", "entities": [[8, 11, "TaskName", "conversational response generation"]]}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics : System Demonstrations , pages 270\u2013278.227", "entities": []}, {"text": "A Implementation Details A.1 How the Retriever Calculates the Scores Our retriever follows the architecture of Biencoder ( Mazare et al . , 2018 ) , and the score SR(z , c)andSR\u2032(z , r)are calculated as follows : SR(z , c ) = d(z)\u00b7q(c ) , SR\u2032(z , r ) = d(z)\u00b7d(r ) , d(z ) = BERT r(z ) , d(r ) = BERT r(r ) , q(c ) = BERT c(c),(3 ) where d(z)andd(r)are encoded vectors produced by response encoder BERT randq(c)is an encoded vector produced by context encoder BERT c.", "entities": [[57, 58, "MethodName", "BERT"], [64, 65, "MethodName", "BERT"], [71, 72, "MethodName", "BERT"], [82, 83, "MethodName", "BERT"], [91, 92, "MethodName", "BERT"]]}, {"text": "The notation R\u2032indicates that it only uses the response encoder instead of using the context encoder together .", "entities": []}, {"text": "CORGE is not limited to use Bi - encoder as a retriever and can be applied to other types of a retriever ( e.g. Poly - encoder ( Humeau et al . , 2019 ) ) .", "entities": []}, {"text": "A.2 Model Details As we mentioned in Section 5.2 , we employ Biencoder 256 M and Blender 90 M as a retriever and a generator of each exemplar - based generative model , respectively .", "entities": [[16, 17, "MethodName", "Blender"]]}, {"text": "For MatToGen , additional MLP layers are added to the retriever , as follows the details in Cai et al .", "entities": [[4, 5, "DatasetName", "MLP"]]}, {"text": "( 2019b )", "entities": []}, {"text": ".", "entities": []}, {"text": "When training the models , weights of the retriever and the generator are initialized with the pre - trained Bi - encoder 256 M and Blender 90 M , respectively , For Blender 90 M , we use the model released by ParlAI ( Miller et al . , 2017 ) , which is fine - tuned on the BST + dataset .", "entities": [[25, 26, "MethodName", "Blender"], [32, 33, "MethodName", "Blender"]]}, {"text": "For Bi - encoder 256 M , we fine - tune the model released by ParlAI on the BST + dataset , and we follow the hyperparameter settings of Humeau et al .", "entities": []}, {"text": "( 2019 ) , which are implemented in the ParlAI library .", "entities": []}, {"text": "The pre - defined response set is constructed from the BST + training set , which contains about 400 K responses .", "entities": []}, {"text": "We use NVIDIA DGX Station A100 for training the models .", "entities": []}, {"text": "A.3 Hyperparameters When training exemplar - based generative models with CORGE , five ( k=5 ) exemplars are utilized for each training instance .", "entities": []}, {"text": "The exemplar - based generators are trained with a batch size of 32 and an initial learning rate of 7e-6 , and the learning rate is decayed in half when the training loss meetsthe plateau .", "entities": [[9, 11, "HyperparameterName", "batch size"], [16, 18, "HyperparameterName", "learning rate"], [23, 25, "HyperparameterName", "learning rate"], [32, 33, "MetricName", "loss"]]}, {"text": "The model is trained until there is no progress in the validation PPL .", "entities": []}, {"text": "A.4 Generation Strategy When we generate samples using generative model , exemplar - based generative models , and knowledgegrounded generative models , we adopt a beam decoding strategy which is widely used in generative models ( Graves , 2012 ) .", "entities": []}, {"text": "Following ( Roller et al . , 2021 ) , we choose a minimum beam length and a beam size as 20 BPE tokens and 10 , respectively , and use tri - gram beam blocking on context and response blocks .", "entities": [[22, 23, "MethodName", "BPE"]]}, {"text": "During the inference phase , both exemplar - based generative models and knowledgegrounded generative models use the top-1 scoring candidate as an exemplar chosen from utilizing the relevance score SR(z , c ) .", "entities": []}, {"text": "B Evaluation Details", "entities": []}, {"text": "We prepare dialogue cases that have three - turn input contexts and the gold response from the BST and evaluate them by human pair - wise comparison and automatic evaluation .", "entities": []}, {"text": "There are 980 test cases , and we randomly choose 100 test cases for the human evaluation .", "entities": []}, {"text": "B.1 Pair - wise Human Evaluation As we described in Section 5.3 , we use Amazon Mechanical Turk to collect the annotations .", "entities": []}, {"text": "Each test case is rated by three annotators to improve the robustness of the evaluation result .", "entities": []}, {"text": "We set a maximum number of annotations per worker in order to reduce the potential bias .", "entities": []}, {"text": "To control the quality of the annotations , we only allowed annotators who satisfy the following requirements to evaluate our results : ( 1 ) HITs approval rate greater than 95 % , ( 2 ) Location is one of Australia , Canada , New Zealand , United Kingdom , and the United States , ( 3 ) Lifetime number of HITs approved greater than 1000 , following Li", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2018 ) .", "entities": []}, {"text": "Figure 5 shows the instructions and the interface for the human evaluation .", "entities": []}, {"text": "To mitigate the bias from the annotator , we randomly shuffle the order of the model and the corresponding response .", "entities": []}, {"text": "B.2 Automatic Evaluation For automatic metrics , we calculate the metric for each case and take the average of those values .", "entities": []}, {"text": "When calculating BLEU , we use sentence_bleu function in nltk python package ( Loper and Bird , 2002).228", "entities": [[2, 3, "MetricName", "BLEU"]]}, {"text": "Figure 5 : The interface of pairwise human evaluation for appropriateness and informativeness .", "entities": []}, {"text": "C Measuring Inference Time We measure how much time spend when the model generates the responses .", "entities": []}, {"text": "When generating the response , Blender 90 M takes 0.481seconds , and RetNRef + CORGE takes 0.523seconds per instance .", "entities": [[5, 6, "MethodName", "Blender"]]}, {"text": "There is only an 8.7%amount of inference time gap between Blender 90 M andRetNRef + CORGE .", "entities": [[10, 11, "MethodName", "Blender"]]}, {"text": "This tells us that exemplar - based generation can significantly improve the quality of responses regarding appropriateness , informativeness , and diversity without increasing the amount of time to generate answers .", "entities": []}, {"text": "We test our model on NVIDIA DGX Station A100 with PyTorch 1.7.1 , CUDA 11.0 , CuDNN 8.0 , and here we adopt the generation strategy we describe above .", "entities": []}, {"text": "When we measure the inference time , we only use a single GPU ( NVIDIA A100 GPU , 40 GB Memory ) , and the inference time is measured as the average inference time of 100 response generations .", "entities": []}, {"text": "D Additional Results We provide additional samples for the retrieved exemplar and the model response from the baselines and our models in Table 6.229", "entities": []}, {"text": "Input ContextA : I crash around 230 to 300 .", "entities": []}, {"text": "I do n\u2019t have much of a social life .", "entities": []}, {"text": "B : Neither do I , you are not alone A : I am alone but I \u2019m not lonely .", "entities": []}, {"text": "I have a dog who \u2019s great company .", "entities": []}, {"text": "Bi - encoder 256 M", "entities": []}, {"text": "Any friends ?", "entities": []}, {"text": "My dog is one of mine .", "entities": []}, {"text": "Blender 90 M That \u2019s good to hear , I \u2019 ve a dog too , he \u2019 s my best friend .", "entities": [[0, 1, "MethodName", "Blender"]]}, {"text": "Exemplar Any friends ?", "entities": []}, {"text": "My dog is one of mine .", "entities": []}, {"text": "RetNRef I am sorry to hear that .", "entities": []}, {"text": "Do you have any hobbies that you like to do ?", "entities": []}, {"text": "RetNRef", "entities": []}, {"text": "\u03b1", "entities": [[0, 1, "HyperparameterName", "\u03b1"]]}, {"text": "My dog is one of my friends ?", "entities": []}, {"text": "Is yours one of any of his friends ?", "entities": []}, {"text": "lol .", "entities": []}, {"text": "RetNRef +", "entities": []}, {"text": "CORGE What kind of dog is it ?", "entities": []}, {"text": "I \u2019 ve got a chihuahua and she \u2019 s my best friend .", "entities": []}, {"text": "Exemplar I love dogs too .", "entities": []}, {"text": "My best friend is my dog .", "entities": []}, {"text": "MatToGen", "entities": []}, {"text": "I love my best friend , he \u2019 s the best dog I \u2019ve ever had .", "entities": []}, {"text": "What is your best friend ?", "entities": []}, {"text": "MatToGen +", "entities": []}, {"text": "CORGE I love dogs too , my best friend is my dog .", "entities": []}, {"text": "Do you have any hobbies ?", "entities": []}, {"text": "Exemplar nicde .", "entities": []}, {"text": "KIF I am sorry to hear that .", "entities": []}, {"text": "Do you have any hobbies that you like to do ?", "entities": []}, {"text": "Exemplar I \u2019m usually alone because I do n\u2019t like my family .", "entities": []}, {"text": "RAG I am sorry to hear that .", "entities": [[0, 1, "MethodName", "RAG"]]}, {"text": "Do you have any hobbies that you like to do ?", "entities": []}, {"text": "Input ContextA : Sounds like a horror movie , my favorite kind B :", "entities": []}, {"text": "Haha , yeah he melts my heart .", "entities": []}, {"text": "A : Did you do anything fun for Halloween ?", "entities": []}, {"text": "Bi - encoder 256 M I enjoy Halloween , it \u2019s fun to dress up .", "entities": []}, {"text": "Do you like it ?", "entities": []}, {"text": "Blender 90 M I went to a halloween party with my friends .", "entities": [[0, 1, "MethodName", "Blender"]]}, {"text": "It was a lot of fun .", "entities": []}, {"text": "What about you ?", "entities": []}, {"text": "Exemplar I enjoy Halloween , it \u2019s fun to dress up .", "entities": []}, {"text": "Do you like it ?", "entities": []}, {"text": "RetNRef", "entities": []}, {"text": "No , I don \u2019 t think I could do it .", "entities": []}, {"text": "I \u2019 m not a big fan of halloween .", "entities": []}, {"text": "RetNRef", "entities": []}, {"text": "\u03b1 I like it , it \u2019 s fun to dress up .", "entities": [[0, 1, "HyperparameterName", "\u03b1"]]}, {"text": "Do you like halloween ?", "entities": []}, {"text": "I enjoy dressing up .", "entities": []}, {"text": "RetNRef +", "entities": []}, {"text": "CORGE I like to dress up as a clown , but I don \u2019 t think I \u2019 ll be doing that this year .", "entities": []}, {"text": "Exemplar", "entities": []}, {"text": "No we went to a haunted house", "entities": []}, {"text": "and I got chased often .", "entities": []}, {"text": "MatToGen", "entities": []}, {"text": "No we never got to go to the haunted house we went to once and got chased by a ghost .", "entities": []}, {"text": "MatToGen +", "entities": []}, {"text": "CORGE", "entities": []}, {"text": "No , I don \u2019 t like to go to haunted houses .", "entities": []}, {"text": "I \u2019 m scared of them .", "entities": []}, {"text": "Exemplar nicde .", "entities": []}, {"text": "KIF", "entities": []}, {"text": "Yes , I went to a haunted house and watched all the horror movies .", "entities": []}, {"text": "It was so scary !", "entities": []}, {"text": "Exemplar Are you doing anything cool for halloween", "entities": []}, {"text": "RAG", "entities": [[0, 1, "MethodName", "RAG"]]}, {"text": "No , I don \u2019 t think I \u2019 m going to .", "entities": []}, {"text": "I \u2019 ve never been a fan of halloween .", "entities": []}, {"text": "Input ContextA :", "entities": []}, {"text": "Oh God no !", "entities": []}, {"text": "I ca n\u2019t stay tied down to one woman .", "entities": []}, {"text": "Why would you want to do that ?", "entities": []}, {"text": "B : I know right ?", "entities": []}, {"text": "Most people consider marriage to be involving 2 people but in certain parts of the world that varies between cultures and religions , so it does n\u2019t seem so bad", "entities": []}, {"text": "A : Marriage is very good .", "entities": []}, {"text": "Bi - encoder 256 M I agree , but in some cultures , marriage is recommended and unmarried folks are frowned upon !", "entities": []}, {"text": "Blender 90 M I agree !", "entities": [[0, 1, "MethodName", "Blender"]]}, {"text": "I \u2019 m not sure if i could do it though .", "entities": []}, {"text": "I don \u2019 t think I could .", "entities": []}, {"text": "Exemplar I agree , but in some cultures , marriage is recommended and unmarried folks are frowned upon !", "entities": []}, {"text": "RetNRef I agree .", "entities": []}, {"text": "I think it \u2019 s important for people to have a healthy relationship with each other .", "entities": []}, {"text": "RetNRef \u03b1 I agree , but some folks are recommended to marry in some cultures , and some are frown upon !", "entities": [[1, 2, "HyperparameterName", "\u03b1"]]}, {"text": "RetNRef + CORGE I agree !", "entities": []}, {"text": "In some cultures marriage is recommended , but in some countries it \u2019 s not recommended .", "entities": []}, {"text": "Exemplar I agree .", "entities": []}, {"text": "I think it \u2019 s important for people to have a healthy relationship with each other .", "entities": []}, {"text": "MatToGen", "entities": []}, {"text": "I agree , some cultures are more strict than others , but i agree that some religions are more lenient .", "entities": []}, {"text": "MatToGen + CORGE I agree !", "entities": []}, {"text": "In some cultures marriage is recommended by some religions , but I don \u2019 t believe in it !", "entities": []}, {"text": "Exemplar nicde .", "entities": []}, {"text": "KIF I agree !", "entities": []}, {"text": "I think it \u2019 s important to remember that marriage is a legal , social , and financial union .", "entities": []}, {"text": "Exemplar That is good and great RAG I agree !", "entities": [[6, 7, "MethodName", "RAG"]]}, {"text": "I think it \u2019 s important for people to have a healthy relationship with each other .", "entities": []}, {"text": "Table 6 : Additional examples for model responses and provided exemplars corresponding to given input contexts.230", "entities": []}]