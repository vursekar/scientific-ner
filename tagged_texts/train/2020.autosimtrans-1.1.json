[{"text": "Proceedings of the 1st Workshop on Automatic Simultaneous Translation , pages 1\u20139 July 10 , 2020 .", "entities": [[8, 9, "TaskName", "Translation"]]}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics1Dynamic Sentence Boundary Detection for Simultaneous Translation Ruiqing Zhang Baidu , Inc. , / Beijing , China zhangruiqing01@baidu.comChuanqiang Zhang Baidu , Inc. , / Beijing ,", "entities": [[6, 8, "TaskName", "Boundary Detection"], [10, 11, "TaskName", "Translation"]]}, {"text": "China zhangchuanqiang@baidu.com", "entities": []}, {"text": "Abstract Simultaneous Translation is a great challenge in which translation starts before the source sentence \ufb01nished .", "entities": [[2, 3, "TaskName", "Translation"]]}, {"text": "Most studies take transcription as input and focus on balancing translation quality and latency for each sentence .", "entities": []}, {"text": "However , most ASR systems can not provide accurate sentence boundaries in realtime .", "entities": []}, {"text": "Thus it is a key problem to segment sentences for the word streaming before translation .", "entities": []}, {"text": "In this paper , we propose a novel method for sentence boundary detection that takes it as a multi - class classi\ufb01cation task under the endto - end pre - training framework .", "entities": [[11, 13, "TaskName", "boundary detection"]]}, {"text": "Experiments show signi\ufb01cant improvements both in terms of translation quality and latency .", "entities": []}, {"text": "1 Introduction Simultaneous Translation aims to translate the speech of a source language into a target language as quickly as possible without interrupting the speaker .", "entities": [[3, 4, "TaskName", "Translation"]]}, {"text": "Typically , a simultaneous translation system is comprised of an auto - speech - recognition ( ASR ) model and a machine translation ( MT ) model .", "entities": [[12, 15, "TaskName", "speech - recognition"], [21, 23, "TaskName", "machine translation"]]}, {"text": "The ASR model transforms the audio signal into the text of source language and the MT model translates the source text into the target language .", "entities": []}, {"text": "Recent studies on simultaneous translation ( Cho and Esipova , 2016 ; Ma et al . , 2019 ; Arivazhagan et al . , 2019 ) focus on the trade - off between translation quality and latency .", "entities": []}, {"text": "They explore a policy that determines when to begin translating with the input of a stream of transcription .", "entities": []}, {"text": "However , there is a gap between transcription and ASR that some ASR model does n\u2019t provide punctuations or can not provide accurate punctuation in realtime , while the transcription is always well - formed .", "entities": []}, {"text": "See Figure 1 for illustration .", "entities": []}, {"text": "Without sentence boundaries , the state - of - the - art wait - k model takes insuf\ufb01cient text as input and produces an incorrect translation .", "entities": []}, {"text": "Therefore , sentence boundary detection ( or sentence segmentation)1plays an important role to narrow the gap between the ASR and transcription .", "entities": [[3, 5, "TaskName", "boundary detection"]]}, {"text": "A good segmentation will not only improve translation quality but also reduce latency .", "entities": []}, {"text": "Studies of sentence segmentation falls into one of the following two bins : \u000fThe strategy performs segmentation from a speech perspective .", "entities": [[2, 4, "TaskName", "sentence segmentation"]]}, {"text": "F \u00a8ugen et al .", "entities": []}, {"text": "( 2007 ) and Bangalore et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2012 ) used prosodic pauses in speech recognition as segmentation boundaries .", "entities": [[7, 9, "TaskName", "speech recognition"]]}, {"text": "This method is effective in dialogue scenarios , with clear silence during the conversation .", "entities": []}, {"text": "However , it does not work well in long speech audio , such as lecture scenarios .", "entities": []}, {"text": "According to Venuti ( 2012 ) , silence - based chunking accounts for only 6.6 % , 10 % , and 17.1 % in English , French , and German , respectively .", "entities": [[10, 11, "TaskName", "chunking"]]}, {"text": "Indicating that in most cases , it can not effectively detect boundaries for streaming words .", "entities": []}, {"text": "\u000fThe strategy takes segmentation as a standard text processing problem .", "entities": []}, {"text": "The studies considered the problem as classi\ufb01cation or sequence labeling , based on SVM , ( Sridhar et al . , 2013 ) conditional random \ufb01led ( CRFs ) ( Lu and Ng , 2010 ; Wang et al . , 2012 ; Uef\ufb01ng et al . , 2013 ) .", "entities": [[13, 14, "MethodName", "SVM"]]}, {"text": "Other researches utilized language model , either based on N - gram ( Wang et al . , 2016 ) or recurrent neural network ( RNN)(Tilk and Alum \u00a8ae , 2015 ) .", "entities": []}, {"text": "In this paper , we use classi\ufb01cation to solve the problem of sentence segmentation from the perspective of text .", "entities": [[12, 14, "TaskName", "sentence segmentation"]]}, {"text": "Instead of predicting a sentence boundary for a certain position , we propose a multiposition boundary prediction approach .", "entities": []}, {"text": "Speci\ufb01cally , for a source text x", "entities": []}, {"text": "= fx1;:::;x Tg , we calculate the probability of predicting sentence boundary 1We use both terms interchangeably in this paper .", "entities": []}, {"text": "2 src One of two things is going to happen .", "entities": []}, {"text": "Either it \u2019s going to \u2026", "entities": []}, {"text": "Reference Eines von zwei", "entities": []}, {"text": "Dingen wird passieren .", "entities": []}, {"text": "Entweder wird ...", "entities": []}, {"text": "wait3 Eines von zwei", "entities": []}, {"text": "Dingen wird passieren .", "entities": []}, {"text": "Entweder wird \u2026 src without   boundary One of two things is going to happen either it \u2019s going to \u2026 wait3", "entities": []}, {"text": "Eines von zwei", "entities": []}, {"text": "Dingen wird passieren entweder es ist geht dass \u2026 Figure 1 : An English - to - German example that translates from a streaming source with and without sentence boundaries .", "entities": []}, {"text": "We take the wait - K model ( Ma et al . , 2019 ) for illustration , K=3 here .", "entities": []}, {"text": "The wait3 model \ufb01rst performs three READ ( wait ) action at the beginning of each sentence ( as shown in blue ) , and then alternating one READ with one WRITE action in the following steps .", "entities": []}, {"text": "Given the input source without sentence boundaries ( in the 4thline ) , the wait3 model ( in the 5thline ) does n\u2019t take the three READ action at the beginning of following sentences .", "entities": []}, {"text": "Therefore , the English phrase \u201c it \u2019s going to \u201d , which should have been translated as \u201c wird \u201d , produced a meaningless translation \u201c es ist geht dass \u201d with limited context during wait3 model inference .", "entities": []}, {"text": "afterxt , t = T;T\u00001;:::;T\u0000M. Thus the latency of translation can be controlled within L+M words , where Lis the length of the sentence .", "entities": []}, {"text": "Inspired by the recent pre - training techniques ( Devlin et al . , 2019 ; Sun et al . , 2019 ) that successfully used in many NLP tasks , we used a pre - trained model for initialization and \ufb01ne - tune the model on the source side of the sentence .", "entities": [[0, 1, "DatasetName", "Inspired"]]}, {"text": "Overall , the contributions are as follows : \u000fWe propose a novel sentence segmentation method based on pre - trained language representations , which have been successfully used in various NLP tasks .", "entities": [[12, 14, "TaskName", "sentence segmentation"]]}, {"text": "\u000fOur method dynamically predicts the boundary at multiple locations , rather than a speci\ufb01c location , achieving high accuracy with low latency .", "entities": [[18, 19, "MetricName", "accuracy"]]}, {"text": "2 Background Recent studies show that the pre - training and \ufb01netuning framework achieves signi\ufb01cant improvements in various NLP tasks .", "entities": []}, {"text": "Generally , a model is \ufb01rst pre - trained on large unlabeled data .", "entities": []}, {"text": "After that , on the \ufb01ne - tuning step , the model is initialized by the parameters obtained by the pre - training step and \ufb01ne - tuned using labeled data for speci\ufb01c tasks .", "entities": []}, {"text": "Devlin et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) proposed a generalized framework BERT , to learn language representations based on a deep Transformer ( Vaswani et al . , 2017 ) encoder .", "entities": [[7, 8, "MethodName", "BERT"], [17, 18, "MethodName", "Transformer"]]}, {"text": "Rather than traditionally train a language model from - left - to - right or from - rightto - left , they proposed a masked language model ( MLM ) that randomly replace some tokens in a sequence by a placeholder ( mask ) and trained the model to predict the original tokens .", "entities": [[28, 29, "DatasetName", "MLM"]]}, {"text": "They also pre - train the model for the next sentence prediction(NSP ) task that is to predict whether a sentence is the subsequent sentence of the \ufb01rst sentence .", "entities": []}, {"text": "Sun et al .", "entities": []}, {"text": "( 2019 ) proposed a pre - training framework ERNIE , by integrating more knowledge .", "entities": []}, {"text": "Rather than masking single tokens , they proposed to mask a group of words on different levels , such as entities , phrases , etc .", "entities": []}, {"text": "The model achieves state - of - theart performances on many NLP tasks .", "entities": []}, {"text": "In this paper , we train our model under the ERNIE framework .", "entities": []}, {"text": "3 Our Method Given a streaming input", "entities": []}, {"text": "x = fx1;:::;x t;:::;x Tg , the task of sentence segmentation is to determine whetherxt2xis the end of a sentence .", "entities": [[9, 11, "TaskName", "sentence segmentation"]]}, {"text": "Thus the task can be considered as a classi\ufb01cation problem , that isp(ytjx;\u0012 ) , whereyt2", "entities": []}, {"text": "f0;1 g. However , in simultaneous translation scenario , the latency is unacceptable if we take the full source text as contextual information .", "entities": []}, {"text": "Thus we should limit the context size and make a decision dynamically .", "entities": [[5, 7, "HyperparameterName", "context size"]]}, {"text": "As the input is a word streaming , the sentence boundary detection problem can be transformed as , whether there exists a sentence boundary until the current word xt .", "entities": [[10, 12, "TaskName", "boundary detection"]]}, {"text": "Thus we can use the word streaming as a context to make a prediction .", "entities": []}, {"text": "We propose a multi - class classi\ufb01cation model to predict the probability of a few words before xtas sentence boundaries ( Section 3.1 ) .", "entities": []}, {"text": "We use the ERNIE framework to \ufb01rst pre - train a language representation and then \ufb01ne - tune it to sentence boundary detection ( Section 3.2 ) .", "entities": [[21, 23, "TaskName", "boundary detection"]]}, {"text": "We also propose a dynamic voted inference strategy ( Section 3.3 ) .", "entities": []}, {"text": "3.1 The Model For a streaming input", "entities": []}, {"text": "x = fx1;:::;x tg , our goal is to detect whether there is a sentence boundary", "entities": []}, {"text": "3 \ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc65\ud835\udc650\ud835\udc65\ud835\udc651\ud835\udc65\ud835\udc652 \u2026 \ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22122\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22121\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61 \ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c \u2026 \u210e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\u210e\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\ud835\udc38\ud835\udc38\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc38\ud835\udc380\ud835\udc38\ud835\udc381\ud835\udc38\ud835\udc382 \u2026 \ud835\udc38\ud835\udc38\ud835\udc61\ud835\udc61\u22122\ud835\udc38\ud835\udc38\ud835\udc61\ud835\udc61\u22121\ud835\udc38\ud835\udc38\ud835\udc61\ud835\udc61 \u2026 \u2026 \u2026 \ud835\udc42\ud835\udc42\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\ud835\udc36\u03d5 0\u22121\u22122 Classes   \ud835\udc36\ud835\udc36\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc46\ud835\udc46\ud835\udc4e\ud835\udc4e\ud835\udc65\ud835\udc65 Masked Language Model\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c \u2026 \u210e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\u210e\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61 \ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c \u2026 \u210e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\u210e\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61 \" . \" \ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c \u2026 \u210e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\u210e\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52 \" .\"\ud835\udc3c\ud835\udc3c\ud835\udc61\ud835\udc61 \ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c \u2026 \u210e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc4e\ud835\udc5c\ud835\udc5c\ud835\udc5c\ud835\udc5c \" .\"\ud835\udc38\ud835\udc38\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61\u210e\ud835\udc5c\ud835\udc5c\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc52\ud835\udc61\ud835\udc61Figure 2 : Illustration of the dynamic classi\ufb01cation model .", "entities": []}, {"text": "M= 2 means there are 4 classes .", "entities": []}, {"text": "We use ERNIE to train a classi\ufb01er .", "entities": []}, {"text": "Class \u001e means that there is no sentence boundary in the stream till now .", "entities": []}, {"text": "Class \u0000m m= 0;1;2means", "entities": []}, {"text": "thatxt\u0000mis the end of a sentence", "entities": []}, {"text": "and we then put a period after it .", "entities": []}, {"text": "till the current word xtfrom last sentence boundary .", "entities": []}, {"text": "Rather than a binary classi\ufb01cation that detects whetherxtis a sentence boundary , we propose a multi - class method .", "entities": []}, {"text": "The classes are as follows : y=8 > > > > > > < > > > > > > : \u001e ; no sentence boundary detected 0 ; x tis the end of a sentence \u00001 ; x t\u00001is the end of a sentence : : : \u0000M ; x t\u0000Mis the end of a sentence whereMis the maximum offset size to the current state .", "entities": [[27, 28, "DatasetName", "0"]]}, {"text": "Thus , we have M+ 2classes .", "entities": []}, {"text": "See Figure 2 for illustration .", "entities": []}, {"text": "We set M= 2 , indicating that the model predicts 4 classes for the input stream .", "entities": []}, {"text": "If the output class is \u001e , meaning that the model does not detect any sentence boundary .", "entities": []}, {"text": "Thus the model will continue receiving new words .", "entities": []}, {"text": "If the output class is 0 , indicating that the current wordxtis the end of a sentence and we put a period after the word .", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "Similarly , class \u0000mdenotes to add a sentence boundary after xt\u0000m .", "entities": []}, {"text": "While a sentence boundary is detected , the sentence will be extracted from the stream and sent to the MT system as an input for translation .", "entities": []}, {"text": "The sentence detection then continues from xt\u0000m+1 .", "entities": []}, {"text": "Each time our system receives a new word xt , the classi\ufb01er predicts probabilities for the last M+1 words as sentence boundaries .", "entities": []}, {"text": "If the output class is \u001e , the classi\ufb01er receives a new word xt+1 , and recompute the probabilities for xt+1,xt , xt\u00001,:::,xt\u0000M+1 .", "entities": []}, {"text": "Generally , more contextual information will help the classi\ufb01er improve the precision ( Section 4.5 ) .", "entities": []}, {"text": "3.2 Training Objective Our training data is extracted from paragraphs .", "entities": []}, {"text": "Question marks , exclamation marks , and semicolons are mapped to periods and all other punctuation symbols are removed from the corpora .", "entities": []}, {"text": "Then for every two adjacent sentences in a paragraph , we concatenate them to form a long sequence ,", "entities": []}, {"text": "x. We record the position of the period as rand then remove the period from the sequence .", "entities": []}, {"text": "Forx= ( x1;x2;:::;x N)with N words , we generater+Msamples for t= 1;2;:::;(r+M ) , in the form of < ( x1;:::;x t);yt > , whereytis the label that : yt=\u001a \u001e ; ift < r \u0000(t\u0000r);ift2[r;r+M]\u001b ( 1 ) Note that if the length of the second sentence is less than M , we concatenate subsequent sentences untilr+Msamples are collected .", "entities": []}, {"text": "Then we de\ufb01ne the loss function as follows : J(\u0012 ) = X ( x;r)2Dlog(r\u00001X t=1p(yt= \u001e jx\u0014t;\u0012 ) + r+MX t = rp(yt=\u0000(t\u0000r))jx\u0014t;\u0012))(2 ) whereDis the dataset that contains pairs of concatenated sentences xand its corresponding position of the removed periods", "entities": [[4, 5, "MetricName", "loss"]]}, {"text": "r. Mis a hyperparameter denotes the number of waiting words .", "entities": []}, {"text": "Note that our method differs from previous work in the manner of classi\ufb01cation .", "entities": []}, {"text": "Sridhar et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2013 ) predicts whether a word xtlabeled as the end of a sentence or not by a binary classi\ufb01cation : p(yt= 0jxt+2 t\u00002 )", "entities": []}, {"text": "+ p(yt= 1jxt+2 t\u00002 ) = 1 ( 3 ) whereyt= 0meansxtis not the end of a sentence andyt= 1 meansxtis the end.xt+2 t\u00002denotes 5 wordsxt\u00002;xt\u00001;:::;x t+2 .", "entities": []}, {"text": "Some other language - model based work ( Wang et al . , 2016 ) calculates probabilities over all words in the vocabulary including the period : X w2V[\\:\"p(yt = wjx\u0014t ) = 1 ( 4 ) and decides whether xtis a sentence boundary by comparing the probability of yt= \u201c . \u201d", "entities": []}, {"text": "andyt= xt+1 .", "entities": []}, {"text": "4 \ud835\udc65\ud835\udc651\ud835\udc65\ud835\udc652 \u2026 \ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22124\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22123\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22122 \ud835\udc65\ud835\udc651\ud835\udc65\ud835\udc652 \u2026 \ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22124\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22123\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22122\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22121 \ud835\udc65\ud835\udc651\ud835\udc65\ud835\udc652 \u2026 \ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22124\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22123\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22122\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22121\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\ud835\udc5d\ud835\udc5d\ud835\udc66\ud835\udc66=0|\ud835\udc65\ud835\udc651, \u2026 ,\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22122 \ud835\udc5d\ud835\udc5d\ud835\udc66\ud835\udc66=\u22121|\ud835\udc65\ud835\udc651, \u2026 ,\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61\u22121 \ud835\udc5d\ud835\udc5d\ud835\udc66\ud835\udc66=\u22122|\ud835\udc65\ud835\udc651, \u2026 ,\ud835\udc65\ud835\udc65\ud835\udc61\ud835\udc61Figure 3 : Our voting algorithm for online prediction withMequals to 2 .", "entities": []}, {"text": "Input the stream text till xt , the overall probability of add a sentence boundary after xt\u00002is averaged by the M+ 1 probabilities in red , while forxt\u00001(in green ) and xt(in blue ) , the number of deterministic probability is less than M+ 1 .", "entities": []}, {"text": "The performance of these methods is limited by incomplete semantics , without considering global boundary detection .", "entities": [[14, 16, "TaskName", "boundary detection"]]}, {"text": "In our methods , we leverage more future words and restrict classes globally : p(yt= \u001e jx\u0014t ) + MX m=0p(yt=\u0000mjx\u0014t ) = 1 ( 5 ) The restriction is motivated that in a lecture scenario , where a sentence could not be very short that contains only 1 or 2 words .", "entities": []}, {"text": "Thus , the probability distribution prohibits that adjacent words to be the end of sentences at the same time .", "entities": []}, {"text": "3.3 Dynamic Inference At inference time , we predict sentence boundaries sequentially with a dynamic voting strategy .", "entities": []}, {"text": "Each time a new word xtis received , we predict the probability ofM+ 1classes as shown in the bottom of Figure 3 , then calculate if the probability of previousM+ 1positions ( xt\u0000M;xt\u0000M+1;xt ) is larger then a threshold \u0012Th .", "entities": []}, {"text": "If yes , we add a sentence boundary at the corresponding position .", "entities": []}, {"text": "Otherwise , we continue to receive new words .", "entities": []}, {"text": "Note that the probability is adopted as the voted probability .", "entities": []}, {"text": "While the probability of adding a sentence boundary after xt\u0000MhasM+1probabilities to calculate the average , the number of probabilities to determine whether it is a sentence boundary at subsequent positions is less than M+ 1 .", "entities": []}, {"text": "Here we use the voted average of existing probabilities .", "entities": []}, {"text": "Speci\ufb01cally , to judge whether xt0is a sentenceDataset Sentences Tokens / s TrainWMT 14 4.4 M 23.22 IWSLT 14 0.19 M 20.26 TestIWSLT 2010 - 20147040 19.03 Table 1 : Experimental Corpora without punctuation .", "entities": []}, {"text": "Token / s denotes the number of tokens per sentence in English .", "entities": []}, {"text": "boundary , it needs t\u0000t0 + 1probabilities : 1 t\u0000t0 + 1t\u0000t0X m=0p(y=\u0000mjx1;:::;x t+m)(6 ) wheret02[t\u0000M;t ] .", "entities": []}, {"text": "If more than one sentence boundary probabilities forxt\u0000M;:::;x texceeds the threshold \u0012That the same time , we choose the front - most position as a sentence boundary .", "entities": []}, {"text": "This is consistent with our training process , that is , if there is a sample of two or more sentence boundaries , we ignore the following and label the class ytaccording to the \ufb01rst boundary .", "entities": []}, {"text": "This is because we generate samples with each period in the original paragraph as depicted in Section 3.2 .", "entities": []}, {"text": "From another point of view , the strategy can also compensate for some incorrect suppression of adjacent boundaries , thereby improving online prediction accuracy .", "entities": [[23, 24, "MetricName", "accuracy"]]}, {"text": "4 Experiment Experiments are conducted on English - German ( En - De ) simultaneous translation .", "entities": []}, {"text": "We evaluate 1 ) the F - score2of sentence boundary detection and 2 ) case - sensitive tokenized 4 - gram BLEU ( Papineni et al . , 2002 ) as the \ufb01nal translation effect of the segmented sentences .", "entities": [[9, 11, "TaskName", "boundary detection"], [21, 22, "MetricName", "BLEU"]]}, {"text": "To reduce the impact of the ASR system , we use the transcription without punctuation in both training and evaluation .", "entities": []}, {"text": "The datasets used in our experiments are listed in Table 1 .", "entities": []}, {"text": "We use two parallel corpus from machine translation task : WMT 143and", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "IWSLT 14 4 . WMT 14 is a text translation corpus including 4.4 M sentences , mainly on news and web sources .", "entities": []}, {"text": "And IWSLT 14 is a speech translation corpus of TED lectures with transcribed text and corresponding translation .", "entities": []}, {"text": "Here we only use the text part in it , containing 0.19 M sentences in the training set .", "entities": []}, {"text": "2harmonic average of the precision and recall 3http://www.statmt.org/wmt14/translation-task.html 4https://wit3.fbk.eu/", "entities": []}, {"text": "5Method Hyperparameter F - score BLEU avgCW maxCW Oracle NA 1.0 22.76 NA NA N - gram N=5,\u0012Th = e0:00.46 17.83 6.64 56 N - gram N=5,\u0012Th", "entities": [[5, 6, "MetricName", "BLEU"]]}, {"text": "=", "entities": []}, {"text": "e2:00.48 19.20 13.43 161 T - LSTM d=256 0.55 20.46 10.14 53 dynamic - force \u0012l= 40;\u0012Th= 0:5 0.74 22.01 14.43 40 dynamic - base \u0012Th= 0:5 0.74 21.93 14.58 50 Table 2 : Segmentation Performance trained on IWSLT2014 .", "entities": [[6, 7, "MethodName", "LSTM"]]}, {"text": "All methods are conducted with future words M equals to 1 .", "entities": []}, {"text": "We train the machine translation model on WMT 14 with the base version of the Transformer model ( Vaswani et al . , 2017 ) , achieving a BLEU score of 27.2 on newstest2014 .", "entities": [[3, 5, "TaskName", "machine translation"], [15, 16, "MethodName", "Transformer"], [28, 30, "MetricName", "BLEU score"]]}, {"text": "And our sentence boundary detection model is trained on the source transcription of IWSLT 14 unless otherwise speci\ufb01ed ( Section 4.3 ) .", "entities": [[3, 5, "TaskName", "boundary detection"]]}, {"text": "To evaluate the system performance , we merge the IWSLT test set of 4 years ( 2010 - 2014 ) to construct a big test set of 7040 sentences .", "entities": []}, {"text": "The overall statistics of our dataset is shown in Table 1 .", "entities": []}, {"text": "We evaluate our model and two existing methods listed below : \u000fdynamic - base is our proposed method that detect sentence boundaries dynamically using a multi - class classi\ufb01cation .", "entities": []}, {"text": "\u000fdynamic - force adds a constraint on dynamicbase .", "entities": []}, {"text": "In order to keep in line with ( Wang et al . , 2016 ) , we add a constraint that sentence should be force segmented if longer than \u0012l .", "entities": []}, {"text": "\u000fN - gram is the method using an N - gram language model to compare the probability of adding vs. not adding a boundary at xtafter receiving xt\u0000N+1;:::;x t. We implement according to ( Wang et al . , 2016 ) .", "entities": []}, {"text": "\u000fT - LSTM uses a RNN - based classi\ufb01cation model with two classes .", "entities": [[2, 3, "MethodName", "LSTM"]]}, {"text": "We implement a unidirectional RNN and perform training according to ( Tilk and Alum \u00a8ae , 2015)5 .", "entities": []}, {"text": "Our classi\ufb01er in dynamic - base anddynamicforce is trained under ERNIE base framework .", "entities": []}, {"text": "We use the released6parameters obtained at pretraining step as initialization .", "entities": []}, {"text": "In the \ufb01ne - tuning stage , we use a learning rate of 2e\u00005 .", "entities": [[10, 12, "HyperparameterName", "learning rate"]]}, {"text": "5we only keep the two classes of period and \u001e in this work 6https://github.com/PaddlePaddle/ERNIE4.1 Overall Results Table 2 reports the results of source sentence segmentation on En - De translation , where the latency is measured by Consecutive Wait ( CW ) ( Gu et al . , 2017 ) , the number of words between two translate actions .", "entities": [[23, 25, "TaskName", "sentence segmentation"]]}, {"text": "To eliminate the impact of the different policies in simultaneous translation , we only execute translation at the end of each sentence .", "entities": []}, {"text": "Therefore , the CW here denotes the sentence length L plus the number of future words", "entities": []}, {"text": "M. We calculate its average and maximum value as \u201c avgCW \u201d and \u201c maxCW \u201d , respectively .", "entities": []}, {"text": "Better performance expect high F - score , BLEU , and low latency ( CW ) .", "entities": [[8, 9, "MetricName", "BLEU"]]}, {"text": "The translation effect obtained by using the groundtruth period as the sentence segmentation is shown in the \ufb01rst line of Oracle .", "entities": [[11, 13, "TaskName", "sentence segmentation"]]}, {"text": "The N - gram method calculate the probability of add ( padd ) and not add ( pnot ) period at each position , and decide whether to chunk by comparing whether padd = pnotexceeds\u0012Th .", "entities": []}, {"text": "The N - gram method without threshold tuning ( with \u0012Th = e0:0 ) divides sentences into small pieces , achieving the lowest average latency of 6:64 .", "entities": []}, {"text": "However , the Fscore of segmentation is very low because of the incomplete essence of the n - gram feature .", "entities": []}, {"text": "Notable , the precision and recall differs much ( precision = 0:33;recall = 0:78 ) in this setup .", "entities": []}, {"text": "Therefore , we need to choose a better threshold by grid search ( Wang et al . , 2016 ) .", "entities": []}, {"text": "With \u0012Thequals toe2:0 , the F - score of N - gram method increased a little bit ( 0:46!0:48 ) , with a more balanced precision and recall ( precision = 0:51;recall = 0:48 ) .", "entities": []}, {"text": "However , the max latency runs out of control , resulting in a maximum of 161 words in a sentence .", "entities": []}, {"text": "We also tried to shorten the latency of the N - gram method by force segmentation ( Wang et al . , 2016 ) , but the result was very poor ( precision = 0:33;recall = 0:40 ) .", "entities": []}, {"text": "The T - LSTM method with the hidden size of 256 performs better than N - gram , but the F - score", "entities": [[3, 4, "MethodName", "LSTM"]]}, {"text": "6   0.5 0.55 0.6 0.65 0.7 0.75 200k 400k 600k 800kF - score Number of stepsBasic Duplicate Sort Synthetic   20.2 20.4 20.6 20.8 21 21.2 21.4 21.6 21.8 22 22.2 200k", "entities": []}, {"text": "400k 600k 800kBLEU Number of stepsBasic Duplicate Sort SyntheticFigure 4 : Performance evaluated on IWSLT14 testset for different training sample building strategies .", "entities": []}, {"text": "and BLEU is still limited .", "entities": [[1, 2, "MetricName", "BLEU"]]}, {"text": "On the contrary , our dynamic -based approaches with M= 1 achieve the best F - score at 0.74 and the \ufb01nal translation is very close to the result of Oracle .", "entities": []}, {"text": "In particular , the precision and recall reached about 0.72 and 0.77 in both dynamic - force anddynamic - base , respectively .", "entities": []}, {"text": "Accurate sentence segmentation brings better performance in translation , bringing an improvement of 1.55 over T - LSTM .", "entities": [[1, 3, "TaskName", "sentence segmentation"], [17, 18, "MethodName", "LSTM"]]}, {"text": "Moreover , our approach is not inferior in terms of latency .", "entities": []}, {"text": "Both average latency and max latency is controlled at a relatively low level .", "entities": []}, {"text": "It is interesting to note that , dynamic - force performs better than dynamic - base , in terms of latency and BLEU .", "entities": [[22, 23, "MetricName", "BLEU"]]}, {"text": "This suggests the effectiveness of the force segmentation strategy , that is , select the chunking location with a sentence length limitation will not affect the accuracy of segmentation , and would enhance the translation effect .", "entities": [[15, 16, "TaskName", "chunking"], [26, 27, "MetricName", "accuracy"]]}, {"text": "4.2 Magic in Data Processing According to Section 3.2 , the order between sentences of original corpora would affect the generation of training samples .", "entities": []}, {"text": "In this section , we investigate the effect of various data reordering strategies .", "entities": []}, {"text": "A basic method is to use the original sentence order of speech corpora , denote as Basic .", "entities": []}, {"text": "However , the samples generated is limited , which makes the model easy to over-\ufb01t .", "entities": []}, {"text": "To overcome this problem , we adopt two methods to expand data scale : 1 ) Duplicate the original data multiple times or 2 ) Add Synthetic adjacent sentences , through randomly selecting two sentences from the corpora .", "entities": []}, {"text": "These two methods greatly expand the total amount of data , but the gain to the model is uncertain .", "entities": []}, {"text": "As an alternative , we explore a Sort method , to sort sentencesaccording to alphabetic order .", "entities": []}, {"text": "The performance of the four training data organization methods is shown in Figure 4 , all built on IWSLT2014 and conducted under the setup of M= 1and\u0012l= 40 .", "entities": []}, {"text": "It is clear that Basic , Duplicate andSynthetic are all involved in the problem of over-\ufb01tting .", "entities": []}, {"text": "They quickly achieved their best results and then gradually declined .", "entities": []}, {"text": "Surprisingly , theSort approach is prominent in both segmentation accuracy and translation performance .", "entities": [[9, 10, "MetricName", "accuracy"]]}, {"text": "This may be due to the following reasons : 1 ) Sentence classi\ufb01cation is not a dif\ufb01cult task , especially when M= 1 for 3 - class classi\ufb01cation ( y2 [ \u001e ; 0;\u00001 ] ) , making the task easy to over-\ufb01t .", "entities": []}, {"text": "2 ) Compared with Basic , Duplicate is more abundant in the sample combination in batch training , but there is no essential difference between the two methods .", "entities": []}, {"text": "3 ) Synthetic hardly pro\ufb01ts our model , because the synthesized data may be very simple due to random selection .", "entities": []}, {"text": "4 ) Sort may simulate dif\ufb01cult cases in real scenes and train them pertinently , bringing it a poor performance at start but not prone to over\ufb01t .", "entities": []}, {"text": "There are many samples with identical head and tail words in the sorted data , such as : \u201c and it gives me a lot of hope kand ... \u201d and \u201c that means there \u2019s literally thousands of new ideas kthat ... \u201d .", "entities": []}, {"text": "Even human beings \ufb01nd it dif\ufb01cult to determine whether the words before kis sentence boundaries of these samples .", "entities": []}, {"text": "In Basic , Duplicate andSynthetic methods , such samples are usually submerged in a large quantity of simple samples .", "entities": []}, {"text": "However , the data organization mode of Sort greatly strengthens the model \u2019s ability to learn these dif\ufb01cult samples .", "entities": []}, {"text": "There is no need to worry that the Sort method can not cover simple samples .", "entities": []}, {"text": "Because we sort by rows in source \ufb01le , and some of the rows contain multiple sentences ( an average of 1.01 sentences", "entities": []}, {"text": "7Method F - score BLEU avgCW maxCW N - gram 0.48 19.58 15.60 156 T - LSTM 0.56 20.77 15.65 51 dyn - force 0.68 21.48 15.53 40 dyn - base 0.68 21.40 16.08 46 Table 3 : Segmentation Performance trained on WMT14 .", "entities": [[4, 5, "MetricName", "BLEU"], [16, 17, "MethodName", "LSTM"], [42, 43, "DatasetName", "WMT14"]]}, {"text": "All methods are conducted with future words Mequals to 1 .", "entities": []}, {"text": "N - gram uses grid - search to get the best hyperparamters .", "entities": []}, {"text": "dynis short for dynamic anddynamicforce adopts\u0012l= 40 .", "entities": []}, {"text": "per row ) , which are in real speech order .", "entities": []}, {"text": "We argue that these sentences are suf\ufb01cient to model the classi\ufb01cation of simple samples , based on the rapid over\ufb01t performance of the other three methods .", "entities": []}, {"text": "4.3 Out - of - Domain vs. In - Domain Next , we turn to the question that how does the domain of training corpus affects results .", "entities": []}, {"text": "With the test set unchanged , we compare the sentence boundary detections model trained on out - of - domain corpora WMT 14 and in - domain corpora IWSLT 14 , respectively .", "entities": []}, {"text": "As mentioned before , WMT 14 is a larger text translation corpus mainly on news and web sources .", "entities": []}, {"text": "But the test set comes from IWSLT , which contains transcriptions of TED lectures of various directions .", "entities": []}, {"text": "Intuitively , larger dataset provides more diverse samples , but due to domain changes , it does not necessarily lead to improvements in accuracy .", "entities": [[23, 24, "MetricName", "accuracy"]]}, {"text": "The performance of various models trained on WMT14 is shown in Table 3 .", "entities": [[7, 8, "DatasetName", "WMT14"]]}, {"text": "Dynamic - force also achieves the best translation performance with a relatively small latency on average and limited the max latency within 40 words .", "entities": []}, {"text": "However , it underperforms the same model trained on IWSLT2014 ( as shown in Table 2 ) , demonstrating its sensitivity to the training domain .", "entities": []}, {"text": "On the contrary , N - gram andT - LSTM is hardly affected .", "entities": [[9, 10, "MethodName", "LSTM"]]}, {"text": "For N - gram , one possible reason is the before mentioned weakness of the N - gram : segmentation depends on only Nprevious words , which is more steady compared to the whole sentence , thus eliminating the perturbation of whole sentence brought by the domain variation .", "entities": []}, {"text": "For T - LSTM , it even improves a little compared with its in - domain performance .", "entities": [[3, 4, "MethodName", "LSTM"]]}, {"text": "This may be due to the lack of training samples .", "entities": []}, {"text": "0.19 M sentences of IWSLT2014 is insuf\ufb01cient to \ufb01t the parameters of T - LSTM .", "entities": [[14, 15, "MethodName", "LSTM"]]}, {"text": "Thus the model would bene\ufb01t from increasing the corpus size .", "entities": []}, {"text": "However , our method needs less data in\u0012lF - score BLEU avgCW 10 0.40 16.27 5.85 20 0.58 20.34 9.74 40 0.74 22.01 14.43 80 0.73 21.60 15.15 Table 4 : Segmentation Performance of dynamic - force trained on IWSLT2014 .", "entities": [[10, 11, "MetricName", "BLEU"]]}, {"text": "All methods are conducted with future words Mequals to 1 . training because our model has been pre - trained .", "entities": []}, {"text": "Based on a powerful representation , we need only a small amount of training data in \ufb01ne - tuning , which is best aligned with the test set in the domain .", "entities": []}, {"text": "4.4 Length of window \u0012l", "entities": []}, {"text": "Next , we discuss the effect of changing \u0012.", "entities": []}, {"text": "The performance of dynamic - force with varying \u0012lis shown in Table 4 .", "entities": []}, {"text": "Smaller \u0012lbrings shorter latency , as well as worse performance .", "entities": []}, {"text": "The effect is extremely poor with \u0012l= 10 .", "entities": []}, {"text": "There are two possible reasons : 1 ) Constraint sentence length less than \u0012l is too harsh under small \u0012l , 2 ) The discrepancy between the unrestricted training and length - restricted testing causes the poor effect .", "entities": []}, {"text": "We \ufb01rst focus on the second possible reason .", "entities": []}, {"text": "While the difference between dynamic - base and dynamic - force is only in prediction , we want to know whether we can achieve better results by controlling the length of training samples .", "entities": []}, {"text": "Accordingly , we only use the samples shorter than a \ufb01xed value : \u0012lin training phrase .", "entities": []}, {"text": "At inference time , we use both dynamic - force with the same sentence length constraint\u0012landdynamic - base to predict sentence boundaries .", "entities": []}, {"text": "As elaborated in Figure 5 , For each pair of curves with a same \u0012l , dynamic - force and dynamic - base present similar performance .", "entities": []}, {"text": "This demonstrates the main reason for the poor performance with small \u0012lis not the training - testing discrepancy but lies in the \ufb01rst reason that the force constraint is too harsh .", "entities": []}, {"text": "Moreover , it is interesting to \ufb01nd that the performance of \u0012l= 80 is similar with \u0012l= 40 at the beginning but falls a little during training .", "entities": []}, {"text": "This probably because the setup with \u0012l= 40 can \ufb01lter some inaccurate cases , as the average number of words in IWSLT2014 training set is 20.26 .", "entities": []}, {"text": "4.5 Number of Future", "entities": []}, {"text": "Words", "entities": []}, {"text": "M", "entities": []}, {"text": "We investigate whether can we achieve better performance with more or less future words .", "entities": []}, {"text": "We experiment with Mfrom 0to5 .", "entities": []}, {"text": "The result is shown", "entities": []}, {"text": "8   15 16 17 18 19 20 21 22 23 200k 400k 600k 800kBLEU Number of steps10 - Force 20 - Force 40 - Force 80 - Force 10 - Base 20 - Base 40 - Base 80 - BaseFigure 5 : Translation performance on IWSLT2014 testset .", "entities": [[43, 44, "TaskName", "Translation"]]}, {"text": "\u201c \u0012l - Force \u201d denotes to set the sentence length threshold to \u0012lin both training sample generation and prediction .", "entities": []}, {"text": "\u201c \u0012l - Base \u201d is to set this constraint only in training samples generation process .", "entities": []}, {"text": "M F - score BLEU avgCW 0 0.66 21.54 13.23 1 0.74 22.01 14.43 2 0.77 22.23 15.24 3 0.79 22.23 16.52 4 0.80 22.29 17.15", "entities": [[4, 5, "MetricName", "BLEU"], [6, 7, "DatasetName", "0"]]}, {"text": "Table", "entities": []}, {"text": "5 : Segmentation Performance of dynamic - force trained on IWSLT2014 .", "entities": []}, {"text": "All methods are conducted with\u0012l= 40 .", "entities": []}, {"text": "in Table 5 .", "entities": []}, {"text": "Reducing Mto zero means that do not refer to any future words in prediction .", "entities": []}, {"text": "This degrades performance a lot , proving the effectiveness of adding future words in prediction .", "entities": []}, {"text": "Increase M from 1 to 2 also promote the performance in both sentence boundary detection f - score and the system BLEU .", "entities": [[13, 15, "TaskName", "boundary detection"], [21, 22, "MetricName", "BLEU"]]}, {"text": "However , as more future words added ( increaseMto 3 and 4 ) , the improvement becomes less obvious .", "entities": []}, {"text": "5 Related Work Sentence boundary detection has been explored for years , but the majority of these work focuses on of\ufb02ine punctuation restoration , instead of applied in simultaneous translation .", "entities": [[4, 6, "TaskName", "boundary detection"]]}, {"text": "Existing work can be divided into two classes according to the model input .", "entities": []}, {"text": "5.1 N - gram based methods Some work takes a \ufb01xed size of words as input .", "entities": []}, {"text": "Focus on utilizing a limited size of the streaming input , they predict the probability of putting a boundary at a speci\ufb01c position xtby a N - gram lan - guage model ( Wang et al . , 2016 ) or a classi\ufb01cation model ( Sridhar et al . , 2013 ; Yarmohammadi et al . , 2013 ) .", "entities": []}, {"text": "The language - model based method make decision depends on Nwords ( xt\u0000N+2;:::;x t+1 ) and compares its probability with ( xt\u0000N+2;:::;x t ; \u201c . \u201d ) .", "entities": []}, {"text": "The classi\ufb01cation model takes features of Nwords aroundxtand classi\ufb01es to two classes denoting xt is a sentence boundary or not .", "entities": []}, {"text": "The main de\ufb01ciency of this method is that the dependencies outside the input window are lost , resulting in low accuracy .", "entities": [[20, 21, "MetricName", "accuracy"]]}, {"text": "5.2 Whole sentence - based methods Some other work focuses on restoring punctuation and capitalization using the whole sentence .", "entities": []}, {"text": "To improve the sentence boundary classi\ufb01cation accuracy , some work upgrade the N - gram input to variable - length input by using recurrent neural network ( RNN ) ( Tilk and Alum \u00a8ae , 2015 ; Salloum et al . , 2017 ) .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "Some other work takes punctuation restoration as a sequence labeling problem and investigates using Conditional Random Fields ( CRFs ) ( Lu and Ng , 2010 ; Wang et al . , 2012 ;", "entities": []}, {"text": "Ueffing et al . , 2013 ) .", "entities": []}, {"text": "Peitz et al .", "entities": []}, {"text": "( 2011 ) and Cho et al .", "entities": []}, {"text": "( 2012 ) treats this problem as a machine translation task , training to translate non - punctuated transcription into punctuated text .", "entities": [[8, 10, "TaskName", "machine translation"]]}, {"text": "However , all these methods utilize the whole sentence information , which is not \ufb01t for the simultaneous translation scenario .", "entities": []}, {"text": "Moreover , the translation model based methods require multiple steps of decoding , making it unsuitable for online prediction .", "entities": []}, {"text": "6 Conclusion In this paper , we propose an online sentence boundary detection approach .", "entities": [[11, 13, "TaskName", "boundary detection"]]}, {"text": "With the input of streaming words , our model predicts the probability of multiple positions rather than a certain position .", "entities": []}, {"text": "By adding this adjacent position constraint and using dynamic prediction , our method achieves higher accuracy with lower latency .", "entities": [[15, 16, "MetricName", "accuracy"]]}, {"text": "We also incorporate the pre - trained technique , ERNIE to implement our classi\ufb01cation model .", "entities": []}, {"text": "The empirical results on IWSLT2014 demonstrate that our approach achieves signi\ufb01cant improvements of 0.19 F - score on sentence segmentation and 1.55 BLEU points compared with the language - model based methods .", "entities": [[18, 20, "TaskName", "sentence segmentation"], [22, 23, "MetricName", "BLEU"]]}, {"text": "References Naveen Arivazhagan , Colin Cherry , Wolfgang Macherey , Chung - Cheng Chiu , Semih Yavuz ,", "entities": []}, {"text": "9Ruoming Pang , Wei Li , and Colin Raffel .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Monotonic in\ufb01nite lookback attention for simultaneous machine translation .", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics .", "entities": []}, {"text": "Srinivas Bangalore , Vivek Kumar Rangarajan Sridhar , Prakash Kolan , Ladan Golipour , and Aura Jimenez .", "entities": [[4, 5, "DatasetName", "Kumar"]]}, {"text": "2012 .", "entities": []}, {"text": "Real - time incremental speech - tospeech translation of dialogs .", "entities": []}, {"text": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Eunah Cho , Jan Niehues , and Alex Waibel . 2012 .", "entities": []}, {"text": "Segmentation and punctuation prediction in speech language translation using a monolingual translation system .", "entities": []}, {"text": "In International Workshop on Spoken Language Translation ( IWSLT ) 2012 .", "entities": [[6, 7, "TaskName", "Translation"]]}, {"text": "Kyunghyun Cho and Masha Esipova . 2016 .", "entities": []}, {"text": "Can neural machine translation do simultaneous translation ?", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1606.02012 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In Proceedings of NAACL - HLT 2019 .", "entities": []}, {"text": "Christian F \u00a8ugen , Alex Waibel , and Muntsin Kolss .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Simultaneous translation of lectures and speeches .", "entities": []}, {"text": "Machine translation , 21(4 ) .", "entities": [[0, 2, "TaskName", "Machine translation"]]}, {"text": "Jiatao Gu , Graham Neubig , Kyunghyun Cho , and Victor OK Li .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Learning to translate in real - time with neural machine translation .", "entities": [[9, 11, "TaskName", "machine translation"]]}, {"text": "Wei Lu and Hwee Tou Ng . 2010 .", "entities": []}, {"text": "Better punctuation prediction with dynamic conditional random \ufb01elds .", "entities": []}, {"text": "InProceedings of the 2010 conference on empirical methods in natural language processing .", "entities": []}, {"text": "Mingbo Ma , Liang Huang , Hao Xiong , Kaibo Liu , Chuanqiang Zhang , Zhongjun He , Hairong Liu , Xing Li , and Haifeng Wang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "STACL : simultaneous translation with integrated anticipation and controllable latency .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Kishore Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .", "entities": []}, {"text": "Bleu : a method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th annual meeting on association for computational linguistics .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Stephan Peitz , Markus Freitag , Arne Mauser , and Hermann Ney . 2011 .", "entities": []}, {"text": "Modeling punctuation prediction as machine translation .", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "In International Workshop on Spoken Language Translation ( IWSLT ) 2011 .Wael", "entities": [[6, 7, "TaskName", "Translation"]]}, {"text": "Salloum , Gregory Finley , Erik Edwards , Mark Miller , and David Suendermann - Oeft . 2017 .", "entities": []}, {"text": "Deep learning for punctuation restoration in medical reports .", "entities": []}, {"text": "In BioNLP 2017 .", "entities": []}, {"text": "Vivek Kumar Rangarajan Sridhar , John Chen , Srinivas Bangalore , Andrej Ljolje , and Rathinavelu Chengalvarayan .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "2013 .", "entities": []}, {"text": "Segmentation strategies for streaming speech translation .", "entities": []}, {"text": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .", "entities": []}, {"text": "Yu Sun , Shuohuan Wang , Yukun Li , Shikun Feng , Xuyi Chen , Han Zhang , Xin Tian , Danxiang Zhu , Hao Tian , and Hua Wu . 2019 .", "entities": []}, {"text": "Ernie : Enhanced representation through knowledge integration .", "entities": []}, {"text": "arXiv preprint arXiv:1904.09223 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Ottokar Tilk and Tanel Alum \u00a8ae .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Lstm for punctuation restoration in speech transcripts .", "entities": [[0, 1, "MethodName", "Lstm"]]}, {"text": "In Sixteenth annual conference of the international speech communication association .", "entities": []}, {"text": "Nicola Uef\ufb01ng , Maximilian Bisani , and Paul V ozila .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Improved models for automatic punctuation prediction for spoken and written text .", "entities": []}, {"text": "In Interspeech .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In 31st Conference on Neural Information Processing Systems ( NIPS 2017 ) .", "entities": []}, {"text": "L. Venuti .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "The translation studies reader .", "entities": []}, {"text": "Xiaolin Wang , Andrew Finch , Masao Utiyama , and Eiichiro Sumita .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "An ef\ufb01cient and effective online sentence segmenter for simultaneous interpretation .", "entities": []}, {"text": "In Proceedings of the 3rd Workshop on Asian Translation ( WAT2016 ) .", "entities": [[8, 9, "TaskName", "Translation"]]}, {"text": "Xuancong Wang , Hwee Tou Ng , and Khe Chai Sim . 2012 .", "entities": []}, {"text": "Dynamic conditional random \ufb01elds for joint sentence boundary and punctuation prediction .", "entities": []}, {"text": "In Thirteenth Annual Conference of the International Speech Communication Association .", "entities": []}, {"text": "Mahsa Yarmohammadi , Vivek Kumar Rangarajan Sridhar , Srinivas Bangalore , and Baskaran Sankaran .", "entities": [[4, 5, "DatasetName", "Kumar"]]}, {"text": "2013 .", "entities": []}, {"text": "Incremental segmentation and decoding strategies for simultaneous translation .", "entities": []}, {"text": "In Proceedings of the Sixth International Joint Conference on Natural Language Processing .", "entities": []}]