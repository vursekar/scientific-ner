[{"text": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Student Research Workshop , pages 22\u201328 Minneapolis , Minnesota , June 3 - 5 , 2019 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2017 Association for Computational Linguistics22The Strength of the Weakest Supervision : Topic Classi\ufb01cation Using Class Labels Jiatong Li1 , Kai Zheng2 , Hua Xu3 , Qiaozhu Mei4 ,", "entities": []}, {"text": "Yue Wang5 1Department of Computer Science , Rutgers University 2Department of Informatics , University of California , Irvine 3School of Biomedical Informatics , The University of Texas Health Science Center at Houston 4School of Information , University of Michigan , Ann Arbor 5School of Information and Library Science , University of North Carolina at Chapel Hill 1jiatong.li@rutgers.edu,2zhengkai@uci.edu,3hua.xu@uth.tmc.edu , 4qmei@umich.edu,5wangyue@email.unc.edu", "entities": [[26, 27, "DatasetName", "Texas"], [31, 32, "DatasetName", "Houston"]]}, {"text": "Abstract", "entities": []}, {"text": "When developing topic classi\ufb01ers for realworld applications , we begin by de\ufb01ning a set of meaningful topic labels .", "entities": []}, {"text": "Ideally , an intelligent classi\ufb01er can understand these labels right away and start classifying documents .", "entities": []}, {"text": "Indeed , a human can con\ufb01dently tell if a news article is about science , politics , sports , or none of the above , after knowing just the class labels .", "entities": []}, {"text": "We study the problem of training an initial topic classi\ufb01er using only class labels .", "entities": []}, {"text": "We investigate existing techniques for solving this problem and propose a simple but effective approach .", "entities": []}, {"text": "Experiments on a variety of topic classi\ufb01cation data sets show that learning from class labels can save signi\ufb01cant initial labeling effort , essentially providing a \u201c free \u201d warm start to the topic classi\ufb01er .", "entities": []}, {"text": "1 Introduction When developing topic classi\ufb01ers for real - world tasks , such as news categorization , query intent detection , and user - generated content analysis , practitioners often begin by crafting a succinct de\ufb01nition , or a class label , to de\ufb01ne each class .", "entities": [[18, 20, "TaskName", "intent detection"]]}, {"text": "Unfortunately , these carefully written class labels are completely ignored by supervised topic classi\ufb01cation models .", "entities": []}, {"text": "Given a new task , these models typically require a signi\ufb01cant amount of labeled documents to reach even a modest initial performance .", "entities": []}, {"text": "In contrast , a human can readily understand new topic categories by reading the class de\ufb01nitions and making connections to prior knowledge .", "entities": []}, {"text": "Labeling initial examples for every new task can be time - consuming and laborintensive , especially in resource - constrained domains like medicine and law .", "entities": []}, {"text": "Therefore it is desirable if a topic classi\ufb01er can proactively interpret class labels before the training starts , giving itself a \u201c warm start \u201d .", "entities": []}, {"text": "An imperfect initial model can always be \ufb01ne - tuned with more labeled documents .", "entities": []}, {"text": "# oflabelsclassificationperformancelearningfromclasslabelsignoringclasslabelscoldstartwarmstart0Figure 1 : Learning from class labels can give \u201c warm start \u201d to a classi\ufb01er , accelerating the learning process .", "entities": []}, {"text": "As conceptually shown in Figure 1 , a warm start can reduce the total number of training labels for a classi\ufb01er to reach certain performance level .", "entities": []}, {"text": "In this work , we study algorithms that can initialize a topic classi\ufb01er using class labels only .", "entities": []}, {"text": "Since class labels are the starting point of any topic classi\ufb01cation task , they can be viewed as the earliest hence weakest supervision signal .", "entities": []}, {"text": "We propose a simple and effective approach that combines word embedding and naive Bayes classi\ufb01cation .", "entities": []}, {"text": "On six topic classi\ufb01cation data sets , we evaluate a suite of existing approaches and the proposed approach .", "entities": []}, {"text": "Experimental results show that class labels can train a topic classi\ufb01er that generalizes as well as a classi\ufb01er trained on hundreds to thousands of labeled documents .", "entities": []}, {"text": "2 Related Work Text retrieval .", "entities": []}, {"text": "Classifying documents by short labels can be viewed as evaluating textual similarity between a document and a label .", "entities": []}, {"text": "Baeza - Yates et al .", "entities": []}, {"text": "( 2011 ) called this approach \u201c naive text classi\ufb01cation \u201d .", "entities": []}, {"text": "Treating labels as search queries , we can classify a document into a class if it best matches the label of that class .", "entities": []}, {"text": "Well - studied text retrieval methods , such as vector space models and probabilistic models ( Croft et al . , 2010 ) , can produce matching scores .", "entities": []}, {"text": "To mitigate vocabulary mismatch , such a classi\ufb01er can be further enhanced", "entities": []}, {"text": "23by self - training : the classi\ufb01er assigns pseudo labels to top - ranked documents as done in pseudo relevance feedback ( Rocchio , 1965 ) , and updates itself using those labels .", "entities": []}, {"text": "Semi - supervised learning .", "entities": []}, {"text": "Our problem setting can be seen as an extreme case of weak supervision : we only use class labels as the ( noisy ) supervision signal , and nothing else .", "entities": []}, {"text": "If we view class labels as \u201c labeled documents \u201d , one from each class , and to - be - classi\ufb01ed documents as unlabeled documents , then we cast the problem as semisupervised learning ( Zhu , 2006 ) .", "entities": []}, {"text": "Self - training is one such technique : a generative classi\ufb01er is trained using only class labels , and then teaches itself using its own predictions on unlabeled data .", "entities": []}, {"text": "If we view class labels as \u201c labeled features \u201d , then we expect the classi\ufb01er to predict a class when a document contains the class label words .", "entities": []}, {"text": "For instance , Druck et al .", "entities": []}, {"text": "( 2008 ) proposed generalized expectation criteria that uses feature words ( class labels ) to train a discriminative classi\ufb01er .", "entities": []}, {"text": "Jagarlamudi et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2012 ) and Hingmire and Chakraborti ( 2014 ) proposed Seeded LDA to incorporate labeled words / topics into statistical topic modeling .", "entities": [[12, 13, "MethodName", "LDA"]]}, {"text": "The inferred document - topic mixture probabilities can be used to classify documents .", "entities": []}, {"text": "Zero - shot learning aims to classify visual objects from a new class using only word descriptions of that class ( Socher et al . , 2013 ) .", "entities": [[0, 4, "TaskName", "Zero - shot learning"]]}, {"text": "It \ufb01rst learns visual features and their correspondence with word descriptions , and then constructs a new classi\ufb01er by composing learned features .", "entities": []}, {"text": "Most research on zero - shot learning focuses on image classi\ufb01cation , but the same principle applies to text classi\ufb01cation as well ( Pushp and Srivastava , 2017 ) .", "entities": [[3, 7, "TaskName", "zero - shot learning"]]}, {"text": "Our proposed method constructs a new classi\ufb01er by composing learned word embeddings in a probabilistic manner .", "entities": [[10, 12, "TaskName", "word embeddings"]]}, {"text": "Since the new classi\ufb01er transfers semantic knowledge in word embedding to topic classi\ufb01cation tasks , it is broadly related totransfer learning ( Pan and Yang , 2010 ) .", "entities": []}, {"text": "The main difference is that in transfer learning the information about the new task is in the form of labeled data , not class de\ufb01nition words .", "entities": [[6, 8, "TaskName", "transfer learning"]]}, {"text": "3 Proposed Method Let a test document xbe a sequence of words ( w1;\u0001\u0001\u0001;wj;\u0001\u0001\u0001 ) , and a class topic description y be a sequence of words dy= ( w1;\u0001\u0001\u0001;wy;\u0001\u0001\u0001 ) .", "entities": []}, {"text": "All words are in vocabulary V. We propose a generative approach , where the predictive probabil - ityp(yjx)/p(xjy)p(y ) .", "entities": []}, {"text": "Generative approaches tends to perform well when training data is scarce , which is the case in our setting .", "entities": []}, {"text": "We assume there exists weak prior knowledge on which classes are popular and which are rare .", "entities": []}, {"text": "We can then construct rough estimates ^p(y)using simple heuristics as described in ( Schapire et al . , 2002 ) .", "entities": []}, {"text": "It distributes probability mass qevenly among majority classes , and 1\u0000qevenly among minority classes .", "entities": []}, {"text": "We treat the most frequent class as the majority class , the rest as minority classes , andq= 0:7 in our experiments .", "entities": []}, {"text": "By interpreting class topic description as words , we obtain ^p(xjy )", "entities": []}, {"text": "= p(xjdy ) .", "entities": []}, {"text": "We assume that the dyexpresses a noisy - OR relation of the words it contains ( Oni \u00b4 sko et al . , 2001 ) .", "entities": []}, {"text": "Up to \ufb01rst - order approximation : p(xjdy )", "entities": []}, {"text": "= 1\u0000Y wy2dy(1\u0000p(xjwy ) )", "entities": []}, {"text": "\u0019X wy2dyp(xjwy ) ; ( 1 ) where eachwyis a word in the class topic descriptiondy .", "entities": []}, {"text": "Further , we assume that words in documentxare conditionally independent given a label wordwy(na\u00a8\u0131ve Bayes assumption ): p(xjwy )", "entities": []}, {"text": "= Y wj2xp(wjjwy ): ( 2 ) Combining ( 1 ) and ( 2 ) , the document likelihood is ^p(xjy )", "entities": []}, {"text": "= X wy2dyY wj2xp(wjjwy ): ( 3 ) To this end , we need a word association model p(w1jw2);8w1;w22V.", "entities": []}, {"text": "It can be ef\ufb01ciently learned by word embedding algorithms .", "entities": []}, {"text": "The skipgram algorithm ( Mikolov et al . , 2013 ) learns vector representations of words , such that for words w1;w2 , their vectors uw1;vw2approximate the conditional probability1 p(w1jw2 )", "entities": []}, {"text": "= exp\u0000 u > w1vw2\u0001 P w2Vexp ( u > wvw2 ): ( 4 ) 1The two sets of word vectors fuw : w2Vgand fvw : w2Vgproduced by skip - gram correspond to the input and output parameters of a two - layer neural network .", "entities": []}, {"text": "Typically , only the output parameters are used as the \u201c learned word vectors \u201d .", "entities": []}, {"text": "Here we need both input and output parameters to compute p(w1jw2 ) .", "entities": []}, {"text": "24Combining ( 3 ) with ( 4 ) , the document likelihood becomes ^p(xjy )", "entities": []}, {"text": "= X wy2dyexp0 @X wj2x\u0010 u > wjvwy\u0000Cwy\u00111 A ; whereCwy= logP w2Vexp\u0000 u > wvwy\u0001 is independent of document xand only related to label wordwy , therefore can be precomputed and stored to save computation .", "entities": []}, {"text": "Finally , we construct an generative classi\ufb01er as ^p(yjx)/^p(xjy)^p(y ) .", "entities": []}, {"text": "We call this method word embedding na \u00a8\u0131ve Bayes ( WENB ) .", "entities": []}, {"text": "3.1 Continued Training The proposed method produces pseudo labels ^p(yjxj)for unlabeled documents fxjgm j=1 .", "entities": []}, {"text": "When true labelsf(xi;yi)gn i=1are available , we can train a new discriminative logistic regression classi\ufb01er p\u0012(yjx)using both true and pseudo labels ( \u0012is the model parameter ): J(\u0012 ) = nX i=1X y2Y\u00001fyi = yglogp\u0012(yjxi )", "entities": [[12, 14, "MethodName", "logistic regression"]]}, {"text": "+ \u0015k\u0012k2 + \u0016mX j=1X", "entities": []}, {"text": "y2Y\u0000^p(yjxj ) logp\u0012(yjxj ): ( 5 ) To \ufb01nd the balance of pseudo vs. true labels in ( 5 ) , we search the hyperparameter \u0016on a 5point gridf10\u00002;10\u00001;0:4;0:7;1 g. We expect pseudo labels to have comparable importance as true labels when nis small ( \ufb01ne granularity for \u00162[10\u00001;1 ] ) , and their importance will diminish asngets large ( \u0016= 10\u00002).\u0016is automatically selected such that it gives the best 5 - fold crossvalidation accuracy on ntrue labels .", "entities": [[74, 75, "MetricName", "accuracy"]]}, {"text": "4 Experiments We compare a variety of methods on six topic classi\ufb01cation data sets .", "entities": []}, {"text": "The goals are ( 1 ) to study the best classi\ufb01cation performance achievable using class labels only , and ( 2 ) to estimate the equivalent amount of true labels needed to achieve the same warm - start performance .", "entities": []}, {"text": "4.1 Compared Methods Retrieval - based methods .", "entities": []}, {"text": "We use language modeling retrieval function with Dirichlet smoothing ( Zhai and Lafferty , 2001 ) ( \u0016= 2500 ) to match a document to class labels ( IR ) .", "entities": []}, {"text": "The top 10resultsare then used as pseudo - labeled documents to retrain three classi\ufb01ers : IR+Roc : a Rocchio classi\ufb01er ( \u000b = 1 ; \f = 0:5 ;", "entities": []}, {"text": "= 0);IR+NB : a multinomial naive Bayes classi\ufb01er ( Laplace smoothing , \u000b = 0:01);IR+LR a logistic regression classi\ufb01er ( linear kernel , C= 1 ) .", "entities": [[16, 18, "MethodName", "logistic regression"]]}, {"text": "Semi - supervised methods .", "entities": []}, {"text": "ST-0 : the initial self - training classi\ufb01er using class labels as \u201c training documents \u201d ( multinomial na \u00a8\u0131ve Bayes , Laplace smoothing", "entities": []}, {"text": "= 0:01).ST-1 : ST-0 retrained on 10most con\ufb01dent documents predicted by itself .", "entities": []}, {"text": "GE : a logistic regression classi\ufb01er trained using generalized expectation criteria ( Druck et al . , 2008 ) .", "entities": [[3, 5, "MethodName", "logistic regression"]]}, {"text": "Class labels are used as labeled features .", "entities": []}, {"text": "sLDA : a supervised topic model trained using seeded LDA ( Jagarlamudi et al . , 2012 ) .", "entities": [[9, 10, "MethodName", "LDA"]]}, {"text": "Besides kseeded topics ( kis the number of classes ) , we use an extra topic to account for other content in the corpus .", "entities": []}, {"text": "Word embedding - based methods .Cosine : a centroid - based classi\ufb01er , where class de\ufb01nitions and documents are represented as average of word vectors .", "entities": []}, {"text": "WENB :", "entities": []}, {"text": "The proposed method ( Section 3 ) .", "entities": []}, {"text": "WENB+LR : a logistic regression classi\ufb01er trained only on pseudo labels produced by WENB ( Section 3.1 , n= 0 ) .", "entities": [[3, 5, "MethodName", "logistic regression"], [19, 20, "DatasetName", "0"]]}, {"text": "For general domain tasks , we take raw text from English Wikipedia , English news crawl ( WMT , 2014 ) , and 1 billion word news corpus ( Chelba et al . , 2013 ) to train word vectors .", "entities": []}, {"text": "For medical domain tasks , we take raw text from MEDLINE abstracts ( NLM , 2018 ) to train word vectors .", "entities": [[1, 3, "DatasetName", "medical domain"]]}, {"text": "We \ufb01nd 50 - dimensional skip - gram word vectors perform reasonably well in the experiments .", "entities": []}, {"text": "4.2 Data Sets We consider six topic classi\ufb01cation data sets with different document lengths and application domains .", "entities": []}, {"text": "Table 1 summarizes basic statistics of these data sets .", "entities": []}, {"text": "Table 4 and 5 in the appendix show actual class labels used in each data set .", "entities": []}, {"text": "Data set Avg word / doc # classes # docs Wiki Titles 3.1 ( 1.1 ) 15 30,000 News Titles 6.7 ( 9.5 ) 4 422,937 Y Questions 5.0 ( 2.6 ) 10 1,460,000 20 News 101.6 ( 438.5 ) 20 18,846 Reuters 76.5 ( 117.3 ) 10 8,246 Med WSD 202.8 ( 46.6 ) 2 / task 190 / task Table 1 : Statistics of topic classi\ufb01cation data sets .", "entities": []}, {"text": "Numbers in column \u201c Avg word / doc \u201d are \u201c mean ( standard deviation ) \u201d .", "entities": []}, {"text": "25Wiki Titles News Titles Y Questions 20 News Reuters Med WSD Majority guess .83 13.26 1.82 .48 6.47 34.20 IR 3.14 ( .25 ) 14.20 ( .06 ) 6.15 ( .06 ) 19.57 ( .95 ) 8.37 ( .55 ) 52.99 ( .64 ) IR+Roc 2.93 ( .24 ) 14.20 ( .06 ) 8.35 ( 1.12 ) 25.09 ( .93 ) 19.33 ( 1.87 ) 59.89 ( .54 ) IR+NB 5.44 ( .53 ) 32.98 ( 2.13 ) 14.45 ( .45 ) 30.45 ( 1.46 ) 62.59 ( 2.43 ) 82.12 ( .41 ) IR+LR 3.26 ( .30 ) 13.44 ( .10 ) 7.38 ( 2.08 ) 34.76 ( 1.50 ) 6.48 ( .07 ) 68.35 ( .38 ) ST-0 3.16 ( .32 ) 16.03 ( .16 ) 6.15 ( .02 ) 19.49 ( .98 ) 6.79 ( .17 ) 69.11 ( .26 ) ST-1", "entities": []}, {"text": "5.62 ( .29 ) 24.34 ( .36 ) 10.02 ( .49 ) 22.91 ( 1.29 ) 55.77 ( 1.62 ) 82.97 ( .56 ) GE 9.55 ( .90 ) 14.54 ( .08 ) 31.72 ( .05 ) 48.71 ( .41 ) 21.65 ( 27.36 ) 62.63 ( .37 ) sLDA", "entities": []}, {"text": "7.07 ( 0.97 ) 51.16 ( 8.10 ) 40.98 ( 2.61 ) 24.80 ( 4.98 ) 30.61 ( 4.80 ) 69.81 ( 1.09 ) Cosine 27.67 ( .59 ) 33.49 ( .11 ) 31.16 ( .03 ) 26.19 ( .75 ) 6.56 ( .16 ) 32.65 ( .19 ) WENB 26.70 ( .48 ) 63.02 ( .10 ) 44.89 ( .06 ) 32.23 ( .48 ) 34.99 ( 1.99 ) 68.27 ( .20 ) WENB+LR 24.88 ( .39 ) 63.76 ( .11 ) 45.69 ( .09 ) 30.57 ( .71 ) 32.04 ( 1.44 ) 62.57 ( .19 ) Table 2 : Macro - averaged F1(% ) of compared methods on different data sets .", "entities": []}, {"text": "The numbers are \u201c mean ( standard deviation ) \u201d of 5 - fold cross validation .", "entities": []}, {"text": "Top two numbers in each column are highlighted in boldface .", "entities": []}, {"text": "Data set # of labels Wiki Titles 1500 News Titles 200 Y Questions 1500 - 2000 20 News 100 - 200 Reuters 100 - 200 Med WSD 20 / task \u0002198 tasks Table 3 : Number of true labels needed for a logistic regression classi\ufb01er to achieve the same performance as \u201c WENB+LR \u201d .", "entities": [[42, 44, "MethodName", "logistic regression"]]}, {"text": "Three short text data sets are ( 1 ) Wiki Titles : Wikipedia article titles sampled from 15 main categories ( Wikipedia Main Topic ) .", "entities": []}, {"text": "( 2 ) News Titles : The UCI news title data set ( Lichman , 2013 ) .", "entities": []}, {"text": "( 3 ) Y Questions : User - posted questions in Yahoo Answers ( Yahoo Language Data , 2007 ) .", "entities": []}, {"text": "Three long text data sets are ( 1 ) 20 News : The well - known 20 newsgroup data set .", "entities": []}, {"text": "( 2 ) Reuters .", "entities": []}, {"text": "The Reuters-21578 data set ( Lewis ) .", "entities": [[1, 2, "DatasetName", "Reuters-21578"]]}, {"text": "We take the articles from the 10 largest topics .", "entities": []}, {"text": "( 3 ) Med WSD : The MeSH word sense disambiguation ( WSD ) data set ( Jimeno - Yepes et", "entities": [[8, 11, "TaskName", "word sense disambiguation"]]}, {"text": "al . , 2011 ) .", "entities": []}, {"text": "Each WSD task aims to tell the sense ( meaning ) of an ambiguous term in a MEDLINE abstract .", "entities": []}, {"text": "For instance , the term \u201c cold \u201d may refer to Low Temperature , Common Cold , orChronic Obstructive Lung Disease , depending on its context .", "entities": []}, {"text": "These senses are used as the class labels .", "entities": []}, {"text": "We use 198 ambiguous words with at least 100 labeled abstracts in the data set , and report the average statistics over 198 independent classi\ufb01cation tasks .", "entities": []}, {"text": "Although no true labels are used for training , some methods require unlabeled data for retrieval , pseudo - labeling , and re - training .", "entities": []}, {"text": "We split unlabeled data into 5 folds , using 4 folds to \u201c train \u201d a classi\ufb01er and 1 fold for test .", "entities": []}, {"text": "We use macroaveragedF1as the performance metric because not all data sets have a balanced class distribution.4.3 Results and Discussion Label savings .", "entities": []}, {"text": "Table 2 shows that overall , class labels can train text classi\ufb01ers remarkably better than majority guess .", "entities": []}, {"text": "This is no small feat considering that the classi\ufb01er has not seen any labeled documents yet .", "entities": []}, {"text": "Such performance gain essentially comes \u201c for free \u201d , as any text classi\ufb01cation task has to start by de\ufb01ning classes .", "entities": []}, {"text": "In Table 3 , we report the number of true labels needed for a logistic regression model to achieve the same performance as WENB+LR .", "entities": [[14, 16, "MethodName", "logistic regression"]]}, {"text": "The most signi\ufb01cant savings happen on short documents : class labels are equivalent to hundreds to thousands of labeled documents at the beginning of the training process .", "entities": []}, {"text": "Effect of document length .", "entities": []}, {"text": "On short documents ( Wiki Titles , News Titles , Y Questions ) , leveraging unlabeled data does not help with most semi - supervised methods due to severe vocabulary mismatch .", "entities": []}, {"text": "The proposed methods ( WENB and WENB+LR ) show robust performance , because pretrained word vectors can capture semantic similarity even without any word overlap between a class label and a document .", "entities": [[18, 20, "TaskName", "semantic similarity"]]}, {"text": "This prior knowledge is essential when documents are short .", "entities": []}, {"text": "On long documents ( 20 News , Reuters , Med WSD ) , leveraging unlabeled data helps , since long documents have richer content and are more likely to contain not only label words themselves , but also other topic - speci\ufb01c words .", "entities": []}, {"text": "Retrieval - based and semi - supervised methods are able to learn these words by exploiting intra - document word co - occurrences .", "entities": []}, {"text": "Performance of other methods .", "entities": []}, {"text": "Learning from class labels themselves provides very limited help ( IR and ST-0 ) .", "entities": []}, {"text": "Using class labels as search queries and labeled documents are closely related : IR and ST-0 perform similarly ; so do IR+NB and ST-1 .", "entities": []}, {"text": "When using class labels as search queries ,", "entities": []}, {"text": "26 101102103 # true labels00.20.40.60.81Figure 2 : Continued training behavior : Atheism vs. Autos .", "entities": []}, {"text": "Colored band:\u00061standard deviation .", "entities": []}, {"text": "re - ranking ( IR+Roc ) is less useful than training classi\ufb01ers ( IR+NB and IR+LR ) .", "entities": []}, {"text": "After initial retrieval , training a na \u00a8\u0131ve Bayes classi\ufb01er is almost always better than a logistic regression classi\ufb01er ( IR+NB vs. IR+LR ) , demonstrating the power of generative models when supervision signal is sparse .", "entities": [[16, 18, "MethodName", "logistic regression"]]}, {"text": "Using class labels as labeled features ( GE and sLDA ) performs well occasionally ( GE on 20 News ; sLDA on Y Questions ) , but not consistently .", "entities": []}, {"text": "The Cosine method performs well only on Wiki Titles , the shortest documents , because without supervision , representing a long document as an average of word vectors causes signi\ufb01cant information loss .", "entities": [[31, 32, "MetricName", "loss"]]}, {"text": "Finally , it is encouraging to see WENB+LR sometimes outperform WENB , as WENB+LR is much smaller than WENB+LR in terms of model size .", "entities": []}, {"text": "4.4 Continued Training and Error Analysis Figure 2 and 3 compare logistic regression classi\ufb01ers trained with and without pseudo labels generated by WENB .", "entities": [[4, 5, "MetricName", "Error"], [11, 13, "MethodName", "logistic regression"]]}, {"text": "Note that the classi\ufb01er trained with pseudo labels ( cont . train ) has a much lower performance variance than the logistic regression classi\ufb01er trained only on true labels ( LR ) .", "entities": [[21, 23, "MethodName", "logistic regression"]]}, {"text": "The warm - started classi\ufb01er can serve as a good starting point for further training .", "entities": []}, {"text": "Figure 2 shows a salient warm - start effect on a balanced binary classi\ufb01cation task in 20 News .", "entities": []}, {"text": "The weight \u0016of pseudo labels increases when true labels are few ( initial classi\ufb01er as an informative prior ) .", "entities": []}, {"text": "As expected , \u0016 decreases when true labels become abundant .", "entities": []}, {"text": "Figure 3 shows another binary classi\ufb01cation task in 20 News where the warm - start effect is limited .", "entities": []}, {"text": "Correspondingly , \u0016quickly diminishes as more true labels are available .", "entities": []}, {"text": "With 100 or more true labels , pseudo labels have a negligible weight ( \u0016= 10\u00002 ) .", "entities": []}, {"text": "In machine learning terms , these pseudo labels specify an incorrect prior that the model should quickly forget , so that it will not hinder the overall learning process .", "entities": []}, {"text": "101102103 # true labels00.20.40.60.81Figure 3 : Continued training behavior : Medical vs. Mideast .", "entities": []}, {"text": "Colored band:\u00061standard deviation .", "entities": []}, {"text": "A closer investigation reveals that the word vector for mideast ( the class label of one topic in Figure 3 ) is not well - trained .", "entities": []}, {"text": "This is because in general text corpus , the word mideast is rather infrequent compared to commonly used alternatives , such as middle east .", "entities": []}, {"text": "The word vector of mideast is surrounded by other infrequent words or misspellings ( such as hizballah , jubeir , saudis , isreal ) as opposed to more frequent and relevant ones ( such as israel , israeli , saudi , arab ) .", "entities": []}, {"text": "Since WENB uses the semantic knowledge in word vectors to infer pseudo labels , the quality of class label word vectors will affect the pseudo label accuracy .", "entities": [[26, 27, "MetricName", "accuracy"]]}, {"text": "5 Conclusion and Future Directions We studied the problem of training topic classi\ufb01ers using only class labels .", "entities": []}, {"text": "Experiments on six data sets show that class labels can save a signi\ufb01cant amount of labeled examples in the beginning .", "entities": []}, {"text": "Retrieval - based and semi - supervised methods tend to perform better on long documents , while the proposed method performs better on short documents .", "entities": []}, {"text": "This study opens up many interesting avenues for future work .", "entities": []}, {"text": "First , we introduce a new perspective on text classi\ufb01cation : can we build a text classi\ufb01er by just providing a short description of each class ?", "entities": []}, {"text": "This is a more challenging ( but more user - friendly ) setup than standard supervised classi\ufb01cation .", "entities": []}, {"text": "Second , future work can investigate tasks such as sentiment and emotion classi\ufb01cation , which are more challenging than topic classi\ufb01cation tasks .", "entities": [[11, 12, "DatasetName", "emotion"]]}, {"text": "Third , the two approaches \u2013 leveraging unlabeled data ( retrievalbased and semi - supervised methods ) and leveraging pretrained models ( the proposed method ) \u2013 could be combined to give robust performance on both short and long documents .", "entities": []}, {"text": "Finally , we can invite users into the training loop : in addition to labeling documents , users can also revise the class de\ufb01nitions to improve the classi\ufb01er .", "entities": []}, {"text": "27Acknowledgments We thank the anonymous reviewers for their helpful comments .", "entities": []}, {"text": "This work was in part supported by the National Library of Medicine under grant number 2R01LM010681 - 05 .", "entities": []}, {"text": "Qiaozhu Mei \u2019s work was supported in part by the National Science Foundation under grant numbers 1633370 and 1620319 .", "entities": []}, {"text": "Yue Wang would like to thank the support of the Eleanor M. and Frederick G. Kilgour Research Grant Award by the UNC - CH School of Information and Library Science .", "entities": []}, {"text": "References 2014 .", "entities": []}, {"text": "WMT 2014", "entities": [[0, 2, "DatasetName", "WMT 2014"]]}, {"text": "English News Crawl .", "entities": []}, {"text": "http://www.statmt.org/wmt14/ training - monolingual - news - crawl .", "entities": []}, {"text": "Ricardo Baeza - Yates , Berthier de Ara \u00b4 ujo Neto Ribeiro , et al . 2011 .", "entities": []}, {"text": "8.3.2 Naive Text Classi\ufb01cation , chapter 8 .", "entities": []}, {"text": "New York : ACM Press ; Harlow , England : Addison - Wesley , .", "entities": [[3, 4, "DatasetName", "ACM"]]}, {"text": "Ciprian Chelba , Tomas Mikolov , Mike Schuster , Qi Ge , Thorsten Brants , Phillipp Koehn , and Tony Robinson . 2013 .", "entities": []}, {"text": "One billion word benchmark for measuring progress in statistical language modeling .", "entities": [[0, 3, "DatasetName", "One billion word"]]}, {"text": "arXiv preprint arXiv:1312.3005 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "W Bruce Croft , Donald Metzler , and Trevor Strohman .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Retrieval Models , chapter 7 . Addison - Wesley Reading .", "entities": []}, {"text": "Gregory Druck , Gideon Mann , and Andrew McCallum .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Learning from labeled features using generalized expectation criteria .", "entities": []}, {"text": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval , pages 595\u2013602 . ACM .", "entities": [[7, 8, "DatasetName", "ACM"], [15, 17, "TaskName", "information retrieval"], [21, 22, "DatasetName", "ACM"]]}, {"text": "Swapnil Hingmire and Sutanu Chakraborti .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Topic labeled text classi\ufb01cation : a weakly supervised approach .", "entities": []}, {"text": "In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval , pages 385\u2013394 . ACM .", "entities": [[6, 7, "DatasetName", "ACM"], [14, 16, "TaskName", "information retrieval"], [20, 21, "DatasetName", "ACM"]]}, {"text": "Jagadeesh Jagarlamudi , Hal Daum \u00b4 e III , and Raghavendra Udupa .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Incorporating lexical priors into topic models .", "entities": [[4, 6, "TaskName", "topic models"]]}, {"text": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics , pages 204\u2013213 . Association for Computational Linguistics .", "entities": []}, {"text": "Antonio J Jimeno - Yepes , Bridget T McInnes , and Alan R Aronson .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Exploiting mesh indexing in medline to generate a data set for word sense disambiguation .", "entities": [[11, 14, "TaskName", "word sense disambiguation"]]}, {"text": "BMC bioinformatics , 12(1):223 .", "entities": []}, {"text": "David D. Lewis .", "entities": []}, {"text": "Reuters-21578 .", "entities": [[0, 1, "DatasetName", "Reuters-21578"]]}, {"text": "http : //www.daviddlewis.com / resources/ testcollections / reuters21578 .M Lichman .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Uci machine learning repository [ http://archive .", "entities": [[0, 4, "DatasetName", "Uci machine learning repository"]]}, {"text": "ics .", "entities": []}, {"text": "uci .", "entities": []}, {"text": "edu / ml ] .", "entities": []}, {"text": "university of california , school of information and computer science .", "entities": []}, {"text": "Irvine , CA .", "entities": []}, {"text": "Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Jeff Dean .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Distributed representations of words and phrases and their compositionality .", "entities": []}, {"text": "In Advances in neural information processing systems , pages 3111\u20133119 .", "entities": []}, {"text": "NLM .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "MEDLINE / PubMed Data . ftp://ftp.ncbi.nlm.nih.gov/pubmed/ baseline .", "entities": []}, {"text": "Agnieszka Oni \u00b4 sko , Marek J Druzdzel , and Hanna Wasyluk .", "entities": []}, {"text": "2001 .", "entities": []}, {"text": "Learning bayesian network parameters from small data sets : Application of noisy - or gates .", "entities": []}, {"text": "International Journal of Approximate Reasoning , 27(2):165\u2013182 .", "entities": []}, {"text": "Sinno Jialin Pan and Qiang Yang .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "A survey on transfer learning .", "entities": [[3, 5, "TaskName", "transfer learning"]]}, {"text": "IEEE Transactions on knowledge and data engineering , 22(10):1345\u20131359 .", "entities": []}, {"text": "Pushpankar Kumar Pushp and Muktabh Mayank Srivastava . 2017 .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "Train once , test anywhere : Zeroshot learning for text classi\ufb01cation .", "entities": []}, {"text": "arXiv preprint arXiv:1712.05972 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "J. J. Rocchio .", "entities": []}, {"text": "1965 .", "entities": []}, {"text": "Relevance feedback in information retrieval , report no .", "entities": [[3, 5, "TaskName", "information retrieval"]]}, {"text": "ISR-9 to the National Science Foundation , The Computation Laboratory of Harvard University , to appear August .", "entities": []}, {"text": "Robert E Schapire , Marie Rochery , Mazin Rahim , and Narendra Gupta . 2002 .", "entities": []}, {"text": "Incorporating prior knowledge into boosting .", "entities": []}, {"text": "In ICML , volume 2 , pages 538 \u2013 545 .", "entities": []}, {"text": "Richard Socher , Milind Ganjoo , Christopher D Manning , and Andrew Ng . 2013 .", "entities": []}, {"text": "Zero - shot learning through cross - modal transfer .", "entities": [[0, 4, "TaskName", "Zero - shot learning"]]}, {"text": "In Advances in neural information processing systems , pages 935\u2013943 .", "entities": []}, {"text": "Wikipedia Main Topic .", "entities": []}, {"text": "Category : Main topic classi\ufb01cations .", "entities": []}, {"text": "https://en.wikipedia .", "entities": []}, {"text": "org / wiki / Category : Main_topic _ classifications .", "entities": []}, {"text": "Yahoo Language Data . 2007 .", "entities": []}, {"text": "Yahoo !", "entities": []}, {"text": "Answers Comprehensive Questions and Answers version 1.0 ( multi part ) .", "entities": []}, {"text": "https://webscope.sandbox .", "entities": []}, {"text": "yahoo.com/catalog.php?datatype=l .", "entities": []}, {"text": "Chengxiang Zhai and John Lafferty .", "entities": []}, {"text": "2001 .", "entities": []}, {"text": "A study of smoothing methods for language models applied to ad hoc information retrieval .", "entities": [[12, 14, "TaskName", "information retrieval"]]}, {"text": "In Proceedings of 24th International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 334\u2013342 .", "entities": [[5, 6, "DatasetName", "ACM"], [13, 15, "TaskName", "Information Retrieval"]]}, {"text": "Xiaojin Zhu . 2006 .", "entities": []}, {"text": "Semi - supervised learning literature survey .", "entities": []}, {"text": "Computer Science , University of WisconsinMadison , 2(3):4 .", "entities": []}, {"text": "28A", "entities": []}, {"text": "Class Labels Used in Each Data Set Data set Class labels Wiki Titles Arts , Games , Geography , Health , History , Industry , Law , Life , Mathematics , Matter , Nature , People , Religion , Science / Technology , Society News Titles Business , Technology , Entertainment , Health Y - Questions Society / Culture , Science / Mathematics , Health , Education / Reference , Computers / Internet , Sports , Business / Finance , Entertainment / Music , Family Relationships , Politics / Government 20 News Atheism , Graphics , Microsoft , IBM , Mac , Windows , Sale , Autos , Baseball , Motorcycles , Hockey , Encrypt , Electronics , Medical , Space , Christian Guns , Mideast , Politics , Religion Reuters Earnings / Forecasts , Mergers / Acquisitions , Crude Oil , Trade , Foreign Exchange , Interest Rates , Money Supply , Shipping , Sugar , Coffee Table 4 : Class labels in 5 topic classi\ufb01cation data sets .", "entities": []}, {"text": "Task ( ambiguous term)Class labels ( senses ) AA Amino Acids , Alcoholics Anonymous ADA Adenosine Deaminase , American Dental Association ADH Alcohol dehydrogenase , Argipressin ADP Adenosine Diphosphate , Automatic Data Processing Adrenal Adrenal Glands , Epinephrine Ala Alanine , Alpha - Linolenic Acid , Aminolevulinic Acid ALS Antilymphocyte Serum , Amyotrophic Lateral Sclerosis ANA American Nurses \u2019 Association , Antibodies , Antinuclear Arteriovenous AnastomosesArteriovenous anastomosis procedure , Structure of anatomicarteriovenous anastomosis Astragalus Talus , Astragalus Plant B - Cell Leukemia B - Cell Leukemia , Chronic Lymphocytic Leukemia BAT Chiroptera , Brown Fat BLM Bloom Syndrome , Bleomycin Borrelia Lyme Disease , Borrelia bacteria BPD Bronchopulmonary Dysplasia , Borderline PersonalityDisorder BR Brazil , Bromides Brucella abortus Brucella abortus infection , Brucella abortus bacterium BSA Body Surface Area , Bovine Serum Albumin BSE Bovine SpongiformEncephalopathy , Breast Self - Examination Ca Hippocampus ( Brain ) , Calcium , California , Canada Table 5 : The \ufb01rst 20 ambiguous terms / tasks in Med WSD data set .", "entities": [[48, 49, "MethodName", "ALS"], [80, 81, "DatasetName", "Cell"], [84, 85, "DatasetName", "Cell"]]}]