[{"text": "Findings of the Association for Computational Linguistics : EMNLP 2020 , pages 4752\u20134765 November 16 - 20 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics4752Probabilistic Case - based Reasoning for Open - World Knowledge Graph Completion Rajarshi Das , Ameya Godbole , Nicholas Monath , Manzil Zaheer , Andrew McCallum University of Massachusetts , Amherst , USA Google Research , USA frajarshi , agodbole , nmonath , mccallum g@cs.umass.edu", "entities": [[13, 16, "TaskName", "Knowledge Graph Completion"], [37, 38, "DatasetName", "Google"]]}, {"text": "manzilzaheer@google.com", "entities": []}, {"text": "Abstract A case - based reasoning ( CBR ) system solves a new problem by retrieving \u2018 cases \u2019 that are similar to the given problem .", "entities": []}, {"text": "If such a system can achieve high accuracy , it is appealing owing to its simplicity , interpretability , and scalability .", "entities": [[7, 8, "MetricName", "accuracy"]]}, {"text": "In this paper , we demonstrate that such a system is achievable for reasoning in knowledgebases ( KBs ) .", "entities": []}, {"text": "Our approach predicts attributes for an entity by gathering reasoning paths from similar entities in the KB .", "entities": []}, {"text": "Our probabilistic model estimates the likelihood that a path is effective at answering a query about the given entity .", "entities": []}, {"text": "The parameters of our model can be ef\ufb01ciently computed using simple path statistics and require no iterative optimization .", "entities": []}, {"text": "Our model is non - parametric , growing dynamically as new entities and relations are added to the KB .", "entities": []}, {"text": "On several benchmark datasets our approach signi\ufb01cantly outperforms other rule learning approaches and performs comparably to state - of - the - art embedding - based approaches .", "entities": []}, {"text": "Furthermore , we demonstrate the effectiveness of our model in an \u201c open - world \u201d setting where new entities arrive in an online fashion , signi\ufb01cantly outperforming state - ofthe - art approaches and nearly matching the best of\ufb02ine method.1 1 Introduction We live in an evolving world with a lot of heterogeneity as well as new entities being created continuously .", "entities": []}, {"text": "For example , scienti\ufb01c papers and Wikipedia pages describing facts about new entities , are being constantly added ( e.g. COVID -19 ) .", "entities": []}, {"text": "These new \ufb01ndings further trigger the inference of newer facts , each with its own diverse reasoning .", "entities": []}, {"text": "We are interested in developing such automated reasoning systems for large knowledge - bases ( KBs ) .", "entities": []}, {"text": "In machine learning , non - parametric methods hold the promise of handling evolving data ( Cover 1Code available at https://github.com/ ameyagodbole / Prob - CBRand Hart , 1967 ; Rasmussen , 2000 ) .", "entities": []}, {"text": "Most current KG completion models learn low dimensional parametric representation of entities and relations via tensor factorization or sophisticated neural approaches ( Nickel et al . , 2011 ; Bordes et al . , 2013 ; Socher et al . , 2013 ; Sun et al . , 2019 ; Vashishth et al . , 2020 ) .", "entities": []}, {"text": "Another line of work learns Hornclause style reasoning rules from the KG and stores them in its parameters ( Rockt \u00a8aschel and Riedel , 2017 ; Das et al . , 2018 ; Minervini et al . , 2020 ) .", "entities": []}, {"text": "However , these parametric approaches work with a \ufb01xed set of entities and it is unclear how these models will adapt to new entities .", "entities": []}, {"text": "This paper presents a k - nearest neighbor ( KNN ) based approach for KG reasoning that is reminiscent of case - based reasoning ( CBR ) in classical AI .", "entities": []}, {"text": "A CBR system solves a new problem by retrieving \u2018 cases \u2019 that are similar to the given problem , revising the solution to retrieved cases ( if necessary ) and reusing it for the new problem ( Schank , 1982 ; Leake , 1996 , inter - alia ) .", "entities": []}, {"text": "For the task of \ufb01nding a target entity given a source entity and binary KG relation ( e.g. ( JOHN VONNEUMAN , PLACE OFDEATH , ? ) in Figure 1 ) , our approach \ufb01rst retrieves ksimilar entities ( cases ) to the query entity .", "entities": []}, {"text": "Next , for each retrieved entity , it \ufb01nds multiple KG paths2(each path is a solution to retrieved cases ) to the entity they are connected by the query relation ( e.g. paths between ( RICHARD FEYNMAN , USA ) ) .", "entities": []}, {"text": "However , one solution seldom works for all queries .", "entities": []}, {"text": "For example , even though the path \u2018 BORN IN \u2019 is predictive of \u2018 PLACE OFDEATH \u2019 for US - born scientists ( \ufb01gure 1 ) , it does not work for scientists who have immigrated to USA .", "entities": []}, {"text": "To handle this , we present a probabilistic CBR approach which learns to weighs paths with respect to an estimate of its prior and its precision , given the query .", "entities": []}, {"text": "The prior of a path rep2A path is a contiguous sequence of KG facts such as RICHARD FEYNMAN!AFFILIATED!CALTECH!LOCATED!USA .", "entities": []}, {"text": "4753 Richard   Feynman   Murray   Gelmann Sheldon   Lee Albert   Einstein   Germany born IAS Princeton   USAaffiliation   located   John   Von   Neumann   Hungary place_of_death born affiliation   Edward   Teller born place_of _ death    Lawrence   Livermore   affiliation   place_of_death ?", "entities": []}, {"text": "located   USAborn place_of_death born born place_of _ death   place_of _ death", "entities": []}, {"text": "Caltech affiliation   affiliation Boston U. affiliation   located   located   Edward   Teller John   Von   Neumann P(e2", "entities": []}, {"text": "| p = ( born ) , c=1 ,   q", "entities": []}, {"text": "= place_of_death )", "entities": []}, {"text": "= 0", "entities": [[1, 2, "DatasetName", "0"]]}, {"text": "P(e2|p = ( affiliation ,   located_in , c=1 ,   q = place_of_death ) = 1 Albert   Einstein Cluster = 1 P(e2 |", "entities": []}, {"text": "p = ( born ) , c=2 ,   q = place_of_death ) = 1   P(e2|p = ( affiliation ,   located_in , c=2 ,   q = place_of_death ) = 1 Richard   Feynman   Sheldon   LeeMurray   Gelmann Cluster = 2   Query : ( Jon Von Neumann ,   place_of_death , ? )", "entities": []}, {"text": "Albert Einstein , Edward Teller ,   Richard Feynman , Murray   Gelmann , Sheldon Lee .", "entities": []}, {"text": "KNN - Search John   Von   Neumann   Paths gathered from KNN entities :   1 ) place_of_death(x , y ) \u21d0 born(x , y )   2 ) place_of_death(x , y ) \u21d0   affiliation(x , z ) ^", "entities": []}, {"text": "located(z , y )   Figure 1 : Given the query , ( J ONVONNEUMANN , PLACE OFDEATH , ? ) , our model gathers reasoning paths from similar entities such as other scientists .", "entities": []}, {"text": "However , not all gathered paths work for a query e.g. the path ( \u2018 BORN ( x , y ) \u2019 ) would not work for V ONNEUMANN .", "entities": []}, {"text": "This highlights the importance of learning path weights for clusters of similar entities .", "entities": []}, {"text": "Even though \u2018 BORN IN \u2019 could be a reasonable path for predicting PLACE OFDEATH , this does not apply for V ONNEUMANN and other scientists in his cluster .", "entities": []}, {"text": "The precision parameter of the path given the cluster helps in penalizing the \u2018 BORN IN \u2019 path .", "entities": []}, {"text": "Note that the node USA is repeated twice in the \ufb01gure to reduce clutter .", "entities": []}, {"text": "resents its frequency while the precision represents the likelihood that the path will lead to a correct answer entity .", "entities": []}, {"text": "To obtain robust estimates of the path parameters , we cluster similar entities together and compute them by simple count statistics ( \u00a7 2.2.3 ) .", "entities": []}, {"text": "Apart from computing these estimates , our method needs no further training .", "entities": []}, {"text": "Overall , our simple approach outperforms several recent parametric rule learning methods ( Das et al . , 2018 ; Minervini et al . , 2020 ) and performs competitively with various state - of - the - art KG completion approaches ( Dettmers et al . , 2018 ) on multiple datasets .", "entities": []}, {"text": "An advantage of non - parametric models is that it can adapt to growing data by adjusting its number of parameters .", "entities": [[18, 21, "HyperparameterName", "number of parameters"]]}, {"text": "In the same spirit , we show that our model can seamlessly handle an \u2018 open - world \u2019 setting in which new entities arrive in the KG .", "entities": []}, {"text": "This is made possible by several design choices such as ( a ) representing entities as sparse ( non - learned ) vector of its relation types ( \u00a7 2.2.1 ) , ( b ) our use of an online non - parametric hierarchical clustering algorithm ( Monath et al . , 2019 ) that can ef\ufb01ciently recompute changes in cluster assignments because of the newly added entity ( \u00a7 2.3 ) , ( c ) and a simple and ef\ufb01cient way of recomputing the prior and precision parameters for paths per cluster ( \u00a7 2.2.3 ) .", "entities": []}, {"text": "Current models for KG completion that learn entity representations for a \ufb01xed set of entities can not handle the open - world setting .", "entities": []}, {"text": "In fact we show that , retraining the models continually with new data leads to severe degradation of the model performance with models forgetting what it had learned before .", "entities": []}, {"text": "For example , the performance ( MRR ) ofROTATE model ( Sun et al . , 2019 ) drops by 11 points ( absolute ) on WN18RR in this setting ( \u00a7 3.4 ) .", "entities": [[6, 7, "MetricName", "MRR"], [26, 27, "DatasetName", "WN18RR"]]}, {"text": "On the other hand , we show that with new data , the performance of our model is consistent as it is able to seamlessly reason with the newly arrived data .", "entities": []}, {"text": "Our work is most closely related to a recent concurrent work by Das et al .", "entities": []}, {"text": "( 2020 ) where they propose a model that gathers paths from entities similar to the query entity .", "entities": []}, {"text": "However , Das et al . ( 2020 ) encourages path that occur frequently in the KG and does not learn to weigh paths differently for queries .", "entities": []}, {"text": "This often leads to wrong inference leading to low performance .", "entities": []}, {"text": "For example , on the test - II evaluation subset of FB122 where all triples can be inferred by logical rules , Das et al .", "entities": [[11, 12, "DatasetName", "FB122"]]}, {"text": "( 2020 ) scores quite low ( 63 MRR ) because of learning incorrect rules .", "entities": [[8, 9, "MetricName", "MRR"]]}, {"text": "On the other hand , we score signi\ufb01cantly higher ( 94.83 MRR ) demonstrating that we can learn more effective rules .", "entities": [[11, 12, "MetricName", "MRR"]]}, {"text": "In fact , we consistently and signi\ufb01cantly outperform Das et al .", "entities": []}, {"text": "( 2020 ) on several benchmark datasets .", "entities": []}, {"text": "Also , unlike us , they do not test themselves in the challenging open - world setting .", "entities": []}, {"text": "The contributions of this paper are as follows : ( a ) We present a KNN based approach for KG completion that gathers reasoning paths from entities that are similar to the query entity .", "entities": []}, {"text": "Following a principled probabilistic approach ( \u00a7 2.2 ) , our model weighs each path by its likelihood of reaching a correct answer which penalizes paths that are spurious in nature .", "entities": []}, {"text": "( b ) The parameters of our model grow with data and can be estimated ef\ufb01ciently using simple count statistics ( \u00a7 2.3 ) .", "entities": []}, {"text": "Apart from this , our approach needs no training .", "entities": []}, {"text": "We show that our", "entities": []}, {"text": "4754simple approach signi\ufb01cantly outperforms various rule learning methods ( Das et al . , 2018 ;", "entities": []}, {"text": "Minervini et al . , 2020 ; Das et al . , 2020 ) on many benchmark datasets .", "entities": []}, {"text": "( c ) We also show that our model can easily handle addition of facts about new entities and is able to seamlessly integrate and reason with the newly added data signi\ufb01cantly outperforming parametric embedding based models .", "entities": []}, {"text": "2 Non - parametric Reasoning in KGs 2.1 Notation and Task Description LetVdenote the set of entities , Rdenote the set of binary relations and Gdenote a KB or equivalently a Knowledge Graph ( KG ) .", "entities": []}, {"text": "Formally , G= ( V;E;R)is a directed labeled multigraph where VandEdenote the vertices and edges of the graph respectively .", "entities": []}, {"text": "Note that , E\u0012V\u0002R\u0002V. Let(e1;r;e2)denote a fact in Gwhere e1,e22V andr2E. Also , following previous approaches ( Bordes et al . , 2013 ) , we add the inverse relation of every edge , i.e. , for an fact ( e1;r;e2)2E , we add the edge ( e2;r\u00001;e1)to the graph .", "entities": []}, {"text": "( If the set of binary relations Rdoes not contain the inverse relation r\u00001 , it is added to Ras well ) .", "entities": []}, {"text": "Task : We consider the task of query answering on KGs , i.e. , answering questions of the form ( e1q;rq ; ? ) , where answer is an entity in the KG .", "entities": []}, {"text": "Paths in KG : A path in a KG between two entitieses , etis de\ufb01ned as a sequence of alternating entity and relations that connect esandet .", "entities": []}, {"text": "A length of a path is the number of relation ( edges ) in the path .", "entities": []}, {"text": "Formally , let a path p=", "entities": []}, {"text": "( e1;r1;e2 ; : : : ; rn;en+1 ) with st(p ) = e1,en(p )", "entities": []}, {"text": "= en+1and len(p )", "entities": []}, {"text": "= n. We also de\ufb01ne a path type as the sequence of the relations in p , i.e. , type(p ) = ( r1;r2 ; : : : ; rn ) .", "entities": []}, {"text": "LetP denote the set of all paths in G. LetPn\u0012P = fpj len(p)\u0014ngbe the set of all paths of length up to n. Also , let Pndenote the set of all path types with length up to n , i.e. Pn = ftype(p)jp2Png .", "entities": []}, {"text": "Let Pn(e1;r)\u0012Pndenote all path types of length up tonthat originate at e1and end at the entities that are connected to e1by a direct edge of type r.", "entities": []}, {"text": "In other words , if Se1r = fe2j(e1;r;e2)2Ggdenotes the set of entities that are connected to e1via a direct edge r , then Pn(e1;r)denotes the set of all path types of length up to n that start from e1and end at entities in Se1r .", "entities": []}, {"text": "By de\ufb01nition , r2Pn(e1;r ) .", "entities": []}, {"text": "Similarly , we de\ufb01ne Pn(e1;r)which contain paths instead of path types.2.2 Model Given a query , our approach gathers KG path types from entities that are similar to the query entity .", "entities": []}, {"text": "Each path type is weighed with respect to an estimate of both its frequency and precision ( \u00a7 2.2.1 ) .", "entities": []}, {"text": "By clustering similar entities together ( \u00a7 2.2.2 ) , our model obtains robust estimate of the path statistics ( \u00a7 2.2.3 ) .", "entities": []}, {"text": "Our approach is non - parametric because - ( a ) Instead of storing reasoning rules in parameters ( Das et al . , 2018 ; Minervini et al . , 2020 ) , it derives them dynamically from k - similar entities ( like a non - parametric k - nn classi\ufb01er ( Cover and Hart , 1967 ) ) .", "entities": [[49, 52, "MethodName", "k - nn"]]}, {"text": "( b ) We cluster entities together using a non - parametric clustering approach and provide an ef\ufb01cient way of adding / estimating parameters when entities are added to the KG ( \u00a7 2.3 ) .", "entities": []}, {"text": "2.2.1 Reasoning from contextual entities Our approach \ufb01rst \ufb01nds ksimilar entities to the query entity that have atleast an edge of type rq .", "entities": []}, {"text": "For example , for the query ( MELINDA GATES , WORKS INCITY , ? ) , we would consider WARREN BUFFET if we observe ( WARREN BUFFET , WORKS INCITY , OMAHA ) .", "entities": []}, {"text": "We refer to these entities as \u2018 contextual entities \u2019 .", "entities": []}, {"text": "Each entity is represented as a sparse vector of its outgoing edge types , i.e.ei2f0;1gjRj .", "entities": []}, {"text": "If entity eihasmdistinct outgoing edge types , then the dimension corresponding to those types are set to 1 .", "entities": []}, {"text": "This is an extremely simple and \ufb02exible way of representing entities which we \ufb01nd to work well .", "entities": []}, {"text": "Also note that , as more data is added about an entity , this sparse representation makes it trivial to update the embeddings .", "entities": []}, {"text": "LetEc;qdenote the set of contextual entities for the query q.", "entities": []}, {"text": "To compute Ec;q , we \ufb01rst sort entities with respect to their cosine distance with respect to query entity and select the kentities with the least distance and which have the query relation rq .", "entities": []}, {"text": "For each contextual entity ec , we gather the path types ( up to length n ) that connect ecto the entities it is connected by the edge rq(i.e . Pn(ec;rq ) in\u00a72.1 ) .", "entities": []}, {"text": "These extracted path types will be used to reason about the query entity .", "entities": []}, {"text": "Let Pn(Ec;q;rq )", "entities": []}, {"text": "= S ec2Ec;qPn(ec;rq)represent the set of unique path types from the contextual entities .", "entities": []}, {"text": "The probability of \ufb01nding the answer entity e2given the query is given by : P(e2je1q;rq ) = \u00e5 p2Pn(E(c;q);rq)P(e2;pje1q;rq ) = \u00e5 pP(pje1q;rq)P(e2jp;e1q;rq)(1 )", "entities": []}, {"text": "4755We marginalize the random variable representing the path types obtained from Ec;q .", "entities": []}, {"text": "P(pje1q;rq ) denotes the probability of \ufb01nding a path type given the query .", "entities": []}, {"text": "This term captures how frequently each path type co - occurs with a query and represents the prior probability for a path type .", "entities": []}, {"text": "On the other hand , P(e2jp;e1q;rq)captures the proportion of times , when a path type pis traversed starting from the query entity , we reach the correct answer instead of some other entity .", "entities": []}, {"text": "This term can be understood as capturing the likelihood of reaching the right answer or the \u2019 precision \u2019 of a reasoning path type .", "entities": []}, {"text": "This is crucial in penalizing \u2018 spurious \u2019 path types that sometimes coincidentally \ufb01nd the right answer entity .", "entities": []}, {"text": "For example , for the query relation WORKS INCITY , the path type ( FRIEND^ LIVES INCITY ) might have a high prior probability ( since people often have many friends in the city where they work ) .", "entities": []}, {"text": "However , this path is \u2018 spurious \u2019 with respect to WORKS INCITY , since they might have friends living in various cities and hence this path type will not necessarily return the correct answer .", "entities": []}, {"text": "2.2.2", "entities": []}, {"text": "Entity Clustering Equation 1 has parameters for each entity in the KG .", "entities": []}, {"text": "For large KGs , this can quickly lead to parameter explosion .", "entities": []}, {"text": "Also , estimating per - entity parameter leads to noisy estimates due to sparsity .", "entities": []}, {"text": "Instead , we choose to cluster similar entities together .", "entities": []}, {"text": "Let cbe a random variable representing the cluster assignment of the query entity .", "entities": []}, {"text": "Then for the pathprior term , we have P(pje1q;rq ) = \u00e5 cP(cje1q;rq)P(pjc;e1q;rq ) We assume that each entity is assigned to one cluster , so P(cje1q;rq)is zero for all clusters except the cluster in which the query entity belongs to .", "entities": []}, {"text": "Secondly we assume , that the prior probability of a path given the entity and cluster can be determined from the cluster alone and is independent of each entity in the cluster .", "entities": []}, {"text": "In other words , if ce1qis the cluster in which the e1;qhas been assigned , then P(pjce1q;e1q;rq ) = P(pjce1q;rq ) .", "entities": []}, {"text": "Instead of perentity parameters , we now aggregate statistics over entities in the same cluster and have per - cluster parameters .", "entities": []}, {"text": "We also show that this leads to significantly better performance ( \u00a7 3.3 ) .", "entities": []}, {"text": "A similar argument applies for the path - precision term in which we calculate the proportion of times , a path leads to the correct answer entity starting from each entity in the cluster .", "entities": []}, {"text": "To perform clustering , we use hierarchical agglomerative clustering with average linkage with the entity - entity similarity de\ufb01ned in \u00a7 2.2.1 .", "entities": []}, {"text": "We extract a non - parameteric number of clusters from the hierarchy using a threshold on the linkage function .", "entities": []}, {"text": "Agglomerative clustering has been shown to be effective in many knowledge - base related tasks such as entity resolution ( Lee et al . , 2012 ; Vashishth et al . , 2018 ) and in general has shown to outperform \ufb02at clustering methods such as K - means ( Green et al . , 2012 ; Kobren et", "entities": [[17, 19, "TaskName", "entity resolution"]]}, {"text": "al . , 2017 ) .", "entities": []}, {"text": "A \ufb02at clustering is extracted from the hierarchical clustering by using a threshold on the linkage function score .", "entities": []}, {"text": "We perform a breadth \ufb01rst search from the root of the tree stopping at nodes for which the linkage is above the given threshold .", "entities": []}, {"text": "The nodes where the search stops give a \ufb02at clustering ( refer to \u00a7 A.2 for more detail on this ) .", "entities": []}, {"text": "2.2.3 Parameter Estimation Next we discuss how to estimate path prior and precision terms .", "entities": []}, {"text": "There exists abundant modeling choices to estimate them .", "entities": []}, {"text": "For example , following Chen et al .", "entities": []}, {"text": "( 2018 ) , we could train a neural network model to estimate P(pjce1q;rq ) .", "entities": []}, {"text": "However , with our original goal of designing a simple and ef\ufb01cient non - parametric model , we estimate these parameters by simple count statistics from the KG .", "entities": []}, {"text": "E.g. , the path prior P(pjc;rq)is estimated as \u00e5ec2c\u00e5p02Pn(ec;rq ) 1[type(p0 ) = p ] \u00e5ec2c\u00e5p02Pn(ec;rq ) 1(2 )", "entities": []}, {"text": "For each entity in cluster c , we consider the paths that connect ecto entities it is directly connected to via edge type rq(Pn(ec;rq)in\u00a72.1 ) .", "entities": []}, {"text": "The path prior for a path type pis computed as the proportion of times the type of paths in Pn(ec;rq)is equal to p. Note that in equation 2 , if a path type appears multiple times , we count all instances .", "entities": []}, {"text": "For example , for the query relation WORKS INCITY , a path of the form ( COWORKER^WORKS INCITY ) can occur multiple times , since a person can have multiple different co - workers .", "entities": []}, {"text": "Considering just path types will lead to under - weighing of such important paths .", "entities": []}, {"text": "Similarly , the path - precision probability ( P(e2jp;c;rq ) ) can be estimated as , \u00e5ec2c\u00e5p02Pn(ec ) 1[type(p0 ) = p]\u0001 1[en(p0)2Secrq ] \u00e5ec2c\u00e5p02Pn(ec )", "entities": []}, {"text": "1[type(p0 )", "entities": []}, {"text": "= p ] ( 3 ) LetPn(ec)denote the paths of up to length nstarting from the entity ec .", "entities": []}, {"text": "Note , unlike Pn(ec;rq ) , the", "entities": []}, {"text": "4756 Bill   Gates Gates   Found .", "entities": []}, {"text": "Seattle Microsoft   located ex - chair USA nationality cityDurham   Steve friend   ( a ) An initial incomplete KG ( Melinda Gates , CEO , Gates Found . )   ( Melinda Gates , spouse , Bill Gates )   ( Melinda Gates , nationality , USA )   ( Melinda Gates , friend , Steve )   ( Melinda Gates , studied Duke University )   ( Duke University , located , Durham )   ( b ) New entities ( Melinda Gates , Duke   Univ ) and facts are added to KG .", "entities": [[22, 23, "DatasetName", "Melinda"], [33, 34, "DatasetName", "Melinda"], [43, 44, "DatasetName", "Melinda"], [52, 53, "DatasetName", "Melinda"], [61, 62, "DatasetName", "Melinda"], [84, 85, "DatasetName", "Melinda"]]}, {"text": "Bill   Gates   Gates   Found .", "entities": []}, {"text": "Seattle Microsoft   located ex - chair USAnationality   city Durham Steve   friend   Melinda   Gates   Duke   Univ .   ceostudied   located friend   spouseworks_in_city ? located ?", "entities": [[15, 16, "DatasetName", "Melinda"]]}, {"text": "( c ) New facts can be derived from the new and   existing facts such as ( Melinda Gates , works_in_city ,   ? )", "entities": [[18, 19, "DatasetName", "Melinda"]]}, {"text": "and ( Duke Univ , located_in , ? )", "entities": []}, {"text": "nationality Figure 2 : We consider a setting where new entities and facts are added continuously to the KG .", "entities": []}, {"text": "Our non - parametric approach can seamlessly reason with the newly added entities and can infer new facts about them ( e.g. ( M ELINDA , WORKS INCITY , ? )", "entities": []}, {"text": "or ( D UKE UNIV.,LOCATED INCOUNTRY , ? ) ) without requiring expensive training .", "entities": []}, {"text": "paths in Pn(ec)do not have to end at speci\ufb01c entities .", "entities": []}, {"text": "Also from \u00a7 2.1,en(p)denotes the end entity for a path pandSecrqdenotes the set of entities that are connected to ecvia a direct edge of type rq .", "entities": []}, {"text": "Equation 3 , therefore , estimates the proportion of times the path psuccessfully ends at one of the answer entities when starting from ec , given rq .", "entities": []}, {"text": "There are several advantages in estimating the parameters using simple count statistics .", "entities": []}, {"text": "Firstly , they are extremely simple , and statistics for each entity in clusters can be computed in parallel making them extremely time ef\ufb01cient .", "entities": []}, {"text": "Secondly once they are computed , our approach needs no further training .", "entities": []}, {"text": "Lastly , when new data is added , it makes it easy to update the parameters without training from scratch .", "entities": []}, {"text": "To summarize , given a query entity ( e1q;rq ) , our method gathers reasoning paths from ksimilar entities to e1q .", "entities": []}, {"text": "These reasoning paths are then traversed in the KG starting from e1q , leading to a set of candidate answer entities .", "entities": []}, {"text": "The score of each answer entity candidate is computed as a weighted sum of the reasoning paths the lead to them ( Equation 1 ) .", "entities": []}, {"text": "Each path is weighed with an estimate of its frequency ( Equation 2 ) and precision ( Equation 3 ) given the query relation .", "entities": []}, {"text": "The next section describes how we extend our model for open - world setting where new entities and facts are added to the KB .", "entities": []}, {"text": "2.3 Open - world Setting A great bene\ufb01t of non - parametric models is that it can seamlessly handle growing data by adding new parameters .", "entities": []}, {"text": "New entities constantly arrive in the world ( e.g. new Wikipedia articles about entities are frequently created ) .", "entities": []}, {"text": "We consider a setting ( Figure 2 ) in which new entities with few facts ( edges ) about them keep getting added to the KG .", "entities": []}, {"text": "This setting is challenging for parametric models ( Das et al . , 2018 ; Sun et al . , 2019 ) as it is unclear howthese models can incorporate new entities without retraining from scratch .", "entities": []}, {"text": "However , retraining to obtain entity embeddings on industrial scale KGs might be impractical ( e.g. consider Facebook social graph where new users are joining continuously ) .", "entities": [[5, 7, "TaskName", "entity embeddings"]]}, {"text": "Next , we show that our approach can handle this setting ef\ufb01ciently in the following way : ( a)Adding / updating entity representations : First we need to create entity representations for the newly arrived entities .", "entities": []}, {"text": "Also , for some existing entities for which new edges were added ( e.g. BILL GATES , DURHAM , etc . in \ufb01gure 2 ) , their representations need to be updated .", "entities": []}, {"text": "Recall , that we represent entities as a sparse vector of its edge types and hence this step is trivial for our approach .", "entities": [[0, 1, "MetricName", "Recall"]]}, {"text": "( b)Updating cluster assignments : Next the new entities needs to be added to clusters of similar entities .", "entities": []}, {"text": "Also , the cluster assingments of entities that got updated can also change as well and their change can further trigger changes to the clustering of other entities .", "entities": []}, {"text": "To handle this , one could naively cluster all entities in the KG , however that could be wasteful and time - consuming for large KGs .", "entities": []}, {"text": "Instead , we use an online hierarchical clustering algorithm - GRINCH ( Monath et al . , 2019 ) , which has shown to perform as well as agglomerative clustering in the online setting .", "entities": []}, {"text": "GRINCH observes one entity at a time , placing it next to its nearest neighbor and performing local re - arrangements in the form of rotations of tree nodes and global rearrangments in the form of grafting a subtrees from part of the tree to another .", "entities": []}, {"text": "Entities can be deleted from a hierarchy by simply removing the corresponding leaf node .", "entities": []}, {"text": "We \ufb01rst use GRINCH to delete the entities whose representations had changed because of the addition of the new node and then incrementally add those entities back along with the newly added entities in the KG .", "entities": []}, {"text": "We extract a \ufb02at clustering from the hierarchical clustering built", "entities": []}, {"text": "4757jVj jRj j Ej NELL-995 75,492 200 154,213 FB122 9,738 122 112,476 WN18RR 40,943 11 93,003 Table 1 : Dataset Statistics by G RINCH using the same method as in \u00a7 2.2.2 .", "entities": [[4, 5, "DatasetName", "NELL-995"], [8, 9, "DatasetName", "FB122"], [12, 13, "DatasetName", "WN18RR"]]}, {"text": "( c)Re - estimating new parameters : After reassigning clusters , the \ufb01nal step is to estimate the per - cluster parameters .", "entities": []}, {"text": "This computation is ef\ufb01cient as it is clear from equations 2 and 3 that the contribution from each entity in a cluster can be computed independently ( and hence can be easily parallelized ) .", "entities": []}, {"text": "However , even for each entity , this computation needs path traversal in the KG which is expensive .", "entities": []}, {"text": "We show that we do not have to recompute for all entities in the clusters .", "entities": []}, {"text": "Letndenote the maximum length of a reasoning path considered by our model .", "entities": []}, {"text": "For every new entity eiadded to the KG , we need to recompute statistics for entities that lie within cycles of length up to ( n+1)starting from ei .", "entities": []}, {"text": "Please refer to appendix ( A.4 ) for a justi\ufb01cation of this result .", "entities": []}, {"text": "3 Experiments In this section , we evaluate our proposed approach on a wide array of knowledge - base completion ( KBC ) benchmarks ( \u00a7 3.3 ) .", "entities": []}, {"text": "To evaluate the nonparametric nature of our approach , we also evaluate on an \u2018 open - world \u2019 setting ( \u00a7 2.3 ) in which new entities are added to the KG .", "entities": []}, {"text": "We demonstrate our proposed approach is competitive to several stateof - the - art methods on benchmarks in the standard setting , but it greatly outperforms other methods in the online setting ( \u00a7 3.4 ) .", "entities": []}, {"text": "The best hyper - parameters for all experiments including the range of hyperparameter tried and results on validation set are noted in \u00a7 A.6 .", "entities": []}, {"text": "3.1 Data and Evaluation Protocol Data .", "entities": []}, {"text": "We evaluate on the following KBC datasets :", "entities": []}, {"text": "NELL-995 , FB122 ( Guo et al . , 2016 ) , WN18RR ( Dettmers et al . , 2018 ) .", "entities": [[0, 1, "DatasetName", "NELL-995"], [2, 3, "DatasetName", "FB122"], [12, 13, "DatasetName", "WN18RR"]]}, {"text": "FB122 is a subset of the dataset derived from Freebase , FB15 K ( Bordes et al . , 2013 ) , containing 122 relations regarding people , locations , and sports .", "entities": [[0, 1, "DatasetName", "FB122"]]}, {"text": "NELL-995 ( Xiong et al . , 2017 ) a subset of the NELL derived from the 995th iteration of the system .", "entities": [[0, 1, "DatasetName", "NELL-995"], [13, 14, "DatasetName", "NELL"]]}, {"text": "WN18RR was created by Dettmers et al .", "entities": [[0, 1, "DatasetName", "WN18RR"]]}, {"text": "( 2018 ) from WN18 by removing inverse relation test - leakage .", "entities": [[4, 5, "DatasetName", "WN18"]]}, {"text": "Evaluation metrics .", "entities": []}, {"text": "Following previous work , we evaluate our method using HITS @N and mean reciprocal rank ( MRR ) , which are standard metrics for evaluating a ranked list .", "entities": [[16, 17, "MetricName", "MRR"]]}, {"text": "3.2 Experimental Setting Knowledge Base Completion .", "entities": [[3, 6, "TaskName", "Knowledge Base Completion"]]}, {"text": "Given an entity e1 and a relation r , our task is retrieve all entities e2 such that ( e1;r;e2)belongs in the edges Ein a KG G.", "entities": []}, {"text": "This task is known as tail prediction .", "entities": []}, {"text": "If the relation is instead the inverse relation r\u00001 , we assume that we are given an e0 2and asked to predict entitiese0 1such that ( e0 1;r\u00001;e0 2)belongs in the edges E(head prediction ) .", "entities": []}, {"text": "To be exactly comparable to baselines , we report an average of head and tail prediction results3 .", "entities": []}, {"text": "We are given a knowledge graph with three partitions of edges , Etrain , Edev , Etest .", "entities": []}, {"text": "For this task , we evaluate against several stateof - the - art embeddings based models such as DistMult ( Yang et al . , 2015 ) , ComplEx ( Trouillon et al . , 2016 ) , ConvE ( Dettmers et al . , 2018 ) , RotatE", "entities": [[48, 49, "MethodName", "RotatE"]]}, {"text": "( Sun et al . , 2019 ) .", "entities": []}, {"text": "We also compare against several parametric rule learning methods \u2014 NTP ( Rockt \u00a8aschel and Riedel , 2017 ) , NeuralLP ( Yang et al . , 2017 ) , MINERV A ( Das et al . , 2018 ) , GNTP ( Minervini et al . , 2020 ) and also the closely related CBR approach of Das et al .", "entities": []}, {"text": "( 2020 ) .", "entities": []}, {"text": "Open - world Knowledge Base Completion .", "entities": [[3, 6, "TaskName", "Knowledge Base Completion"]]}, {"text": "In this setting , we begin with the top 10 % of the most popular nodes ( with several edges going out from them ) and add more randomly selected nodes such that the initial seed KB contains 50 % of all the entities in V. This is to ensure , that the seed KB is not too sparse and the initial models trained on them are meaningful .", "entities": []}, {"text": "Next , any edges between the nodes selected are added to the seed KB .", "entities": []}, {"text": "We divide the rest of the entities randomly into 10 batches .", "entities": []}, {"text": "Each batch of entities is incrementally added to the KB along with the edges contained in it .", "entities": []}, {"text": "The validation and test set are also divided in the same way , i.e. if both the head and tail entity of a triple are present in the KB , only then the triple is put in the corresponding splits .", "entities": []}, {"text": "Parametric models for KBC that learn representations for a \ufb01xed set of entities can not handle \u2018 open - world \u2019 setting out - of - the - box .", "entities": []}, {"text": "We extend the most competitive embedding based model - RotatE ( Sun et al . , 2019 ) for this task .", "entities": [[9, 10, "MethodName", "RotatE"]]}, {"text": "For every new entity arriving in a batch , we initialize a new entity embedding for it .", "entities": []}, {"text": "We explore two ways of initial3except for NELL-995 dataset where like our baselines , we report tail - prediction performance .", "entities": [[7, 8, "DatasetName", "NELL-995"]]}, {"text": "4758Test - I Test - II Test - ALL Hits@N ( % ) MRRHits@N ( % ) MRRHits@N ( % ) MRR3 5 10 3 5 10 3 5 10With RulesKALE - Pre ( Guo et al . , 2016 )", "entities": []}, {"text": "35.8 41.9 49.8 0.291 82.9 86.1 89.9 0.713 61.7 66.2 71.8 0.523 KALE - Joint ( Guo et al . , 2016 )", "entities": []}, {"text": "38.4 44.7 52.2 0.325 79.7", "entities": []}, {"text": "84.1 89.6 0.684 61.2 66.4 72.8 0.523 ASR - DistMult ( Minervini et al . , 2017 ) 36.3 40.3 44.9 0.330 98.0 99.0 99.2 0.948 70.7 73.1 75.2 0.675 ASR - ComplEx ( Minervini et al . , 2017 ) 37.3 41.0 45.9 0.338 99.2 99.3 99.4 0.984 71.7 73.6 75.7 0.698 KBLR(Garcia - Duran and Niepert , 2018 ) \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 74.0 77.0 79.7 0.702Without", "entities": []}, {"text": "RulesTransE ( Bordes et al . , 2013 ) 36.0 41.5 48.1 0.296 77.5 82.8 88.4 0.630 58.9 64.2 70.2 0.480 DistMult ( Yang et al . , 2015 ) 36.0 40.3 45.3 0.313 92.3 93.8 94.7 0.874 67.4 70.2 72.9 0.628 ComplEx ( Trouillon et al . , 2016 )", "entities": []}, {"text": "37.0 41.3 46.2 0.329 91.4 91.9 92.4 0.887 67.3 69.5 71.9 0.641 GNTPs ( Minervini et al . , 2020 ) 33.7 36.9 41.2 0.313 98.2 99.0 99.3 0.977 69.2 71.1 73.2 0.678 RotatE", "entities": [[33, 34, "MethodName", "RotatE"]]}, {"text": "( Sun et al . , 2019 ) 51.1 55.1 60.3 0.471 86.8 88.6 90.7 0.846 70.8 73.57 77.0 0.678 CBR ( Das et al . , 2020 ) 40.0 44.5 48.8 0.359 67.8 71.8 75.9 0.636 57.0 61.2 65.3 0.527", "entities": []}, {"text": "Our Model 49.0 52.7 57.1 0.457 94.8 95.0 95.3 0.948 74.2 76.0 78.2 0.727 Table 2 : Link prediction results on FB122 .", "entities": [[17, 19, "TaskName", "Link prediction"], [21, 22, "DatasetName", "FB122"]]}, {"text": "Test - II denotes a subset of triples that can be inferred via logical rules .", "entities": []}, {"text": "Metric TransE DistMult ComplEx ConvE RotatE GNTP", "entities": [[1, 2, "MethodName", "TransE"], [5, 6, "MethodName", "RotatE"]]}, {"text": "MINERV A CBR Our Model HITS @1 - 0.39 0.41 0.40 0.43 0.41 0.40 0.38 0.43 HITS @3 - 0.44 0.46 0.44 0.49 0.44 0.43 0.46 0.49 HITS @10 0.50 0.49 0.51 0.52 0.57 0.48 0.49 0.51 0.55 MRR 0.23 0.43 0.44 0.43 0.48 0.43 0.43 0.43 0.48 HITS @1 0.53 0.61 0.61 0.67 0.65 - 0.66 0.70 0.77 HITS @3 0.79 0.73 0.76 0.81 0.82 - 0.77 0.83 0.85 HITS @10 0.87 0.79 0.83 0.86 0.87 - 0.83 0.87 0.89 MRR 0.67 0.68 0.69 0.75 0.74 - 0.72 0.77 0.81", "entities": [[38, 39, "MetricName", "MRR"], [81, 82, "MetricName", "MRR"]]}, {"text": "Table 3 : Results on WN18RR ( above ) and NELL-995 ( tail - prediction;below ) izing the new entity embeddings \u2014 ( a ) random initialization , and ( b ) average of element - wise rotation of entity embeddings w.r.t the relation that this new entity is connected to .", "entities": [[5, 6, "DatasetName", "WN18RR"], [10, 11, "DatasetName", "NELL-995"], [19, 21, "TaskName", "entity embeddings"], [39, 41, "TaskName", "entity embeddings"]]}, {"text": "Speci\ufb01cally , let t denote the new entity and let S = f(h;r;t)gbe the facts associated with entity t.", "entities": []}, {"text": "Then the embedding etis computed as et = \u00e5(h;r;t)2Seh\u000eer jSj(4 )", "entities": []}, {"text": "Here,\u000erepresents the Hadamard ( or element - wise ) product .", "entities": []}, {"text": "This initialization minimizes the RotatE objective for the new embedding ensuring that it is \u201c well - placed \u201d according to the model in the previous time step .", "entities": [[4, 5, "MethodName", "RotatE"]]}, {"text": "Embeddings for new relations are initialized randomly .", "entities": []}, {"text": "Next , the model is further trained on the new batch of triples so that the new entity embeddings get trained .", "entities": [[17, 19, "TaskName", "entity embeddings"]]}, {"text": "Note , for massive KGs , it might be impractical to re - train on the entire data as new batches of data arrive frequently , however to still prevent the model to forget what it had learned before , we also sample m% of triples that it had already been trained on and re - train on them .", "entities": []}, {"text": "We ensure that triples in the neighborhood of the newly added entities are ten times likely to be sampled more than other triples .", "entities": []}, {"text": "We also try a setting where we try freezing the initially trained entity embeddings and only training the new entityand relation embeddings .", "entities": [[12, 14, "TaskName", "entity embeddings"]]}, {"text": "3.3 Results on KBC benchmarks The results for KBC tasks are presented in Table 2 and 34 .", "entities": []}, {"text": "Our method does signi\ufb01cantly better than parametric rule learning approaches such as MINERV A , GNTPs and the recent case - based approach of Das et al .", "entities": []}, {"text": "( 2020 ) .", "entities": []}, {"text": "We would like to highlight the difference between the performance of our model and that of Das et al .", "entities": []}, {"text": "( 2020 ) on the test - II evaluation of FB122 where triples can be answered by learning logical rules .", "entities": [[10, 11, "DatasetName", "FB122"]]}, {"text": "This results emphasizes the importance of our probabilistic weighing of paths .", "entities": []}, {"text": "We also perform comparably to most embedding based models and achieve state - of - the - art results on the overall test sets of FB122 and NELL-995 .", "entities": [[25, 26, "DatasetName", "FB122"], [27, 28, "DatasetName", "NELL-995"]]}, {"text": "We report the mean over 3 runs for our model .", "entities": []}, {"text": "We perform an ablation where we do not cluster entities ( i.e. every entity has its own cluster ) and have per - entity parameters .", "entities": []}, {"text": "Table 4 notes the drop in performance due to the noisy estimates of path prior and precision parameters because of sparsity .", "entities": []}, {"text": "Table 6 shows an example where our model learns to score different paths based on the type of entities present in the cluster .", "entities": []}, {"text": "Effect of path length on WN18RR :", "entities": [[5, 6, "DatasetName", "WN18RR"]]}, {"text": "On the dev set of WN18RR , out of 2985 queries where 4There are no reported results of GNTPs on NELL-995", "entities": [[5, 6, "DatasetName", "WN18RR"], [20, 21, "DatasetName", "NELL-995"]]}, {"text": "4759Our Method Our Method w/o clustering HITS @1 0.42 0.29 HITS @3 0.46 0.36 HITS @10 0.51 0.45 MRR 0.45 0.34 Table 4 : Impact of clustering on WN18RR", "entities": [[18, 19, "MetricName", "MRR"], [28, 29, "DatasetName", "WN18RR"]]}, {"text": "RotatE", "entities": [[0, 1, "MethodName", "RotatE"]]}, {"text": "Our Method Our Method ( n=3 ) ( n=5 ) HITS @1 0.43 0.42 0.43 HITS @3 0.49 0.46 0.49 HITS @10 0.57 0.51 0.55 MRR 0.48 0.45 0.48 Table 5 : Impact of path length on WN18RR our method does not rank the answer in the top10,2030 queries require a minimum path length greater than 3 .", "entities": [[25, 26, "MetricName", "MRR"], [37, 38, "DatasetName", "WN18RR"]]}, {"text": "Path - based reasoning models have no power to answer these queries .", "entities": []}, {"text": "To correct for this , we perform an experiment with the path length n=5(950of2030 answers are reachable ) .", "entities": []}, {"text": "The results in Table 5 show that our method recovers a signi\ufb01cant portion of performance when allowed to use longer reasoning paths .", "entities": []}, {"text": "3.4 Open - World KBC results Figure 3 reports the result for this task .", "entities": []}, {"text": "We report results on the RotatE model with randomly initialized embeddings for new entities ( RotatE ) and the model with systematic initialization of new entity embeddings ( RotatE+ ) .", "entities": [[5, 6, "MethodName", "RotatE"], [15, 16, "MethodName", "RotatE"], [25, 27, "TaskName", "entity embeddings"]]}, {"text": "We experiment with m = f10%;30%gof previously seen edges and retrain on them .", "entities": []}, {"text": "We \ufb01nd that not including previously seen edges leads to severe degradation of overall performance due to the model forgetting what it had learned in the past .", "entities": []}, {"text": "We also report results with freezing the already seen entity representations and only learning representations for new entities ( RotatE - Freeze ) .", "entities": [[19, 20, "MethodName", "RotatE"]]}, {"text": "All models were trained till the validation set ( containing both new and old triples ) performance stopped improving .", "entities": []}, {"text": "For our approach , we also report results for an oracle setting where we re - cluster all entities as new data arrives and re - estimate all parameters from scratch ( instead of using GRINCH and recomputing only required parameters ( \u00a7 2.3 ) .", "entities": []}, {"text": "For both datasets , the of\ufb02ine - best results were obtained by RotatE ( 47.1 for FB122 test - I , 48 for WN18RR ) .", "entities": [[12, 13, "MethodName", "RotatE"], [16, 17, "DatasetName", "FB122"], [23, 24, "DatasetName", "WN18RR"]]}, {"text": "We report performance on the entire evaluation set ( full ) and also on the set containing the newly added edges ( new ) .", "entities": []}, {"text": "The main summary of the results are ( i ) RotatE model converges to a much lower performance in the online setting losing", "entities": [[10, 11, "MethodName", "RotatE"]]}, {"text": "at least 8 MRR pointsin", "entities": [[3, 4, "MetricName", "MRR"]]}, {"text": "FB122", "entities": [[0, 1, "DatasetName", "FB122"]]}, {"text": "and at least 11 points in WN18RR .", "entities": [[6, 7, "DatasetName", "WN18RR"]]}, {"text": "On FB122 , we observe that the model prefers to learn new information more by sacri\ufb01cing previously learned facts ( 2nd sub\ufb01gure in \ufb01gure 3 ) ( ii ) In the freeze setting , the model performance deteriorates quickly after a certain point indicating saturation , i.e. it becomes hard for the model to learn new information about arriving entities by keeping the parameters of the existing entities \ufb01xed .", "entities": [[1, 2, "DatasetName", "FB122"]]}, {"text": "( iii ) On the full evaluation , RotatE+ performs better than RotatE showing that bad initialization deteriorates performance over time , however , there is still a large gap between the best performance ( iv ) Our approach almost matches our performance in oracle setting indicating the effectiveness of the online clustering and fast parameter approximation .", "entities": [[12, 13, "MethodName", "RotatE"]]}, {"text": "( v ) Lastly , we perform closest to the of\ufb02ine best results outperforming all variants of RotatE. 4 Related Work Open - world KG completion .", "entities": []}, {"text": "Shi and Weninger ( 2018 ) consider the task of open - world KG completion .", "entities": []}, {"text": "However , they use text descriptions to learn entity representations using convolutional neural networks .", "entities": []}, {"text": "Our model does not use additional text data and we use very simple entity representations that helps us to perform well .", "entities": []}, {"text": "Tang et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) learns to update a KG with new links by reading news .", "entities": []}, {"text": "Even though they handle adding or deleting new edges , they do not observe new entities .", "entities": []}, {"text": "Lastly , none of them learn from similar entities using a CBR approach .", "entities": []}, {"text": "Inductive representation learning on KGs .", "entities": [[1, 3, "TaskName", "representation learning"]]}, {"text": "Recent works ( Teru et al . , 2020 ; Wang et al . , 2020 ) learn entity independent relation representations and hence allow them to handle unseen entities .", "entities": []}, {"text": "However , they do not perform contextual reasoning by gathering reasoning paths from similar entities .", "entities": []}, {"text": "Moreoever , in our open - world setting , we consider the more challenging setting , where new facts and entities are arriving in a streaming fashion and we give an ef\ufb01cient way of updating parameters using online hierarchical clustering .", "entities": []}, {"text": "This allows our method to be applicable in settings where the initial KG is small and it grows continuously .", "entities": []}, {"text": "Rule induction in knowledge graphs .", "entities": [[3, 5, "TaskName", "knowledge graphs"]]}, {"text": "Classic work in inductive logic programming ( ILP ) ( Muggleton et al . , 1992 ; Quinlan , 1990 ) induce rules from grounded facts .", "entities": [[3, 6, "TaskName", "inductive logic programming"]]}, {"text": "However , they need explicit counter - examples which are not present in KBs and they do not scale to large KBs .", "entities": []}, {"text": "Recent ILP approaches ( Gal \u00b4 arraga et al . , 2013 , 2015 ) try to \ufb01x", "entities": []}, {"text": "4760 0 2 4 6 8 10 Time Step0.150.200.250.300.350.400.450.50MRR FB122", "entities": [[1, 2, "DatasetName", "0"], [9, 10, "DatasetName", "FB122"]]}, {"text": "Full ( 10 % ) RotatE+", "entities": []}, {"text": "RotatE RotatE freeze Ours - Online Ours - Oracle Offline Best 2 4 6 8 10 Time Step0.00.10.20.30.40.5MRR FB122 New ( 10 % ) 0 2 4 6 8 10 Time Step0.10.20.30.40.5MRR", "entities": [[0, 1, "MethodName", "RotatE"], [1, 2, "MethodName", "RotatE"], [18, 19, "DatasetName", "FB122"], [24, 25, "DatasetName", "0"]]}, {"text": "WN18RR", "entities": [[0, 1, "DatasetName", "WN18RR"]]}, {"text": "Full ( 10 % ) 2 4 6 8 10 Time Step0.00.10.20.30.40.5MRR WN18RR New ( 10 % ) 0 2 4 6 8 10 Time Step0.200.250.300.350.400.450.50MRR", "entities": [[12, 13, "DatasetName", "WN18RR"], [18, 19, "DatasetName", "0"]]}, {"text": "FB122", "entities": [[0, 1, "DatasetName", "FB122"]]}, {"text": "Full ( 30 % ) RotatE+", "entities": []}, {"text": "RotatE RotatE freeze Ours - Online Ours - Oracle Offline Best 2 4 6 8 10 Time Step0.00.10.20.30.40.5MRR FB122 New ( 30 % ) 0 2 4 6 8 10 Time Step0.20.30.40.5MRR WN18RR", "entities": [[0, 1, "MethodName", "RotatE"], [1, 2, "MethodName", "RotatE"], [18, 19, "DatasetName", "FB122"], [24, 25, "DatasetName", "0"], [32, 33, "DatasetName", "WN18RR"]]}, {"text": "Full ( 30 % ) 2 4 6 8 10 Time Step0.00.10.20.30.40.5MRR WN18RR New ( 30%)Figure 3 : Results for open - world setting when trained with 10 % ( top row ) and 30 % ( bottom row ) of already seen edges .", "entities": [[12, 13, "DatasetName", "WN18RR"]]}, {"text": "Our online method matches the of\ufb02ine version of our approach and outperforms the online variants of RotatE. After all data is observed our online method achieves results closest to the best of\ufb02ine method \u2019s results .", "entities": []}, {"text": "Athlete Cluster(athlete - led - sports - team , team - plays - in - league ) ( athlete - home - stadium , league - stadiums\u00001 ) Politician Cluster(politician - us - member - of - political - group , person - belongs - to - organization\u00001 , agent - belongs - to - organization ) ( agent - collaborates - with - agent , agent - belongs - to - organization ) Table 6 : High scoring paths in different clusters for the query agent - belongs - to - organization in NELL-995 this de\ufb01ciency by guessing counter examples from rules and making it more scalable .", "entities": [[49, 50, "DatasetName", "agent"], [58, 59, "DatasetName", "agent"], [64, 65, "DatasetName", "agent"], [66, 67, "DatasetName", "agent"], [86, 87, "DatasetName", "agent"], [94, 95, "DatasetName", "NELL-995"]]}, {"text": "Statistical relational learning methods ( Getoor and Taskar , 2007 ; Kok and Domingos , 2007 ; Schoenmackers et al . , 2010 ) and probabilistic logic approaches ( Richardson and Domingos , 2006 ; Broecheler et al . , 2010 ; Wang et al . , 2013 ) combine machine learning and logic to learn rules .", "entities": []}, {"text": "However , none of these work derive reasoning rules dynamically from similar entities in the knowledge graph .", "entities": []}, {"text": "Bayesian non - parametric approaches for linkprediction .", "entities": []}, {"text": "There is a rich body of work in bayesian non - parametrics to automatically learn the latent dimension of entities ( Kemp et al . , 2006 ; Xu et", "entities": []}, {"text": "al . , 2006 ) .", "entities": []}, {"text": "Our method does not learn latent dimension of entities , instead our work is nonparametric because it gathers reasoning paths from nearest neighbors and can seamlessly reason with new entities by ef\ufb01ciently updating parameters using online non - parametric hierarchical clustering .", "entities": []}, {"text": "Embedding - based approach for link prediction .", "entities": [[5, 7, "TaskName", "link prediction"]]}, {"text": "We also compare to the more popular embeddings based models based on tensor factorization or neural approaches ( Nickel et al . , 2011 ; Bordes et al . , 2013 ; Dettmers et al . , 2018 ; Sun et al . , 2019 ) .", "entities": []}, {"text": "Our simple approach which needs no iterative opti - mization outperforms most of them and performs comparably to the latest RotatE model .", "entities": [[20, 21, "MethodName", "RotatE"]]}, {"text": "Moreover we outperform RotatE in the online experiments .", "entities": [[3, 4, "MethodName", "RotatE"]]}, {"text": "CBR for KG completion .", "entities": []}, {"text": "There has been few attempts to apply CBR for knowledge management ( Dubitzky et al . , 1999 ; Bartlmae and Riemenschneider , 2000 ) , however they do not do contextualized reasoning or consider online settings .", "entities": []}, {"text": "Our work is most closely related to the recent work of Das et al .", "entities": []}, {"text": "( 2020 ) .", "entities": []}, {"text": "However , since it does not take in to account the importance of each path , it suffers from low performance , with our model outperforming it in several benchmarks .", "entities": []}, {"text": "5 Conclusion We present a simple yet accurate approach for probabilistic case - based reasoning in knowledge bases .", "entities": []}, {"text": "Our method is non - parametric , deriving reasoning rules dynamically from similar entities in the KB and is capable of handling new entities .", "entities": []}, {"text": "We cluster similar entities together and estimate per - cluster parameters that measures the prior and precision of paths using simple count statistics .", "entities": []}, {"text": "Our simple approach performs competitively to the best embeddings based models on several benchmarks and outperforms all models in the open - world setting .", "entities": []}, {"text": "4761Acknowledgements We thank anonymous reviewers and members of UMass IESL and NLP groups for helpful discussion and feedback .", "entities": []}, {"text": "This work is funded in part by the Center for Data Science and the Center for Intelligent Information Retrieval , and in part by the National Science Foundation under Grants No .", "entities": [[17, 19, "TaskName", "Information Retrieval"]]}, {"text": "IIS-1514053", "entities": []}, {"text": "and No . 1763618 , and in part by the Chan Zuckerberg Initiative under the project Scienti\ufb01c Knowledge Base Construction .", "entities": []}, {"text": "Any opinions , \ufb01ndings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily re\ufb02ect those of the sponsor .", "entities": []}, {"text": "References Kai Bartlmae and Michael Riemenschneider .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "Case based reasoning for knowledge management in kdd projects .", "entities": []}, {"text": "In PAKM .", "entities": []}, {"text": "Antoine Bordes , Nicolas Usunier , Alberto GarciaDuran , Jason Weston , and Oksana Yakhnenko .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Translating embeddings for modeling multirelational data .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Matthias Broecheler , Lilyana Mihalkova , and Lise Getoor .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Probabilistic similarity logic .", "entities": []}, {"text": "In UAI .", "entities": []}, {"text": "Wenhu Chen , Wenhan Xiong , Xifeng Yan , and William Wang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Variational knowledge graph reasoning .", "entities": []}, {"text": "In NAACL .", "entities": []}, {"text": "Thomas Cover and Peter Hart .", "entities": []}, {"text": "1967 .", "entities": []}, {"text": "Nearest neighbor pattern classi\ufb01cation .", "entities": []}, {"text": "IEEE transactions on information theory .", "entities": []}, {"text": "Rajarshi Das , Shehzaad Dhuliawala , Manzil Zaheer , Luke Vilnis , Ishan Durugkar , Akshay Krishnamurthy , Alex Smola , and Andrew McCallum .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Go for a walk and arrive at the answer : Reasoning over paths in knowledge bases using reinforcement learning .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Rajarshi Das , Ameya Gobole , Shehzaad Dhuliawala , Manzil Zaheer , and Andrew McCallum . 2020 .", "entities": []}, {"text": "Nonparametric reasoning in knowledge bases .", "entities": []}, {"text": "In AKBC .", "entities": []}, {"text": "Tim Dettmers , Pasquale Minervini , Pontus Stenetorp , and Sebastian Riedel .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Convolutional 2d knowledge graph embeddings .", "entities": [[2, 5, "TaskName", "knowledge graph embeddings"]]}, {"text": "In AAAI .", "entities": []}, {"text": "W Dubitzky , AG B \u00a8uchner , and FJ Azuaje .", "entities": []}, {"text": "1999 .", "entities": []}, {"text": "Viewing knowledge management as a case - based reasoning application .", "entities": []}, {"text": "In AAAI Workshop Technical Report , pages 23\u201327 .", "entities": []}, {"text": "Luis Gal \u00b4 arraga , Christina Te\ufb02ioudi , Katja Hose , and Fabian M Suchanek . 2015 .", "entities": []}, {"text": "Fast rule mining in ontological knowledge bases with amie+ .", "entities": []}, {"text": "In VLDB .Luis", "entities": []}, {"text": "Antonio Gal \u00b4 arraga , Christina Te\ufb02ioudi , Katja Hose , and Fabian Suchanek .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Amie : association rule mining under incomplete evidence in ontological knowledge bases .", "entities": []}, {"text": "In WWW .", "entities": []}, {"text": "Alberto Garcia - Duran and Mathias Niepert .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Kblrn : End - to - end learning of knowledge base representations with latent , relational , and numerical features .", "entities": []}, {"text": "In UAI .", "entities": []}, {"text": "Lise Getoor and Ben Taskar .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Introduction to statistical relational learning .", "entities": []}, {"text": "MIT press .", "entities": []}, {"text": "Spence Green , Nicholas Andrews , Matthew R Gormley , Mark Dredze , and Christopher D Manning .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Entity clustering across languages .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Shu Guo , Quan Wang , Lihong Wang , Bin Wang , and Li Guo . 2016 .", "entities": []}, {"text": "Jointly embedding knowledge graphs and logical rules .", "entities": [[2, 4, "TaskName", "knowledge graphs"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Charles Kemp , Joshua B Tenenbaum , Thomas L Grif\ufb01ths , Takeshi Yamada , and Naonori Ueda . 2006 .", "entities": []}, {"text": "Learning systems of concepts with an in\ufb01nite relational model .", "entities": []}, {"text": "In AAAI .", "entities": []}, {"text": "Ari Kobren , Nicholas Monath , Akshay Krishnamurthy , and Andrew McCallum . 2017 .", "entities": []}, {"text": "A hierarchical algorithm for extreme clustering .", "entities": []}, {"text": "In KDD .", "entities": []}, {"text": "Stanley Kok and Pedro Domingos .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Statistical predicate invention .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "David B Leake .", "entities": []}, {"text": "1996 .", "entities": []}, {"text": "Cbr in context : The present and future .", "entities": []}, {"text": "Case - based reasoning : Experiences , lessons , and future directions .", "entities": []}, {"text": "Heeyoung Lee , Marta Recasens , Angel Chang , Mihai Surdeanu , and Dan Jurafsky .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Joint entity and event coreference resolution across documents .", "entities": [[3, 6, "TaskName", "event coreference resolution"]]}, {"text": "In EMNLP / CoNLL .", "entities": []}, {"text": "Pasquale Minervini , Matko Bo \u02c7snjak , Tim Rockt \u00a8aschel , Sebastian Riedel , and Edward Grefenstette .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Differentiable reasoning on large knowledge bases and natural language .", "entities": []}, {"text": "In AAAI .", "entities": []}, {"text": "Pasquale Minervini , Thomas Demeester , Tim Rockt \u00a8aschel , and Sebastian Riedel . 2017 .", "entities": []}, {"text": "Adversarial sets for regularising neural link predictors .", "entities": []}, {"text": "arXiv preprint arXiv:1707.07596 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Nicholas Monath , Ari Kobren , Akshay Krishnamurthy , Michael R Glass , and Andrew McCallum .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Scalable hierarchical clustering with tree grafting .", "entities": []}, {"text": "InKDD .", "entities": []}, {"text": "Stephen Muggleton , Ramon Otero , and Alireza Tamaddoni - Nezhad .", "entities": []}, {"text": "1992 .", "entities": []}, {"text": "Inductive logic programming .", "entities": [[0, 3, "TaskName", "Inductive logic programming"]]}, {"text": "Springer .", "entities": []}, {"text": "Maximilian Nickel , V olker Tresp , and Hans - Peter Kriegel . 2011 .", "entities": []}, {"text": "A three - way model for collective learning on multi - relational data .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "J Ross Quinlan .", "entities": []}, {"text": "1990 .", "entities": []}, {"text": "Learning logical de\ufb01nitions from relations .", "entities": []}, {"text": "Machine learning .", "entities": []}, {"text": "4762Carl Edward Rasmussen .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "The in\ufb01nite gaussian mixture model .", "entities": []}, {"text": "In Neurips .", "entities": []}, {"text": "Matthew Richardson and Pedro Domingos .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Markov logic networks .", "entities": []}, {"text": "Machine learning .", "entities": []}, {"text": "Tim Rockt \u00a8aschel and Sebastian Riedel . 2017 .", "entities": []}, {"text": "End - toend differentiable proving .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Roger C Schank .", "entities": []}, {"text": "1982 .", "entities": []}, {"text": "Dynamic memory : A theory of reminding and learning in computers and people .", "entities": []}, {"text": "cambridge university press .", "entities": []}, {"text": "Stefan Schoenmackers , Oren Etzioni , Daniel S Weld , and Jesse Davis .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Learning \ufb01rst - order horn clauses from web text .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Baoxu Shi and Tim Weninger .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Open - world knowledge graph completion .", "entities": [[3, 6, "TaskName", "knowledge graph completion"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Richard Socher , Danqi Chen , Christopher D Manning , and Andrew Ng . 2013 .", "entities": []}, {"text": "Reasoning with neural tensor networks for knowledge base completion .", "entities": [[6, 9, "TaskName", "knowledge base completion"]]}, {"text": "In Neurips .", "entities": []}, {"text": "Zhiqing Sun , Zhi - Hong Deng , Jian - Yun Nie , and Jian Tang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Rotate :", "entities": []}, {"text": "Knowledge graph embedding by relational rotation in complex space .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Jizhi Tang , Yansong Feng , and Dongyan Zhao .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Learning to update knowledge graphs by reading news .", "entities": [[3, 5, "TaskName", "knowledge graphs"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Komal K Teru , Etienne Denis , and William L Hamilton .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Inductive relation prediction by subgraph reasoning .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "Th\u00b4eo Trouillon , Johannes Welbl , Sebastian Riedel , \u00b4 Eric Gaussier , and Guillaume Bouchard .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Complex embeddings for simple link prediction .", "entities": [[4, 6, "TaskName", "link prediction"]]}, {"text": "In ICML .", "entities": []}, {"text": "Shikhar Vashishth , Prince Jain , and Partha Talukdar .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Cesi : Canonicalizing open knowledge bases using embeddings and side information .", "entities": []}, {"text": "In WWW .", "entities": []}, {"text": "Shikhar Vashishth , Soumya Sanyal , Vikram Nitin , and Partha Talukdar . 2020 .", "entities": []}, {"text": "Composition - based multirelational graph convolutional networks .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Hongwei Wang , Hongyu Ren , and Jure Leskovec .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Entity context and relational paths for knowledge graph completion .", "entities": [[6, 9, "TaskName", "knowledge graph completion"]]}, {"text": "arXiv preprint arXiv:2002.06757 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "William Yang Wang , Kathryn Mazaitis , and William W Cohen .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Programming with personalized pagerank : a locally groundable \ufb01rst - order probabilistic logic .", "entities": []}, {"text": "In CIKM .", "entities": []}, {"text": "Wenhan Xiong , Thien Hoang , and William Yang Wang .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Deeppath :", "entities": []}, {"text": "A reinforcement learning method for knowledge graph reasoning .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Zhao Xu , V olker Tresp , Kai Yu , and Hans - Peter Kriegel .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "In\ufb01nite hidden relational models .", "entities": []}, {"text": "In UAI.Bishan Yang , Wen - tau Yih , Xiaodong He , Jianfeng Gao , and Li Deng . 2015 .", "entities": []}, {"text": "Embedding entities and relations for learning and inference in knowledge bases .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Fan Yang , Zhilin Yang , and William W Cohen . 2017 .", "entities": []}, {"text": "Differentiable learning of logical rules for knowledge base reasoning .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "4763Algorithm 1 Select a \ufb02at clustering from a tree structure .", "entities": []}, {"text": "1 : input : V : Entities , root : Root of tree , t : Threshold 2 : output : C1;C2;:::;CK : A \ufb02at partition 3 : f rontier", "entities": []}, {"text": "[ root ] 4 : result fg 5 : while f rontier is not empty do 6 : n f rontier : pop ( ) 7 : iflinkage ( n)>tthen 8 : result fng[result 9 : else 10 : forcinn : children do 11 : f rontier : push(c ) 12 : end for 13 : end if 14 : end while 15 : return result A Appendix A.1 Entity Clusters Both clustering methods used in this paper , hierarchical agglomerative clustering ( HAC ) and GRINCH measure similarities between sets of clusters via a linkage function .", "entities": []}, {"text": "In particular , we use average pairwise linkage .", "entities": []}, {"text": "For two sets AandB , this is de\ufb01ned as : 1 jAjjBj\u00e5 a2A\u00e5 a2Bsim(a;b ) ( 5 ) A.2 Selecting Flat Clusterings A hierarchical clustering Tover the entities V , encodes a large number of \ufb02at partitions of the entities , often referred to as tree consistent partitions in the clustering literature .", "entities": []}, {"text": "We select one of these tree consistent partitions using a threshold on the linkage function , t.", "entities": []}, {"text": "The algorithm performs a breadth \ufb01rst search starting at the root node .", "entities": []}, {"text": "The search stops at any node for which the linkage is above the given value t. Pseudocode is given in Algorithm 1 .", "entities": []}, {"text": "A.3 Number of Entity Updates Per Batch In Online Setting", "entities": []}, {"text": "We analyze the number of entities that need to be re - clustered and added in each round .", "entities": []}, {"text": "We observe that it is signi\ufb01cantly fewer than the number of entities in the KB .", "entities": []}, {"text": "Note that an online method like the one proposed in this paper just needs to run on the new and modi\ufb01ed entities while a batch algorithm would need to run on the entire KB . 0 2 4 6 8 Batch Number0500010000150002000025000300003500040000Number of Entities New in Batch Modi\ufb01ed in Batch Total in KBFigure 4 : Number of entities added to KB in each batch and number of entities modi\ufb01ed in each batch .", "entities": [[35, 36, "DatasetName", "0"]]}, {"text": "These new and modi\ufb01ed entities need to be updated in the clustering algorithm in each update .", "entities": []}, {"text": "A.4 Finding entities for re - estimating parameters Proposition : Let ndenote the maximum length of a reasoning path considered by our model .", "entities": []}, {"text": "For every new entity eiadded to the KG , we need to recompute statistics for entities that lie within cycles of length up to ( n+1)starting from ei .", "entities": []}, {"text": "We see from Eq 2 , that the estimate for the prior for a path type pdepends on Pn(ec;rq)i.e .", "entities": []}, {"text": "the set of paths that lead from ecto entities that are connected toecvia relation rq .", "entities": []}, {"text": "WLOG , say etis such an entity i.e. ( ec;rq;et)2G. When a new entity / edge is added to the KG , this set of paths might increase .", "entities": []}, {"text": "It is easy to see that the set Pn(ec;rq)is updated iff a new path pnewof length\u0014nappears between ec andet .", "entities": []}, {"text": "In this case , the edges in pnewwould form a cycle with the edge ( ec;rq;et ) .", "entities": []}, {"text": "The length of the cycle would be at most len(pnew)+1which in turn is at most of length n+1 .", "entities": []}, {"text": "This , to \ufb01nd entities for which the prior has changed after the addition of a new edge / entity , it is suf\ufb01cient to \ufb01nd entities lying on cycles of length up to n+1starting from the new entity / edge .", "entities": []}, {"text": "This mechanism for \ufb01nding entities for recomputation is only approximate when computing the precision .", "entities": []}, {"text": "We see from Eq 3 , that the numerator depends on paths that lead to the answer entity ( as with prior ) while denominator depends on all nlength paths around ec .", "entities": []}, {"text": "So , if the numerator is ever to be increased , we would catch that update by the proposed cycle \ufb01nding method .", "entities": []}, {"text": "However , even if an entity does not lie on a cycle with the new edge / entity , if there is a path of length nfrom ecto the new edge / entity , the denominator count would", "entities": []}, {"text": "4764People Professions Sports Org .", "entities": []}, {"text": "Religious Entities Marvin Gay Statistician St. Louis Blues Isalm", "entities": []}, {"text": "At time Shaquille O\u2019Neal Assoc .", "entities": []}, {"text": "football manager Orlando Pirates Russian Orthodox church t\u00001 Avril Lavinge Structural Engineer Shef\ufb01eld Wednesday FC Buddhism Woody Harrleson Financial backer Malaya national football team United Church of Christ", "entities": []}, {"text": "At time", "entities": []}, {"text": "Elliot Smith Harpsichordist Excelsior Rotterdam The Mormons t Barbara Stanwick Child Actor Seattle Super Sonic Eastern Rite Catholic Table 7 : Example Clusters discovered in online setting .", "entities": []}, {"text": "We show the assignment of new entities to the clusters in the particular time step ( below line ) .", "entities": []}, {"text": "WN18RR FB122 NELL-995 HITS @1 0.422 0.694 0.296 HITS @3 0.461 0.739 0.405 HITS @10 0.508 0.779 0.502 MRR 0.451 0.724 0.367 Table 8 : Results on Validation set WN18RR NELL-995 HITS @1 41.8\u0006(5.7e-2 ) 76.5\u00062e-1 HITS @3 46.5\u00060 85.2\u00067e-2 HITS @10 51.3\u0006(5.7e-2 ) 89.5\u00061.4e-2 MRR 45\u0006(5.7e-2 )", "entities": [[0, 1, "DatasetName", "WN18RR"], [1, 2, "DatasetName", "FB122"], [2, 3, "DatasetName", "NELL-995"], [18, 19, "MetricName", "MRR"], [29, 30, "DatasetName", "WN18RR"], [30, 31, "DatasetName", "NELL-995"], [45, 46, "MetricName", "MRR"]]}, {"text": "81.45 \u00062e-1 Table 9 : Mean and Variance across different hyperparams be incremented .", "entities": []}, {"text": "Thus , the precision estimates for some entities might be an over - estimate of the path precision ( had it been recomputed after new edges are added to the KB ) .", "entities": []}, {"text": "A.5 Example Clusters Table 7 shows some example of new entities arriving and getting assigned to their respective clusters by G RINCH .", "entities": []}, {"text": "A.6 Reproducibility Checklist Computing Infrastructure : All our experiments were run on a Xeon E5 - 2680 v4 @ 2.40GHz CPU with 128 GB RAM .", "entities": [[24, 25, "MethodName", "RAM"]]}, {"text": "No GPUs were needed for the experiments .", "entities": []}, {"text": "The results on the validation set are reported in table 8 and avg . of 3 runs are reported in table 9 .", "entities": []}, {"text": "The NELL-995 does not come with a validation set , and therefore we selected 3000 edges randomly from the full NELL KB .", "entities": [[1, 2, "DatasetName", "NELL-995"], [20, 21, "DatasetName", "NELL"]]}, {"text": "As a result , many of the query relations were different from what was present in the splits of NELL-995 and hence is not a good representative .", "entities": [[19, 20, "DatasetName", "NELL-995"]]}, {"text": "However , we report test results for the best hyper - parameter values that we got on this validation set .", "entities": []}, {"text": "The \ufb01xed number of parameters in our modelare essentially the sparse non - learned entity vectors ( which can be easily stored in COO format without taking much space ) .", "entities": [[2, 5, "HyperparameterName", "number of parameters"]]}, {"text": "Other than that , our model is non - parametric with the number of parameters tied to the data .", "entities": [[12, 15, "HyperparameterName", "number of parameters"]]}, {"text": "For experiments on WN18RR : \u000fInference time : 18.9 queries / s ( total of 6268 queries ) \u000fTrain time : around 20 mins .", "entities": [[3, 4, "DatasetName", "WN18RR"]]}, {"text": "\u000fBest Hyper - parameters : \u2013 Number of nearest - neighbor entities ( K ): 40 \u2013 Number of paths from neighbors ( N ): 60 \u2013 Max length of path ( n ): 5 \u2013 Linkage for hierarchical clustering ( l ): 0.25 \u000fHyper - parameter method / bounds : Grid search \u2013 K : [ 5 , 10 , 15 , 20 , 30 , 40 , 50 ] \u2013 N : [ 5 , 10 , 20 , 40 , 60 , 80 ] \u2013 l : [ 0.25 , 0.3 , 0.35 , 0.4 , 0.45 , 0.5 , 0.6 ]", "entities": []}, {"text": "For experiments on FB122 : \u000fInference time : \u000fTrain time : around 90 mins \u000fBest Hyper - parameters : \u2013 Number of nearest - neighbor entities ( K ): 10 \u2013 Number of paths from neighbors ( N ): 80 \u2013 Max length of path ( n ): 3 \u2013 Linkage for hierarchical clustering ( l ): 0.6 \u000fHyper - parameter method / bounds : Grid search", "entities": [[3, 4, "DatasetName", "FB122"]]}, {"text": "4765 \u2013 K : [ 5 , 10 , 15 , 20 , 30 , 40 , 50 ] \u2013 N : [ 5 , 10 , 15 , 25 , 60 , 80 ] \u2013 l : [ 0.4 , 0.45 , 0.5 , 0.6 , 0.65 , 0.7 , 0.75 , 0.8 , 0.95 ] For experiments on NELL-995 : \u000fInference time : 9.05 queries / s ( total of 2825 queries ) \u000fTrain time : around 90 mins \u000fBest Hyper - parameters : \u2013 Number of nearest - neighbor entities ( K ): 15 \u2013 Number of paths from neighbors ( N ): 25 \u2013 Max length of path ( n ): 3 \u2013 Linkage for hierarchical clustering ( l ): 0.95 \u000fHyper - parameter method / bounds : Random search \u2013 K : [ 5 , 10 , 15 , 20 , 30 , 40 , 50 ] \u2013 N : [ 5 , 10 , 20 , 40 , 60 , 80 ] \u2013 l : [ 0.4 , 0.45 , 0.5 , 0.6 , 0.65 , 0.7 , 0.75 ]", "entities": [[60, 61, "DatasetName", "NELL-995"], [132, 134, "MethodName", "Random search"]]}]