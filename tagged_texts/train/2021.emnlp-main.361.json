[{"text": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages 4406\u20134416 November 7\u201311 , 2021 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2021 Association for Computational Linguistics4406Solving Aspect Category Sentiment Analysis as a Text Generation Task Jian Liu1 , Zhiyang Teng2;3 , Leyang Cui2;3 , Hanmeng Liu2;3 ,", "entities": [[7, 9, "TaskName", "Sentiment Analysis"], [11, 13, "TaskName", "Text Generation"]]}, {"text": "Yue Zhang2;3", "entities": []}, {"text": "1School of Computer Science , Fudan University 2School of Engineering , Westlake University 3Institute of Advanced Technology , Westlake Institute for Advanced Study jianliu17@fudan.edu.cn , { tengzhiyang , cuileyang , liuhanmeng , zhangyue}@westlake.edu.cn Abstract Aspect category sentiment analysis has attracted increasing research attention .", "entities": [[36, 38, "TaskName", "sentiment analysis"]]}, {"text": "The dominant methods make use of pre - trained language models by learning effective aspect category - speci\ufb01c representations , and adding speci\ufb01c output layers to its pre - trained representation .", "entities": []}, {"text": "We consider a more direct way of making use of pre - trained language models , by casting the ACSA tasks into natural language generation tasks , using natural language sentences to represent the output .", "entities": []}, {"text": "Our method allows more direct use of pre - trained knowledge in seq2seq language models by directly following the task setting during pre - training .", "entities": [[12, 13, "MethodName", "seq2seq"]]}, {"text": "Experiments on several benchmarks show that our method gives the best reported results , having large advantages in few - shot and zero - shot settings .", "entities": []}, {"text": "1 Introduction Aspect - based sentiment analysis ( ABSA ) is a \ufb01negrained sentiment analysis task that includes a number of subtasks , two of which are aspect category sentiment analysis ( ACSA ) and aspect category detection ( ACD ) .", "entities": [[2, 7, "TaskName", "Aspect - based sentiment analysis"], [13, 15, "TaskName", "sentiment analysis"], [29, 31, "TaskName", "sentiment analysis"], [35, 38, "TaskName", "aspect category detection"]]}, {"text": "Figure 1 shows an example , where the input is \u201c The restaurant was expensive , but the menu was great \u201d .", "entities": []}, {"text": "ACD detects the aspect categories , such as price andfood , and ACSA predicts the sentiment polarities toward each aspect category .", "entities": []}, {"text": "In this work , we focus on these two tasks as well as the joint task that combines both .", "entities": []}, {"text": "Previous studies have investigated various methods that treat ACSA and ACD as classi\ufb01cation tasks , learning aspect - speci\ufb01c sentence representations ( Wang et al . , 2016 ; Ruder et al . , 2016 ) .", "entities": []}, {"text": "Recently , pre - trained language models ( PLM ) have shown their effectiveness to this end ( Jiang et al . , 2019 ) .", "entities": []}, {"text": "The main idea is to make use of pre - trained models such as BERT ( Devlin et al . , 2019a ) for representing an aspect - speci\ufb01c form of the input ( e.g. , by concatenating the aspect category to the end of The restaurant was expensive , but the menu was great < price , food > < price : negative >    <", "entities": [[14, 15, "MethodName", "BERT"]]}, {"text": "food : positive > ACSAACDFigure 1 : Example of aspect category detection ( ACD ) and aspect category sentiment analysis ( ACSA ) .", "entities": [[9, 12, "TaskName", "aspect category detection"], [18, 20, "TaskName", "sentiment analysis"]]}, {"text": "the input sentence ( Figure 3(a ) ) ) , which provides useful semantic features for ACSA and ACD classi\ufb01ers .", "entities": []}, {"text": "Such methods have given highly competitive results ( Sun et al . , 2019 ; Li et", "entities": []}, {"text": "al . , 2020b ) .", "entities": []}, {"text": "The above classi\ufb01cation models bene\ufb01t from contextualized representations , which contain knowledge learned by pre - training over large data ( Lin et al . , 2019 ) .", "entities": []}, {"text": "However , their use of pre - trained knowledge can be viewed as indirect due to at least two reasons .", "entities": []}, {"text": "First , the classi\ufb01cation task is performed by using a neural network on top of pretrained representation , with separate network parameters .", "entities": []}, {"text": "Second , the integration of aspect category makes the aspect - speci\ufb01c input representation not exactly a natural language sentence , which differs from the pre - training setting .", "entities": []}, {"text": "Intuitively , more pre - trained knowledge could be leveraged by connecting pre - training and ACSA at the task level , rather than only at the representation level .", "entities": []}, {"text": "We investigate the above potentials by casting the sentiment classi\ufb01cation tasks into language modelling tasks .", "entities": [[12, 14, "TaskName", "language modelling"]]}, {"text": "In particular , as shown in Figure 2 , both ACSA and ACD are transformed into sequence - to - sequence ( seq2seq ) tasks , where the encoder takes the input sentence and the decoder generates a natural language sentence .", "entities": [[22, 23, "MethodName", "seq2seq"]]}, {"text": "For ACD , the output follows a template stating whether the speci\ufb01c aspect is discussed ( e.g. , \u201c The hcategory _ typeicategory is discussed \u201d ) ; for ACSA , the sentiment polarity of a speci\ufb01c aspect is stated ( e.g. , \u201c The sentiment polarity of hgiven _ categoryiishpolarity _ typei \u201d ) .", "entities": []}, {"text": "The setting corresponds closely to the denoising auto-", "entities": [[6, 7, "TaskName", "denoising"]]}, {"text": "4407 The r estaurant was too expensive The sentiment polarity of price is positive      ( scoring : 0.1 )", "entities": []}, {"text": "The sentiment polarity of price is neutral       ( scoring : 0.2 )", "entities": []}, {"text": "The sentiment polarity of price is negative     ( scoring : 0.7 ) Aspect category sentiment analysis The price category is discussed            ( scoring : 0.9 )", "entities": [[15, 17, "TaskName", "sentiment analysis"]]}, {"text": "The price category is not discussed      ( scoring : 0.1)Aspect category detectionFigure 2 : ACSA as a generation task .", "entities": []}, {"text": "encoder training scheme of BART ( Lewis et al . , 2020 ) , which we use as the pre - trained model .", "entities": [[4, 5, "MethodName", "BART"]]}, {"text": "Compared with classi\ufb01cation - based methods , our method does not include more network parameters , and thus can potentially generalize better to new domains ( Brown et al . , 2020 ;", "entities": []}, {"text": "Gao et al . , 2020 ) .", "entities": []}, {"text": "Given a new domain with completely unseen aspect categories and sentiment labels , our method can be applied without changing output layer structure .", "entities": []}, {"text": "In addition to classi\ufb01cation - based methods , we take masked language models ( MLM ) as a baseline also , for which a natural counterpart of our method is a mask - re\ufb01lling task .", "entities": [[14, 15, "DatasetName", "MLM"]]}, {"text": "As shown in Figure 3(b ) , different from our method , the output template is concatenated to the input , with the keyword being masked for prediction .", "entities": []}, {"text": "This MLM task corresponds closely to BERT ( Devlin et al . , 2019a ) pre - training .", "entities": [[1, 2, "DatasetName", "MLM"], [6, 7, "MethodName", "BERT"]]}, {"text": "In comparison to this MLM method , a generation method can better learn the correlation between the input and output template as two related sequences , which has been demonstrated by the strong performance of BART for abstractive text summarization ( Lewis et al . , 2020 ) .", "entities": [[4, 5, "DatasetName", "MLM"], [35, 36, "MethodName", "BART"], [37, 40, "TaskName", "abstractive text summarization"]]}, {"text": "Experimental results on three standard benchmarks datasets show that both generation and MLM methods outperform classi\ufb01cation methods using the same pre - trained language models .", "entities": [[12, 13, "DatasetName", "MLM"]]}, {"text": "Finally , generation methods give stronger performances than MLM methods , outperforming the previous stateof - the - art methods by a large margin .", "entities": [[8, 9, "DatasetName", "MLM"]]}, {"text": "In addition , using the generation method , we show that jointly performing ACSA and ACD leads to better results than the traditional pipeline .", "entities": []}, {"text": "To our knowledge , we are the \ufb01rst to employ a generative pre - trained language model to address an ACSA / ACD problem .", "entities": []}, {"text": "We release our code at https://github . com / lgw863 / ACSA - generation .2", "entities": []}, {"text": "Related Work Aspect Category Sentiment Analysis Wang et al .", "entities": [[4, 6, "TaskName", "Sentiment Analysis"]]}, {"text": "( 2016 ) propose an attention - based LSTM network , which can concentrate on different parts of a sentence when different aspect categories are taken as input .", "entities": [[8, 9, "MethodName", "LSTM"]]}, {"text": "Ruder et al .", "entities": []}, {"text": "( 2016 ) model the interdependencies of sentences in a text with a hierarchical bidirectional LSTM .", "entities": [[14, 16, "MethodName", "bidirectional LSTM"]]}, {"text": "Yin et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2017 ) model the task as a machine comprehension problem by constructing pseudo question - answer pairs .", "entities": []}, {"text": "Xue and Li ( 2018 ) extract sentiment features with CNN and selectively output aspect category related features with gating mechanisms .", "entities": []}, {"text": "Xing et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) , Liang et al .", "entities": []}, {"text": "( 2019 ) and Zhu et al .", "entities": []}, {"text": "( 2019 ) incorporate aspect category information into sentence encoders in the context modeling stage .", "entities": []}, {"text": "Sun et al .", "entities": []}, {"text": "( 2019 ) construct auxiliary sentences from the aspect categories and convert ACSA to a sentence - pair classi\ufb01cation task .", "entities": []}, {"text": "Li et al .", "entities": []}, {"text": "( 2020b ) predict the sentiment of an aspect category mentioned in a sentence by aggregating the sentiments of the words indicating the aspect category in the sentence .", "entities": []}, {"text": "Several joint models were proposed to avoid error propagation , which perform ACD and ACSA jointly .", "entities": []}, {"text": "Schmitt et al .", "entities": []}, {"text": "( 2018 ) propose two joint models : end - to - end LSTM and end - to - end CNN , which produce all the aspect categories and their corresponding sentiment polarities at once .", "entities": [[13, 14, "MethodName", "LSTM"]]}, {"text": "Hu et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) propose constrained attention networks ( CAN ) to constrain the attention weight allocation .", "entities": []}, {"text": "Wang et al .", "entities": []}, {"text": "( 2019 ) propose the aspect - level sentiment capsules model ( AS - Capsules ) , which utilizes the correlation between aspect category and sentiment through shared components .", "entities": []}, {"text": "Li et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2020a ) propose a novel joint model which contains a shared sentiment prediction layer .", "entities": []}, {"text": "All the models above are classi\ufb01cation methods , which use a separate output network to give the output label .", "entities": []}, {"text": "In contrast , we investigate natural language generation methods by directly following the pre - training process of language models .", "entities": []}, {"text": "Masked Language Model Methods There is a line of work using the masked language model ( MLM ) for natural language understanding tasks .", "entities": [[16, 17, "DatasetName", "MLM"], [19, 22, "TaskName", "natural language understanding"]]}, {"text": "The basic idea is to leverage information from pre - trained models by de\ufb01ning speci\ufb01c sentence prompt in a language modelling task .", "entities": [[19, 21, "TaskName", "language modelling"]]}, {"text": "Brown et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2020 ) use prompt for few - shot learning in text classi\ufb01cation tasks .", "entities": [[6, 10, "TaskName", "few - shot learning"]]}, {"text": "Schick and Sch\u00fctze ( 2020 ) rephrase inputs as cloze questions for text classi\ufb01cation .", "entities": []}, {"text": "Schick et", "entities": []}, {"text": "al . ( 2020 ) and Gao et al .", "entities": []}, {"text": "( 2020 )", "entities": []}, {"text": "4408 Pre - trained Encoder Themenuwasgreat</s > Pre - trained Decoderlabel < s > < /s > food Themenuwasgreat</s >", "entities": []}, {"text": "< s > < /s > food(a ) BART classi\ufb01cation .", "entities": [[8, 9, "MethodName", "BART"]]}, {"text": "The menu was great .", "entities": []}, {"text": "The sentiment polarity of food   is [ MASK ] .", "entities": []}, {"text": "MLM    headpositive    neutral    negative Input sentence Template ( b ) Masked language model(MLM ) .", "entities": [[0, 1, "DatasetName", "MLM"]]}, {"text": "Encoder x1 x 2 x 3 x 4 x 5Decoder t0 t 1 t 2 t 3 t 4 Thesentiment polarity of price < s > is Therestaurant was tooexpensivet 5 t 6t1 t 2 t 3 t 4 t 5 t 6 t 7sentiment polarity of price positiveis The ( c ) BART generation .", "entities": [[53, 54, "MethodName", "BART"]]}, {"text": "Figure 3 : A comparison of aspect category sentiment analysis methods .", "entities": [[8, 10, "TaskName", "sentiment analysis"]]}, {"text": "extend Schick and Sch\u00fctze ( 2020 ) by automatically generating label words and templates , respectively .", "entities": []}, {"text": "Petroni et al .", "entities": []}, {"text": "( 2019 ) extract relation between entities from BERT by constructing cloze - style templates .", "entities": [[8, 9, "MethodName", "BERT"]]}, {"text": "We are the \ufb01rst to apply such methods to ACSA , taking it as a baseline .", "entities": []}, {"text": "Different from these template - based models , our \ufb01nal model uses BART for text generation , which better models the correlations between the input sentence and the output sentence compared with BERT .", "entities": [[12, 13, "MethodName", "BART"], [14, 16, "TaskName", "text generation"], [32, 33, "MethodName", "BERT"]]}, {"text": "Generation Methods", "entities": []}, {"text": "There has been work casting NLP problems as sequence generation tasks ( Vinyals et al . , 2015 ; Ma et al . , 2017 ; Stanovsky and Dagan , 2018 ;", "entities": []}, {"text": "Raffel et al . , 2020 ) , where the output is a sequence of tokens rather than a natural language sentence .", "entities": []}, {"text": "Daza and Frank ( 2018 ) treat semantic role labelling as a sequence - to - sequence process .", "entities": []}, {"text": "Li et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) solve the entity - relation extraction task as a multi - turn question answering generation method .", "entities": [[7, 9, "TaskName", "relation extraction"], [15, 17, "TaskName", "question answering"]]}, {"text": "Our work is similar in casting an NLP task as a generation task .", "entities": []}, {"text": "Different from the above methods , our goal is to make the most of pre - trained knowledge in BART for ACSA .", "entities": [[19, 20, "MethodName", "BART"]]}, {"text": "3 Methods Formally for ACD , the input is a sentence X= fx1 ; : : : ; x ng = x1 : n , where xidenotes the i - th word .", "entities": []}, {"text": "For ACSA , a set of pre - identi\ufb01ed aspect categories are also given .", "entities": []}, {"text": "We introduce relevant pre - trained language models in 3.1 , classi\ufb01cation methods in Section 3.2 , MLM methods in Section 3.3 , and our generation method in Section 3.4.3.1 Pre - trained language Models We take BERT ( Devlin et al . , 2019a ) and BART ( Lewis et al . , 2020 ) as the pre - trained language models .", "entities": [[17, 18, "DatasetName", "MLM"], [37, 38, "MethodName", "BERT"], [47, 48, "MethodName", "BART"]]}, {"text": "Both are built on the Transformer ( Vaswani et al . , 2017 ) architecture .", "entities": [[5, 6, "MethodName", "Transformer"]]}, {"text": "BERT ( Devlin et al . , 2019a ) is an encoder stack of Transformer for masked text \ufb01lling , where a model uses the context words to predict masked words .", "entities": [[0, 1, "MethodName", "BERT"], [14, 15, "MethodName", "Transformer"]]}, {"text": "BART ( Lewis et al . , 2020 ) is a denoising auto - encoder seq2seq model pre - training for natural language generation .", "entities": [[0, 1, "MethodName", "BART"], [11, 12, "TaskName", "denoising"], [15, 16, "MethodName", "seq2seq"]]}, {"text": "Its training applies document corruption such as randomly deleting tokens from the input and corrupting text with an arbitrary noising function .", "entities": []}, {"text": "BART is trained to reconstruct the original text .", "entities": [[0, 1, "MethodName", "BART"]]}, {"text": "3.2 The Classi\ufb01cation Method We use a multi - layer perceptrons network as the classi\ufb01er model , which takes a representation vector as input .", "entities": []}, {"text": "Both BERT and BART are considered as the encoders .", "entities": [[1, 2, "MethodName", "BERT"], [3, 4, "MethodName", "BART"]]}, {"text": "BERT Classi\ufb01cation BERT adopts \u201c [ CLS ] input sentence", "entities": [[0, 1, "MethodName", "BERT"], [2, 3, "MethodName", "BERT"]]}, {"text": "[ SEP ] given_category", "entities": []}, {"text": "[ SEP ] \u201d as input .", "entities": []}, {"text": "The \ufb01nal hidden state corresponding to \u201c [ CLS ] \u201d is used as the representation for classi\ufb01cation .", "entities": []}, {"text": "BART Classi\ufb01cation BART adopts \u201c hSiinput sentenceh = Sigiven_categoryh = Si \u201d as input and predicts the sentiment polarity of the sentence towards the given category .", "entities": [[0, 1, "MethodName", "BART"], [2, 3, "MethodName", "BART"]]}, {"text": "The same input is fed into the encoder and decoder ( see Figure 3(a ) ) .", "entities": []}, {"text": "Formally , suppose that the query category is a , x0 = hSi , xn+1 = h = Si , xn+2 = a , xn+3 = h = Si , then the input to BART is x0 : n+3= hSix1 ; : : : ; x nh = Siah = Si .", "entities": [[34, 35, "MethodName", "BART"]]}, {"text": "The output hidden vec-", "entities": []}, {"text": "4409tors obtained by the BART encoder ( ENCODER ) and BART decoder ( D ECODER ) are : henc = ENCODER ( x0 : n+3 ) h0 : : : hn+3", "entities": [[4, 5, "MethodName", "BART"], [10, 11, "MethodName", "BART"]]}, {"text": "= DECODER ( henc;x0 : n+3 )", "entities": []}, {"text": "The output vector hn+3is then taken as the representation vector for classi\ufb01cation .", "entities": []}, {"text": "3.3", "entities": []}, {"text": "The MLM Method Masked language models ( MLM ) ( Devlin et al . , 2019a ) complete a given prompt by \ufb01lling missing tokens .", "entities": [[1, 2, "DatasetName", "MLM"], [7, 8, "DatasetName", "MLM"]]}, {"text": "We refer to the template including a given category and MASK token together as a prompt .", "entities": []}, {"text": "For sentiment analysis tasks , BERT MLM adopts the input sentence and the prompt as the model input and predicts the sentiment polarity label word towards the given category .", "entities": [[1, 3, "TaskName", "sentiment analysis"], [5, 6, "MethodName", "BERT"], [6, 7, "DatasetName", "MLM"]]}, {"text": "For BART MLM , the same input is fed into the encoder and decoder , and the highest decoder prediction from label words of the MASK token is the predicted polarity label(see Figure 3(b ) ) .", "entities": [[1, 2, "MethodName", "BART"], [2, 3, "DatasetName", "MLM"]]}, {"text": "We use the same template in the MLM method and generation method , following the template creation method in section 3.4.1 .", "entities": [[7, 8, "DatasetName", "MLM"]]}, {"text": "3.4 The Generation Method We take both ACSA and ACD as language model ranking problems under a seq2seq framework ( see Figure 3(c ) ) .", "entities": [[17, 18, "MethodName", "seq2seq"]]}, {"text": "The target sequence Tai;pk(Tai )", "entities": []}, {"text": "= ft1 ; : : : ; t mgis a template \ufb01lled by the given category aiand the polarity type pk .", "entities": []}, {"text": "We \ufb01rst introduce how to create templates in Section 3.4.1 , and then show the inference and training details in Section 3.4.2 and Section 3.4.3 , respectively .", "entities": []}, {"text": "3.4.1 Template Creation For ACSA , we manually create templates containing one slot for the given _ category and another slot for the polarity _ type label .", "entities": []}, {"text": "We set a category word set A = fa1 ; : : : ; ajCjg , jCjis the category type size ( e.g. , ai=\u201cprice \u201d ) and polarity type word set P = fp1 ; : : : ; pjLjg , jLjis the polarity type size ( e.g. , pk=\u201cpositive \u201d ) , and use words to de\ufb01ne templates Tai;pk(e.g .", "entities": []}, {"text": "\u201c The sentiment polarity of price is positive \u201d ) .", "entities": []}, {"text": "The template T is \u201c The sentiment polarity of haiiishpki \u201d .", "entities": []}, {"text": "For a given category ai , we can obtain a list of templates Tai=", "entities": []}, {"text": "[ Tai;p1 ; : : : ; Tai;pjLj ] .", "entities": []}, {"text": "For ACD , we use aito create a sentiment templateT+ aifor an existing aspect category , and a none - category template T\u0000 ai .", "entities": []}, {"text": "T+is \u201c Thehaiicategory is discussed \" andT\u0000is \u201c Thehaiicategory is not discussed \" .3.4.2", "entities": []}, {"text": "Inference For ACSA , we \ufb01rst enumerate all possible polarities for the given category of the sentence Xand \ufb01ll them in the prepared templates , and then use the \ufb01ne - tuned pre - trained generative language model to assign a score for each template Tai;pk = ft1 ; : : : ; t mg , formulated as : f(Tai;pk ) = mX c=1logP(tcjt1 : c\u00001;X ) ( 1 ) We calculate a score f(Tai;pk)for each possible polarity by employing the pre - trained generative language model ( i.e. , BART ) to score the templates , and then choose the polarity of category aiwith the largest score .", "entities": [[90, 91, "MethodName", "BART"]]}, {"text": "For ACD , we \ufb01rst create templates T+ aiandT\u0000 ai for all possible categories of the sentence X , and then use the \ufb01ne - tuned pre - trained generative language model to assign a score for each template Tai = ft1 ; : : : ; t mg , in a similar way as Equation 1 .", "entities": []}, {"text": "Also , we decide whether the aicategory is discussed or not in the input sentence according to the higher score between T+ aiandT\u0000 ai .", "entities": []}, {"text": "3.4.3 Training For ACSA , suppose that the polarity type of aiispk .", "entities": []}, {"text": "We \ufb01ll the given category aiand the polarity type pkinto template Tto create a gold target output Tai;pk .", "entities": []}, {"text": "Similarly for ACD , if the category of aiis discussed , the gold target T+ aiis obtained by \ufb01lling aiintoT+ , and otherwise is T\u0000 ai .", "entities": []}, {"text": "For ACSA , we use all gold polarities in the training set to construct ( X;T)pairs .", "entities": []}, {"text": "For ACD , we use all gold categories in the training set to construct ( X;T+)pairs , and additionally create negative samples ( X;T\u0000)by sampling all none existing categories in the input .", "entities": []}, {"text": "Finally , we obtain f(X;T)g = f(X;T+)[(X;T\u0000)g Given a sequence pair ( X;T ) , we feed the input X = x1 : nto the BART encoder , obtaining hidden representations of the sentence : henc = ENCODER ( x1 : n ) ( 2 ) At the cth step of the decoder , hencand previous output tokens t1 : c\u00001are then as inputs , yielding a representation using attention ( Vaswani et al . , 2017 )", "entities": [[25, 26, "MethodName", "BART"]]}, {"text": "hdec c = DECODER ( henc ; t1 : c\u00001 ) ( 3 ) The conditional probability of the word tcis de\ufb01ned as : P(tcjt1 : c\u00001;X ) =", "entities": []}, {"text": "SOFTMAX ( hdec cWlm+blm);(4 ) where Wlm2Rdh\u0002jVjandblm2RjVj , jVjrepresents the vocab size of pre - trained BART .", "entities": [[0, 1, "MethodName", "SOFTMAX"], [16, 17, "MethodName", "BART"]]}, {"text": "The", "entities": []}, {"text": "4410cross - entropy between the decoder \u2019s output and the original template is used as the loss function : L=\u0000mX c=1logP(tcjt1;c\u00001;X ) ( 5 ) 4 Experiments We choose the SemEval-2014 restaurant review ( Rest14 ) ( Pontiki et al . , 2014a ) , a variant of Rest14 ( Rest14 - hard ) ( Xue and Li , 2018 ) and the multiaspect multi - sentiment ( MAMS ) ( Jiang et al . , 2019 ) datasets for sentence - level sentiment , the TripAdvisor ( Wang et al . , 2010 ) and BeerAdvocate ( McAuley et al . , 2012 ; Lei et al . , 2016 ) datasets for document - level sentiment .", "entities": [[16, 17, "MetricName", "loss"], [68, 69, "DatasetName", "MAMS"], [96, 97, "DatasetName", "BeerAdvocate"]]}, {"text": "Standard splits of training / development / testing sets are adopted following previous work Tay et al .", "entities": []}, {"text": "( 2018 ) , the details of which are shown in Appendix A.", "entities": []}, {"text": "We use the pre - trained BERT - base1and BARTbase2models for task \ufb01ne - tuning .", "entities": [[6, 7, "MethodName", "BERT"]]}, {"text": "We select the \ufb01ne - tuning learning rate from { 4e-5 , 2e-5 , and 1e5 } and batch size from { 8 , 16 , 24 } for different models .", "entities": [[6, 8, "HyperparameterName", "learning rate"], [18, 20, "HyperparameterName", "batch size"]]}, {"text": "The dropout probability is 0.1 .", "entities": []}, {"text": "The best model con\ufb01guration is selected according to the highest performance on the development set .", "entities": []}, {"text": "The details of settings are shown in Appendix A. 4.1 Baseline Methods We compare our generation method with classi\ufb01cation and MLM baselines ( Figure 3 ) using the same encoder .", "entities": [[20, 21, "DatasetName", "MLM"]]}, {"text": "In particular , BART generation ( i.e. , Figure 3(c ) ) is compared with BART classi\ufb01cation ( Figure 3(a ) ) and BART MLM ( Figure 3(b ) ) , as well as BERT classi\ufb01cation andBERT MLM .", "entities": [[3, 4, "MethodName", "BART"], [15, 16, "MethodName", "BART"], [23, 24, "MethodName", "BART"], [24, 25, "DatasetName", "MLM"], [34, 35, "MethodName", "BERT"], [37, 38, "DatasetName", "MLM"]]}, {"text": "In addition , our method is also compared with other models in the literature as follows .", "entities": []}, {"text": "For sentence - level ACSA , we also compare our method with the following state - of - the - art methods in the literature .", "entities": []}, {"text": "( 1 ) non - BERT models : GCAE ( Xue and Li , 2018 ) ,", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "As - capsule ( Wang et al . , 2019 ) and CapsNet ( Jiang et al . , 2019 ) ; ( 2 ) BERT ( Devlin et al . , 2019b ) based models : BERT - pair - QA - B ( Sun et al . , 2019 ) , CapsNet - BERT ( Jiang et al . , 2019 ) and AC - MIMLLN - BERT ( Li et al . , 2020b ) .", "entities": [[12, 13, "MethodName", "CapsNet"], [25, 26, "MethodName", "BERT"], [37, 38, "MethodName", "BERT"], [53, 54, "MethodName", "CapsNet"], [55, 56, "MethodName", "BERT"], [69, 70, "MethodName", "BERT"]]}, {"text": "For document - level ACSA , we compare our method with the following methods .", "entities": []}, {"text": "( 1 ) non - BERT models : LSTM ( Tang et al . , 2015 ) , HAN ( Yang et al . , 2016 ) and MR ( machine comprehension pat1https://github.com/google-research/", "entities": [[5, 6, "MethodName", "BERT"], [8, 9, "MethodName", "LSTM"], [28, 29, "DatasetName", "MR"]]}, {"text": "bert 2https://huggingface.co/facebook/ bart - base / tree / mainACSA Template T", "entities": []}, {"text": "Dev accuracy The sentiment polarity of aiispk 83.78", "entities": [[1, 2, "MetricName", "accuracy"]]}, {"text": "The sentiment is pkforai 83.44 Theaicategory has a pklabel 82.31 Table 1 : ACSA results using different templates .", "entities": []}, {"text": "ai indicates given category , pkindicates polarity type .", "entities": []}, {"text": "ACD Template T+/T\u0000Dev F1 Theaicategory is discussed Theaicategory is not discussed93.13", "entities": [[3, 4, "MetricName", "F1"]]}, {"text": "The sentence discusses the aicategory The sentence discusses no aicategory92.67 It is about the aicategory It is not about the aicategory92.44 Table 2 : ACD results using different templates .", "entities": []}, {"text": "aiindicates category type .", "entities": []}, {"text": "tern )", "entities": []}, {"text": "( Yin et al . , 2017 ) ; ( 2 ) BERT ( Devlin et al . , 2019b ) based model : BERT classi\ufb01cation .", "entities": [[12, 13, "MethodName", "BERT"], [24, 25, "MethodName", "BERT"]]}, {"text": "For ACD , we compare our method with the following methods .", "entities": []}, {"text": "( 1 ) non - BERT models : XRCE ( Brun et al . , 2014 ) , NRC - Canada ( Kiritchenko et", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "al . , 2014 ) ; ( 2 ) BERT ( Devlin et al . , 2019b ) based models : BERT classi\ufb01cation , BERT - pair - NLI - B ( Sun et al . , 2019 ) , CNE - net ( Dai et al . , 2020 ) .", "entities": [[9, 10, "MethodName", "BERT"], [21, 22, "MethodName", "BERT"], [24, 25, "MethodName", "BERT"]]}, {"text": "4.2 Development Experiments Different templates can be used for expressing the same meaning .", "entities": []}, {"text": "For instance , \u201c The sentiment polarity of hgiven _ categoryiis positive \u201d can also be expressed by \u201c The sentiment is positive forhgiven _ categoryi \u201d .", "entities": []}, {"text": "For ACSA , we investigate the impact of manual templates using the MAMS development set .", "entities": [[12, 13, "DatasetName", "MAMS"]]}, {"text": "Table 1 shows the impact of different choice of templates .", "entities": []}, {"text": "For instance , \u201c Thehgiven _ categoryi category has ahpolarity _ typeilabel \u201d and \u201c The sentiment polarity of hgiven _ categoryiis hpolarity _ typei \u201d give 82.31 % and 83.78 % accuracy , respectively , indicating that the template has in\ufb02uence on the \ufb01nal performance .", "entities": [[32, 33, "MetricName", "accuracy"]]}, {"text": "This is consistent with \ufb01nds of Gao et al .", "entities": []}, {"text": "( 2020 ) for the fewshot task .", "entities": []}, {"text": "Based on the development results , we use the top performing template \u201c The sentiment polarity ofhgiven _ categoryiishpolarity _ typei \u201d in our ACSA experiments .", "entities": []}, {"text": "For ACD , we investigate the impact of templates using the Rest14 development set .", "entities": []}, {"text": "Table 2 shows the performance impact of different templates .", "entities": []}, {"text": "We use the top performing template \u201c The hcategory _ typeicategory is discussed \u201d as templateT+and \u201c Thehcategory _ typeicategory is not discussed \u201d as template T\u0000in our ACD experiments .", "entities": []}, {"text": "4411Category Model Rest14 Rest14 - hard MAMS Classi\ufb01cation w/o PLMGCAE ( Xue and Li , 2018 ) 81.336(\u00060.883 ) 54.717(\u00064.920 ) 72.098y As - capsule ( Wang et al . , 2019 ) 82.179(\u00060.414 ) 60.755(\u00062.773 ) 75.116(\u00060.473 )", "entities": [[6, 7, "DatasetName", "MAMS"]]}, {"text": "CapsNet ( Jiang et al . , 2019 ) 81.172(\u00060.631 ) 53.962(\u00060.924 ) 73.986y AC - MIMLLN ( Li et al . , 2020b ) 81.603(\u00060.715 ) 65.283(\u00062.264 ) 76.427(\u00060.704 )", "entities": [[0, 1, "MethodName", "CapsNet"]]}, {"text": "Classi\ufb01cation w PLMBERT classi\ufb01cation 87.482(\u00060.906 ) 67.547(\u00065.894 ) 78.292y BART classi\ufb01cation 88.289(\u00060.943 ) 68.698(\u00063.407 ) 78.761(\u00060.752 )", "entities": [[9, 10, "MethodName", "BART"]]}, {"text": "BERT - pair - QA - B ( Sun et al . , 2019 ) 87.523(\u00061.175 ) 69.433(\u00064.368 ) 79.134(\u00060.973 )", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "CapsNet - BERT ( Jiang et al . , 2019 ) 86.557(\u00060.943 ) 51.321(\u00061.412 ) 79.461y AC - MIMLLN - BERT ( Li et al . , 2020b ) 89.250(\u00060.720 ) 74.717(\u00063.290 ) 81.198(\u00060.606 )", "entities": [[0, 1, "MethodName", "CapsNet"], [2, 3, "MethodName", "BERT"], [20, 21, "MethodName", "BERT"]]}, {"text": "Masked language modelBERT MLM 88.446(\u00060.825 ) 69.021(\u00062.753 ) 79.019(\u00060.935 ) BART MLM 88.667(\u00060.768 ) 69.585(\u00062.529 ) 79.243(\u00060.854 )", "entities": [[3, 4, "DatasetName", "MLM"], [10, 11, "MethodName", "BART"], [11, 12, "DatasetName", "MLM"]]}, {"text": "Generation BART generation 90.545(\u00060.315)\u000377.358(\u00062.160)\u000383.130(\u00060.478)\u0003", "entities": [[1, 2, "MethodName", "BART"]]}, {"text": "Table 3 : Results of the sentence - level ACSA in terms of accuracy ( % , mean \u0006(std)).yrefers to Jiang", "entities": [[13, 14, "MetricName", "accuracy"]]}, {"text": "et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "* means the result is signi\ufb01cant at p < 0:01using paired t - test comparing to BART MLM andBART classi\ufb01cation .", "entities": [[16, 17, "MethodName", "BART"], [17, 18, "DatasetName", "MLM"]]}, {"text": "Model TripAdvisor BeerAdvocate LSTM 44.02 34.78 HAN 44.68 36.03 MR 46.56 38.06 BERT classi\ufb01cation 47.03 39.85 BART classi\ufb01cation 47.45 40.44 BERT MLM 48.03 40.58 BART MLM 48.36 40.72 BART generation 49.51\u000341.42\u0003 Table 4 : Results of the document - level ACSA in terms of accuracy ( % ) .", "entities": [[2, 3, "DatasetName", "BeerAdvocate"], [3, 4, "MethodName", "LSTM"], [9, 10, "DatasetName", "MR"], [12, 13, "MethodName", "BERT"], [16, 17, "MethodName", "BART"], [20, 21, "MethodName", "BERT"], [21, 22, "DatasetName", "MLM"], [24, 25, "MethodName", "BART"], [25, 26, "DatasetName", "MLM"], [28, 29, "MethodName", "BART"], [44, 48, "MetricName", "accuracy ( % )"]]}, {"text": "* means the result is signi\ufb01cant at p < 0:01using paired t - test comparing to BART MLM andBART classi\ufb01cation .", "entities": [[16, 17, "MethodName", "BART"], [17, 18, "DatasetName", "MLM"]]}, {"text": "4.3 ACSA Experiments The results of sentence - level ACSA are shown in Table 3 .", "entities": []}, {"text": "We can see that , \ufb01rst , the performance of BERT MLM andBART MLM is better than BERT classi\ufb01cation andBART classi\ufb01cation , respectively .", "entities": [[10, 11, "MethodName", "BERT"], [11, 12, "DatasetName", "MLM"], [13, 14, "DatasetName", "MLM"], [17, 18, "MethodName", "BERT"]]}, {"text": "In particular , BERT MLM gives a strong baseline , outperforming all non - BERT and BERT classi\ufb01cation baselines .", "entities": [[3, 4, "MethodName", "BERT"], [4, 5, "DatasetName", "MLM"], [14, 15, "MethodName", "BERT"], [16, 17, "MethodName", "BERT"]]}, {"text": "This shows that making use of pre - training at the tasklevel can achieve better results than that at the representation level .", "entities": []}, {"text": "Also , the BART MLM andclassi\ufb01cation models perform better than the corresponding BERT models .", "entities": [[3, 4, "MethodName", "BART"], [4, 5, "DatasetName", "MLM"], [12, 13, "MethodName", "BERT"]]}, {"text": "Second , BART generation outperforms all baselines on all three datasets , which indicates that our model can better detect multiple sentiment polarities in one sentence toward different aspect categories .", "entities": [[2, 3, "MethodName", "BART"]]}, {"text": "Third , BART generation performs signi\ufb01cantly better than BART MLM , giving absolutely 3.89 % stronger accuracy on MAMS , demonstrating the effectiveness of the generation method .", "entities": [[2, 3, "MethodName", "BART"], [8, 9, "MethodName", "BART"], [9, 10, "DatasetName", "MLM"], [16, 17, "MetricName", "accuracy"], [18, 19, "DatasetName", "MAMS"]]}, {"text": "This shows the strength of BART pre - training for generating semantically related content , which was also re\ufb02ected by the strong performance of BART on abstractive sum - Model P R F1 XRCE 83.23 81.37 82.29 NRC - Canada 91.04 86.24 88.58 BERT classi\ufb01cation 92.78 89.07 90.89 BERT - pair - NLI - B 93.57 90.83 92.18", "entities": [[5, 6, "MethodName", "BART"], [24, 25, "MethodName", "BART"], [32, 33, "MetricName", "F1"], [43, 44, "MethodName", "BERT"], [48, 49, "MethodName", "BERT"]]}, {"text": "CNE - net 93.76 90.83 92.27 BART classi\ufb01cation 93.01 89.92 91.44 BART MLM 93.44 89.83 91.60 BART generation 95.18 90.54 92.80 Table 5 : Rest14 results : Aspect Category Detection .", "entities": [[6, 7, "MethodName", "BART"], [11, 12, "MethodName", "BART"], [12, 13, "DatasetName", "MLM"], [16, 17, "MethodName", "BART"], [27, 30, "TaskName", "Aspect Category Detection"]]}, {"text": "We use the results reported in XRCE ( Brun et al . , 2014 ) , NRC - Canada ( Kiritchenko et al . , 2014 ) , BERT - pairNLI - B ( Sun et al . , 2019 ) and CNE - net ( Dai et al . , 2020 ) .", "entities": [[28, 29, "MethodName", "BERT"]]}, {"text": "marization ( Lewis et al . , 2020 ) .", "entities": []}, {"text": "In contrast , the MLM method concatenates the input and output into one sequence , and thus fails to model their correlation in encoder - decoder pre - trainng .", "entities": [[4, 5, "DatasetName", "MLM"]]}, {"text": "The performances of our model on documentlevel ACSA are shown in Table 4 .", "entities": []}, {"text": "Compared with LSTM , HAN and MR , BERT classi\ufb01cationandBART classi\ufb01cation outperform all baselines , which shows the effectiveness of pre - training .", "entities": [[2, 3, "MethodName", "LSTM"], [6, 7, "DatasetName", "MR"], [8, 9, "MethodName", "BERT"]]}, {"text": "BERT MLM andBART MLM surpass BERT classi\ufb01cation andBART classi\ufb01cation , respectively .", "entities": [[0, 1, "MethodName", "BERT"], [1, 2, "DatasetName", "MLM"], [3, 4, "DatasetName", "MLM"], [5, 6, "MethodName", "BERT"]]}, {"text": "Our BART generation model achieves improvements of 1.15 % and 0.70 % over BART MLM on TripAdvisor and BeerAdvocate , respectively , demonstrating that the generation method can more effectively make use of BART for ACSA .", "entities": [[1, 2, "MethodName", "BART"], [13, 14, "MethodName", "BART"], [14, 15, "DatasetName", "MLM"], [18, 19, "DatasetName", "BeerAdvocate"], [33, 34, "MethodName", "BART"]]}, {"text": "4.4 ACD Experiments Results on the Rest14 ACD subtask are presented in Table 5 .", "entities": []}, {"text": "Following Pontiki et al .", "entities": []}, {"text": "( 2014b ) , we use Micro - F1 for evaluating .", "entities": [[6, 9, "MetricName", "Micro - F1"]]}, {"text": "Again BART generation achieves better results than BART classi\ufb01cation and BART MLM .", "entities": [[1, 2, "MethodName", "BART"], [7, 8, "MethodName", "BART"], [10, 11, "MethodName", "BART"], [11, 12, "DatasetName", "MLM"]]}, {"text": "Our model outperforms all baselines", "entities": []}, {"text": "4412ModelRest14 MAMS P R F1 P R F1 Pipeline BART generation 82.03 76.46 79.15 77.04 71.92 74.39 Joint BERT classi\ufb01cation 77.75 76.07 76.90 74.14 71.92 73.01 Joint BART classi\ufb01cation 81.92", "entities": [[1, 2, "DatasetName", "MAMS"], [4, 5, "MetricName", "F1"], [7, 8, "MetricName", "F1"], [9, 10, "MethodName", "BART"], [18, 19, "MethodName", "BERT"], [27, 28, "MethodName", "BART"]]}, {"text": "73.59 77.53 74.59 74.13 74.36 Joint BART MLM 81.88 76.73 79.22 75.32 75.07 75.19 Joint BART generation 82.76 81.91 82.33 77.18 76.58 76.88 Table 6 : Performance on combination setting .", "entities": [[6, 7, "MethodName", "BART"], [7, 8, "DatasetName", "MLM"], [15, 16, "MethodName", "BART"]]}, {"text": "Figure 4 : Few - shot ACSA performance on different test sets .", "entities": []}, {"text": "Model P R F1 BERT classi\ufb01cation 90.50 86.68 88.50 BART classi\ufb01cation 90.67 88.34 89.49 BART MLM 90.57 88.86 89.71 BART generation 90.71 90.16 90.43 Table 7 : MAMS results : Aspect Category Detection .", "entities": [[3, 4, "MetricName", "F1"], [4, 5, "MethodName", "BERT"], [9, 10, "MethodName", "BART"], [14, 15, "MethodName", "BART"], [15, 16, "DatasetName", "MLM"], [19, 20, "MethodName", "BART"], [27, 28, "DatasetName", "MAMS"], [30, 33, "TaskName", "Aspect Category Detection"]]}, {"text": "on precision and F-1 score .", "entities": []}, {"text": "In particular , a more than 95 % precision score is achieved , which shows that our model can effectively exclude the aspect categories not mentioned in the input .", "entities": []}, {"text": "We also investigate the performance on the MAMS dataset , which consists of at least two unique aspect categories with different sentiment polarities in each input sentence .", "entities": [[7, 8, "DatasetName", "MAMS"]]}, {"text": "Table 7 shows thatBART generation outperforms all baselines , indicating better ability of our model to detect multiple aspect categories in one sentence .", "entities": []}, {"text": "4.5 A Joint Model", "entities": []}, {"text": "The generation method allows us to build a straightforward joint model by extending the \ufb01rst template in Table 1 , using \u201c The sentiment polarity of < given_category > is none \u201d as a template for nonexisting aspect categories .", "entities": []}, {"text": "The results on Rest-14 and MAMS are presented in Table 6 .", "entities": [[5, 6, "DatasetName", "MAMS"]]}, {"text": "We \ufb01nd that joint BART generation achieves better results on this task with improvements over pipeline BART generation .", "entities": [[4, 5, "MethodName", "BART"], [16, 17, "MethodName", "BART"]]}, {"text": "Joint BART generation outperforms all baselines on precision , recall and F-1 score , which shows the advantage of joint learning .", "entities": [[1, 2, "MethodName", "BART"]]}, {"text": "Model R!M M!R BERT classi\ufb01cation 43.38 62.28 BART classi\ufb01cation 46.61 68.55 BART MLM 47.86 70.64 BART generation 49.84 72.46 Table 8 : Zero - Shot results : ACSA .", "entities": [[3, 4, "MethodName", "BERT"], [7, 8, "MethodName", "BART"], [11, 12, "MethodName", "BART"], [12, 13, "DatasetName", "MLM"], [15, 16, "MethodName", "BART"]]}, {"text": "R !", "entities": []}, {"text": "M indicates training on Rest14 and testing on MAMS .", "entities": [[8, 9, "DatasetName", "MAMS"]]}, {"text": "M !", "entities": []}, {"text": "R indicates training on MAMS and testing on Rest14 .", "entities": [[4, 5, "DatasetName", "MAMS"]]}, {"text": "4.6 Few - Shot and Zero - Shot Learning We evaluate the model performance on ACSA where only a small amount of labelled data is available for training , simulating the low - resource data scenarios by randomly sampling training instances from a large training set .", "entities": [[5, 9, "TaskName", "Zero - Shot Learning"]]}, {"text": "In particular , we use different numbers of instances for training , randomly sampling a \ufb01xed number of instances per category type ( 10 , 20 , 50 , 100 , 200 , 500 instances per category type for Rest14 and MAMS ) .", "entities": [[41, 42, "DatasetName", "MAMS"]]}, {"text": "The results are shown in Figure 4 , where the methods of BERT classi\ufb01cation , BART classi\ufb01cation andBART MLM are also compared .", "entities": [[12, 13, "MethodName", "BERT"], [15, 16, "MethodName", "BART"], [18, 19, "DatasetName", "MLM"]]}, {"text": "It can be seen that on all the datasets , our model outperforms BERT classi\ufb01cation , BART classi\ufb01cationandBART MLM , especially when the number of training instances is small .", "entities": [[13, 14, "MethodName", "BERT"], [16, 17, "MethodName", "BART"], [18, 19, "DatasetName", "MLM"]]}, {"text": "For example , when there are only 10 training instances , our model gives accuracy scores of 82.01 % on Rest14 , as compared to 38.57 % by BERT classi\ufb01cation and 50.16 % by BART classi\ufb01cation .", "entities": [[14, 15, "MetricName", "accuracy"], [28, 29, "MethodName", "BERT"], [34, 35, "MethodName", "BART"]]}, {"text": "When the number of instances grows as large as 500 , our model gives 2.24 % and 2.65 % better accuracies than BART MLM on Rest14 and MAMS , respectively .", "entities": [[22, 23, "MethodName", "BART"], [23, 24, "DatasetName", "MLM"], [27, 28, "DatasetName", "MAMS"]]}, {"text": "One", "entities": []}, {"text": "4413 Figure 5 : Comparison of accuracy with different category frequency on MAMS .", "entities": [[6, 7, "MetricName", "accuracy"], [12, 13, "DatasetName", "MAMS"]]}, {"text": "possible reason is that our method makes more use of direct sentiment knowledge in the pre - trained language model by directly adopting the original structure of BART mentioned earlier .", "entities": [[27, 28, "MethodName", "BART"]]}, {"text": "In contrast , classi\ufb01cation methods can not achieve this due to transferring the sentiment bias indirectly .", "entities": []}, {"text": "The results of our zero - shot learning experiments are in Table 8 .", "entities": [[4, 8, "TaskName", "zero - shot learning"]]}, {"text": "In all cases , our method outperforms all the baselines .", "entities": []}, {"text": "In particular , the model trained on MAMS has a better performance on Rest14 than the reverse zero - shot setting , which proves that the MAMS dataset has a higher challenge .", "entities": [[7, 8, "DatasetName", "MAMS"], [26, 27, "DatasetName", "MAMS"]]}, {"text": "5 Analysis 5.1 In\ufb02uence of Category Frequency Aspect categories can be implicit and do not necessarily occur as terms in the given sentence .", "entities": []}, {"text": "To explore the correlation between ACSA accuracy and the occurrence frequency of a given category , we split the eight categories in the MAMS test set into four subsets based on the occurrence frequency .", "entities": [[6, 7, "MetricName", "accuracy"], [23, 24, "DatasetName", "MAMS"]]}, {"text": "The category ( i.e. , miscellaneous ) that never occurs in the given sentence is put into the zero frequency subset , the 15 % least frequent ( i.e. , ambience , staff ) are put into low frequency subset , the 30 % most frequent ( i.e. , menu , service ) are put into high frequency subset , and the remaining ( i.e. , price , food , place ) are put into mid frequency subset .", "entities": []}, {"text": "Figure 5 shows the accuracy of BART classi\ufb01cation and our model against the frequency .", "entities": [[4, 5, "MetricName", "accuracy"], [6, 7, "MethodName", "BART"]]}, {"text": "As the category occurrence frequency decreases , the relative gap of accuracy between the two models increases .", "entities": [[11, 12, "MetricName", "accuracy"]]}, {"text": "In the zero frequency , our method gives absolutely 8.03 % stronger accuracy than BART classi\ufb01cation .", "entities": [[12, 13, "MetricName", "accuracy"], [14, 15, "MethodName", "BART"]]}, {"text": "This demonstrates that our method is more robust in summarizing the sentiment polarity of abstract or rare categories .", "entities": []}, {"text": "Even if there are no explicit category terms in the sentence , the generation method can give the implicit category opinion of the whole sentence according to the context .", "entities": []}, {"text": "Service was fine and the food deliver ed in r easonable time given the cr owd , but for the price I was disappointed .", "entities": []}, {"text": "< miscellaneous : neutral >    <", "entities": []}, {"text": "incorrect output : negative >", "entities": []}, {"text": "The kids r eally enjoyed their food and the value on the kids menu is good .", "entities": []}, {"text": "< menu : neutral >    <", "entities": []}, {"text": "incorrect output : positive >", "entities": []}, {"text": "The decor could be a bit better , and if ther e was a small bar the overall atmospher e would be a bit mor e inviting .", "entities": []}, {"text": "< place :", "entities": []}, {"text": "negative >    <", "entities": []}, {"text": "incorrect output : neutral > ( a ) ( b ) ( c)Figure 6 : Examples of BART classi\ufb01cation .", "entities": [[17, 18, "MethodName", "BART"]]}, {"text": "( a ) is an instance with category do not occur as term in sentence .", "entities": []}, {"text": "( b ) represents that our method is not affected by the surrounding interference information .", "entities": []}, {"text": "( c ) needs conditional reasoning for analysis .", "entities": []}, {"text": "Our method can obtain correct sentiment polarity .", "entities": []}, {"text": "5.2 Case Study Figure 6 shows typical examples from the test set which can not be inferred by the BART classi\ufb01cation model .", "entities": [[19, 20, "MethodName", "BART"]]}, {"text": "In sentence ( a ) , the given category miscellaneous does not occur as a term in the given sentence .", "entities": []}, {"text": "Our method can synthesize different sentiment polarities with different aspects to obtain correct polarity .", "entities": []}, {"text": "In sentence ( b ) , \u201c the value on the kids menu is good \u201d , good modi\ufb01es the value , rather than the given category menu .", "entities": []}, {"text": "Our method gives the correct polarity , not being affected by the surrounding other aspect sentiments .", "entities": []}, {"text": "The last instance ( c ) has conditional reasoning which is dif\ufb01cult for BART classi\ufb01cation .", "entities": [[13, 14, "MethodName", "BART"]]}, {"text": "In contrast , BART generationgives the correct label by correctly recognizing the negativity in \u201c if there was ... would be a bit more inviting \u201d .", "entities": [[3, 4, "MethodName", "BART"]]}, {"text": "This is likely because our method makes use of pre - trained knowledge to infer the inter - sentential correlations between the input and the output sequences , which the BART classi\ufb01cationmodel failed to achieve due to the indirect use of BART in the additional classi\ufb01cation network .", "entities": [[30, 31, "MethodName", "BART"], [41, 42, "MethodName", "BART"]]}, {"text": "6 Conclusion We investigated a generation method for aspect category detection ( ACD ) and aspect category sentiment analysis ( ACSA ) , which can make better use of BART \u2019s advantages in making semantic level summaries to the input by not introducing additional model parameters .", "entities": [[8, 11, "TaskName", "aspect category detection"], [17, 19, "TaskName", "sentiment analysis"], [29, 30, "MethodName", "BART"]]}, {"text": "Experiments show that our proposed method obtains superior performance over the baseline models for both sentence - level and document - level aspect sentiment analysis .", "entities": [[23, 25, "TaskName", "sentiment analysis"]]}, {"text": "In contrast to the traditional sentiment classi\ufb01cation methods , our method is also more powerful on zero - shot and few - shot tasks .", "entities": []}, {"text": "4414Acknowledgements Zhiyang Teng is the corresponding author .", "entities": []}, {"text": "We would like to thank the anonymous reviewers for their insightful comments .", "entities": []}, {"text": "We gratefully acknowledge funding from the National Natural Science Foundation of China ( NSFC No.61976180 ) .", "entities": []}, {"text": "References Tom B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert - V oss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Language models are few - shot learners .", "entities": []}, {"text": "Caroline Brun , Diana Nicoleta Popa , and Claude Roux .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "XRCE : hybrid classi\ufb01cation for aspect - based sentiment analysis .", "entities": [[5, 10, "TaskName", "aspect - based sentiment analysis"]]}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation , SemEval@COLING 2014 , Dublin , Ireland , August 2324 , 2014 , pages 838\u2013842 .", "entities": []}, {"text": "The Association for Computer Linguistics .", "entities": []}, {"text": "Jiajun Cheng , Shenglin Zhao , Jiani Zhang , Irwin King , Xin Zhang , and Hui Wang . 2017 .", "entities": []}, {"text": "Aspect - level sentiment classi\ufb01cation with heat ( hierarchical attention ) network .", "entities": []}, {"text": "In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management , pages 97\u2013106 .", "entities": [[5, 6, "DatasetName", "ACM"], [12, 13, "TaskName", "Management"]]}, {"text": "Zehui Dai , Cheng Peng , Huajie Chen , and Yadong Ding .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "A multi - task incremental learning framework with category name embedding for aspect - category sentiment analysis .", "entities": [[4, 6, "TaskName", "incremental learning"], [15, 17, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , EMNLP 2020 , Online , November 16 - 20 , 2020 , pages 6955\u20136965 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Angel Daza and A. Frank .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A sequence - tosequence model for semantic role labeling .", "entities": [[6, 9, "TaskName", "semantic role labeling"]]}, {"text": "In Rep4NLP@ACL .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019a .", "entities": []}, {"text": "BERT : Pre - training of deep bidirectional transformers for language understanding .", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 , Minneapolis , Minnesota .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019b .", "entities": []}, {"text": "Bert : Pre - training ofdeep bidirectional transformers for language understanding .", "entities": []}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 .", "entities": []}, {"text": "Tianyu Gao , Adam Fisch , and Danqi Chen .", "entities": [[3, 4, "MethodName", "Adam"]]}, {"text": "2020 .", "entities": []}, {"text": "Making pre - trained language models better few - shot learners .", "entities": []}, {"text": "Mengting Hu , Shiwan Zhao , Li Zhang , Keke Cai , Zhong Su , Renhong Cheng , and Xiaowei Shen . 2019 .", "entities": []}, {"text": "Can : Constrained attention networks for multi - aspect sentiment analysis .", "entities": [[9, 11, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 4593\u20134602 .", "entities": []}, {"text": "Qingnan Jiang , Lei Chen , Ruifeng Xu , Xiang Ao , and Min Yang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "A challenge dataset and effective models for aspect - based sentiment analysis .", "entities": [[7, 12, "TaskName", "aspect - based sentiment analysis"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 6281\u20136286 .", "entities": []}, {"text": "Svetlana Kiritchenko , Xiaodan Zhu , Colin Cherry , and Saif Mohammad . 2014 .", "entities": []}, {"text": "Nrc - canada-2014 : Detecting aspects and sentiment in customer reviews .", "entities": []}, {"text": "InProceedings of the 8th International Workshop on Semantic Evaluation , SemEval@COLING 2014 , Dublin , Ireland , August 23 - 24 , 2014 , pages 437\u2013442 .", "entities": []}, {"text": "The Association for Computer Linguistics .", "entities": []}, {"text": "Tao Lei , Regina Barzilay , and Tommi S. Jaakkola .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Rationalizing neural predictions .", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , EMNLP 2016 , Austin , Texas , USA , November 1 - 4 , 2016 , pages 107 \u2013 117 .", "entities": [[19, 20, "DatasetName", "Texas"]]}, {"text": "The Association for Computational Linguistics .", "entities": []}, {"text": "Mike Lewis , Yinhan Liu , Naman Goyal , Marjan Ghazvininejad , Abdelrahman Mohamed , Omer Levy , Veselin Stoyanov , and Luke Zettlemoyer .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "BART :", "entities": [[0, 1, "MethodName", "BART"]]}, {"text": "Denoising sequence - to - sequence pretraining for natural language generation , translation , and comprehension .", "entities": [[0, 1, "TaskName", "Denoising"]]}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 7871\u20137880 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Xiaoya Li , Fan Yin , Zijun Sun , Xiayu Li , Arianna Yuan , Duo Chai , Mingxin Zhou , and Jiwei Li .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Entity - relation extraction as multi - turn question answering .", "entities": [[2, 4, "TaskName", "relation extraction"], [8, 10, "TaskName", "question answering"]]}, {"text": "In Proceedings of the 57th Conference of the Association for Computational Linguistics , ACL 2019 , Florence , Italy , July 28- August 2 , 2019 , Volume 1 : Long Papers , pages 1340\u20131350 .", "entities": [[16, 17, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yuncong Li , Zhe Yang , Cunxiang Yin , Xu Pan , Lunan Cui , Qiang Huang , and Ting Wei . 2020a .", "entities": []}, {"text": "A joint model for aspect - category sentiment analysis with", "entities": [[7, 9, "TaskName", "sentiment analysis"]]}, {"text": "4415shared sentiment prediction layer .", "entities": []}, {"text": "In Proceedings of the 19th Chinese National Conference on Computational Linguistics , pages 1112\u20131121 , Haikou , China .", "entities": []}, {"text": "Chinese Information Processing Society of China .", "entities": []}, {"text": "Yuncong Li , Cunxiang Yin , Sheng - hua Zhong , and Xu Pan . 2020b .", "entities": []}, {"text": "Multi - instance multi - label learning networks for aspect - category sentiment analysis .", "entities": [[3, 7, "TaskName", "multi - label learning"], [12, 14, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , EMNLP 2020 , Online , November 16 - 20 , 2020 , pages 3550 \u2013 3560 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yunlong Liang , Fandong Meng , Jinchao Zhang , Jinan Xu , Yufeng Chen , and Jie Zhou .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "A novel aspect - guided deep transition model for aspect based sentiment analysis .", "entities": [[11, 13, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 5572\u20135584 .", "entities": []}, {"text": "Yongjie Lin , Yi Chern Tan , and Robert Frank .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Open sesame : Getting inside BERT \u2019s linguistic knowledge .", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2019 ACL Workshop BlackboxNLP : Analyzing and Interpreting Neural Networks for NLP , pages 241\u2013253 , Florence , Italy .", "entities": [[20, 21, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chunpeng Ma , L. Liu , Akihiro Tamura , T. Zhao , and E. Sumita . 2017 .", "entities": []}, {"text": "Deterministic attention for sequence - to - sequence constituent parsing .", "entities": []}, {"text": "In AAAI .", "entities": []}, {"text": "Julian J. McAuley , Jure Leskovec , and Dan Jurafsky .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Learning attitudes and attributes from multiaspect reviews .", "entities": []}, {"text": "CoRR , abs/1210.3926 .", "entities": []}, {"text": "Fabio Petroni , Tim Rockt\u00e4schel , Sebastian Riedel , Patrick Lewis , Anton Bakhtin , Yuxiang Wu , and Alexander Miller .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Language models as knowledge bases ?", "entities": []}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLPIJCNLP ) , pages 2463\u20132473 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Maria Pontiki , Dimitris Galanis , John Pavlopoulos , Harris Papageorgiou , Ion Androutsopoulos , and Suresh Manandhar .", "entities": []}, {"text": "2014a .", "entities": []}, {"text": "SemEval-2014 task 4 : Aspect based sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation ( SemEval 2014 ) , pages 27\u201335 , Dublin , Ireland .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Maria Pontiki , Dimitris Galanis , John Pavlopoulos , Harris Papageorgiou , Ion Androutsopoulos , and Suresh Manandhar .", "entities": []}, {"text": "2014b .", "entities": []}, {"text": "Semeval-2014 task 4 : Aspect based sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation , SemEval@COLING 2014 , Dublin , Ireland , August 23 - 24 , 2014 , pages 27\u201335 .", "entities": []}, {"text": "The Association for Computer Linguistics .", "entities": []}, {"text": "Colin Raffel , Noam Shazeer , Adam Roberts , Katherine Lee , Sharan Narang , Michael Matena , Yanqi Zhou , Wei Li , and Peter J. Liu . 2020 .", "entities": [[6, 7, "MethodName", "Adam"]]}, {"text": "Exploring the limits of transfer learning with a uni\ufb01ed text - to - text transformer .", "entities": [[4, 6, "TaskName", "transfer learning"]]}, {"text": "J. Mach .", "entities": []}, {"text": "Learn .", "entities": []}, {"text": "Res . , 21:140:1\u2013140:67 .", "entities": []}, {"text": "Sebastian Ruder , Parsa Ghaffari , and John G Breslin .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "A hierarchical model of reviews for aspectbased sentiment analysis .", "entities": [[7, 9, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 999\u20131005 .", "entities": []}, {"text": "Timo Schick , Helmut Schmid , and Hinrich Sch\u00fctze . 2020 .", "entities": [[0, 1, "DatasetName", "Timo"]]}, {"text": "Automatically identifying words that can serve as labels for few - shot text classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 28th International Conference on Computational Linguistics , pages 5569\u20135578 , Barcelona , Spain ( Online ) .", "entities": []}, {"text": "International Committee on Computational Linguistics .", "entities": []}, {"text": "Timo Schick and Hinrich Sch\u00fctze . 2020 .", "entities": [[0, 1, "DatasetName", "Timo"]]}, {"text": "Exploiting cloze questions for few shot text classi\ufb01cation and natural language inference .", "entities": [[9, 12, "TaskName", "natural language inference"]]}, {"text": "Martin Schmitt , Simon Steinheber , Konrad Schreiber , and Benjamin Roth . 2018 .", "entities": []}, {"text": "Joint aspect and polarity classi\ufb01cation for aspect - based sentiment analysis with end - to - end neural networks .", "entities": [[6, 11, "TaskName", "aspect - based sentiment analysis"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 1109\u20131114 .", "entities": []}, {"text": "Gabriel Stanovsky and Ido Dagan .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Semantics as a foreign language .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Chi Sun , Luyao Huang , and Xipeng Qiu . 2019 .", "entities": []}, {"text": "Utilizing bert for aspect - based sentiment analysis via constructing auxiliary sentence .", "entities": [[3, 8, "TaskName", "aspect - based sentiment analysis"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 380\u2013385 .", "entities": []}, {"text": "Duyu Tang , Bing Qin , and Ting Liu . 2015 .", "entities": []}, {"text": "Document modeling with gated recurrent neural network for sentiment classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , EMNLP 2015 , Lisbon , Portugal , September 17 - 21 , 2015 , pages 1422\u20131432 .", "entities": []}, {"text": "The Association for Computational Linguistics .", "entities": []}, {"text": "Yi Tay , Luu Anh Tuan , and Siu Cheung Hui .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Learning to attend via word - aspect associative fusion for aspect - based sentiment analysis .", "entities": [[10, 15, "TaskName", "aspect - based sentiment analysis"]]}, {"text": "In ThirtySecond AAAI Conference on Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141 ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems , volume 30 , pages 5998\u20136008 .", "entities": []}, {"text": "Curran Associates , Inc.", "entities": []}, {"text": "Oriol Vinyals , Lukasz Kaiser , Terry Koo , Slav Petrov , Ilya Sutskever , and Geoffrey E. Hinton . 2015 .", "entities": []}, {"text": "Grammar as a foreign language .", "entities": []}, {"text": "In NIPS .", "entities": []}, {"text": "4416Hongning Wang , Yue Lu , and Chengxiang Zhai .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Latent aspect rating analysis on review text data : a rating regression approach .", "entities": []}, {"text": "In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Washington , DC , USA , July 25 - 28 , 2010 , pages 783\u2013792 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "ACM .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Yequan Wang , Minlie Huang , Xiaoyan Zhu , and Li Zhao .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Attention - based lstm for aspectlevel sentiment classi\ufb01cation .", "entities": [[3, 4, "MethodName", "lstm"]]}, {"text": "In Proceedings of the 2016 conference on empirical methods in natural language processing , pages 606\u2013615 .", "entities": []}, {"text": "Yequan Wang , Aixin Sun , Minlie Huang , and Xiaoyan Zhu . 2019 .", "entities": []}, {"text": "Aspect - level sentiment analysis using ascapsules .", "entities": [[3, 5, "TaskName", "sentiment analysis"]]}, {"text": "In The World Wide Web Conference , pages 2033\u20132044 .", "entities": []}, {"text": "Bowen Xing , Lejian Liao , Dandan Song , Jingang Wang , Fuzheng Zhang , Zhongyuan Wang , and Heyan Huang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Earlier attention ?", "entities": []}, {"text": "aspectaware lstm for aspect sentiment analysis .", "entities": [[1, 2, "MethodName", "lstm"], [4, 6, "TaskName", "sentiment analysis"]]}, {"text": "arXiv preprint arXiv:1905.07719 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Wei Xue and Tao Li .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Aspect based sentiment analysis with gated convolutional networks .", "entities": [[2, 4, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 2514\u20132523 .", "entities": []}, {"text": "Zichao Yang , Diyi Yang , Chris Dyer , Xiaodong He , Alexander J. Smola , and Eduard H. Hovy .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Hierarchical attention networks for document classi\ufb01cation .", "entities": []}, {"text": "In NAACL HLT 2016 , The 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , San Diego California , USA , June 1217 , 2016 , pages 1480\u20131489 .", "entities": []}, {"text": "Yichun Yin , Yangqiu Song , and Ming Zhang . 2017 .", "entities": []}, {"text": "Document - level multi - aspect sentiment classi\ufb01cation as machine comprehension .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , EMNLP 2017 , Copenhagen , Denmark , September 9 - 11 , 2017 , pages 2044\u20132054 .", "entities": []}, {"text": "Peisong Zhu , Zhuang Chen , Haojie Zheng , and Tieyun Qian .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Aspect aware learning for aspect category sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "ACM Trans .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Knowl .", "entities": []}, {"text": "Discov .", "entities": []}, {"text": "Data , 13(6 ) .", "entities": []}, {"text": "A Datasets A.1 Sentence - Level Datasets Rest14 ( Pontiki et al . , 2014a )", "entities": []}, {"text": "Following previous work ( Cheng et al . , 2017 ; Tay et al . , 2018 ; Hu et al . , 2019 ) , we remove samples with con\ufb02ict polarities .", "entities": []}, {"text": "Since there is no of\ufb01cial development set for Rest14 , we use the split offered by Tay et al .", "entities": []}, {"text": "( 2018).Dataset Pos .", "entities": []}, {"text": "Neg .", "entities": []}, {"text": "Neu .", "entities": []}, {"text": "Rest14Train 1855 733 430 Dev 324 106 70 Test 657 222 94 Rest14 - hard Test 21 20 12 MAMS - ACSATrain 1929 2084 3077", "entities": [[19, 20, "DatasetName", "MAMS"]]}, {"text": "Dev 241 259 388 Test 245 263 393 Table 9 : Statistics of the sentence - level datasets .", "entities": []}, {"text": "Dataset # docs # words / doc words / sent TripAdvisor 29,391 251.7 18.0 BeerAdvocate 51,020 144.5 12.1 Table 10 : Statistics of the document - level datasets .", "entities": [[14, 15, "DatasetName", "BeerAdvocate"]]}, {"text": "The rating scale of TripAdvisor dataset is 1 - 5 .", "entities": []}, {"text": "The rating scale of BeerAdvocate dataset is 1 - 10 .", "entities": [[4, 5, "DatasetName", "BeerAdvocate"]]}, {"text": "Rest14 - hard Following Xue and Li ( 2018 ) , we construct Rest14 - hard , where the training set and development set are the same as Rest14 \u2019s , while test set is constructed from the test set of Rest14 .", "entities": []}, {"text": "The test set of Rest14 - hard only includes sentences containing at least two aspect categories with different sentiment polarities .", "entities": []}, {"text": "MAMS Jiang et", "entities": [[0, 1, "DatasetName", "MAMS"]]}, {"text": "al .", "entities": []}, {"text": "( 2019 )", "entities": []}, {"text": "Since the test set of Rest14 - hard is small , we also adopt the MultiAspect Multi - Sentiment dataset for Aspect Category Sentiment Analysis ( denoted by MAMS ) .", "entities": [[23, 25, "TaskName", "Sentiment Analysis"], [28, 29, "DatasetName", "MAMS"]]}, {"text": "All sentences in MAMS contain multiple aspect categories with different sentiment polarities .", "entities": [[3, 4, "DatasetName", "MAMS"]]}, {"text": "A.2 Document - Level Datasets TripAdvisor ( Wang et al . , 2010 ) and BeerAdvocate ( McAuley et al . , 2012 ; Lei et al . , 2016 ) contain seven aspects ( value , room , location , cleanliness , check in / front desk , service , and business service ) and four aspects ( feel , look , smell , and taste ) respectively .", "entities": [[15, 16, "DatasetName", "BeerAdvocate"]]}, {"text": "We randomly split them into training , development , and testing sets with 80/10/10 % .", "entities": []}, {"text": "Statistics of these three sentence - level datasets are given in Table 9 and two document - level datasets are described in Table 10 .", "entities": []}, {"text": "B Settings Each method is trained for 30 epochs , during which the model with the best performance on the validation set is saved .", "entities": []}, {"text": "We also apply early stopping in training , which means that the training will stop if the performance on validation set does not improve in 5 epochs .", "entities": [[3, 5, "MethodName", "early stopping"]]}]