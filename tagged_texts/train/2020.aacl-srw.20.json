[{"text": "Proceedings of the 1st Conference of the Asia - Paci\ufb01c Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing : Student Research Workshop , pages 139\u2013145 December 4 - 7 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics139Exploring Statistical and Neural Models for Noun Ellipsis Detection and Resolution in English Payal Khullar International Institute of Information Technology Hyderabad Gachibowli , Hyderabad payal.khullar@research.iiit.ac.in", "entities": []}, {"text": "Abstract Computational approaches to noun ellipsis resolution has been sparse , with only a naive rulebased approach that uses syntactic feature constraints for marking noun ellipsis licensors and selecting their antecedents .", "entities": []}, {"text": "In this paper , we further the ellipsis research by exploring several statistical and neural models for both the subtasks involved in the ellipsis resolution process and addressing the representation and contribution of manual features proposed in previous research .", "entities": []}, {"text": "Using the best performing models , we build an end - to - end supervised Machine Learning ( ML ) framework for this task that improves the existing F1 score by 16.55 % for the detection and 14.97 % for the resolution subtask .", "entities": [[28, 30, "MetricName", "F1 score"]]}, {"text": "Our experiments demonstrate robust scores through pretrained BERT ( Bidirectional Encoder Representations from Transformers ) embeddings for word representation , and more so the importance of manual features \u2013 once again highlighting the syntactic and semantic characteristics of the ellipsis phenomenon .", "entities": [[7, 8, "MethodName", "BERT"]]}, {"text": "For the classi\ufb01cation decision , we notice that a simple Multilayar Perceptron ( MLP ) works well for the detection of ellipsis ; however , Recurrent Neural Networks ( RNN ) are a better choice for the much harder resolution step .", "entities": [[13, 14, "DatasetName", "MLP"]]}, {"text": "1 Introduction Noun ellipsis is a linguistic phenomenon where the head noun of a noun phrase gets deleted , without making the sentence ungrammatical .", "entities": []}, {"text": "For example in the sentence in ( 1 ) from ( Lobeck , 1995 ) , the noun presentation is elided at \u201d [ e ] \u201d .", "entities": []}, {"text": "1.John \u2019s presentation on urban development was virtually ignored because [ NP Mary \u2019s", "entities": []}, {"text": "[ e ] ] was so much more interesting .", "entities": []}, {"text": "The elided information can be retrieved from the previous context as in ( 1 ) or with the knowledge of idiomatic usage of language as in I will be back in two [ e ] .", "entities": []}, {"text": "where twomeans two minutes .", "entities": []}, {"text": "It is Figure 1 : An example of the noun ellipsis resolution process from the dialogue L131377 of the m 44 movie of the Cornell Movie Dialogs dataset .", "entities": [[24, 25, "DatasetName", "Cornell"]]}, {"text": "Here , the nicest andgirldenote the ellipsis licensor and antecedent respectively .", "entities": []}, {"text": "also possible that the reference of the elided information comes from extra - linguistic , situational context .", "entities": []}, {"text": "For example , consider a speaker pointing towards the roses in a shop and saying an utterance as in I will take two [ e ] .", "entities": []}, {"text": "While human interlocutors resolve any such elided information by disambiguating from context , cognitive commonsense extension and reasoning ( Chen , 2016 ) , ellipsis resolution can be a hard task for Natural Language Processing ( NLP ) systems ( Hardt , 1999 ) .", "entities": []}, {"text": "Resolution of ellipsis comprises two tasks - detection of the elided material and antecedent selection ( Liu et al . , 2016b ; Nielsen , 2003 ) .", "entities": []}, {"text": "Ellipses occur in the environment of certain syntactical structures or trigger words , also known as licensors or triggers of ellipses .", "entities": []}, {"text": "They are useful syntactic cues for the detection of noun ellipsis .", "entities": []}, {"text": "See Figure 1 for an example of the noun ellipsis resolution process .", "entities": []}, {"text": "2 Related Work Nominal ellipsis has been a topic of interest in theoretical linguistics for a very long time ( Halliday and Hasan , 1976 ;", "entities": []}, {"text": "Dalrymple et al . , 1991 ; Lobeck , 1995 ; Lappin , 1996 ; Hobbs and Kehler , 1997 ; Hardt , 1999 ; Johnson , 2001 ; Wijnen et", "entities": []}, {"text": "al . , 2003 ; Merchant , 2004 ; Frazier , 2008 ; Chung et al . , 2010 ; Mer-", "entities": []}, {"text": "140chant , 2010 ; Goksun et al . , 2010 ; Gunther , 2011 ; Rouveret , 2012 ;", "entities": []}, {"text": "Lindenbergh et al . , 2015 ; van Craenenbroeck and Merchant , 2013 ; Park , 2017 ; Hyams et al . , 2017 ; Kim et al . , 2019 ) .", "entities": []}, {"text": "Computational approaches to the ellipsis phenomenon majorly focus on the Verb Phrase Ellipsis ( VPE ) along with a few related phenomenon such as gapping , sluicing and do - so anaphora , for instance , the detection of VPE in the Penn Treebank using pattern match ( Hardt , 1992 ) , a transformation learning - based approach to generated patterns for VPE resolution ( Hardt , 1998 ) , the domain independent VPE detection and resolution using machine learning ( Nielsen , 2003 ) , automatically parsed text ( Nielsen , 2004b ) , sentence trimming methods ( McShane et al . , 2015 ) , linguistic principles ( McShane and Babkin , 2016 ) , improved parsing techniques that encode elided material dependencies for reconstruction of sentences containing gapping ( Schuster et al . , 2018 ) , discriminative and margin infused algorithms ( Dean et al . , 2016 ) , Multilayer Perceptrons ( MLP ) and Transformers ( Zhang et al . , 2019 ) .", "entities": [[42, 44, "DatasetName", "Penn Treebank"], [158, 159, "DatasetName", "MLP"]]}, {"text": "In recent times , there has been a surge in the computational research on nominal ellipsis and closely related phenomena ( Khullar et al . , 2020 , 2019 ; Lapshinova - Koltunski et al . , 2018 ; Menzel , 2017 ; Menzel and LapshinovaKoltunski , 2014 ) .", "entities": []}, {"text": "For the resolution process , we previously proposed a rule based system ( Khullar et al . , 2019 ) that detects noun ellipsis using syntactic constraints on licensors of ellipsis and resolves them by matching Part - of - Speech ( POS ) tag similarity between the licensor of ellipsis and the modi\ufb01er of the antecedent .", "entities": [[36, 39, "DatasetName", "Part - of"]]}, {"text": "It later \ufb01ne tunes these syntactic rules on a small curated dataset that contains 234 instances of noun ellipsis along with some negative samples ( Khullar et al . , 2019 ) .", "entities": []}, {"text": "For the present paper , we further the research on noun ellipses by using the NoEl corpus annotated by us previously ( Khullar et al . , 2020 ) to experiment with state - ofthe - art ML models .", "entities": []}, {"text": "3", "entities": []}, {"text": "The Proposed Approach Following the VPE resolution framework presented by ( Zhang et al . , 2019 ) , we investigate a similar framework for noun ellipsis resolution in English and present alternative choices of the models at each step as shown in Figure 2 .", "entities": []}, {"text": "We use the NoEl corpus ( Khullar et al . , 2020 ) that marks noun ellipsis instances as a separate layer ( using the stand - off annotation scheme ) on the Cornell Movie Dialogs corpus ( Danescu - Niculescu - Mizil and Lee , 2011).The corpus marks a total of 946 annotations , of which 438 are described as endophoric , i.e. with a textual antecedent , and 508 exophoric , i.e. without a textual antecedent .", "entities": [[33, 34, "DatasetName", "Cornell"]]}, {"text": "3.1 Noun Ellipsis Detection From a given sentence , we \ufb01rst select all words belonging to the syntactic categories that can license noun ellipsis in English , i.e. cardinal and ordinal numbers , determiners and adjectives ( Ross , 1967 ; Lobeck , 1995 ; Mitkov , 1999 ;", "entities": []}, {"text": "Saito et al . , 2008 ; Kim et al . , 2019 ; Khullar et al . , 2019 ) using a POS tag \ufb01lter .", "entities": []}, {"text": "The POS tags are obtained from state - ofthe - art spaCy parser ( Honnibal and Johnson , 2015 ) .", "entities": []}, {"text": "For simplicity , we refer to words with these categories as noun modi\ufb01ers ( although in strict linguistic terms , this might be problematic ) .", "entities": []}, {"text": "For each of these selected noun modi\ufb01ers , we follow the task speci\ufb01cation for VPE detection used by ( Nielsen , 2004a ;", "entities": []}, {"text": "Bos and Spenader , 2011 ; Liu et al . , 2016a ; Dean et al . , 2016 ) and present noun ellipsis detection as a binary classi\ufb01cation task , where given a noun modi\ufb01er and the sentence in which it occurs as the input , the goal of the classi\ufb01er is to predict whether the noun modi\ufb01er licenses a noun ellipsis or not .", "entities": []}, {"text": "Formally , for a given licensor word liis a licensor in a sentence s , the task is represented as follows : f(li ; s)\u0000 ! f 0;1 g where 1 denotes that liis a licensor in s , and 0 otherwise .", "entities": [[40, 41, "DatasetName", "0"]]}, {"text": "We experiment with both static and contextualised word embeddings for word and context representation .", "entities": [[7, 9, "TaskName", "word embeddings"]]}, {"text": "For the former , we choose pretrained fastText ( FT ) word embeddings ( Bojanowski et al . , 2016 ) as they provide representations for rare and unknown words that might be frequent in the movie dialogues .", "entities": [[7, 8, "MethodName", "fastText"], [11, 13, "TaskName", "word embeddings"]]}, {"text": "For the latter , we use pretrained BERT embeddings from the BERT base uncased wordpiece model for English ( Devlin et", "entities": [[7, 8, "MethodName", "BERT"], [11, 12, "MethodName", "BERT"], [14, 15, "MethodName", "wordpiece"]]}, {"text": "al . , 2019 ) , as these currently offer the most powerful embeddings taking into account a large left and right context .", "entities": []}, {"text": "fastText We take pretrained FT word embeddings for the noun modi\ufb01er and sentence in which it is present and sum pool to obtain a single vector that we use to train our classi\ufb01ers .", "entities": [[0, 1, "MethodName", "fastText"], [5, 7, "TaskName", "word embeddings"]]}, {"text": "For the statistical models , we choose Naive Bayes and Linear Support Vector Machine ( SVM ) , and use scikit learn ( Pedregosa et al . , 2011 ) with 5 - fold cross validation for training and testing .", "entities": [[11, 14, "MethodName", "Support Vector Machine"], [15, 16, "MethodName", "SVM"]]}, {"text": "We choose a", "entities": []}, {"text": "141 Figure 2 : The proposed framework for noun ellipsis detection and resolution in English .", "entities": []}, {"text": "simple MLP and a biLSTM ( Bidirectional Long Short Term Memory ) as our state - of - the - art neural classi\ufb01ers .", "entities": [[1, 2, "DatasetName", "MLP"], [4, 5, "MethodName", "biLSTM"]]}, {"text": "BERT We separate the sentence and the licensor with a [ SEP ] token and keep the sequence length to 300 as this is the maximum sentence length in the training data .", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "After creating the concatenated set of tokens , if the number of tokens are greater than 300 , we clip it to 300 , otherwise we add [ PAD ] tokens which correspond to the embedding of 768 dimensional zero - vector .", "entities": [[28, 29, "DatasetName", "PAD"]]}, {"text": "The [ CLS ] output of the BERT model ( Devlin et al . , 2019 ) is then fed into Naive Bayes , Linear SVM , MLP and bi - LSTM networks as above .", "entities": [[7, 8, "MethodName", "BERT"], [25, 26, "MethodName", "SVM"], [27, 28, "DatasetName", "MLP"], [31, 32, "MethodName", "LSTM"]]}, {"text": "Manual Syntactic Features For each of these models , we additionally experiment with manual syntactic features .", "entities": []}, {"text": "We use the lexical features proposed by ( Dean et al . , 2016 ) and extended lexical features by ( Zhang et al . , 2019 ) , and take the \ufb01ve syntactic constraints on licensors of ellipsis explored by ( Khullar et al . , 2019 ) for their rulebased approach as our slot pattern features .", "entities": []}, {"text": "We concatenate all these features to the embeddings from the previous step and check if they improve the classi\ufb01cation decision .", "entities": []}, {"text": "3.2 Noun Ellipsis Resolution We de\ufb01ne noun ellipsis resolution as a binary classi\ufb01cation task where given a licensor , antecedent candidate and their context , the goal of the classi\ufb01er is to predict whether the antecedent candidateis the resolution of the ellipsis licensed by the licensor .", "entities": []}, {"text": "Formally , given a sentence s , the licensor lifrom the detection step , and the antecedent candidate aj ; the noun ellipsis resolution task can be de\ufb01ned as follows : f(aj ; li ; s)\u0000 !", "entities": []}, {"text": "f 0;1 g where 1 denotes that the antecedent candidate ajis the actual resolution of the ellipsis licensed by li , and 0 otherwise .", "entities": [[22, 23, "DatasetName", "0"]]}, {"text": "Embeddings Similar to the detection step , we take pretrained fastText word embeddings for the licensor , antecedent candidate and context , and sum pool to obtain a single vector .", "entities": [[10, 11, "MethodName", "fastText"], [11, 13, "TaskName", "word embeddings"]]}, {"text": "In case of BERT , we separate the sentence , the licensor and the antecedent candidate with a [ SEP ] token and follow the same steps as in the detection step .", "entities": [[3, 4, "MethodName", "BERT"]]}, {"text": "Manual Syntactic and Semantic Features We use POS tags of the licensor and modi\ufb01er of the antecedent as our syntactic features and cosine similarity between their POS tags as our semantic features , following ( Khullar et al . , 2019 ) .", "entities": []}, {"text": "We concatenate these features to the embeddings to explore the ef\ufb01cacy of adding manual features on resolution .", "entities": []}, {"text": "4 Experiments We choose Naive Bayes and linear SVM as our statistical models , and Multilayer Perceprton ( MLP ) and bidirectional Long Short Term Memory ( biLSTM ) network as our neural models .", "entities": [[8, 9, "MethodName", "SVM"], [18, 19, "DatasetName", "MLP"], [27, 28, "MethodName", "biLSTM"]]}, {"text": "For the", "entities": []}, {"text": "142Subtask Classi\ufb01cation Representation Precision Recall F1 - Score FT 0.4192 0.5807 0.4869 FT+F 0.4923 0.6275 0.5517 Naive Bayes BERT 0.5511 0.6203 0.5837 BERT+F 0.5990 0.6213 0.6099 FT 0.4502 0.5560 0.4975 FT+F 0.4824 0.6400 0.5501 SVM BERT 0.5766 0.6503 0.6112 BERT+F 0.5799 0.6771 0.6247 Detection FT 0.6504 0.6974 0.6731 FT+F 0.7123 0.8977 0.7943 MLP BERT 0.6999 0.7398 0.7193 BERT+F 0.9116 0.8901 0.9007 FT 0.6010 0.6531 0.6260 FT+F 0.6901 0.8745 0.7714 bi - LSTM BERT 0.7001 0.7503 0.7243 BERT+F 0.8655 0.8163 0.8402 Table 1 : Precision , Recall and F1 - Score values of different statistical and neural models on the noun ellipsis detection task .", "entities": [[3, 4, "MetricName", "Precision"], [4, 5, "MetricName", "Recall"], [5, 8, "MetricName", "F1 - Score"], [18, 19, "MethodName", "BERT"], [34, 35, "MethodName", "SVM"], [35, 36, "MethodName", "BERT"], [52, 53, "DatasetName", "MLP"], [53, 54, "MethodName", "BERT"], [71, 72, "MethodName", "LSTM"], [72, 73, "MethodName", "BERT"], [83, 84, "MetricName", "Precision"], [85, 86, "MetricName", "Recall"], [87, 90, "MetricName", "F1 - Score"]]}, {"text": "FT stands for fastText and + F denotes concatenation of manual features to the embeddings .", "entities": [[3, 4, "MethodName", "fastText"]]}, {"text": "Values in bold depict best performance .", "entities": []}, {"text": "detection task , we take the annotated 946 positive samples ( exophoric ) and randomly choose 946 negative samples .", "entities": []}, {"text": "Similarly , for the resolution task , we take 438 positive samples ( endophoric ) and 438 randomly chosen negative samples .", "entities": []}, {"text": "We perform a standard 70 - 10 - 20 split to obtain the train , development and test set respectively , and follow the 5 - fold cross validation procedure to capture both classes properly in each case .", "entities": []}, {"text": "For MLP , we take a simple , two - layer feedforward network ( FFNN ) or two layers of multiple computational units interconnected in a feed - forward way without loops .", "entities": [[1, 2, "DatasetName", "MLP"], [11, 13, "MethodName", "feedforward network"]]}, {"text": "We have a single hidden layer with 768 neurons and a sigmoid function .", "entities": []}, {"text": "A unidirectional weight connection exists between the two successive layers .", "entities": []}, {"text": "The classi\ufb01cation decision is made by turning the input vector representations of a word with its context into a score .", "entities": []}, {"text": "The network has a softmax output layer .", "entities": [[4, 5, "MethodName", "softmax"]]}, {"text": "For bi - LSTM , we have embedding layer , time - distributed translate layer , Bi - LSTM ( RNN ) layer , batch normalization layer , dropout layer and prediction layer .", "entities": [[3, 4, "MethodName", "LSTM"], [18, 19, "MethodName", "LSTM"], [24, 26, "MethodName", "batch normalization"]]}, {"text": "The activation used is Softmax .", "entities": [[4, 5, "MethodName", "Softmax"]]}, {"text": "The loss function is calculated with cross entropy .", "entities": [[1, 2, "MetricName", "loss"]]}, {"text": "We train in batch sizes of 16 and early stopping with max epochs of 100 .", "entities": [[8, 10, "MethodName", "early stopping"]]}, {"text": "In early stopping the patience is kept to be 10 and the optimizer used isAdam .", "entities": [[1, 3, "MethodName", "early stopping"], [12, 13, "HyperparameterName", "optimizer"]]}, {"text": "We use default values for the learning rate .", "entities": [[6, 8, "HyperparameterName", "learning rate"]]}, {"text": "We use Keras ( Chollet et al . , 2015 ) for coding the models .", "entities": []}, {"text": "5 Results We evaluate the performance of our models in terms of F1 - score , computed by taking an average F1 - scores obtained from the 5 - folds results .", "entities": [[12, 15, "MetricName", "F1 - score"], [20, 22, "MetricName", "average F1"]]}, {"text": "We experiment with sixteen models each for the noun ellipsis detection and resolution .", "entities": []}, {"text": "The results on the testset for Precision , Recall and F1 - Score values are presented in Table.2 .", "entities": [[6, 7, "MetricName", "Precision"], [8, 9, "MetricName", "Recall"], [10, 13, "MetricName", "F1 - Score"]]}, {"text": "As expected , the neural models perform signi\ufb01cantly better than the statistical ones for both the subtasks .", "entities": []}, {"text": "Our experiments show that for the detection task , BERT embeddings with a simple MLP gives best scores .", "entities": [[9, 10, "MethodName", "BERT"], [14, 15, "DatasetName", "MLP"]]}, {"text": "This is expected because , BERT currently provides the most powerful contextual word representations , using 12 separate attention mechanism for each layer , where , at each layer , each token can focus on 12 distinct aspects of other tokens .", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "Since Transformers ( Vaswani et al . , 2017 ) use many distinct attention heads ( 12 * 12=144 for the base BERT model ) , each head can focus on a different kind of constituent combinations , making BERT broadly attending over the whole sentence .", "entities": [[22, 23, "MethodName", "BERT"], [39, 40, "MethodName", "BERT"]]}, {"text": "In our task , the", "entities": []}, {"text": "143Subtask Classi\ufb01cation Representation Precision Recall F1 - Score FT 0.2992 0.5112 0.3775 FT+F 0.3379 0.5750 0.4257 Naive Bayes BERT 0.3919 0.5503 0.4578 BERT+F 0.4558 0.6230 0.5264 FT 0.4001 0.4960 0.4429 FT+F 0.5024 0.6040 0.5485 SVM BERT 0.4966 0.6003 0.5435 BERT+F 0.5372 0.6611 0.5927 Resolution FT 0.5901 0.6577 0.6221 FT+F 0.7005 0.8122 0.7522 MLP BERT", "entities": [[3, 4, "MetricName", "Precision"], [4, 5, "MetricName", "Recall"], [5, 8, "MetricName", "F1 - Score"], [18, 19, "MethodName", "BERT"], [34, 35, "MethodName", "SVM"], [35, 36, "MethodName", "BERT"], [52, 53, "DatasetName", "MLP"], [53, 54, "MethodName", "BERT"]]}, {"text": "0.6951 0.7798 0.7350 BERT+F 0.8015 0.8531 0.8265 FT 0.6009 0.6321 0.6161 FT+F 0.7029 0.8044 0.7502 bi - LSTM BERT 0.7195 0.7383 0.7288 BERT+F 0.8652 0.8166 0.8401 Table 2 : Precision , Recall and F1 - Score values of different statistical and neural models on the noun ellipsis resolution subtask .", "entities": [[17, 18, "MethodName", "LSTM"], [18, 19, "MethodName", "BERT"], [29, 30, "MetricName", "Precision"], [31, 32, "MetricName", "Recall"], [33, 36, "MetricName", "F1 - Score"]]}, {"text": "FT stands for fastText and + F denotes concatenation of manual features to the embeddings .", "entities": [[3, 4, "MethodName", "fastText"]]}, {"text": "BERT with MLP model is robust and ef\ufb01ciently makes generalisations on the syntactic and semantic dependency between the elided noun and the pre - modi\ufb01ers and modi\ufb01ers ( licensors ) .", "entities": [[0, 1, "MethodName", "BERT"], [2, 3, "DatasetName", "MLP"]]}, {"text": "For the resolution task , however , bi - LSTMs work better than MLP .", "entities": [[13, 14, "DatasetName", "MLP"]]}, {"text": "Unlike MLPs , Bi - LSTMs take into consideration left to right and right to left context , capturing long range dependencies in a sentence and , hence , are better suited for handling the resolution of a cohesive discourse device like ellipsis where the distance between elided phrase and antecedent can be several words .", "entities": []}, {"text": "The suf\ufb01cient neurons in the hidden layer with sigmoidal function ensures the MLP approximate the nonlinear relationships between the Curated Dataset P R F Detection ( Khullar et al . , 2019 ) 69.15 85.53 76.47 MLP , BERT+F 91.72 94.32 93.02 Resolution ( Khullar et al . , 2019 ) 78.79 63.41 70.27 bi - LSTM , BERT+F 87.01 83.54 85.24 Table 3 : Precision ( P ) , Recall ( R ) and F1 - Score ( F ) values ( % ) of the rule - based approach by ( Khullar et al . , 2019 ) and the neural model presented in this paper.input and output , but they are not innately designed to capture temporal relationships within a sentence .", "entities": [[12, 13, "DatasetName", "MLP"], [36, 37, "DatasetName", "MLP"], [56, 57, "MethodName", "LSTM"], [65, 66, "MetricName", "Precision"], [70, 71, "MetricName", "Recall"], [75, 78, "MetricName", "F1 - Score"]]}, {"text": "Hence , although they perform well for a task like detection that needs local information , they are outperformed by bi - LSTMs on the resolution task that requires capturing a deeper relationship between the antecedent and the elided noun .", "entities": []}, {"text": "We also note that manual feature addition boosts results greatly for all models , highlighting that ellipsis is a syntactically constrained phenomenon .", "entities": []}, {"text": "We \ufb01nally integrate the best models for each subtask into an end - to - end pipeline , as in Figure 2 .", "entities": []}, {"text": "Now , instead of the gold vectors ( from the annotations ) , the resolution model is fed the ouput licensor vector from the detection model .", "entities": []}, {"text": "This obviously results into error propagation into the second model , and lowers the precision value to 82.52 % , recall to 78.66 % and consequently , the F1 - score to 80.55 % of the \ufb01nal system .", "entities": [[28, 31, "MetricName", "F1 - score"]]}, {"text": "The error in the \ufb01nal system comes from failing to detect actual licensors , wrongly identifying non - licensor words and correct licensor detection but failed antecedent resolution .", "entities": []}, {"text": "We run our \ufb01nal system on the curated dataset prepared by ( Khullar et al . , 2019 ) and compare the results with their rule - based approach .", "entities": []}, {"text": "As expected , this model improves the F1 - score by 16.55 % for noun ellipsis detection and 14.97 % for noun ellipsis res-", "entities": [[7, 10, "MetricName", "F1 - score"]]}, {"text": "144olution .", "entities": []}, {"text": "See Table 3 .", "entities": []}, {"text": "The even higher accuracy on the curated dataset can be explained by the nature of the sentences in this dataset which are from textbooks , and , hence , free of grammatical errors , etc . \u2013 resulting into improved parser performance in the pre - processing step .", "entities": [[3, 4, "MetricName", "accuracy"]]}, {"text": "Although , the presented models achieve high scores on both the tasks separately and in the pipeline process , the results can be further improved with hyper - parameter tuning and additional regularization .", "entities": []}, {"text": "6 Conclusion We explored statistical and neural models for noun ellipsis detection and resolution , presenting a strong results for this task .", "entities": []}, {"text": "As expected , neural classi\ufb01ers perform signi\ufb01cantly better than the statistical with the same input representation .", "entities": []}, {"text": "As with several other NLP tasks , the contextual nature of BERT is useful for noun ellipsis resolution too , making robust predictions with simple neural classi\ufb01ers .", "entities": [[11, 12, "MethodName", "BERT"]]}, {"text": "Finally , addition of manual features boosts the performance of all classi\ufb01ers including those that use BERT , highlighting that ellipsis is a syntactically constrained phenomenon .", "entities": [[16, 17, "MethodName", "BERT"]]}, {"text": "References Piotr Bojanowski , Edouard Grave , Armand Joulin , and Tomas Mikolov .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Enriching word vectors with subword information .", "entities": []}, {"text": "arXiv preprint arXiv:1607.04606 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Johan Bos and Jennifer Spenader . 2011 .", "entities": []}, {"text": "An annotated corpus for the analysis of vp ellipsis .", "entities": []}, {"text": "Language Resources and Evaluation , 45(4):463\u2013494 .", "entities": []}, {"text": "Wei Chen .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "The motivation of ellipsis .", "entities": []}, {"text": "Theory and Practice in Language Studies , 6(11):2134 \u2013 2139 .", "entities": []}, {"text": "Franc \u00b8ois Chollet et al . 2015 .", "entities": []}, {"text": "Keras .", "entities": []}, {"text": "https://keras.io .", "entities": []}, {"text": "Sandra Chung , William Ladusaw , and James McCloskey .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Sluicing ( :) between structure and inference .", "entities": []}, {"text": "In Representing language : Essays in honor of Judith Aissen .", "entities": [[4, 5, "DatasetName", "Essays"]]}, {"text": "Jeroen van Craenenbroeck and Jason Merchant .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Ellipsis phenomena .", "entities": []}, {"text": "In The Cambridge Handbook of Generative Syntax , pages 701\u2013745 .", "entities": [[2, 3, "DatasetName", "Cambridge"]]}, {"text": "Cambridge University Press .", "entities": [[0, 1, "DatasetName", "Cambridge"]]}, {"text": "Mary Dalrymple , Stuart M. Shieber , and Fernando C. N. Pereira . 1991 .", "entities": []}, {"text": "Ellipsis and higher - order uni\ufb01cation .", "entities": []}, {"text": "Linguistics and Philosophy , 14(4):399\u2013452 .", "entities": [[2, 3, "TaskName", "Philosophy"]]}, {"text": "Cristian Danescu - Niculescu - Mizil and Lillian Lee . 2011 .", "entities": []}, {"text": "Chameleons in imagined conversations : Anew approach to understanding coordination of linguistic style in dialogs .", "entities": []}, {"text": "In Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics , ACL 2011 .", "entities": []}, {"text": "Kian Kenyon Dean , Jackie Chi Kit Cheung , and Doina Precup . 2016 .", "entities": []}, {"text": "Verb phrase ellipsis resolution using discriminative and margin - infused algorithms .", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , page 1734\u20131743 .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Lyn Frazier .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Processing ellipsis : A processing solution to the undergeneration problem ?", "entities": []}, {"text": "In Proceedings of the 26th West Coast Conference on Formal Linguistics .", "entities": []}, {"text": "Tilbe Goksun , Tom W. Roeper , Kathy Hirsh - Pasek , and Roberta Michnick Golinkoff .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "From nounphrase ellipsis to verbphrase ellipsis : The acquisition path from context to abstract reconstruction .", "entities": []}, {"text": "Christine Gunther .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Noun ellipsis in english : adjectival modi\ufb01ers and the role of context .", "entities": []}, {"text": "The structure of the noun phrase in English : synchronic and diachronic explorations , 15(2):279\u2013301 .", "entities": []}, {"text": "Michael Alexander Kirkwood Halliday and Ruqaiya Hasan .", "entities": []}, {"text": "1976 .", "entities": []}, {"text": "Cohesion in english .", "entities": []}, {"text": "page 76 .", "entities": []}, {"text": "Daniel Hardt .", "entities": []}, {"text": "1992 .", "entities": []}, {"text": "An algorithm for vp ellipsis .", "entities": []}, {"text": "page 9\u201314 .", "entities": []}, {"text": "In Proceedings of the 30th annual meeting on Association for Computational Linguistics .", "entities": []}, {"text": "Daniel Hardt .", "entities": []}, {"text": "1998 .", "entities": []}, {"text": "Improving ellipsis resolution with transformation - based learning .", "entities": []}, {"text": "AAAI fall symposium .", "entities": []}, {"text": "Daniel Hardt .", "entities": []}, {"text": "1999 .", "entities": []}, {"text": "Dynamic interpretation of verb phrase ellipsis .", "entities": []}, {"text": "Linguistics and Philosophy , 22(2):187\u2013221 .", "entities": [[2, 3, "TaskName", "Philosophy"]]}, {"text": "Jerry R. Hobbs and Andrew Kehler .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "A theory of parallelism and the case of vp ellipsis .", "entities": []}, {"text": "In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics , ACL \u2019 98 / EACL \u2019 98 , pages 394\u2013401 , Stroudsburg , PA , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Matthew Honnibal and Mark Johnson .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "An improved non - monotonic transition system for dependency parsing .", "entities": [[8, 10, "TaskName", "dependency parsing"]]}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 1373\u20131378 , Lisbon , Portugal .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nina Hyams , Victoria Mateu , and Lauren Winans .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Ellipsis meets wh - movement : sluicing in early grammar .", "entities": []}, {"text": "145Kyle Johnson .", "entities": []}, {"text": "2001 .", "entities": []}, {"text": "What vp ellipsis can do , and what it ca n\u2019t , but not why .", "entities": []}, {"text": "pages 439\u2013479 .", "entities": []}, {"text": "Payal Khullar , Allen Anthony , and Manish Shrivastava .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Using syntax to resolve npe in english .", "entities": []}, {"text": "In Proceedings of Recent Advances in Natural Language Processing , pages 535\u2013541 .", "entities": []}, {"text": "Payal Khullar , Kushal Majmundar , and Manish Shrivastava .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Noel : An annotated corpus for noun ellipsis in english .", "entities": []}, {"text": "In Language Resources Evaluation Conference .", "entities": []}, {"text": "Nayoun Kim , Laurel Brehm , and Masaya Yoshida .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The online processing of noun phrase ellipsis and mechanisms of antecedent retrieval .", "entities": []}, {"text": "Language , Cognition and Neuroscience , 34(2):190\u2013213 .", "entities": []}, {"text": "Shalom Lappin .", "entities": []}, {"text": "1996 .", "entities": []}, {"text": "The interpretatin of ellipsis .", "entities": []}, {"text": "In Shalom Lappin , editor , The Handbook of Contemporary Semantic Theory , pages 145\u2013176 .", "entities": []}, {"text": "Blackwell .", "entities": []}, {"text": "Ekaterina Lapshinova - Koltunski , Christian Hardmeier , and Pauline Krielke .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Parcorfull : a parallel corpus annotated with full coreference .", "entities": [[0, 1, "DatasetName", "Parcorfull"]]}, {"text": "In Proceedings of the Eleventh International Conference on Language Resources and Evaluation , LREC 2018 , Miyazaki , Japan , May 7 - 12 , 2018 .", "entities": []}, {"text": "Charlotte Lindenbergh , Angeliek van Hout , and Bart Hollebrandse . 2015 .", "entities": []}, {"text": "Extending ellipsis research : The acquisition of sluicing in dutch .", "entities": []}, {"text": "BUCLD 39 Online Proceedings Supplement , 39 .", "entities": []}, {"text": "Chin - Ting Liu , Li - mei Chen , Yu - Ching Lin , Chia - Fang Cheng , and Hui - chen Chang .", "entities": []}, {"text": "2016a .", "entities": []}, {"text": "Speech intelligibility and the production of fricative and affricate among Mandarin - speaking children with cerebral palsy .", "entities": []}, {"text": "In Proceedings of the 28th Conference on Computational Linguistics and Speech Processing ( ROCLING 2016 ) , pages 153\u2013163 , Tainan , Taiwan .", "entities": []}, {"text": "The Association for Computational Linguistics and Chinese Language Processing ( ACLCLP ) .", "entities": []}, {"text": "Zhengzhong Liu , Edgar Gonzalez , and Dan Gillick . 2016b .", "entities": []}, {"text": "Verb phrase ellipsis detection using automatically parsed text .", "entities": []}, {"text": "pages 32\u201340 .", "entities": []}, {"text": "Anne Lobeck .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "Functional Heads , Licensing , and Identi\ufb01cation .", "entities": []}, {"text": "Oxford University Press .", "entities": []}, {"text": "Marjorie McShane and Petr Babkin .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Detection and resolution of verb phrase ellipsis .", "entities": []}, {"text": "Linguistic Issues in Language Technology , 13(1 ) .", "entities": []}, {"text": "Marjorie McShane , Sergei Nirenburg , and Petr Babkin . 2015 .", "entities": []}, {"text": "Sentence trimming in service of verb phrase ellipsis resolution .", "entities": []}, {"text": "In EAPCogSci .", "entities": []}, {"text": "Katrin Menzel . 2017 .", "entities": []}, {"text": "Understanding English - German contrasts : a corpus - based comparative analysis of ellipses as cohesive devices .", "entities": []}, {"text": "Ph.D. thesis , Universitat des Saar- landes , Saarbrucken .", "entities": []}, {"text": "Katrin Menzel and Ekaterina Lapshinova - Koltunski . 2014 .", "entities": []}, {"text": "Kontrastive analyse deutscher und englischer koh \u00a8asionsmittel in verschiedenen diskurstypen .", "entities": []}, {"text": "tekst i dyskurs - Text und Diskurs .", "entities": []}, {"text": "Zeitschrift der Abteilung f \u00a8ur germanistische Sprachwissenschaft des Germanistischen Instituts Warschau .", "entities": []}, {"text": "Jason Merchant .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Fragments and ellipsis .", "entities": []}, {"text": "Linguistics and Philosophy , 27(6):661\u2013738 .", "entities": [[2, 3, "TaskName", "Philosophy"]]}, {"text": "Jason Merchant .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Three Kinds of Ellipsis : Syntactic , Semantic , Pragmatic ?", "entities": []}, {"text": "Ruslan Mitkov .", "entities": [[0, 1, "DatasetName", "Ruslan"]]}, {"text": "1999 .", "entities": []}, {"text": "Anaphora Resolution .", "entities": []}, {"text": "Oxford University Press .", "entities": []}, {"text": "Leif Arda Nielsen .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Using machine learning techniques for vpe detection .", "entities": []}, {"text": "Leif Arda Nielsen . 2004a .", "entities": []}, {"text": "Robust VPE detection using automatically parsed text .", "entities": []}, {"text": "In Proceedings of the ACL Student Research Workshop , pages 49\u201354 , Barcelona , Spain .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Leif Arda Nielsen .", "entities": []}, {"text": "2004b .", "entities": []}, {"text": "Verb phrase ellipsis detection using automatically parsed text .", "entities": []}, {"text": "Dongwoo Park .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "When does ellipsis occur , and what is elided ?", "entities": []}, {"text": "PhD dissertation , University of Maryland .", "entities": []}, {"text": "F. Pedregosa , G. Varoquaux , A. Gramfort , V .", "entities": []}, {"text": "Michel , B. Thirion , O. Grisel , M. Blondel , P. Prettenhofer , R. Weiss , V .", "entities": []}, {"text": "Dubourg , J. Vanderplas , A. Passos , D. Cournapeau , M. Brucher , M. Perrot , and E. Duchesnay . 2011 .", "entities": []}, {"text": "Scikit - learn : Machine learning in Python .", "entities": []}, {"text": "Journal of Machine Learning Research , 12:2825\u20132830 .", "entities": []}, {"text": "John Robert Ross .", "entities": []}, {"text": "1967 .", "entities": []}, {"text": "Constraints on variables in syntax .", "entities": []}, {"text": "Massachusetts Institute of Technology .", "entities": []}, {"text": "Alain Rouveret .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Vp ellipsis , phases and the syntax of morphology .", "entities": []}, {"text": "Natural Language & Linguistic Theory , 30(3):897\u2013963 .", "entities": []}, {"text": "Mamoru Saito , Jonah Lin , and Keiko Murasugi . 2008 .", "entities": []}, {"text": "Nominal - ellipsis and the structure of noun phrases in chinese and japanese .", "entities": []}, {"text": "Journal of East Asian Linguistics , 17 .", "entities": []}, {"text": "Sebastian Schuster , Joakim Nivre , and Christopher D. Manning .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Sentences with gapping : Parsing and reconstructing elided predicates .", "entities": []}, {"text": "ArXiv e - prints .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N. Gomez , Lukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Frank Wijnen , Tom W. Roeper , and Hiske van der Meulen .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Discourse binding : Does it begin with nominal ellipsis ?", "entities": []}, {"text": "Wei - Nan Zhang , Yue Zhang , Yuanxing Liu , Donglin Di , and Ting Liu1 .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "A neural network approach to verb phrase ellipsis resolution .", "entities": []}]