[{"text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 742\u2013751 July 5 - 10 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics742Rigid Formats Controlled Text Generation Piji", "entities": [[7, 9, "TaskName", "Text Generation"]]}, {"text": "Li Haisong Zhang Xiaojiang Liu Shuming Shi Tencent AI Lab , Shenzhen , China fpijili , hansonzhang , kieranliu , shumingshi g@tencent.com", "entities": []}, {"text": "Abstract Neural text generation has made tremendous progress in various tasks .", "entities": [[2, 4, "TaskName", "text generation"]]}, {"text": "One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating .", "entities": []}, {"text": "However , we may confront some special text paradigms such as Lyrics ( assume the music score is given ) , Sonnet , SongCi ( classical Chinese poetry of the Song dynasty ) , etc .", "entities": []}, {"text": "The typical characteristics of these texts are in three folds : ( 1 ) They must comply fully with the rigid prede\ufb01ned formats .", "entities": []}, {"text": "( 2 ) They must obey some rhyming schemes .", "entities": []}, {"text": "( 3 ) Although they are restricted to some formats , the sentence integrity must be guaranteed .", "entities": []}, {"text": "To the best of our knowledge , text generation based on the prede\ufb01ned rigid formats has not been well investigated .", "entities": [[7, 9, "TaskName", "text generation"]]}, {"text": "Therefore , we propose a simple and elegant framework named SongNet to tackle this problem .", "entities": [[10, 11, "MethodName", "SongNet"]]}, {"text": "The backbone of the framework is a Transformer - based auto - regressive language model .", "entities": [[7, 8, "MethodName", "Transformer"]]}, {"text": "Sets of symbols are tailor - designed to improve the modeling performance especially on format , rhyme , and sentence integrity .", "entities": []}, {"text": "We improve the attention mechanism to impel the model to capture some future information on the format .", "entities": []}, {"text": "A pre - training and \ufb01ne - tuning framework is designed to further improve the generation quality .", "entities": []}, {"text": "Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates signi\ufb01cantly better results in terms of both automatic metrics and the human evaluation.1 1 Introduction Recent years have seen the tremendous progress in the area of natural language generation especially bene\ufb01ting by the neural network models such as Recurrent Neural Networks ( RNN ) or Convolutional Neural Networks ( CNN ) based sequence - tosequence ( seq2seq ) frameworks ( Bahdanau et al . , 1Code : http://github.com/lipiji/SongNet \u6a54\u0809\u078d\u05d9\u0b06\u036b\u3153\u316b\u0797\u0690\u041f\u6f9e\u07a9\u065d\u0bf0\u3a21\u08de\u0a18\u35d8\u036b\u07be\u0a4b\u0bce\u0579\u0ba7\u6f9e \u06de \u0797\u0a34\u0436\u07a6\u036b \u25b2 \u0460\u09e9\u5437 \u2f54 \u6f9e\u0ba9\u0a4a\u06e8\u4032\u4b26\u0481\u0638\u036b\u0551\u07c4\u0bda\u077b\u05f2\u6f9e", "entities": [[69, 70, "MethodName", "seq2seq"]]}, {"text": "Let me not to the marriage of true minds", "entities": []}, {"text": "Admit impediments , love is not love Which alters when it alteration finds Or bends with the remover to remove .", "entities": []}, {"text": "Lyrics SongCi SonnetFigure 1 : Examples of text with rigid formats .", "entities": []}, {"text": "In lyrics , the syllables of the lyric words must align with the tones of the notation .", "entities": []}, {"text": "In SongCi and Sonnet , there are strict rhyming schemes and the rhyming words are labeled in red color and italic font .", "entities": []}, {"text": "2014 ; Gehring et al . , 2017 ) , Transformer and its variants ( Vaswani et al . , 2017 ; Dai et al . , 2019 ) , pre - trained auto - regressive language models such as XLNet ( Yang et al . , 2019 ) and GPT2 ( Radford et al . , 2019 ) , etc .", "entities": [[10, 11, "MethodName", "Transformer"], [40, 41, "MethodName", "XLNet"]]}, {"text": "Performance has been improved signi\ufb01cantly in lots of tasks such as machine translation ( Bahdanau et al . , 2014 ; Vaswani et", "entities": [[11, 13, "TaskName", "machine translation"]]}, {"text": "al . , 2017 ) , dialogue systems ( Vinyals and Le , 2015 ; Shang et al . , 2015 ; Li , 2020 ) , text summarization ( Rush et al . , 2015 ; Li et al . , 2017 ; See et al . , 2017 ) , story telling ( Fan et al . , 2018 ; See et al . , 2019 ) ,", "entities": [[27, 29, "TaskName", "text summarization"]]}, {"text": "poetry writing ( Zhang and Lapata , 2014 ; Lau et al . , 2018 ; Liao et al . , 2019 ) , etc .", "entities": []}, {"text": "Generally , most of the above mentioned tasks can be regarded as free text generation , which means that no constraints on the format and structure , say the number of words and rhyming rules .", "entities": [[13, 15, "TaskName", "text generation"]]}, {"text": "Note that tasks of dialogue generation and story telling are almost in an open - ending generation style as long as the generated content is relevant with the conditional input text .", "entities": [[4, 6, "TaskName", "dialogue generation"]]}, {"text": "Although there are", "entities": []}, {"text": "743formats constraints on the poetry text , the proposed models just treat the formats as kind of latent information and let the model capture this feature implicitly during training ( Liao et al . , 2019 ) .", "entities": []}, {"text": "The model trained on the \ufb01ve - character quatrain corpus can not generate seven - character verses .", "entities": []}, {"text": "Moreover , it is impossible to trigger these models to generate satisfying results according to arbitrary new de\ufb01ned formats .", "entities": []}, {"text": "In practice we will confront some special text paradigms such as Lyrics ( assume the music score is given ) , Sonnet ( say Shakespeare \u2019s Sonnets ( Shakespeare , 2000 ) ) , SongCi ( a kind of Ci .", "entities": []}, {"text": "Ci is a type of lyric poetry in the tradition of Classical Chinese poetry.2 , SongCi is the Ci created during Song dynasty ) , etc . , and some examples are illustrated in Figure 1 .", "entities": []}, {"text": "The typical characteristics of these text can be categorized into three folds : ( 1 ) The assembling of text must comply fully with the prede\ufb01ned rigid formats .", "entities": []}, {"text": "Assume that the music score is composed , then the lyricist must \ufb01ll the lyric content strictly tally with the schemes lie in the notation .", "entities": []}, {"text": "Take partial of song \u201c Edelweiss \u201d as shown in the \ufb01rst row of Figure 1 as example , the syllables of the lyric words must align with the tones of the notation .", "entities": []}, {"text": "The second row of Figure 1 depicts the content of a SongCi created based on the CiPai of \u201c Bu Suan Zi \u201d .", "entities": []}, {"text": "Given the CiPai , the number of characters and the syntactical structure of the content are also de\ufb01ned ( e.g. , the number of characters of each clause : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 . ) .", "entities": []}, {"text": "( 2 ) The arrangement of the content must obey the de\ufb01ned rhyming schemes .", "entities": []}, {"text": "For example , all the \ufb01nal words ( words in red color and italic font ) of the SongCi content in Figure1 are rhyming ( the spelling of each word is : \u201c zhu \u201d , \u201c yu \u201d , \u201c du \u201d , and \u201c gu \u201d . ) .", "entities": []}, {"text": "The example in the third row of Figure 1 comes from Shakespeare \u2019s \u201c Sonnet 116 \u201d ( Shakespeare , 2000 ) , the \ufb01rst four sentences .", "entities": []}, {"text": "Usually , the rhyming schemes of Shakespeare \u2019s Sonnets is \u201c ABAB CDCD EFEF GG \u201d 3 .", "entities": []}, {"text": "In the example , the rhyming words in scheme \u201c ABAB \u201d are \u201c minds \u201d , \u201c love \u201d , \u201c \ufb01nds \u201d , and \u201c remove \u201d .", "entities": []}, {"text": "( 3 ) Even though the format is rigid , the sentence integrity must always be guaranteed .", "entities": []}, {"text": "Incomplete sentence such as \u201c love is not the \u201d is inappropriate .", "entities": []}, {"text": "To the best of our knowledge , text generation based on the prede\ufb01ned rigid formats constraints has not been well investigated yet .", "entities": [[7, 9, "TaskName", "text generation"]]}, {"text": "In this work , 2http://en.wikipedia.org/wiki/Ci ( poetry ) 3http://en.wikipedia.org/wiki/Shakespeare%27s sonnetswe propose a simple and elegant framework named SongNet to address this challenging problem .", "entities": [[17, 18, "MethodName", "SongNet"]]}, {"text": "The backbone of the framework is a Transformer - based auto - regressive language model .", "entities": [[7, 8, "MethodName", "Transformer"]]}, {"text": "Considering the three folds characteristics mentioned above , we introduce sets of tailor - designed indicating symbols to improve the modeling performance , especially for the robustness of the format , rhyme , as well as sentence integrity .", "entities": []}, {"text": "We improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity .", "entities": []}, {"text": "Inspired by BERT ( Devlin et al . , 2019 ) and GPT ( Radford et al . , 2018 , 2019 ) , a pretraining and \ufb01ne - tuning framework is designed to further improve the generation quality .", "entities": [[0, 1, "DatasetName", "Inspired"], [2, 3, "MethodName", "BERT"], [12, 13, "MethodName", "GPT"]]}, {"text": "To verify the performance of our framework , we collect two corpora , SongCi and Sonnet , in Chinese and English respectively .", "entities": []}, {"text": "Extensive experiments on the collected datasets demonstrate that our proposed framework can generate satisfying results in terms of both the tailor - designed automatic metrics including format accuracy , rhyming accuracy , sentence integrity , as well as the human evaluation results on relevance , \ufb02uency , and style .", "entities": [[27, 28, "MetricName", "accuracy"], [30, 31, "MetricName", "accuracy"]]}, {"text": "In summary , our contributions are as follows : \u000fWe propose to tackle a new challenging task : rigid formats controlled text generation .", "entities": [[21, 23, "TaskName", "text generation"]]}, {"text": "A pre - training and \ufb01ne - tuning framework named SongNet is designed to address the problem .", "entities": [[10, 11, "MethodName", "SongNet"]]}, {"text": "\u000fSets of symbols are tailor - designed to improve the modeling performance .", "entities": []}, {"text": "We improve the attention mechanism to impel the model to capture the future information to further enhance the sentence integrity .", "entities": []}, {"text": "\u000fTo verify the performance of our framework SongNet , we collect two corpora , SongCi and Sonnet , in Chinese and English respectively .", "entities": [[7, 8, "MethodName", "SongNet"]]}, {"text": "We design several automatic evaluation metrics and human evaluation metrics to conduct the performance evaluation .", "entities": []}, {"text": "\u000fExtensive experiments conducted on two collected corpora demonstrate that our proposed framework generates signi\ufb01cantly better results given arbitrary formats , including the cold - start formats or even the formats newly de\ufb01ned by ourselves .", "entities": []}, {"text": "2 Task De\ufb01nition", "entities": []}, {"text": "The task of rigid formats controlled text generation is de\ufb01ned as follows :", "entities": [[6, 8, "TaskName", "text generation"]]}, {"text": "744 love is not love , < /s > bends with remove < /s > < bos > InputToken EmbeddingsFormat & Rhyme EmbeddingsSegment", "entities": []}, {"text": "EmbeddingsGlobal Position Embeddings Intra Position Embeddings \u7016\u7016 .\u7016\u7016\u7016\u7016", "entities": []}, {"text": "\u06f3\u0b6a\u0b6d\u0b74\u0b63 \u06f3\u0b67\u0b71\u06f3\u0b6c\u0b6d\u0b72\u06f3\u0b6a\u0b6d\u0b74\u0b63", "entities": []}, {"text": "\u06f3\u01e1\u06f3\u0bb4\u0200\u0b71\u0bb5\u06f3\u0b60\u0b63\u0b6c\u0b62\u0b71", "entities": []}, {"text": "\u06f3\u0b75\u0b67\u0b72\u0b66 \u06f3 \u0b70 \u0b63\u0b6b \u06f3\u01e4\u06f3\u0bb4\u0200\u0b71\u0bb5 \u06f3\u0bb4\u0b60\u0b6d\u0b71\u0bb5\u06f3\u0bd6\u0c2c\u06f3\u0bd6\u0c2c\u06f3\u0bd6\u0c2c\u06f3\u0bd6\u0c2e\u06f3\u0bd6\u0c2d\u06f3\u0bd6\u0c2c\u06f3\u0bb4\u0200\u0b71\u0bb5\u06f3\u0bb4\u0200\u0b71\u0bb5\u06f3\u0bb4\u0200\u0b71\u0bb5 \u06f3\u0bd6\u0c2c\u06f3\u0bd6\u0c2e\u06f3\u0bd6\u0c2d\u06f3\u0bb4\u0200\u0b71\u0bb5\u06f3\u0bb4\u0200\u0b71\u0bb5\u06f3\u0bb4\u0200\u0b71\u0bb5 \u06f3\u0bb4\u0b63\u0b6d\u0b71\u0bb5\u06f3\u0bb4\u0b63\u0b6d\u0b71\u0bb5\u06f3\u0bb4\u0b63\u0b6d\u0b71\u0bb5 \u06f3\u0be3\u0c30\u06f3\u0be3\u0c2f\u06f3\u0be3\u0c2e\u06f3\u0be3\u0c2d\u06f3\u0be3\u0c2c \u06f3\u0be3\u0c32\u06f3\u0be3\u0c31\u06f3\u0be3\u0c2d\u06f3\u0be3\u0c2c\u06f3\u0be6\u0c2c\u06f3\u0be6\u0c2c\u06f3\u0be6\u0c2c\u06f3\u0be6\u0c2c\u06f3\u0be6\u0c2c\u06f3\u0be6\u0c2d\u06f3\u0be6\u0c2d\u06f3\u0be6\u0c2d\u06f3\u0be6\u0c2d\u06f3\u0bda\u0c2c\u06f3\u0bda\u0c2d\u06f3\u0bda\u0c2e\u06f3\u0bda\u0c2f\u06f3\u0bda\u0c30\u06f3\u0bda\u0c31\u06f3\u0bda\u0c32\u06f3\u0bda\u0c33\u06f3\u0bda\u0c2d\u0c2d\u06f3\u0bda\u0c2d\u0c2e\u06f3\u0bda\u0c2d\u0c2f\u06f3\u0bda\u0c2d\u0c30love is not love , < /s > bends with remove < /s >", "entities": []}, {"text": "< eos > Output \u7016 .", "entities": []}, {"text": "\u6fc1\u6fd5\u6fe7\u6fdf\u6fd9\u6fd8\u6f94\u6fc1\u6fe9\u6fe0\u6fe8\u6fdd\u6fa1\u6fbc\u6fd9\u6fd5\u6fd8\u6f94\u6fb5\u6fe8\u6fe8\u6fd9\u6fe2\u6fe8\u6fdd\u6fe3\u6fe2 \u6fbb\u6fe0\u6fe3\u6fd6\u6fd5\u6fe0\u6f94\u6fc1\u6fe9\u6fe0\u6fe8\u6fdd\u6fa1\u6fbc\u6fd9\u6fd5\u6fd8\u6f94\u6fb5\u6fe8\u6fe8\u6fd9\u6fe2\u6fe8\u6fdd\u6fe3\u6fe2Figure 2 : The framework of our proposed model .", "entities": []}, {"text": "Input : a rigid format C2C : C = fc0c1c2c3 ; c0c1c2c3c4c5 : g ( 1 ) whereCis the set of all possible formats .", "entities": []}, {"text": "Note that we can de\ufb01ne arbitrary new formats not restricted to the ones pre - de\ufb01ned in the corpus , thus jCj!1 .", "entities": []}, {"text": "Format token cidenotes a place - holder symbol of Cwhich need to be translated into a real word token .", "entities": []}, {"text": "Format Ccontains 10words plus two extra punctuation characters \u201c , \u201d and \u201c . \u201d", "entities": []}, {"text": "Output : a natural language sentence Y2Y which tally with the de\ufb01ned format C : Y = loveisnotlove ; bendswiththeremovertoremove : where the example sentences are extracted from the Shakespeare \u2019s Sonnets ( Shakespeare , 2000 ) .", "entities": []}, {"text": "From the resultYwe can observe that the count of words is 10 which is consistent with the format C. The punctuation characters \u201c , \u201d and \u201c . \u201d are also correct .", "entities": []}, {"text": "Thus , we claim that it is a 100 % format accuracy result .", "entities": [[11, 12, "MetricName", "accuracy"]]}, {"text": "Also , since the two clause sentences are complete , we can get a good sentence integrity score .", "entities": []}, {"text": "IfCis de\ufb01ned on the literary genres of SongCi or Sonnet which have rhyming constraints , the rhyming performance should be evaluated as well .", "entities": []}, {"text": "Recall thatCcan be arbitrary and \ufb02exible , thus we can rebuild a new format C0based on the generated result Yby masking partial content , say C0 = fc0c1c2love ; c 0c1c2c3c4remove : g , then we may obtain better results by re - generating based onC0 .", "entities": [[0, 1, "MetricName", "Recall"]]}, {"text": "We name this operation as polishing .", "entities": []}, {"text": "Finally , the target of this problem is to \ufb01nd a mapping function Gto conduct the rigid formats controlled text generation : Y = G(C ) ( 2)3 Framework Description 3.1 Overview As shown in Figure 2 , the backbone of our framework is a Transformer - based auto - regressive language model .", "entities": [[19, 21, "TaskName", "text generation"], [45, 46, "MethodName", "Transformer"]]}, {"text": "The input can be the whole token sequences of samples from SongCi or Sonnet .", "entities": []}, {"text": "We tailor - design several sets of indicating symbols to enhance the performance in terms of accuracy on format , rhyme , and sentence integrity .", "entities": [[16, 17, "MetricName", "accuracy"]]}, {"text": "Speci\ufb01cally , symbols C = fcigare introduced for format and rhyming modeling ; Intra - position symbols P = fpigare designed to represent the local positions of the tokens within each sentence aiming to improve the rhyming performance and the sentence integrity .", "entities": []}, {"text": "Segment symbols S = fsigare employed to identify the sentence border to further improve the sentence quality .", "entities": []}, {"text": "Attention mechanism is improved to impel the model to capture the future format information such as the sentence ending markers .", "entities": []}, {"text": "Similar to BERT ( Devlin et al . , 2019 ) and GPT ( Radford et al . , 2018 , 2019 ) , pre - training and \ufb01ne - tuning paradigm is utilized to boost the performance of the original models .", "entities": [[2, 3, "MethodName", "BERT"], [12, 13, "MethodName", "GPT"]]}, {"text": "3.2 Details We use two sentences ( as shown in Figure 1 ) \u201c love is not love , ... , bends with the remover to remove \u201d extracted from the Shakespeare \u2019s Sonnets ( Shakespeare , 2000 ) as examples to describe the details of our framework SongNet .", "entities": [[48, 49, "MethodName", "SongNet"]]}, {"text": "Since our basic model is a Transformer - based auto - regressive language model , during training , the input is \u201c hbosilove is not love , h = si ... , bends with the remover to remove.h = si \u201d , and the corresponding output is a left - shifting version of the input ( tokenized , and", "entities": [[6, 7, "MethodName", "Transformer"]]}, {"text": "we", "entities": []}, {"text": "745ignore \u201c ... \u201d for convenience and clarity ): love is not love ; h = si bends with the remover to remove : h = si heosi whereh = sidenotes the clause or sentence separator , andheosiis the ending marker of the whole sequence .", "entities": []}, {"text": "The target of our framework is to conduct the formats controlled text generation .", "entities": [[11, 13, "TaskName", "text generation"]]}, {"text": "Therefore , the indicating symbols for format and rhyme as well as the sentence integrity are designed based on the target output sequence .", "entities": []}, {"text": "Format and Rhyme Symbols : C = fc0;c0;c0;c2;c1;h = si c0;c0;c0;c0;c0;c2;c1;h = si;heosig(3 ) where we usefc0gto represent the general tokens ; fc1gdepict the punctuation characters ; fc2grepresent the rhyming tokens \u201c love \u201d and \u201c remove \u201d .", "entities": []}, {"text": "h = si andheosiare kept .", "entities": []}, {"text": "Intra - Position Symbols : P = fp4;p3;p2;p1;p0;h = si p6;p5;p4;p3;p2;p1;p0;h = si;heosig(4 ) fpigdenote the local positions of tokens within the same clause or sentence .", "entities": []}, {"text": "Note that we align the position symbol indices in a descending order .", "entities": []}, {"text": "The aim is to improve the sentence integrity by impelling the symbols capture the sentence dynamic information , precisely , the sense to end a sequence .", "entities": []}, {"text": "For example , fp0gusually denote punctuation characters , thus fp1gshould be the ending words of sentences .", "entities": []}, {"text": "Segment Symbols : S = fs0;s0;s0;s0;s0;h = si s1;s1;s1;s1;s1;s1;s1;h = si;heosig(5 ) wheresiis the symbol index for", "entities": []}, {"text": "sentence i.", "entities": []}, {"text": "The purpose is to enhance the interactions between different sentences in different positions by de\ufb01ning the sentence index features .", "entities": []}, {"text": "During training , all the symbols as well as the input tokens are fed into the transformer - based language model .", "entities": []}, {"text": "Contrast to Transformer ( Vaswani et al . , 2017 ) , BERT ( Devlin et al . , 2019 ) , and GPT2 ( Radford et al . , 2019 ) , we modify the traditional attention strategies slightly to \ufb01t our problem .", "entities": [[2, 3, "MethodName", "Transformer"], [12, 13, "MethodName", "BERT"]]}, {"text": "Speci\ufb01cally , for the input , we \ufb01rst obtain the representations by summing all the embeddings of the input tokens and symbols , as shown in the red solid box of Figure 2 : H0 t = Ewt+Ect+Ept+Est+Egt(6)where 0is the layer index and tis the state index .", "entities": []}, {"text": "E\u0003is the embedding vector for input \u0003.wt is the real token at position t.c , p , andsare three pre - de\ufb01ned symbols .", "entities": []}, {"text": "gis the global position index same as position symbols used in Transformer ( Vaswani et al . , 2017 ) .", "entities": [[11, 12, "MethodName", "Transformer"]]}, {"text": "Moreover , the state at time tneed to know some future information to grasp the global sequence dynamic information .", "entities": []}, {"text": "For example , the model may want to know if it should close the decoding progress by generating the last word and a punctuation character to end the sentence .", "entities": []}, {"text": "To represent the global dynamic information , we introduce another variable F0by only summing the pre - de\ufb01ned symbols as shown in the blue dash box of Figure 2 : F0 t = Ect+Ept+Est ( 7 ) After processing the input , two blocks of attention mechanisms are introduced to conduct the feature learning procedure .", "entities": []}, {"text": "The \ufb01rst block is a masking multi - head self - attention component , and the second block is named global multi - head attention .", "entities": [[21, 25, "MethodName", "multi - head attention"]]}, {"text": "Masking Multi - Head Self - Attention : C1 t = LN\u0000 FFN(C1 t ) + C1 t\u0001 C1 t = LN\u0000 SLF - ATT(Q0 t;K0 \u0014t;V0 \u0014t ) + H0 t\u0001 Q0 = H0WQ K0;V0 = H0WK;H0WV ( 8) where SLF - ATT(\u0001),LN(\u0001 ) , and FFN(\u0001 ) represent self - attention mechanism , layer normalization , and feed - forward network respectively .", "entities": [[55, 57, "MethodName", "layer normalization"]]}, {"text": "Note that we only use the states whose indices \u0014tas the attention context .", "entities": []}, {"text": "After obtaining C1 tfrom Equation ( 8) , we feed it into the second attention block to capture the global dynamic information from F0 .", "entities": []}, {"text": "Global Multi - Head Attention : H1 t = LN\u0000 FFN(H1 t ) + H1 t\u0001 H1 t = LN\u0000 GLOBAL -ATT(Q1", "entities": [[1, 5, "MethodName", "Multi - Head Attention"]]}, {"text": "t;K1;V1 )", "entities": []}, {"text": "+ C1 t\u0001 Q1 = C1WQ K1;V1 = F0WK;F0WV ( 9 ) We can observe that all the context information fromF0are considered .", "entities": []}, {"text": "This is the reason why we name it as \u201c global attention \u201d and why the input real token information Ewtis NOT considered .", "entities": []}, {"text": "Then", "entities": []}, {"text": "746the calculation of the uni\ufb01ed \ufb01rst model layer is \ufb01nished .", "entities": []}, {"text": "We can iteratively apply these two attention blocks on the whole Lmodel layers until obtain the \ufb01nal representations HL .", "entities": []}, {"text": "Note that His renewed layerly , however the global variable F0is \ufb01xed .", "entities": []}, {"text": "Finally , the training objective is to minimize the negative log - likelihood over the whole sequence : Lnll=\u0000nX t=1logP(ytjy < t ) ( 10 ) 3.3 Pre - training and Fine - tuning Although our framework can be trained purely on the training dataset of the target corpus , usually the scale of the corpus is limited .", "entities": [[10, 13, "MetricName", "log - likelihood"]]}, {"text": "For example , there are only about 150 samples in the corpus of Shakespeare \u2019s Sonnets ( Shakespeare , 2000 ) .", "entities": []}, {"text": "Therefore , we also design a pre - training and \ufb01ne - tuning framework to further improve the generation quality .", "entities": []}, {"text": "Recall that in the task de\ufb01nition in Section 2 , we claim that our model owns the ability of re\ufb01ning and polishing .", "entities": [[0, 1, "MetricName", "Recall"]]}, {"text": "To achieve this goal , we adjust the masking strategy used in BERT ( Devlin et al . , 2019 ) to our framework according to our de\ufb01nitions .", "entities": [[12, 13, "MethodName", "BERT"]]}, {"text": "Speci\ufb01cally , we randomly ( say 20 % ) select partial of the original content and keep them not changed when building the format symbols", "entities": []}, {"text": "C.", "entities": []}, {"text": "For example , we will get a new symbol set C0for", "entities": []}, {"text": "the example sentences : C0 = fc0 ; c0 ; c0 ; love ; c 1;h = si bends ; c 0 ; c0 ; c0 ; c0 ; remove ; c 1;h = si;heosig where \u201c love \u201d , \u201c bends \u201d and \u201c remove \u201d are kept in the formatC0 .", "entities": [[21, 22, "DatasetName", "0"]]}, {"text": "After the pre - training stage , we can conduct the \ufb01ne - tuning procedure directly on the target corpus without adjusting any model structure .", "entities": []}, {"text": "3.4 Generation We can assign any format and rhyming symbols C to control the generation .", "entities": []}, {"text": "Given C , we will obtain PandSautomatically .", "entities": []}, {"text": "And the model can conduct generation starting from the special token hbosiiteratively until meet the ending marker heosi .", "entities": []}, {"text": "Both beam - search algorithm ( Koehn , 2004 ) and truncated top - k sampling ( Fan et al . , 2018 ; Radford et", "entities": []}, {"text": "al . , 2019 ) method are utilized to conduct the decoding.4 Experimental Setup 4.1 Settings The parameter size of our model are \ufb01xed in both the pre - training stage and the \ufb01ne - tuning stage .", "entities": []}, {"text": "The number of layers L= 12 , and hidden size is 768 .", "entities": [[1, 4, "HyperparameterName", "number of layers"]]}, {"text": "We employ 12 heads in both the masking multihead self - attention block and the global attention block .", "entities": []}, {"text": "Adam ( Kingma and Ba , 2014 ) optimization method with Noam learning - rate decay strategy and 10,000 warmup steps is employed to conduct the pre - training .", "entities": [[0, 1, "MethodName", "Adam"]]}, {"text": "4.2 Datasets We conduct all the experiments on two collected corpus with different literary genres : SongCi and Sonnet , in Chinese and English respectively .", "entities": []}, {"text": "The statistic number are shown in Table 3 .", "entities": []}, {"text": "We can see that Sonnet is in small size since we only utilize the samples from the Shakespeare \u2019s Sonnets ( Shakespeare , 2000 ) .", "entities": []}, {"text": "Since SongCi and Sonnet are in different languages , thus we conduct the pre - training procedure on two large scale corpus in the corresponding languages respectively .", "entities": []}, {"text": "For Chinese , we collect Chinese Wikipedia ( 1700 M Characters ) and a merged Chinese News ( 9200 M Characters ) corpus from the Internet .", "entities": []}, {"text": "We did not conduct the word segmenting operations on the Chinese datasets , which means that we just use the characters to build the vocabulary , and the size is 27681 .", "entities": []}, {"text": "For English , same as BERT , we employ English Wikipedia ( 2400 M words ) and BooksCorpus ( 980 M words )", "entities": [[5, 6, "MethodName", "BERT"]]}, {"text": "( Zhu et al . , 2015 ) to conduct the pre - training .", "entities": []}, {"text": "We did not use BPE operation ( Sennrich et al . , 2015 ) on this corpus considering the format controlling purpose .", "entities": [[4, 5, "MethodName", "BPE"]]}, {"text": "We keep the most frequent 50,000 words to build the vocabulary .", "entities": []}, {"text": "4.3 Evaluation Metrics Besides PPL andDistinct ( Li et al . , 2016 ) , we also tailor - design several metrics for our task to conduct the evaluation for format , rhyme , and sentence integrity .", "entities": []}, {"text": "Format Assume that there are msentences de\ufb01ned in the format C = fCs 1;Cs 2;:::;Cs mg , and the generated results YcontainsnsentencesY= fYs 1;Ys 2;:::;Ys ng .", "entities": []}, {"text": "Without loss of generality , we alignCandYfrom the beginning , and calculate the format quality according to the following rules : ( 1 ) the length difference jjCs ij\u0000jYs ijj\u0014\u000e ; ( 2 ) the punctuation characters must be same .", "entities": [[1, 2, "MetricName", "loss"]]}, {"text": "For SongCi , we let\u000e= 0 and rule ( 2 ) must be conforming .", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "747ModelPPL # Diversity ( Distinct ) \" VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 S2S 19.61 20.43 75.35 2.48 98.35 36.23 GPT2 148.11 104.99 - - - GPT2 w/ Fine - tuning 18.25 17.00 73.87 2.57 96.07 33.92 SongNet ( only Pre - training ) 24.41 16.23 74.84 4.59 95.09 54.98 SongNet ( only Fine - tuning ) 12.75 14.73 75.96 2.69 97.59 37.26 SongNet 11.56 12.64 75.04 2.66 97.29 36.78 ModelFormat \" Rhyme\"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 S2S 44.32 38.16 53.80 52.27 8.30\u00062.06 GPT2 w/ Fine - tuning 35.70 35.20 53.48 52.50 45.92\u000620.12 SongNet ( only Pre - training ) 29.12 29.46 53.77 53.13 30.98\u000614.06", "entities": [[47, 48, "MethodName", "SongNet"], [60, 61, "MethodName", "SongNet"], [73, 74, "MethodName", "SongNet"], [84, 85, "MetricName", "F1"], [88, 89, "MetricName", "F1"], [91, 92, "MetricName", "F1"], [95, 96, "MetricName", "F1"], [112, 113, "MethodName", "SongNet"]]}, {"text": "SongNet ( only Fine - tuning ) 99.81 99.83 79.23 78.63 2.14\u00060.10", "entities": [[0, 1, "MethodName", "SongNet"]]}, {"text": "SongNet 99.88 99.89 73.21 72.59 1.77\u00060.16 Table 1 : Automatic evaluation results on SongCi ModelPPL # Diversity ( Distinct ) \" VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 GPT2 w/ Fine - tuning 31.47 31.03 73.87 2.57 96.07 33.92 SongNet ( only Pre - training ) 28.56 28.07 49.92 25.14 85.35 65.70 SongNet ( only Fine - tuning ) 34.62 34.53 42.31 4.96 90.76 47.26 SongNet 27.46 27.63 43.01 10.43 80.06 56.14 ModelFormat \" Rhyme\"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 GPT2 w/ Fine - tuning 2.03 1.91 5.20 6.24 15.77\u00063.63", "entities": [[0, 1, "MethodName", "SongNet"], [48, 49, "MethodName", "SongNet"], [61, 62, "MethodName", "SongNet"], [74, 75, "MethodName", "SongNet"], [85, 86, "MetricName", "F1"], [89, 90, "MetricName", "F1"], [92, 93, "MetricName", "F1"], [96, 97, "MetricName", "F1"]]}, {"text": "SongNet ( only Pre - training ) 99.99 99.99 3.93 4.01 15.28\u00062.04 SongNet ( only Fine - tuning ) 99.25 99.99 7.50 7.41 18.86\u00062.59 SongNet 98.73 98.73 11.46 11.41 11.86\u00063.01 Table 2 : Automatic evaluation results on Sonnet Corpus # Train # Dev # Test # V ocab SongCi 19,244 847 962 5310 Sonnet 100 27 27 2801 Table 3 : Statistics of the datasets SongCi and Sonnet .", "entities": [[0, 1, "MethodName", "SongNet"], [12, 13, "MethodName", "SongNet"], [24, 25, "MethodName", "SongNet"]]}, {"text": "For Sonnet , we relax the condition where we let \u000e= 1 and ignore rule ( 2 ) .", "entities": []}, {"text": "Assume that the number of format - correct sentences is n0 , then we can obtain Precision p = n0 = n , Recallr = n0 = m , and F1 - measure .", "entities": [[16, 17, "MetricName", "Precision"], [30, 31, "MetricName", "F1"]]}, {"text": "We report both the Macro - F1 and Micro - F1 in the results tables .", "entities": [[4, 7, "MetricName", "Macro - F1"], [8, 11, "MetricName", "Micro - F1"]]}, {"text": "Rhyme For SongCi , usually , there is only one group of rhyming words in one sample .", "entities": []}, {"text": "As the example shown in Table 1 , the pronunciation of the red rhyming words are \u201c zhu \u201d , \u201c y \u00a8u \u201d , \u201c du \u201d , and \u201c gu \u201d respectively , and the rhyming phoneme is \u201c u \u201d .", "entities": []}, {"text": "For the generated samples , we \ufb01rst use the toolpinyin4to get the pronunciations ( PinYin ) of the words in the rhyming positions , and then conduct the evaluation .", "entities": []}, {"text": "For Shakespeare \u2019s Sonnets corpus , the rhyming rule is clear \u201c ABAB CDCD EFEF GG \u201d and there are 7 groups of rhyming tokens .", "entities": []}, {"text": "For the generated samples , we employ the CMU Pronouncing Dictionary5(Speech@CMU , 1998 ) to obtain the phonemes of the words in the rhyming positions .", "entities": []}, {"text": "For example , the phonemes for word \u201c asleep \u201d and \u201c steep \u201d are [ \u2019 AH0 \u2019 , \u2019S \u2019 , \u2019 L \u2019 , \u2019 IY1 \u2019 , \u2019 P \u2019 ] and [ \u2019S \u2019 , \u2019 T \u2019 , \u2019 IY1 \u2019 , \u2019 P \u2019 ] respectively .", "entities": []}, {"text": "And then we can conduct the evaluation by counting the overlapping units from both the original words and the extracted phonemes group by group .", "entities": []}, {"text": "We report the Macro - F1 and Micro - F1 numbers in the results tables as well .", "entities": [[3, 6, "MetricName", "Macro - F1"], [7, 10, "MetricName", "Micro - F1"]]}, {"text": "Integrity Since the format in our task is strict and 4http://github.com/mozillazg/python-pinyin 5http://www.speech.cs.cmu.edu/cgi-bin/cmudict", "entities": []}, {"text": "748ModelPPL # Diversity ( Distinct ) \" VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 SongNet 12.75 14.73 75.96 2.69 97.59 37.26 SongNet - GRU 16.52 20.49 74.73 1.77 98.30 28.98 SongNet w/o C 13.51 15.38 75.42 2.48 97.36 34.85 SongNet w/o P 14.16 17.16 73.73 2.56 97.52 34.82", "entities": [[23, 24, "MethodName", "SongNet"], [30, 31, "MethodName", "SongNet"], [32, 33, "MethodName", "GRU"], [39, 40, "MethodName", "SongNet"], [48, 49, "MethodName", "SongNet"]]}, {"text": "SongNet w/ inverse - P 13.40 15.13 74.95 2.54 97.76 35.65 SongNet w/o S 13.23 15.44 75.38 2.74 97.31 37.50 ModelFormat \" Rhyme\"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 SongNet 99.81 99.83 79.23 78.63 2.14\u00060.10", "entities": [[0, 1, "MethodName", "SongNet"], [11, 12, "MethodName", "SongNet"], [24, 25, "MetricName", "F1"], [28, 29, "MetricName", "F1"], [31, 32, "MetricName", "F1"], [35, 36, "MetricName", "F1"], [36, 37, "MethodName", "SongNet"]]}, {"text": "SongNet - GRU 98.99 98.99 52.13 50.93 3.28\u00061.67 SongNet w/o C 84.73 85.39 78.59 78.24 1.77\u00060.53 SongNet w/o P 99.61 99.59 67.85 67.29 3.33\u00060.18", "entities": [[0, 1, "MethodName", "SongNet"], [2, 3, "MethodName", "GRU"], [8, 9, "MethodName", "SongNet"], [16, 17, "MethodName", "SongNet"]]}, {"text": "SongNet w/ inverse - P 99.68 99.69 65.89 65.43 2.24\u00060.21 SongNet w/o S 99.84 99.86 80.43 80.13 1.99\u00060.10 Table 4 : Ablation analysis on SongCi rigid", "entities": [[0, 1, "MethodName", "SongNet"], [10, 11, "MethodName", "SongNet"]]}, {"text": ", thus the number of words to be predicted is also pre - de\ufb01ned .", "entities": []}, {"text": "Our model must organize the language using the limited positions , thus sentence integrity may become a serious issue .", "entities": []}, {"text": "For example , the integrity of \u201c love is not love .", "entities": []}, {"text": "h = si \u201d is much better than\u201clove is not the .", "entities": []}, {"text": "h = si \u201d .", "entities": []}, {"text": "To conduct the evaluation of sentence integrity , we design a straightforward method by calculating the prediction probability of the punctuation characters beforeh = sigiven the pre\ufb01x tokens : Integrity = 2\u00001 jYjjYjP i=1log(P(yi puncjyi 0;yi 1;:::;yi < punc ) )", "entities": []}, {"text": "( 11 ) whereYis the generated sequence of sentences .", "entities": []}, {"text": "Smaller integrity metric value indicates higher sentence quality .", "entities": []}, {"text": "To achieve this goal , we conduct pre - trainings for two GPT2 ( Radford et al . , 2019 ) models on the large scale Chinese corpus and English corpus respectively .", "entities": []}, {"text": "Then we utilize the GPT2 models to conduct the evaluation for sentence integrity .", "entities": []}, {"text": "Human Evaluations For SongCi , we sampled 50 samples for 25 CiPais .", "entities": []}, {"text": "For Sonnet , the whole 27 samples in the test set are selected for human evaluation .", "entities": []}, {"text": "We recruit three helpers to score the Relevance , Fluency , and Style .", "entities": []}, {"text": "The rating criteria are as follows : Relevance : +2 : all the sentences are relevant to the same topic ; +1 : partial sentences are relevant ; 0 : not relevant at all .", "entities": [[28, 29, "DatasetName", "0"]]}, {"text": "Fluency : +2 : \ufb02uent;+1 : readable but with some grammar mistakes ; 0 : unreadable .", "entities": [[13, 14, "DatasetName", "0"]]}, {"text": "Style : +2 : match with SongCi orSonnet genres ; +1 : partially match ; 0 : mismatch .", "entities": [[15, 16, "DatasetName", "0"]]}, {"text": "4.4 Comparison Methods S2SSequence - to - sequence framework with attention mechanism ( Bahdanau et al . , 2014 ) .", "entities": []}, {"text": "We regard the format and rhyme symbols Cas the input sequence , and the target as the output sequence .", "entities": []}, {"text": "GPT2", "entities": []}, {"text": "We \ufb01ne - tune the GPT2 models ( the pretraining versions are used for sentence integrity evaluation ) on SongCi and Sonnet respectively .", "entities": []}, {"text": "SongNet Out proposed framework with both the per - training and \ufb01ne - tuning stages .", "entities": [[0, 1, "MethodName", "SongNet"]]}, {"text": "We also conduct ablation analysis to verify the performance of the de\ufb01ned symbols as well as the variants of model structures .", "entities": []}, {"text": "\u000fSongNet ( only pre - tuning )", "entities": []}, {"text": "Without the \ufb01netuning stage .", "entities": []}, {"text": "\u000fSongNet ( only \ufb01ne - tuning )", "entities": []}, {"text": "Without the pretraining stage .", "entities": []}, {"text": "\u000fSongNet - GRU Employ GRU ( Cho et al . , 2014 ) to replace Transformer as the core structure .", "entities": [[2, 3, "MethodName", "GRU"], [4, 5, "MethodName", "GRU"], [15, 16, "MethodName", "Transformer"]]}, {"text": "\u000fSongNet w/o C Remove the format and rhyme symbols C. \u000fSongNet w/o P Remove the intra - position symbolsP. \u000fSongNet w/o S Remove the sentence segment symbolsS. \u000fSongNet", "entities": []}, {"text": "w/ inverse - P Arrange the intraposition indices in ascending order instead of the descending order .", "entities": []}, {"text": "749 Figure 3 : Parameter tuning of kon the metrics of Rhyme , Integrity , and Micro - Dist-2 .", "entities": []}, {"text": "Model Cases of Generated Results SongNet - SongCi CiPai : Zhe Gu Tian , Format : 7 . 7 . 7 , 7 . 3 , 3 . 7 . 7 , 7 .", "entities": [[5, 6, "MethodName", "SongNet"]]}, {"text": "\u2256\u369c\u3a31\u4733\u3524\u2ad1\u3c44(qian)\u023c\u1d1b\u67cd\u1cff\u660d\u3524\u41b8\u3595(nuan)\u023c\u3c76\u37df\u65f5\u1d70\u3596\u6898\u3a8a(can)\u6f13\u6631\u6796\u3629\u3c87\u4da1\u3be9\u3de0(man)\u023c\u3524\u1d0c\u4aa0(guan)\u6f13\u1db9\u1e54\u5edb(yuan)\u023c\u3b5e \u2833 \u34e6 \u34e4\u3d04\u3da9\u1e33(ban)\u023c\u3a31\u20ec\u387b\u1d09\u346f\u574b\u1d65\u6f13\u2273\u1d39\u37a5\u6a41\u34df\u58c4\u1e33(ban)\u023c CiPai : Bu Suan Zi , Format : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 .", "entities": []}, {"text": "\u34af\u3607 \u3201 \u2d17\u34cb\u6f13\u3596\u5248\u55e8\u20c3\u3859(chu)\u023c \u281b \u2249\u63f5\u3e61\u2240\u1d8b\u6510\u6f13\u443a\u2d54\u3f6e\u51b0 \u230f (tu)\u023c\u1e54 \u2803 \u4a1a\u27ef\u3a8a\u6f13\u3552\u4996\u67cd\u65e7(yu)\u023c\u41eb\u5ab7\u2ad1\u3784\u1e33 \u2b0e \u6a1e\u6f13\u6898 \u2627 \u48ca\u2242\u36f0(zhu)\u023c", "entities": []}, {"text": "CiPai : Self - Defined , Format : 3 , 3 , 5 . 3 , 3 , 5 . 7 , 7 . \u4edf \u2ba8 \u1d2c\u6f13\u3c40\u3b33 \u2815 \u6f13\u212a\u3608 \u2b0e \u27f5 \u2828 (tian)\u023c\u50e9\u661b\u3d04\u6f13\u41eb\u3496\u51b2\u6f13\u5b00\u3461\u2d75\u67dd\u1dd8(xian)\u023c \u281b \u1d44\u20c8\u441e\u1cff\u35f1 \u3000 \u6f13\u3607 \u2881 \u51b0\u2e70\u1e3b\u51b0 \u2605 (yuan)\u023c CiPai : Self - Defined , Format : 9 . 9 . 9 . 9 .", "entities": []}, {"text": "\u65e7\u3c11\u6dc3\u3bc8\u4bbb\u4bbb \u4dc5 \u1e5b\u2ad1(han)\u023c\u5c89\u3b33\u587e\u3664\u34f5\u5181\u50e9\u3d04\u64f1(xian)\u023c\u3a4b\u4a10\u1cff\u366e\u647e\u2430\u6088\u6091\u64f3(jian)\u023c\u3524\u22ba\u1d0c \u2729 \u2afa\u37a5 \u4dd4 \u510c \u2b70 (shan)\u023c SongNet - Sonnet how do you hold such a thing like this , \\ when my eyes are so not black ?", "entities": [[10, 11, "MethodName", "SongNet"]]}, {"text": "\\", "entities": []}, {"text": "but how can i show myself , so strange , \\ that all this black is white ?", "entities": []}, {"text": "where am i to hide this from my eyes , \\ from this white mine eyes   all fals , \\ where is the good fortune , in me , \\ that hath no exc use , no excuse ?", "entities": []}, {"text": "what is that which can mask the true love \\ and for whom is this   true love more ?", "entities": []}, {"text": "\\ the one , which shall save the poor my eye , \\ from the false truth of my judgment ?", "entities": []}, {"text": "what lies , for when you are not that , \\ no one in this and that   can see me lies !", "entities": []}, {"text": "Table 5 : Cases of the generated results for SongCi and Sonnet respectively .", "entities": []}, {"text": "For SongCi , the number in Format ( e.g. , 3,5,7 ) denotes the number of tokens in one sentence .", "entities": []}, {"text": "The rhyming words are labeled in red color and italic font following is the Pinyin .", "entities": []}, {"text": "( Since cases are provided to con\ufb01rm the format consistency , thus we did not conduct translation for the Chinese samples .", "entities": []}, {"text": "Translation for Chinese poetry is also a challenging task . )", "entities": [[0, 1, "TaskName", "Translation"]]}, {"text": "Model Cases of Generated Results Given the Formats with Partial Content SongNet - SongCi CiPai : Bu Suan Zi , Format : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 .", "entities": [[11, 12, "MethodName", "SongNet"]]}, {"text": "Format C \u6f21", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ \u212f\u023c", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u1ece\u023c _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_ \u31a4\u023c _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u4a10\u023c ( 1)\u67cd\u3595\u52b9\u27ef\u51e5\u6f13\u22c7\u352e\u2d73\u34f5 \u212f\u023c\u647e\u4130\u36f2\u5171\u1d08 \u2105 \u60cb\u6f13 \u2819 \u2b10 \u1d39\u3524 \u1ece\u023c\u2070 \u2b10 \u2d73\u34f5\u5181\u6f13\u2fee \u2e96 \u51b0\u34f5 \u31a4\u023c\u1d88\u1e3b\u6073 \u2e83 \u2064\u2dda\u3664\u6f13\u3a64\u3a64\u658e\u3524 \u4a10\u023c ( 2)\u3524\u3664\u3524\u22c7\u22ba\u6f13\u51b0\u2e70\u20df\u3be1 \u212f\u023c\u64e7 \u2815 \u4dfe \u3667\u36f2\u5326\u3c11\u6f13\u3da9\u3764\u1db9\u1db9 \u1ece\u023c\u64e7 \u2815 \u1d1b\u67cd\u696b\u6f13\u1e3b\u34e6\u34f5\u6898 \u31a4\u023c\u1e45 \u2f29 \u3742\u364d\u3559\u34f5\u4e9d\u6f13\u20b6\u533c\u34df\u1db9 \u4a10\u023c Format C \u6f21_\u65e7 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ \u212f\u023c", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u20af \u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u1ece\u023c _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ \u3524\u6f13 _", "entities": []}, {"text": "_ \u3524_\u31a4\u023c", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "\u2b70 \u51b0 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "\u6f13 _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ \u4a10\u023c ( 1)\u3524\u65e7\u47a6\u5edd\u5324\u6f13\u36f2\u3596\u64e7\u2cf6 \u212f\u023c\u2aaa\u3abe\u3a64\u5e86\u5d0e\u2ad1 \u20af \u6f13\u457d\u2999\u441e\u3524 \u1ece\u023c\u3a62\u34e4\u3fd7\u3573 \u3524\u6f13\u51b0\u65fd\u3524\u67cd\u31a4\u023c\u1cff\u3fb8 \u2b70 \u51b0\u6088\u463b\u350d\u6f13\u2249\u1f19\u6510\u2d71 \u4a10\u023c ( 2)\u65e9\u65e7\u2e03\u5e7a\u3595\u6f13\u34af\u3ca7 \u4dfe \u3be1 \u212f\u023c\u387b\u1d09\u2af8\u6661\u3d7e\u4edf \u20af \u6f13\u1cff \u281b \u67cd\u51b0 \u1ece\u023c\u3552\u34e4\u3fd7\u647e \u3524\u6f13\u4660\u5c76\u3524\u2ab4\u31a4\u023c\u3694\u4453 \u2b70 \u51b0\u533c\u22f5\u27ef\u6f13\u1d0c\u352e\u37a5\u6a41", "entities": []}, {"text": "\u4a10\u023c SongNet - Sonnet _ _", "entities": [[1, 2, "MethodName", "SongNet"]]}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "with _ hearts , _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "lacking _", "entities": []}, {"text": "_ dead ; _ _", "entities": []}, {"text": "_ love _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ parts , and _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ buried .", "entities": []}, {"text": "_ many _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ tear , hath _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "_ eye , _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ now appear , _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ thee lie !", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ buried _", "entities": []}, {"text": "_ live , _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_ of _ _", "entities": []}, {"text": "gone , _ _", "entities": []}, {"text": "_ parts _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ give , _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "_", "entities": []}, {"text": "thine alone : _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ view _ thee , _ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_ _", "entities": []}, {"text": "_", "entities": []}, {"text": "all _ _", "entities": []}, {"text": "_", "entities": []}, {"text": "me .though all thy love with thy hearts , thou still are lacking of my dead ;   if thy love love is lost to your love and parts ,   and yet mine own heart can be buried .", "entities": []}, {"text": "so many are ill or in tear , hath not this time that we will make their eye , for that which lies not well hath now appear , no longer nor the world that holds thee lie !", "entities": []}, {"text": "for if it would be buried in my live ,   or by the earth ofmine was gone ,   then my own parts as my body and mine give , may not be so far beyond thine alone : so far   as thee and this world view find thee , then mine life be far enough from allthee and no me .", "entities": []}, {"text": "Table 6 : Cases of the generated results given the formats with partial pre - de\ufb01ned content .", "entities": []}, {"text": "Format token \u201c \u201d needs to be translated to real word token .", "entities": []}, {"text": "5 Results and Discussions 5.1 Results Please note that we mainly employ top- ksampling method ( Fan et al . , 2018 ; Radford et al . , 2019 ) to conduct the generation , and we let k= 32 here .", "entities": []}, {"text": "The parameter tuning of kis described in Section 5.3 .", "entities": []}, {"text": "Table 1 and Table 2 depict the experimental results of SongNet as well as the baseline methods S2S and GPT2 on corpus SongCi and Sonnet respectively .", "entities": [[10, 11, "MethodName", "SongNet"]]}, {"text": "It is obvious that our pre - training and \ufb01ne - tuning framework SongNet obtain the best per - formance on most of the automatic metrics .", "entities": [[13, 14, "MethodName", "SongNet"]]}, {"text": "Especially on the metric of Format accuracy , SongNet can even obtain a 98%+ value which means that our framework can conduct the generation rigidly matching with the pre - de\ufb01ned formats .", "entities": [[6, 7, "MetricName", "accuracy"], [8, 9, "MethodName", "SongNet"]]}, {"text": "On the metric of PPL , Rhyme accuracy , and sentence integrity , SongNet also performs signi\ufb01cantly better in a large gap than the baseline methods such as S2S and GPT2 as well as the model variants only with the pre - training or \ufb01ne - tuning stage .", "entities": [[7, 8, "MetricName", "accuracy"], [13, 14, "MethodName", "SongNet"]]}, {"text": "Another observation is that some of the results on corpus Sonnet are not as good as the results", "entities": []}, {"text": "750Model Relevance Fluency Style SongNet - SongCi 1.36 1.45 2.00 SongNet - Sonnet 0.58 0.42 0.83 Table 7 : Human evaluation results .", "entities": [[4, 5, "MethodName", "SongNet"], [10, 11, "MethodName", "SongNet"]]}, {"text": "on SongCi .", "entities": []}, {"text": "The main reason is that Sonnet only contains 100 samples in the training set as shown in Table 3 .", "entities": []}, {"text": "Therefore , the model can not capture suf\ufb01cient useful features especially for the rhyming issue .", "entities": []}, {"text": "5.2 Ablation Analysis We conduct ablation study on corpus SongCi and the experimental results are depicted in Table 4 .", "entities": []}, {"text": "It should note that all the models are purely trained on SongCi corpus without any pre - training stages .", "entities": []}, {"text": "From the results we can conclude that the introduced symbols C , P , andSindeed play crucial roles in improving the overall performance especially on the metrics of format , rhyme , and sentence integrity .", "entities": []}, {"text": "Even though some of the components can not improve the performance simultaneously on all the metrics , the combination of them can obtain the best performance .", "entities": []}, {"text": "5.3 Parameter Tuning Since we employ top- ksampling as our main decoding strategy , thus we design several experiments to conduct the parameter tuning on k.", "entities": []}, {"text": "We let k to be 1 , 5 , 10 , 20 , 50 , 500 respectively .", "entities": []}, {"text": "We also provide the beam - search ( beam=5 ) results for comparing and reference .", "entities": []}, {"text": "The parameter tuning results are depicted in Figure 3 .", "entities": []}, {"text": "From the results we can observe that large kcan increase the diversity of the results signi\ufb01cantly .", "entities": []}, {"text": "But the Rhyme accuracy and the sentence integrity will drop simultaneously .", "entities": [[3, 4, "MetricName", "accuracy"]]}, {"text": "Therefore , in the experiments we let k= 32 to obtain a trade - off between the diversity and the general quality .", "entities": []}, {"text": "5.4 Human Evaluation For human evaluation , we just conduct the judging on the results generated by our \ufb01nal model SongNet .", "entities": [[20, 21, "MethodName", "SongNet"]]}, {"text": "From the result we can observe that the results on corpus SongCi is much better than the ones on corpus Sonnet , which is because the corpus scale is different .", "entities": []}, {"text": "And the the small scale also lead to dramatically dropping on all the metrics.5.5 Case Analysis Table 5 depicts several generated cases for SongCi and Sonnet respectively .", "entities": []}, {"text": "For SongCi , the formats ( CiPai ) are all cold - start samples which are not in the training set or even newly de\ufb01ned .", "entities": []}, {"text": "Our model can still generate high quality results on the aspects offormat , rhyme as well as integrity .", "entities": []}, {"text": "However , for corpus Sonnet , even though the model can generate 14 lines text , the quality is not as good as SongCi due to the insuf\ufb01cient training - set ( only 100 samples ) .", "entities": []}, {"text": "We will address this interesting and challenging few - shot issue in the future .", "entities": []}, {"text": "In addition , we mentioned that our model has the ability of re\ufb01ning and polishing given the format Cwhich contains some \ufb01xed text information .", "entities": []}, {"text": "The examples of the generated results under this setting are shown in Table 6 , which show that our model SongNet can generate satisfying results especially on SongCi .", "entities": [[20, 21, "MethodName", "SongNet"]]}, {"text": "6 Conclusion We propose to tackle a challenging task called rigid formats controlled text generation .", "entities": [[13, 15, "TaskName", "text generation"]]}, {"text": "A pre - training and \ufb01ne - tuning framework SongNet is designed to address the problem .", "entities": [[9, 10, "MethodName", "SongNet"]]}, {"text": "Sets of symbols are tailordesigned to improve the modeling performance for format , rhyme , and sentence integrity .", "entities": []}, {"text": "Extensive experiments conducted on two collected corpora demonstrate that our framework generates significantly better results in terms of both automatic metrics and human evaluations given arbitrary cold start formats .", "entities": []}, {"text": "References Dzmitry Bahdanau , Kyunghyun Cho , and Yoshua Bengio .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Neural machine translation by jointly learning to align and translate .", "entities": [[1, 3, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1409.0473 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Kyunghyun Cho , Bart van Merrienboer , Caglar Gulcehre , Dzmitry Bahdanau , Fethi Bougares , Holger Schwenk , and Yoshua Bengio .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Learning phrase representations using rnn encoder \u2013 decoder for statistical machine translation .", "entities": [[10, 12, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1724 \u2013 1734 .", "entities": []}, {"text": "Zihang Dai , Zhilin Yang , Yiming Yang , William W Cohen , Jaime Carbonell , Quoc V Le , and Ruslan Salakhutdinov .", "entities": [[21, 22, "DatasetName", "Ruslan"]]}, {"text": "2019 .", "entities": []}, {"text": "Transformer - xl : Attentive language models beyond a \ufb01xed - length context .", "entities": [[0, 3, "MethodName", "Transformer - xl"]]}, {"text": "arXiv preprint arXiv:1901.02860 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "751Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 .", "entities": []}, {"text": "Angela Fan , Mike Lewis , and Yann Dauphin .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Hierarchical neural story generation .", "entities": [[2, 4, "TaskName", "story generation"]]}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 889\u2013898 .", "entities": []}, {"text": "Jonas Gehring , Michael Auli , David Grangier , Denis Yarats , and Yann N Dauphin . 2017 .", "entities": []}, {"text": "Convolutional sequence to sequence learning .", "entities": [[1, 4, "MethodName", "sequence to sequence"]]}, {"text": "In Proceedings of the 34th International Conference on Machine Learning - Volume 70 , pages 1243\u20131252 .", "entities": []}, {"text": "JMLR .", "entities": []}, {"text": "org .", "entities": []}, {"text": "Diederik P Kingma and Jimmy Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "arXiv preprint arXiv:1412.6980 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Philipp Koehn .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Pharaoh : a beam search decoder for phrase - based statistical machine translation models .", "entities": [[11, 13, "TaskName", "machine translation"]]}, {"text": "In Conference of the Association for Machine Translation in the Americas , pages 115 \u2013 124 .", "entities": [[6, 8, "TaskName", "Machine Translation"]]}, {"text": "Springer .", "entities": []}, {"text": "Jey Han Lau , Trevor Cohn , Timothy Baldwin , Julian Brooke , and Adam Hammond .", "entities": [[14, 15, "MethodName", "Adam"]]}, {"text": "2018 .", "entities": []}, {"text": "Deep - speare : A joint neural model of poetic language , meter and rhyme .", "entities": []}, {"text": "arXiv preprint arXiv:1807.03491 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jiwei Li , Michel Galley , Chris Brockett , Jianfeng Gao , and Bill Dolan .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "A diversity - promoting objective function for neural conversation models .", "entities": []}, {"text": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 110\u2013119 .", "entities": []}, {"text": "Piji Li .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "An empirical investigation of pre - trained transformer language models for open - domain dialogue generation .", "entities": [[14, 16, "TaskName", "dialogue generation"]]}, {"text": "arXiv preprint arXiv:2003.04195 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Piji Li , Wai Lam , Lidong Bing , and Zihao Wang .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Deep recurrent generative decoder for abstractive text summarization .", "entities": [[5, 8, "TaskName", "abstractive text summarization"]]}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 2091\u20132100 .", "entities": []}, {"text": "Yi Liao , Yasheng Wang , Qun Liu , and Xin Jiang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Gpt - based generation for classical chinese poetry .", "entities": [[0, 1, "MethodName", "Gpt"]]}, {"text": "arXiv preprint arXiv:1907.00151 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Alec Radford , Karthik Narasimhan , Tim Salimans , and Ilya Sutskever . 2018 .", "entities": []}, {"text": "Improving language understanding with unsupervised learning .", "entities": []}, {"text": "Technical report , Technical report , OpenAI .", "entities": []}, {"text": "Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 .", "entities": []}, {"text": "Language models are unsupervised multitask learners .", "entities": []}, {"text": "OpenAI Blog , 1(8).Alexander M Rush , Sumit Chopra , and Jason Weston .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "A neural attention model for abstractive sentence summarization .", "entities": [[6, 8, "TaskName", "sentence summarization"]]}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 379\u2013389 .", "entities": []}, {"text": "Abigail See , Peter J Liu , and Christopher D Manning .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Get to the point : Summarization with pointergenerator networks .", "entities": [[5, 6, "TaskName", "Summarization"]]}, {"text": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1073 \u2013 1083 .", "entities": []}, {"text": "Abigail See , Aneesh Pappu , Rohun Saxena , Akhila Yerukola , and Christopher D Manning .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Do massively pretrained language models make better storytellers ?", "entities": [[2, 5, "TaskName", "pretrained language models"]]}, {"text": "arXiv preprint arXiv:1909.10705 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Rico Sennrich , Barry Haddow , and Alexandra Birch . 2015 .", "entities": []}, {"text": "Neural machine translation of rare words with subword units .", "entities": [[1, 3, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1508.07909 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "William Shakespeare .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "Shakespeare \u2019s sonnets .", "entities": []}, {"text": "Yale University Press .", "entities": []}, {"text": "Lifeng Shang , Zhengdong Lu , and Hang Li . 2015 .", "entities": []}, {"text": "Neural responding machine for short - text conversation .", "entities": [[4, 8, "TaskName", "short - text conversation"]]}, {"text": "InProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Volume 1 : Long Papers ) , pages 1577\u20131586 . Speech@CMU .", "entities": []}, {"text": "1998 .", "entities": []}, {"text": "Carnegie - mellon university pronouncing dictionary for american english .", "entities": []}, {"text": "Version 0.7b .", "entities": []}, {"text": "Available at [ http://www.speech.cs.cmu.edu/cgi-bin/cmudict ] .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Advances in neural information processing systems , pages 5998\u20136008 .", "entities": []}, {"text": "Oriol Vinyals and Quoc Le . 2015 .", "entities": []}, {"text": "A neural conversational model .", "entities": []}, {"text": "arXiv preprint arXiv:1506.05869 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Zhilin Yang , Zihang Dai , Yiming Yang , Jaime Carbonell , Ruslan Salakhutdinov , and Quoc V Le . 2019 .", "entities": [[12, 13, "DatasetName", "Ruslan"]]}, {"text": "Xlnet :", "entities": [[0, 1, "MethodName", "Xlnet"]]}, {"text": "Generalized autoregressive pretraining for language understanding .", "entities": []}, {"text": "arXiv preprint arXiv:1906.08237 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Xingxing Zhang and Mirella Lapata .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Chinese poetry generation with recurrent neural networks .", "entities": []}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 670\u2013680 .", "entities": []}, {"text": "Yukun Zhu , Ryan Kiros , Rich Zemel , Ruslan Salakhutdinov , Raquel Urtasun , Antonio Torralba , and Sanja Fidler .", "entities": [[9, 10, "DatasetName", "Ruslan"]]}, {"text": "2015 .", "entities": []}, {"text": "Aligning books and movies : Towards story - like visual explanations by watching movies and reading books .", "entities": []}, {"text": "In Proceedings of the IEEE international conference on computer vision , pages 19 \u2013 27 .", "entities": []}]