[{"text": "Proceedings of the Fourth Workshop on Online Abuse and Harms , pages 114\u2013124 Online , November 20 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17114Six Attributes of Unhealthy Conversations Ilan Price University of Oxford ilan.price@maths.ox.ac.ukJordan Gifford - Moore jordan.gifford-moore@\ufb02inders.edu.au Jory Fleming University of South Carolina \ufb02eminj6@mailbox.sc.eduSaul Musker saul@presidency.gov.zaMaayan Roichman University of Oxford maayan.roichman@anthro.ox.ac.uk Guillaume Sylvain gs1867@nyu.eduNithum", "entities": []}, {"text": "Thain Google Brain nthain@google.com", "entities": [[1, 2, "DatasetName", "Google"]]}, {"text": "Lucas Dixon Google Research ldixon@google.comJeffrey Sorensen Jigsaw sorenj@google.com", "entities": [[2, 3, "DatasetName", "Google"], [6, 7, "MethodName", "Jigsaw"]]}, {"text": "Abstract We present a new dataset of approximately 44000 comments labeled by crowdworkers .", "entities": []}, {"text": "Each comment is labelled as either \u2018 healthy \u2019 or \u2018 unhealthy \u2019 , in addition to binary labels for the presence of six potentially \u2018 unhealthy \u2019 sub - attributes : ( 1 ) hostile ; ( 2 ) antagonistic , insulting , provocative or trolling ; ( 3 ) dismissive ; ( 4 ) condescending or patronising ; ( 5 ) sarcastic ; and/or ( 6 ) an unfair generalisation .", "entities": []}, {"text": "Each label also has an associated con\ufb01dence score .", "entities": []}, {"text": "We argue that there is a need for datasets which enable research based on a broad notion of \u2018 unhealthy online conversation \u2019 .", "entities": []}, {"text": "We build this typology to encompass a substantial proportion of the individual comments which contribute to unhealthy online conversation .", "entities": []}, {"text": "For some of these attributes , this is the \ufb01rst publicly available dataset of this scale .", "entities": []}, {"text": "We explore the quality of the dataset , present some summary statistics and initial models to illustrate the utility of this data , and highlight limitations and directions for further research .", "entities": []}, {"text": "1 Introduction Analysis of online user discussion continues to be a critical area of interdisciplinary research .", "entities": []}, {"text": "Increasing rates of internet access and the development of a diverse range of online forums has allowed for conversation between individuals across the globe on an extraordinary range of topics .", "entities": []}, {"text": "However , this has been accompanied by a surge in abuse and other negative behaviours online , the impacts of whichhave been well - documented in academic research .", "entities": []}, {"text": "It has been found that targeted negative comments and harassment online can seriously impact individual well - being ( Weingartner and Stahel , 2019 ; Bauman , 2013 ) , force users to leave a community or reduce online participation ( Wulczyn et al . , 2017 ; Blackburn and Kwak , 2014 ) , and potentially lead to of\ufb02ine hate - crimes ( Mulki et al . , 2019 ; Hassan et al . , 2018 ) .", "entities": []}, {"text": "While these forms of comments may be explicit or overtly harmful , they are also often dif\ufb01cult to detect or ambiguous .", "entities": []}, {"text": "Where there are insuf\ufb01cient moderation resources to scale with a forum \u2019s user - base , this can lead to unchecked negative discourse , or cause website administrators to restrict user comment functions .", "entities": []}, {"text": "This means that research which aims to enable automated moderation , provide a review triage service for human moderation teams , or design systems to nudge users towards healthier conversation , has signi\ufb01cant potential for contributing to both the availability and quality of online discourse .", "entities": []}, {"text": "A persistent challenge for researchers and site administrators in this area is the need to : ( a ) establish a typology of comments which are undesirable in online discussions ; ( b ) apply this typology in a consistent and reliable manner ; and ( c ) account for adversarial user behaviour in response to moderation .", "entities": []}, {"text": "This is complicated by the fact that there is no single objective set of categories for speech which ought to be excluded in all contexts , with", "entities": []}, {"text": "115perceptions of undesirable speech differing across individuals , cultures , geographies , and online communities ( Vidgen et al . , 2019 ) .", "entities": []}, {"text": "Prior research on toxic comments online has found that classi\ufb01ers trained on crowdsourced data can be effective at detecting the most overt forms of toxic comments .", "entities": []}, {"text": "However , there remain dif\ufb01culties in detecting subtler forms of toxicity which may be implicit , require idiosyncratic knowledge , familiarity with the conversation context , or familiarity with particular cultural tropes ( Kohli et al . , 2018 ; van Aken et al . , 2018 ; Parekh and Patel , 2017 ) .", "entities": []}, {"text": "One of the key ingredients to progress on this front will be high quality , large , annotated datasets addressing these more subtle harmful attributes , from which machine learning models will be able to learn .", "entities": []}, {"text": "Unfortunately , for most subtler toxic attributes there are few available datasets ( or none , particularly in many languages other than English ) , which is a bottleneck preventing further research ( Fortuna et al . , 2019 ) .", "entities": []}, {"text": "We aim to contribute to research in this area through the release of the Unhealthy Comment Corpus ( UCC ) of approximately 44,000 comments and corresponding crowdsourced labels and con\ufb01dence scores .", "entities": [[18, 19, "DatasetName", "UCC"]]}, {"text": "The labelling typology for the dataset identi\ufb01es for each comment a higher - level classi\ufb01cation of whether that comment \u2018 has a place in a healthy online conversation \u2019 , accompanied for each comment by binary labels for whether it is : ( 1 ) hostile , ( 2 ) antagonistic , insulting , provocative or trolling ( together , \u2018 antagonistic \u2019 ) , ( 3 ) dismissive , ( 4 ) condescending or patronising ( together , \u2018 condescending \u2019 ) , ( 5 ) sarcastic , and/or ( 6 ) an unfair generalisation .", "entities": []}, {"text": "For each label there is also an associated con\ufb01dence score ( between 0.5 and 1 ) .", "entities": []}, {"text": "The UCC is open source and available on Github.1 The UCC contributes further high quality data on attributes like sarcasm , hostility , and condescension , adding to existing datasets on these and related attributes ( Wang and Potts , 2019 ;", "entities": [[1, 2, "DatasetName", "UCC"], [10, 11, "DatasetName", "UCC"]]}, {"text": "Davidson et al . , 2017 ; Wulczyn et al . , 2017 ; Chen et al . , 2017 ) , and provides ( to the best of our knowledge ) the \ufb01rst dataset of this scale with labels for dismissiveness , unfair generalisations , antagonistic behavior , and overall assessments of whether those comments fall within \u2018 healthy \u2019 conversation .", "entities": []}, {"text": "We also make use of and illustrate the bene\ufb01ts of annotator trustworthiness scores when crowdsourcing labels on subjective data of this sort .", "entities": []}, {"text": "1github.com/conversationai/unhealthy-conversationsThis paper is structured as follows .", "entities": []}, {"text": "Section 2 outlines the motivation and background to the UCC attribute typology .", "entities": [[9, 10, "DatasetName", "UCC"]]}, {"text": "Section 3 details the data collection and quality control processes .", "entities": []}, {"text": "In Section 4 we present some summary statistics , bene\ufb01ts , and limitations of the data , and in Section 5 we present a baseline classi\ufb01cation model for this dataset , and evaluate its performance .", "entities": []}, {"text": "Section 6 highlights potential sources of bias in this dataset , and the need to be cognisant of these when conducting further research in this area ( Dixon et al . , 2018 ) .", "entities": []}, {"text": "2", "entities": []}, {"text": "From \u2018 toxic \u2019 comments to \u2018 unhealthy \u2019 conversation In this paper , we broadly characterise a healthy online public conversation as one where posts and comments are made in good faith , are not overly hostile or destructive , and generally invite engagement .", "entities": []}, {"text": "Such a conversation may include robust engagement and debate , and is generally ( though not always ) focused on substance and ideas .", "entities": []}, {"text": "Importantly , though , healthy contributions to online conversations are not necessarily friendly , grammatically correct , well constructed , intellectual , substantive , or even free of any vulgarity .", "entities": []}, {"text": "Some harmful contributions to conversations are obviously derogatory , threatening , violent , or insulting ( Anderson et al . , 2018 ) , and these are the sorts of comments which have been the primary focus of research in algorithmic moderation assistance and related areas .", "entities": []}, {"text": "However , many of those comments which deter people from engagement or create downward spirals in interactions can be more subtle ( Zhang et al . , 2018 ) .", "entities": []}, {"text": "This is especially the case with conversations online , many of which ( i ) take place in a \u2018 public \u2019 forum that is visible to thousands of others , and ( ii ) involve strangers who have never met and know little about one another ( Santana , 2014 ) .", "entities": []}, {"text": "These two features of online conversations can sometimes enhance commenters \u2019 sensitivity to subtler forms of toxicity like sarcasm , condescension , or dismissiveness , amplifying their negative impact on conversations despite the fact that these attributes may be less ( or not at all ) harmful in other speci\ufb01c contexts .", "entities": []}, {"text": "Identifying subtle indicators of problematic online comments is a dif\ufb01cult task .", "entities": []}, {"text": "There are at least three reasons for this .", "entities": []}, {"text": "First , they are less extreme and therefore less likely to use clearly identi\ufb01able explicit or in\ufb02ammatory language .", "entities": []}, {"text": "Second , a substantive point might be made in an in\ufb02ammatory", "entities": []}, {"text": "116way , or a remark may be perceived differently depending on the context , norms , and expectations of the reader .", "entities": []}, {"text": "Third , there is an even greater risk of identifying \u2018 false positives \u2019 and \u2018 false negatives \u2019 , since many of the expressions used in subtle forms of toxicity can also be deployed for positive contributions .", "entities": []}, {"text": "For example , sarcasm is often used in derisive or bullying ways , but it can also be used for humour or to express a substantive , inoffensive point ( Vidgen et al . , 2019 ) .", "entities": []}, {"text": "The challenge is to identify the subtle characteristics of harmful comments online despite their ambiguity , without falsely identifying healthy comments .", "entities": []}, {"text": "We differentiate between two categories .", "entities": []}, {"text": "The \ufb01rst , which is the most well studied to date , are those whose explicit intention is to insult , threaten , or abuse .", "entities": []}, {"text": "The second category , are comments which engage with others , share an opinion , or contribute to the conversation , but are written in a way which is likely to antagonise , hurt , or deter others .", "entities": []}, {"text": "We found these comments to be at least as prevalent in the sample data ( Table 1 ) .", "entities": []}, {"text": "Our typology of unhealthy attributes aims to include this second category of comments , and determine whether annotators believe they belong in a healthy online conversation .", "entities": []}, {"text": "Our hypothesis was that together these 6 attributes account for the majority of \u2018 unhealthy \u2019 comments online , but that there will still be some comments that are \u2018 unhealthy \u2019 but do not display any sub - attribute , and also some which are \u2018 healthy \u2019 despite representing one or more sub - attributes ( see Figure 1 ) .", "entities": []}, {"text": "In general , whether the presence of these attributes indicates healthy or unhealthy conversation will also depend signi\ufb01cantly on the nature of the forum and users .", "entities": []}, {"text": "Nonetheless , the combination of an abstract \u2018 health \u2019 rating with the other 6 attributes provides a useful dataset for investigating nuanced comments , and could be used to help develop a broader range of models that are customised for speci\ufb01c production environments .", "entities": []}, {"text": "3 Source data and annotation The dataset comprises randomly chosen comments from the Globe and Mail news site ( sampled from the SFU Opinion and Comment Corpus dataset ) ( Kolhatkar et al . , 2019 ) , of 250 characters or less .", "entities": []}, {"text": "Comment scores were crowdsourced using Figure Eight ( now Appen ) .", "entities": []}, {"text": "The annotation job consisted of 588 crowdworkers ( annotators ) providing Figure 1 : A visualisation of the proposed typology of unhealthy online comments .", "entities": []}, {"text": "The grey pentagon represents unhealthy comments .", "entities": []}, {"text": "Note that in this \ufb01gure , \u2018 hostile \u2019 and \u2018 antagonistic \u2019 are represented jointly as \u2018 hostile \u2019 .", "entities": []}, {"text": "244468 judgements on 44355 comments.2Each annotator was asked to identify for each comment whether it was healthy and if any of the attributes were present , in the form of a standard questionnaire ( see Appendix A ) .", "entities": []}, {"text": "Annotators were not given any wider context or additional information about where a comment was posted or how it was engaged with by other users .", "entities": []}, {"text": "To both accommodate and attempt to resolve meaningful disagreement , we applied a dynamic judgement method which requests additional annotations for those comments on which there was insuf\ufb01cient consensus ( either yes or no with a con\ufb01dence of less than 75 % ) .", "entities": []}, {"text": "All comments were annotated at least three times , and more annotators were added , up to a limit of \ufb01ve annotators per comment until suf\ufb01cient consensus was reached .", "entities": []}, {"text": "Annotation Job Re\ufb01nement .", "entities": []}, {"text": "The inherent subtlety , subjectivity , and frequent ambiguity of the attributes covered in this dataset make crowdsourcing quality attribute labels an unavoidably dif\ufb01cult process .", "entities": []}, {"text": "Typically the goal in an annotation task would simply be to maximise agreement between the multiple annotators of each comment .", "entities": []}, {"text": "However , when the annotation task is inherently subjective and 2According to statistics provided by Appen , the average time spent on those annotations which were included in the \ufb01nal dataset was between 12 and 13 seconds per comment .", "entities": []}, {"text": "117meaningful difference of opinion is itself valuable data , the goal becomes instead to maximise common understanding of the task across annotators .", "entities": []}, {"text": "This entails tailoring the phrasing of the questions put to annotators , so as to create as common an understanding as possible of what each question is really asking .", "entities": []}, {"text": "This way , disagreement between annotators re\ufb02ected in the dataset will represent different reasonable readings of the same comment which are themselves important to capture .", "entities": []}, {"text": "In research on irony and sarcasm , for example , Filatova noted the dif\ufb01culty even among expert researchers in formally de\ufb01ning these terms ( Filatova , 2012 ) .", "entities": []}, {"text": "For the other attributes included in this dataset which are as ( if not more ) ambiguous and subtle than sarcasm , we expect this to hold true as well .", "entities": []}, {"text": "The exact wording of each question on the questionnaire went through multiple iterations , tested by smaller scale experiments to evaluate effectiveness .", "entities": []}, {"text": "The quality of the resulting data was evaluated manually by our team , calculating the proportion of perceived mistaken annotations and their \u2018 severity \u2019 : to what extent a judgement was \u2018 obviously wrong \u2019 , as opposed to an understandable alternative reading of a comment .", "entities": []}, {"text": "We found that providing annotators with precise and more comprehensive de\ufb01nitions of each attribute was not more likely to produce interannotator agreement or better quality data .", "entities": []}, {"text": "Neither , however , were best results produced by asking simple , \u2018 yes or no \u2019 questions such as \u2018 Is this comment dismissive ? \u2019 for all attributes .", "entities": []}, {"text": "The best results were achieved by relying primarily on annotators implicit understandings of and intuitions about the attributes , aided by brief inline explanations .", "entities": []}, {"text": "We added explanations to avoid mistakes for those attributes which are more ambiguous , and for which our smaller tests had indicated required further guidance .", "entities": []}, {"text": "These can be seen in the questionnaire included as Appendix A.", "entities": []}, {"text": "To ensure that disagreement re\ufb02ects reasonable difference of opinion , rather than inattention or misunderstanding of the task , it is necessary to apply a method of quality control .", "entities": []}, {"text": "The attempt to create a labeled dataset is premised on the assumption of some \u2018 ground truth \u2019 ; that it is possible for comments to have labels and con\ufb01dence scores accurately representing the presence of one or more attributes to some extent .", "entities": []}, {"text": "However , the extent to which a comment displays one or more attribute is subjective , and the scores would be unhelpfulif they did not capture what a wider and more diverse audience than our team of authors would understand the comments to mean .", "entities": []}, {"text": "Our process of quality control therefore aimed to reduce the number of \u2018 bad \u2019 annotators , those who either do not understand or appropriately engage with the task , while still allowing for differences of opinion .", "entities": []}, {"text": "Our primary quality control mechanism was to collate a set of \u2018 test comments \u2019 , for which we had manually established the correct answers .", "entities": [[7, 8, "DatasetName", "collate"]]}, {"text": "Annotators encountered one test comment per batch of seven comments they reviewed , without knowing which of the seven was the test comment , and their running accuracy on these test comments was de\ufb01ned as their \u2018 trustworthiness score \u2019 .", "entities": [[27, 28, "MetricName", "accuracy"]]}, {"text": "The task required that annotators maintain a trustworthiness score of more than 78 % .", "entities": []}, {"text": "If an annotator dropped below this level , they were removed from the annotator pool for this task , and all of their prior annotations were discarded3 .", "entities": []}, {"text": "The removed \u2018 bad \u2019 annotator judgements were replaced by newly collected trusted judgements as necessary .", "entities": []}, {"text": "We restricted our test comments to what were ( in our view ) clear and de\ufb01nitive examples of the attributes , such that one would fail on the test comments only if one has an incorrect understanding of what is meant by a particular attribute .", "entities": []}, {"text": "In the course of our preliminary small - scale re\ufb01ning iterations of the questionnaire , analysis of responses revealed some recurring misunderstandings or mistakes .", "entities": []}, {"text": "For example , a common error was to label all non - sarcastic humour as sarcasm , or to con\ufb02ate polite disagreement with dismissiveness .", "entities": []}, {"text": "As a result , we identi\ufb01ed and included speci\ufb01c test comments , drawn from real examples , aimed at reducing these common errors .", "entities": []}, {"text": "We included very few test comments for the higher level question on whether a comment belongs in a healthy conversation .", "entities": []}, {"text": "Any test questions on this topic were very extreme examples , such as highly abusive explicit comments , to ensure that annotators were not randomly answering that question .", "entities": []}, {"text": "We had two reasons for minimising the use of test comments for this question .", "entities": []}, {"text": "Firstly , since this was in our view the most open - ended question , it is dif\ufb01cult to establish tests on the basis of which to exclude annotators .", "entities": []}, {"text": "Secondly , allowing greater 3This was a threshold selected through initial test jobs , to balance budget and quality considerations .", "entities": []}, {"text": "A higher threshold yields more trustworthy annotations , but consequently discards more existing data when annotators drop below that threshold .", "entities": []}, {"text": "118annotator discretion on this question provides insight on whether there is a correlation between the six attributes and being labelled as unhealthy.4 4 The UCC dataset The dataset comprises a total of 44355 comments labelled \u2018 yes \u2019 or \u2018 no \u2019 for each attribute , along with a con\ufb01dence score for each label .", "entities": [[24, 25, "DatasetName", "UCC"]]}, {"text": "The labels and corresponding con\ufb01dence scores for each attribute are based on an aggregation of the answers given by different annotators , weighted by their respective \u2018 trustworthiness \u2019 scores .", "entities": []}, {"text": "As an example to demonstrate this process , consider a comment annotated by 5 annotators with trustworthiness scores 0.78 , 0.85 , 0.9 , 1.0 , and 0.95 , who judge a comment for a particular attribute with judgements \u2018 yes \u2019 , \u2018 yes \u2019 , \u2018 yes \u2019 , \u2019 no \u2019 , \u2019 yes \u2019 respectively .", "entities": []}, {"text": "Let Tbe the sum of their trustworthiness scores , and Ty , Tnthe sum of the trustworthiness scores of those who answered \u2018 yes \u2019 and \u2018 no \u2019 respectively .", "entities": []}, {"text": "The label is then determined by which of TyorTnis larger , in this case it isTy , and the con\ufb01dence score is Ty = T , in this case 0.78 .", "entities": []}, {"text": "The proportion of comments that contain each attribute is shown in Table 1 and the con\ufb01dence distributions are shown in Figure 2 .", "entities": []}, {"text": "Attribute Proportion Antagonistic / Insulting / Trolling 4.7 % Condescending / Patronising 5.5 % Dismissive 3.1 % ( Unfair ) Generalisation 2 % Hostile 2.5 % Sarcastic 4.3 % Unhealthy 7.5 % Table 1 : Percentage of positive labels for each attribute .", "entities": []}, {"text": "As the comments were sampled from the SFU Opinion and Comment Corpus dataset , the prevalence for each attribute is inevitably low .", "entities": []}, {"text": "Despite the label imbalance , the dataset represents an important contribution to identi\ufb01cation of this wider variety of subtle attributes , with thousands of positive examples for each .", "entities": []}, {"text": "Our manual analysis during initial iterations of the annotation job indicated that 4There remains a clear methodological issue with using this data for comparing the set of comments classed as \u2018 unhealthy \u2019 with those classed as one or more of the other attributes : having been asked all questions as part of the same questionnaire , annotators may have been primed to associate the attributes with \u2018 unhealthiness \u2019 , even if they would not have done so otherwise .", "entities": []}, {"text": "( a ) ( b ) Figure 2 : Density estimation ( Rosenblatt et al . , 1956 ) of con\ufb01dence scores for each attribute .", "entities": [[9, 11, "TaskName", "Density estimation"]]}, {"text": "Figure 2a shows con\ufb01dence scores for those comments labelled as \u2019 no \u2019 for each unhealthy attribute , while Figure 2b represents those of comments labelled \u2019 yes \u2019 .", "entities": []}, {"text": "these \ufb01nal proportions are roughly representative of the prevalence of these attributes in similar live contexts , such as North American online newspaper comment sections .", "entities": []}, {"text": "There are speci\ufb01c attributes , notably sarcasm , for which it can be possible to collate a corpus of self - labelled data , for example by scraping tweets with \u2018 # sarcastic \u2019 from Twitter , or comments followed by \u2018 /s \u2019 on Reddit ( Khodak et al . , 2018 ) .", "entities": [[15, 16, "DatasetName", "collate"], [45, 46, "DatasetName", "Reddit"]]}, {"text": "In these speci\ufb01c circumstances , the avoidance of the need to crowdsource and pay for annotations can permit much larger and more balanced datasets .", "entities": []}, {"text": "However , for all other attributes we consider , and in fora like the comment sections of news sites , relying on self - labelled data is not possible .", "entities": []}, {"text": "For these attributes , crowdsourcing is the only feasible way to obtain high quality data , and as such we would expect proportions re\ufb02ecting those observed in similar contexts .", "entities": []}, {"text": "Inspection of random subsets of the new UCC", "entities": [[7, 8, "DatasetName", "UCC"]]}, {"text": "119 ( a ) A distinction between a hostile comment and one which intends to insult , antagonize , provoke or troll other users .", "entities": []}, {"text": "( b ) Subtle condescension ( c ) Implicit yet clear dismissiveness .", "entities": []}, {"text": "Figure 3 : Examples of subtleties correctly picked up by annotators , with con\ufb01dence scores shown in brackets alongside the resultant label .", "entities": []}, {"text": "dataset reveals that the data is generally of a high quality , and captures important nuances , accurately identifying these subtle attributes , both when they overlap ( as is common ) , and also when they do not ( see Figure 3 for examples ) .", "entities": []}, {"text": "Figure 4 shows the correlations between attributes , calculated based on the pool of comments which are labelled as one or more of the six unhealthy attributes .", "entities": []}, {"text": "The \ufb01gure highlights two important facts .", "entities": []}, {"text": "First , the relatively low correlation between most attributes indicates that the dataset succeeds in differentiating between these different types of subtle unhealthy attributes .", "entities": []}, {"text": "As expected , there is signi\ufb01cant correlation between antagonistic and hostile comments .", "entities": []}, {"text": "There is some correlation between the often more subtle attributes like dismissiveness / condescension and antagonism , while these are less correlated with hostility .", "entities": []}, {"text": "We also include correlations with the \u2018 toxicity \u2019 scores produced by Jigsaw \u2019s Perspective API ( perspectiveapi.com ) , which again con\ufb01rms that our attributes , in particular those other than antagonistic and hostile , capture something distinct from overt toxicity .", "entities": [[12, 13, "MethodName", "Jigsaw"]]}, {"text": "A notable feature of Figure 4 is the slightly negative correlations between sarcasm and other attributes , indicating that annotators generally did not associate sarcasm with other unhealthy attributes .", "entities": []}, {"text": "Secondly , \u2018 unhealthy \u2019 correlates signi\ufb01cantly withantagonism and hostility , but very little with the other attributes , indicating a fairly broad general notion of healthy conversation on the part of the annotators , which mostly includes dismissive , condescending , sarcastic and generalising comments .", "entities": []}, {"text": "Figure 4 : Inter - attribute correlations , including with \u2018 toxicity \u2019 as scored by Perspective API .", "entities": []}, {"text": "Despite its generally high quality , the nature of the task and the annotation method entails some level of noise in the dataset .", "entities": []}, {"text": "This noise is particularly dif\ufb01cult to quantify given the need to distinguish between different but reasonable interpretations of a comment , and simply incorrect annotations caused by a lack of understanding or care on the part of an annotator ( for example , one comment reading \u201c You are an ignorant\u0003sshole \u201d was judged not to be needlessly hostile , an obvious error ) .", "entities": []}, {"text": "This highlights the dif\ufb01culties of using traditional reliability metrics like Krippendorff \u2019s \u000b  for crowdsourced annotations on subjective tasks ( D\u2019Arcey et al . , 2019 ) .", "entities": []}, {"text": "Krippendorff \u2019s \u000b is a number between 0 and 1 intended to indicate the extent to which annotators agree compared with what would have happened if they guessed randomly .", "entities": [[7, 8, "DatasetName", "0"]]}, {"text": "The base assumption then is that all disagreement between annotators decreases reliability , which is not necessarily the case for subjective attributes ( Salminen et al . , 2018b ;", "entities": []}, {"text": "Swanson et al . , 2014 ) .", "entities": []}, {"text": "Despite the above caveat , we conduct analysis using Krippendorff \u2019s \u000b ( K- \u000b ) for two reasons .", "entities": []}, {"text": "Firstly , to allow for comparison with other literature in the \ufb01eld , we report the K- \u000b for judgements on each attribute in Table 2 .", "entities": []}, {"text": "They range from 0.31 - 0.39 , which is comparable with other datasets labelling \u2018 similar \u2019 phenomenon , such as sarcasm ( 0.24 - 0.38 ) ( Swanson et al . , 2014 ; Justo et al . , 2018 ; D\u2019Arcey", "entities": []}, {"text": "120et al . , 2019 ) , and hate speech with sub - attributes from Figure Eight annotators ( 0.21 ) ( Lazaridou et al . , 2020 ) .", "entities": [[8, 10, "DatasetName", "hate speech"]]}, {"text": "The one exception is the set of judgements on whether a comment has a place in a healthy conversation , with a lower K- \u000b of 0.26 .", "entities": []}, {"text": "Given that this is a more open - ended question , this is not necessarily surprising .", "entities": []}, {"text": "Attribute K- \u000b  Antagonistic / Insulting / Trolling 0.39 Condescending / Patronising 0.36 Dismissive 0.31 Generalisation 0.35 Hostile 0.36 Sarcastic 0.34 Unhealthy 0.26 Table 2 : Krippendorff \u2019s alpha by attribute .", "entities": [[28, 29, "HyperparameterName", "alpha"]]}, {"text": "Secondly , to the extent that K- \u000b is an important reliability metric for this form of data , it supports our use of \u2018 trustworthiness \u2019 scores when aggregating judgements on a given comment to decide labels and con\ufb01dence scores .", "entities": []}, {"text": "Speci\ufb01cally , as shown in Figure 5 , we see that as we increase the trustworthiness threshold for annotators whose judgements are included , the resulting K- \u000b steadily increase .", "entities": []}, {"text": "This provides some indication that our trustworthiness scores do capture the reliability of our annotators , and thus that their judgements ought to be weighted more highly in the \ufb01nal con\ufb01dence in a comment \u2019s labels .", "entities": []}, {"text": "Also included in the UCC dataset are the individual annotations for each comment by all \u2018 trusted \u2019 annotators .", "entities": [[4, 5, "DatasetName", "UCC"]]}, {"text": "Users of the data may therefore apply any alternative trustworthiness threshold , or use a preferred aggregation method to derive labels .", "entities": []}, {"text": "5 Models and results Use of a pre - trained BERT model ( Devlin et al . , 2019 ) and \ufb01ne - tuning on this dataset produces classi\ufb01ers with modest performance ( Figure 6 ) , compared to the state of the art for sequence classi\ufb01cation .", "entities": [[10, 11, "MethodName", "BERT"]]}, {"text": "The best performing attributes , \u2018 hostile \u2019 and \u2018 antagonistic \u2019 are also those most similar to the types of attributes typically annotated in comment classi\ufb01cation work .", "entities": []}, {"text": "The other attributes seem to cluster together , with the \u2018 sarcastic \u2019 label particularly noteworthy for its low performance .", "entities": []}, {"text": "To give context to the model performance , we follow ( Wulczyn et al . , 2017 ) and compare our performance with human workers .", "entities": []}, {"text": "For each comment , Figure 5 : Krippendorff \u2019s \u000b for various threshold levels of annotator trustworthiness .", "entities": []}, {"text": "0.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate0.00.20.40.60.81.0True Positive Rateantagonise 0.825 hostile 0.82 dismissive 0.806 condescending 0.791 healthy 0.76 generalisation 0.696 generalisation_unfair 0.671 sarcastic 0.588 Figure 6 : Receiver operating characteristic curves and AUC for class each attribute .", "entities": [[34, 35, "MetricName", "AUC"]]}, {"text": "we hold out one annotator to act as our \u2018 human model \u2019 and use the aggregated score of the other annotators as the ground truth to compute the ROC AUC .", "entities": [[29, 31, "MetricName", "ROC AUC"]]}, {"text": "To stabilize our results , this procedure is repeated \ufb01ve times and the average reported .", "entities": []}, {"text": "We use the same test sets to compute the ROC AUC of the trained BERT model and average those scores as well .", "entities": [[9, 11, "MetricName", "ROC AUC"], [14, 15, "MethodName", "BERT"]]}, {"text": "As we can see , for all attributes other than \u2018 sarcastic \u2019 the BERT model outperforms a randomly selected human annotator , indicating that it has suf\ufb01ciently captured the semantic and syntactic structures for these attributes .", "entities": [[14, 15, "MethodName", "BERT"]]}, {"text": "For \u2018 sarcastic \u2019 , the gap between the BERT model and human annotators indicates a rich area for studying whether model performance can be improved .", "entities": [[9, 10, "MethodName", "BERT"]]}, {"text": "6 Potential Unintended Biases One further challenge which comes with annotating more subtle unhealthy attributes is the potential to encode unintended societal biases and value judgements in models trained on this data .", "entities": []}, {"text": "For example ,", "entities": []}, {"text": "121Attribute Human AUC BERT AUC Antagonistic 0.71 0.82 Condescending 0.72 0.78 Dismissive 0.68 0.82 Generalisation 0.73 0.74 Hostile 0.76 0.84", "entities": [[2, 3, "MetricName", "AUC"], [3, 4, "MethodName", "BERT"], [4, 5, "MetricName", "AUC"]]}, {"text": "Sarcastic 0.72 0.64 Unhealthy 0.62 0.69 Table 3 : Comparing Human and BERT performance sarcasm is often communicated by stating something which the author presumes to be so obviously untrue that it will be read as sarcastic .", "entities": [[12, 13, "MethodName", "BERT"]]}, {"text": "These presumptions re\ufb02ect the author \u2019s biases - or in the cases of comment annotation , labelling comments as sarcastic re\ufb02ects the annotators beliefs of what is obviously untrue .", "entities": []}, {"text": "With the comment corpus being in English , and given the subtlety of the attributes , higher quality annotations were likely to be achieved by annotators with \ufb01rst - language pro\ufb01ciency in English .", "entities": []}, {"text": "The best proxy for this available on the Figure Eight platform was to restrict the country of origin of our annotators to a limited subset of countries with a large English - speaking population ( as either an of\ufb01cial language or primary second language ) , in particular : the United States , the United Kingdom , South Africa , Sweden , New Zealand , Norway , Netherlands , Denmark , Canada , and Australia .", "entities": []}, {"text": "Although our early iterations of this annotation job indicated a signi\ufb01cant reduction in annotators failing test comments once this was enforced , this introduces a clear cultural and geographic bias .", "entities": []}, {"text": "For example , the comment \u2018 Iran and Turkey are the BEST places to be a woman ! \u2019 , was scored as sarcastic with 72 % con\ufb01dence by the annotators .", "entities": []}, {"text": "Finding this comment sarcastic relies on an assumption by the annotators ( of which the pool excludes residents of Iran and Turkey ) that Iran and Turkey are clearly not the best places to be women .", "entities": []}, {"text": "Our annotators were not selected as broadly representative across language , geography , culture , or other attributes and this assumption is not universal .", "entities": []}, {"text": "While important research has begun to explore the composition of the global crowd workforce , it remains dif\ufb01cult to select for annotators representative of speci\ufb01c characteristics on crowd work platforms ( Posch et al . , 2018 ) .", "entities": []}, {"text": "In the current version of the Appen platform , unless annotators are asked standalone questions on demographics , the only available de - tails are the annotators \u2019 country and/or city ( and even then , only for some annotators ) .", "entities": []}, {"text": "Research and modelling based on this dataset , and similar datasets , requires the exercise of great care in mitigating biases produced by the underlying data collection .", "entities": []}, {"text": "This potential selection bias is likely to be evident across the broader healthy / unhealthy categorisation along with each of the attributes .", "entities": [[2, 4, "TaskName", "selection bias"]]}, {"text": "Prior research has found substantial disagreement on subtle attributes of speech both among individuals and across geographies ( Salminen et al . , 2018a ) .", "entities": []}, {"text": "Finally , the source of the comments and their manner of presentation could introduce bias into the dataset .", "entities": []}, {"text": "The source data is solely from a Canadian online newspaper comment section and comments were presented in isolation to annotators , without the surrounding context of the news article and other comments .", "entities": []}, {"text": "Annotators were also provided with the standard questionnaire ( Appendix A ) , which includes high level descriptions of the attributes that may not generalise across cultures .", "entities": []}, {"text": "There is a substantial body of research demonstrating the potential impact of introducing biased datasets , and Vidgen et al .", "entities": []}, {"text": "( Vidgen et al . , 2019 ) note that public datasets in this area are prone to systematic bias and mislabelling , with interannotator agreement typically low for complex multi - class tasks of this kind .", "entities": []}, {"text": "These challenges are to be expected in a relatively new \ufb01eld which aims to improve on human baseline moderation for highly subjective characteristics of online discussion .", "entities": []}, {"text": "At this early stage of research , we must be mindful of addressing these biases and cognisant that the manner in which this data is collected can have critical impacts on users in a production environment .", "entities": []}, {"text": "It is important to note at this stage of the \ufb01eld in general , and with our understanding of this dataset in particular , that the UCC dataset is not designed to train models which are immediately available for automated moderation without human intervention in a live online setting .", "entities": [[26, 27, "DatasetName", "UCC"]]}, {"text": "As the \ufb01eld develops further , initial use - cases may include less interventionist \u2018 nudges \u2019 or reminders of how a comment could be perceived by a reader to assist participants in discussions online .", "entities": []}, {"text": "7 Conclusions and Further work We introduced a new corpus of labelled comments and a typology for some of the more subtle aspects of unhealthy online conversation .", "entities": []}, {"text": "Our typology provides 6 sub - attributes of typically unhealthy con-", "entities": []}, {"text": "122tributions , and con\ufb01dence scores for the labels .", "entities": []}, {"text": "We described the process and challenges in creating such a dataset , and provided statistics to convey the scale of data .", "entities": []}, {"text": "In particular , we note that although there is a substantial body of research on more extreme forms of negative contributions , such as toxicity , the subtler forms of unhealthy comments in our typology are often similarly prevalent online .", "entities": []}, {"text": "Our analysis also shows that the sub - attributes are largely independent from overt toxicity , and mostly correlated with unhealthy contributions .", "entities": []}, {"text": "We also provide results from a modern baseline ML model ( \ufb01ne tuning BERT ) and note that performance exceeds that of a crowd - worker .", "entities": [[13, 14, "MethodName", "BERT"]]}, {"text": "This suggests that further work could also be done to collect a larger corpus of annotations to improve the capacity to measure models in this domain .", "entities": []}, {"text": "While this dataset provides a new contribution in gathering the 6 attributes under the umbrella of an \u2018 unhealthy \u2019 conversation , there also remains an open question as to how exhaustive this typology of unhealthy contributions is .", "entities": []}, {"text": "Future research and annotation work could further re\ufb01ne the typology , amend the standard questionnaire , or apply it to forums which differ in cultural and geographic context .", "entities": []}, {"text": "Further work also includes exploring the unintended biases in the model and data .", "entities": []}, {"text": "This dataset is well - placed to further explore early signs of conversations going awry ( Zhang et al . , 2018 ) , while models based on the data could be explored to provide assistance to moderating online conversations .", "entities": []}, {"text": "References Betty van Aken , Julian Risch , Ralf Krestel , and Alexander L \u00a8oser .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Challenges for toxic comment classi\ufb01cation : An in - depth error analysis .", "entities": []}, {"text": "In Proceedings of the 2nd Workshop on Abusive Language Online ( ALW2 ) , pages 33\u201342 .", "entities": [[7, 9, "TaskName", "Abusive Language"]]}, {"text": "Ashley A Anderson , Sara K Yeo , Dominique Brossard , Dietram A Scheufele , and Michael A Xenos .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Toxic talk : How online incivility can undermine perceptions of media .", "entities": []}, {"text": "International Journal of Public Opinion Research , 30(1):156\u2013168 .", "entities": []}, {"text": "Sheri Bauman .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Cyberbullying : What does research tell us ?", "entities": []}, {"text": "Theory into practice , 52(4):249\u2013256 .", "entities": []}, {"text": "Jeremy Blackburn and Haewoon Kwak .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Stfu noob !", "entities": []}, {"text": "predicting crowdsourced decisions on toxic behavior in online games .", "entities": []}, {"text": "In Proceedings of the 23rd international conference on World wide web , pages 877\u2013888 .", "entities": []}, {"text": "Hao Chen , Susan Mckeever , and Sarah Jane Delany .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Presenting a labelled dataset for real - time de - tection of abusive user posts .", "entities": []}, {"text": "In Proceedings of the International Conference on Web Intelligence , pages 884\u2013890 .", "entities": []}, {"text": "J Trevor D\u2019Arcey , Shereen Oraby , and Jean E Fox Tree .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Wait signals predict sarcasm in online debates .", "entities": []}, {"text": "Dialogue & Discourse , 10(2):56\u201378 .", "entities": []}, {"text": "Thomas Davidson , Dana Warmsley , Michael Macy , and Ingmar Weber . 2017 .", "entities": []}, {"text": "Automated hate speech detection and the problem of offensive language .", "entities": [[1, 4, "TaskName", "hate speech detection"]]}, {"text": "InProceedings of the Eleventh International AAAI Conference on Web and Social Media .", "entities": []}, {"text": "J. Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Lucas Dixon , John Li , Jeffrey Sorensen , Nithum Thain , and Lucy Vasserman .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Measuring and mitigating unintended bias in text classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2018 AAAI / ACM Conference on AI , Ethics , and Society , pages 67\u201373 .", "entities": [[7, 8, "DatasetName", "ACM"], [12, 13, "DatasetName", "Ethics"]]}, {"text": "Elena Filatova .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Irony and sarcasm : Corpus generation and analysis using crowdsourcing .", "entities": []}, {"text": "In Proceedings of the Eighth International Conference on Language Resources and Evaluation ( LREC 2012 ) , pages 392\u2013398 .", "entities": []}, {"text": "Paula Fortuna , Joao Rocha da Silva , Leo Wanner , S\u00b4ergio Nunes , et al . 2019 .", "entities": []}, {"text": "A hierarchically - labeled portuguese hate speech dataset .", "entities": [[5, 7, "DatasetName", "hate speech"]]}, {"text": "In Proceedings of the Third Workshop on Abusive Language Online , pages 94\u2013104 .", "entities": [[7, 9, "TaskName", "Abusive Language"]]}, {"text": "Ghayda Hassan , S \u00b4 ebastien Brouillette - Alarie , S \u00b4 eraphin Alava , Divina Frau - Meigs , Lysiane Lavoie , Arber Fetiu , Wynnpaul Varela , Evgueni Borokhovski , Vivek Venkatesh , C \u00b4 ecile Rousseau , et al .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Exposure to extremist online content could lead to violent radicalization :", "entities": []}, {"text": "A systematic review of empirical evidence .", "entities": []}, {"text": "International journal of developmental science , 12(1 - 2):71\u201388 .", "entities": []}, {"text": "Raquel Justo , Jos \u00b4 e M Alcaide , M", "entities": []}, {"text": "In \u00b4 es Torres , and Marilyn Walker .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Detection of sarcasm and nastiness : new resources for spanish language .", "entities": []}, {"text": "Cognitive Computation , 10(6):1135\u20131151 .", "entities": []}, {"text": "Mikhail Khodak , Nikunj Saunshi , and Kiran V odrahalli .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A large self - annotated corpus for sarcasm .", "entities": []}, {"text": "InProceedings of the Eleventh International Conference on Language Resources and Evaluation ( LREC 2018 ) .", "entities": []}, {"text": "Manav Kohli , Emily Kuehler , and John Palowitch .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Paying attention to toxic comments online .", "entities": []}, {"text": "Web : https://stanford.io/2YfKMvE .", "entities": []}, {"text": "Varada Kolhatkar , Hanhan Wu , Luca Cavasso , Emilie Francis , Kavan Shukla , and Maite Taboada .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The sfu opinion and comments corpus : A corpus for the analysis of online news comments .", "entities": []}, {"text": "Corpus Pragmatics , pages 1\u201336 .", "entities": []}, {"text": "123Konstantina Lazaridou , Alexander L \u00a8oser , Maria Mestre , and Felix Naumann .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Discovering biased news articles leveraging multiple human annotations .", "entities": []}, {"text": "In Proceedings of the 12th Conference on Language Resources and Evaluation , pages 1268 \u2013 1277 .", "entities": []}, {"text": "Hala Mulki , Hatem Haddad , Chedi Bechikh Ali , and Halima Alshabani .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "L - hsab : a levantine twitter dataset for hate speech and abusive language .", "entities": [[9, 11, "DatasetName", "hate speech"], [12, 14, "TaskName", "abusive language"]]}, {"text": "In Proceedings of the Third Workshop on Abusive Language Online , pages 111\u2013118 .", "entities": [[7, 9, "TaskName", "Abusive Language"]]}, {"text": "Pooja Parekh and Hetal Patel .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Toxic comment tools : A case study .", "entities": []}, {"text": "International Journal of Advanced Research in Computer Science , 8(5 ) .", "entities": []}, {"text": "Lisa Posch , Arnim Bleier , Fabian Fl \u00a8ock , and Markus Strohmaier .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Characterizing the global crowd workforce : A cross - country comparison of crowdworker demographics .", "entities": []}, {"text": "Murray Rosenblatt et", "entities": []}, {"text": "al .", "entities": []}, {"text": "1956 .", "entities": []}, {"text": "Remarks on some nonparametric estimates of a density function .", "entities": []}, {"text": "The Annals of Mathematical Statistics , 27(3):832\u2013837 .", "entities": []}, {"text": "Joni Salminen , Fabio Veronesi , Hind Almerekhi , SoonGvo Jung , and Bernard J Jansen .", "entities": []}, {"text": "2018a .", "entities": []}, {"text": "Online hate interpretation varies by country , but more by individual : A statistical analysis using crowdsourced ratings .", "entities": []}, {"text": "In 2018 Fifth International Conference on Social Networks Analysis , Management and Security ( SNAMS ) , pages 88\u201394 .", "entities": [[10, 11, "TaskName", "Management"]]}, {"text": "IEEE .", "entities": []}, {"text": "Joni O. Salminen , Hind A. Al - Merekhi , Partha Dey , , and Bernard James Jansen . 2018b .", "entities": []}, {"text": "Inter - rater agreement for social computing studies .", "entities": []}, {"text": "In Proceedings of the 5th International Conference on Social Networks Analysis , Management and Security , pages 80\u201387 .", "entities": [[12, 13, "TaskName", "Management"]]}, {"text": "Arthur D Santana .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Virtuous or vitriolic : The effect of anonymity on civility in online newspaper reader comment boards .", "entities": []}, {"text": "Journalism practice , 8(1):18\u201333 .", "entities": []}, {"text": "Reid Swanson , Stephanie Lukin , Luke Eisenberg , Thomas Corcoran , and Marilyn Walker . 2014 .", "entities": []}, {"text": "Getting reliable annotations for sarcasm in online dialogues .", "entities": []}, {"text": "In Proceedings of the Ninth International Conference on Language Resources and Evaluation ( LREC\u201914 ) , pages 4250\u20134257 .", "entities": []}, {"text": "Bertie Vidgen , Alex Harris , Dong Nguyen , Rebekah Tromble , Scott Hale , and Helen Margetts .", "entities": [[16, 17, "DatasetName", "Helen"]]}, {"text": "2019 .", "entities": []}, {"text": "Challenges and frontiers in abusive content detection .", "entities": []}, {"text": "In Proceedings of the Third Workshop on Abusive Language Online , pages 80\u201393 , Florence , Italy .", "entities": [[7, 9, "TaskName", "Abusive Language"], [14, 15, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Zijian Wang and Christopher Potts . 2019 .", "entities": []}, {"text": "Talkdown : A corpus for condescension detection in context .", "entities": [[0, 1, "DatasetName", "Talkdown"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 3702 \u2013 3710.Sebastian Weingartner and Lea Stahel .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Online aggression from a sociological perspective : An integrative view on determinants and possible countermeasures .", "entities": []}, {"text": "In Proceedings of the Third Workshop on Abusive Language Online , pages 181\u2013187 .", "entities": [[7, 9, "TaskName", "Abusive Language"]]}, {"text": "Ellery Wulczyn , Nithum Thain , and Lucas Dixon . 2017 .", "entities": []}, {"text": "Ex machina : Personal attacks seen at scale .", "entities": []}, {"text": "In Proceedings of the 26th International Conference on World Wide Web , pages 1391\u20131399 .", "entities": []}, {"text": "Justine Zhang , Jonathan P Chang , Cristian DanescuNiculescu - Mizil , Lucas Dixon , Yiqing Hua , Nithum Tahin , and Dario Taraborelli .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Conversations gone awry : Detecting early signs of conversational failure .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": ", volume 1 .", "entities": []}, {"text": "124A Annotator Questionnaire Overview", "entities": []}, {"text": "In this job , you will be asked to read a comment and to express an overall opinion about whether you think it has a place in a healthy conversation online .", "entities": []}, {"text": "You will also be asked to identify whether it displays a range of characteristics that may lead to unhealthy conversations .", "entities": []}, {"text": "These characteristics include : sarcasm , gross generalisations , hostility , aggression , dismissiveness , condescension and patronization .", "entities": []}, {"text": "All of the comments you will see are real comments posted by users in online conversations .", "entities": []}, {"text": "Most of them will have been posted in response to one or more comments made by others ( which you are not given ) .", "entities": []}, {"text": "However , the questions are designed in such a way that you should be able to answer them without seeing these other comments .", "entities": []}, {"text": "The data collected here will be used to help build tools which promote healthier conversations online .", "entities": []}, {"text": "Note : \u2022Please bear in mind that the questions do not ask whether you agree or disagree with the substance of each comment .", "entities": []}, {"text": "Do your best to ignore your own opinion on the substantive idea or claim made in the comment when answering the questions .", "entities": []}, {"text": "\u2022Please be sure to read the full text of the comment before answering the questions .", "entities": []}, {"text": "Sometimes the part of a comment which displays one or more of the attributes you will be asked about , appears close to the end of the comment .", "entities": []}, {"text": "1 . Healthy Online Conversations : What are the characteristics of a healthy conversation ?", "entities": []}, {"text": "\u2022Posts and comments are made in good faith \u2022Posts and comments are not overly hostile , and are not destructive \u2022The comments in the conversation generally invite engagement", "entities": []}, {"text": "\u2022The conversation may include robust engagement and debate\u2022The conversation is generally focused on substance and ideas", "entities": []}, {"text": "A healthy conversation does not necessarily require all posts and comments to be :", "entities": []}, {"text": "\u2022 friendly \u2022 grammatically correct \u2022", "entities": []}, {"text": "well constructed or well structured \u2022 sanitized and free of any vulgarity \u2022 intellectual or substantive With this in mind please answer the following question : Do you think this comment has a place in a healthy online conversation ?", "entities": []}, {"text": "2.A comment is sarcastic if it uses irony in order to mock or convey contempt , or if its intended meaning is different from what is literally said .", "entities": []}, {"text": "Sarcasm can be used playfully , or harshly .", "entities": []}, {"text": "Note : Not all humour ( or nastiness ) is sarcastic .", "entities": []}, {"text": "Is this comment sarcastic ?", "entities": []}, {"text": "3.Does this comment make a generalisation about a speci\ufb01c group of people ?", "entities": []}, {"text": "4.If", "entities": []}, {"text": "yes , would a member of that group feel that the generalisation is unfair ?", "entities": []}, {"text": "5 . Is this comment needlessly hostile ?", "entities": []}, {"text": "6.Is the intention of this comment to insult , antagonize , provoke , or troll other users ?", "entities": []}, {"text": "7.A comment with a condescending or patronising tone will generally assume an attitude of superiority , and imply that the other commenter(s ) is ignorant , child - like , naive , or unintelligent .", "entities": []}, {"text": "Such comments will usually imply that the other commenter should n\u2019t be taken seriously .", "entities": []}, {"text": "Is this comment condescending and/or patronising ?", "entities": []}, {"text": "8.A comment is dismissive if it rejects or ridicules another comment without good reason , or tries to push another commenter and their ideas out of the conversations .", "entities": []}, {"text": "Note : A comment which expresses disagreement is not necessarily dismissive .", "entities": []}, {"text": "Is this comment dismissive ?", "entities": []}]