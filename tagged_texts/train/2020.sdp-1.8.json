[{"text": "Proceedings of the First Workshop on Scholarly Document Processing , pages 72\u201380 Online , November 19 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P1772Learning CNF Blocking for Large - scale Author Name Disambiguation Kunho Kimy\u0003 , Athar Se\ufb01dz , C. Lee Gilesz yMicrosoft Corporation , Redmond , WA , USA zThe Pennsylvania State University , University Park , PA , USA kuki@microsoft.com , azs5955@psu.edu ,", "entities": []}, {"text": "clg20@psu.edu", "entities": []}, {"text": "Abstract Author name disambiguation ( AND ) algorithms identify a unique author entity record from all similar or same publication records in scholarly or similar databases .", "entities": []}, {"text": "Typically , a clustering method is used that requires calculation of similarities between each possible record pair .", "entities": []}, {"text": "However , the total number of pairs grows quadratically with the size of the author database making such clustering dif\ufb01cult for millions of records .", "entities": []}, {"text": "One remedy is a blocking function that reduces the number of pairwise similarity calculations .", "entities": []}, {"text": "Here , we introduce a new way of learning blocking schemes by using a conjunctive normal form ( CNF ) in contrast to the disjunctive normal form ( DNF ) .", "entities": []}, {"text": "We demonstrate on PubMed author records that CNF blocking reduces more pairs while preserving high pairs completeness compared to the previous methods that use a DNF and that the computation time is signi\ufb01cantly reduced .", "entities": []}, {"text": "In addition , we also show how to ensure that the method produces disjoint blocks so that much of the AND algorithm can be ef\ufb01ciently paralleled .", "entities": []}, {"text": "Our CNF blocking method is tested on the entire PubMed database of 80 million author mentions and ef\ufb01ciently removes 82.17 % of all author record pairs in 10 minutes .", "entities": []}, {"text": "1 Introduction Author name disambiguation ( AND ) refers to the problem of identifying each unique author entity record from all publication records in scholarly databases ( Ferreira et al . , 2012 ) .", "entities": []}, {"text": "It is also an important preprocessing step for a variety of problems .", "entities": []}, {"text": "One example is processing author - related queries properly ( e.g. , identify all of a particular author \u2019s \u0003Work done while the author was at Pennsylvania State University A shorter preprint version of this paper was published at arXiv ( Kim et", "entities": [[39, 40, "DatasetName", "arXiv"]]}, {"text": "al . , 2017)publications ) in a digital library search engine .", "entities": []}, {"text": "Another is to calculate author - related statistics such as an h - index , and collaboration relationships between authors .", "entities": []}, {"text": "Typically , a clustering method is used to calculate AND .", "entities": []}, {"text": "Such clustering calculates pairwise similarities between each possible pairs of records that then determines whether each pair should be in the same cluster .", "entities": []}, {"text": "Since the number of possible pairs in a database with the number of records nis n(n\u00001)=2 , it grows as O ( n2 ) .", "entities": []}, {"text": "Sincencan be millions of authors in some databases such as PubMed , AND algorithms need methods that scale , such as a blocking function ( Christen , 2012 ) .", "entities": []}, {"text": "The blocking function produces a reduced list of candidate pairs , and only the pairs on the list are considered for clustering .", "entities": []}, {"text": "Blocking usually consists of blocking predicates .", "entities": []}, {"text": "Each predicate is a logical binary function with a combination of an attribute and a similarity criterion .", "entities": []}, {"text": "One example can be exact match of the last name .", "entities": [[4, 6, "MetricName", "exact match"]]}, {"text": "A simple but effective way of blocking involves manually selecting the predicates , with respect to the data characteristics .", "entities": []}, {"text": "Much recent work on large - scale AND uses a heuristic that is theinitial match of \ufb01rst name andexact match of last name ( Torvik and Smalheiser , 2009 ; Liu et al . , 2014 ; Levin et al . , 2012 ;", "entities": []}, {"text": "Kim et al . , 2016 ) .", "entities": []}, {"text": "Although this gives reasonable completeness , it can be problematic when the database is extremely large , such as the author mentions in CiteSeerX ( 10 M publications , 32 M authors ) , PubMed ( 24 M publications , 88 M authors ) , and Web of Science ( 45 M publications , 163 M authors)1 .", "entities": []}, {"text": "The blocking results on PubMed using this heuristic are shown in Table 1 .", "entities": []}, {"text": "Note that most of the block sizes are less than 100 names , but a few blocks are extremely large .", "entities": []}, {"text": "Since the number 1Numbers were as of 2016 .", "entities": []}, {"text": "73Table 1 : Block Size Distribution of PubMed author mentions using the simple blocking heuristic .", "entities": []}, {"text": "Block Size Frequency Percentage 2\u0014n<10 1,586,677 59.91 % 10\u0014n<100 910,272 34.37 % 100\u0014n<1000 144,361 5.45 % 1000\u0014n<10000 6,998 0.26 % 10000\u0014n<50000 184 0.01 % n\u001550000 9<0.01 % Total 2,648,501 100.0 % of pairs grows quadratically , those few blocks can dominate the computation time .", "entities": []}, {"text": "This imbalance of the block size is due to the popularity of certain surnames , especially Asian names ( Kim et al . , 2016 ) .", "entities": []}, {"text": "To make matters worse , this problem increases in time , since the growth rates of publication records are rapidly increasing .", "entities": []}, {"text": "To improve the blocking , there has been work on learning the blocking ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ; Cao et al . , 2011 ; Kejriwal and Miranker , 2013 ; Das Sarma et al . , 2012 ; Fisher et al . , 2015 ) .", "entities": []}, {"text": "These can be categorized into two different methods .", "entities": []}, {"text": "One is a disjoint blocking , where each block is separated so each record belongs to a single block .", "entities": []}, {"text": "Another is non - disjoint blocking , where some blocks have shared records .", "entities": []}, {"text": "Each has advantages .", "entities": []}, {"text": "Disjoint blocking can make the clustering step easily parallelized , while non - disjoint blocking often produces smaller blocks .", "entities": []}, {"text": "and also has more degrees of freedom from which to select the similarity criterion .", "entities": []}, {"text": "Here , we propose to learn a non - disjoint blocking with a conjunctive normal form ( CNF ) .", "entities": []}, {"text": "Our main contributions are : \u000fPropose a CNF blocking , which reduces more pairs compared to DNF blocking , in order to achieve a large number of pairs completeness .", "entities": []}, {"text": "This also reduces the processing time , which bene\ufb01ts various applications such as online disambiguation , author search , etc . \u000fExtend the method to produce disjoint blocks , so that the AND clustering step can be easily parallelized .", "entities": []}, {"text": "\u000fCompare different gain functions , which are used to \ufb01nd the best blocking predicates for each step of learning .", "entities": []}, {"text": "Previous work is discussed in the next session .", "entities": []}, {"text": "This is followed by problem de\ufb01nition .", "entities": []}, {"text": "Next , wedescribe learning of CNF blocking and how to use it to ensure the production of disjoint blocks .", "entities": []}, {"text": "Next , we evaluate our methods on the PubMed dataset .", "entities": []}, {"text": "Finally , the last section consists of a summary work with possible future directions .", "entities": []}, {"text": "2 Related Work Blocking has been widely studied for record linkage and entity disambiguation .", "entities": [[12, 14, "TaskName", "entity disambiguation"]]}, {"text": "Standard blocking is the simplest but most widely used method ( Fellegi and Sunter , 1969 ) .", "entities": []}, {"text": "It is done by considering only pairs that meet all blocking predicates .", "entities": []}, {"text": "Another is the sorted neighborhood approach ( Hern \u00b4 andez and Stolfo , 1995 ) which sorts the data by a certain blocking predicate , and forms blocks with pairs of those records within a certain window .", "entities": []}, {"text": "Yan et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2007 ) further improved this method to adaptively select the size of the window .", "entities": []}, {"text": "Aizawa and Oyama ( 2005 ) introduced a suf\ufb01x array - based indexing method , which uses an inverted index of suf\ufb01xes to generate candidate pairs .", "entities": []}, {"text": "Canopy clustering ( McCallum et al . , 2000 ) generates blocks by clustering with a simple similarity measure and use loose & tight thresholds to generate overlapping clusters .", "entities": []}, {"text": "Recent surveys ( Christen , 2012 ; Papadakis et al . , 2016 , 2020 ) imply that there are no clear winners and proper parameter tuning is required for a speci\ufb01c task .", "entities": []}, {"text": "Much work optimized the blocking function for standard blocking .", "entities": []}, {"text": "The blocking function is typically presented with a logical formula with blocking predicates .", "entities": []}, {"text": "Two studies focused on learning a disjunctive normal form ( DNF ) blocking ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ) were published in the same year .", "entities": []}, {"text": "Making use of manually labeled record pairs , they used a sequential covering algorithm to \ufb01nd the optimal blocking predicates in a greedy manner .", "entities": []}, {"text": "Additional unlabeled data was used to estimate the reduction ratio of their cost function ( Cao et al . , 2011 ) while an unsupervised algorithm was used to automatically generate labeled pairs with rule - based heuristics used to learn DNF blocking ( Kejriwal and Miranker , 2013 ) .", "entities": []}, {"text": "All the work above proposed to learn nondisjoint blocking because of the logical ORterms in the DNF .", "entities": []}, {"text": "However , other work learns the blocking function with a pure conjunction , to ensure the generation of disjoint blocks .", "entities": []}, {"text": "Das et al .", "entities": []}, {"text": "( 2012 ) learns a conjunctive blocking tree , which has different blocking predicates for each branch of the", "entities": []}, {"text": "74tree .", "entities": []}, {"text": "Fisher et al .", "entities": []}, {"text": "( 2015 ) produces blocks with respect to a size restriction , by generating candidate blocks with a list of prede\ufb01ned blocking predicates and then performs a merge and split to generate the block with the desired size .", "entities": []}, {"text": "Our work proposes a method for learning a nondisjoint blocking function in a conjunctive normal form ( CNF ) .", "entities": []}, {"text": "Our method is based on a previous CNF learner(Mooney , 1995 ) , which uses the fact that a CNF can be a logical dual of a DNF . 3 Problem De\ufb01nition Our work tackles the same problem with baseline DNF blocking ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ) , but in a different way to get the optimized blocking function .", "entities": []}, {"text": "Let", "entities": []}, {"text": "R = fr1;r2;\u0001\u0001\u0001;rngbe the set of records in the database , where nis the number of records .", "entities": []}, {"text": "Each recordrhaskattributes , and Abe the attribute setA = fa1 : a2;\u0001\u0001\u0001;akg .", "entities": []}, {"text": "A blocking predicate pis a combination of an attribute aand a similarity function sde\ufb01ned toa .", "entities": []}, {"text": "An example of s is exact string match of a. A blocking predicate can be seen as a logical binary function applied to each pair of records , so p(rx;ry ) = f0;1 g , where rx;ry2R. A blocking function fis a boolean logic formula consisting with blocking predicates p1;p2;\u0001\u0001\u0001;pn , and each predicate is connected with either conjunction ^or disjunction _ .", "entities": []}, {"text": "An example isfexample = ( p1^p2)_p3 .", "entities": []}, {"text": "Since it is made up of blocking predicates , f(rx;ry ) = f0;1 g for allrx;ry2R. The goal is to \ufb01nd an optimal blocking function f\u0003that covers a minimum number of record pairs while missing up to a fraction \" of total number of matching record pairs .", "entities": []}, {"text": "To formalize it , f\u0003= argmin fX ( rx;ry)2Rf(rx;ry ) such that\u0015(1\u0000\")\u0002jR+j(1 ) whereR+is set of matching record pairs .", "entities": []}, {"text": "4 Learning the Blocking Function Here , we \ufb01rst brie\ufb02y review DNF blocking and then introduce our CNF blocking function .", "entities": []}, {"text": "This section describes the gain functions that select an optimal predicate term for each step in the CNF learner .", "entities": []}, {"text": "Finally , we discuss an extension that ensures the production of disjunctive blocks .", "entities": []}, {"text": "Algorithm 1 DNF Blocking 1 : function LEARN CONJTERMS ( L;P;p;k ) 2 : LetPos be set of positive samples in L 3 : LetNeg be set of negative samples in L 4 : Terms fpg 5 : CurTerm p 6 : i 1 7 : whilei < k do 8 : Findpi2Pthat maximizes gain function C ALCGAIN(Pos;Neg;CurTerm ^pi ) 9 : CurTerm CurTerm^pi 10 : AddCurTerm toTerms 11 : i i+ 1 12 : end while 13 : returnTerms 14 : end function 15 : 16 : function LEARN DNF(L;P;k ) 17 : CandTerms \u001e  18 : forp2Pdo 19 : Terms LEARN CONJ(L;P;p;k ) 20 : CandTerms CandTerms [ Terms 21 : end for 22 : LetPos be set of positive samples in L 23 : LetNeg be set of negative samples in L 24 : DNF \u001e  25 : whilejPosj>\"\u0002jPosjdo 26 : FindT2CandTerms that maximizes gain function CALCGAIN(Pos;Neg;T ) 27 : ifCALCGAIN(Pos;Neg;t ) > 0then 28 : DNF DNF_T 29 :", "entities": [[35, 36, "MethodName", "fpg"]]}, {"text": "LetPosCov be alll2Pos that satis\ufb01esT 30 : LetNegCov be alll2Neg that satis\ufb01esT 31 : Pos Pos\u0000PosCov 32 : Neg Neg\u0000NegCov 33 : else 34 : break loop 35 : end if 36 : end while 37 : returnDNF 38 : end function", "entities": []}, {"text": "754.1 DNF Blocking DNF blocking was originally proposed by ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ) .", "entities": []}, {"text": "Given labeled pairs , these methods attempt to learn the blocking function in the form of a DNF , the disjunction ( logical OR ) of conjunction ( logical AND ) terms .", "entities": []}, {"text": "Learning DNFs is known to be a NP - hard problem ( Bilenko et al . , 2006 ) .", "entities": []}, {"text": "Thus , an approximation algorithm was used to learn k - DNF blocking by using a sequential covering algorithm .", "entities": []}, {"text": "k - DNF means each conjunction term has , at most , kpredicates .", "entities": []}, {"text": "Algorithm 1 shows the process of DNF blocking .", "entities": []}, {"text": "Function LEARN DNF in lines 1638 is the main part of the algorithm .", "entities": []}, {"text": "It has 3 inputs which are the Llabeled sample pairs , Pblocking predicates , and kparameters of maximum predicates considered for each conjunction term .", "entities": []}, {"text": "First , the algorithm selects a set of candidate conjunction terms with at most kpredicates .", "entities": []}, {"text": "For each predicatep , it generates kcandidate conjunction terms with the highest gain function .", "entities": []}, {"text": "Using the candidate terms , the algorithm learns the blocking function by using a sequential covering algorithm .", "entities": []}, {"text": "It sequentially selects a conjunction term , from the set of candidates , that has the maximum gain value on the remaining samples , and attaches it with logical ORto the DNF term .", "entities": []}, {"text": "In each step , all samples covered by the selected conjunction term are removed .", "entities": []}, {"text": "This process repeats until it covers the desired minimum amount of positive samples , or there is no candidate term that can further be improved .", "entities": []}, {"text": "4.2 CNF Blocking CNF blocking can be learned with a small modi\ufb01cation to DNF blocking .", "entities": []}, {"text": "CNF can be presented as the entire negation of a corresponding DNF and vice versa based on De Morgan \u2019s laws .", "entities": []}, {"text": "Using this , Mooney proposed CNF learning ( Mooney , 1995 ) , which is a logical dual of DNF learning .", "entities": []}, {"text": "This motivated our CNF blocking method .", "entities": []}, {"text": "Algorithm 2 illustrates the proposed CNF blocking and has a similar structure to algorithm 1 .", "entities": []}, {"text": "Instead of running a sequential covering algorithm to cover all positive samples , CNF blocking tries to cover all negative samples using negated blocking predicates .", "entities": []}, {"text": "In other words , a DNF formula is learned that is consistent with a negated predicate , which we designate negated DNF ( NegDNF ) .", "entities": []}, {"text": "NegP is the negation of each predicate pinP. LEARN CNF gets 3 inputs ,", "entities": []}, {"text": "where Lare labeledAlgorithm 2 CNF Blocking 1 : function LEARN NEGCONJTERMS", "entities": []}, {"text": "( L;NegP;p;k ) 2 : LetPos be set of positive samples in L 3 : LetNeg be set of negative samples in L 4 : Terms fpg 5 : CurTerm p 6 : i 1 7 : whilei < k do 8 : Findpi2NegP that maximizes gain function CALCNEGGAIN(Pos;Neg;CurTerm ^pi ) 9 : CurTerm CurTerm^pi 10 : AddCurTerm toTerms 11 : i i+ 1 12 : end while 13 : returnTerms 14 : end function 15 : 16 : function LEARN CNF(L;P;k ) 17 : CandTerms \u001e  18 : LetNegP is negation of each p2P 19 : forp2NegP do 20 : Terms LEARN NEGCONJ(L;NegP;p;k ) 21 : CandTerms CandTerms [ Terms 22 : end for 23 : LetPos be set of positive samples in L 24 : LetNeg be set of negative samples in L 25 : NegDNF \u001e  26 : whilejPosj>(1\u0000\")\u0002jPosjdo 27 : FindT2CandNegTerms that maximizes gain function CALCNEGGAIN(Pos;Neg;Term )", "entities": [[26, 27, "MethodName", "fpg"]]}, {"text": "28 : ifCALCNEGGAIN(Pos;Neg;T ) > 0", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "then 29 : NegDNF NegDNF_T 30 : LetPosCov be alllinPos that satis\ufb01esT 31 : LetNegCov be alllinNeg that satis\ufb01esT 32 : Pos Pos\u0000PosCov 33 : Neg Neg\u0000NegCov 34 : else 35 : break loop 36 : end if 37 : end while 38 : CNF :( NegDNF ) 39 : returnCNF 40 : end function", "entities": []}, {"text": "76sample pairs , Pare blocking predicates , and kis maximum number of predicates in each term .", "entities": []}, {"text": "The algorithm \ufb01rst generates a set of negated candidate conjunction term Terms from allpin NegP ( line 19 - 22 ) .", "entities": []}, {"text": "A dual of the original gain function CALCNEGGAIN selects a predicate for generating a negated candidate conjunction .", "entities": []}, {"text": "Then , as in DNF blocking , the sequential covering algorithm is used to learn the negated DNF formula ( line 26 - 37 ) , which iteratively adds a negated conjunction term until it covers the desired number of samples .", "entities": [[38, 41, "HyperparameterName", "number of samples"]]}, {"text": "We select a negated conjunction term with a gain function , CALCNEGGAIN .", "entities": []}, {"text": "Also , note that the termination condition of the loop ( line 26 ) is when\"of total positive samples are covered with the learnedNegDNF .", "entities": []}, {"text": "This ensures that we miss less than\"of the total number of positive samples in the \ufb01nal CNF formula .", "entities": []}, {"text": "After getting the \ufb01nal NegDNF , it is negated to get the desired CNF .", "entities": []}, {"text": "4.3 Gain Function The gain function estimates the bene\ufb01t of adding a speci\ufb01c term to the learned formula .", "entities": []}, {"text": "It is used in two different places in the algorithm - when choosing the conjunction candidates ( line 8) and when choosing a term from the candidates for each iteration ( line 27 - 28 ) .", "entities": []}, {"text": "Previous methods have proposed different gain functions .", "entities": []}, {"text": "Here we describe each and compare the results in the experiments .", "entities": []}, {"text": "P , Nis the total number of positive and negative samples , andp , nis the number of remaining positive and negative samples covered by the term .", "entities": []}, {"text": "4.3.1 Information Gain Originally from Mooney \u2019s CNF learner ( 1995 ) , it is the dual of the information gain of a DNF learner gain", "entities": []}, {"text": "CNF = n\u0002\u0014 log\u0012n n+p\u0013 \u0000log\u0012N N+P\u0013\u0015 : ( 2 ) 4.3.2 Ratio Between Positive and Negative Samples Covered Bilenko et al .", "entities": []}, {"text": "( 2006 ) used this for DNF blocking .", "entities": []}, {"text": "It calculates the ratio between the number of positives and the number of negatives covered .", "entities": []}, {"text": "For CNF learning , we use its dual gain", "entities": []}, {"text": "CNF = n p : ( 3 ) 4.3.3 Reduction Ratio Michaelson and Knoblock ( 2006 ) used terms with the maximum reduction ratio ( RR ) .", "entities": [[25, 26, "DatasetName", "RR"]]}, {"text": "In addition , Algorithm 3 Disjoint CNF Blocking 1 : function DISJOINT CNF(L;P disjoint;Pfull;k ) 2 : Conj LEARN CNF ( L;P disjoint;1 ) 3 : LetL0be set ofl2Lsatis\ufb01esConj 4 : CNF LEARN CNF ( Lremain;Pfull;k ) 5 : Blocks ApplyConj to whole data 6 : forBlock2Blocks do 7 : LetL00bel2Block that satis\ufb01es CNF 8 : Consider pairs in L00only for clustering 9 : end for 10 : end function they \ufb01lter out all terms with pairwise completeness ( PC ) below threshold t.", "entities": []}, {"text": "We use the dual of the original function used as a CNF , which is now gain CNF =( p+n P+Nifn N > t 0 otherwise:(4 ) 4.4", "entities": [[24, 25, "DatasetName", "0"]]}, {"text": "Learning Disjoint Blocks Disjoint blocking functions generate blocks for each record that resides in a single block ; thus such blocks are mutually exclusive .", "entities": []}, {"text": "It has the advantage that parallelization can be performed ef\ufb01ciently after applying the blocking by running processes for each blocks separately .", "entities": []}, {"text": "A blocking function is disjoint if and only if it satis\ufb01es the following conditions : 1 ) it only consists of pure conjunction ( logical AND ) , 2 ) all predicates use non - relative similarity measures .", "entities": []}, {"text": "That is , measures that compare the absolute value of blocking key , e.g. exact match of \ufb01rst ncharacters .", "entities": [[14, 16, "MetricName", "exact match"]]}, {"text": "DNF and CNF blocking are both non - disjoint blocking due to the condition 1 above .", "entities": []}, {"text": "We introduce a simple extension to ensure our CNF blocking can produce disjoint blocks .", "entities": []}, {"text": "This is done by \ufb01rst producing two blocking functions .", "entities": []}, {"text": "The \ufb01rst function learns a blocking function with only conjunctions based on our CNF blocking method using k= 1 and a limited set of predicates with nonrelative similarity measures .", "entities": []}, {"text": "Then , CNF blocking is learned with our k - CNF method with the whole set of predicates for pairs remaining after applying 1 - CNF ( conjunction of single attributes ) .", "entities": []}, {"text": "We \ufb01rst apply the 1 - CNF to the whole database to produce disjoint blocks .", "entities": []}, {"text": "Then for each block , we apply the second k - CNF blocking function to \ufb01lter out pairs not satis\ufb01es the k - CNF function .", "entities": []}, {"text": "This is similar to applying a \ufb01lter as in Gu and Baxter", "entities": []}, {"text": "77Table 2 : Summary of PubMed Benchmark Dataset # Authors # Mentions # Total Pairs # Matched Pairs 214 3,964 7,854,666 51,052 ( 2004 ) and Khabsa et al . ( 2015 )", "entities": []}, {"text": ".", "entities": []}, {"text": "While they use a heuristic , our method automatically learns the optimal one .", "entities": []}, {"text": "Note that this method still produces a CNF since it combines conjunction terms and k - CNF with logical AND .", "entities": []}, {"text": "5 Experiments 5.1 Benchmark Dataset", "entities": []}, {"text": "We use the PubMed to evaluate these methods .", "entities": []}, {"text": "PubMed is a public large - scale scholarly database maintained by the National Center for Biotechnology Information ( NCBI ) at the National Library of Medicine ( NLM ) .", "entities": []}, {"text": "We use NIH principal investigator ( PI ) data for evaluation , which include PI IDs and corresponding publications .", "entities": []}, {"text": "We randomly picked 10 names from the most frequent ones in the dataset and manually veri\ufb01ed that all publications belong to each PI .", "entities": []}, {"text": "The set of names include C * Lee , J * Chen , J * Smith , M * Johnson , M * Miller , R * Jones , S * Kim , X * Yang , Y * Li , Y * Wang , where C * means any name starts with C. Table 2 shows the statistics of the dataset .", "entities": []}, {"text": "Experiments are done with 5 - fold cross validation .", "entities": []}, {"text": "5.2 Methodology 5.2.1 Evaluation Metrics We evaluate our CNF blocking with reduction ratio ( RR ) , pairs completeness ( PC ) , and F - measure .", "entities": [[14, 15, "DatasetName", "RR"], [24, 27, "MetricName", "F - measure"]]}, {"text": "These metrics are often used to evaluate blocking methods .", "entities": []}, {"text": "Those metrics can be calculated as follows : RR= 1\u0000p+n P+N ; ( 5 ) PC = p P ; ( 6 ) F=2\u0002RR\u0002PC RR+PC : ( 7 ) whereP , Nare the numbers of positive and negative samples , and p , nare the numbers of positive and negative samples covered with the blocking function .", "entities": []}, {"text": "RR measures the ef\ufb01ciency of the blocking function , PC measures the quality of the blocking function .", "entities": [[0, 1, "DatasetName", "RR"]]}, {"text": "F is the harmonic mean of RR and PC.Table 3 : Blocking Predicates Used for Learning NonDisjoint Blocking Function Blocking Key Similarity Criterion First Name exact;first ( n);last ( n);compatible Last Name exact;first ( n);last ( n);compatible Middle Name exact;first", "entities": [[6, 7, "DatasetName", "RR"]]}, {"text": "( n);last ( n);compatible Title cos Af\ufb01liation exact;cos;compatible Coauthor cos Order order Year exact;digit;diff", "entities": [[8, 9, "DatasetName", "Coauthor"]]}, {"text": "Venue exact;cos 5.2.2 Blocking Predicates Used We \ufb01rst de\ufb01ne the similarity criterion used for the experiments .", "entities": []}, {"text": "We observed an important characteristic of the data : some attributes are empty ( e.g. year : 7.8 % , af\ufb01liation : 81.1 % ) or have only partial information ( 54.5 % has only initials for the \ufb01rst name ) .", "entities": []}, {"text": "To deal with this , we add compatible to those blocking keys .", "entities": []}, {"text": "Below is brief explanation of each similarity criterion .", "entities": []}, {"text": "\u000fexact : Exact match .", "entities": [[2, 4, "MetricName", "Exact match"]]}, {"text": "\u000ffirst ( n);last ( n ): First / Last ncharacter match , where nis an integer .", "entities": []}, {"text": "We check f1;3;5;7gfor name attributes .", "entities": []}, {"text": "\u000forder : AssignsTrue if both records are \ufb01rst authors , last authors , or non-\ufb01rst and non - last authors .", "entities": []}, {"text": "\u000fdigit ( n ): Firstndigit match .", "entities": []}, {"text": "We check f1;2;3gfor year .", "entities": []}, {"text": "\u000fcompatible :", "entities": []}, {"text": "True if at least one of the records are empty ( Eq . 8) .", "entities": []}, {"text": "If the key is name , it also checks if the initial matches if one of the records has only initial .", "entities": []}, {"text": "compatible ( A;B ) =(", "entities": []}, {"text": "True if at least one is empty exact ( A;B)otherwise ( 8) \u000fcos : Cosine distance of TF - IDF bag - ofwords vector .", "entities": []}, {"text": "We check with threshold f0:2;0:4;0:6;0:8 g. \u000fdiff : Year difference .", "entities": []}, {"text": "We use the threshold f2;5;10 g. Using those similarity measures , We de\ufb01ne two different sets of blocking predicates .", "entities": []}, {"text": "Table 3 shows", "entities": []}, {"text": "78 0.90 0.92 0.94 0.96 0.98 1.00 Pairs Completeness0.700.750.800.850.900.95Reduction Ratio Information Gain PosNeg Ratio Reduction RatioFigure 1 : Gain Functions for PC \u2013 RR where PosNeg Ratio is the ratio between positive and negative samples covered .", "entities": [[23, 24, "DatasetName", "RR"]]}, {"text": "blocking predicates used for non - disjoint blocking .", "entities": []}, {"text": "Disjoint blocking requires the use of predicates with non - relative similarity measures to ensure blocks are mutually exclusive .", "entities": []}, {"text": "For disjoint blocking , we use the set of blocking predicates excluding the ones with the relative similarity measures ( exact , compatible , diff ) in Table 3 .", "entities": []}, {"text": "5.2.3 Parameter Setting The parameter \" is used to vary the PC .", "entities": []}, {"text": "We tested values in [ 0;1]to get the PC \u2013 RR curve .", "entities": [[10, 11, "DatasetName", "RR"]]}, {"text": "kis selected experimentally to calculate the maximum reachable F - measure .", "entities": [[8, 11, "MetricName", "F - measure"]]}, {"text": "We use k= 3 for further experiments .", "entities": []}, {"text": "5.3 Experiments 5.3.1 Gain Function Figure 1 shows the PC \u2013 RR curve tested on three different gain functions .", "entities": [[11, 12, "DatasetName", "RR"]]}, {"text": "Blocking usually requires a high PC , so that we do not lose matched pairs after it is applied .", "entities": []}, {"text": "As such , we focused on experiments with high PC values .", "entities": []}, {"text": "As we can see from the results , information gain has highest RR overall .", "entities": [[12, 13, "DatasetName", "RR"]]}, {"text": "Thus , we use it as the gain function for the rest of the experiments .", "entities": []}, {"text": "5.3.2 Non - disjoint CNF Blocking We compare non - disjoint CNF blocking with the DNF blocking ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ) and canopy clustering ( McCallum et al . , 2000 ) .", "entities": []}, {"text": "We used the set of Jaro \u2013 Winkler distance attributes for canopy clustering .", "entities": []}, {"text": "Figure 2 shows the PC \u2013 RR curve for each method .", "entities": [[6, 7, "DatasetName", "RR"]]}, {"text": "Both CNF and DNF were better than canopy clustering , as was shown in Bilenko et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2006 ) .", "entities": []}, {"text": "CNF and DNF results are comparable for lower PC values .", "entities": []}, {"text": "However , for high PC ( > 0:9 ) values , CNF has a better RR .", "entities": [[15, 16, "DatasetName", "RR"]]}, {"text": "We also tested another dataset used 0.83 0.85 0.88 0.90 0.93 0.95 0.98 1.00 Pairs Completeness0.550.600.650.700.750.800.850.900.951.00Reduction Ratio CNF Blocking DNF Blocking Canopy ClusteringFigure 2 : PC \u2013 RR for non - disjoint blocking methods in ( Khabsa et al . , 2015 ) .", "entities": [[27, 28, "DatasetName", "RR"]]}, {"text": "For PC=0.99 , RR for CNF blocking was 0.882 while DNF blocking was 0.745 .", "entities": [[3, 4, "DatasetName", "RR"]]}, {"text": "We believe this is due to certain characteristics of scholarly databases .", "entities": []}, {"text": "As discussed on the previous section , some attributes are empty for some records .", "entities": []}, {"text": "DNF learns a blocking function by adding conjunction terms to gradually cover positive pairs .", "entities": []}, {"text": "Although the proposed similarity criterioncompatible could catch positive pairs with empty attributes , it allows many negative pairs to pass the criterion , which makes the RR low .", "entities": [[26, 27, "DatasetName", "RR"]]}, {"text": "On the other hand , CNF learns a blocking function to cover ( and \ufb01lter out ) negative pairs gradually .", "entities": []}, {"text": "Negative pairs are much more obvious to de\ufb01ne ( pairs with different values ) , which makes the CNF more effective .", "entities": []}, {"text": "Another advantage of using CNF is the processing time .", "entities": []}, {"text": "Fast processing time to apply blocking is important for some applications , one example is when we do a online disambiguation ( Khabsa et al . , 2015 ) , another is to do an author search which requires to \ufb01nd the relevant cluster quickly ( Kim et al . , 2018 ) .", "entities": []}, {"text": "We measured the average processing time of applying each blocking method at high PC ( PC=0.99 ) , CNF blocking , DNF blocking , canopy clustering took 1.39s , 2.09s , 0.44s respectively .", "entities": []}, {"text": "Canopy clustering was the fastest but generally we saw from the Figure 2 that its RR is much lower in high PC .", "entities": [[15, 16, "DatasetName", "RR"]]}, {"text": "CNF blocking has a faster processing time compared to DNF blocking .", "entities": []}, {"text": "This is because CNF is composed with conjunctions , so it can quickly reject pairs that are not consistent with any terms .", "entities": []}, {"text": "On the other hand , DNF consists of disjunction terms , so each pair should check all terms to make the decision .", "entities": []}, {"text": "Learned CNF is also simpler than DNF .", "entities": []}, {"text": "Learned CNF at this level is as below ( fn , mn , ln is \ufb01rst , middle , last name respectively ):", "entities": []}, {"text": "79 0.88 0.90 0.92 0.94 0.96 0.98 1.00 Pairs Completeness0.600.650.700.750.800.850.900.951.00Reduction Ratio Disjoint CNF Clustering - based ( Fisher et al . 2015 )", "entities": []}, {"text": "Conjunction Nondisjoint CNFFigure 3 : PC \u2013 RR for disjoint blocking methods f(fn,\ufb01rst(5))_(fn , compatible)_(coauth , cos(0.8))g ^f(ln , exact)g ^f(mn , compatible)g ^f((fn,\ufb01rst(3))_(fn , compatible))g And learned DNF is : f((coauth , cos(0.8))^(ln , exact)^(mn , compatible))g _ f((venue , cos(0.4))^(mn,\ufb01rst(1)^(fn , compatible)g _ f(fn , compatible)^(mn,\ufb01rst(1)^(ln , exact)g _ f((venue , cos(0.8))^(fn , exact)g", "entities": [[7, 8, "DatasetName", "RR"]]}, {"text": "In addition , we observed that proposed compatible predicate was frequently used in our result .", "entities": []}, {"text": "This shows the effectiveness of compatible in dealing with the empty value .", "entities": []}, {"text": "5.3.3 Extension to Disjoint CNF", "entities": []}, {"text": "Blocking We evaluate our extension to disjoint blocks with CNF blocking .", "entities": []}, {"text": "We compare the blocking learned with a pure conjunction , our proposed method , and the method of Fisher et al . ( 2015 ) .", "entities": []}, {"text": "Figure 3 shows the reduction ratio pair completion ( RR \u2013 PC ) curve for each method .", "entities": [[9, 10, "DatasetName", "RR"]]}, {"text": "We also plot the original non - disjoint CNF blocking for comparison .", "entities": []}, {"text": "We see that our proposed disjoint CNF blocking is the best amongst all disjoint methods .", "entities": []}, {"text": "Fisher \u2019s method produced nearly uniformsized blocks , but had limitations in reaching a high PC and had a generally lower RR compared to our method .", "entities": [[21, 22, "DatasetName", "RR"]]}, {"text": "Disjoint CNF did n\u2019t perform as well when compared to non - disjoint CNF because it is forced to use a pure conjunction on its \ufb01rst step .", "entities": []}, {"text": "However , this simple extension easily helps parallelize the clustering process , so that the algorithm scales better .", "entities": []}, {"text": "Testing our method to all of PubMed , 82.17 % of the pairs are created in 10.5 min with 24 threads .", "entities": []}, {"text": "Parallelization is important for disambiguation algorithms to scale to PubMed size scholarly databases ( Khabsa et al . , 2014 ) .", "entities": []}, {"text": "Processing time for disjoint CNF blockingcomparable to the original non - disjoint CNF blocking .", "entities": []}, {"text": "The learned disjoint CNF is : f(fn,\ufb01rst(1))g^f ( ln , exact)g^ f(fn , compatible)_(coauth , cos(0.8))g^ f(mn , compatible)g First two terms are from 1 - CNF , and others from 3 - CNF learner .", "entities": []}, {"text": "We also tested this function to the whole PubMed .", "entities": []}, {"text": "6 Conclusion We show how to learn an ef\ufb01cient blocking function with a conjunctive normal form ( CNF ) of blocking predicates .", "entities": []}, {"text": "Using CNF as a negation of the corresponding disjunctive normal form ( DNF ) of predicates ( Mooney , 1995 ) , our method is a logical dual of existing DNF blocking methods ( Bilenko et al . , 2006 ; Michelson and Knoblock , 2006 ) .", "entities": []}, {"text": "We \ufb01nd that our method reduces more pairs for a large number of target pairs completeness and has a faster run time .", "entities": []}, {"text": "We devise an extension that ensures that our CNF blocking produces disjoint blocks .", "entities": []}, {"text": "Thus , the clustering process can be ef\ufb01ciently parallelized .", "entities": []}, {"text": "Future work could use multiple levels of blocking functions for processing each block ( Das Sarma et al . , 2012 ) and using linear programming to \ufb01nd an optimal CNF ( Su et al . , 2016 ) .", "entities": []}, {"text": "7 Acknowledgement We gratefully acknowledge partial support from the National Science Foundation and the National Bureau of Economic Research and useful discussions with Bruce Weinberg .", "entities": []}, {"text": "References Akiko Aizawa and Keizo Oyama .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "A fast linkage detection scheme for multi - source information integration .", "entities": []}, {"text": "In International Workshop on Challenges in Web Information Retrieval and Integration , pages 30\u201339 .", "entities": [[7, 9, "TaskName", "Information Retrieval"]]}, {"text": "Mikhail Bilenko , Beena Kamath , and Raymond J. Mooney .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Adaptive blocking : Learning to scale up record linkage .", "entities": []}, {"text": "In Proceedings of the 6th IEEE International Conference on Data Mining(ICDM\u201906 ) , pages 87\u201396 .", "entities": []}, {"text": "Yunbo Cao , Zhiyuan Chen , Jiamin Zhu , Pei Yue , ChinYew Lin , and Yong Yu . 2011 .", "entities": []}, {"text": "Leveraging unlabeled data to scale blocking for record linkage .", "entities": []}, {"text": "In Proceedings of the International Joint Conference on Arti\ufb01cial Intelligence ( IJCAI ) , volume 22 , page 2211 .", "entities": []}, {"text": "80Peter Christen .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "A survey of indexing techniques for scalable record linkage and deduplication .", "entities": []}, {"text": "IEEE Transactions on Knowledge and Data Engineering ( TKDE ) , 24(9):1537\u20131555 .", "entities": []}, {"text": "Anish Das Sarma , Ankur Jain , Ashwin Machanavajjhala , and Philip Bohannon .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "An automatic blocking mechanism for large - scale de - duplication tasks .", "entities": []}, {"text": "In Proceedings of the 21st ACM international conference on Information and knowledge management ( CIKM ) , pages 1055\u20131064 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Ivan P Fellegi and Alan B Sunter .", "entities": []}, {"text": "1969 .", "entities": []}, {"text": "A theory for record linkage .", "entities": []}, {"text": "Journal of the American Statistical Association , 64(328):1183\u20131210 .", "entities": []}, {"text": "Anderson A. Ferreira , Marcos Andr \u00b4 e Gonc \u00b8alves , and Alberto H.F. Laender .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "A brief survey of automatic methods for author name disambiguation .", "entities": []}, {"text": "Acm Sigmod Record , 41(2):15\u201326 .", "entities": [[0, 1, "DatasetName", "Acm"]]}, {"text": "Jeffrey Fisher , Peter Christen , Qing Wang , and Erhard Rahm . 2015 .", "entities": []}, {"text": "A clustering - based framework to control block sizes for entity resolution .", "entities": [[10, 12, "TaskName", "entity resolution"]]}, {"text": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 279\u2013288 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Lifang Gu and Rohan Baxter .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Adaptive \ufb01ltering for ef\ufb01cient record linkage .", "entities": []}, {"text": "In Proceedings of the 2004 SIAM International Conference on Data Mining , pages 477\u2013481 .", "entities": []}, {"text": "Mauricio A Hern \u00b4 andez and Salvatore J Stolfo .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "The merge / purge problem for large databases .", "entities": []}, {"text": "In ACM Sigmod Record , volume 24 , pages 127\u2013138 .", "entities": [[1, 2, "DatasetName", "ACM"]]}, {"text": "Mayank Kejriwal and Daniel P Miranker .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "An unsupervised algorithm for learning blocking schemes .", "entities": []}, {"text": "InProceedings of the IEEE 13th International Conference on Data Mining ( ICDM ) , pages 340\u2013349 .", "entities": []}, {"text": "Madian Khabsa , Pucktada Treeratpituk , and C. Lee Giles .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Large scale author name disambiguation in digital libraries .", "entities": []}, {"text": "In IEEE International Conference on Big Data , pages 41\u201342 .", "entities": []}, {"text": "Madian Khabsa , Pucktada Treeratpituk , and C. Lee Giles . 2015 .", "entities": []}, {"text": "Online person name disambiguation with constraints .", "entities": []}, {"text": "In Proceedings of the ACM / IEEE Joint Conference on Digital Libraries(JCDL\u201915 ) , pages 37\u201346 .", "entities": [[4, 5, "DatasetName", "ACM"]]}, {"text": "Kunho Kim , Madian Khabsa , and C. Lee Giles . 2016 .", "entities": []}, {"text": "Random forest dbscan clustering for uspto inventor name disambiguation and con\ufb02ation .", "entities": []}, {"text": "In IJCAI-16 Workshop on Scholarly Big Data : AI Perspectives , Challenges , and Ideas .", "entities": []}, {"text": "Kunho Kim , Athar Se\ufb01d , and C Lee Giles . 2017 .", "entities": []}, {"text": "Scaling author name disambiguation with cnf blocking .", "entities": []}, {"text": "arXiv preprint arXiv:1709.09657 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Kunho Kim , Athar Se\ufb01d , and C. Lee Giles .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A web service for author name disambiguation in scholarly databases .", "entities": []}, {"text": "In Proceedings of the IEEEInternational Conference on Web Services ( ICWS ) , pages 265\u2013273 .", "entities": []}, {"text": "Michael Levin , Stefan Krawczyk , Steven Bethard , and Dan Jurafsky .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Citation - based bootstrapping for large - scale author disambiguation .", "entities": []}, {"text": "Journal of the American Society for Information Science and Technology , 63(5):1030\u20131047 .", "entities": []}, {"text": "Wanli Liu , Rezarta Islamaj Do \u02d8gan , Sun Kim , Donald C Comeau , Won Kim , Lana Yeganova , Zhiyong Lu , and W John Wilbur .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Author name disambiguation for pubmed .", "entities": []}, {"text": "Journal of the Association for Information Science and Technology , 65(4):765\u2013781 .", "entities": []}, {"text": "Andrew McCallum , Kamal Nigam , and Lyle H Ungar . 2000 .", "entities": []}, {"text": "Ef\ufb01cient clustering of high - dimensional data sets with application to reference matching .", "entities": []}, {"text": "In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 169\u2013178 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Matthew Michelson and Craig A Knoblock . 2006 .", "entities": []}, {"text": "Learning blocking schemes for record linkage .", "entities": []}, {"text": "In Proceedings of the 21st AAAI Conference on Arti\ufb01cial Intelligence , pages 440\u2013445 .", "entities": []}, {"text": "Raymond J Mooney .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "Encouraging experimental results on learning cnf .", "entities": []}, {"text": "Machine Learning , 19(1):79\u201392 .", "entities": []}, {"text": "George Papadakis , Dimitrios Skoutas , Emmanouil Thanos , and Themis Palpanas . 2020 .", "entities": []}, {"text": "Blocking and \ufb01ltering techniques for entity resolution : A survey .", "entities": [[5, 7, "TaskName", "entity resolution"]]}, {"text": "ACM Computing Surveys ( CSUR ) , 53(2):1\u201342 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "George Papadakis , Jonathan Svirsky , Avigdor Gal , and Themis Palpanas . 2016 .", "entities": []}, {"text": "Comparative analysis of approximate blocking techniques for entity resolution .", "entities": [[7, 9, "TaskName", "entity resolution"]]}, {"text": "Proceedings of the VLDB Endowment , 9(9):684 \u2013 695 .", "entities": []}, {"text": "Guolong Su , Dennis Wei , Kush R Varshney , and Dmitry M Malioutov .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Learning sparse twolevel boolean rules .", "entities": []}, {"text": "In Proceedings of the IEEE 26th International Workshop on Machine Learning for Signal Processing ( MLSP ) , pages 1\u20136 .", "entities": []}, {"text": "Vetle I Torvik and Neil R Smalheiser .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Author name disambiguation in medline .", "entities": []}, {"text": "ACM Transactions on Knowledge Discovery from Data ( TKDD ) , 3(3):11 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Su Yan , Dongwon Lee , Min - Yen Kan , and Lee C Giles .", "entities": []}, {"text": "2007", "entities": []}, {"text": ".", "entities": []}, {"text": "Adaptive sorted neighborhood methods for ef\ufb01cient record linkage .", "entities": []}, {"text": "In Proceedings of the 7th ACM / IEEE - CS joint conference on Digital libraries , pages 185\u2013194 .", "entities": [[5, 6, "DatasetName", "ACM"], [9, 10, "DatasetName", "CS"]]}]