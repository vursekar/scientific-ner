[{"text": "Proceedings of NAACL - HLT 2019 , pages 4077\u20134085 Minneapolis , Minnesota , June 2 - June 7 , 2019 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics4077Benchmarking Hierarchical Script Knowledge Yonatan Bisk1Jan Buys1Karl Pichotta\u0003Yejin Choi1;2 1Paul G. Allen School of Computer Science and Engineering , University of Washington 2Allen Institute for Arti\ufb01cial Intelligence fybisk , jbuysg@cs.washington.edu Abstract Understanding procedural language requires reasoning about both hierarchical and temporal relations between events .", "entities": []}, {"text": "For example , \u201c boiling pasta \u201d is a sub - event of \u201c making a pasta dish \u201d , typically happens before \u201c draining pasta , \u201d and requires the use of omitted tools ( e.g. a strainer , sink ... ) .", "entities": []}, {"text": "While people are able to choose when and how to use abstract versus concrete instructions , the NLP community lacks corpora and tasks for evaluating if our models can do the same .", "entities": []}, {"text": "In this paper , we introduce KIDSCOOK , a parallel script corpus , as well as a cloze task which matches video captions with missing procedural details .", "entities": []}, {"text": "Experimental results show that state - of - the - art models struggle at this task , which requires inducing functional commonsense knowledge not explicitly stated in text .", "entities": []}, {"text": "1 Introduction The level of detail used in natural language communication varies : descriptive or instructive text for experts may elide over details the reader can seamlessly infer , while text for more novice audiences may be more verbose .", "entities": []}, {"text": "A given document typically adheres to a single level of verbosity suited to its presumed audience ( Grice , 1975 ) , so learning correspondences between abstract and detailed descriptions of similar concepts from text is a challenging problem .", "entities": []}, {"text": "Commonsense knowledge of how complex events decompose into stereotypical sequences of simpler events is a necessary component of a system that can automatically understand and reason about different types of discourse .", "entities": []}, {"text": "Hierarchical correspondences between abstract and detailed representations of concepts and events were an important aspect of the original formulation of scripts for natural language understanding ( Schank and \u0003Author now at Google .", "entities": [[22, 25, "TaskName", "natural language understanding"], [31, 32, "DatasetName", "Google"]]}, {"text": "Work done while unaf\ufb01liated .", "entities": []}, {"text": "1.Take the strainer with the pasta and pour the pasta into the sauce.2.Stir the pasta into sauce while it is in the pan.3.Let the pasta and sauce simmer for a few minutes .", "entities": []}, {"text": "Add pasta to the sauce t2 < latexit sha1_base64=\"P4+gfywhwn2dG1TBnMWEEbekCJE=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64=\"P4+gfywhwn2dG1TBnMWEEbekCJE=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64=\"P4+gfywhwn2dG1TBnMWEEbekCJE=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64=\"P4+gfywhwn2dG1TBnMWEEbekCJE=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit>1.Put a \u00a0 large \u00a0 pot \u00a0 half \u00a0 full of \u00a0 water \u00a0 on the \u00a0 stove.2.Turn \u00a0 the heat on under the pot and \u00a0 wait \u00a0 for the \u00a0 water \u00a0 to boil hard.3.Pour the pasta into the boiling \u00a0 water .", "entities": []}, {"text": "Cook the pastat0", "entities": []}, {"text": "< latexit sha1_base64=\"apCCl0QQ / pUAKLQ3uBGKSWYytus=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64=\"apCCl0QQ / pUAKLQ3uBGKSWYytus=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64=\"apCCl0QQ / pUAKLQ3uBGKSWYytus=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64=\"apCCl0QQ / pUAKLQ3uBGKSWYytus=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit > \u2026 \u2026 Drain the pasta1.Put the strainer in the sink .", "entities": []}, {"text": "2.Once the pot with pasta is cool enough , grab it by the handles .", "entities": []}, {"text": "3.Pour the pasta and water into the strainer in the sink.4.Pick up the strainer and shake it a little bit so more water comes out.t1 < latexit sha1_base64=\"FVaQdjUWZVLyUUalbbTR1NMDoKM=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64=\"FVaQdjUWZVLyUUalbbTR1NMDoKM=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64=\"FVaQdjUWZVLyUUalbbTR1NMDoKM=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64=\"FVaQdjUWZVLyUUalbbTR1NMDoKM=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit > Figure 1 : An example KIDSCOOK sequence with multiple types of hierarchy and abstraction : the example contains sequences of complex instructions , given both as sentences and sequences of simpler instructions .", "entities": []}, {"text": "Abelson , 1977 ; DeJong , 1981 ) but required handwritten data structures encoding world knowledge .", "entities": []}, {"text": "However , the automatic induction of such commonsense knowledge from open - domain noisy text corpora remains an open problem ( Chambers , 2013 ; Weber et al . , 2018 ; Zellers et al . , 2018 ) .", "entities": []}, {"text": "As a step towards solving this problem we consider textual descriptions of actions in a cooking domain .", "entities": []}, {"text": "We introduce a dataset , KIDSCOOK , targeted at exploring the automatic acquisition of correspondences between abstract and concrete descriptions of actions .", "entities": []}, {"text": "The dataset consists of higher - level single - sentence imperative descriptions paired with lower - level descriptions with elided details included .", "entities": []}, {"text": "Descriptions come from real grounded actions , built on top of the YouCookII video caption dataset ( Zhou et al . , 2017 ) .", "entities": []}, {"text": "Figure 1 gives an example annotation from the dataset : the phrase \u201c drain the pasta , \u201d presented to an annotator with its corresponding video clip , was annotated as corresponding to four constituent steps appropriate as instruction for a child .", "entities": []}, {"text": "The constituent steps are \u201c simpler \u201d in the sense that they correspond to more atomic actions , but not necessarily in their linguistic complexity .", "entities": []}, {"text": "We identify over 1,500 procedures and tools which KIDSCOOK makes explicit but are assumed as", "entities": []}, {"text": "4078commonsense world knowledge by YouCookII .", "entities": []}, {"text": "The KIDSCOOK dataset allows us to learn mappings between abstract and concrete descriptions via sequence - to - sequence prediction .", "entities": []}, {"text": "We apply several standard neural sequence - to - sequence models ; however , since these models do not expose explicit , interpretable correspondences between abstract and concrete descriptions , we also propose the application of neural transduction models which capture correspondences with latent hard alignment variables .", "entities": []}, {"text": "We de\ufb01ne a cloze - style evaluation to complement our dataset , in which models must predict the values of held - out tokens which target knowledge of tool usage , temporal ordering , and kitchen commonsense .", "entities": []}, {"text": "We \ufb01nd that our neural transduction models are able to match the predictive power of traditional neural sequence models while providing interpretable alignments between abstract and concrete subsequences useful for our primary goal of analysis of implicit hierarchical script knowledge .", "entities": []}, {"text": "2 Data & Task Our approach situates script learning as a case of grounding .", "entities": []}, {"text": "For simplicity of exposition , let us assume there are three levels of abstraction to grounding : abstract!concrete!motor control .", "entities": []}, {"text": "Most prior work in grounding treats language monolithically1and ignores the issue of audience .", "entities": []}, {"text": "In practice , this means the task formulation or exposed API may implicitly bias the language to be more concrete .", "entities": []}, {"text": "By viewing the task as purely linguistic , we have no API or robot that constrains our language ; instead , we de\ufb01ne our audience as children .", "entities": []}, {"text": "By eliciting child - directed instructions , we collect concrete language capturing otherwise implicit world knowledge that a child would not know .", "entities": []}, {"text": "Because annotators assume a smart and capable but uninformed listener , we posit this language corresponds closely to the most \u201c concrete \u201d form in which language naturally occurs .", "entities": []}, {"text": "2.1 Data Collection We construct a task on Amazon \u2019s Mechanical Turk , where workers are asked to explain a video action caption to a child.2Every instruction is paired with the original YouTube video and YouCook caption so the annotator could see how 1Notable exceptions include the hierarchical instructions of ( Regneri et al . , 2013 ) and ( Bisk et al . , 2016 ) .", "entities": [[35, 36, "DatasetName", "YouCook"]]}, {"text": "2Pay was calculated based on $ 15 / hr and assuming workers took 1.5x as long to complete a task as the experimenters .", "entities": []}, {"text": "Avg Len Seqs Tokens V ocab YC KC Train 8,125 307,573 3,573 10.0 37.9 Valid 1,014 36,830 1,479 8.8 36.3 Test 1,020 37,156 1,489 8.8 36.4 Table 1 : KIDSCOOK corpus statistics the action was performed , rather than hallucinating additional details .", "entities": []}, {"text": "All captions received three simpli\ufb01cations .", "entities": []}, {"text": "The instructions ask users to focus on missing information and allow them up to \ufb01ve steps .", "entities": []}, {"text": "Finally , we explicitly asked annotators to simplify complex actions ( e.g. dice ) that can be de\ufb01ned by a series of more basic actions ( e.g. cut ) .", "entities": []}, {"text": "OurKIDSCOOK corpus statistics are shown in Table 1 .", "entities": []}, {"text": "In total we collected over 10 K action sequences ( \u0018400 K tokens ) .", "entities": []}, {"text": "The average caption is approximately 4x longer than a YouCook caption .", "entities": [[9, 10, "DatasetName", "YouCook"]]}, {"text": "Most importantly 1,536 lemmas and 2,316 lexical types from KIDSCOOK \u2019s vocabulary do not appear in any of the original captions .", "entities": []}, {"text": "This indicates that there are over 1,500 new concepts , tools , and procedures that were assumed by YouCookII but are now explicit in KIDSCOOK .", "entities": []}, {"text": "2.2 Cloze Task To investigate what new knowledge is being introduced and whether a model has captured it , we construct a cloze - style slot-\ufb01lling task ( Chambers , 2017 ; Hermann et al . , 2015 ) .", "entities": []}, {"text": "We drop key content words from the concrete realization of an abstract instruction and ask the model to predict them .", "entities": []}, {"text": "Several examples from the validation set are shown in Table 2 .", "entities": []}, {"text": "Correctly predicting the missing words requires knowledge of the manner of executing a task and the tools required .", "entities": []}, {"text": "To choose candidate words to drop , we only allow words that occur primarily in the concrete instructions .", "entities": []}, {"text": "Additionally , we do not drop stop words , numbers , or words occurring fewer than \ufb01ve times .", "entities": []}, {"text": "We do , however , drop units of measure ( cup , minute , etc . ) .", "entities": []}, {"text": "This ensures we create blanks whose answers are previously omitted concrete details .", "entities": []}, {"text": "Relatedly , under this \ufb01lter the answer to a blank is very rarely an ingredient , as our goal is not to memorize recipes , but to infer the tool knowledge necessary to execute them .", "entities": []}, {"text": "In total , we whitelist\u00181,000 words that can be dropped to create blanks .", "entities": []}, {"text": "We prefer longer blanks when available to give preference to compound nouns ( e.g. wire whisk ) .", "entities": []}, {"text": "Finally , we do not drop any words", "entities": []}, {"text": "4079ABSchop garlic into small pieces .", "entities": []}, {"text": "CONput garlic on cutting board .press", "entities": []}, {"text": "on back of knife with hand , cutting into small pieces .", "entities": []}, {"text": "ABSadd some parmesan cheese into the bowl and mix them well .", "entities": []}, {"text": "CONuse a grater tograte some parmesan cheese into the bowl .", "entities": []}, {"text": "use a wire whisk tostirthe cheese in .", "entities": []}, {"text": "ABSadd the tofu to the wok .", "entities": []}, {"text": "CONdrain the waterfrom the tofu using a strainer .", "entities": []}, {"text": "add the tofu into the pan . use a spoon tostirthe tofu in the mixture .", "entities": []}, {"text": "Table 2 : Example abstract / concrete pairs with blanks ( red ) where predictions and surprisal are computed .", "entities": []}, {"text": "from the concrete sentence if they occur in the abstract description .", "entities": []}, {"text": "This restriction eliminates any bene\ufb01ts that might have been achieved via models with copy mechanisms .", "entities": []}, {"text": "Examples that do not meet our criteria are removed from the corpus .", "entities": []}, {"text": "3 Models We investigate the utility of sequence - to - sequence models with attention ( Bahdanau et al . , 2015 ) to generate concrete realizations of abstract task descriptions .", "entities": []}, {"text": "We hypothesize that models that learn explicit alignments are particularly amenable to interpretable analysis on the task .", "entities": []}, {"text": "Therefore , in addition to using the global attention model of ( Luong et al . , 2015 ) , we adapt the transducer model proposed by Yu et al . ( 2016 ) , which uses learned latent discrete variables to model phraseto - phrase alignments .", "entities": []}, {"text": "In contrast to many standard neural models , this approach enables us to incorporate prior knowledge about the alignment structure , and to extract interpretable alignments between task phrases .", "entities": []}, {"text": "Closely related architectures have been proposed for segmental sequence modeling ( Wang et al . , 2017 ) and phrase - based neural machine translation ( Huang et al . , 2018 ) .", "entities": [[23, 25, "TaskName", "machine translation"]]}, {"text": "We train the transducer models using Viterbi EM ( after doing marginal likelihood training for the initial iterations ) , as we found it gave higher predictive accuracy than marginal likelihood training only .", "entities": [[7, 8, "MetricName", "EM"], [27, 28, "MetricName", "accuracy"]]}, {"text": "Following Yu et al .", "entities": []}, {"text": "( 2016 ) we experiment with both a \ufb01xed alignment transition probability model and a transition model with a neural parameterization .", "entities": []}, {"text": "Cloze task prediction is performed greedily.3At each slot the Viterbi alignment of the pre\ufb01x of the sequence up to that slot is computed .", "entities": []}, {"text": "See appendix 7 for model details.4 We also evaluate the performance of a language modelling baseline and a seq2seq model without attention ( Sutskever et al . , 2014 ) , to compare the 3During preliminary experiments beam search did not improve performance .", "entities": [[13, 15, "TaskName", "language modelling"], [18, 19, "MethodName", "seq2seq"]]}, {"text": "4All code and data is available at https://github . com / janmbuys / ScriptTransduction .effect of not modeling alignment at all .", "entities": []}, {"text": "We expect all the models to implicitly capture aspects of world knowledge .", "entities": []}, {"text": "However , the discrete latent variable models provide Viterbi alignments over the training data , from which we can compile a look - up table with the extracted knowledge .", "entities": []}, {"text": "In neural attention models , this knowledge is only weakly recoverable : extracting information requires hand tuning attention thresholds and there is no direct way to extract contiguous alignments for multi - word phrases .", "entities": []}, {"text": "4 Results 4.1 Evaluation Metrics During generation , we provide the model with the number of words in each blank to be predicted .", "entities": []}, {"text": "We consider two setups for evaluating examples with multiple blanks , both assuming that predictions are made left - to - right : Oracle , where the gold prediction of each blank is fed into the model to condition on for future predictions , and Greedy , where the model prediction is used for future predictions .", "entities": []}, {"text": "We compute the proportion of exact word matches over each blank and the precision of the top k= 5 predictions for both setups .", "entities": []}, {"text": "Additionally we compute the average surprisal of the gold prediction ( conditioning on oracle predictions ) .", "entities": []}, {"text": "The surprisal of a word ( Attneave , 1959 ; Hale , 2001 ) is its negative log probability under the model : \u0000log(P(wijw1 : i\u00001 ) ) .", "entities": []}, {"text": "The higher the probability of the ground truth , the lower the model \u2019s \u201c surprise \u201d at seeing it in that context .", "entities": []}, {"text": "Finally , as a quantitative proxy for interpretability , we report the length of the transducer models \u2019 average Viterbi alignment span : our goal is a model which balances low average alignment lengths and high matching or ranking scores .", "entities": []}, {"text": "4.2 Cloze Task Results", "entities": []}, {"text": "We report results on the prediction task in Table 4 .", "entities": []}, {"text": "First we consider models trained only on our dataset : All the models that incorporate a notion of alignment do substantially better than those who", "entities": []}, {"text": "4080abstract!concrete concrete !", "entities": []}, {"text": "abstract parmesan sprinkle grated , grate , hold a grater , ... whisk eggs , mayonnaise , milk , combine , pour , stir , ...", "entities": []}, {"text": "macaroni stove on high heat , large pot , bowl , ... spatula colors , thickens , coated , simmer , grill , ... egg place the boiled , gently crack the , crack , ... tongs shrimp , bratwurst , turn , bun , marinate , ... sauce stir hot , pour gravy , lower setting , \ufb01nd a spoon , ... cutting board onions , bell pepper , meat , bok choy , ... oil spray cooking , splashing , slowly pour , ... preheat oven , broil , medium , degrees , ...", "entities": []}, {"text": "Table 3 : Example Viterbi Alignments .", "entities": []}, {"text": "For concrete to abstract , we match any phrase containing the word(s ) .", "entities": []}, {"text": "Oracle Greedy Model Match Top-5 Match Top-5 Surp Language Model 21.59 52.32 21.72 43.33 3.970 Seq2seq 23.57 53.38 23.44 45.76 3.755 + Att 24.52 53.98 24.57 47.34 3.780 Transducer 24.72 55.09 24.91 47.80 4.780 + ParamTran 23.81", "entities": [[15, 16, "MethodName", "Seq2seq"]]}, {"text": "53.98 24.00 46.19 3.547 OpenAI GPT 23.19 42.43 15.55 32.86 4.781 + \ufb01ne - tuning 38.01 63.69 31.05 57.05 3.151 Table 4 : Results on the Cloze prediction task ( Match = Exact Match , Top-5 = Precision of Top 5 predictions , Surp = Surprisal ) .", "entities": [[5, 6, "MethodName", "GPT"], [32, 34, "MetricName", "Exact Match"], [37, 38, "MetricName", "Precision"]]}, {"text": "Transducer results are reported for models with unparameterized and parameterized ( + ParamTran ) alignment transition models .", "entities": []}, {"text": "The best andsecond best results are emphasized .", "entities": []}, {"text": "do not .", "entities": []}, {"text": "We see that our transducer model with \ufb01xed alignment transition probabilities performs best in terms of predictive accuracy ( exact match and top-5 precision ) , while the seqseq model with attention is the next best in most comparisons .", "entities": [[17, 18, "MetricName", "accuracy"], [19, 21, "MetricName", "exact match"]]}, {"text": "The model with parameterized transitions has the lowest surprisal though , as it is more con\ufb01dent about the alignment predictions it is making .", "entities": []}, {"text": "Using average alignment length to quantify whether the phrase alignments exhibit desirable structure , we see that the alignments found by the unparameterized transition model ( average length 6.18 ) are signi\ufb01cantly shorter than those of the parameterized model ( average length 16.61 ) .", "entities": []}, {"text": "Investigation shows that the paramaterized model mostly learns degenerate alignments , aligning most of the concrete sequence to either the start or end of the abstract sentence .", "entities": []}, {"text": "In contrast , qualitative analysis of the unparameterized transition model show that its alignments learn desirable correspondences ( see Figure 2 ) .", "entities": []}, {"text": "Therefore among our proposed models ( trained on in - domain data only ) the transducer with unparameterized transitions satis\ufb01es our desiderata of displaying both good predictive power for word generation , and learning interpretable alignments .", "entities": []}, {"text": "Given the recent success of massively precut the dough in half and shape each half into a ball .<S > place the dough on a cutting board .", "entities": []}, {"text": "using a sharp tool such as a   knife   ,   cut   the   dough   in   half   .   shape   each   half   of   the   dough   into   a   ball   .", "entities": []}, {"text": "weigh the   cabbage   and   add   salt   .<S >   pour the   cabbage   into   the   big   bowl   .", "entities": []}, {"text": "use   a   spoon   and   scoop   some   salt   into   the   bowlplace the bread over high \ufb02ame .<S > take the tongs and pick up the bread .", "entities": []}, {"text": "set the bread on a grill .   put   on the   grill   over   the   high   \ufb02ame   .... < latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit > e0 < latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit > e6 < latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit> ... <latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64=\"Ul1zjHMk9xZA8oyRXJLJOxn4TQw=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit > e0 < latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64=\"1NSVA7XC5wla7NGfXitfHcXtZN8=\">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit > e6 < latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64=\"12MfjmJDqM21J4rd2GarPcwFAso=\">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit > Figure 2 : Example Viterbi alignments trained language models ( Peters et al . , 2018 ) , we are interested if these approaches transfer to our cloze task .", "entities": []}, {"text": "We evaluate the OpenAI GPT transformer language model ( Radford et al . , 2018 ) with and without \ufb01ne - tuning .", "entities": [[4, 5, "MethodName", "GPT"]]}, {"text": "Without \ufb01ne - tuning this model does slightly worse than our best domainspeci\ufb01c model .", "entities": []}, {"text": "With \ufb01ne - tuning , its accuracy is substantially higher , but it still suffers from the same fundamental limitations as our other models ( see Table 5 ) .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "The transformer ( Vaswani et al . , 2017 ) attention is multi - headed and multi - layered which prohibits direct interpretability .", "entities": []}, {"text": "5 Qualitative Analysis We visualize alignments of our transduction model over two partial sequences in Fig .", "entities": []}, {"text": "2 .", "entities": []}, {"text": "This shows which hidden vector of the abstract sentence aligned to every region of the concrete sequence .", "entities": []}, {"text": "Speci\ufb01cally , we see how tools like the big bowl , spoon , and tongs are introduced to facilitate the actions .", "entities": []}, {"text": "There are also implications , e.g. that high indicates grill .", "entities": []}, {"text": "For further analysis we extract alignments over the training corpus , linking each decoded phrase with the word from the encoding it used during generation .", "entities": []}, {"text": "We then aggregate these tuples into a table which we can \ufb01lter ( based on our whitelist ) and sort ( with PMI ) .", "entities": []}, {"text": "This process is imprecise as it discards the context in which the alignment occurs , but it nonetheless extracts many", "entities": []}, {"text": "4081Abs shape each dough ball into a circle and add tomato sauce .", "entities": []}, {"text": "Pred \ufb02atten out your dough into a \ufb02at circle using your hands .", "entities": []}, {"text": "take a knife to add tomato sauce to the center of your dough .", "entities": []}, {"text": "use the back side of the knife tocutthe sauce out .", "entities": []}, {"text": "make sure you keep the sauce about aninch from the edges .", "entities": []}, {"text": "Gold \ufb02atten out your dough into a \ufb02at circle using your hands .", "entities": []}, {"text": "take a spoon to add tomato sauce to the center of your dough .", "entities": []}, {"text": "use the back side of the spoon tospread the sauce out .", "entities": []}, {"text": "make sure you keep the sauce about aninch from the edges .", "entities": []}, {"text": "Abs place the kale cucumber bell peppers carrots and radishes on the wrapper .", "entities": []}, {"text": "Pred put the cuton a cutting .", "entities": []}, {"text": "put a cutting amount of kale on the cutting .", "entities": []}, {"text": "add a cutamount of cucumber ...", "entities": []}, {"text": "Gold put the wrap on a plate .", "entities": []}, {"text": "put a small amount of kale on the wrap .", "entities": []}, {"text": "add a small amount of cucumber ...", "entities": []}, {"text": "Abs wrap the pizza .", "entities": []}, {"text": "Pred \ufb01nd a large piece to put the pizza om .", "entities": []}, {"text": "place the pizza in the center for it not to stick around .", "entities": []}, {"text": "grab the plastic wrap and start wrap ping theentirething and pizza .", "entities": []}, {"text": "wrap all around until completely covered on all corners .", "entities": []}, {"text": "put in freezer on a cold waterand freeze overnight Gold \ufb01nd a hard surface to put the pizza om .", "entities": []}, {"text": "place the pizza in the center for it not to slide around .", "entities": []}, {"text": "grab the plastic wrap and start wrap ping thehard surface and pizza .", "entities": []}, {"text": "wrap all around until fully covered on all corners .", "entities": []}, {"text": "put in freezer on a\ufb02atsurface and freeze overnight Table 5 : Above is the output of OpenAI GPT when forced to greedily decode answers to blanks in validation .", "entities": [[17, 18, "MethodName", "GPT"]]}, {"text": "of the phenomena we would hope to see ( Table 3 ) .", "entities": []}, {"text": "The left - hand side of the table shows words from the abstract YouCook annotations and corresponding phrases in the concrete annotation .", "entities": [[13, 14, "DatasetName", "YouCook"]]}, {"text": "For the righthand side we searched for common concrete terms that may be preceded or followed by other terms , and present the abstract terms they were most often generated by .", "entities": []}, {"text": "Finally , Table 5 shows three randomly chosen examples ( from the validation set ) of greedy decodings for slot \ufb01lling with GPT \ufb01ne - tuned on our dataset .", "entities": [[22, 23, "MethodName", "GPT"]]}, {"text": "These examples demonstrate that , \ufb01rst , there are cases where GPT is successful or produces a semantically valid answer ( e.g. fully vs completely ) .", "entities": [[11, 12, "MethodName", "GPT"]]}, {"text": "Second , as is common with greedy decoding , the model can get stuck in a loop ( e.g. cut , cutting , cutting , ... ) .", "entities": []}, {"text": "Finally , note there are nonsensical cases where the model appears to have discarded the abstract context ( e.g. knife to add tomato sauce orfreezer on a cold water ) .", "entities": []}, {"text": "6 Related Work Many script learning systems are based on event co - occurrence and language modeling in large text corpora , and can infer implicit events without creating explicit situation - speci\ufb01c frame structures ( Chambers and Jurafsky , 2008 ; Rudinger et al . , 2015 ; Pichotta and Mooney , 2016 ) .", "entities": []}, {"text": "Other systems induce situation - speci\ufb01c frames from text ( Cheung et al . , 2013 ;", "entities": []}, {"text": "Balasubramanian et al . , 2013 ) .", "entities": []}, {"text": "However , these methods do not explicitly target the commonsense correspondence between differing levels of detail of complex events .", "entities": []}, {"text": "Most relevant to this paper is the pioneering work of Regneri et al .", "entities": []}, {"text": "( 2013 ) as extended by Senina", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2014 ) and Rohrbach et al .", "entities": []}, {"text": "( 2014).These papers present the TACOS corpus , consisting of natural language descriptions of activities in videos paired with low - level activity labels .", "entities": []}, {"text": "Senina et al .", "entities": []}, {"text": "( 2014 ) collect an additional level of multi - sentence annotations on the corpus , which allowing for video caption generation at multiple levels of detail .", "entities": []}, {"text": "Rohrbach et al .", "entities": []}, {"text": "( 2014 ) describe a similar corpus of natural descriptions of composite actions , useful for activity recognition in video .", "entities": [[16, 18, "TaskName", "activity recognition"]]}, {"text": "These corpora differ in a number of important ways from KIDSCOOK ; in particular , the language has somewhat limited complexity and \u201c naturalness \u201d when describing complex scenarios , a phenomenon also observed in the robotics literature ( Scalise et al . , 2018 ) .", "entities": []}, {"text": "Our data collection process avoids more formulaic language by eliciting \u201c child - directed \u201d descriptions .", "entities": []}, {"text": "7 Conclusion We introduce a new hierarchical script learning dataset and cloze task in which models must learn commonsense world knowledge about tools , procedures and even basic physics to perform well .", "entities": []}, {"text": "Our aim is to begin a conversation about abstraction in language , how it is modeled , and what is implicitly hidden .", "entities": []}, {"text": "Our abstract and concrete instructions are grounded in the same videos yet differ dramatically due to their assumed audiences .", "entities": []}, {"text": "We show that a neural transduction model produces interpretable alignments for analyzing these otherwise latent correlations and phenomena .", "entities": []}, {"text": "Acknowledgements This work was supported in part by NSF ( IIS1524371 & 1703166 ) and through DARPA \u2019s CwC program through ARO ( W911NF-15 - 1 - 0543 ) .", "entities": [[16, 17, "DatasetName", "DARPA"]]}, {"text": "4082References Fred Attneave .", "entities": []}, {"text": "1959 .", "entities": []}, {"text": "Applications of information theory to psychology : A summary of basic concepts , methods , and results .", "entities": []}, {"text": "Henry Holt .", "entities": []}, {"text": "Dzmitry Bahdanau , KyungHyun Cho , and Yoshua Bengio .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Neural machine translation by jointly learning to align and translate .", "entities": [[1, 3, "TaskName", "machine translation"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Niranjan Balasubramanian , Stephen Soderland , Mausam , and Oren Etzioni .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Generating coherent event schemas at scale .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Yonatan Bisk , Daniel Marcu , and William Wong . 2016 .", "entities": []}, {"text": "Towards a dataset for human computer communication via grounded language acquisition .", "entities": [[9, 11, "TaskName", "language acquisition"]]}, {"text": "In Proceedings of the AAAI 2016 Workshop on Symbiotic Cognitive Systems , pages 729\u2013732 , Phoenix , AZ .", "entities": []}, {"text": "Peter F Brown , Vincent J Della Pietra , Stephen A Della Pietra , and Robert L Mercer .", "entities": []}, {"text": "1993 .", "entities": []}, {"text": "The mathematics of statistical machine translation : Parameter estimation .", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "CL , 19(2):263\u2013311 .", "entities": []}, {"text": "Nathanael Chambers .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Event schema induction with a probabilistic entity - driven model .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Nathanael Chambers . 2017 .", "entities": []}, {"text": "Behind the scenes of an evolving event cloze test .", "entities": [[7, 9, "TaskName", "cloze test"]]}, {"text": "In LSDSem .", "entities": []}, {"text": "Nathanael Chambers and Dan Jurafsky .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Unsupervised learning of narrative event chains .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Jackie Chi Kit Cheung , Hoifung Poon , and Lucy Vanderwende .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Probabilistic frame induction .", "entities": []}, {"text": "In NAACL .", "entities": []}, {"text": "Gerald F. DeJong .", "entities": []}, {"text": "1981 .", "entities": []}, {"text": "Generalizations based on explanations .", "entities": []}, {"text": "In IJCAI .", "entities": []}, {"text": "Arthur P Dempster , Nan M Laird , and Donald B Rubin .", "entities": []}, {"text": "1977 .", "entities": []}, {"text": "Maximum likelihood from incomplete data via the em algorithm .", "entities": []}, {"text": "Journal of the royal statistical society . , pages 1\u201338 .", "entities": []}, {"text": "Jason Eisner .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Inside - outside and forwardbackward algorithms are just backprop ( tutorial paper ) .", "entities": []}, {"text": "In Workshop on Structured Prediction for NLP .", "entities": [[3, 5, "TaskName", "Structured Prediction"]]}, {"text": "H. Paul Grice . 1975 .", "entities": []}, {"text": "Logic and conversation .", "entities": []}, {"text": "Syntax and Semantics 3 : Speech Acts , pages 41\u201358 .", "entities": []}, {"text": "John Hale .", "entities": []}, {"text": "2001 .", "entities": []}, {"text": "A probabilistic earley parser as a psycholinguistic model .", "entities": []}, {"text": "In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies , pages 1\u20138 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Karl Moritz Hermann , Tomas Kocisky , Edward Grefenstette , Lasse Espeholt , Will Kay , Mustafa Suleyman , and Phil Blunsom .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Teaching machines to read and comprehend .", "entities": []}, {"text": "In NIPS .", "entities": []}, {"text": "Sepp Hochreiter and J \u00a8urgen Schmidhuber .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Long short - term memory .", "entities": [[0, 5, "MethodName", "Long short - term memory"]]}, {"text": "Neural Computation , 9(8):1735\u20131780.Po - Sen Huang , Chong Wang , Sitao Huang , Dengyong Zhou , and Li Deng .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Towards neural phrasebased machine translation .", "entities": [[3, 5, "TaskName", "machine translation"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Thang Luong , Hieu Pham , and Christopher D Manning .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Effective approaches to attention - based neural machine translation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Jeffrey Pennington , Richard Socher , and Christopher Manning .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "GloVe : Global vectors for word representation .", "entities": [[0, 1, "MethodName", "GloVe"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Matthew Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Deep contextualized word representations .", "entities": []}, {"text": "In NAACL .", "entities": []}, {"text": "Karl Pichotta and Raymond J Mooney . 2016 .", "entities": []}, {"text": "Learning statistical scripts with LSTM recurrent neural networks .", "entities": [[4, 5, "MethodName", "LSTM"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Alex Radford , Karthik Narasimhan , Tim Salimans , and Ilya Sutskever . 2018 .", "entities": []}, {"text": "Improving language understanding by generative pre - training .", "entities": []}, {"text": "Technical report , OpenAI .", "entities": []}, {"text": "Mechaela Regneri , Marcus Rohrbach , Dominikus Wetzel , Stefan Thater , Bernt Schiele , and Manfred Pinkal .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Grounding action descriptions in videos .", "entities": []}, {"text": "TACL , 1 . Anna Rohrbach , Marcus Rohrbach , Wei Qiu , Annemarie Friedrich , Manfred Pinkal , and Bernt Schiele .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Coherent multi - sentence video description with variable level of detail .", "entities": [[4, 6, "TaskName", "video description"]]}, {"text": "In GCPR .", "entities": []}, {"text": "Rachel Rudinger , Vera Demberg , Ashutosh Modi , Benjamin Van Durme , and Manfred Pinkal . 2015 .", "entities": []}, {"text": "Learning to predict script events from domainspeci\ufb01c text .", "entities": []}, {"text": "In * Sem .", "entities": []}, {"text": "Rosario Scalise , Yonatan Bisk , Maxwell Forbes , Daqing Yi , Yejin Choi , and Siddhartha Srinivasa .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Balancing shared autonomy with human - robot communication .", "entities": []}, {"text": "arXiv preprint arXiv:1805.07719 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Roger C. Schank and Robert P. Abelson .", "entities": []}, {"text": "1977 .", "entities": []}, {"text": "Scripts , Plans , Goals and Understanding : An Inquiry into Human Knowledge Structures .", "entities": []}, {"text": "LEA .", "entities": []}, {"text": "Anna Senina , Marcus Rohrbach , Wei Qiu , Annemarie Friedrich , Sikandar Amin , Mykhaylo Andriluka , Manfred Pinkal , and Bernt Schiele .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Coherent multi - sentence video description with variable level of detail .", "entities": [[4, 6, "TaskName", "video description"]]}, {"text": "arXiv preprint arXiv:1403.6173 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Valentin I Spitkovsky , Hiyan Alshawi , and Daniel Jurafsky .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Lateen EM : Unsupervised training with multiple objectives , applied to dependency grammar induction .", "entities": [[1, 2, "MetricName", "EM"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Valentin I Spitkovsky , Hiyan Alshawi , Daniel Jurafsky , and Christopher D Manning .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Viterbi training improves unsupervised dependency parsing .", "entities": [[3, 6, "TaskName", "unsupervised dependency parsing"]]}, {"text": "In CoNLL .", "entities": []}, {"text": "4083Ilya Sutskever , Oriol Vinyals , and Quoc V .", "entities": []}, {"text": "Le . 2014 .", "entities": []}, {"text": "Sequence to sequence learning with neural networks .", "entities": [[0, 3, "MethodName", "Sequence to sequence"]]}, {"text": "In NIPS .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems , pages 5998\u20136008 .", "entities": []}, {"text": "Chong Wang , Yining Wang , Po - Sen Huang , Abdelrahman Mohamed , Dengyong Zhou , and Li Deng . 2017 .", "entities": []}, {"text": "Sequence modeling via segmentations .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "Noah Weber , Leena Shekhar , Niranjan Balasubramanian , and Nathanael Chambers .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Hierarchical quantized representations for script generation .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Lei Yu , Phil Blunsom , Chris Dyer , Edward Grefenstette , and Tomas Kocisky . 2017 .", "entities": []}, {"text": "The neural noisy channel .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Lei Yu , Jan Buys , and Phil Blunsom .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Online segment to segment neural transduction .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Rowan Zellers , Yonatan Bisk , Roy Schwartz , and Yejin Choi .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Swag : A large - scale adversarial dataset for grounded commonsense inference .", "entities": [[0, 1, "DatasetName", "Swag"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .", "entities": []}, {"text": "Luowei Zhou , Chenliang Xu , and Jason J Corso . 2017 .", "entities": []}, {"text": "Towards automatic learning of procedures from web instructional videos .", "entities": []}, {"text": "arXiv preprint arXiv:1703.09788 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "4084A Transducer Model We brie\ufb02y describe the model of Yu , Buys , and Blunsom ( 2016 ) and our minor modi\ufb01cations thereto .", "entities": []}, {"text": "A.1 Alignment with Latent Variables", "entities": []}, {"text": "We model the conditional probability of a concrete sequenceygiven abstract sequence xthrough", "entities": []}, {"text": "a latent alignment variable abetweenxandy , which is a sequence of variables aj , withaj = isignifying thatyjis aligned to xi .", "entities": []}, {"text": "The marginal probability ofygivenxis p(yjx )", "entities": []}, {"text": "= X ap(y;ajx ): ( 1 ) In the following , we use mto denote the length ofxandnto denote the length of y.", "entities": []}, {"text": "The model formulation restricts alignments to be monotonic , i.e.aj+1\u0015ajfor allj .", "entities": []}, {"text": "The model factorizes over timesteps into alignment and word prediction probabilities , such that the word prediction at each timestep is informed by its alignment : p(y;ajx )", "entities": []}, {"text": "= Y jp(ajjaj\u00001;x1 : aj\u00001;y1 : j\u00001 ) \u0002p(yjjaj;x1 : aj;y1 : j\u00001)(2 )", "entities": []}, {"text": "The abstract and concrete sequences are both encoded with LSTM Recurrent Neural Networks ( Hochreiter and Schmidhuber , 1997 ) .", "entities": [[9, 10, "MethodName", "LSTM"]]}, {"text": "In contrast to standard attention - based models , the aligned encoder representation is not fed into the decoder RNN state , but only used to make next word predictions .", "entities": []}, {"text": "Due to the small size of the training data , words in both sequences are embedded using \ufb01xed GloVe embeddings ( Pennington et al . , 2014 ) .", "entities": [[18, 20, "MethodName", "GloVe embeddings"]]}, {"text": "The word emission probability is then de\ufb01ned as p(yjjaj;x1 : aj;y1 : j\u00001 ) = softmax(MLP ( eaj;dj ) ) ( 3 ) withethe encoder hidden states and dthe decoder hidden states .", "entities": []}, {"text": "The alignment probability factorizes into shift andemit probabilities , where a shift action increments the alignment to the next word in the input sequence , and an emit action generates the next output word .", "entities": []}, {"text": "We refer to these as transition probabilities .", "entities": []}, {"text": "This formulation enables us to restrict the hard alignment to be monotonic .", "entities": []}, {"text": "We consider two parameterizations of this distribution .", "entities": []}, {"text": "In the \ufb01rst , the probabilities are parameterized by the neural network , using the encoderand decoder hidden state in a similar manner to how the word emission probability was computed .", "entities": []}, {"text": "The alignment probability at a given timestep is therefore parameterized as p(ajjaj\u00001;x1 : aj\u00001;y1 : j\u00001 )", "entities": []}, {"text": "= p(emitjaj;x1 : aj;y1 : j\u00001 ) \u0002aj\u00001Y i = aj\u00001p(shiftji;x1 : i;y1 : j\u00001);(4 )", "entities": []}, {"text": "where p(shiftji;x1 : i;y1 : j\u00001 ) = \u001b(MLP ( ei;dj ) ) ; ( 5 ) p(emitji;x1 : i;y1 : j\u00001 ) = 1\u0000p(shiftji;x1 : i;y1 : j\u00001):(6 ) We also consider using the simpler , \ufb01xed alignment parameterization in Yu , Buys , and Blunsom ( 2016 ) , where the transition probability is conditioned only on sequence length , not on xory , and can therefore be estimated using the ratio between input and output sentence lengths .", "entities": []}, {"text": "The alignment probabilities are not updated during training , and consequently the posterior distribution over the alignments is biased towards this prior , favoring alignments close to the diagonal .", "entities": []}, {"text": "The parameterized alignment model contains as special cases two degenerate solutions : ( 1 ) an unconditional language model and ( 2 ) a seq2seq model .", "entities": [[24, 25, "MethodName", "seq2seq"]]}, {"text": "These occur if the model performs all emits before shifting or all shifts before emitting , respectively .", "entities": []}, {"text": "To prevent the creation of a language model we force the last output word to be aligned to the last word in the abstract sequence , similar to Yu et al . ( 2017 ) .", "entities": []}, {"text": "However , the parameterized transition model could still in practice revert to a pure sequence - to - sequence model .", "entities": []}, {"text": "A.2 Marginalization Next we brie\ufb02y describe the dynamic program used to marginalize over alignments during training and to \ufb01nd the most likely alignments of a given alignment during inference ; we refer the reader to Yu , Buys , and Blunsom ( 2016 ) for a more thorough treatment .", "entities": []}, {"text": "The forward variable \u000b i(j)representing p(y1 : j;aj = ijx1 : i)is recursively as \u000b i(j )", "entities": []}, {"text": "= p(yjji;x1 : i;y1 : j\u00001 ) \u0002iX k=1 \u000b k(j\u00001)p(aj = ijk;x 1 : k;y1 : j\u00001):(7 ) The marginal likelihood objective is to train the model to optimize \u000b m(n )", "entities": []}, {"text": "= p(y1 : n;an=", "entities": []}, {"text": "4085mjx1 : m ) .", "entities": []}, {"text": "The gradients are computed with automatic differentiation ; as this is is equivalent to using the forward - backward algorithm to estimate the gradients ( Eisner , 2016 ) , only the forward algorithm has to be implemented .", "entities": []}, {"text": "To make the implementation GPU - ef\ufb01cient , we vectorize the computation of \u000b .", "entities": []}, {"text": "The computation iterates through decoding steps , each of which can be generated from an alignment to any of the encoder tokens .", "entities": []}, {"text": "We can ef\ufb01ciently construct a transition matrix T , corresponding to all possible encoder states performing all possible shifts , and emission matrix Ejwhich is a gather by word indexj .", "entities": []}, {"text": "To compute the forward probabilities at each timestep , the current forward probabilities are \ufb01rst multiplied by all possible transitions .", "entities": []}, {"text": "A sum in logspace collapses all paths , and the emission ( word generation ) probabilities are multiplied to obtain the new forward probabilities .", "entities": []}, {"text": "When \ufb01xed transition probabilities are used , Tis precomputed .", "entities": []}, {"text": "A.3 Viterbi EM Training Latent variable models can be trained either through directly optimizing the likelihood objective through gradient descent ( as described above ) , or with the Expectation Maximization ( EM ) algorithm ( Dempster et al . , 1977 ) , which alternates between calculating expectations over the values of the latent variables given the current parameters , and maximizing the expected complete data log likelihood given those expectations .", "entities": [[2, 3, "MetricName", "EM"], [32, 33, "MetricName", "EM"]]}, {"text": "We consider training our alignment model with Viterbi EM ( Brown et al . , 1993 ) , also known as \u201c hard \u201d EM , where at each iteration the most likely assignment of the hidden variables ( alignments ) are found and the parameters are updated to optimize the log likelihood given those alignments .", "entities": [[8, 9, "MetricName", "EM"], [24, 25, "MetricName", "EM"]]}, {"text": "Viterbi EM has been shown to give superior performance to standard EM on unsupervised parsing ( Spitkovsky et al . , 2010 ) , due to better convergence properties in practice by making the distribution more peaked .", "entities": [[1, 2, "MetricName", "EM"], [11, 12, "MetricName", "EM"]]}, {"text": "We perform batched Viterbi EM training by computing the Viterbi alignments for a batch , and then performing a gradient step based on treating those alignments as observations .", "entities": [[4, 5, "MetricName", "EM"]]}, {"text": "We follow a two - stage training procedure : we \ufb01rst directly optimize the marginal likelihood with batched SGD to \ufb01nd a reasonable initial distribu - tion over alignments , before switching to Viterbi EM training .", "entities": [[18, 19, "MethodName", "SGD"], [34, 35, "MetricName", "EM"]]}, {"text": "Such a strategy has been shown to reduce the chance that the model will get stuck in local optima ( Spitkovsky et", "entities": []}, {"text": "al . , 2011 ) .", "entities": []}, {"text": "A.4 Inference", "entities": []}, {"text": "We apply the trained models to multiple inference problems to evaluate how well they are capturing script knowledge .", "entities": []}, {"text": "The \ufb01rst is \ufb01nding the most likely alignment given a pair of abstract and concrete sequences .", "entities": []}, {"text": "We use the standard Viterbi algorithm , in which we replace the sum in equation ( 7 ) with max , and keep track of the index corresponding to each value of \u000b during the forward computation .", "entities": []}, {"text": "The most likely alignment can then be traced back from an = m. The second inference problem is slot-\ufb01lling , for application to the cloze task .", "entities": []}, {"text": "Given an abstract sentence and a partially-\ufb01lled concrete sequence , we want to use the model to predict words to \ufb01ll the given blanks .", "entities": []}, {"text": "To make the prediction , we sample 5 candidate sequences by predicting words for each slot , in left - to - right order , and then choosing the sequence with the highest overall probability .", "entities": []}, {"text": "Words are predicted by sampling with temperature 0:1 , in order to peak the distribution while still allowing some diversity in the samples .", "entities": []}, {"text": "The motivation for selecting the \ufb01nal output from multiple samples is that the original samples are biased , as they are only conditioned on the left context .", "entities": []}, {"text": "At the start of the prediction for each slot , the Viterbi alignment of the pre\ufb01x of the sequence up to the start of that slot is re - predicted , independent of previous alignment predictions .", "entities": []}, {"text": "Consequently alignment decisions can be revised , and the slot alignments are no longer constrained to be monotonic , which makes the slot prediction model more \ufb02exible .", "entities": []}, {"text": "For the parameterized transition model , the slot alignment is predicted greedily by incrementing the last predicted alignment while the shift probability is greater than 0:5 .", "entities": []}, {"text": "The \ufb01xed transition model assumes that the alignment of the word preceding the slot is shared across the slot .", "entities": []}]