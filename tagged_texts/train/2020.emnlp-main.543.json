[{"text": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 6695\u20136704 , November 16\u201320 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics6695Less is More : Attention Supervision with Counterfactuals for Text Classi\ufb01cation Seungtaek Choi Yonsei University hist0613@yonsei.ac.krHaeju Park Yonsei University phj0225@yonsei.ac.krJinyoung Yeo Yonsei University jinyeo@yonsei.ac.krSeung - won Hwang Yonsei University seungwonh@yonsei.ac.kr Abstract We aim to leverage human and machine intelligence together for attention supervision .", "entities": []}, {"text": "Speci\ufb01cally , we show that human annotation cost can be kept reasonably low , while its quality can be enhanced by machine selfsupervision .", "entities": []}, {"text": "Speci\ufb01cally , for this goal , we explore the advantage of counterfactual reasoning , over associative reasoning typically used in attention supervision .", "entities": []}, {"text": "Our empirical results show that this machine - augmented human attention supervision is more e \u000b ective than existing methods requiring a higher annotation cost , in text classi\ufb01cation tasks , including sentiment analysis and news categorization .", "entities": [[32, 34, "TaskName", "sentiment analysis"]]}, {"text": "1 Introduction The practical importance of attention mechanism has been well - established , for both ( a ) improving NLP models ( Vaswani et al . , 2017 ) , and also ( b ) enhancing human understanding of models ( Serrano and Smith , 2019 ; Wiegre \u000b e and Pinter , 2019 ) .", "entities": []}, {"text": "This paper pursues the former direction , but unlike existing models , typically using attention in \u201c unsupervised \u201d nature .", "entities": []}, {"text": "Adding human supervision to attention has been shown to improve model predictions and explanations ( Jain and Wallace , 2019 ) .", "entities": []}, {"text": "For example , consider a review in ( Tang et al . , 2019 )", "entities": []}, {"text": "\u201c this place is small and crowded but the service is quick \u201d .", "entities": []}, {"text": "Models with unsupervised attention may attend highly on \u201c quick \u201d , a generic strong signal for restaurant reviews , but one may supervise to focus on \u201c crowded \u201d to guide models to predict a negative sentiment correctly .", "entities": []}, {"text": "For this goal , attention supervision task ( Yu et al . , 2017 ; Liu et al . , 2017 ) treats attention as output variables so that models can be trained to generate similar attention to human supervision .", "entities": []}, {"text": "We categorize such human supervision into the following two levels:\u0088Sample level rationale :", "entities": []}, {"text": "In the above example , whether to attend on quick orcrowded depends on the ground - truth sentiment class .", "entities": []}, {"text": "Human annotator is required to examine each training sample , and highlight important words speci\ufb01c to a sample and its class label .", "entities": []}, {"text": "\u0088Task level : An alternative with lower annotation overhead would be annotating vocabulary , separately from training samples .", "entities": []}, {"text": "That is , both quick andcrowded are annotated to attend , since both have high importance for the target task of sentiment classi\ufb01cation .", "entities": []}, {"text": "A naive belief would be assuming the former with a higher annotation cost is more e \u000b ective at supervising the model \u2019s attention .", "entities": []}, {"text": "Our key claim , in contrast , is that requiring more annotation , or , sample - speci\ufb01c supervision , can be less e \u000b ective than requiring lessfrom human then augmenting it by machine ( less - is - more -hypothesis ) .", "entities": []}, {"text": "Similar skepticism on asking more , or sample - level rationales from humans , was explored in ( Bao et al . , 2018 ) , where machine attention from large additional annotations was more e \u000b ective supervisions than rationales .", "entities": []}, {"text": "In this paper , we validate less - is - more without additional annotation overhead , by proposing a holistic approach of combining both human annotation and machine attention .", "entities": []}, {"text": "Key distinctions from ( Bao et al . , 2018 ) are ( a ) humans annotate even less , and ( b ) without additional training resources .", "entities": []}, {"text": "Speci\ufb01cally , we start by loosening the definition of human annotation ( Camburu et al . , 2018 ; Zhong et al . , 2019 ) into the task - level annotation : it reduces annotation cost to the size of vocabulary , or often to zero , when public resources such as sentiment lexicon replace such annotation .", "entities": []}, {"text": "We show the e \u000b ectiveness of this zero - cost supervision , for both sentiment classi\ufb01cation and news categorization scenarios , after our proposed adaptation .", "entities": []}, {"text": "6696Our adaptation goal is an unsupervised adaptation of task - level human annotation to samplelevel supervision signals for attention /classi\ufb01cation models .", "entities": []}, {"text": "Speci\ufb01cally , we propose Sample - level Attentio NAdaptation ( SANA ) .", "entities": []}, {"text": "Speci\ufb01cally , for self - supervising such adaptation , SANA conducts what - if tests per each sample , of whether the permutation on human annotation changes the machine prediction .", "entities": []}, {"text": "That is , we collect the counterfactual ( machine ) supervisions for free , by observing whether highly attended word by human leads to the same machine prediction , compared to when such attention is counterfactually lowered .", "entities": []}, {"text": "In such a case , SANA supervises to reduce the importance of the word .", "entities": []}, {"text": "We validate such counterfactual signals are missing pieces for adapting word importance to sample - speci\ufb01c prediction .", "entities": []}, {"text": "We evaluate SANA on three popular datasets , SST2 , IMDB , and 20NG .", "entities": [[8, 9, "DatasetName", "SST2"], [10, 11, "DatasetName", "IMDB"]]}, {"text": "In all of the text classi\ufb01cation datasets , SANA achieves signi\ufb01cant improvements over baselines , using unsupervised attention or supervised with task- or sample - level human annotations , in the following four dimensions : Models supervised by SANA predict more accurately , explain causality of attention better , and are more robust over adversarial attacks , and more tolerant of the scarcity of training samples .", "entities": []}, {"text": "2 Preliminaries 2.1 Text Classi\ufb01cation with Attention Text classi\ufb01cation assumes a dataset D = fxi;yigN i=1 which associates an input text xito its corresponding class label yi .", "entities": []}, {"text": "We will omit the index iwhen dealing with a single input sample .", "entities": []}, {"text": "Let the input sequence of word features ( e.g. , embeddings ) be denoted as x = fwtgT t=1 , where Tis the length of the sequence .", "entities": []}, {"text": "The sequence of hidden states produced by an encoding function f \u001e with learnable parameters \u001e is then h = fhtgT t=1 .", "entities": []}, {"text": "Formally , f \u001e : x!(h;\u02c6 \u000b ) , where attention weights \u02c6 \u000b = f\u02c6 \u000b tgT t=1indicate a probability distribution over the hidden states ( Zou et al . , 2018 ; Yang et al . , 2016 ) .", "entities": []}, {"text": "Finally , the hidden representations are fed into a function g\u0012 : ( h;\u02c6 \u000b ) !", "entities": []}, {"text": "\u02c6y with learnable parameters \u0012and a softmax layer that predicts the probabilities \u02c6 yover classes : \u02c6y = Softmax ( W>\u02dch+b ) ; \u0012=fW;bg ( 1 ) where \u02dch = P ht2h\u02c6 \u000b thtand Softmax ( zi)= ezi = P jezj .", "entities": [[6, 7, "MethodName", "softmax"], [18, 19, "MethodName", "Softmax"], [34, 35, "MethodName", "Softmax"]]}, {"text": "The parameters \u001e and\u0012are trained to minimize the cross - entropy loss Ltask(\u02c6y;y ) between the predicted label \u02c6 yand the ground - truth label y.2.2 Attention Supervision Attention can be treated as output variables , so that humans can supervise .", "entities": [[11, 12, "MetricName", "loss"]]}, {"text": "Given an input sample x , let \u000b and\u02c6 \u000b be the attention labels ( provided by human annotators ) and the trained attention weights .", "entities": []}, {"text": "Then , the loss for attention supervision is de\ufb01ned as the cross - entropy loss Latt(\u02c6 \u000b ; \u000b ) between \u02c6 \u000b and \u000b .", "entities": [[3, 4, "MetricName", "loss"], [14, 15, "MetricName", "loss"]]}, {"text": "Finally , the parameters of the text classi\ufb01cation network with attention supervision are trained to minimize both loss terms together as follows : L = Ltask(\u02c6y;y)+\u0016\u0001Latt ( \u02c6 \u000b ; \u000b ) ( 2 ) where\u0016is a preference weight .", "entities": [[17, 18, "MetricName", "loss"]]}, {"text": "Requiring humans to explicitly annotate soft labels \u000b has been considered unrealistic ( Barrett et al . , 2018 ) , and often delegated to implicit signals such as eye gaze .", "entities": []}, {"text": "As an alternative to asking humans to annotate , important words for the given sample and class label have been typically annotated as rationale ( Bao et al . , 2018 ; Zhao et", "entities": []}, {"text": "al . , 2018 ) .", "entities": []}, {"text": "Formally , given an input sample xand its class label y , let A2f0;1gTbe a binary vector of selecting words in x , i.e. ,8wt2x : A(wt)2f0;1 g. Then , we convert the attention annotation Ainto a soft distribution of target attention labels \u000b using softmax : \u000b t = exp(\u0015\u0001A(wt ) )", "entities": [[46, 47, "MethodName", "softmax"]]}, {"text": "PT t0=1exp(\u0015\u0001A(wt0))(3 )", "entities": []}, {"text": "where\u0015is a positive hyper - parameter that controls the variance of scores : when \u0015increases , the distribution of \u000b becomes more skewed , guiding to attend a few of more important words .", "entities": []}, {"text": "To illustrate a rationale , when given the aforementioned review sample in Sec . 1 , possible annotations for the negative label are either \u201c this place is small and crowded but the service is quick \u201d or \u201c this place is small and crowded but the service is quick \u201d , where the underlines indicate the hard selection by human .", "entities": []}, {"text": "Then , we can translate them into the sample - level annotation A=[1;1;1;1;1;1;0;0;0;0;0 ] or A= [ 0;0;0;0;0;1;0;0;0;0;0 ] .", "entities": []}, {"text": "3 Less is More for Attention Supervision Sample - level annotation is reportedly too expensive in many practical settings ( Zhong et", "entities": []}, {"text": "al . , 2019 ) , and is far di \u000ecult for humans to capture the dependency with corresponding class labels .", "entities": []}, {"text": "In contrast , annotators may select important words for a target task , namely task - level attention annotation", "entities": []}, {"text": "6697(Def . 3.1 ) , without looking up individual samples and their labels .", "entities": []}, {"text": "De\ufb01nition 3.1 ( Task - level Attention Annotation )", "entities": []}, {"text": "Assuming the existence of the vocabulary V , the vocab - level annotation Atask2 f0;1gjVjis", "entities": []}, {"text": "a binary vector of the hard selection for words in V , i.e. ,8wt2V : Atask(wt)2 f0;1 g. Based onAtask , when given an input sample x , we can use a proxy of the sample - level annotation A , i.e. , 8wt2x : A(wt)=Atask(wt ) .", "entities": []}, {"text": "Sample - level Task - level Reduction ratio SST2 208 K 16 K -92.3 % IMDB 5 M 124 K", "entities": [[8, 9, "DatasetName", "SST2"], [15, 16, "DatasetName", "IMDB"]]}, {"text": "-97.5 % 20NG 232 K 22 K -90.5 % Table 1 : Comparison of annotation space As shown in Tab . 1 , the annotation space , which is referred to as a word set size for annotation , is 10\u001836 times smaller at task - level than at samplelevel .", "entities": []}, {"text": "Generally , the vocabulary size is far smaller than the total number of word occurrences in training samples .", "entities": []}, {"text": "Our goal is thus to keep annotation cost cognitively reasonable ( Zou et al . , 2018 ; Zhao et", "entities": []}, {"text": "al . , 2018 ) , leaving machine self - supervision to close the annotation quality gap ( Sec . 3.1 and 3.2 ) .", "entities": []}, {"text": "Meanwhile , we present a setup of zero - cost supervision , which allows us attention supervision without any human e \u000b orts in all scenarios using public resources and tools ( Sec . 3.3 ) .", "entities": []}, {"text": "3.1 Counterfactuals as Causal Signals Our key idea is to leverage causal signals ( Johansson et al . , 2016 ) from human annotation A(or attention labels \u000b ) of an input sample xto its corresponding model prediction \u02c6y .", "entities": []}, {"text": "More speci\ufb01cally , we test whether two di \u000b erent attentions ( one is original and the other is counterfactual ) on the same input sample xlead to di \u000b erent prediction results \u02c6y .", "entities": []}, {"text": "If high ( original ) and low ( counterfactual ) attention weights for an word wtyield the same ( or very similar ) prediction , it provides evidence to edit the importance of word wtinAinto a lower value .", "entities": []}, {"text": "Formally , let \u02c6 \u000b and \u00af \u000b be the original and counterfactual attention weights , respectively , and let \u02c6yand\u00afytbe the original prediction and its counterfactual prediction with attention change ( i.e. , from \u02c6 \u000b tto\u00af \u000b t ) on wt2x , respectively .", "entities": []}, {"text": "Then , knowing the quantityj\u02c6y\u0000\u00afytj , measured as the individualized treatment e \u000b ect ( ITE ) , enables measuring howAlgorithm 1 SANA Input : Training dataset D , Task - level annotation A Output : Model parameters f \u001e ; \u0012g", "entities": []}, {"text": "Initialize attention labels \u000b from A.Using Eq ( 3 ) f \u001e ; \u0012g argmin \u001e ; \u0012L(D ; \u000b ; \u001e ; \u0012).Using Eq ( 2 ) forz=1to z maxdo foreach ( x;y)2Ddo", "entities": []}, {"text": "h;\u02c6 \u000b  f \u001e ( x ) \u02c6y g\u0012(h;\u02c6 \u000b ) foreach w t2xdo ifA(wt)>0then \u00af \u000b  Counterfactuals ( \u02c6 \u000b ; wt ) \u00afyt g\u0012(h;\u00af \u000b ) ifTVD ( \u02c6y;\u00afyt)<\u000fthen A(wt )", "entities": []}, {"text": "\u0001A(wt ) end end end end \u0015", "entities": []}, {"text": "\u00001\u0015 .", "entities": []}, {"text": "In Eq ( 3 ) Update attention labels \u000b from A.Using Eq ( 3 ) f \u001e ; \u0012g argmin \u001e ; \u0012L(D ; \u000b ; \u001e ; \u0012).Using Eq ( 2 ) end returnf \u001e ; \u0012g much the word wtcontributes to the original prediction via attention mechanism .", "entities": []}, {"text": "For this measurement , we adopt the Total Variance Distance ( Jain and Wallace , 2019 ) between the two predictions , which is de\ufb01ned as follows : TVD ( \u02c6y;\u00afyt)=1 2CX c=1j\u02c6yc\u0000\u00afyc tj ( 4 ) where cis the class index .", "entities": []}, {"text": "If TVD value is too low , we can give a penalty by decaying the human annotation A(wt ) with a factor of", "entities": []}, {"text": ", which we empirically set as 0.5 , to update the attention labels .", "entities": []}, {"text": "3.2 Sample - level Attention Adaptation Based on TVD , we propose a simple yet e \u000b ective approach , Sample - level Attentio NAdaptation ( SANA ) , to derive the sample - level machine attention from the task - level human annotation .", "entities": []}, {"text": "As described in Alg . 1 , SANA starts with the classi\ufb01cation model trained with the initial attention labels \u000b .", "entities": []}, {"text": "Based on \u001e and\u0012 , we run the classi\ufb01cation inference several times for an input sample : one for obtaining the original attention weights \u02c6 \u000b  and the others for counterfactual attention weights \u00af \u000b .", "entities": []}, {"text": "More speci\ufb01cally , we \ufb01rst store the hidden representations hand the attention weights \u02c6 \u000b from f \u001e , and the original prediction \u02c6y .", "entities": []}, {"text": "Then , for each", "entities": []}, {"text": "6698word wt , Counterfactuals returns the counterfactual attention weights \u00af \u000b , by 1 ) copying \u02c6 \u000b but 2 ) assigning zero to the t - th dimension and 3 ) renormalizing as probability distribution , and we obtain its corresponding prediction result \u00afytby re - using h. Note that , since the hidden representation at time step tcontextualizes a word wtwith surrounding words , we adopt perturbing only single words in SANA , not multiple words at the same time , also enjoying the computational advantage .", "entities": []}, {"text": "Finally , based on \u02c6yand\u00afyt , as de\ufb01ned in Eq ( 4 ) , we compute TVD and update the human annotation Aby threshold \u000fand decay ratio", "entities": []}, {"text": ".", "entities": []}, {"text": "Once an iteration1is completed over the whole training corpus , we re", "entities": []}, {"text": "- train the network with the updated attention annotation and labels .", "entities": []}, {"text": "For the stable update , we observe that increasing the coe \u000ecient\u0015in", "entities": []}, {"text": "Eq ( 3 ) is crucial , as TVD is not an optimal metric , preventing \u000b from being \ufb02attened .", "entities": []}, {"text": "3.3 Zero - cost Supervision From this point on , for task - level supervision , we assume zero - cost human annotation e \u000b orts , either by using public resources or self - supervision .", "entities": []}, {"text": "Supervision by public resources Task - level annotation are often publicly available as resources or tools .", "entities": []}, {"text": "For example , sentiment lexicon ( Esuli and Sebastiani , 2006 ) consists of sentiment words , which are important to the sentiment classi\ufb01cation task , and named - entity recognizer ( NER ) ( Peters et al . , 2017 ) can collect entity words commonly attended in news categorization task .", "entities": [[32, 33, "TaskName", "NER"]]}, {"text": "We empirically show that both lexicon and NER can be adequate substitutes for the manual task - level annotation .", "entities": [[7, 8, "TaskName", "NER"]]}, {"text": "Model distillation In an extreme scenario without any human annotator and public resources , inspired by self knowledge distillation ( Furlanello et al . , 2018 ) , we report results for using the attention weights of the unsupervised model as a supervision .", "entities": [[17, 19, "MethodName", "knowledge distillation"]]}, {"text": "Note , however , this is highly unlikely in practice , but reported as a lower bound accuracy , when unsupervised attention noise is propagated through distillation supervision .", "entities": [[17, 18, "MetricName", "accuracy"]]}, {"text": "Using SANA is even more critical in this noisy annotation scenario , to denoise attention supervision from counterfactual reasoning , which we empirically analyze this in the subsequent section .", "entities": []}, {"text": "1O(jDj\u0001T ) , where Tis the maximum sequence length4", "entities": []}, {"text": "Experiment Setup 4.1 Datasets To validate the e \u000b ectiveness of SANA , we use the following three text classi\ufb01cation datasets , which are widely used ( Wang et al . , 2018 ; Jain and Wallace , 2019 ) and statistically diverse as well .", "entities": []}, {"text": "We split the o \u000ecial training split into 90 % and 10 % as training and validation sets respectively .", "entities": []}, {"text": "We expect SANA in two - sentence tasks , such as SNLI and MPQA , would be promising , which we leave as future work .", "entities": [[11, 12, "DatasetName", "SNLI"], [13, 14, "DatasetName", "MPQA"]]}, {"text": "\u0088SST2 ( Socher et al . , 2013 ): Stanford Sentiment Treebank provides around 11 K sentences tagged with sentiment on a scale from 1 ( most negative ) to 5 ( most positive ) .", "entities": []}, {"text": "We \ufb01lter out neutral samples and dichotomize the remaining sentences into positive ( 4,5 ) and negative ( 1,2 ) .", "entities": []}, {"text": "We set the maximum sequence length as 30 .", "entities": []}, {"text": "\u0088IMDB ( Maas et", "entities": []}, {"text": "al . , 2011 ): IMDB Large Movie Review Corpus is a binary sentiment classi\ufb01cation dataset containing 50 K polarized ( positive or negative ) movie reviews , split into half for training and testing .", "entities": [[5, 6, "DatasetName", "IMDB"]]}, {"text": "We set the maximum sequence length as 180 .", "entities": []}, {"text": "\u008820NG : 20 Newsgroups2contains around 19 K documents evenly categorized into 20 di \u000b erent categories .", "entities": []}, {"text": "Following ( Jain and Wallace , 2019 ) , we extract samples belonging to baseballandhockey classes , which we designate as 0 and 1 , deriving a binary classi\ufb01cation task ( Hockey vs Baseball ) .", "entities": [[21, 22, "DatasetName", "0"]]}, {"text": "We set the maximum sequence length as 300 .", "entities": []}, {"text": "4.2 Implementation Details For all datasets , we use skip - gram ( Mikolov et al . , 2013 ) ( o \u000ecial GoogleNews - vectors - negative300 ) word embeddings with 300 dimensions .", "entities": [[29, 31, "TaskName", "word embeddings"]]}, {"text": "We use 1layered GRU for each direction with hidden size of 150 for both SST2 and IMDB , and 300 for 20NG dataset , with g\u0012of 300 dimension with 0.5 dropout rate .", "entities": [[3, 4, "MethodName", "GRU"], [14, 15, "DatasetName", "SST2"], [16, 17, "DatasetName", "IMDB"]]}, {"text": "For attention mechanism , the size of trainable context vector is set to 100 for SST2 and 300 for IMDB and 20NG .", "entities": [[15, 16, "DatasetName", "SST2"], [19, 20, "DatasetName", "IMDB"]]}, {"text": "For attention supervision , we use the balancing coe\u000ecient\u0016=1:0 for SST2 and IMDB , and \u0016= 2:0 for 20NG .", "entities": [[10, 11, "DatasetName", "SST2"], [12, 13, "DatasetName", "IMDB"]]}, {"text": "Contrary to Zou et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) , we 2http://qwone.com/ ~jason/20Newsgroups/", "entities": []}, {"text": "6699observe a larger \u0016is more e \u000b ective for the smaller dataset .", "entities": []}, {"text": "We set the contrasting coe \u000ecient\u0015=3 except\u0015=5 for 20NG dataset .", "entities": []}, {"text": "In Alg . 1 , we use decay ratio", "entities": []}, {"text": "= 2:0 and TVD threshold \u000f=0:3 .", "entities": []}, {"text": "In our experiments , the decay ratio is not signi\ufb01cantly correlated with the \ufb01nal accuracy , but correlated more with the convergence period .", "entities": [[14, 15, "MetricName", "accuracy"]]}, {"text": "Setting", "entities": []}, {"text": "= 2:0 leads to the reported performance within zmax=5 .", "entities": []}, {"text": "For BERT , we train BERT - base architecture with a batch size of 4 over 3 epochs .", "entities": [[1, 2, "MethodName", "BERT"], [5, 6, "MethodName", "BERT"], [11, 13, "HyperparameterName", "batch size"]]}, {"text": "We used Adam with a learning rate of 6.25e-5 and PiecewiseLinear scheduler .", "entities": [[2, 3, "MethodName", "Adam"], [5, 7, "HyperparameterName", "learning rate"]]}, {"text": "All parameters are optimized until convergence , using Adam optimizer of learning rate 0 : 001 .", "entities": [[8, 9, "MethodName", "Adam"], [9, 10, "HyperparameterName", "optimizer"], [11, 13, "HyperparameterName", "learning rate"], [13, 14, "DatasetName", "0"]]}, {"text": "The learning parameters were chosen by the best performance on the validation set .", "entities": []}, {"text": "In Alg . 1 , the models are additionally \ufb01ne - tuned over 10 epochs for each iteration .", "entities": []}, {"text": "Note that learning time longer than our setting does not contribute to improving the model accuracy .", "entities": [[15, 16, "MetricName", "accuracy"]]}, {"text": "5 Results and Discussion We now proceed to empirically validate the e \u000b ectiveness of SANA , compared to unsupervised attention , and attention supervision approaches using either task - level or sample - level annotations as baselines ( shortly , unsupervised , task - level , and sample ) .", "entities": []}, {"text": "For task - level annotations ( e.g. , in SANA ) , we adopt pre - annotated task - level annotations without any additional human e \u000b orts : for the two sentiment tasks , we use SentiWordNet ( Esuli and Sebastiani , 2006 ) , and for 20NG task , we use entities recognized by AllenNLP NER ( Peters et al . , 2017 ) .", "entities": [[57, 58, "TaskName", "NER"]]}, {"text": "We thus present the empirical \ufb01ndings for the following four research questions : RQ1 : Does SANA improve model accuracy ?", "entities": [[19, 20, "MetricName", "accuracy"]]}, {"text": "RQ2 : Does SANA improve model robustness ?", "entities": []}, {"text": "RQ3 : Is SANA e \u000b ective for data - scarce cases ?", "entities": []}, {"text": "RQ4 : Does SANA improve attention explainability ?", "entities": []}, {"text": "5.1 RQ1 : Classi\ufb01cation Accuracy", "entities": [[4, 5, "MetricName", "Accuracy"]]}, {"text": "The main objective of this work is to improve attention supervisions for the purpose of better text classi\ufb01cation .", "entities": []}, {"text": "Thus , we evaluate the three attention methods by their contribution to the classi\ufb01cation performance .", "entities": []}, {"text": "Tab . 2 shows the classi\ufb01cation accuracy for three classi\ufb01cation datasets .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "In the table , we can observe the proposed approach , SANA with task - level annotation , outperforms all baselines in all the datasets .", "entities": []}, {"text": "Among the results , Accuracy SST2 IMDB 20NG BERT 91.67 94.10 93.25 unsupervised BiGRU 83.96 88.07 86.04 model distillation BiGRU 83.53 86.93 85.12 + SANA 84.35 88.03 88.23 task - level annotation BiGRU 85.12 89.30 87.19 + SANA 85.72 90.10 89.13 Table 2 : Classi\ufb01cation Performance : accuracy ( % ) on the three classi\ufb01cation datasets .", "entities": [[4, 5, "MetricName", "Accuracy"], [5, 6, "DatasetName", "SST2"], [6, 7, "DatasetName", "IMDB"], [8, 9, "MethodName", "BERT"], [13, 14, "MethodName", "BiGRU"], [19, 20, "MethodName", "BiGRU"], [32, 33, "MethodName", "BiGRU"], [47, 51, "MetricName", "accuracy ( % )"]]}, {"text": "SANA achieves the largest improvement over in 20NG dataset , which has the smallest training data .", "entities": []}, {"text": "This suggests that SANA can also provide e \u000b ective attention supervisions in data - scarce environments .", "entities": []}, {"text": "To discuss this issue further , we will repeat this comparison over the varying size of training data for RQ3 .", "entities": []}, {"text": "Our study also con\ufb01rms two additional observations to our advantage \u2013 counterfactual 1 ) is e \u000b ective even in model distillation setting and 2 ) meaningfully contributes to performance gains .", "entities": []}, {"text": "More speci\ufb01cally , 1 ) SANA achieves 84.35 % in SST2 dataset which is higher than the distillation only model , but lower than task - level supervised model .", "entities": [[10, 11, "DatasetName", "SST2"]]}, {"text": "2 ) this model gets 88.23 % in 20NG dataset , which outperforms even task - level supervised model with 1.04 point gains .", "entities": []}, {"text": "This also suggests the limitation of model distillation as supervision signals and supervision by public resources can provide better initial point for SANA than model distillation .", "entities": []}, {"text": "Our key contribution is to show zero - cost attention supervision can improve a simple model closer to a highly sophisticated model , such as BERT ( Devlin et al . , 2019 ) requiring more layers and data .", "entities": [[25, 26, "MethodName", "BERT"]]}, {"text": "This motivates us to supervise attention for BERT , though understanding of BERT internals , such as ( Rogers et al . , 2020 ) , is mostly observational at this stage \u2013 Intervening with attention would be an interesting future work .", "entities": [[7, 8, "MethodName", "BERT"], [12, 13, "MethodName", "BERT"]]}, {"text": "Our experimental results show that SANA works well in diverse scenarios , but we observe that the e \u000b ectiveness is reduced when the length of target text increases ( Figure 2 ) or token identi\ufb01ability decreases ( e.g. , complex architecture ): SANA more", "entities": []}, {"text": "6700e \u000b ectively works when the token identi\ufb01ability is improved ( by adding residual connection between two recurrent layers ) , achieving 0.83 point gain from 89.14 % , which is larger gap than 0.47 point gain without residual connection .", "entities": [[13, 15, "MethodName", "residual connection"], [38, 40, "MethodName", "residual connection"]]}, {"text": "5.2 RQ2 : Robustness in Adversarial Attacks Having tested for the overall performance with the original datasets , we evaluate the robustness of SANA with the the adversarial datasets .", "entities": []}, {"text": "Recently , adversarial examples ( Zhang et al . , 2019 ) have been employed as an evaluation tool for model robustness : while the adversarial example conveys very similar semantics of its original sample , but with small and intentional feature perturbations to cause classi\ufb01cation models to make false predictions .", "entities": []}, {"text": "For robustness analysis , we thus test whether the attention models can keep the original predictions from adversarial examples .", "entities": []}, {"text": "This experiment consists of the following steps : First , based on the original training data , we set a basic BiGRU model ( without attention mechanism ) as threat model , which an adversarial attack method aims to deceive .", "entities": [[21, 22, "MethodName", "BiGRU"], [34, 36, "TaskName", "adversarial attack"]]}, {"text": "Second , based on the original test data , we generate paraphrase texts by using the state - of - the - art attack method ( Alzantot et al . , 2018 ) with word - level perturbations .", "entities": []}, {"text": "Third , we randomly select almost 500 paraphrase texts , which succeed in changing the prediction of threat model , i.e. , adversarial examples .", "entities": []}, {"text": "Finally , we report the accuracy of the three attention models over both adversarial examples and their corresponding original samples , respectively .", "entities": [[5, 6, "MetricName", "accuracy"]]}, {"text": "Tab .", "entities": []}, {"text": "3 presents the results of adversarial attacks.3 In the table , we can \ufb01nd that SANA is more robust , showing the smallest gap of the classi\ufb01cation accuracy between the original and adversarial samples .", "entities": [[27, 28, "MetricName", "accuracy"]]}, {"text": "It demonstrates that , when the network is attending to the words having causal signals to the model prediction , the network becomes more robust against adversarial attacks , which is consistent with the experimental results in Lai et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "In addition to that , we observe similar results against the white - box adversarial examples ( Tsai et al . , 2019 ) , where SANA improves 3.20 and 1.80 point gains from both unsupervised and supervised attentions .", "entities": []}, {"text": "3The reason why \u201c Original \u201d is di \u000b erent from natural accuracy in Tab . 2 is that we conduct the experiments over the original samples only paired with the adversarial examples , incurring the biases in the test set .", "entities": [[12, 13, "MetricName", "accuracy"]]}, {"text": "Figure 1 : Sample E \u000b ectiveness : accuracy ( % ) on varying the amount of training samples in IMDB dataset .", "entities": [[8, 12, "MetricName", "accuracy ( % )"], [20, 21, "DatasetName", "IMDB"]]}, {"text": "5.3 RQ3 : Sample E \u000b ectiveness This section compares models over the varying amount of training samples in IMDB dataset , as a stress test for data - scarce scenarios .", "entities": [[19, 20, "DatasetName", "IMDB"]]}, {"text": "For this experiment , we collect the samplespeci\ufb01c annotations from human workers .", "entities": []}, {"text": "First , we randomly select 500 training samples from IMDB dataset , and ask the worker to underline the apparent rationales for the sentiment class , guided by the de\ufb01nition of rationale in Zhang", "entities": [[9, 10, "DatasetName", "IMDB"]]}, {"text": "et al .", "entities": []}, {"text": "( 2016 )", "entities": []}, {"text": ".", "entities": []}, {"text": "The data collection is conducted using an open annotation tool ( Yang et al . , 2018 ) .", "entities": []}, {"text": "Then , we build an additional method , named sample , which is trained with the collected sample - speci\ufb01c annotations .", "entities": []}, {"text": "The results are presented in Fig .", "entities": []}, {"text": "1 .", "entities": []}, {"text": "We notice that SANA and sample show much stronger performance when the training data is scarce , where similar results are reported in ( Bao et al . , 2018 ) .", "entities": []}, {"text": "As we expected , the attention supervision using the sample - speci\ufb01c annotations gets a higher accuracy than that using the task - level annotations , but can not be scaled - up above 500 training samples , which is represented by the red reference line .", "entities": [[16, 17, "MetricName", "accuracy"]]}, {"text": "In contrast , SANA improves accuracy with \u00151000 samples and its scalability .", "entities": [[5, 6, "MetricName", "accuracy"]]}, {"text": "This result demonstrates that our counterfactual inferences successfully augment one annotation into multiple ( counterfactual ) attention supervisions , better regularizing from limited samples .", "entities": []}, {"text": "5.4 RQ4 : Attention as Human Explanation", "entities": []}, {"text": "This section studies whether attention , after supervision , is more e \u000b ective for human consumption as model explanation .", "entities": []}, {"text": "Existing metrics for explainability measure whether attention correlates with ( a ) class prediction or ( b ) feature importance , discussed in the next sections respectively .", "entities": [[18, 20, "TaskName", "feature importance"]]}, {"text": "6701SST2 IMDB 20NG Original Adversarial j\u0001j Original Adversarial j\u0001j Original Adversarial j\u0001j unsupervised 47.2 47.8 0.6 68.8 64.1 4.7 47.7 48.3 0.6 task - level 50.3 48.3 2.1 69.2 65.0 4.1 48.7 48.2 0.5 task - level + SANA ( Ours ) 49.9 49.7 0.2 69.4 65.2 4.1 48.1 48.3 0.2 Table 3 : Adversarial Attack : accuracy ( % ) for original and adversarial examples on the three classi\ufb01cation dataset .", "entities": [[1, 2, "DatasetName", "IMDB"], [54, 56, "TaskName", "Adversarial Attack"], [57, 61, "MetricName", "accuracy ( % )"]]}, {"text": "Against the adversarial attacks , the proposed method SANA shows consistent performance with the smallest accuracy gap ( j\u0001j ) over all the datasets .", "entities": [[15, 16, "MetricName", "accuracy"]]}, {"text": "For this evaluation , we use 485 , 532 , and 478 pairs of original samples and adversarial examples , in SST2 , IMDB , and 20NG respectively .", "entities": [[21, 22, "DatasetName", "SST2"], [23, 24, "DatasetName", "IMDB"]]}, {"text": "5.4.1 Attention as Causal Explanation One measure for the explainability of attention is whether each attention weight captures the causality of word and class prediction , by permuting words and observing prediction changes .", "entities": []}, {"text": "If the learning is successful , such causal signals should be consistently observed in the test predictions .", "entities": []}, {"text": "To validate this , we employ the attention - permutation experiments designed in ( Jain and Wallace , 2019 ) , i.e. ,what - if simulation .", "entities": []}, {"text": "Speci\ufb01cally , when given an input sample in the test phase , we look into whether the randomly mutated attention ( i.e. , cause ) from the original attention yields any changes in the corresponding prediction result ( i.e. , e \u000b ect ) .", "entities": []}, {"text": "Here , TVD for the permutation can be regarded as a desirable evaluation measure : as TVD is lower , the ( original ) learned attention has a weak mapping with the model prediction , and vice versa .", "entities": []}, {"text": "The results are presented in Fig .", "entities": []}, {"text": "2 , where x - axis refers to TVD values , i.e. , the di \u000b erence of model predictions , and y - axis refers to the frequency of what - if simulations on their returning TVD value .", "entities": []}, {"text": "To carefully analyze this , we divide the simulation results by four di \u000b erent intervals of input sequence length , which can be an in\ufb02uencing factor : as the perturbations on longer texts are unlikely to make prediction changes ( Sen et al . , 2020 ) .", "entities": []}, {"text": "In this \ufb01gure , we can observe that SANA has the lowest frequency on TVD = 0 in all cases , showing the distribution skewed to larger TVD ( i.e. , right on x - axis ) compared to baselines .", "entities": [[16, 17, "DatasetName", "0"]]}, {"text": "Such distribution suggests that attention in SANA strongly a \u000b ects model prediction by the causal signals .", "entities": []}, {"text": "In unsupervised andvocab ( i.e. , task - level ) , the distributions are skewed to lower TVD ( i.e. , left on x - axis ) , having larger frequency on zero TVD than SANA .", "entities": []}, {"text": "These patterns indicate the baselines have weak attentions loosely aligned to model predictions , motivating SANA even working well in long texts.5.4.2", "entities": []}, {"text": "Attention as Importance Indicator As an alternative metric of attention explainablity , ( Jain and Wallace , 2019 ) considers the relationship between attention weights and gradient - based feature importance score of each word .", "entities": [[29, 31, "TaskName", "feature importance"]]}, {"text": "However , prior research suggests using word as a unit of importance feature is rather arti\ufb01cial , as word is contextualized by , and interacts with other words : ( Wiegre \u000b e and Pinter , 2019 ) observes such limitation , and", "entities": []}, {"text": "Shapley ( Chen et al . , 2018 ) measures interaction between features for capturing dependency of arbitrary subsets .", "entities": []}, {"text": "For this purpose , we report the KL divergence between C - Shapley4and attention weights , DKL(Shapley ( x)jjattention ( x ) ) .", "entities": []}, {"text": "We present the results in Tab . 4 , showing SANA approach is the most well correlated method with Shapley scores , well capturing word dependency .", "entities": []}, {"text": "unsupervised task - level SANA IMDB 52.62 12.69 8.86 Table 4 : KL - divergence from C - Shapley Intuitively , C - Shapley observes the interaction in n - gram , and our work , attending upon hidden representations of RNN , which are softn - grams , captures similar interactions .", "entities": [[5, 6, "DatasetName", "IMDB"]]}, {"text": "This result manifests that , standing on self - supervision signals , our counterfactual process can improve the explanation on the contextualization ability of RNN architectures .", "entities": []}, {"text": "6 Related Work Instead of treating attention as a by - product of model training , the following work explored how machine /human can consume attention for model improvement or explanation , respectively .", "entities": []}, {"text": "Machine /human may also provide supervision .", "entities": []}, {"text": "We thus categorize existing work by machine /human 4https://github.com/Jianbo-Lab/LCShapley", "entities": []}, {"text": "6702 ( a ) SST2 ( b ) IMDB ( c ) 20NG Figure 2 : Attention Analysis : x - axis refers to TVD values returned by what - if simulations and y - axis refers to the simulation frequency according to the returning TVD value .", "entities": [[4, 5, "DatasetName", "SST2"], [8, 9, "DatasetName", "IMDB"]]}, {"text": "The compared datasets are ( a ) SST2 for sentence - level binary classi\ufb01cation , ( b ) IMDB and ( c ) 20NG for document - level binary classi\ufb01cation.consumption and supervision .", "entities": [[7, 8, "DatasetName", "SST2"], [18, 19, "DatasetName", "IMDB"]]}, {"text": "Our work falls into human providing supervision ( with machine augmenting supervision ) for machine consumption .", "entities": []}, {"text": "6.1 Attention to /from", "entities": []}, {"text": "Human As for human consuming attention as explanation , there has been criticism that unsupervised attention weights are too poorly correlated with the contribution of each word for machine decision ( or , unfaithful ) ( Jain and Wallace , 2019 ; Serrano and Smith , 2019 ; Pruthi et al . , 2019 ) .", "entities": []}, {"text": "Meanwhile , ( Wiegre \u000b e and Pinter , 2019 ) develops diagnostics to decide when attention is good enough as explanation .", "entities": []}, {"text": "As for improving human consumption , one direction focuses on better aligning models to human , another on improving annotation quality .", "entities": []}, {"text": "First , identi\ufb01ability ( Brunner et al . , 2020 ) explains human - machine discrepancy , where tokenlevel information is lost in model hidden states .", "entities": []}, {"text": "For better alignment , ( Tutek and \u02c7Snajder , 2020 ) utilizes masked language model ( MLM ) loss and ( Mohankumar et al . , 2020 ) invents orthogonal LSTM representations .", "entities": [[16, 17, "DatasetName", "MLM"], [18, 19, "MetricName", "loss"], [30, 31, "MethodName", "LSTM"]]}, {"text": "Second , toward the direction of improving annotation , ( Barrett et al . , 2018 ; Zhong et al . , 2019 ; Bao et al . , 2018 ) adopts sample - speci\ufb01c human annotations .", "entities": []}, {"text": "In addition to rationales , ( Zhao et al . , 2018 ) uses event trigger words and ( Kim and Kim , 2018 ) leverages user authenticated domains to narrow down the scope of attentions .", "entities": []}, {"text": "( Strubell et al . , 2018 ) injects word dependency relations to recognize the semantic roles in text .", "entities": []}, {"text": "Such annotation overhead can be replaced by existing pre - annotated resources : ( Zou et al . , 2018 ) considers sentiment lexicon dictionary for a related task .", "entities": []}, {"text": "We pursue the second direction , but without incurring additional human annotation , by exploring the counterfactual augmentation , originated from self - supervision signals , contributing towards both accuracy and robustness of the model .", "entities": [[29, 30, "MetricName", "accuracy"]]}, {"text": "6.2 Attention to /from", "entities": []}, {"text": "Machine Machine consuming attention for higher accuracy is the most classical target scenario .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "( Yang et al . , 2016 ) proposes hierarchical attention for document classi\ufb01cation , ( Chen et al . , 2016 ) personalizes classi\ufb01cation to user and product attributes .", "entities": []}, {"text": "( Margatina et al . , 2019 ) incorporates knowledge information to the self - attention module , i.e. , lexicon features .", "entities": []}, {"text": "Alternatively , machine may mine or augment attention supervision : ( Tang et al . , 2019 ) automatically mines attention supervision by masking - out", "entities": []}, {"text": "6703highly attentive words in a progressive manner .", "entities": []}, {"text": "( Choi et al . , 2019 ) augments counterfactual observations to debias human attention supervision via instance similarity .", "entities": []}, {"text": "Our work is of combining the strength of the two works : we automatically improve attention supervision via self - supervision signals , but we build it with free task - level resources .", "entities": []}, {"text": "7 Conclusion & Future Work", "entities": []}, {"text": "We studied the problem of attention supervision , and showed that requiring sample - level human supervision is often less e \u000b ective than task - level alternative with lower ( and often zero- ) overhead .", "entities": []}, {"text": "Speci\ufb01cally , we proposed a counterfactual signal for self - supervision , to augment task - level human annotation , into sample - level machine attention supervision , to increase both the accuracy and robustness of the model .", "entities": [[32, 33, "MetricName", "accuracy"]]}, {"text": "We hope future research to explore scenarios where human intuition is not working as well as text classi\ufb01cation , such as graph attention (", "entities": []}, {"text": "Veli \u02c7ckovi \u00b4 c et al . , 2017 ) .", "entities": []}, {"text": "Acknowledgments This work is supported by AI Graduate School Program ( 2020 - 0 - 01361 ) and IITP grant ( No.20170 - 01779 , XAI ) supervised by IITP .", "entities": [[13, 14, "DatasetName", "0"]]}, {"text": "Hwang is a corresponding author .", "entities": []}, {"text": "References Moustafa Alzantot , Yash Sharma , Ahmed Elgohary , Bo - Jhang Ho , Mani Srivastava , and Kai - Wei Chang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Generating natural language adversarial examples .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Yujia Bao , Shiyu Chang , Mo Yu , and Regina Barzilay .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Deriving machine attention from human rationales .", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Maria Barrett , Joachim Bingel , Nora Hollenstein , Marek Rei , and Anders S\u00f8gaard .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Sequence classi\ufb01cation with human attention .", "entities": []}, {"text": "In CoNLL .", "entities": []}, {"text": "Gino Brunner , Yang Liu , Damian Pascual Ortiz , Oliver Richter , Massimiliano Ciaramita , and Roger Wattenhofer .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "On identi\ufb01ability in transformers .", "entities": []}, {"text": "Oana - Maria Camburu , Tim Rockt \u00a8aschel , Thomas Lukasiewicz , and Phil Blunsom .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "e - snli : natural language inference with natural language explanations .", "entities": [[0, 3, "DatasetName", "e - snli"], [4, 7, "TaskName", "natural language inference"]]}, {"text": "In NeurIPS .", "entities": []}, {"text": "Huimin Chen , Maosong Sun , Cunchao Tu , Yankai Lin , and Zhiyuan Liu . 2016 .", "entities": []}, {"text": "Neural sentiment classi\ufb01cation with user and product attention .", "entities": []}, {"text": "In EMNLP .Jianbo", "entities": []}, {"text": "Chen , Le Song , Martin J Wainwright , and Michael I Jordan .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "L - shapley and c - shapley : E\u000ecient model interpretation for structured data .", "entities": []}, {"text": "Seungtaek Choi , Haeju Park , and Seung - won Hwang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Counterfactual attention supervision .", "entities": []}, {"text": "In 2019 IEEE International Conference on Data Mining ( ICDM ) , pages 1006\u20131011 . IEEE .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "Bert : Pre - training of deep bidirectional transformers for language understanding .", "entities": []}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 .", "entities": []}, {"text": "Andrea Esuli and Fabrizio Sebastiani .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Sentiwordnet : A publicly available lexical resource for opinion mining .", "entities": [[8, 10, "TaskName", "opinion mining"]]}, {"text": "In LREC .", "entities": []}, {"text": "Tommaso Furlanello , Zachary C Lipton , Michael Tschannen , Laurent Itti , and Anima Anandkumar .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Born again neural networks .", "entities": []}, {"text": "ICML .", "entities": []}, {"text": "Sarthak Jain and Byron C Wallace .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Attention is not explanation .", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Fredrik Johansson , Uri Shalit , and David Sontag .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Learning representations for counterfactual inference .", "entities": [[3, 5, "TaskName", "counterfactual inference"]]}, {"text": "In ICML .", "entities": []}, {"text": "Joo - Kyung Kim and Young - Bum Kim .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Supervised domain enablement attention for personalized domain classi\ufb01cation .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Qiuxia Lai , Wenguan Wang , Salman Khan , Jianbing Shen , Hanqiu Sun , and Ling Shao . 2019 .", "entities": []}, {"text": "Human vs machine attention in neural networks : A comparative study .", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Chenxi Liu , Junhua Mao , Fei Sha , and Alan L Yuille . 2017 .", "entities": []}, {"text": "Attention correctness in neural image captioning .", "entities": [[4, 6, "TaskName", "image captioning"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Andrew L Maas , Raymond E Daly , Peter T Pham , Dan Huang , Andrew Y Ng , and Christopher Potts . 2011 .", "entities": []}, {"text": "Learning word vectors for sentiment analysis .", "entities": [[4, 6, "TaskName", "sentiment analysis"]]}, {"text": "In ACL .", "entities": []}, {"text": "Katerina Margatina , Christos Baziotis , and Alexandros Potamianos .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Attention - based conditioning methods for external knowledge integration .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 3944 \u2013 3951 .", "entities": []}, {"text": "Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Je \u000b Dean .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Distributed representations of words and phrases and their compositionality .", "entities": []}, {"text": "In NIPS .", "entities": []}, {"text": "Akash Kumar Mohankumar , Preksha Nema , Sharan Narasimhan , Mitesh M Khapra , Balaji Vasan Srinivasan , and Balaraman Ravindran .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "2020 .", "entities": []}, {"text": "Towards transparent and explainable attention models .", "entities": []}, {"text": "arXiv preprint arXiv:2004.14243 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "6704Matthew Peters , Waleed Ammar , Chandra Bhagavatula , and Russell Power . 2017 .", "entities": []}, {"text": "Semi - supervised sequence tagging with bidirectional language models .", "entities": []}, {"text": "InACL .", "entities": []}, {"text": "Danish Pruthi , Mansi Gupta , Bhuwan Dhingra , Graham Neubig , and Zachary C Lipton .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Learning to deceive with attention - based explanations .", "entities": []}, {"text": "arXiv preprint arXiv:1909.07913 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Anna Rogers , Olga Kovaleva , and Anna Rumshisky .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "A primer in bertology : What we know about how bert works .", "entities": []}, {"text": "arXiv preprint arXiv:2002.12327 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Cansu Sen , Thomas Hartvigsen , Biao Yin , Xiangnan Kong , and Elke Rundensteiner . 2020 .", "entities": []}, {"text": "Human attention maps for text classi\ufb01cation : Do humans and neural networks focus on the same words ?", "entities": []}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics .", "entities": []}, {"text": "So\ufb01a Serrano and Noah A Smith .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Is attention interpretable ?", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D Manning , Andrew Ng , and Christopher Potts . 2013 .", "entities": []}, {"text": "Recursive deep models for semantic compositionality over a sentiment treebank .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Emma Strubell , Patrick Verga , Daniel Andor , David Weiss , and Andrew McCallum .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Linguistically - informed self - attention for semantic role labeling .", "entities": [[7, 10, "TaskName", "semantic role labeling"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Jialong Tang , Ziyao Lu , Jinsong Su , Yubin Ge , Linfeng Song , Le Sun , and Jiebo Luo . 2019 .", "entities": []}, {"text": "Progressive selfsupervised attention learning for aspect - level sentiment analysis .", "entities": [[8, 10, "TaskName", "sentiment analysis"]]}, {"text": "In ACL .", "entities": []}, {"text": "Yi - Ting Tsai , Min - Chu Yang , and Han - Yu Chen .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Adversarial attack on sentiment classi\ufb01cation .", "entities": [[0, 2, "TaskName", "Adversarial attack"]]}, {"text": "In Proceedings of the 2019 ACL Workshop BlackboxNLP : Analyzing and Interpreting Neural Networks for NLP , pages 233\u2013240 .", "entities": []}, {"text": "Martin Tutek and Jan \u02c7Snajder .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Staying true to your word:(how ) can attention become explanation ?", "entities": []}, {"text": "arXiv preprint arXiv:2005.09379 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Petar Veli \u02c7ckovi \u00b4 c , Guillem Cucurull , Arantxa Casanova , Adriana Romero , Pietro Lio , and Yoshua Bengio .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Graph attention networks .", "entities": []}, {"text": "arXiv preprint arXiv:1710.10903 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Alex Wang , Amanpreet Singh , Julian Michael , Felix Hill , Omer Levy , and Samuel Bowman .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Glue : A multi - task benchmark and analysis platform for natural language understanding .", "entities": [[11, 14, "TaskName", "natural language understanding"]]}, {"text": "In Proceedingsof the 2018 EMNLP Workshop BlackboxNLP : Analyzing and Interpreting Neural Networks for NLP , pages 353\u2013355 .", "entities": []}, {"text": "Sarah Wiegre \u000b e and Yuval Pinter .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Attention is not not explanation .", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Jie Yang , Yue Zhang , Linwei Li , and Xingxuan Li .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Yedda : A lightweight collaborative text span annotation tool .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Zichao Yang , Diyi Yang , Chris Dyer , Xiaodong He , Alexander J Smola , and Eduard H Hovy .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Hierarchical attention networks for document classi\ufb01cation .", "entities": []}, {"text": "In NAACL .", "entities": []}, {"text": "Licheng Yu , Mohit Bansal , and Tamara Berg . 2017 .", "entities": []}, {"text": "Hierarchically - attentive rnn for album summarization and storytelling .", "entities": [[6, 7, "TaskName", "summarization"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Wei Emma Zhang , Quan Z Sheng , and Ahoud Abdulrahmn F Alhazmi .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Generating textual adversarial examples for deep learning models : A survey .", "entities": []}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Ye Zhang , Iain Marshall , and Byron C Wallace .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Rationale - augmented convolutional neural networks for text classi\ufb01cation .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Yue Zhao , Xiaolong Jin , Yuanzhuo Wang , and Xueqi Cheng .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Document embedding enhanced event detection with hierarchical and supervised attention .", "entities": [[0, 2, "TaskName", "Document embedding"], [3, 5, "TaskName", "event detection"]]}, {"text": "InACL .", "entities": []}, {"text": "Ruiqi Zhong , Steven Shao , and Kathleen McKeown .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Fine - grained sentiment analysis with faithful attention .", "entities": [[3, 5, "TaskName", "sentiment analysis"]]}, {"text": "arXiv preprint .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Yicheng Zou , Tao Gui , Qi Zhang , and Xuanjing Huang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A lexicon - based supervised attention model for neural sentiment analysis .", "entities": [[9, 11, "TaskName", "sentiment analysis"]]}, {"text": "In COLING .", "entities": []}]