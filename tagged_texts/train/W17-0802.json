[{"text": "Proceedings of the 11th Linguistic Annotation Workshop , pages 13\u201323 , Valencia , Spain , April 3 , 2017 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2017 Association for Computational Linguistics Finding Good Conversations Online : The Yahoo News Annotated Comments Corpus Courtney Napoles , 1Joel Tetreault , 2Enrica Rosato , 3Brian Provenzale , 4andAasish Pappu3 1Johns Hopkins University , napoles@cs.jhu.edu 2Grammarly , joel.tetreault@grammarly.com 3Yahoo,{aasishkp|enricar } @yahoo - inc.com 4Accellion ,", "entities": []}, {"text": "bprovenzale@gmail.com", "entities": []}, {"text": "Abstract", "entities": []}, {"text": "This work presents a dataset and annotation scheme for the new task of identifying \u201c good \u201d conversations that occur online , which we call ERICs :", "entities": []}, {"text": "Engaging , Respectful , and/or Informative Conversations .", "entities": []}, {"text": "We develop a taxonomy to re\ufb02ect features of entire threads and individual comments which we believe contribute to identifying ERICs ; code a novel dataset of Yahoo News comment threads ( 2.4kthreads and 10kcomments ) and 1kthreads from the Internet Argument Corpus ; and analyze the features characteristic of ERICs .", "entities": []}, {"text": "This is one of the largest annotated corpora of online human dialogues , with the most detailed set of annotations .", "entities": []}, {"text": "It will be valuable for identifying ERICs and other aspects of argumentation , dialogue , and discourse .", "entities": []}, {"text": "1 Introduction Automatically curating online comments has been a large focus in recent NLP and social media work , as popular news outlets can receive millions of comments on their articles each month ( Warzel , 2012 ) .", "entities": []}, {"text": "Comment threads often range from vacuous to hateful , but good discussions dooccur online , with people expressing different viewpoints and attempting to inform , convince , or better understand the other side , but they can get lost among the multitude of unconstructive comments .", "entities": []}, {"text": "We hypothesize that identifying and promoting these types of conversations ( ERICs ) will cultivate a more civil and constructive atmosphere in online communities and potentially encourage participation from more users .", "entities": []}, {"text": "ERICs are characterized by:\u2022A respectful exchange of ideas , opinions , and/or information in response to a given topic(s ) .", "entities": []}, {"text": "\u2022Opinions expressed as an attempt to elicit a dialogue or persuade .", "entities": []}, {"text": "\u2022Comments that seek to contribute some new information or perspective on the relevant topic .", "entities": []}, {"text": "ERICs have no single identifying attribute : for instance , an exchange where communicants are in total agreement throughout can be an ERIC , as can an exchange with heated disagreement .", "entities": []}, {"text": "Figures 1 and 2 contain two threads that are characterized by continual disagreement , but one is an ERIC and the other is not .", "entities": []}, {"text": "We have developed a new coding scheme to label ERICs and identify six dimensions of comments and three dimensions of threads that are frequently seen in the comments section .", "entities": []}, {"text": "Many of these labels are for characteristics of online conversations not captured by traditional argumentation or dialogue features .", "entities": []}, {"text": "Some of the labels we collect have been annotated in previous work ( \u00a7 2 ) , but this is the \ufb01rst time they are aggregated in a single corpus at the dialogue level .", "entities": []}, {"text": "In this paper , we present the Yahoo News Annotated Comments Corpus ( YNACC ) , which contains 2.4kthreads and 10kcomments from the comments sections of Yahoo News articles .", "entities": []}, {"text": "We additionally collect annotations on 1kthreads from the Internet Argument Corpus ( Abbott et al . , 2016 ) , representing another domain of online debates .", "entities": []}, {"text": "We contrast annotations of Yahoo and IAC threads , explore ways in which threads perceived to be ERICs differ in this two venues , and identify some unanticipated characteristics of ERICs .", "entities": []}, {"text": "This is the \ufb01rst exploration of how characteristics of individual comments contribute to the dialogue - level classi\ufb01cation of an exchange .", "entities": []}, {"text": "YNACC will facilitate research to understand ERICS and other aspects of dialogue .", "entities": []}, {"text": "The corpus and annotations will be available at https : //github.com / cnap / ynacc .13", "entities": []}, {"text": "Legend Agreement : Agree   ! , Disagree   \" , Adjunct opinion \u270b Audience : Broadcast   $ , Reply   % Persuasiveness : Persuasive   & , Not persuasive   ' Sentiment : Mixed   ( , Neutral   ) , Negative   \u2639 , Positive   + Topic : Off - topic with article   , , off - topic with conv .", "entities": []}, {"text": "-Tone :                          .ControversialControversialSarcasticSarcastic $ \t  ' \t  \u2639 % ' \t  \u2639 \" \t  % \t  & \t  ) \u270b % \t  & \t  )", "entities": []}, {"text": "\u270b % '", "entities": []}, {"text": "\u2639 \u2639 \" \t  % \t  & \t  \u2639 \u2639 \" \t when a country has to use force to keep it 's businesses behind a wall .", "entities": []}, {"text": ". .", "entities": []}, {"text": "something is very wrong .", "entities": []}, {"text": "will the next step be forcing the talented and wealthy to remain ?", "entities": []}, {"text": "this strategy did not work well for the soviet union .", "entities": []}, {"text": "Ayour solution is?B@B , lower the govt imposed costs and businesses will stay voluntarily .", "entities": []}, {"text": "Cjust because a company was started in us , given large tax breakes in the us and makes most of its profits in the us does not mean it owes loyalty right ?", "entities": []}, {"text": "they have to appease the shareholders who want more value so lower your cost of business by lowering taxes while still getting all the perks is one way of doing it .", "entities": []}, {"text": "D@D - in your world who eventually pays the taxes that our gov't charges business?C@C lowering corporate taxes does not equate to more jobs , its only equates to corporations making more money .", "entities": []}, {"text": "did you think they take their profits and make high paying jobs with them ?", "entities": []}, {"text": "lol wake up!BHeadline : Allergan CEO : Feds blindsided us on Pfizer dealFigure 1 : An ERIC that is labeled argumentative , positive / respectful , and having continual disagreement .", "entities": []}, {"text": "ControversialMean ! \t  \" \t  \u2639 Controversial $ \t  % \t  & ' \t  $ \" \t  \u2639 ' \t ControversialInformative $ \t  % \t  ( ' \t Informative $ \t  % \t  ( ' \t Controversial $ \t  % \t  \u2639 ' \t  $ \" \t  ( \t  ) ' \t  $ \" \t  ( \t  ) ' \t  $ \" \t  ( \t  ) ' \t  $ \" \t  ( ' \t\t  ) quit your whining you are in america assimilate into american society .", "entities": []}, {"text": "or go back where you came from .", "entities": []}, {"text": "Eamerican society is that of immigrants and the freedom to practice whatever religion you wish .", "entities": []}, {"text": "you anti american?F@F , you may be an immigrant , but i 'm notGthe only reason you are an american is because of immigrants .", "entities": []}, {"text": "Fthat can be said of all humans .", "entities": []}, {"text": "humans migrated from africa .", "entities": []}, {"text": "everyone in germany is an immigrant .", "entities": []}, {"text": "Gthen any statement about they need to \" go back \" is irrelevant and wrong .", "entities": []}, {"text": "thanks for proving my point .", "entities": []}, {"text": "Ffloridians tell new yorkers to go back .", "entities": []}, {"text": "you have no point .", "entities": []}, {"text": "Gjust because someone says something does nt make it valid .", "entities": []}, {"text": "your point has no point .", "entities": []}, {"text": "Fjust because someone says something does nt make it valid .", "entities": []}, {"text": "nothing you say is valid .", "entities": []}, {"text": "Gthat 's your opinion .", "entities": []}, {"text": "but it 's not valid .", "entities": []}, {"text": "my factual statement is .", "entities": []}, {"text": "FHeadline : ' The Daily Show ' Nailed", "entities": []}, {"text": "How Islamophobia Hurts the Sikh Community Too Figure 2 : A non - ERIC that is labeled argumentative andoff - topic with continual disagreement .", "entities": []}, {"text": "2 Related work Recent work has focused on the analysis of usergenerated text in various online venues , including labeling certain qualities of individual comments , comment pairs , or the roles of individual commenters .", "entities": []}, {"text": "The largest and most extensively annotated corpus predating this work is the Internet Argument Corpus ( IAC ) , which contains approximately 480kcomments in 16.5kthreads from on - line forums in which users debate contentious issues .", "entities": []}, {"text": "The IAC has been coded for for topic ( 3k threads ) , stance ( 2kauthors ) , and agreement , sarcasm , and hostility ( 10kcomment pairs ) ( Abbott et al . , 2016 ;", "entities": []}, {"text": "Walker et al . , 2012 ) .", "entities": []}, {"text": "Comments from online news articles are annotated in the SENSEI corpus , which contains human - authored summaries of 1.8kcomments posted on Guardian articles ( Barker et al . , 2016 ) .", "entities": []}, {"text": "Participants described14", "entities": []}, {"text": "each comment with short , free - form text labels and then wrote a 150\u2013250 - word comment summary with these labels .", "entities": []}, {"text": "Barker et al .", "entities": []}, {"text": "( 2016 ) recognized that comments have diverse qualities , many of which are coded in this work ( \u00a7 3 ) , but did not explicitly collect labels of them .", "entities": []}, {"text": "Previous works present a survey of how editors and readers perceive the quality of comments posted in online news publications ( Diakopoulos and Naaman , 2011 ) and review the criteria professional editors use to curate comments ( Diakopoulos , 2015 ) .", "entities": []}, {"text": "The latter identi\ufb01es 15 criteria for curating user - generated responses , from online and radio comments to letters to the editor .", "entities": []}, {"text": "Our annotation scheme overlaps with those criteria but also diverges as we wish for the labels to re\ufb02ect the nature of all comments posted on online articles instead of just the qualities sought in editorially curated comments .", "entities": []}, {"text": "ERICs can take many forms and may not re\ufb02ect the formal tone or intent that editors in traditional news outlets seek .", "entities": []}, {"text": "Our coding scheme intersects with attributes examined in several different areas of research .", "entities": []}, {"text": "Some of the most recent and relevant discourse corpora from online sources related to this work include the following : Concepts related to persuasiveness have been studied , including annotations for \u201c convincing - ness \u201d in debate forums ( Habernal and Gurevych , 2016 ) , in\ufb02uencers in discussions from blogs and Wikipedia ( Biran et al . , 2012 ) , and user relations as a proxy of persuasion in reddit ( Tan et al . , 2016 ; Wei et al . , 2016 ) .", "entities": [[72, 73, "DatasetName", "reddit"]]}, {"text": "Politeness was labeled and identi\ufb01ed in Stack Exchange and Wikipedia discussions ( Danescu - NiculescuMizil et al . , 2013 ) .", "entities": []}, {"text": "Some previous work focused on detecting agreement has considered blog and Wikipedia discussions ( Andreas et al . , 2012 ) and debate forums ( Skeppstedt et al . , 2016 ) .", "entities": []}, {"text": "Sarcasm has been identi\ufb01ed in a corpus of microblogs identi\ufb01ed with the hashtag # sarcasm on Twitter ( Gonz \u00b4 alez - Ib \u00b4 anez et al . , 2011 ; Davidov et al . , 2010 ) and in online forums ( Oraby et al . , 2016 ) .", "entities": []}, {"text": "Sentiment has been studied widely , often in the context of reviews ( Pang and Lee , 2005 ) , and in the context of user - generated exchanges , positive and negative attitudes have been identi\ufb01ed in Usenet discussions ( Hassan et al . , 2010 ) .", "entities": []}, {"text": "Other qualities of user - generated text that are not covered in this work but have been investigated before include metaphor ( Jang et al . , 2014 ) and tolerance ( Mukherjee et al . , 2013 ) in online discussionthreads , \u201c dogmatism \u201d of reddit users ( Fast and Horvitz , 2016 ) , and argumentation units in discussions related to technology ( Ghosh et al . , 2014 ) .", "entities": [[47, 48, "DatasetName", "reddit"]]}, {"text": "3 Annotation scheme", "entities": []}, {"text": "This section outlines our coding scheme for identifying ERICs , with labels for comment threads and each comment contained therein .", "entities": []}, {"text": "Starting with the annotation categories from the IAC and the curation criteria of Diakopoulos ( 2015 ) , we have adapted these schemes and identi\ufb01ed new characteristics that have broad coverage over 100 comment threads ( \u00a7 4 ) that we manually examined .", "entities": []}, {"text": "Annotations are made at the thread - level and thecomment - level .", "entities": []}, {"text": "Thread - level annotations capture the qualities of a thread on the whole , while comment - level annotations re\ufb02ect the characteristics of each comment .", "entities": []}, {"text": "The labels for each dimension are described below .", "entities": []}, {"text": "Only one label per dimension is allowed unless otherwise speci\ufb01ed .", "entities": []}, {"text": "3.1 Thread labels Agreement", "entities": []}, {"text": "The overall agreement present in a thread .", "entities": []}, {"text": "\u2022Agreement throughout \u2022Continual disagreement \u2022Agreement\u2192disagreement : Begins with agreement which turns into disagreement .", "entities": []}, {"text": "\u2022Disagreement\u2192agreement : Starts with disagreement that converges into agreement .", "entities": []}, {"text": "Constructiveness", "entities": []}, {"text": "A binary label indicating when a conversation is an ERIC , or has a clear exchange of ideas , opinions , and/or information done so somewhat respectfully.1 \u2022Constructive \u2022Not", "entities": []}, {"text": "constructive Type The overall type or tone of the conversation , describing the majority of comments .", "entities": []}, {"text": "Two labels can be chosen if conversations exhibit more than one dominant feature .", "entities": []}, {"text": "\u2022Argumentative : Contains a lot of \u201c back and forth \u201d between participants that does not necessarily reach a conclusion .", "entities": []}, {"text": "\u2022Flamewar : Contains insults , users \u201c yelling \u201d at each other , and no information exchanged .", "entities": []}, {"text": "1Note that this de\ufb01nition of constructive differs from that of Niculae and Danescu - Niculescu - Mizil ( 2016 ) , who use the term to denote discrete progress made towards identifying a point on a map .", "entities": []}, {"text": "Our de\ufb01nition draws from the more traditional meaning when used in the context of conversations as \u201c intended to be useful or helpful \u201d ( Macmillan , 2017).15", "entities": []}, {"text": "\u2022Off - Topic / digression : Comments are completely irrelevant to the article or each other , or the conversation starts on topic but veers off into another direction .", "entities": []}, {"text": "\u2022Personal stories : Participants exchange personal anecdotes .", "entities": []}, {"text": "\u2022Positive / respectful : Consists primarily of comments expressing opinions in a respectful , potentially empathetic manner .", "entities": []}, {"text": "\u2022Snarky / humorous : Participants engage with each other using humor rather than argue or sympathize .", "entities": []}, {"text": "May be on- or off - topic .", "entities": []}, {"text": "3.2 Comment labels Agreement Agreement expressed with explicit phrasing ( e.g. , I disagree ... ) or implicitly , such as in Figure 2 .", "entities": []}, {"text": "Annotating the target of ( dis)agreement is left to future work due to the number of other codes the annotators need to attend to .", "entities": []}, {"text": "Multiple labels can be chosen per comment , since a comment can express agreement with one statement and disagreement with another .", "entities": []}, {"text": "\u2022Agreement with another commenter \u2022Disagreement with another commenter \u2022Adjunct opinion : Contains a perspective that has not yet been articulated in the thread .", "entities": []}, {"text": "Audience The target audience of a comment .", "entities": []}, {"text": "\u2022Reply to speci\ufb01c commenter : Can be explicit ( i.e. , @HANDLE ) or implicit ( not directly naming the commenter ) .", "entities": []}, {"text": "The target of a reply is not coded .", "entities": []}, {"text": "\u2022Broadcast message : Is not directed to a speci\ufb01c person(s ) .", "entities": []}, {"text": "Persuasiveness A binary label indicating whether a comment contains persuasive language or an intent to persuade .", "entities": []}, {"text": "\u2022Persuasive \u2022Not persuasive Sentiment The overall sentiment of a comment , considering how the user feels with respect to what information they are trying to convey .", "entities": []}, {"text": "\u2022Negative \u2022Neutral \u2022Positive \u2022Mixed : Contains both positive and negative sentiments .", "entities": []}, {"text": "Tone These qualities describe the overall tone of a comment , and more than one can apply .", "entities": []}, {"text": "\u2022Controversial : Puts forward a strong opinion that will most likely cause disagreement .", "entities": []}, {"text": "\u2022Funny : Expresses or intends to express humor.\u2022Informative : Contributes new information to the discussion .", "entities": []}, {"text": "\u2022Mean : The purpose of the comment is to be rude , mean , or hateful .", "entities": []}, {"text": "\u2022Sarcastic : Uses sarcasm with either intent to humor ( overlaps with Funny ) or offend .", "entities": []}, {"text": "\u2022Sympathetic : A warm , friendly comment that expresses positive emotion or sympathy .", "entities": [[10, 11, "DatasetName", "emotion"]]}, {"text": "Topic The topic addressed in a comment , and more than one label can be chosen .", "entities": []}, {"text": "Comments are on - topic unless either Off - topic label is selected .", "entities": []}, {"text": "\u2022Off - topic with the article \u2022Off - topic with the conversation : A digression from the conversation .", "entities": []}, {"text": "\u2022Personal story : Describes the user \u2019s personal experience with the topic .", "entities": []}, {"text": "4 Corpus collection With the taxonomy described above , we coded comments from two separate domains : online news articles and debate forums .", "entities": []}, {"text": "Threads from online news articles YNACC contains threads from the \u201c comments section \u201d of Yahoo News articles from April 2016.2Yahoo \ufb01lters comments containing hate speech ( Nobata et al . , 2016 ) and abusive language using a combination of manual review and automatic algorithms , and these comments are not included in our corpus .", "entities": [[24, 26, "DatasetName", "hate speech"], [35, 37, "TaskName", "abusive language"]]}, {"text": "From the remaining comments , we identi\ufb01ed threads , which contain an initial comment and at least one comment posted in reply .", "entities": []}, {"text": "Yahoo threads have a single - level of embedding , meaning that users can only post replies under a top - level comment .", "entities": []}, {"text": "In total , we collected 521,608 comments in 137,620 threads on 4,714 articles on topics including \ufb01nance , sports , entertainment , and lifestyle .", "entities": []}, {"text": "We also collected the following metadata for each comment : unique user ID , time posted , headline , URL , category , and the number of thumbs up and thumbs down received .", "entities": []}, {"text": "We included comments posted on a thread regardless of how much time had elapsed since the initial comment because the vast majority of comments were posted in close sequence : 48 % in the \ufb01rst hour after an initial comment , 67 % within the \ufb01rst three hours , and 92 % within the \ufb01rst 24 hours .", "entities": []}, {"text": "We randomly selected 2,300 threads to annotate , oversampling longer threads since the aver2Excluding comments labeled non - English by LangID , a high - accuracy tool for identifying languages in multiple domains ( Lui and Baldwin , 2012)16", "entities": [[25, 26, "MetricName", "accuracy"]]}, {"text": "IAC Yahoo # Threads 1,000 2,400 # Comments 16,555 9,160 Thread length 29\u00b155 4 \u00b13 Comment length 568\u00b1583 232 \u00b1538 Trained 0 1,400 threads 9,160 comments Untrained 1,000 threads 1,300 threads Table 1 : Description of the threads and comments annotated in this work and and the number coded by trained and untrained annotators .", "entities": [[21, 22, "DatasetName", "0"]]}, {"text": "Thread length is in comments , comment length in characters .", "entities": []}, {"text": "age Yahoo thread has only 3.8 comments .", "entities": []}, {"text": "The distribution of thread lengths is 20 % with 2\u20134 comments , 60 % 5\u20138 , and 20 % 9\u201315 .", "entities": []}, {"text": "For a held - out test set , we collected an additional 100 threads from Yahoo articles posted in July 2016 , with the same length distribution .", "entities": []}, {"text": "Those threads are not included in the analysis performed herein .", "entities": []}, {"text": "Threads from web debate forums To test this annotation scheme on a different domain , we also code online debates from the IAC 2.0 ( Abbott et al . , 2016 ) .", "entities": []}, {"text": "IAC threads are categorically different from Yahoo ones in terms of their stated purpose ( debate on a particular topic ) and length .", "entities": []}, {"text": "The mean IAC thread has 29 comments and each comment has 102 tokens , compared to Yahoo threads which have 4 comments with 51 tokens each .", "entities": []}, {"text": "Because signi\ufb01cant attention is demanded to code the numerous attributes , we only consider IAC threads with 15 comments or fewer for annotation , but do not limit the comment length .", "entities": []}, {"text": "In total , we selected 1,000 IAC thread to annotate , speci\ufb01cally : 474 threads from 4forums that were coded in the IAC , all 23 threads from CreateDebate , and 503 randomly selected threads from ConvinceMe .", "entities": []}, {"text": "4.1 Annotation The corpus was coded by two groups of annotators : professional trained editors and untrained crowdsourced workers .", "entities": []}, {"text": "Three separate annotators coded each thread .", "entities": []}, {"text": "The trained editors were paid contractors who received two 30\u201345 - minute training sessions , editorial guidelines ( 2,000 - word document ) , and two sample annotated threads .", "entities": []}, {"text": "The training sessions were recorded and available to the annotators during annotation , as were the guidelines .", "entities": []}, {"text": "They could communicate their questions to the trainers , who were two authors of this paper , and receive feedback during the training and annotation phases .", "entities": []}, {"text": "Because training is expensive and time consuming , we also collected annotations from untrained coders on Amazon Mechanical Turk ( AMT ) .", "entities": []}, {"text": "To simplify the task for AMT , we only solicited thread - level labels , paying $ 0.75 per thread .", "entities": []}, {"text": "For quality assurance , only workers located in the United States or Canada with a minimum HIT acceptance rate of 95 % could participate , and the annotations were spot - checked by the authors .", "entities": []}, {"text": "Trained annotators coded 1,300 Yahoo threads and the 100 - thread test set on the comment- and thread - levels ; untrained annotators coded threadlevel labels of 1,300 Yahoo threads ( 300 of which overlapped with the trained annotations ) and 1,000 IAC threads ( Table 1 ) .", "entities": []}, {"text": "In total , 26 trained and 495 untrained annotators worked on this task .", "entities": []}, {"text": "4.2 Con\ufb01dence To assess the dif\ufb01culty of the task , we also collected a rating for each thread from the trained annotators describing how con\ufb01dent they were with their judgments of each thread and the comments it comprises .", "entities": []}, {"text": "Ratings were made on a 5 - level Likert scale , with 1 being not at all con\ufb01dent and 5 fully con\ufb01dent .", "entities": []}, {"text": "The levels of con\ufb01dence were high ( 3.9\u00b10.7 ) , indicating that coders were able to distinguish the thread and comment codes with relative ease .", "entities": []}, {"text": "4.3 Agreement levels We measure inter - annotator agreement with Krippendorff \u2019s alpha ( Krippendorff , 2004 ) and \ufb01nd that , over all labels , there are substantial levels of agreement within groups of annotators : \u03b1= 0.79 for trained annotators and \u03b1= 0.71and72for untrained annotators on the Yahoo and IAC threads , respectively .", "entities": [[12, 13, "HyperparameterName", "alpha"]]}, {"text": "However , there is lower agreement on thread labels than comment labels ( Table 2 ) .", "entities": []}, {"text": "The agreement of thread type is 25 % higher for the Yahoo threads than the IAC ( 0.62\u20130.64 compared to 0.48 ) .", "entities": []}, {"text": "The less subjective comment labels ( i.e. , agreement , audience , and topic ) have higher agreement than persuasiveness , sentiment , and tone .", "entities": []}, {"text": "While some of the labels have only moderate agreement ( 0.5 < \u03b1 < 0.6 ) , we \ufb01nd these results satisfactory as the agreement levels are higher than those reported for similarly subjective discourse annotation tasks ( e.g. , Walker et al .", "entities": [[12, 13, "HyperparameterName", "\u03b1"], [33, 35, "DatasetName", "subjective discourse"]]}, {"text": "( 2012 ) )", "entities": []}, {"text": ".", "entities": []}, {"text": "To evaluate the untrained annotators , we compare the thread - level annotations made on 300 Yahoo threads by both trained and untrained coders,17", "entities": []}, {"text": "Yahoo IAC Thread label Trained Untrained Untrained Agreement 0.52 0.50 0.53 Constructive 0.48 0.52 0.63 Type 0.62 0.64 0.48 Comment label Agreement 0.80 \u2013 \u2013 Audience 0.74 \u2013 \u2013 Persuasiveness 0.48 \u2013 \u2013 Sentiment 0.50 \u2013 \u2013 Tone 0.63 \u2013 \u2013 Topic 0.82 \u2013 \u2013 Table 2 : Agreement levels found for each label category within trained and untrained groups of annotators , measured by Krippendorff \u2019s alpha .", "entities": [[67, 68, "HyperparameterName", "alpha"]]}, {"text": "Category Label Matches Constructive class \u2013 0.61 Agreement \u2013 0.62 Thread type", "entities": []}, {"text": "Overall 0.81 Argumentative 0.72 Flamewar 0.80 Off - topic 0.82 Personal stories 0.94 Respectful 0.81 Snarky / humorous 0.85 Table 3 : Percentage of threads ( out of 300 ) for which the majority label of the trained annotators matched that of the untrained annotators .", "entities": []}, {"text": "by taking the majority label per item from each group of annotators and calculating the percent of exact matches ( Table 3 ) .", "entities": []}, {"text": "When classifying thethread type , multiple labels are allowed for each thread , so we convert each option into a boolean and analyze them separately .", "entities": []}, {"text": "Only 8 % of the threads have no majority constructive label in the trained and/or untrained annotations , and 20 % have no majority agreement label .", "entities": []}, {"text": "Within both annotation groups , there are majority labels on all of thethread type labels .", "entities": []}, {"text": "The category with the lowest agreement is constructive class with only 61 % of the majority labels matching , followed closely byagreement ( only 62 % matching ) .", "entities": []}, {"text": "A very high percent of the thread type labels ( 81 % ) .", "entities": []}, {"text": "The strong agreement levels between trained and untrained annotators suggest that crowdsourcing is reliable for coding thread - level characteristics .", "entities": []}, {"text": "5 Annotation analysis To understand what makes a thread constructive , we explore the following research questions : 1 . How does the overall thread categorization differ between ERICs and non - ERICs ?", "entities": []}, {"text": "( \u00a7 5.1 ) 2 .", "entities": []}, {"text": "What types of comments make up ERICscompared to non - ERICs ?", "entities": []}, {"text": "( \u00a7 5.2 ) 3 . Are social signals related to whether a thread is an ERIC ?", "entities": []}, {"text": "( \u00a7 5.3 ) 5.1 Thread - level annotations Before examining what types of threads are ERICs , we \ufb01rst compare the threads coded by different sets of annotators ( trained or untrained ) and from different sources ( IAC or Yahoo ) .", "entities": []}, {"text": "We measure the signi\ufb01cance of annotation group for each label with a test of equal proportions for binary categories ( constructiveness and each thread type ) and a chi - squared test of independence for theagreement label .", "entities": []}, {"text": "Overall , annotations by the trained and untrained annotators on Yahoo threads are very similar , with signi\ufb01cant differences only between some of the thread type labels ( Figure 3 ) .", "entities": []}, {"text": "We posit that the discrepancies between the trained and untrained annotators is due to the former \u2019s training sessions and ability to communicate with the authors , which could have swayed annotators to make inferences into the coding scheme that were not overtly stated in the instructions .", "entities": []}, {"text": "The differences between Yahoo and IAC threads are more pronounced .", "entities": []}, {"text": "The only label for which there is no signi\ufb01cant difference is personal stories ( p= 0.41 , between the IAC and trained Yahoo labels ) .", "entities": []}, {"text": "All other IAC labels are signi\ufb01cantly different from both trained and untrained Yahoo labels ( p < 0.001 ) .", "entities": []}, {"text": "ERICs are more prevalent in the IAC , with 70 % of threads labeled constructive , compared to roughly half of Yahoo threads .", "entities": []}, {"text": "On the whole , threads from the IAC are more concordant and positive than from Yahoo : they have more agreement and less disagreement , more than twice as many positive / respectful threads , and fewer than half the \ufb02amewars .", "entities": []}, {"text": "For Yahoo threads , there is no signi\ufb01cant difference between trained and untrained coders for constructiveness ( p= 0.11 ) and the argumentativethread type ( p= 0.07 ; all other thread types are signi\ufb01cant with p < 10\u22125 ) .", "entities": []}, {"text": "There is no significant difference between the agreement labels , either ( p= 1.00 ) .", "entities": []}, {"text": "Untrained coders are more likely than trained to classify threads using emotional labels like snarky , \ufb02amewar , and positive / respectful , while trained annotators more frequently recognize off - topic threads .", "entities": []}, {"text": "These differences should be taken into consideration for evaluating the IAC codes , and for future efforts collecting subjective annotations through crowdsourcing.18", "entities": []}, {"text": "0.00 0.25 0.50 0.75 1.00snarky / humorouspositive / respectfulpersonal storiesoff - topic / digression\ufb02amewarargumentativenot constructiveconstructivedisagreement\u2192agreementagreement\u2192disagreementcontinual disagreementagreement throughout Agreement Constructiveness TypeIAC , untrained Yahoo , untrained Yahoo , trainedFigure 3 : % threads assigned labels by annotator type ( trained , untrained ) and source ( Yahoo , IAC ) .", "entities": []}, {"text": "We measure the strength of relationships between labels with the phi coef\ufb01cient ( Figure 4 ) .", "entities": []}, {"text": "There is a positive association between ERICs and allagreement labels in both Yahoo ( trained ) and IAC threads , which indicates that concord is not necessary for threads to be constructive .", "entities": []}, {"text": "The example in Figure 1 is a constructive thread that is argumentative and contains disagreement .", "entities": []}, {"text": "Thread types associated with non - ERICs are \ufb02amewars , off - topic digressions , and snarky / humorous exchanges , which is consistent across data sources .", "entities": []}, {"text": "The labels from untrained annotators show a stronger correlation between \ufb02amewars and not constructive compared to the trained annotators , but the former also identi\ufb01ed more \ufb02amewars .", "entities": []}, {"text": "Some correlations are expected : across all annotating groups , there is a positive correlation between threads labeled with agreement throughout andpositive / respectful , and", "entities": []}, {"text": "disagreement throughoutis correlated with argumentative ( Figures 1 and 2 ) and , to a lesser degree , \ufb02amewar .", "entities": []}, {"text": "The greatest difference between the IAC and Yahoo are the thread types associated with ERICs .", "entities": []}, {"text": "In the IAC , the positive / respectful label has a much stronger positive relationship with constructivethan the trained Yahoo labels , but this could be due to the difference between trained and untrained coders .", "entities": []}, {"text": "Argumentative has a positive correlation with constructive in the Yahoo threads , but a weak negative relationship is found in the IAC .", "entities": []}, {"text": "In both domains , threads characterized as offtopic , snarky , or\ufb02amewars are more likely to benon - ERICs .", "entities": []}, {"text": "Threads with some level of agreement characterized as positive / respectful are commonly ERICs .", "entities": []}, {"text": "A two - tailed z - test shows a signi\ufb01cant difference between the number of ERICs and non - ERICs in Yahoo articles in the Arts & Entertainment , Finance , and Lifestyle categories ( p < 0.005 ; Figure 5 ) .", "entities": []}, {"text": "5.2 Comment annotations We next consider the codes assigned by trained annotators to Yahoo comments ( Figure 6 ) .", "entities": []}, {"text": "The majority of comments are not persuasive , reply to a previous comment , express disagreement , or have negative sentiment .", "entities": []}, {"text": "More than three times as many comments express disagreement than agreement , and comments are labeled negative seven times as frequently as positive .", "entities": []}, {"text": "Approximately half of the comments express disagreement or a negative sentiment .", "entities": []}, {"text": "Very few comments are funny , positive , sympathetic , or contain a personal story ( < 10 % ) .", "entities": []}, {"text": "Encouragingly , only 6 % of comments are off - topic with the conversation , suggesting that participants are attuned to and respectful of the topic .", "entities": []}, {"text": "Only 20 % of comments are informative , indicating that participants infrequently introduce new information to complement the article or discussion .", "entities": []}, {"text": "The only strong correlations are between the binary labels , but the moderate correlations provide insight into the Yahoo threads ( Figure 7 ) .", "entities": []}, {"text": "Some relationships accord with intuition .", "entities": []}, {"text": "For instance , participants tend to go off - topic with the article when they are responding to others and not during broadcast messages ; comments expressing disagreement with a commenter are frequently posted in a reply to a commenter ; comments expressing agreement tend to be sympathetic and have positive sentiment ; and mean comments correlate with negative sentiment .", "entities": []}, {"text": "Commenters in this domain also express disagreement without particular nastiness , since there is no correlation between disagreement andmean orsarcastic comments .", "entities": []}, {"text": "The informative label is moderately correlated with persuasiveness , suggesting that comments containing facts and new information are more convincing than those without .", "entities": []}, {"text": "The correlation between comment and thread labels is shown in Figure 7 .", "entities": []}, {"text": "Many of the relationships are unsurprising , like off - topic threads tend to have off - topic comments , personal - story threads have personal - story comments ; thread agreement levels correlate with comment - level19", "entities": []}, {"text": "agreement throughout continual disagreement agreement\u2192disagreement disagreement\u2192agreement constructive not constructive argumentative \ufb02amewar off - topic / digression personal stories positive / respectful snarky / humoroussnarky / humorouspositive / respectfulpersonal storiesoff - topic / digression\ufb02amewarargumentativenot constructiveconstructivedisagreement\u2192agreementagreement\u2192disagreementcontinual disagreementagreement throughout Agreement Constructiveness Type Agreement ConstructivenessTypeYahoo , trained agreement throughout continual disagreement agreement\u2192disagreement disagreement\u2192agreement constructive not constructive argumentative \ufb02amewar off - topic / digression personal stories positive / respectful snarky / humorous Agreement ConstructivenessTypeYahoo , untrained agreement throughout continual disagreement agreement\u2192disagreement disagreement\u2192agreement constructive not constructive argumentative \ufb02amewar off - topic / digression personal stories positive / respectful snarky / humorous Agreement ConstructivenessTypefIAC , untrained \u2212101 Figure 4 : Correlation between thread labels , measured by the phi coef\ufb01cient ( \u03c6 ) .", "entities": []}, {"text": "0 100 200 300SportsSociety & CultureScience & TechnologyPoliticsLifestyleFinanceCurrent EventsCelebritiesArts & EntertainmentERICs Non - ERICs Figure 5 : Number of threads by article category .", "entities": [[0, 1, "DatasetName", "0"]]}, {"text": "0.00 0.25 0.50 0.75 1.00personal storyoff - topic with conversationoff - topic with articlesympatheticsarcasticmeaninformativefunnycontroversialpositiveneutralnegativemixedpersuasivenot persuasivereply to a speci\ufb01c commenterbroadcast messagedisagreement with commenteragreement with commenteradjunct opinion TopicToneSentimentPersuasionAudienceAgreement Figure 6 : % Yahoo comments assigned each label .", "entities": []}, {"text": "agreements ; and \ufb02amewars are correlated with mean comments .", "entities": []}, {"text": "In accord with our de\ufb01nition of ERICs , constructiveness is positively correlated with informativeandpersuasive comments and negatively correlated with negative andmean comments .", "entities": []}, {"text": "From these correlations one can infer that argumenta - tivethreads are generally respectful because , while they are strongly correlated with comments that arecontroversial or express disagreement or a mixed sentiment , there is no correlation with mean and very little with negative sentiment .", "entities": []}, {"text": "More surprising is the positive correlation between controversial comments and constructive threads .", "entities": []}, {"text": "Controversial comments are more associated with ERICs , not non - ERICs , even though the controversial label also positively correlates with \ufb02amewars , which are negatively correlated with constructiveness .", "entities": []}, {"text": "The examples in Figures 1\u20132 both have controversial comments expressing disagreement , but comments in the second half of the nonERIC veer off - topic and are not persuasive , where the ERIC stays on - topic and persuasive .", "entities": []}, {"text": "5.3", "entities": []}, {"text": "The relationship with social signals Previous work has taken social signals to be a proxy for thread quality , using some function of the total number of votes received by comments within a thread ( e.g. , Lee et al .", "entities": []}, {"text": "( 2014 ) ) .", "entities": []}, {"text": "Because earlier research has indicated that user votes are not completely independent or objective ( Sipos et al . , 2014 ; Danescu - Niculescu - Mizil et al . , 2009 ) , we take the use of votes as a proxy for quality skeptically ad perform our own exploration of the relationship between social signals and the presence of ERICs .", "entities": []}, {"text": "On Yahoo , users reacted to comments with a thumbs up orthumbs down and we collected the total number of such reactions for each comment in our corpus .", "entities": []}, {"text": "First , we compare the total number of thumbs up ( TU ) and thumbs down ( TD ) received by comments in a20", "entities": []}, {"text": "adjunct opinion agreement with commenter disagreement with commenter broadcast message reply to a speci\ufb01c commenter not persuasive persuasive mixed negative neutral positive controversial funny informative mean sarcastic sympathetic off - topic with article off - topic with conversation personal storypersonal storyoff - topic with conversationoff - topic with articlesympatheticsarcasticmeaninformativefunnycontroversialpositiveneutralnegativemixedpersuasivenot persuasivereply to a speci\ufb01c commenterbroadcast messagedisagreement with commenteragreement with commenteradjunct opinion AgreementAudiencePersuasion", "entities": []}, {"text": "SentimentTone TopicComment labelsTopicToneSentimentPersuasionAudienceAgreementComment labels agreement throughout continual disagreement agreement\u2192disagreement disagreement\u2192agreement constructive not constructive argumentative \ufb02amewar off - topic / digression personal stories positive / respectful snarky / humorouspersonal storyoff - topic with conversationoff - topic with articlesympatheticsarcasticmeaninformativefunnycontroversialpositiveneutralnegativemixedpersuasivenot persuasivereply to a speci\ufb01c commenterbroadcast messagedisagreement with commenteragreement with commenteradjunct opinion Agreement ConstructivenessTypeThread labelsTopicToneSentimentPersuasionAudienceAgreementComment labels f \u2212101", "entities": []}, {"text": "Figure 7 : Correlation between comment labels ( left ) and comment labels and thread labels ( right ) .", "entities": []}, {"text": "thread to the coded labels to determine whether there are any relationships between social signals and threads qualities .", "entities": []}, {"text": "We calculate the relationship between labels in each category with TU and TD with Pearson \u2019s coef\ufb01cient for the binary labels and a one - way ANOV A for the agreement category .", "entities": []}, {"text": "The strongest correlation is between TD and untrained annotators \u2019 perception of \ufb02amewars ( r= 0.21 ) , and there is a very weak to no correlation ( positive or negative ) between the other labels and TU , TD , or TU \u2212TD .", "entities": []}, {"text": "There is moderate correlation between TU and TD ( r= 0.46 ) , suggesting that threads that elicit reactions tend to receive both thumbs up and down .", "entities": []}, {"text": "The correlation between TU and TD received by each comment is weaker ( r= 0.23 ) .", "entities": []}, {"text": "Comparing the comment labels to the TU and TD received by each comment also show little correlation .", "entities": []}, {"text": "Comments that reply to a speci\ufb01c commenter are negatively correlated with TU , TD , and TU\u2212TD ( r=0.30 , -0.25 , and -0.22 , respectively ) .", "entities": []}, {"text": "The only other label with a non - negligible correlation is disagreement with a commenter , which negatively correlates with TU ( r=\u22120.21 ) .", "entities": []}, {"text": "There is no correlation between social signal and the presence of ERICs or non - ERICs .", "entities": []}, {"text": "These results support the \ufb01ndings of previous work and indicate that thumbs up or thumbs down alone ( and , presumably , up / down votes ) are inappropriate proxies for quality measurements of comments or threadsin this domain .", "entities": []}, {"text": "6 Conclusion We have developed a coding scheme for labeling \u201c good \u201d online conversations ( ERICs ) and created the Yahoo News Annotated Comments Corpus , a new corpus of 2.4kcoded comment threads posted in response to Yahoo News articles .", "entities": []}, {"text": "Additionally , we have annotated 1kdebate threads from the IAC .", "entities": []}, {"text": "These annotations re\ufb02ect several different characteristics of comments and threads , and we have explored their relationships with each other .", "entities": []}, {"text": "ERICs are characterized by argumentative , respectful exchanges containing persuasive , informative , and/or sympathetic comments .", "entities": []}, {"text": "They tend to stay on topic with the original article and not to contain funny , mean , or sarcastic comments .", "entities": []}, {"text": "We found differences between the distribution of annotations made by trained and untrained annotators , but high levels of agreement within each group , suggesting that crowdsourcing annotations for this task is reliable .", "entities": []}, {"text": "YNACC will be a valuable resource for researchers in multiple areas of discourse analysis .", "entities": []}, {"text": "Acknowledgments We are grateful to Danielle Lottridge , Smaranda Muresan , and Amanda Stent for their valuable input .", "entities": []}, {"text": "We also wish to thank the anonymous reviewers for their feedback.21", "entities": []}, {"text": "References Rob Abbott , Brian Ecker , Pranav Anand , and Marilyn Walker . 2016 .", "entities": []}, {"text": "Internet Argument Corpus 2.0 : An SQL schema for dialogic social media and the corpora to go with it .", "entities": []}, {"text": "In Proceedings of the Tenth International Conference on Language Resources and Evaluation ( LREC 2016 ) , pages 4445\u20134452 , Paris , France , May .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "Jacob Andreas , Sara Rosenthal , and Kathleen McKeown . 2012 .", "entities": []}, {"text": "Annotating agreement and disagreement in threaded discussion .", "entities": []}, {"text": "In Proceedings of the Eight International Conference on Language Resources and Evaluation ( LREC\u201912 ) , pages 818 \u2013 822 , Istanbul , Turkey , May .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "Emma Barker , Monica Lestari Paramita , Ahmet Aker , Emina Kurtic , Mark Hepple , and Robert Gaizauskas . 2016 .", "entities": []}, {"text": "The SENSEI annotated corpus : Human summaries of reader comment conversations in on - line news .", "entities": []}, {"text": "In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue , pages 42\u201352 , Los Angeles , September .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Or Biran , Sara Rosenthal , Jacob Andreas , Kathleen McKeown , and Owen Rambow .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Detecting in\ufb02uencers in written online conversations .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Language in Social Media , pages 37\u201345 , Montr \u00b4 eal , Canada , June .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Cristian Danescu - Niculescu - Mizil , Gueorgi Kossinets , Jon Kleinberg , and Lillian Lee . 2009 .", "entities": []}, {"text": "How opinions are received by online communities : A case study on amazon.com helpfulness votes .", "entities": []}, {"text": "In Proceedings of the 18th International Conference on World Wide Web , WWW \u2019 09 , pages 141\u2013150 , New York . ACM .", "entities": [[22, 23, "DatasetName", "ACM"]]}, {"text": "Cristian Danescu - Niculescu - Mizil , Moritz Sudhof , Dan Jurafsky , Jure Leskovec , and Christopher Potts .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "A computational approach to politeness with application to social factors .", "entities": []}, {"text": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 250\u2013259 , So\ufb01a , Bulgaria , August .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Dmitry Davidov , Oren Tsur , and Ari Rappoport .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Semi - supervised recognition of sarcasm in Twitter and Amazon .", "entities": []}, {"text": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning , pages 107\u2013116 , Uppsala , Sweden , July .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nicholas Diakopoulos and Mor Naaman .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Towards quality discourse in online news comments .", "entities": []}, {"text": "InProceedings of the ACM 2011 Conference on Computer Supported Cooperative Work , CSCW \u2019 11 , pages 133\u2013142 , New York .", "entities": [[3, 4, "DatasetName", "ACM"]]}, {"text": "ACM .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Nicholas Diakopoulos .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Picking the NYT picks : Editorial criteria and automation in the curation ofonline news comments .", "entities": []}, {"text": "ISOJ Journal , 5(1):147 \u2013 166 .", "entities": []}, {"text": "Ethan Fast and Eric Horvitz .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Identifying dogmatism in social media : Signals and models .", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 690\u2013699 , Austin , Texas , November .", "entities": [[19, 20, "DatasetName", "Texas"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Debanjan Ghosh , Smaranda Muresan , Nina Wacholder , Mark Aakhus , and Matthew Mitsui .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Analyzing argumentative discourse units in online interactions .", "entities": []}, {"text": "In Proceedings of the First Workshop on Argumentation Mining , pages 39\u201348 , Baltimore , Maryland , June .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Roberto Gonz \u00b4 alez - Ib \u00b4 anez , Smaranda Muresan , and Nina Wacholder .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Identifying sarcasm in Twitter : A closer look .", "entities": []}, {"text": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies : Short Papers - Volume 2 , pages 581\u2013586 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ivan Habernal and Iryna Gurevych . 2016 .", "entities": []}, {"text": "Which argument is more convincing ?", "entities": []}, {"text": "Analyzing and predicting convincingness of web arguments using bidirectional LSTM .", "entities": [[8, 10, "MethodName", "bidirectional LSTM"]]}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1589 \u2013 1599 , Berlin , Germany , August .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ahmed Hassan , Vahed Qazvinian , and Dragomir Radev .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "What \u2019s with the attitude ?", "entities": []}, {"text": "Identifying sentences with attitude in online discussions .", "entities": []}, {"text": "InProceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 1245\u20131255 , Cambridge , MA , October .", "entities": [[16, 17, "DatasetName", "Cambridge"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Hyeju Jang , Mario Piergallini , Miaomiao Wen , and Carolyn Rose . 2014 .", "entities": []}, {"text": "Conversational metaphors in use : Exploring the contrast between technical and everyday notions of metaphor .", "entities": []}, {"text": "In Proceedings of the Second Workshop on Metaphor in NLP , pages 1\u201310 , Baltimore , MD , June .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Klaus Krippendorff .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Content analysis : An introduction to its methodology .", "entities": []}, {"text": "Sage Publications , Thousand Oaks , CA , 2nd edition .", "entities": []}, {"text": "Jung - Tae Lee , Min - Chul Yang , and Hae - Chang Rim . 2014 .", "entities": []}, {"text": "Discovering high - quality threaded discussions in online forums .", "entities": []}, {"text": "Journal of Computer Science and Technology , 29(3):519\u2013531 .", "entities": []}, {"text": "Macmillan Publishers Ltd. 2009 .", "entities": []}, {"text": "The online English dictionary : De\ufb01nition of constructive .", "entities": []}, {"text": "http://www.macmillandictionary.com/ dictionary / american / constructive .", "entities": []}, {"text": "Accessed January 20 , 2017.22", "entities": []}, {"text": "Marco Lui and Timothy Baldwin .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "langid.py : An off - the - shelf language identi\ufb01cation tool .", "entities": []}, {"text": "In Proceedings of the ACL 2012 System Demonstrations , pages 25\u201330 , Jeju Island , Korea , July .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Arjun Mukherjee , Vivek Venkataraman , Bing Liu , and Sharon Meraz .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Public dialogue : Analysis of tolerance in online discussions .", "entities": []}, {"text": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1680\u20131690 , So\ufb01a , Bulgaria , August .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Vlad Niculae and Cristian Danescu - Niculescu - Mizil .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Conversational markers of constructive discussions .", "entities": []}, {"text": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 568\u2013578 , San Diego , California , June .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chikashi Nobata , Joel Tetreault , Achint Thomas , Yashar Mehdad , and Yi Chang .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Abusive language detection in online user content .", "entities": [[0, 2, "TaskName", "Abusive language"]]}, {"text": "In Proceedings of the 25th International Conference on World Wide Web , pages 145\u2013153 .", "entities": []}, {"text": "International World Wide Web Conferences Steering Committee .", "entities": []}, {"text": "Shereen Oraby , Vrindavan Harrison , Lena Reed , Ernesto Hernandez , Ellen Riloff , and Marilyn Walker . 2016 .", "entities": []}, {"text": "Creating and characterizing a diverse corpus of sarcasm in dialogue .", "entities": []}, {"text": "In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue , pages 31\u201341 , Los Angeles , September .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Bo Pang and Lillian Lee . 2005 .", "entities": []}, {"text": "Seeing stars : Exploiting class relationships for sentiment categorization with respect to rating scales .", "entities": []}, {"text": "In Proceedings of the 43rd annual meeting on association for computational linguistics , pages 115\u2013124 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Ruben Sipos , Arpita Ghosh , and Thorsten Joachims .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Was this review helpful to you ? : It depends !", "entities": []}, {"text": "Context and voting patterns in online content .", "entities": []}, {"text": "In Proceedings of the 23rd International Conference on World Wide Web , pages 337\u2013348 . ACM .", "entities": [[15, 16, "DatasetName", "ACM"]]}, {"text": "Maria Skeppstedt , Magnus Kerren , Carita Sahlgren , and Andreas Paradis .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Unshared task : ( Dis ) agreement in online debates .", "entities": []}, {"text": "In 3rd Workshop on Argument Mining ( ArgMining\u201916 ) , Berlin , Germany , August 7 - 12 , 2016 , pages 154\u2013159 .", "entities": [[4, 6, "TaskName", "Argument Mining"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chenhao Tan , Vlad Niculae , Cristian DanescuNiculescu - Mizil , and Lillian Lee . 2016 .", "entities": []}, {"text": "Winning arguments : Interaction dynamics and persuasion strategies in good - faith online discussions .", "entities": [[6, 8, "DatasetName", "persuasion strategies"]]}, {"text": "In Proceedings of the 25th International Conference on World Wide Web , pages 613\u2013624 .", "entities": []}, {"text": "International World Wide Web Conferences Steering Committee .", "entities": []}, {"text": "Marilyn Walker , Jean Fox Tree , Pranav Anand , Rob Abbott , and Joseph King .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "A corpus for research on deliberation and debate .", "entities": []}, {"text": "In Proceedings of the Eight International Conference on Language Resources and Evaluation ( LREC\u201912 ) , Istanbul , Turkey , May .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "Charlie Warzel .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Everything in moderation .", "entities": []}, {"text": "Adweek , June 18 .", "entities": []}, {"text": "http://www.adweek.com/ digital / everything - moderation141163/ .", "entities": []}, {"text": "Accessed February 20 , 2017 .", "entities": []}, {"text": "Zhongyu Wei , Yang Liu , and Yi Li . 2016 .", "entities": []}, {"text": "Is this post persuasive ?", "entities": []}, {"text": "Ranking argumentative comments in online forum .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Papers ) , pages 195\u2013200 , Berlin , Germany , August .", "entities": []}, {"text": "Association for Computational Linguistics.23", "entities": []}]