[{"text": "Proceedings of the EACL 2017 Software Demonstrations , Valencia , Spain , April 3 - 7 2017 , pages 108\u2013111 c", "entities": []}, {"text": "2017 Association for Computational Linguistics ICE : Idiom and Collocation Extractor for Research and Education Vasanthi Vuppuluri Verizon Labs 375 W Trimble Rd , San Jose , CA 95131 , USA vuppulurivasanthi@gmail.comShahryar Baki , An Nguyen , Rakesh Verma Computer Science Dept . University of Houston Houston , TX 77204 , USA shahryar@cs.uh.com anqnguyen@outlook.com rverma@uh.edu Abstract Collocation and idiom extraction are wellknown challenges with many potential applications in Natural Language Processing ( NLP ) .", "entities": [[45, 46, "DatasetName", "Houston"], [46, 47, "DatasetName", "Houston"]]}, {"text": "Our experimental , open - source software system , called ICE , is a python package for \ufb02exibly extracting collocations and idioms , currently in English .", "entities": []}, {"text": "It also has a competitive POS tagger that can be used alone or as part of collocation / idiom extraction .", "entities": []}, {"text": "ICE is available free of cost for research and educational uses in two user - friendly formats .", "entities": []}, {"text": "This paper gives an overview of ICE and its performance , and brie\ufb02y describes the research underlying the extraction algorithms .", "entities": []}, {"text": "1 Introduction Idioms and collocations are special types of phrases in many languages .", "entities": []}, {"text": "An idiom is a phrase whose meaning can not be obtained compositionally , i.e. , by combining the meanings of the words that compose it .", "entities": []}, {"text": "Collocations are phrases in which there is a semantic association between the component words and some restrictions on which words can be replaced and which can not .", "entities": []}, {"text": "In short , collocations are arbitrarily restricted lexeme combinations such as look into andfully aware .", "entities": []}, {"text": "Many scientists from diverse \ufb01elds have worked on the challenging tasks of automated collocation and idiom extraction , e.g. , see ( Garg and Goyal , 2014 ; Seretan , 2013 ; Verma and Vuppuluri , 2015 ; Verma et al . , 2016 ) and the references contained therein , yet there is no multi - purpose , ready - to - use , and \ufb02exible system for extracting these phrases .", "entities": []}, {"text": "Collocation and its special forms , such as idioms , can be useful in many important tasks , e.g. , summarization ( Barrera and Verma , 2012 ) , question - answering ( Barrera et al . , 2011),language translation , topic segmentation , authorial style , and so on .", "entities": [[20, 21, "TaskName", "summarization"]]}, {"text": "As a result , a tool for these tasks would be very handy .", "entities": []}, {"text": "To tackle this void , we introduce a feature - rich system called ICE ( short for Idiom and Collocation Extractor ) , which has two versions : one is \ufb02exible and pipelined seamlessly for research purposes as a component of a larger system such as a question answering system , and the second as a web - based tool for educational purposes .", "entities": [[47, 49, "TaskName", "question answering"]]}, {"text": "ICE has a modular architecture and also includes a POS tagger , which can be used alone or as part of collocation or idiom extraction .", "entities": []}, {"text": "An experiment with the CoNLL dataset shows that ICE \u2019s POS tagger is competitive against the Stanford POS tagger .", "entities": []}, {"text": "For ease of use in research , we provide ICE as a python package .", "entities": []}, {"text": "For collocation extraction , ICE uses the IR models and techniques introduced by ( Verma et al . , 2016 ) .", "entities": []}, {"text": "These methods include : dictionary search , online dictionaries , a substitution method that compares the Bing hit counts of a phrase against the Bing hit counts of new phrases obtained by substituting the component words of the phrase one at a time to determine the \u201c adherence factor \u201d of the component words in a collocation , and two methods that try to measure the probability of association of the component words again using hit counts .", "entities": []}, {"text": "In ( Verma et al . , 2016 ) , the authors created a gold - standard dataset of collocations by taking 100 sentences at random from the Wiki50 dataset and manually annotating them for collocations ( including idioms ) using eight volunteers , who used the Oxford Dictionary of Collocations and Oxford Dictionary of Idioms .", "entities": []}, {"text": "Each sentence was given to two annotators , who were given 25 sentences each for annotation , and their work was checked and corrected afterwards by two other people .", "entities": []}, {"text": "In creating this dataset , even with the assistance of dictionaries , human performance108", "entities": []}, {"text": "varied from an F1 - score of about 39 % to 70 % for the collocation task .", "entities": [[3, 6, "MetricName", "F1 - score"]]}, {"text": "A comparison showed that their combination schemes outperformed existing techniques , such as MWEToolkit ( Ramisch et al . , 2010 ) and Text - NSP ( Banerjee and Pedersen , 2003 ) , with the best method achieving an F1score of around 40 % on the gold - standard dataset , which is within the range of human performance .", "entities": []}, {"text": "For idiom extraction , ICE uses the semanticsbased methods introduced by ( Verma and Vuppuluri , 2015 ) .", "entities": []}, {"text": "The salient feature of these methods is that they use Bing search for the de\ufb01nition of a given phrase and then check the compositionality of the phrase de\ufb01nition against combinations of the words obtained when a de\ufb01ne word query is issued , where the word belongs to the phrase .", "entities": []}, {"text": "If there is a difference in the meaning , that phrase is considered an idiom .", "entities": []}, {"text": "In ( Verma and Vuppuluri , 2015 ) , authors showed that their method outperforms AMALGr ( Schneider et al . , 2014 ) .", "entities": []}, {"text": "Their best method achieved an F1 - score of about 95 % on the VNC tokens dataset .", "entities": [[5, 8, "MetricName", "F1 - score"]]}, {"text": "Thus , ICE includes extraction methods for idioms and collocations that are state - of - the - art .", "entities": []}, {"text": "Other tools exist for collocation extraction , e.g. , see ( Anagnostou and Weir , 2006 ) , in which four methods including Text - NSP are compared .", "entities": []}, {"text": "2 ICE - Architecture and Algorithms As ICE \u2019s algorithms are based on Bing search , users must provide a valid user i d for the Bing API .", "entities": []}, {"text": "ICE receives a list of sentences as an input and outputs a list of all collocations and idioms .", "entities": []}, {"text": "It \ufb01rst splits the input sentences using NLTK sentence tokenizer , then generates n - grams and part of speech tags .", "entities": []}, {"text": "ICE \u2019s n - gram generator takes care of punctuation marks and has been shown to be better than NSP \u2019s n - gram generator .", "entities": []}, {"text": "Finally , the output n - grams are given to the collocation and idiom detection algorithms .", "entities": []}, {"text": "Collocation and idiom extraction has been done by the algorithm given by ( Verma et al . , 2016)1and ( Verma and Vuppuluri , 2015 ) .", "entities": []}, {"text": "For part of speech tagging we combined NLTK \u2019s regex tagger with NLTK \u2019s N - Gram Tagger to have a better performance on POS tagging .", "entities": []}, {"text": "We compared our tagger with Stanford POS tagger ( Manning et al . , 2014 ) on the CoNLL dataset.2 The accuracy of our tagger is 92.11 % , which is 1http://www2.cs.uh.edu/ \u02dcrmverma / paper _ 216.pdf 2Available at http://www.cnts.ua.ac.be/ conll2003 / ner/ Figure 1 : Collocation extractor diagram Figure 2 : Idiom extractor diagram slightly higher than 91.19 % , the accuracy of the Stanford tagger on the same corpus .", "entities": [[21, 22, "MetricName", "accuracy"], [40, 41, "DatasetName", "conll2003"], [62, 63, "MetricName", "accuracy"]]}, {"text": "Collocation / Idiom Extractor .", "entities": []}, {"text": "The collocation extraction technique combines different methods in a pipeline in order to increase precision .", "entities": []}, {"text": "Figures 1 and 2 show the idiom and collocation extraction system architectures separately .", "entities": []}, {"text": "As shown in the diagrams , there are two methods for identifying idioms ( called And and Or ) and four different methods for identifying collocations including : of\ufb02ine dictionary search , online dictionary search , web search and substitution , and web search and independence .", "entities": []}, {"text": "For collocations , ICE pipelines the \ufb01rst and second methods , then pipelines them with the third or the fourth method ( both options are available109", "entities": []}, {"text": "in the code )", "entities": []}, {"text": ".", "entities": []}, {"text": "These methods are connected sequentially .", "entities": []}, {"text": "This means that if something is considered as a collocation in one component , it will be added to the list of collocations and will not be given to the next component ( yes / no arrows in the diagram ) .", "entities": []}, {"text": "Table 1 shows the description of each component in collocation extractor diagram .", "entities": []}, {"text": "TheNgram Extractor receives all sentences and generates n - grams ranging from bigrams up to 8grams .", "entities": []}, {"text": "It uses NLTK sentence and word tokenizers for generating tokens .", "entities": []}, {"text": "Then , it combines the generated tokens together taking care of punctuation to generate the n - grams .", "entities": []}, {"text": "Dictionary Check uses WordNet ( Miller , 1995 ) as a dictionary and looks up each n - gram to see if it exists in WordNet or not ( a collocation should exist in the dictionary ) .", "entities": []}, {"text": "All n - grams that are considered as non - collocations are given to the next component as input .", "entities": []}, {"text": "The next component is Online Dictionary .", "entities": []}, {"text": "It searches online dictionaries to see if the n - gram exists in any of them or not .", "entities": []}, {"text": "It uses Bing Search API3to search for n - grams in the web .", "entities": []}, {"text": "Web Search and Substitution is the next component in the pipeline .", "entities": []}, {"text": "This method uses Bing Search API to obtain hit counts for a phrase query .", "entities": []}, {"text": "Then each word in the n - gram will be replaced by 5 random words ( one at the time ) , and the hit counts are obtained .", "entities": []}, {"text": "At the end , we will have a list of hit counts .", "entities": []}, {"text": "These values will be used to differentiate between collocations and non - collocations .", "entities": []}, {"text": "The last component in the pipeline of collocation extraction is Web Search and Independence .", "entities": []}, {"text": "The idea of this method is to check whether the probability of a phrase exceeds the probability that we would expect if the words are independent .", "entities": []}, {"text": "It uses hit counts in order to estimate the probabilities .", "entities": []}, {"text": "These probabilities are used to differentiate between collocations and non - collocations .", "entities": []}, {"text": "When running the collocation extraction function , one of the components should be selected out of the third and fourth ones .", "entities": []}, {"text": "TheIdiom Extractor diagram is relatively simpler .", "entities": []}, {"text": "Given the input n - gram , it creates n + 1 sets .", "entities": []}, {"text": "The \ufb01rst contains ( stemmed ) words in the meaning of the phrase .", "entities": []}, {"text": "The next n sets contain stemmed word in the meaning of each word in the n - gram .", "entities": []}, {"text": "Then it applies the set difference operator to n pairs containing the \ufb01rst set and each of 3http://datamarket.azure.com/dataset/ bing / searchthe n sets .", "entities": []}, {"text": "The Or subsystem considers a phrase as an idiom if at least one word survives one of the subtractions ( union of difference sets should be non - empty ) .", "entities": []}, {"text": "For the And , at least one word has to exist that survived every subtraction ( intersection of difference sets should be non - empty )", "entities": []}, {"text": "Performance .", "entities": []}, {"text": "ICE outperforms both TextNSP and MWEToolkit .", "entities": []}, {"text": "On the gold - standard dataset , ICE \u2019s F1 - score was 40.40 % , MWEToolkit \u2019s F1 - score was 18.31 % , and Text - NSP had 18 % .", "entities": [[9, 12, "MetricName", "F1 - score"], [18, 21, "MetricName", "F1 - score"]]}, {"text": "We also compared our idiom extraction with AMALGr method ( Schneider et al . , 2014 ) on their dataset and the highest F1 - score achieved by ICE was 95 % compared to 67.42 % for AMALGr .", "entities": [[23, 26, "MetricName", "F1 - score"]]}, {"text": "For detailed comparison of ICE \u2019s collocation and idiom extraction algorithm with existing tools , please refer to ( Verma et al . , 2016 ) and ( Verma and Vuppuluri , 2015 ) .", "entities": []}, {"text": "Sample Code .", "entities": []}, {"text": "Below is the sample code for using ICE \u2019s collocation extraction as part of a bigger system .", "entities": []}, {"text": "For idiom extraction you can use IdiomExtractor class instead of collocationExtractor .", "entities": []}, {"text": "> > input=[\"he and Chazz duel with all keys on the line . \" ]", "entities": []}, {"text": "> > from ICE import CollocationExtractor > > extractor = CollocationExtractor .", "entities": []}, {"text": "with_collocation_pipeline ( \" T1 \" , bing_key = \" Temp \" , pos_check = False ) > > print(extractor .", "entities": []}, {"text": "get_collocations_of_length ( input , length = 3 ) ) > >", "entities": []}, {"text": "[ \" on the line \" ] Educational Uses . ICE also has a web - based interface for demonstration and educational purposes .", "entities": []}, {"text": "A user can type in a sentence into an input \ufb01eld and get a list of the idioms or collocations in the sentence .", "entities": []}, {"text": "A screen - shot of the web - based interface is shown in Figure 3.4 3 Conclusion ICE is a tool for extracting idioms and collocations , but it also has functions for part of speech 4The web interface is accessible through https:// shahryarbaki.ddns.net/collocation/110", "entities": []}, {"text": "Table 1 : Components of Collocation Extraction Subsystem of ICE Component Description Ngram Extractor Generates bigram up to 8gram Dictionary Check Look up ngram in dictionary ( Wordnet )", "entities": []}, {"text": "Online Dictionary Look up ngram in online dictionaries ( Bing ) Web Search and SubstitutionHitcount for phrase query and 5 generated queries by randomly changing the words in the ngram Web Search and IndependenceProbability of a phrase exceeds the probability that we would expect if the words are independent Figure 3 : Screen - shot of the online version of ICE tagging and n - gram extraction .", "entities": []}, {"text": "All the components of the ICE are connected as a pipeline , hence every part of the system can be changed without affecting the other parts .", "entities": []}, {"text": "The tool is available online at https://github.com/ shahryarabaki / ICE as a python package and also at a website .", "entities": []}, {"text": "The software is Licensed under the Apache License , Version 2.0 .", "entities": []}, {"text": "References Nikolaos K. Anagnostou and George R. S. Weir .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Review of software applications for deriving collocations .", "entities": []}, {"text": "In ICT in the Analysis , Teaching and Learning of Languages , Preprints of the ICTATLL Workshop 2006 , pages 91\u2013100 .", "entities": []}, {"text": "Satanjeev Banerjee and Ted Pedersen .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "The design , implementation , and use of the ngram statistics package .", "entities": []}, {"text": "In International Conference on Intelligent Text Processing and Computational Linguistics , pages 370\u2013381 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Araly Barrera and Rakesh Verma .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Combining syntax and semantics for automatic extractive single - document summarization .", "entities": [[9, 11, "TaskName", "document summarization"]]}, {"text": "In CICLING , volume LNCS 7182 , pages 366\u2013377 .", "entities": []}, {"text": "Araly Barrera , Rakesh Verma , and Ryan Vincent .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Semquest : University of houston \u2019s semanticsbased question answering system .", "entities": [[7, 9, "TaskName", "question answering"]]}, {"text": "In Proceedingsof the Fourth Text Analysis Conference , TAC 2011 , Gaithersburg , Maryland , USA , November 14 - 15 , 2011 .", "entities": []}, {"text": "Chitra Garg and Lalit Goyal .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Automatic extraction of idiom , proverb and its variations from text using statistical approach .", "entities": []}, {"text": "An International Journal of Engineering Sciences .", "entities": []}, {"text": "Christopher D. Manning , Mihai Surdeanu , John Bauer , Jenny Rose Finkel , Steven Bethard , and David McClosky .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "The stanford corenlp natural language processing toolkit .", "entities": []}, {"text": "In ACL ( System Demonstrations ) , pages 55\u201360 .", "entities": []}, {"text": "George A. Miller .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "Wordnet : a lexical database for english .", "entities": []}, {"text": "Communications of the ACM , 38(11):39\u201341 .", "entities": [[3, 4, "DatasetName", "ACM"]]}, {"text": "Carlos Ramisch , Aline Villavicencio , and Christian Boitet . 2010 .", "entities": []}, {"text": "Multiword expressions in the wild ? : the mwetoolkit comes in handy .", "entities": []}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics : Demonstrations , pages 57\u201360 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nathan Schneider , Emily Danchik , Chris Dyer , and Noah A. Smith .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Discriminative lexical semantic segmentation with gaps : running the mwe gamut .", "entities": [[2, 4, "TaskName", "semantic segmentation"]]}, {"text": "Transactions of the Association for Computational Linguistics , 2:193\u2013206 .", "entities": []}, {"text": "Violeta Seretan .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "A multilingual integrated framework for processing lexical collocations .", "entities": []}, {"text": "In Computational Linguistics - Applications , pages 87 \u2013 108 .", "entities": []}, {"text": "Springer - Netherlands .", "entities": []}, {"text": "Rakesh Verma and Vasanthi Vuppuluri . 2015 .", "entities": []}, {"text": "A new approach for idiom identi\ufb01cation using meanings and the web .", "entities": []}, {"text": "Recent Advances in Natural Language Processing , pages 681\u2013687 .", "entities": []}, {"text": "Rakesh Verma , Vasanthi Vuppuluri , An Nguyen , Arjun Mukherjee , Ghita Mammar , Shahryar Baki , and Reed Armstrong .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Mining the web for collocations : Ir models of term associations .", "entities": []}, {"text": "In International Conference on Intelligent Text Processing and Computational Linguistics .111", "entities": []}]