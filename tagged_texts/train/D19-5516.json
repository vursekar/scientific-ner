[{"text": "Proceedings of the 2019 EMNLP Workshop W - NUT : The 5th Workshop on Noisy User - generated Text , pages 121\u2013125 Hong Kong , Nov 4 , 2019 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics121Who wrote this book ?", "entities": []}, {"text": "A challenge for e - commerce B\u00b4eranger Dumont , Simona Maggio , Ghiles Sidi Said & Quoc - Tien Au Rakuten Institute of Technology Paris fberanger.dumont , simona.maggio g@rakuten.com , fts - ghiles.sidisaid , quoctien.au g@rakuten.com", "entities": []}, {"text": "Abstract Modern e - commerce catalogs contain millions of references , associated with textual and visual information that is of paramount importance for the products to be found via search or browsing .", "entities": []}, {"text": "Of particular signi\ufb01cance is the book category , where the author name(s ) \ufb01eld poses a signi\ufb01cant challenge .", "entities": []}, {"text": "Indeed , books written by a given author might be listed with different authors \u2019 names due to abbreviations , spelling variants and mistakes , among others .", "entities": []}, {"text": "To solve this problem at scale , we design a composite system involving open data sources for books , as well as deep learning components , such as approximate match with Siamese networks and name correction with sequence - tosequence networks .", "entities": []}, {"text": "We evaluate this approach on product data from the e - commerce website Rakuten France , and \ufb01nd that the top proposal of the system is the normalized author name with 72 % accuracy .", "entities": [[33, 34, "MetricName", "accuracy"]]}, {"text": "1 Introduction Unlike brick - and - mortar stores , e - commerce websites can list hundreds of millions of products , with thousands of new products entering their catalogs every day .", "entities": []}, {"text": "The availability and the reliability of the information on the products , or product data , is crucial for the products to be found by the users via textual or visual search , or using faceted navigation .", "entities": []}, {"text": "Books constitute a prominent part of many large ecommerce catalogs .", "entities": []}, {"text": "Relevant book properties include : title , author(s ) , format , edition , and publication date , among others .", "entities": []}, {"text": "In this work , we focus on the names of book authors , as they are found to be extremely relevant to the user and are commonly used in search queries on e - commerce websites , but suffer from considerable variability and noise .", "entities": []}, {"text": "To the best of our knowledge , there is no large - scale public dataset for books that captures the variability arising on e - commerce marketplaces from user - generated input .", "entities": []}, {"text": "Thus , in this work we use product data from Rakuten France ( RFR).1 1https://fr.shopping.rakuten.comThe variability and noise is evident in the RFR dataset .", "entities": []}, {"text": "For example , books written by F. Scott Fitzgerald are also listed with the following author \u2019s names : \u201c Francis Scott Fitzgerald \u201d ( full name ) , \u201c Fitzgerald , F. Scott \u201d ( inversion of the \ufb01rst and last name ) , \u201c Fitzgerald \u201d ( last name only ) , \u201c F. Scott Fitgerald \u201d ( misspelling of the last name ) , \u201c F SCOTT FITZGERALD \u201d ( capitalization and different typological conventions ) , as well as several combinations of those variations .", "entities": []}, {"text": "The variability of the possible spellings for an author \u2019s name is very hard to capture using rules , even more so for names which are not primarily written in latin alphabet ( such as arabic or asian names ) , for names containing titles ( such as \u201c Dr. \u201d or \u201c Pr . \u201d ) , and for pen names which may not follow the usual conventions .", "entities": []}, {"text": "This motivated us to explore automated techniques for normalizing the authors \u2019 names to their best known ( \u201c canonical \u201d ) spellings .", "entities": []}, {"text": "Fortunately , a wealth of open databases exist for books , making it possible to match a signi\ufb01cant fraction of the books listed in e - commerce catalogs .", "entities": []}, {"text": "While not always clean and unambiguous , this information is extremely valuable and enables us to build datasets of name variants , used to train machine learning systems to normalize authors \u2019 names .", "entities": []}, {"text": "To this end , in addition to the match with open databases , we will explore two different approaches : approximate match with known authors \u2019 names using Siamese neural networks , and direct correction of the provided author \u2019s name using sequenceto - sequence learning with neural networks .", "entities": []}, {"text": "Then , an additional machine learning component is used to rank the results .", "entities": []}, {"text": "The rest of the paper is organized as follows : we present the data from RFR and from the open databases in Section 2 , before turning to the experimental setup for the overall system and for each of its components in Section 3 .", "entities": []}, {"text": "Finally , we give results in Section 4 , we present related works in Section 5 , and conclude in Section 6 .", "entities": []}, {"text": "2 Book data 2.1 Rakuten France data The RFR dataset contains 12 million book references2 .", "entities": []}, {"text": "The most relevant product data for normalization is : 2The RFR dataset is publicly available at https://rit .", "entities": []}, {"text": "rakuten.co.jp/data_release .", "entities": []}, {"text": "122 F. S. Fitzgerald   Match with open bibliographic sourcesSiamese   approx .", "entities": []}, {"text": "name matchingSeq2seq name correctiona   l   d F   r   aFitzgerald , F. Scott F. Scott Fitzgerald Frank S. FitzgeraldF. Scott Fitzgerald RankingISBNNAMEFigure 1 : Overview of the system for normalizing author names .", "entities": []}, {"text": "Each component is detailed in Section 3 .", "entities": []}, {"text": "Table 1 : Performances of the external bibliographic resources used for matching books on RFR via ISBN .", "entities": []}, {"text": "Source URL % of ISBNs Open Library openlibrary.org 24.9 % ISBNdb isbndb.com 36.3 % Goodreads www.goodreads.com", "entities": []}, {"text": "64.7 % Google Books books.google.com 51.2 % OCLC www.oclc.org 52.2 % BnF www.bnf.fr 7.4 % Sudoc www.sudoc.abes.fr 29.0 % Babelio www.babelio.com", "entities": [[2, 3, "DatasetName", "Google"]]}, {"text": "7.9 % \u000fISBN3 in 10 digit or 13 digit format ; \u000fproduct title , which includes the book title , often supplemented with extra information in free text ; \u000fauthor(s ) of the book as the input catalog name provided by the seller .", "entities": []}, {"text": "In particular , the ISBN is a worldwide unique identi\ufb01er for books , which makes it a prime candidate for unambiguous matching with external sources .", "entities": []}, {"text": "In this dataset , an ISBN is present for about 70 % of the books .", "entities": []}, {"text": "Among the books with no ISBN , 30 % are ancient books which are not expected to be associated an ISBN .", "entities": []}, {"text": "2.2 External bibliographic resources There is no central authority providing consistent information on books associated with an ISBN .", "entities": []}, {"text": "However , there is a wealth of bibliographic resources and open databases for books .", "entities": []}, {"text": "In order to retrieve the author \u2019s name(s ) associated with the books in the RFR dataset , we perform ISBN matching using public APIs on eight of them , listed in Table 1 along with the fraction of found ISBNs from this dataset .", "entities": []}, {"text": "We \ufb01nd the sources to be highly complementary and that 75 % of the books with an ISBN are matched with at least one source .", "entities": []}, {"text": "The match via ISBN on external bibliographic resources is the \ufb01rst component of the system depicted in Fig .", "entities": []}, {"text": "1 . 2.3 Dataset of name entities", "entities": []}, {"text": "In order to train and evaluate machine learning systems to match or correct authors \u2019 names , a dataset of name en3International Standard Book Number , see https:// www.isbn-international.orgtities containing the different surface forms ( or variants ) of authors \u2019 names is required .", "entities": []}, {"text": "The entities should re\ufb02ect as well as possible the variability that can be found in the RFR dataset , as was illustrated in the case of F. Scott Fitzgerald in Section 1 .", "entities": []}, {"text": "For each entity , a canonical name should be elected and correspond to the name that should be preferred for the purpose of e - commerce .", "entities": []}, {"text": "Instead of setting these gold spellings by following some prede\ufb01ned rules ( i.e. family name in the \ufb01rst position , initial of \ufb01rst name , etc . ) , for e - commerce applications it is more appropriate that the displayed authors names have the most popular spellings among readers .", "entities": []}, {"text": "In agreement with Rakuten catalog analysts we set the most popular spelling of an author name as the one found on Wikipedia4or DBpedia ( Lehmann et al . , 2015 ) .", "entities": [[22, 23, "DatasetName", "DBpedia"]]}, {"text": "While Wikipedia seems more pertinent to select canonical names matching the e - commerce user expectations , specialized librarian data services , such as the Library of Congress Name Authority5 , could be used in future research to enrich the dataset of name entities .", "entities": []}, {"text": "Name entities are collected in three distinct ways : 1.ISBN matching : for each book the different author names found via ISBN search on external sources and the RFR author name \ufb01eld build up an entity .", "entities": []}, {"text": "The canonical form is the one that is matched with Wikipedia or DBpedia ; else the one provided by the greatest number of sources .", "entities": [[12, 13, "DatasetName", "DBpedia"]]}, {"text": "2.Matching of Rakuten authors : we build entities using fuzzy search on the author name \ufb01eld on DBpedia and consider the DBpedia value to be canonical .", "entities": [[17, 18, "DatasetName", "DBpedia"], [21, 22, "DatasetName", "DBpedia"]]}, {"text": "We limit the number of false positives in fuzzy search by tokenizing both names , and keeping only the names where at least one token from the name on RFR is approximately found in the external resource ( Levenshtein distance < 2 ) .", "entities": []}, {"text": "3.Name variants : DBpedia , BnF , and JRCnames ( Steinberger et al . , 2011 ; Maud et", "entities": [[3, 4, "DatasetName", "DBpedia"]]}, {"text": "al . , 2016 ) directly provide data about people ( not limited to book authors ) and their name variants .", "entities": []}, {"text": "4https://www.wikipedia.org 5id.loc.gov/authorities/names.html", "entities": []}, {"text": "123As an example , by using the wikiPageRedirects \ufb01eld in DBpedia we can build a large entity for the canonical name \u201c Anton Tchekhov \u201d , containing \u201c Anton Tchechov \u201d , \u201c Ant ` on P`avlovi \u02c7c Ch\u00b4echov \u201d , \u201c Checkhov \u201d , \u201c Anton Chekov \u201d , and many more .", "entities": [[10, 11, "DatasetName", "DBpedia"]]}, {"text": "After creating the name entity dataset , we normalize all names to latin-1 .", "entities": []}, {"text": "We obtain about 750,000 entities , for a total of 2.1 million names .", "entities": []}, {"text": "2.4 Annotated Rakuten France data In order to evaluate the overall system , we need product data from RFR for which the canonical author name has been carefully annotated and can be considered as the ground truth .", "entities": []}, {"text": "To this end , we have considered a subset of 1000 books from the RFR dataset , discarding books written by more than one author for simplicity.6We \ufb01nd that 467 books have a canonical author name that differs from RFR \u2019s original ( unnormalized ) author name .", "entities": []}, {"text": "Also , 310 do not have an ISBN or do not match on any of the bibliographic resources listed in Section 2.2 .", "entities": []}, {"text": "Among them , 208 books have a canonical name that differs from the input catalog name provided by the seller .", "entities": []}, {"text": "3 Experimental setup The overview of the system can be found in Fig .", "entities": []}, {"text": "1 .", "entities": []}, {"text": "Its \ufb01rst component , the matching via ISBN against external databases , has already been presented in Section 2.2 .", "entities": []}, {"text": "In the rest of this section , we will shed light on the three machine learning components of the system .", "entities": []}, {"text": "3.1 Siamese approximate name matching We want to learn a mapping that assigns a similarity score to a pair of author names such that name variants of the same entity will have high similarity , and", "entities": []}, {"text": "names that belong to different entities will have low similarity .", "entities": []}, {"text": "Once learned , this mapping will enable us to assign an entity to any given name .", "entities": []}, {"text": "To this end , we might use a classical string metric such as the Levenshtein distance or the n - gram distance ( Kondrak , 2005 ) .", "entities": []}, {"text": "However , those are not speci\ufb01c to people \u2019s names , and might return a large distance ( low similarity ) in cases such as the inversion between \ufb01rst name and last name or the abbreviation of the \ufb01rst name to an initial .", "entities": []}, {"text": "Thus , we want to use the dataset of name entities to learn a specialized notion of similarity \u2014 this is known as distance metric learning ( Kulis et al . , 2013 ) .", "entities": [[23, 25, "HyperparameterName", "distance metric"]]}, {"text": "To this purpose , we use a pair of neural networks with shared weights , or Siamese neural network ( Bromley et al . , 1994 ) .", "entities": []}, {"text": "Each network is a recurrent neural network ( RNN ) composed of a character - level embedding layer with 256 units , a bidirectional long shortterm memory ( LSTM ) ( Hochreiter and Schmidhuber , 1997 ) with 2\u0002128units , and a dense layer with 256 units .", "entities": [[28, 29, "MethodName", "LSTM"]]}, {"text": "Each network takes a name as input and outputs a representation \u2014 the two representations are then compared using cosine similarity with a target value equal to 6The annotated RFR dataset is publicly available at https://rit.rakuten.co.jp/data_release .1 for name variants of the same entity , and to 0 otherwise .", "entities": [[47, 48, "DatasetName", "0"]]}, {"text": "We preprocess the input by representing all characters in ASCII and lowercase .", "entities": []}, {"text": "We consider a sequence length of 32 using zero padding .", "entities": []}, {"text": "The Siamese network is trained with contrastive loss ( Hadsell et al . , 2006 ) in order to push the similarity towards 1 for similar pairs , and below a certain margin ( that we set to 0 ) for dissimilar pairs .", "entities": [[1, 3, "MethodName", "Siamese network"], [7, 8, "MetricName", "loss"], [38, 39, "DatasetName", "0"]]}, {"text": "The optimization is done using Adam ( Kingma and Ba , 2014 ) , with a learning rate of 10\u00003and a gradient clipping value of 5 .", "entities": [[5, 6, "MethodName", "Adam"], [16, 18, "HyperparameterName", "learning rate"], [21, 23, "MethodName", "gradient clipping"]]}, {"text": "We use batches of 512 samples , consider a negative to positive pairs ratio of 4 : 1 , and randomly generate new negative pairs at every epoch .", "entities": []}, {"text": "At test time , we search for the canonical name whose representation is closest to that of the query , using only the high - quality name entities from DBpedia , BnF , and JRC - names .", "entities": [[29, 30, "DatasetName", "DBpedia"]]}, {"text": "To this end , we do approximate nearest neighbor search using Annoy7 .", "entities": []}, {"text": "3.2 Name correction with seq2seq networks We use a generative model to correct and normalize authors \u2019 names directly .", "entities": [[4, 5, "MethodName", "seq2seq"]]}, {"text": "The dataset of name entities is again employed to train a sequence - to - sequence ( seq2seq ) model ( Sutskever et al . , 2014 ) to produce the canonical form of a name from one of its variants .", "entities": [[17, 18, "MethodName", "seq2seq"]]}, {"text": "The dataset is further augmented by including additional variants where the \ufb01rst name is abbreviated to an initial .", "entities": []}, {"text": "The seq2seq model is an encoder - decoder using RNNs , with a character embedding layer , as in the case of the Siamese network .", "entities": [[1, 2, "MethodName", "seq2seq"], [23, 25, "MethodName", "Siamese network"]]}, {"text": "The encoder is a bi - directional LSTM with 2\u0002256units , while the decoder is a plain LSTM with 512units connected to a softmax layer that computes a probability distribution over the characters .", "entities": [[7, 8, "MethodName", "LSTM"], [17, 18, "MethodName", "LSTM"], [23, 24, "MethodName", "softmax"]]}, {"text": "The training is performed by minimizing the categorical cross - entropy loss , using teacher forcing ( Williams and Zipser , 1989 ) .", "entities": [[11, 12, "MetricName", "loss"]]}, {"text": "The optimization setting is identical to that of the Siamese nework , with batches of 1024 samples .", "entities": []}, {"text": "For inference , we collect the 10output sequences with highest probability using beam search .", "entities": []}, {"text": "3.3 Ranking of the proposals For any given book with an ISBN and an author \u2019s name , all three techniques shown in Fig .", "entities": []}, {"text": "1 provide one or several candidate canonical names .", "entities": []}, {"text": "As we aim at providing an automated tool to enhance the quality of the book products , the \ufb01nal system should provide a ranked list of candidates with a calibrated con\ufb01dence level .", "entities": []}, {"text": "For this purpose we train a logistic regression to estimate the probability that a proposal is the canonical form for an author \u2019s name .", "entities": [[6, 8, "MethodName", "logistic regression"]]}, {"text": "This information is then used as a con\ufb01dence score to rank the different candidate names returned by the three normalization approaches .", "entities": []}, {"text": "Speci\ufb01cally , we represent a proposal with a set of 12 features : 11 indicating whether it is found in the bibliographic sources , generated from the seq2seq model , matched with the Siamese network or equal to the input name , and", "entities": [[27, 28, "MethodName", "seq2seq"], [33, 35, "MethodName", "Siamese network"]]}, {"text": "one last feature corresponding to the cosine 7https://github.com/spotify/annoy", "entities": []}, {"text": "124distance between the representation of the proposal and that of the input name .", "entities": []}, {"text": "The selected features re\ufb02ect that the con\ufb01dence of the global system should increase with ( i)the consensus among the different sources , and ( ii ) the similarity of the candidate to the input name .", "entities": []}, {"text": "For this component we use the annotated dataset introduced in Section 2.4 , splitting the books between training and test sets , with a ratio of 50 % : 50 % , generating a total of 11185 proposals .", "entities": []}, {"text": "4 Results The three machine learning components discussed in the previous section have been individually evaluated on their speci\ufb01c task .", "entities": []}, {"text": "Furthermore the \ufb01nal system has been evaluated in terms of correctly normalized book authors in a real case scenario .", "entities": []}, {"text": "Siamese approximate name matching We evaluate the Siamese network on a held out test set , and compare it to an n - gram distance , by checking that the nearest neighbor of a name variant is the canonical name of the entity to which it belongs .", "entities": [[7, 9, "MethodName", "Siamese network"]]}, {"text": "We \ufb01nd an accuracy of 79:8%for the Siamese network , against 71:1%for the n - gram baseline with n= 3 .", "entities": [[3, 4, "MetricName", "accuracy"], [7, 9, "MethodName", "Siamese network"]]}, {"text": "We have also checked metrics when introducing a threshold distance above which we consider that no matching entity is found , and found systematic improvement over the baseline .", "entities": []}, {"text": "In the \ufb01nal system , we set the threshold to in\ufb01nity .", "entities": []}, {"text": "Siamese networks are more effective than simpler rule - based approaches and more speci\ufb01cally they perform better than the n - gram baseline on the following cases : \u000fVittorio Hugo!Victor Hugo : capturing name variants in different languages ; \u000fBill Shakespeare!William Shakespeare : capturing common nicknames Name correction with seq2seq networks Similarly to the previous approach , the seq2seq network is evaluated on a held out test set by checking that one of the generated name variants is the canonical name of the entity to which it belongs .", "entities": [[49, 50, "MethodName", "seq2seq"], [58, 59, "MethodName", "seq2seq"]]}, {"text": "As expected , name normalization using seq2seq network gives poorer performances than approximate matching within a dataset of known authors , but constitutes a complementary approach that is useful in case of formatting issues or incomplete names .", "entities": [[6, 7, "MethodName", "seq2seq"]]}, {"text": "This approach alone reaches a top- 10accuracy of 42 % on the entire test set , 26 % on a test set containing only names with initials , and 53 % on a test set containing only minor spelling mistakes .", "entities": []}, {"text": "Some examples where seq2seq performs better than the other methods are as follows :", "entities": [[3, 4, "MethodName", "seq2seq"]]}, {"text": "\u000fV .", "entities": []}, {"text": "Hugo!Victor Hugo : \ufb01rst name prediction for authors we do n\u2019t have in the canonical database ; \u000fVicor Hugo!Victor Hugo : misspelling correction for authors we do n\u2019t have in the canonical database .", "entities": []}, {"text": "Table 2 : Global system top- kaccuracy at the book level .", "entities": []}, {"text": "Type of books # samples acc@1 acc@3 all 500 72 % 85 % unnorm .", "entities": []}, {"text": "input author 235 49 % 67 % no ISBN match 151 50 % 64 % unnorm .", "entities": []}, {"text": "+ no ISBN 109 35 % 49 % Ranking of the proposals With a decision threshold ofp= 0:5 , the trained classi\ufb01er has an accuracy of 93 % for both positive and negative candidates in the test set .", "entities": [[24, 25, "MetricName", "accuracy"]]}, {"text": "The coef\ufb01cients of the estimator reveal the importance of the features and , thus , of the related components .", "entities": []}, {"text": "The three most important contributions are the match with the Siamese network , the match via ISBN in Babelio , and the similarity with the input catalog name , con\ufb01rming the relevance of a multi - approach design choice .", "entities": [[10, 12, "MethodName", "Siamese network"]]}, {"text": "Global system In order to re\ufb02ect the actual use of the global system on e - commerce catalog data , the \ufb01nal evaluation is performed at the book level , by considering all the proposals provided by the different components for a given book .", "entities": []}, {"text": "The metric used is the top- kaccuracy on the ranked list of proposals for each book ; results are summarized in Table 2 .", "entities": []}, {"text": "We \ufb01nd that 72 % of the books have the author \u2019s name normalized by the highest ranked proposal .", "entities": []}, {"text": "Excluding from the evaluation books where the ground truth for the author \u2019s name equals the catalog value , this accuracy drops to 49 % .", "entities": [[20, 21, "MetricName", "accuracy"]]}, {"text": "In the case of books without ISBN or that do not match on any of the bibliographic resources , thus relying on machine learning - based components only , we \ufb01nd that 50 % of the books are normalized by the top proposal .", "entities": []}, {"text": "Finally , for the combination of the above two restrictions , we \ufb01nd a top-1 accuracy of 35 % .", "entities": [[14, 16, "MetricName", "top-1 accuracy"]]}, {"text": "5 Related works There is a long line of work on author name disambiguation for the case of bibliographic citation records ( Hussain and Asghar , 2017 ) .", "entities": []}, {"text": "While related , this problem differs from the one of book authors .", "entities": []}, {"text": "Indeed , unlike most books , research publications usually have several authors , each of them having published papers with other researchers .", "entities": []}, {"text": "The relationships among authors , which can be represented as a graph , may be used to help disambiguate the bibliographic citations .", "entities": []}, {"text": "Named entity linking ( Shen et al . , 2015 ) , where one aims at determining the identity of entities ( such as a person \u2019s name ) mentioned in text , is another related problem .", "entities": [[1, 3, "TaskName", "entity linking"]]}, {"text": "The crucial difference with the disambiguation of book authors is that entity linking systems leverage the context of the named entity mention to link unambiguously to an entity in a pre - populated knowledge base .", "entities": [[11, 13, "TaskName", "entity linking"]]}, {"text": "The conformity of truth in web resources is also a related problem , addressed in the literature by TruthFinder ( Yin et al . , 2008 ) algorithms .", "entities": []}, {"text": "Similarly , the proposed global model in which we combine sources learns to some extent the level of trust of the different", "entities": []}, {"text": "125sources .", "entities": []}, {"text": "Unlike our technique , the TruthFinder approach needs to start from a book we can unambiguously identify in several sources and , thus , needs its ISBN .", "entities": []}, {"text": "Distance metric learning with neural networks has been used for merging datasets on names ( Srinivas et al . , 2018 ) , for normalizing job titles ( Neculoiu et al . , 2016 ) , and for the disambiguation of researchers ( Zhang et al . , 2018 ) .", "entities": [[0, 2, "HyperparameterName", "Distance metric"]]}, {"text": "Sequence - to - sequence learning has been used for the more general task of text normalization ( Sproat and Jaitly , 2016 ) , and for sentence - level grammar error identi\ufb01cation ( Schmaltz et al . , 2016 ) .", "entities": []}, {"text": "To the best of our knowledge , the problem of normalization of book authors name has not been tackled in the previous literature , except for a work on named entity linking for French writers ( Frontini et al . , 2015 ) .", "entities": [[30, 32, "TaskName", "entity linking"]]}, {"text": "6 Conclusions We provided a \ufb01rst attempt at solving the problem of author name normalization in the context of books sold on e - commerce websites .", "entities": []}, {"text": "To this end , we used a composite system involving open data sources for books , approximate match with Siamese networks , name correction with sequence - to - sequence networks , and ranking of the proposals .", "entities": []}, {"text": "We \ufb01nd that 72 % of the books have the author \u2019s name normalized by the highest ranked proposal .", "entities": []}, {"text": "In order to facilitate future research , we are releasing data from Rakuten France : a large dataset containing product information , and a subset of it with expert human annotation for the authors \u2019 names .", "entities": []}, {"text": "They are accessible at rit.rakuten.co.jp/data_release .", "entities": []}, {"text": "Multiple challenges remain and are left for future research .", "entities": []}, {"text": "First , the system should be extended to handle the case of books with multiple authors .", "entities": []}, {"text": "In addition , the book title could be used to help disambiguate between authors and to query external bibliographic resources .", "entities": []}, {"text": "This work can also be seen as an intermediate step towards a knowledge base for book author names with name variants , extending public ones such as BnF , using the ISNI8for easier record linkage whenever available .", "entities": []}, {"text": "Acknowledgments We thank Rapha \u00a8el Ligier - Tirilly for his help with the deployment of the system as microservices , and Laurent Ach for his support .", "entities": []}, {"text": "References J. Bromley et al . 1994 .", "entities": []}, {"text": "Signature veri\ufb01cation using a \u201c siamese \u201d time delay neural network .", "entities": []}, {"text": "pages 737\u2013744 .", "entities": []}, {"text": "F. Frontini et al . 2015 .", "entities": []}, {"text": "Semantic web based named entity linking for digital humanities and heritage texts .", "entities": [[4, 6, "TaskName", "entity linking"]]}, {"text": "R. Hadsell , S. Chopra , and Y .", "entities": []}, {"text": "LeCun .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Dimensionality reduction by learning an invariant mapping .", "entities": [[0, 2, "TaskName", "Dimensionality reduction"]]}, {"text": "S. Hochreiter and J. Schmidhuber .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Long shortterm memory .", "entities": []}, {"text": "Neural computation 9(8):1735\u20131780 .", "entities": []}, {"text": "8International Standard Name Identi\ufb01er , isni.orgI. Hussain and S. Asghar . 2017 .", "entities": []}, {"text": "A survey of author name disambiguation techniques : 2010 to 2016 .", "entities": []}, {"text": "The Knowledge Engineering Review 32 .", "entities": []}, {"text": "D. P. Kingma and J. Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "G. Kondrak .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "N - gram similarity and distance .", "entities": []}, {"text": "Springer , pages 115\u2013126 .", "entities": []}, {"text": "B. Kulis et al . 2013 .", "entities": []}, {"text": "Metric learning : A survey .", "entities": [[0, 2, "TaskName", "Metric learning"]]}, {"text": "Foundations and Trends in Machine Learning 5(4):287\u2013364 .", "entities": []}, {"text": "J. Lehmann et al . 2015 .", "entities": []}, {"text": "DBpedia - a large - scale , multilingual knowledge base extracted from wikipedia .", "entities": [[0, 1, "DatasetName", "DBpedia"]]}, {"text": "Semantic Web Journal 6(2):167\u2013195 .", "entities": []}, {"text": "E. Maud et", "entities": []}, {"text": "al . 2016 .", "entities": []}, {"text": "Jrc - names : Multilingual entity name variants and titles as linked data .", "entities": []}, {"text": "Semantic Web Journal 8(2):283\u2013295 .", "entities": []}, {"text": "P. Neculoiu et al . 2016 .", "entities": []}, {"text": "Learning text similarity with siamese recurrent networks .", "entities": [[1, 3, "TaskName", "text similarity"]]}, {"text": "A. Schmaltz et al . 2016 .", "entities": []}, {"text": "Sentence - level grammatical error identi\ufb01cation as sequence - to - sequence correction .", "entities": []}, {"text": "W. Shen , J. Wang , and J. Han . 2015 .", "entities": []}, {"text": "Entity linking with a knowledge base : Issues , techniques , and solutions .", "entities": [[0, 2, "TaskName", "Entity linking"]]}, {"text": "IEEE TKDE .", "entities": []}, {"text": "R. Sproat and N. Jaitly .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Rnn approaches to text normalization : A challenge .", "entities": []}, {"text": "K. Srinivas , A. Gale , and J. Dolby .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Merging datasets through deep learning .", "entities": []}, {"text": "R. Steinberger et al . 2011 .", "entities": []}, {"text": "Jrc - names : A freely available , highly multilingual named entity resource .", "entities": []}, {"text": "I. Sutskever , O. Vinyals , and Q. V .", "entities": []}, {"text": "Le . 2014 .", "entities": []}, {"text": "Sequence to sequence learning with neural networks .", "entities": [[0, 3, "MethodName", "Sequence to sequence"]]}, {"text": "R. J. Williams and D. Zipser .", "entities": []}, {"text": "1989 .", "entities": []}, {"text": "A learning algorithm for continually running fully recurrent neural networks .", "entities": []}, {"text": "Neural computation 1(2):270\u2013280 .", "entities": []}, {"text": "X. Yin et al . 2008 .", "entities": []}, {"text": "Truth discovery with multiple con\ufb02icting information providers on the web .", "entities": []}, {"text": "IEEE Transactions on Knowledge and Data Engineering .", "entities": []}, {"text": "Y .", "entities": []}, {"text": "Zhang", "entities": []}, {"text": "et al .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Name disambiguation in aminer : Clustering , maintenance , and human in the loop .", "entities": [[3, 4, "DatasetName", "aminer"]]}]