[{"text": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 502\u2013510 Copenhagen , Denmark , September 7\u201311 , 2017 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2017 Association for Computational Linguistics Sentiment Lexicon Construction with Representation Learning Based on Hierarchical Sentiment Supervision Leyi Wang and Rui Xia\u2217 School of Computer Science & Engineering Nanjing University of Science & Technology , China leyiwang.cn@gmail.com , rxia@njust.edu.cn Abstract Sentiment lexicon is an important tool for identifying the sentiment polarity of words and texts .", "entities": [[9, 11, "TaskName", "Representation Learning"]]}, {"text": "How to automatically construct sentiment lexicons has become a research topic in the \ufb01eld of sentiment analysis and opinion mining .", "entities": [[15, 17, "TaskName", "sentiment analysis"], [18, 20, "TaskName", "opinion mining"]]}, {"text": "Recently there were some attempts to employ representation learning algorithms to construct a sentiment lexicon with sentiment - aware word embedding .", "entities": [[7, 9, "TaskName", "representation learning"]]}, {"text": "However , these methods were normally trained under documentlevel sentiment supervision .", "entities": []}, {"text": "In this paper , we develop a neural architecture to train a sentiment - aware word embedding by integrating the sentiment supervision at both document and word levels , to enhance the quality of word embedding as well as the sentiment lexicon .", "entities": []}, {"text": "Experiments on the SemEval 2013 - 2016 datasets indicate that the sentiment lexicon generated by our approach achieves the state - of - the - art performance in both supervised and unsupervised sentiment classi\ufb01cation , in comparison with several strong sentiment lexicon construction methods .", "entities": [[3, 5, "DatasetName", "SemEval 2013"]]}, {"text": "1 Introduction Sentiment lexicon is a set of words ( or phrases ) each of which is assigned with a sentiment polarity score .", "entities": []}, {"text": "Sentiment lexicon plays an important role in many practical sentiment analysis and opinion mining tasks .", "entities": [[9, 11, "TaskName", "sentiment analysis"], [12, 14, "TaskName", "opinion mining"]]}, {"text": "There were some manually annotated universal sentiment lexicons such as General Inquireer ( GI ) and HowNet .", "entities": [[10, 11, "DatasetName", "General"]]}, {"text": "However , due to the ubiquitous domain diversity and absence of domain prior knowledge , the automatic construction technique for domain - speci\ufb01c sentiment lex\u2217The corresponding author of this paper.icons has become a challenging research topic in the \ufb01eld of sentiment analysis and opinion mining ( Wang and Xia , 2016 ) .", "entities": [[40, 42, "TaskName", "sentiment analysis"], [43, 45, "TaskName", "opinion mining"]]}, {"text": "The early work employed unsupervised learning for sentiment lexicon construction .", "entities": []}, {"text": "They normally labelled a set of seed words at \ufb01rst , and then learned the polarity of each candidate word , based on either word conjunction relations ( e.g. , constellation and transition in texts ) ( Hatzivassiloglou and McKeown , 1997 ) , or the word co - occurrence information ( such as pointwise mutual information , PMI ) ( Turney , 2002 ) , between the candidate word and the seed words .", "entities": []}, {"text": "However , the unsupervised manner showed limited effect in sentiment prediction , and the performance greatly depends on the quality of the seed words .", "entities": []}, {"text": "To fully exploit the sentiment labeling information in texts , a series of supervised learning methods was further proposed to learn the sentiment lexicons .", "entities": []}, {"text": "For example , Mohammad et al .", "entities": []}, {"text": "( 2013 ) proposed to construct sentiment lexicons by calculating PMI between the word and the distantly supervised sentiment labels ( such as emoticons ) in tweets and the word \u2019s sentiment orientation ( SO ) .", "entities": []}, {"text": "The resulting lexicons obtained the best results in SemEval 2013 .", "entities": [[8, 10, "DatasetName", "SemEval 2013"]]}, {"text": "More advanced representation learning models were also utilized , with the aim to construct the sentiment lexicons with ef\ufb01cient word embeddings ( Tang et al . , 2014a ; Hamilton et al . , 2016 ; V o and Zhang , 2016 ) .", "entities": [[2, 4, "TaskName", "representation learning"], [19, 21, "TaskName", "word embeddings"]]}, {"text": "The traditional representation learning framework such as Word2Vec only captures the syntactic information in the texts , but ignores the sentiment relations between words .", "entities": [[2, 4, "TaskName", "representation learning"]]}, {"text": "Therefore , some researchers attempted to add sentiment supervision into the network structure , in order to train a sentimentaware word embedding .", "entities": []}, {"text": "For example , Tang et al . ( 2014a ) exploited a dedicated neural architecture to integrate document - level sentiment supervision and the syntactic knowledge for representation502", "entities": []}, {"text": "learning .", "entities": []}, {"text": "The sentiment - aware word embedding is then used to construct a sentiment lexicon .", "entities": []}, {"text": "V o and Zhang ( 2016 ) proposed to learn a two - dimensional sentiment representation based on a simple neural network .", "entities": []}, {"text": "The sentiment lexicons generated by their approach obtained better performance to predict the tweet sentiment labels , in comparison with the PMI - based method ( Mohammad et al . , 2013 ) .", "entities": []}, {"text": "Although these supervised learning methods can to some extent exploit the sentiment labeling information in the texts and can learn a sentiment - aware word embedding , the manner of using document - level sentiment supervision suffers from some complex linguistic phenomena such as negation , transition and comparative degree , and hence unable to capture the \ufb01ne - grained sentiment information in the text .", "entities": []}, {"text": "For example , in the following tweet \u201c Four more fake people added me .", "entities": []}, {"text": "Is this why people do n\u2019t like Twitter ? :(", "entities": []}, {"text": "\u201d , the document - level sentiment label is negative , but there is a positive word \u201c like \u201d in the text .", "entities": []}, {"text": "In representation learning , the embeddings of words are summed up to represent the document , and the word \u201c like \u201d will be falsely associated with the negative sentiment label .", "entities": [[1, 3, "TaskName", "representation learning"]]}, {"text": "Such linguistic phenomena occur frequently in review texts , and makes sentiment - aware word representation learning less effective .", "entities": [[15, 17, "TaskName", "representation learning"]]}, {"text": "To address this problem , in this paper , we propose a new representation learning framework called HSSWE , to learn sentiment - aware word embeddings based on hierarchical sentiment supervision .", "entities": [[13, 15, "TaskName", "representation learning"], [24, 26, "TaskName", "word embeddings"]]}, {"text": "In HSSWE , the learning algorithm is supervised under both document - level sentiment labels and word - level sentiment annotations ( e.g. , labeling \u201c like \u201d as a positive word ) .", "entities": []}, {"text": "By leveraging the sentiment supervision at both document and word level , our approach can avoid the sentiment learning \ufb02aws caused by coarse - grained document - level supervision by incorporating \ufb01negrained word - level supervision , and improve the quality of sentiment - aware word embedding .", "entities": []}, {"text": "Finally , following Tang et al . ( 2014a ) , a simple classi\ufb01er was constructed to obtain the domainspeci\ufb01c sentiment lexicon by using word embeddings as inputs .", "entities": [[24, 26, "TaskName", "word embeddings"]]}, {"text": "The main contributions of this work are as follows : 1 .", "entities": []}, {"text": "To the best of our knowledge , this is the \ufb01rstwork that learns the sentiment - aware word representation under supervision at both document and word levels .", "entities": []}, {"text": "2 . Our approach supports several kinds of wordlevel sentiment annotations such as 1 ) prede\ufb01ned sentiment lexicon ; 2 ) PMI - SO lexicon with hard sentiment annotation ; 3 ) PMISO lexicon with soft sentiment annotation .", "entities": []}, {"text": "By using PMI - SO dictionary as word - level sentiment annotation , our approach is totally corpus - based , without any external resource .", "entities": []}, {"text": "3 .", "entities": []}, {"text": "Our approach obtains the state - of - the - art performance in comparison with several strong sentiment lexicon construction methods , on the benchmark SemEval 2013 - 2016 datasets for twitter sentiment classi\ufb01cation .", "entities": [[23, 25, "DatasetName", "the benchmark"], [25, 27, "DatasetName", "SemEval 2013"]]}, {"text": "2 Related Work In general , sentiment lexicons construction can be classi\ufb01ed into two categories , dictionary - based methods and corpus - based methods .", "entities": []}, {"text": "Dictionary - based methods generally integrate prede\ufb01ned resources , such as WordNet , to construct sentiment lexicons .", "entities": []}, {"text": "Hu and Liu ( 2004 ) exploited WordNet for sentiment lexicon construction .", "entities": []}, {"text": "They \ufb01rst labelled two sets of seed words by polarities , then extended the sets by adding the synonyms for each word to the same set and antonyms to the other .", "entities": []}, {"text": "For a given new word , Kim and Hovy ( 2004 ) introduced a Naive Bayes model to predict the polarities with .the synonym set obtained from WordNet as features .", "entities": []}, {"text": "Kamps et al .", "entities": []}, {"text": "( 2004 ) investigated a graph - theoretic model of WordNet \u2019s synonymy relation and measured the sentiment orientation by distance between each candidate word and the seed words with different polarities .", "entities": []}, {"text": "Heerschop et al .", "entities": []}, {"text": "( 2011 ) proposed a method to propagate the sentiment of seed set words through semantic relations of WordNet .", "entities": []}, {"text": "Corpus - based approaches originate from the latent relation hypothesis : \u201c Pairs of words that cooccur in similar patterns tend to have similar semantic and sentiment relations \u201d ( Turney , 2008 ) .", "entities": []}, {"text": "The primary corpus - based method made the use of PMI .", "entities": []}, {"text": "Turney ( 2002 ) built a sentiment lexicon by calculating PMI between the candidate word and seed words .", "entities": []}, {"text": "The difference of the PMI score between positive and negative seed words is \ufb01nally used as the sentiment orientation ( SO ) of each candidate word ( Turney , 2002 ) .", "entities": []}, {"text": "Many variants of503", "entities": []}, {"text": "PMI were proposed afterwards , for example , positive pointwise mutual information ( PPMI ) , second order co - occurrence PMI ( SOC - PMI ) , etc .", "entities": [[13, 14, "DatasetName", "PPMI"], [23, 24, "DatasetName", "SOC"]]}, {"text": "Hamilton et al .", "entities": []}, {"text": "( 2016 ) proposed to build a sentiment lexicon by a propagation method .", "entities": []}, {"text": "The key of this method is to build a lexical graph by calculating the PPMI between words .", "entities": [[14, 15, "DatasetName", "PPMI"]]}, {"text": "Instead of calculating the PMI between words , Mohammad et al .", "entities": []}, {"text": "( 2013 ) proposed to use emoticons as distant supervision and calculate the PMI between words and the distant class labels , and obtained sound performance for tweet sentiment classi\ufb01cation .", "entities": []}, {"text": "The latest corpus - based approaches normally utilize the up - to - date machine learning models ( e.g. neural networks ) to \ufb01rst learn a sentimentaware distributed representation of words , based on which the sentiment lexicon is then constructed .", "entities": []}, {"text": "There were many word representation learning methods such as NNLM ( Bengio et al . , 2003 ) and Word2Vec ( Mikolov et al . , 2013 ) .", "entities": [[4, 6, "TaskName", "representation learning"]]}, {"text": "However , they mainly consider the syntactic relation of words in the context but ignore the sentiment information .", "entities": []}, {"text": "Some work were later proposed to deal with this problem by incorporating the sentiment information during representation learning .", "entities": [[16, 18, "TaskName", "representation learning"]]}, {"text": "For example , Tang et al .", "entities": []}, {"text": "( 2014a ) adapted a variant of skip - gram model , which can learn the sentiment information based on distant supervision .", "entities": []}, {"text": "Furthermore , Tang et al .", "entities": []}, {"text": "( 2014b ) proposed a new neural network approach called SSWE to train sentimentaware word representation .", "entities": []}, {"text": "V o and Zhang ( 2016 ) exploited a simple and fast neural network to train a 2 - dimensional representation .", "entities": []}, {"text": "Each dimension is explicitly associated with a sentiment polarity .", "entities": []}, {"text": "The sentiment - aware word representation in these methods was normally trained based on only document - level sentiment supervision .", "entities": []}, {"text": "In contrast , the learning algorithm in our approach is supervised under both document - level and wordlevel sentiment supervision .", "entities": []}, {"text": "3", "entities": []}, {"text": "Our Approach Our approach is comprised of three base modules : ( 1 ) Word - level sentiment learning and annotation ; ( 2 ) Sentiment - aware word embedding learning ; ( 3 ) Sentiment lexicon construction .", "entities": []}, {"text": "Our approach depends on document - level sentiment labels .", "entities": []}, {"text": "The tweet corpus provides a cheap way to get document - level sentiment annotation , owing to the distant sentiment supervision .", "entities": []}, {"text": "But it should be noted that our approach is feasiblefor any corpus provided with document - level sentiment labels ( not merely tweets ) .", "entities": []}, {"text": "The \ufb01rst module of our method aims to learn the pseudo sentiment distribution for each word and use it as word - level sentiment annotations to supervise word embedding learning .", "entities": []}, {"text": "In the second module , we learn the sentimentaware embeddings for each word in corpus , based on hierarchical sentiment supervision .", "entities": []}, {"text": "In the last module , we construct a sentiment lexicon by using the sentiment - aware word embeddings as the basis .", "entities": [[16, 18, "TaskName", "word embeddings"]]}, {"text": "3.1 Learning Word - Level Sentiment Supervision", "entities": []}, {"text": "In addition to use a pre - de\ufb01ned sentiment lexicon for word - level annotations , we also propose to learn the word - level sentiment supervision , based on PMI and SO .", "entities": []}, {"text": "( 1 ) PMI and SO Given a corpus with document - level class labels .", "entities": []}, {"text": "We \ufb01rst compute the PMI score between each wordtand two class labels PMI ( t,+ ) = logp(+|t ) p(+ ) , ( 1 ) PMI ( t,\u2212 ) = logp(\u2212|t ) p(\u2212 ) , ( 2 ) where + and\u2212denote the positive and negative document - level class labels , respectively .", "entities": []}, {"text": "Second , we compute the SO score for each wordt : SO(t )", "entities": []}, {"text": "= PMI ( t,+)\u2212PMI ( t,\u2212).(3 ) We call{t , SO ( t)}as PMI - SO dictionary .", "entities": []}, {"text": "The PMI - SO dictionary was widely used as a corpusbased sentiment lexicon for sentiment classi\ufb01cation .", "entities": []}, {"text": "By contrast , in our approach , it is the \ufb01rst step to learn the sentiment - aware word representation .", "entities": []}, {"text": "Our approach supports two kinds of wordlevel sentiment annotations : 1 ) PMI - SO dictionary with hard sentiment annotation ; 2 ) PMI - SO dictionary with soft sentiment annotation .", "entities": []}, {"text": "The word - level sentiment annotation is represented as [ \u02c6p(\u2212|t),\u02c6p(+|t ) ] .", "entities": []}, {"text": "We employ the following two ways to obtain [ \u02c6p(\u2212|t),\u02c6p(+|t ) ] .", "entities": []}, {"text": "( 2 ) PMI - SO lexicon with hard sentiment annotation504", "entities": []}, {"text": "Notations Description et", "entities": []}, {"text": "The embedding of word t de The document representation of d bt", "entities": []}, {"text": "The bias of word - level softmax layer bd The bias of document - level softmax layer \u03b8t Weight of word - level softmax layer \u03b8d Weight of document - level softmax layer p(c|et )", "entities": [[6, 7, "MethodName", "softmax"], [15, 16, "MethodName", "softmax"], [23, 24, "MethodName", "softmax"], [31, 32, "MethodName", "softmax"]]}, {"text": "The sentiment distribution of word tpredicted by our model p(c|de )", "entities": []}, {"text": "The sentiment distribution of document d predicted by our model \u02c6p(c|t ) The word - level sentiment annotation of wordtwith respect to class c \u02c6p(c|d ) The document - level sentiment annotation of documentdwith respect to class c Table 1 : The parameters used in our neural network .", "entities": []}, {"text": "\u201c Hard sentiment annotation \u201d indicates that [ \u02c6p(\u2212|t),\u02c6p(+|t)]is a two - dimensional one - hot representation , where the annotation of words is given by the class labels : [ \u02c6p(\u2212|t),\u02c6p(+|t ) ]", "entities": []}, {"text": "= \uf8f1 \uf8f4\uf8f2 \uf8f4\uf8f3[0,1 ] , ifSO(t)>0 [ 1,0 ] , ifSO(t)<0 random{[1,0]or[0,1]},otherwise .", "entities": []}, {"text": "( 4 ) ( 3 ) PMI - SO lexicon with soft sentiment annotation \u201c Soft sentiment annotation \u201d means that the annotation is given by the probability of two sentiment polarities , rather than the class label .", "entities": []}, {"text": "We \ufb01rst use the sigmoid function to map the SO score to the range of a probability , and then de\ufb01ne [ \u02c6p(\u2212|t),\u02c6p(+|t ) ]", "entities": []}, {"text": "= [ 1\u2212\u03c3(SO(t)),\u03c3(SO(t ) ) ] ( 5 ) as the PMI - SO soft sentiment distribution of the wordt .", "entities": []}, {"text": "3.2 Learning Sentiment - aware Word Representation under Hierarchical Sentiment Supervision", "entities": []}, {"text": "Till now we have obtained both document and word - level sentiment annotations , in the next step , we propose a neural network framework to learn the sentiment - aware word representation by integrating the sentiment supervision at both word and document granularities .", "entities": []}, {"text": "We call it \u201c hierarchical sentiment supervision \u201d .", "entities": []}, {"text": "The architecture of ourmodel is shown in Figure 1 .", "entities": []}, {"text": "We denote the corpus asD={d1,d2, ... ,d N}whereNis the size of the corpus .", "entities": []}, {"text": "Suppose dkisk - th document in D , andti represents the i - th word in a document", "entities": []}, {"text": "d.", "entities": []}, {"text": "The parameters used in our neural network are described in Table 1 .", "entities": []}, {"text": "We construct a embedding matrix C\u2208RV\u00d7M , of which each row represents the embedding of a word in the vocabulary , where Vis the size of the vocabulary and Mis the dimension of word embedding .", "entities": []}, {"text": "We randomly initialize each element of matrixCwith a normal distribution .", "entities": []}, {"text": "( 1 ) Word - Level Sentiment Supervision We use the word - level sentiment annotation [ \u02c6p(\u2212|t),\u02c6p(+|t)]provided in Section 3.1 to supervise word representation learning at the word level .", "entities": [[24, 26, "TaskName", "representation learning"]]}, {"text": "For each word in document d , we map it to a continuous representation as e\u2208Cand feedeinto our model to predict the sentiment distribution of the input word : p(c|e ) = softmax ( \u03b8t\u00b7e+bt ) .", "entities": [[32, 33, "MethodName", "softmax"]]}, {"text": "( 6 ) The cost function is de\ufb01ned as the average cross entropy that measures the difference between the sentiment distribution predicted in our model and the sentiment annotations at the word level : fword=\u22121 TN / summationdisplay k=1 / summationdisplay t\u2208dk / summationdisplay c\u2208{+,\u2212}\u02c6p(c|t ) logp(c|et ) ( 7 ) whereTis the number of words in corpus .", "entities": []}, {"text": "( 2 ) Document - Level Sentiment Supervision We use the document - level sentiment annotations to supervise word representation learning at the document level .", "entities": [[19, 21, "TaskName", "representation learning"]]}, {"text": "In order to obtain a continuous representation of a document d , we simply use the average embedding of words in dasde : de=1 |d|/summationdisplay t\u2208det .", "entities": []}, {"text": "( 8) We feeddeinto our model to predict the sentiment probability : p(c|de ) = softmax ( \u03b8d\u00b7de+bd ) .", "entities": [[15, 16, "MethodName", "softmax"]]}, {"text": "( 9)505", "entities": []}, {"text": "Average Pooling Lookup layerRepresentation Layer \u2026 Output Layer PositiveNegative An Element of EmbeddingSoftmax \u2026 Input layerOperationDocument -Level Sentiment Supervision Word -Level Sentiment Supervision SoftmaxFigure 1 : The Architecture of our Neural Network .", "entities": [[0, 2, "MethodName", "Average Pooling"]]}, {"text": "Given a document d , represented as [ t1,t2, ... ,t n ] .", "entities": []}, {"text": "tiis thei - th word in d. Andetirepresents the embedding of the word ti .", "entities": []}, {"text": "We takede , the average embedding of [ et1,et2, ... ,e tn ] , as the representation of document d.", "entities": []}, {"text": "We get each embedding of words indas input to predict its sentiment polarities .", "entities": []}, {"text": "We also take deas input to predict the sentiment for documentdone time per epoch .", "entities": []}, {"text": "Similarly , the cost function is de\ufb01ned as average cross entropy that measures the difference between the sentiment distribution predicted in our model and the sentiment annotation at the document level : fdoc=\u22121 NN / summationdisplay k=1 / summationdisplay c\u2208{+,\u2212}\u02c6p(c|dk ) logp(c|dek ) ( 10 ) where \u02c6p(c|dk)is the sentiment annotation of documentdk.\u02c6p(c|dk )", "entities": []}, {"text": "= 1 denotes the class label of dkis positive , otherwise \u02c6p(c|dk ) = 0 .", "entities": [[14, 15, "DatasetName", "0"]]}, {"text": "( 3 ) Word and Document - Level Joint Learning In order to learn the sentiment - aware word representation at both word and document levels , we integrate the cost function of two levels in a weighted combination way .", "entities": []}, {"text": "The \ufb01nal cost function is de\ufb01ned as follows : f = \u03b1fword+ ( 1\u2212\u03b1)fdoc ( 11 ) where\u03b1is a tradeoff parameter ( 0\u2264\u03b1\u22641 ) .", "entities": []}, {"text": "Theweight offword can be increased by choosing a lager value of \u03b1 .", "entities": [[11, 12, "HyperparameterName", "\u03b1"]]}, {"text": "We train our neural model with stochastic gradient descent and use AdaGrad ( Duchi et al . , 2011 ) to update the parameters .", "entities": [[6, 9, "MethodName", "stochastic gradient descent"], [11, 12, "MethodName", "AdaGrad"]]}, {"text": "3.3 From Sentiment Representation to Sentiment Lexicon", "entities": []}, {"text": "In this part , we follow the method proposed by Tang et al .", "entities": []}, {"text": "( 2014a ) to build a classi\ufb01er to convert the sentiment - aware word representation learned in Section 3.2 to a sentiment lexicon .", "entities": []}, {"text": "The word representation is the input of the classi\ufb01er and word sentiment polarity is the output .", "entities": []}, {"text": "Firstly , we utilize the embedding of 125 positive and 109 negative seed words manually labelled by Tang et al .", "entities": []}, {"text": "( 2014a ) as training data1 .", "entities": []}, {"text": "Secondly , a variant - KNN classi\ufb01er is also applied to extending the seed words on a web dictionary called Urban Dictionary .", "entities": []}, {"text": "Unlike ( Tang et al . , 1http://ir.hit.edu.cn/ dytang / paper/14coling / data.zip506", "entities": []}, {"text": "Dataset # pos # negTotal SemEval2013 - train 3632 1449 5081 SemEval2013 - dev 482 282 764 SemEval2013 - test 1474 559 2033 SemEval2014 - test 982 202 1184 SemEval2015 - test 1038 365 1403 SemEval2016 - test 7059 3231 10290 Table 2 : Statistics of Evaluation Datasets 2014a ) , we did not extend the neutral words .", "entities": []}, {"text": "Thirdly , a traditional logistic regression classi\ufb01er is trained by using the embeddings of extended sentiment words as the inputs .", "entities": [[4, 6, "MethodName", "logistic regression"]]}, {"text": "The sentiment score of a word is the difference between its positive and negative probabilities .", "entities": []}, {"text": "Finally , the sentiment lexicon can be collected by using the classi\ufb01er to predict the other words \u2019 sentiment score .", "entities": []}, {"text": "4 Experiment Study 4.1 Datasets and Settings We utilize the public distant - supervision corpus2 ( Go et al . , 2009 ) to learn our lexicons .", "entities": []}, {"text": "We set M , the dimension of embedding , as 50 .", "entities": []}, {"text": "The learning rate is 0.3 for stochastic gradient descent optimizer .", "entities": [[1, 3, "HyperparameterName", "learning rate"], [6, 9, "MethodName", "stochastic gradient descent"], [9, 10, "HyperparameterName", "optimizer"]]}, {"text": "We tune the hyper - parameter \u03b1in the training process .", "entities": []}, {"text": "We evaluate the sentiment lexicons in both supervised and unsupervised sentiment classi\ufb01cation tasks , on the SemEval 2013 - 2016 datasets .", "entities": [[16, 18, "DatasetName", "SemEval 2013"]]}, {"text": "The statistics of evaluation datasets are shown in Table 2 .", "entities": []}, {"text": "Supervised Sentiment Classi\ufb01cation Evaluation : To evaluate the effect of the sentiment lexicon in supervised sentiment classi\ufb01cation , we report the supervised sentiment classi\ufb01cation performance by using some pre - de\ufb01ned lexicon features .", "entities": []}, {"text": "We follow ( Mohammad et al . , 2013 ) to extract the lexicon features as follows : \u2022Total count of words in the tweet score of which is greater than 0 ; \u2022Total count of words in the tweet score of which is less than 0 ; \u2022The sum of scores for all word great than 0 ; 2http://help.sentiment140.com/for-students\u2022The sum of scores for all word less than 0 ; \u2022The max score greater than 0 ; \u2022The min score less than 0 ; \u2022Non - zero score of the last positive word in the tweet ; \u2022Non - zero score of the last negative word in the tweet .", "entities": [[31, 32, "DatasetName", "0"], [46, 47, "DatasetName", "0"], [57, 58, "DatasetName", "0"], [68, 69, "DatasetName", "0"], [75, 76, "DatasetName", "0"], [82, 83, "DatasetName", "0"]]}, {"text": "We report the performance of SVM by using these lexicon features .", "entities": [[5, 6, "MethodName", "SVM"]]}, {"text": "The LIBSVM3toolkit is used with a linear kernel and the penalty parameter is set as the default value .", "entities": []}, {"text": "The metric is F1score .", "entities": []}, {"text": "Unsupervised Sentiment Classi\ufb01cation Evaluation : For unsupervised sentiment classi\ufb01cation , we sum up the scores of all sentiment words in the document , according to the sentiment lexicon .", "entities": []}, {"text": "If the sum is greater than 0 , the document will be considered as positive , otherwise negative .", "entities": [[6, 7, "DatasetName", "0"]]}, {"text": "The unsupervised learning evaluation metric is accuracy .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "4.2 ( External ) Comparison with Public Lexicons", "entities": []}, {"text": "We compare our HSSWE method with four sentiment lexicons generated by the related work proposed in recent years : \u2022Sentiment140 was constructed by Mohammad et al .", "entities": []}, {"text": "( 2013 ) on tweet corpus based on PMI between each word and the emoticons .", "entities": []}, {"text": "\u2022HIT was constructed by Tang et al .", "entities": []}, {"text": "( 2014a ) with a representation learning approach .", "entities": [[5, 7, "TaskName", "representation learning"]]}, {"text": "\u2022NNwas constructed by V o and Zhang ( 2016 ) with a neural network method .", "entities": []}, {"text": "\u2022ETSL refers to SemEval-2015 English Twitter Sentiment Lexicon4(Rosenthal et al . , 2015 ; Kiritchenko et", "entities": []}, {"text": "al . , 2014 ) , which is done using Best - Worst Scaling .", "entities": []}, {"text": "Note that Tang et al . ( 2014a ) , V o and Zhang ( 2016 ) used incomplete dataset of SemEval2013 in their papers .", "entities": []}, {"text": "For fair comparison , we conduct 3http://www.csie.ntu.edu.tw/ cjlin / libsvm 4http://www.saifmohammad.com/WebDocs/lexiconstoreleas eonsclpage / SemEval2015 - English - Twitter - Lexicon.zip507", "entities": []}, {"text": "Lexicon Semeval2013 Semeval2014 Semeval2015 Semeval2016 Average Sentiment140 0.7317 0.7271 0.6917 0.6809 0.7079 HIT 0.7181 0.6947 0.6797 0.6928 0.6963 NN 0.7225 0.7115 0.6970 0.6887 0.7049 ETSL 0.7104 0.7090 0.6650 0.6862 0.6926 HSSWE 0.7550 0.7424 0.6921 0.7097 0.7248", "entities": [[6, 7, "DatasetName", "Sentiment140"]]}, {"text": "Table 3 : Supervised Evaluation for External Comparison ( F1Score )", "entities": []}, {"text": "Lexicon Semeval2013", "entities": []}, {"text": "Semeval2014 Semeval2015 Semeval2016 Average Sentiment140 0.7208 0.7416 0.6935 0.6928 0.7122 HIT 0.7566 0.7922 0.7128 0.7282 0.7474 NN 0.6903 0.7280 0.6507 0.6585 0.6819 ETSL 0.7675 0.8226 0.7505 0.7365 0.7693 HSSWE 0.7734 0.8539 0.7669 0.7206 0.7787 Table 4 : Unsupervised Evaluation for External Comparison ( Accuracy ) all the comparison experiments on the complete benchmark datasets .", "entities": [[4, 5, "DatasetName", "Sentiment140"], [43, 44, "MetricName", "Accuracy"]]}, {"text": "Supervised Sentiment Classi\ufb01cation : We \ufb01rst report the supervised sentiment classi\ufb01cation F1 score of \ufb01ve compared methods on the Semeval 2013 - 2016 datasets in Table 3 .", "entities": [[11, 13, "MetricName", "F1 score"], [19, 21, "DatasetName", "Semeval 2013"]]}, {"text": "It can be seen that our HSSWE method gets the best result on all four datasets .", "entities": []}, {"text": "It outperforms Sentiment140 , HIT , NN and ETSL 1.7 , 2.8 , 1.9 , and 3.2 percentages on the average of four datasets .", "entities": [[2, 3, "DatasetName", "Sentiment140"]]}, {"text": "The improvements are signi\ufb01cant according to the paired t - test .", "entities": []}, {"text": "Unsupervised Sentiment Classi\ufb01cation : We then report the unsupervised sentiment classi\ufb01cation accuracy of \ufb01ve methods on the Semeval 2013 - 2016 datasets in Table 4 .", "entities": [[11, 12, "MetricName", "accuracy"], [17, 19, "DatasetName", "Semeval 2013"]]}, {"text": "In can be seen that HSSWE obtains the best performance on Semeval 2013 - 2015 .", "entities": [[11, 13, "DatasetName", "Semeval 2013"]]}, {"text": "On the Semeval 2016 dataset , it is slightly lower than ETSL .", "entities": []}, {"text": "Across four datasets , the average accuracy of HSSWE is 6.6 , 3.1 , 9.6 and 0.94 higher than Sentiment140 , HIT , NN and ETSL , respectively .", "entities": [[5, 7, "MetricName", "average accuracy"], [19, 20, "DatasetName", "Sentiment140"]]}, {"text": "4.3 ( Internal ) Comparison within the Model", "entities": []}, {"text": "In order to further verify the effectiveness of our method and analyze which part of our model contributes the most , we carried out the internal comparison within our model .", "entities": []}, {"text": "We design the following two simpli\ufb01ed versions of our model for comparison : \u2022PMI - SO denotes a PMI - SO based sentiment lexicon with soft sentiment annotation learned in Section 3.1 .", "entities": []}, {"text": "\u2022Doc - Sup denotes the neural network systemwith only document - level sentiment supervision .", "entities": []}, {"text": "It equals to HSSWE when \u03b1= 0 .", "entities": [[6, 7, "DatasetName", "0"]]}, {"text": "Actually , HSSWE can be viewed as a \u201c combination \u201d of PMI - SO and Doc - Sup .", "entities": []}, {"text": "In Tables 5 and 6 , we report the comparison results on supervised and unsupervised sentiment classi\ufb01cation respectively .", "entities": []}, {"text": "Supervised Sentiment Classi\ufb01cation : As is shown in Table 5 , two basic models PMI - SO and Doc - Sup show similar performance .", "entities": []}, {"text": "They have distinct superiority across different datasets .", "entities": []}, {"text": "But both are signi\ufb01cantly lower than HSSWE .", "entities": []}, {"text": "It shows that by combing the supervision at both document and word levels , it can indeed improve the quality of sentiment - aware word embedding and the subsequent sentiment lexicon .", "entities": []}, {"text": "Unsupervised Sentiment Classi\ufb01cation : As is shown in Table 6 , the conclusions are similar with that in supervised sentiment classi\ufb01cation : HSSWE achieves the signi\ufb01cantly better performance .", "entities": []}, {"text": "4.4 Word - level Sentimnt Annotation :", "entities": []}, {"text": "Hard vs. Soft In Section 3.1 , we introduce two kinds of wordlevel sentiment annotation , i.e. , soft and hard sentiment annotation .", "entities": []}, {"text": "We now compare two methods .", "entities": []}, {"text": "The results are reported in Tables 5 and 6 .", "entities": []}, {"text": "It can be seen that for supervised evaluation , HSSWE ( soft ) and HSSWE ( hard ) yield comparative performance .", "entities": []}, {"text": "HSSWE ( hard ) has slight superiority over HSSWE ( hard ) in Semeval 2013 , 2014 and 2016 , but HSSWE ( hard ) is better on Semeval2015 .", "entities": [[13, 15, "DatasetName", "Semeval 2013"]]}, {"text": "In contrast , for unsupervised evaluation , HSSWE ( soft ) is signi\ufb01cantly better than508", "entities": []}, {"text": "Lexicon Semeval2013", "entities": []}, {"text": "Semeval2014 Semeval2015 Semeval2016", "entities": []}, {"text": "Average PMI - SO 0.7265 0.7333 0.7008 0.6858 0.7116 Doc - Sup 0.7326 0.7302 0.6814 0.6986 0.7107 HSSWE ( soft ) 0.7550 0.7424 0.6921 0.7097 0.7248 HSSWE ( hard ) 0.7503 0.7383 0.7020 0.7061 0.7242 Table 5 : Supervised Evaluation for Internal Comparison ( F1Score ) , where HSSWE ( hard ) and HSSWE ( soft ) utilize the PMI - SO lexicon with hard sentiment annotation and soft sentiment annotation at the word level , respectively .", "entities": []}, {"text": "Lexicon Semeval2013", "entities": []}, {"text": "Semeval2014 Semeval2015 Semeval2016", "entities": []}, {"text": "Average Doc - Sup 0.7252 0.8294 0.7391 0.6859 0.7449 HSSWE ( soft ) 0.7734 0.8539 0.7669 0.7206 0.7787 HSSWE ( hard ) 0.7418 0.8395 0.7633 0.7011 0.7614 Table 6 : Unsupervised Evaluation for Internal Comparison ( Accuracy ) 0.0 0.2 0.4 0.6 0.8 1.0 alpha0.680.690.700.710.720.730.740.75Macro - F1 Score SemEval2013 SemEval2014 SemEval2015 SemEval2016 Figure 2 : HSSWE ( soft ) with different \u03b1 HSSWE ( hard ) .", "entities": [[36, 37, "MetricName", "Accuracy"], [46, 48, "MetricName", "F1 Score"], [61, 62, "HyperparameterName", "\u03b1"]]}, {"text": "The average improvement is 1.7 percentage .", "entities": []}, {"text": "4.5 Tuning the Parameter \u03b1", "entities": [[4, 5, "HyperparameterName", "\u03b1"]]}, {"text": "In this section , we discuss the tradeoff between two parts of supervisions by turning the tradeoff parameter\u03b1 .", "entities": []}, {"text": "When\u03b1is 0 , HSSWE only bene\ufb01ts from the document - level sentiment supervision and when \u03b1is 1 , HSSWE bene\ufb01ts from only word - level sentiment supervision .", "entities": [[1, 2, "DatasetName", "0"]]}, {"text": "We observe that HSSWE performs better when \u03b1is in the range of [ 0.45,0.55 ] .", "entities": []}, {"text": "By integrating two component parts of sentiment supervision , HSSWE has signi\ufb01cant superiority over that learned from either one .", "entities": []}, {"text": "4.6 Lexicon Analysis In order to gain more insight of our model and observe the effectiveness of the sentiment lexicon , in Table 7 we extract the positive sentimen - Words HSSWE PMI - SO Doc - Sup well 0.5740 0.5430 0.7898 better 0.5837 0.5358 ( F ) 0.8440 best 0.9455 0.6823 0.9639 \ufb01t 0.2894 -0.5594 ( F ) 0.6076 unreasonable -0.2441 -0.8421", "entities": []}, {"text": "0.5275", "entities": []}, {"text": "( F ) boreddddd -0.1137 -0.7142 0.4843", "entities": []}, {"text": "( F ) sickkkk -0.3892 -0.7692 0.1323 ( F ) overplayed -0.1390 0.5000 ( F ) 0.8448 ( F ) Table 7 : Sentiment Lexicon Analysis , where score with ( F)means falsely predicted polarity or strength .", "entities": []}, {"text": "t score of some representative words learned by different methods .", "entities": []}, {"text": "The positive scores are supposed to be : best > better > well .", "entities": []}, {"text": "HSSWE captures such comparative sentiment strength but PMI - SO does not .", "entities": []}, {"text": "We further observe that in many cases where the results of PMI - SO and Doc - Sup are inconsistent ( e.g. , Doc - Sup incorrectly predicts \u201c unreasonable \u201d , \u201c boreddddd \u201d and\u201csickkk \u201d as positive words , but PMI - SO predicts them correctly ; PMI - SO incorrectly predicts \u201c \ufb01t \u201d but Doc - Sup predicts it correctly . ) , HSSWE often yield the correct results .", "entities": []}, {"text": "It shows the advantages of hierarchical sentiment supervision .", "entities": []}, {"text": "HSSWE can also correct the sentiment prediction where both PMI - SO and Doc - Sup are inef\ufb01cient ( e.g. , \u201c overplayed \u201d ) .", "entities": []}, {"text": "5 Conclusion In this paper , we proposed to construct sentiment lexicons based on a sentiment - aware word representation learning approach .", "entities": [[19, 21, "TaskName", "representation learning"]]}, {"text": "In contrast to traditional methods normally learned based on only the document - level sentiment supervision .", "entities": []}, {"text": "We proposed word representation learning via hierarchical sentiment supervision , i.e. , under the supervi-509", "entities": [[3, 5, "TaskName", "representation learning"]]}, {"text": "sion at both word and document levels .", "entities": []}, {"text": "The wordlevel supervision can be provided based on either prede\ufb01ned sentiment lexicons or the learned PMISO based sentiment annotation of words .", "entities": []}, {"text": "A wide range of experiments were conducted on several benchmark sentiment classi\ufb01cation datasets .", "entities": []}, {"text": "The results indicate that our method is quite effective for sentiment - aware word representation , and the sentiment lexicon generated by our approach beats the state - of - the - art sentiment lexicon construction approaches .", "entities": []}, {"text": "Acknowledgements The work was supported by the Natural Science Foundation of China ( No . 61672288 ) , and the Natural Science Foundation of Jiangsu Province for Excellent Young Scholars ( No . BK20160085 ) .", "entities": []}, {"text": "References Yoshua Bengio , R \u00b4 ejean Ducharme , Pascal Vincent , and Christian Jauvin .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "A neural probabilistic language model .", "entities": [[1, 5, "MethodName", "neural probabilistic language model"]]}, {"text": "Journal of Machine Learning Research , 3(Feb):1137\u20131155 .", "entities": []}, {"text": "John Duchi , Elad Hazan , and Yoram Singer . 2011 .", "entities": []}, {"text": "Adaptive subgradient methods for online learning and stochastic optimization .", "entities": [[4, 6, "TaskName", "online learning"], [7, 9, "TaskName", "stochastic optimization"]]}, {"text": "Journal of Machine Learning Research , 12(Jul):2121\u20132159 .", "entities": []}, {"text": "Alec Go , Richa Bhayani , and Lei Huang .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Twitter sentiment classi\ufb01cation using distant supervision .", "entities": []}, {"text": "CS224N Project Report , Stanford , 1(2009):12 .", "entities": []}, {"text": "William L. Hamilton , Kevin Clark , Jure Leskovec , and Dan Jurafsky .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Inducing domain - speci\ufb01c sentiment lexicons from unlabeled corpora .", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 595\u2013605 .", "entities": []}, {"text": "Vasileios Hatzivassiloglou and Kathleen R McKeown .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Predicting the semantic orientation of adjectives .", "entities": []}, {"text": "In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics , pages 174\u2013181 .", "entities": []}, {"text": "Bas Heerschop , Alexander Hogenboom , and Flavius Frasincar .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Sentiment lexicon creation from lexical resources .", "entities": []}, {"text": "In International Conference on Business Information Systems , pages 185\u2013196 .", "entities": []}, {"text": "Minqing Hu and Bing Liu .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Mining and summarizing customer reviews .", "entities": []}, {"text": "In Proceedings of the Tenth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 168\u2013177 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Jaap Kamps , Maarten Marx , Robert J Mokken , Maarten De Rijke , et al . 2004 .", "entities": []}, {"text": "Using wordnetto measure semantic orientations of adjectives .", "entities": []}, {"text": "In Proceedings of the Fourth International Conference on Language Resources and Evaluation , volume 4 , pages 1115\u20131118 .", "entities": []}, {"text": "Soo - Min Kim and Eduard Hovy .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Determining the sentiment of opinions .", "entities": []}, {"text": "In Proceedings of the 20th international conference on Computational Linguistics , page 1367 .", "entities": []}, {"text": "Svetlana Kiritchenko , Xiaodan Zhu , and Saif M Mohammad . 2014 .", "entities": []}, {"text": "Sentiment analysis of short informal texts .", "entities": [[0, 2, "TaskName", "Sentiment analysis"]]}, {"text": "Journal of Arti\ufb01cial Intelligence Research , 50:723\u2013762 .", "entities": []}, {"text": "Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Ef\ufb01cient estimation of word representations in vector space .", "entities": []}, {"text": "Proceedings of Workshop at 1st International Conference on Learning Representations ( ICLR2013 ) .", "entities": []}, {"text": "Saif M. Mohammad , Svetlana Kiritchenko , and Xiaodan Zhu . 2013 .", "entities": []}, {"text": "Nrc - canada : Building the state - ofthe - art in sentiment analysis of tweets .", "entities": [[12, 14, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the seventh international workshop on Semantic Evaluation Exercises ( SemEval-2013 ) , pages 321\u2013327 .", "entities": []}, {"text": "Sara Rosenthal , Preslav Nakov , Svetlana Kiritchenko , Saif Mohammad , Alan Ritter , and Veselin Stoyanov . 2015 .", "entities": []}, {"text": "Semeval-2015 task 10 : Sentiment analysis in twitter .", "entities": [[4, 6, "TaskName", "Sentiment analysis"]]}, {"text": "In SemEval@ NAACL - HLT , pages 451\u2013463 .", "entities": []}, {"text": "Duyu Tang , Furu Wei , Bing Qin , Ming Zhou , and Ting Liu . 2014a .", "entities": []}, {"text": "Building large - scale twitter - speci\ufb01c sentiment lexicon : A representation learning approach .", "entities": [[11, 13, "TaskName", "representation learning"]]}, {"text": "In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , pages 172\u2013182 .", "entities": []}, {"text": "Duyu Tang , Furu Wei , Nan Yang , Ming Zhou , Ting Liu , and Bing Qin . 2014b .", "entities": []}, {"text": "Learning sentimentspeci\ufb01c word embedding for twitter sentiment classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , pages 1555\u20131565 .", "entities": []}, {"text": "Peter D Turney .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "Thumbs up or thumbs down ? : semantic orientation applied to unsupervised classi\ufb01cation of reviews .", "entities": []}, {"text": "In Proceedings of the 40th annual meeting on association for computational linguistics , pages 417\u2013424 .", "entities": []}, {"text": "Peter D Turney . 2008 .", "entities": []}, {"text": "The latent relation mapping engine : Algorithm and experiments .", "entities": []}, {"text": "Journal of Arti\ufb01cial Intelligence Research , 33:615\u2013655 .", "entities": []}, {"text": "Duy Tin V o and Yue Zhang .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Do nt count , predict !", "entities": []}, {"text": "an automatic approach to learning sentiment lexicons for short text .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , volume 2 , pages 219\u2013224 .", "entities": []}, {"text": "Ke Wang and Rui Xia . 2016 .", "entities": []}, {"text": "A survey on automatical construction methods of sentiment lexicons .", "entities": []}, {"text": "Acta Automatica Sinica , 42(4):495\u2013511.510", "entities": []}]