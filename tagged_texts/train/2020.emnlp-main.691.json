[{"text": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 8566\u20138579 , November 16\u201320 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics8566SeqMix : Augmenting Active Sequence Labeling via Sequence Mixup Rongzhi Zhang", "entities": [[12, 13, "MethodName", "Mixup"]]}, {"text": "Georgia Tech rongzhi.zhang@gatech.eduYue Yu Georgia Tech yueyu@gatech.eduChao Zhang", "entities": []}, {"text": "Georgia Tech chaozhang@gatech.edu", "entities": []}, {"text": "Abstract Active learning is an important technique for low - resource sequence labeling tasks .", "entities": [[1, 3, "TaskName", "Active learning"]]}, {"text": "However , current active sequence labeling methods use the queried samples alone in each iteration , which is an inef\ufb01cient way of leveraging human annotations .", "entities": []}, {"text": "We propose a simple but effective data augmentation method to improve label ef\ufb01ciency of active sequence labeling .", "entities": [[6, 8, "TaskName", "data augmentation"]]}, {"text": "Our method , SeqMix , simply augments the queried samples by generating extra labeled sequences in each iteration .", "entities": []}, {"text": "The key dif\ufb01culty is to generate plausible sequences along with token - level labels .", "entities": []}, {"text": "In SeqMix , we address this challenge by performing mixup for both sequences and token - level labels of the queried samples .", "entities": [[9, 10, "MethodName", "mixup"]]}, {"text": "Furthermore , we design a discriminator during sequence mixup , which judges whether the generated sequences are plausible or not .", "entities": [[8, 9, "MethodName", "mixup"]]}, {"text": "Our experiments on Named Entity Recognition and Event Detection tasks show that SeqMix can improve the standard active sequence labeling method by 2:27%\u20133:75 % in terms ofF1scores .", "entities": [[3, 6, "TaskName", "Named Entity Recognition"], [7, 9, "TaskName", "Event Detection"]]}, {"text": "The code and data for SeqMix can be found at https://github . com / rz - zhang / SeqMix .", "entities": []}, {"text": "1 Introduction Many NLP tasks can be formulated as sequence labeling problems , such as part - of - speech ( POS ) tagging ( Zheng et al . , 2013 ) , named entity recognition ( NER ) ( Lample et al . , 2016 ) , and event extraction ( Yang et al . , 2019 ) .", "entities": [[15, 18, "DatasetName", "part - of"], [33, 36, "TaskName", "named entity recognition"], [37, 38, "TaskName", "NER"], [49, 51, "TaskName", "event extraction"]]}, {"text": "Recently , neural sequential models ( Lample et al . , 2016 ; Akbik et al . , 2018 ; Vaswani et", "entities": []}, {"text": "al . , 2017 ) have shown strong performance for various sequence labeling task .", "entities": []}, {"text": "However , these deep neural models are label hungry \u2014 they require large amounts of annotated sequences to achieve strong performance .", "entities": []}, {"text": "Obtaining large amounts of annotated data can be too expensive for practical sequence labeling tasks , due to tokenlevel annotation efforts .", "entities": []}, {"text": "Active learning is an important technique for sequence labeling in low - resource settings .", "entities": [[0, 2, "TaskName", "Active learning"]]}, {"text": "Active sequence labeling is an iterative process .", "entities": []}, {"text": "In each iteration , a \ufb01xed number of unlabeled sequences are selected by a query policy for annotation and then model updating , in hope of maximally improving model performance .", "entities": []}, {"text": "For example , Tomanek et al . ( 2007 ) ; Shen et al .", "entities": []}, {"text": "( 2017 ) select query samples based on data uncertainties ; Hazra et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) compute model - aware similarity to eliminate redundant examples and improve the diversity of query samples ; and Fang et al .", "entities": []}, {"text": "( 2017 ) ; Liu et al .", "entities": []}, {"text": "( 2018 ) use reinforcement learning to learn query policies .", "entities": []}, {"text": "However , existing methods for active sequence labeling all use the queried samples alone in each iteration .", "entities": []}, {"text": "We argue that the queried samples provide limited data diversity , and using them alone for model updating is inef\ufb01cient in terms of leveraging human annotation efforts .", "entities": []}, {"text": "We study the problem of enhancing active sequence labeling via data augmentation .", "entities": [[10, 12, "TaskName", "data augmentation"]]}, {"text": "We aim to generate augmented labeled sequences for the queried samples in each iteration , thereby introducing more data diversity and improve model generalization .", "entities": []}, {"text": "However , data augmentation for active sequence labeling is challenging , because we need to generate sentences and token - level labels jointly .", "entities": [[2, 4, "TaskName", "data augmentation"]]}, {"text": "Prevailing generative models ( Zhang et al . , 2016 ; Bowman et al . , 2016 ) are inapplicable because they can only generate word sequences without labels .", "entities": []}, {"text": "It is also infeasible to apply heuristic data augmentation methods such as context - based words substitution ( Kobayashi , 2018 ) , synonym replacement , random insertion , swap , and deletion ( Wei and Zou , 2019 ) , paraphrasing ( Cho et al . , 2019 ) or back translation ( Xie et al . , 2019 ) , because label composition is complex for sequence labeling .", "entities": [[7, 9, "TaskName", "data augmentation"]]}, {"text": "Directly using these techniques to manipulate tokens may inject incorrectly labeled sequences into training data and harm model performance .", "entities": []}, {"text": "8567We propose SeqMix , a data augmentation method for generating sub - sequences along with their labels based on mixup ( Zhang et al . , 2018 ) .", "entities": [[5, 7, "TaskName", "data augmentation"], [19, 20, "MethodName", "mixup"]]}, {"text": "Under the active sequence labeling framework , SeqMix is capable of generating plausible pseudo labeled sequences for the queried samples in each iteration .", "entities": []}, {"text": "This is enabled by two key techniques in SeqMix : ( 1 ) First , in each iteration , it searches for pairs of eligible sequences and mixes them both in the feature space and the label space .", "entities": []}, {"text": "( 2 ) Second , it has a discriminator to judge if the generated sequence is plausible or not .", "entities": []}, {"text": "The discriminator is designed to compute the perplexity scores for all the generated candidate sequences and select the low - perplexity sequences as plausible ones .", "entities": [[7, 8, "MetricName", "perplexity"], [20, 21, "MetricName", "perplexity"]]}, {"text": "We show that SeqMix consistently outperforms standard active sequence labeling baselines under different data usage percentiles with experiments on Named Entity Recognition and Event Detection tasks .", "entities": [[19, 22, "TaskName", "Named Entity Recognition"], [23, 25, "TaskName", "Event Detection"]]}, {"text": "On average , it achieves 2:95%;2:27%;3:75%F1improvements on the CoNLL-2003 , ACE05 and WebPage datasets .", "entities": [[8, 9, "DatasetName", "CoNLL-2003"]]}, {"text": "The advantage of SeqMix is especially prominent in low - resource scenarios , achieving 12:06%;8:86%;16:49%F1improvements to the original active learning approach on the above three datasets .", "entities": [[18, 20, "TaskName", "active learning"]]}, {"text": "Our results also verify the proposed mixup strategies and the discriminator are vital to the performance of SeqMix .", "entities": [[6, 7, "MethodName", "mixup"]]}, {"text": "2 Preliminaries 2.1 Problem De\ufb01nition Many NLP problems can be formulated as sequence labeling problems .", "entities": []}, {"text": "Given an input sequence , the task is to annotate it with token - level labels .", "entities": []}, {"text": "The labels often consist of a position pre\ufb01x provided by a labeling schema and a type indicator provided by the speci\ufb01c task .", "entities": []}, {"text": "For example , in the named entity recognition task , we can adopt the BIO ( Beginning , Inside , Outside ) tagging scheme ( M ` arquez et al . , 2005 ) to assign labels for each token : the \ufb01rst token of an entity mention with type Xis labeled as B - X , the tokens inside that mention are labeled as I - X and the non - entity tokens are labeled as O. Consider a large unlabeled corpus U , traditional active learning starts from a small annotated seed setL , and utilizes a query function   ( U;K ;", "entities": [[5, 8, "TaskName", "named entity recognition"], [86, 88, "TaskName", "active learning"]]}, {"text": "( \u0001))to obtainKmost informative unlabeled samplesX = fx1 ; : : : ; xKgalong with their labelsY = fy1;\u0001\u0001\u0001;yKg , where", "entities": []}, {"text": "( \u0001)is the querypolicy .", "entities": []}, {"text": "Then , we remove Xfrom the unlabeled dataUand repeat the above procedure until the satisfactory performance achieved or the annotation capacity reached .", "entities": []}, {"text": "In SeqMix , we aim to further exploit the annotated sethX;Yito generate augmented data hX\u0003;Y\u0003i .", "entities": []}, {"text": "Then the labeled dataset is expanded asL = L[hX;Yi[hX\u0003;Y\u0003i .", "entities": []}, {"text": "Formally , we de\ufb01ne our task as : ( 1 ) construct a generator \u001e ( \u0001 ) to implement sequence and label generation based on the actively sampled data Xand its labelY , ( 2 ) set a discriminator d(\u0001)to yield the \ufb01ltered generation , then ( 3 ) augment the labeled set as L = L[hX;Yi[d ( \u001e ( X;Y ) ) .", "entities": []}, {"text": "2.2 Active Learning for Sequence Labeling Active sequence labeling selects Kmost informative instances   ( \u0001;K ;", "entities": [[1, 3, "TaskName", "Active Learning"]]}, {"text": "( \u0001))in each iteration , with the hope of maximally improving model performance with a \ufb01xed labeled budget .", "entities": []}, {"text": "With the input sequence xof lengthT , we denote the model output asf(\u0001jx;\u0012 ) .", "entities": []}, {"text": "Our method is generic to any query policies", "entities": []}, {"text": "( \u0001 ) .", "entities": []}, {"text": "Below , we introduce several representative policies .", "entities": []}, {"text": "Least Con\ufb01dence ( LC ) Culotta and McCallum ( 2005 ) measure the uncertainty of sequence models by the most likely predicted sequence .", "entities": []}, {"text": "For a CRF model ( Lafferty et al . , 2001 ) , we calculate", "entities": [[2, 3, "MethodName", "CRF"]]}, {"text": "with the predicted sequential label y\u0003as", "entities": []}, {"text": "LC(x ) = 1\u0000max y\u0003(P(y\u0003jx;\u0012 ) ; ( 1 ) where y\u0003is the Viterbi parse .", "entities": []}, {"text": "For BERT ( Devlin et al . , 2019 ) with a token classi\ufb01cation head , we adopt a variant of the least con\ufb01dence measure :", "entities": [[1, 2, "MethodName", "BERT"]]}, {"text": "LC\u2019(x )", "entities": []}, {"text": "= TX t=1(1\u0000max ytP(ytjx;\u0012));(2 )", "entities": []}, {"text": "whereP(ytjx;\u0012 )", "entities": []}, {"text": "= softmax ( f(ytjx;\u0012 ) ) .", "entities": [[1, 2, "MethodName", "softmax"]]}, {"text": "Normalized Token Entropy ( NTE ) Another uncertainty measure for the query policy is normalized entropy ( Settles and Craven , 2008 ) , de\ufb01ned as :", "entities": []}, {"text": "TE(x )", "entities": []}, {"text": "= \u00001 TTX t=1MX m=1Pm(ytjx;\u0012 ) logPm(ytjx;\u0012 ) ; ( 3 ) wherePm(ytjx;\u0012 )", "entities": []}, {"text": "= [ softmax ( f(ytjx;\u0012))]m .", "entities": [[2, 3, "MethodName", "softmax"]]}, {"text": "8568Disagreement Sampling Query - by - committee ( QBC ) ( Seung et al . , 1992 ) , is another approach for specifying the policy , where the unlabeled data can be sampled by the disagreement of the base models .", "entities": []}, {"text": "The disagreement can be de\ufb01ned in several ways , here we take the vote entropy proposed by ( Dagan and Engelson , 1995 ) .", "entities": []}, {"text": "Given a committee consist ofCmodels , the vote entropy for input xis :", "entities": []}, {"text": "VE(x )", "entities": []}, {"text": "= \u00001 TTX t=1MX m=1Vm(yt ) ClogVm(yt ) C ; ( 4 ) whereVm(yt)is the number of models that predict thet - th token xtas the labelm .", "entities": []}, {"text": "3", "entities": []}, {"text": "The SeqMix Method 3.1 Overview Given a corpus for sequence labeling , we assume the dataset contains a small labeled set Land a large unlabeled set Uinitially .", "entities": []}, {"text": "We start from augmenting the seed set Lwith SeqMix .", "entities": []}, {"text": "First , we adopt a pairing function \u0010(\u0001)to", "entities": []}, {"text": "\ufb01nd paired samples by traversingL. Next , we generate mixed - labeled sequences via latent space linear interpolation with one of the approaches mentioned in Section 3.2 .", "entities": []}, {"text": "To ensure the semantic quality of the generated sequences , we use a discriminator d(\u0001)to measure the perplexity of them and \ufb01lter low - quality sequences out .", "entities": [[17, 18, "MetricName", "perplexity"]]}, {"text": "Then we generate the extra labeled sequencesL\u0003=SeqMix ( L ; \u000b ; \u0010(\u0001);d(\u0001))and get the augmented training set L = L[L\u0003.", "entities": []}, {"text": "The sequence labeling model \u0012is initialized on this augmented training setL.", "entities": []}, {"text": "After that , the iterative active learning procedure begins .", "entities": [[5, 7, "TaskName", "active learning"]]}, {"text": "In each iteration , we actively select instances from Uwith a query policy", "entities": []}, {"text": "( \u0001 ) ( Section 2.2 ) to obtain the top KsamplesX=   ( U;K ;", "entities": []}, {"text": "( \u0001 ) ) .", "entities": []}, {"text": "The newly selected samples will be labeled withY , and the batch of samples hX;Yi will be used for SeqMix .", "entities": []}, {"text": "Again , we generate L\u0003=SeqMix ( hX;Yi ; \u000b ; \u0010(\u0001);d(\u0001))and expand the training set as L = L[L\u0003.", "entities": []}, {"text": "Then we train the model\u0012on the newly augmented set L.", "entities": []}, {"text": "The iterative active learning procedure terminates when a \ufb01xed number of iterations are reached .", "entities": [[2, 4, "TaskName", "active learning"], [9, 12, "HyperparameterName", "number of iterations"]]}, {"text": "We summarize the above procedure in Algorithm 1 . 3.2 Sequence Mixup in the Embedding Space Mixup ( Zhang et al . , 2018 ) is a data augmentation method that implements linear interpolation in the input space .", "entities": [[11, 12, "MethodName", "Mixup"], [16, 17, "MethodName", "Mixup"], [27, 29, "TaskName", "data augmentation"]]}, {"text": "Given two input samples xi;xjalongAlgorithm 1", "entities": []}, {"text": "The procedure of active sequence labeling augmentation via SeqMix Input : Labeled seed set L ; Unlabeled setU ; Query function   ( \u0001;K ;", "entities": []}, {"text": "( \u0001 ) ) ; The sequence labeling model\u0012 ; Beta distribution parameter \u000b ; Pairing function\u0010(\u0001 ) ; Discriminator function d(\u0001 ) .", "entities": []}, {"text": "// seed set augmentation L\u0003=SeqMix ( L ; \u000b ; \u0010(\u0001);d(\u0001 ) )", "entities": []}, {"text": "L = L[L\u0003 // model initialization \u0012= train ( \u0012;L ) //", "entities": []}, {"text": "active learning iterations with augmentation forround inactive learning rounds do X= ( U;K ;", "entities": [[0, 2, "TaskName", "active learning"]]}, {"text": "( \u0001 ) )", "entities": []}, {"text": "U = U\u0000X AnnotateXto gethX;Yi L\u0003=SeqMix ( hX;Yi ; \u000b ; \u0010(\u0001);d(\u0001 ) )", "entities": []}, {"text": "L = L[hX;Yi[L\u0003 \u0012= train ( \u0012;L ) end Output : The sequence model trained with active data augmentation : \u0012 with the labels yi;yj , the mixing process is : ~x=\u0015xi+ ( 1\u0000\u0015)xj ; ( 5 ) ~y=\u0015yi+ ( 1\u0000\u0015)yj ; ( 6 ) where\u0015\u0018Beta ( \u000b ; \u000b ) is the mixing coef\ufb01cient .", "entities": [[17, 19, "TaskName", "data augmentation"]]}, {"text": "Through linear combinations on the input level of paired examples and their labels , Mixup regularizes the model to present linear behavior among the training data .", "entities": [[14, 15, "MethodName", "Mixup"]]}, {"text": "Mixup is not directly applicable to generate interpolated samples for text data , because the input space is discrete .", "entities": [[0, 1, "MethodName", "Mixup"]]}, {"text": "To overcome this , SeqMix performs token - level interpolation in the embedding space and selects a token closest to the interpolated embedding .", "entities": []}, {"text": "Speci\ufb01cally , SeqMix constructs a table of tokens Wand their corresponding contextual embeddings E1 .", "entities": []}, {"text": "Given two sequences xi = fw1 i;\u0001\u0001\u0001;wT igandxj = fw1 j;\u0001\u0001\u0001;wT jg with their embedding representations exi= fe1 i;\u0001\u0001\u0001;eT igandexj = fe1 j;\u0001\u0001\u0001;eT jg , thet - th mixed token is the token whose embedding etis closest to the mixed embedding : et= arg min e2E", "entities": [[45, 46, "DatasetName", "e2E"]]}, {"text": "", "entities": []}, {"text": "e\u0000(\u0015et i+ ( 1\u0000\u0015)et j )", "entities": []}, {"text": "", "entities": []}, {"text": "2:(7 ) 1The construction of fW;Egare discussed in Appendix .", "entities": []}, {"text": "8569To get the corresponding wt , we can query the tablefW;Egusing et .", "entities": []}, {"text": "The label generation is straightforward .", "entities": []}, {"text": "For two label sequences yi= fy1", "entities": []}, {"text": "i;\u0001\u0001\u0001;yT igandyj = fy1 j;\u0001\u0001\u0001;yT jg , we get the t - th mixed label as : yt=\u0015yt i+ ( 1\u0000\u0015)yt j ; ( 8) where yt iandyt jare one - hot encoded labels .", "entities": []}, {"text": "Along with the above sequence mixup procedure , we also introduce a pairing strategy that selects sequences for mixup .", "entities": [[5, 6, "MethodName", "mixup"], [18, 19, "MethodName", "mixup"]]}, {"text": "The reason is that , in many sequence labeling tasks , the labels of interest are scarce .", "entities": []}, {"text": "For example , in the NER and event detection tasks , the \u201c O \u201d label is dominant in the corpus , which do not refer to any entities or events of interest .", "entities": [[5, 6, "TaskName", "NER"], [7, 9, "TaskName", "event detection"]]}, {"text": "We thus de\ufb01ne the labels of interest as valid labels , e.g. , the non-\u201cO \u201d labels in NER and event detection , and design a sequence pairing function to select more informative parent sequences for mixup .", "entities": [[18, 19, "TaskName", "NER"], [20, 22, "TaskName", "event detection"], [36, 37, "MethodName", "mixup"]]}, {"text": "Speci\ufb01cally , the sequence pairing function \u0010(\u0001)is designed according to valid label density .", "entities": []}, {"text": "For a sequence , its valid label density is de\ufb01ned as\u0011=n s , wherenis the number of valid labels andsis the length of the sub - sequence .", "entities": []}, {"text": "We set a threshold\u00110for\u0010(\u0001 ) , and the sequence will be considered as an eligible candidate for mixup only when\u0011\u0015\u00110 .", "entities": [[17, 18, "MethodName", "mixup"]]}, {"text": "Based on the above token - level mixup procedure and the sequence pairing function , we propose three different strategies for generating interpolated labeled sequences .", "entities": [[7, 8, "MethodName", "mixup"]]}, {"text": "These strategies are shown in Figure 1 and described below : Whole - sequence mixup As the name suggests , whole - sequence mixup ( Figure 1(a ) ) performs sequence mixing at the whole - sequence level .", "entities": [[14, 15, "MethodName", "mixup"], [23, 24, "MethodName", "mixup"]]}, {"text": "Given two sequenceshxi;yii;hxj;yji2L , they must share the same length without counting padding words .", "entities": []}, {"text": "Besides , the paring function \u0010(\u0001)requires that both the two sequences satisfy \u0011\u0015\u00110 .", "entities": []}, {"text": "Then we perform mixup at all token positions , by employing Equation 7 to generate mixed tokens and Equation 8 to generate mixed labels ( note that the mixed labels are soft labels ) .", "entities": [[3, 4, "MethodName", "mixup"]]}, {"text": "Sub - sequence mixup One drawback of the whole - sequence mixup is that it indiscriminately mixes over all tokens , which may include incompatible subsequences and generate implausible sequences .", "entities": [[3, 4, "MethodName", "mixup"], [11, 12, "MethodName", "mixup"]]}, {"text": "To tackle this , we consider sub - sequence mixup ( Figure 1(b ) ) to mix sub - sequences of the parent sequences .", "entities": [[9, 10, "MethodName", "mixup"]]}, {"text": "It scans the original samples with a window of \ufb01xed - length sto look forAlgorithm 2", "entities": []}, {"text": "The generation procedure of SeqMix Input : Labeled setL = hX;Yi ; Beta distribution parameter \u000b ; Pairing function \u0010(\u0001 ) ; Discriminator functiond(\u0001 ) ; Number of expected generation N. forhxi;yii;hxj;yji;(i6 = j)inLdo if\u0010(hxi;yii;hxj;yji)then \u0015\u0018Beta ( \u000b ; \u000b ) //mixup", "entities": []}, {"text": "the target sub - sequences fort= 1;\u0001\u0001\u0001;Tdo Calculate etby Eq .", "entities": []}, {"text": "( 7 ) ; Get corresponding token wtforet ; Calculate ytby Eq .", "entities": []}, {"text": "( 8) . end ~xsub = fw1;\u0001\u0001\u0001;wTg ~ysub = fy1;\u0001\u0001\u0001;yTg //replace the original sequences forkinfi;jgdo ~xk = xk\u0000xksub+~xsub ~yk = yk\u0000yksub+~ysub ifd(~xk)then L\u0003=L\u0003[h ~ xk;~yki end ifjL\u0003j\u0015Nthen break end end end end Output : Generated sequences and labels L\u0003 paired sub - sequences .", "entities": []}, {"text": "Denote the sub - sequences ofhxi;yii;hxj;yjiasXisub=\b x1 isub ; : : : ; xs isub \t  , Xjsub = n x1 jsub ; : : : ; xs jsubo .", "entities": []}, {"text": "If9xisub2Xisub , xjsub2Xjsub , such that their \u0011\u0015\u00110 , we have\u0010(hxi;yii;hxj;yji ) = True .", "entities": []}, {"text": "Then the subsequences xisubandxjsubare mixed as Figure 1(b ) .", "entities": []}, {"text": "The mixed sub - sequence and labels will replace the original parts of the parent samples , and the other parts of the parent samples remain unchanged .", "entities": []}, {"text": "In this way , sub - sequence mixup is expected to keep the syntax structure of the original sequence , while providing data diversity .", "entities": [[7, 8, "MethodName", "mixup"]]}, {"text": "Label - constrained sub - sequence mixup can be considered as a special case of sub - sequence mixup , where the constraints inherit sub - sequence mixup , and further require that the sub - sequence labels are consistent .", "entities": [[6, 7, "MethodName", "mixup"], [18, 19, "MethodName", "mixup"], [27, 28, "MethodName", "mixup"]]}, {"text": "As Figure 1(c ) shows , after mixing such paired samples , the generation will just update the tokens of the sub - sequences while keeping the labels the same as before .", "entities": []}, {"text": "Hence , this", "entities": []}, {"text": "8570 \ud835\udc52\ud835\udc561\ud835\udc66\ud835\udc561 \ud835\udc52\ud835\udc562\ud835\udc66\ud835\udc562 \ud835\udc52\ud835\udc563\ud835\udc66\ud835\udc563 \ud835\udc52\ud835\udc564\ud835\udc52\ud835\udc565\ud835\udc66\ud835\udc564\ud835\udc66\ud835\udc565 \ud835\udc52\ud835\udc571\ud835\udc52\ud835\udc572\ud835\udc52\ud835\udc573\ud835\udc52\ud835\udc574\ud835\udc52\ud835\udc575\ud835\udc66\ud835\udc571\ud835\udc66\ud835\udc572\ud835\udc66\ud835\udc573\ud835\udc66\ud835\udc574\ud835\udc66\ud835\udc575Input Sequence \ud835\udc8a Input Sequence \ud835\udc8b Generated   Sequence \ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663 \ud835\udc524\ud835\udc525\ud835\udc664\ud835\udc665 raw mixed   embeddingembeddi ng in \u2130embeddings   to be mixedexample labels   to be mixed example mixed labelembedding   in sequence \ud835\udc56embedding   in sequence \ud835\udc57none named   entity named entity mixed labelmixed   embedding Mixup in the Embedding Space Mixup in the Label Space(a )", "entities": [[52, 53, "MethodName", "Mixup"], [57, 58, "MethodName", "Mixup"]]}, {"text": "Whole sequence mixup \ud835\udc52\ud835\udc561\ud835\udc66\ud835\udc561 \ud835\udc52\ud835\udc562\ud835\udc66\ud835\udc562 \ud835\udc52\ud835\udc563\ud835\udc66\ud835\udc563 \ud835\udc52\ud835\udc564\ud835\udc52\ud835\udc565\ud835\udc66\ud835\udc564\ud835\udc66\ud835\udc565 \ud835\udc52\ud835\udc571\ud835\udc52\ud835\udc572\ud835\udc52\ud835\udc573\ud835\udc52\ud835\udc574\ud835\udc52\ud835\udc575\ud835\udc66\ud835\udc571\ud835\udc66\ud835\udc572\ud835\udc66\ud835\udc573\ud835\udc66\ud835\udc574 \ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663", "entities": [[2, 3, "MethodName", "mixup"]]}, {"text": "\ud835\udc52\ud835\udc571\ud835\udc66\ud835\udc571 \ud835\udc52\ud835\udc572\ud835\udc66\ud835\udc572\ud835\udc66\ud835\udc575 Generated Sequence \ud835\udc8a Generated Sequence \ud835\udc8b\ud835\udc52\ud835\udc564\ud835\udc52\ud835\udc565\ud835\udc66\ud835\udc564\ud835\udc66\ud835\udc565 \ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663\ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663Input Sequence \ud835\udc8a Input Sequence \ud835\udc8b Mixup in the Embedding Space Mixup in the Label Space ( b ) Sub - sequence mixup \ud835\udc52\ud835\udc561\ud835\udc66\ud835\udc561 \ud835\udc52\ud835\udc562\ud835\udc66\ud835\udc562 \ud835\udc52\ud835\udc563\ud835\udc66\ud835\udc563 \ud835\udc52\ud835\udc564\ud835\udc52\ud835\udc565\ud835\udc66\ud835\udc564\ud835\udc66\ud835\udc565 \ud835\udc52\ud835\udc571\ud835\udc52\ud835\udc572\ud835\udc52\ud835\udc573\ud835\udc52\ud835\udc574\ud835\udc52\ud835\udc575\ud835\udc66\ud835\udc571\ud835\udc66\ud835\udc572\ud835\udc66\ud835\udc573\ud835\udc66\ud835\udc574 \ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663 \ud835\udc52\ud835\udc571\ud835\udc66\ud835\udc571 \ud835\udc52\ud835\udc572\ud835\udc66\ud835\udc572\ud835\udc66\ud835\udc575 Generated Sequence \ud835\udc8a Generated Sequence \ud835\udc8b\ud835\udc52\ud835\udc564\ud835\udc52\ud835\udc565\ud835\udc66\ud835\udc564\ud835\udc66\ud835\udc565 \ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663\ud835\udc521\ud835\udc522\ud835\udc523\ud835\udc661\ud835\udc662\ud835\udc663Input Sequence \ud835\udc8a Input Sequence \ud835\udc8b Mixup in the Embedding Space Mixup in the Label Space ( c ) Label - constrained sub - sequence mixup Figure 1 : Illustration of the three variants of SeqMix .", "entities": [[14, 15, "MethodName", "Mixup"], [19, 20, "MethodName", "Mixup"], [30, 31, "MethodName", "mixup"], [51, 52, "MethodName", "Mixup"], [56, 57, "MethodName", "Mixup"], [70, 71, "MethodName", "mixup"]]}, {"text": "We use s= 5;\u00110=3 5for whole - sequence mixup and s= 3;\u00110=2 3for sub - sequence mixup and label - constrained sub - sequence mixup .", "entities": [[8, 9, "MethodName", "mixup"], [16, 17, "MethodName", "mixup"], [24, 25, "MethodName", "mixup"]]}, {"text": "The solid red frames indicate paired sequences or sub - sequences , and the red dotted frames indicate generated sequence or sub - sequence .", "entities": []}, {"text": "In the original sequences , the parts not included in the solid red frames will be unchanged in the generated sequences .", "entities": []}, {"text": "For the mixup in the embedding space , we take the embedding in Ewhich is closest to the raw mixed embedding as the generated embedding .", "entities": [[2, 3, "MethodName", "mixup"]]}, {"text": "For the mixup in the label space , the mixed label can be used as the pseudo label .", "entities": [[2, 3, "MethodName", "mixup"]]}, {"text": "version is called label - constrained sub - sequence mixup .", "entities": [[9, 10, "MethodName", "mixup"]]}, {"text": "Comparing the three variants , label - constrained sub - sequence mixup gives the most restrictions to pairing parent samples , sub - sequence mixup sets the sub - sequence - level pattern , while wholesequence mixup just requires \u0011\u0015\u00110for the sequences with the same length .", "entities": [[11, 12, "MethodName", "mixup"], [24, 25, "MethodName", "mixup"], [36, 37, "MethodName", "mixup"]]}, {"text": "3.3 Scoring and Selecting Plausible Sequences During sequence mixup , the mixing coef\ufb01cient \u0015 determines the strength of interpolation .", "entities": [[8, 9, "MethodName", "mixup"]]}, {"text": "When \u0015 approximates 0 or 1 , the generated sequence will be similar to one of the parent sequences , while the \u0015around 0:5produces relatively diverse generation .", "entities": [[3, 4, "DatasetName", "0"]]}, {"text": "However , generating diverse sequences means lowquality sequences can be generated , which can provide noisy contextual information and hurt model performance .", "entities": []}, {"text": "To maintain the quality of mixed sequences , we set a discriminator to score the perplexity of the sequences .", "entities": [[15, 16, "MetricName", "perplexity"]]}, {"text": "The \ufb01nal generated sequences will consist of only the sequences that pass the sequence quality screening .", "entities": []}, {"text": "For the screening , we utilize a language model GPT-2 ( Radford et al . , 2019 ) to score sequence xby computing its perplexity : Perplexity ( x ) = 2\u00001 TPT i=1log p(w i ) ; ( 9 ) whereTis the number of tokens before padding , wiis thei - thtoken of sequence x.", "entities": [[9, 10, "MethodName", "GPT-2"], [24, 25, "MetricName", "perplexity"], [26, 27, "MetricName", "Perplexity"]]}, {"text": "Based on the perplexity and a score range [ s1;s2 ] , the discriminatorcan give judgment for sequence x : d(x ) = 1fs1\u0014Perplexity ( x)\u0014s2g:(10 )", "entities": [[3, 4, "MetricName", "perplexity"]]}, {"text": "The lower the perplexity score , the more natural the sequence .", "entities": [[3, 4, "MetricName", "perplexity"]]}, {"text": "However , the discriminator should also consider the regularization effectiveness and the generation capacity .", "entities": []}, {"text": "Hence , a blind low perplexity setting is undesirable .", "entities": [[5, 6, "MetricName", "perplexity"]]}, {"text": "The overall sequence mixup and selection procedure is illustrated in Algorithm 2 . 4 Experiments 4.1 Experiment Setup Datasets .", "entities": [[3, 4, "MethodName", "mixup"]]}, {"text": "We conduct experiments on three sequence labeling datasets for the named entity recognition ( NER ) and event detection tasks .", "entities": [[10, 13, "TaskName", "named entity recognition"], [14, 15, "TaskName", "NER"], [17, 19, "TaskName", "event detection"]]}, {"text": "( 1)CoNLL-03 ( Tjong Kim Sang and De Meulder , 2003 ) is a corpus for NER task .", "entities": [[16, 17, "TaskName", "NER"]]}, {"text": "It provides four named entity types : persons , locations , organizations , and miscellaneous.2 ( 2)ACE05 is a corpus for event detection .", "entities": [[21, 23, "TaskName", "event detection"]]}, {"text": "It provides 8 event types and 33 subtypes .", "entities": []}, {"text": "We study the event trigger detection problem , which aims to identify trigger tokens in a sentence .", "entities": []}, {"text": "( 3)Webpage ( Ratinov and Roth , 2009 ) is a NER corpus with 20 webpages related to computer science conference and academic websites .", "entities": [[11, 12, "TaskName", "NER"]]}, {"text": "It inherits the entity types from CoNLL-03 .", "entities": []}, {"text": "Data Split .", "entities": []}, {"text": "To investigate low - resource sequence labeling , we randomly take 700 labeled sentences 2We take the English version as our target corpus .", "entities": []}, {"text": "8571from the original CoNLL-03 dataset as the training set .", "entities": []}, {"text": "For ACE05 and WebPage dataset , the annotation is sparse , so we conduct experiments on their original dataset without further slicing .", "entities": []}, {"text": "We set 6 data usage percentiles for the training set in each corpus .", "entities": []}, {"text": "The sequence model is initialed on a small seed set , then it performs \ufb01ve iterates of active learning .", "entities": [[17, 19, "TaskName", "active learning"]]}, {"text": "For the query policy , we use random sampling and the three active learning policies mentioned in Section 2.2 .", "entities": [[12, 14, "TaskName", "active learning"]]}, {"text": "The machine learning performance is evaluated by F1score for each data usage percentile .", "entities": []}, {"text": "Parameters .", "entities": []}, {"text": "We use BERT - base - cased for the NER task as the underlying model , and BERT - basemultilingual - cased for the event trigger detection task .", "entities": [[2, 3, "MethodName", "BERT"], [9, 10, "TaskName", "NER"], [17, 18, "MethodName", "BERT"]]}, {"text": "We set the max length as 128 to pad the varying - length sequences .", "entities": []}, {"text": "The learning rate of the underlying model is 5e-5 , and the batch size is 32 .", "entities": [[1, 3, "HyperparameterName", "learning rate"], [12, 14, "HyperparameterName", "batch size"]]}, {"text": "We train them for 10 epochs at each data usage percentile .", "entities": []}, {"text": "For the parameters of SeqMix , we set \u000b = 8 to sample\u0015from Beta ( \u000b ; \u000b ) .", "entities": []}, {"text": "We use the sub - sequence window length s = f5;5;4 g , the valid label density \u00110 = f0:6;0:2;0:5gfor CoNLL03 , ACE05 and Webpage , respectively .", "entities": [[20, 21, "DatasetName", "CoNLL03"]]}, {"text": "The augment rate is set as 0.2 , and the discriminator score range is set as ( 0;500 ) .", "entities": []}, {"text": "We also perform a detailed parameter study in Section 4.4 .", "entities": []}, {"text": "4.2 Results The main results are presented in Figure 2 , where we use NTE sampling as the default active learning policy .", "entities": [[19, 21, "TaskName", "active learning"]]}, {"text": "From the result , it is clear that our method achieves the best performance consistently at each data usage percentile for all three datasets .", "entities": []}, {"text": "The best SeqMix method ( sub - sequence mixup with NTE sampling ) outperforms the strongest active learning baselines by 2:95 % on CoNLL-03 , 2:27 % on ACE05 and 3:75 % on WebPage in terms of F1 score on average .", "entities": [[8, 9, "MethodName", "mixup"], [16, 18, "TaskName", "active learning"], [37, 39, "MetricName", "F1 score"]]}, {"text": "Moreover , the augmentation advantage is especially prominent for the seed set initialization stage where we only have a very limited number of labeled data .", "entities": []}, {"text": "Through the augmentation , we improve the model performance from 68:65 % to80:71 % , where the seed set is 200 labeled sequences and the augmentation provides extra 40 data points for CoNLL-03 .", "entities": []}, {"text": "The improvement is also signi\ufb01cant on ACE05 ( 40:65 % to49:51 % ) , and WebPage ( 55:18 % to71:67 % ) , which indicates that our SeqMix can largely resolve the label scarcity issue in low - resource scenarios .", "entities": []}, {"text": "We also perform statistical signi\ufb01cance tests forData Usage 200 300 400 500 600 700 ( 0,+1)81.15 82.32 82.74 83.66 83.79 85.05 ( 0 , 2000 ) 80.20 82.24 83.21 83.67 83.90 85.11 ( 0 , 1000 ) 80.13 81.86 83.58 84.22 84.81 85.16 ( 0 , 500 ) 80.71 82.82 84.05 85.28 86.04 86.24 Table 1 : The F1(%)of sub - sequence mixup with NTE sampling in different discriminator score range , evaluated on CoNLL-03 with 700 data .", "entities": [[22, 23, "DatasetName", "0"], [33, 34, "DatasetName", "0"], [44, 45, "DatasetName", "0"], [62, 63, "MethodName", "mixup"]]}, {"text": "the above results .", "entities": []}, {"text": "We use Wilcoxon Signed Rank Test ( Wilcoxon , 1992 ) , a non - parametric alternative to the paired t - test .", "entities": []}, {"text": "This signi\ufb01cance test \ufb01ts our task as F - score is generally assumed to be not normally distributed ( Dror et al . , 2018 ) , and nonparametric signi\ufb01cance tests should be used in such a case .", "entities": []}, {"text": "The results show that sub - sequence mixup and label - constrained sub - sequence mixup can provide a statistical signi\ufb01cance ( the con\ufb01dence level", "entities": [[7, 8, "MethodName", "mixup"], [15, 16, "MethodName", "mixup"]]}, {"text": "= 0:05and", "entities": []}, {"text": "the number of data points N= 6 ) for all the comparisons with active learning baselines on used datasets .", "entities": [[13, 15, "TaskName", "active learning"]]}, {"text": "The whole - sequence mixup passes the statistical signi\ufb01cance test with \u000b = 0:1 andN= 6on CoNLL-03 and WebPage , but fails on ACE05 .", "entities": [[4, 5, "MethodName", "mixup"]]}, {"text": "Among all the three SeqMix variants , subsequence mixup gives the overall best performance ( label - constrained sub - sequence mixup achieves very close performance with sub - sequence mixup on ACE05 dataset ) , but whole - sequence mixup does not yield a consistent improvement to the original active learning method .", "entities": [[8, 9, "MethodName", "mixup"], [21, 22, "MethodName", "mixup"], [30, 31, "MethodName", "mixup"], [40, 41, "MethodName", "mixup"], [50, 52, "TaskName", "active learning"]]}, {"text": "This is because the whole - sequence mixup may generate semantically poor new sequences .", "entities": [[7, 8, "MethodName", "mixup"]]}, {"text": "Instead , the sub - sequencelevel process reserves the original context information between the sub - sequence and the other parts of the whole sequence .", "entities": []}, {"text": "Meanwhile , the updated sub - sequences inherit the original local informativeness , and introduce linguistic diversity to enhance the model \u2019s generalization ability .", "entities": []}, {"text": "To justify that SeqMix can provide improvement to the active learning framework with various query policies , we employ different query policies with SeqMix augmentation under the same experiment setting as Figure 2(a ) .", "entities": [[9, 11, "TaskName", "active learning"]]}, {"text": "From Figure 3 , we \ufb01nd that there is a consistent performance improvement when employing SeqMix with different query policies .", "entities": []}, {"text": "As SeqMix achieves f2:46%;2:85%;2:94%g performance gain for random sampling , LC sampling and NTE sampling respectively .", "entities": []}, {"text": "4.3 Effect of Discriminator To verify the effectiveness of the discriminator , we conduct the ablation study on a subset of CoNLL-", "entities": []}, {"text": "8572 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Data Usage0.700.740.780.820.86F1 score ( a ) CoNLL-03 ( 700 labeled data ) 0.10.20.30.40.50.60.70.80.91.0 Data Usage0.400.450.500.550.600.650.70F1 score   ( b ) ACE05 ( 14k labeled data )", "entities": []}, {"text": "0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Data Usage0.550.600.650.700.75F1 score Random Sampling Least Confidence ( LC ) Normalized Token Entropy ( NTE ) Query - by - Committee Whole - sequence mixup sub - sequence mixup Label - constrained sub - sequence mixup ( c ) WebPage ( 385 labeled data )", "entities": [[33, 34, "MethodName", "mixup"], [37, 38, "MethodName", "mixup"], [44, 45, "MethodName", "mixup"]]}, {"text": "Figure 2 : The F1score of test set in terms of data usage on CoNLL-03 , ACE05 and WebPage .", "entities": []}, {"text": "Data Usage 200 300 400 500 600 700 Average r= 0:2 80.22 ( +0.76 ) 82.23(+0.43 ) 83.61 ( +0.61 ) 84.62 ( +0.53 ) 85.16 ( +0.10 ) 85.22 ( -0.11 ) + 0.39 r= 0:4 79.71 ( +0.25 ) 82.48(+0.68 ) 82.66 ( -0.34 ) 83.46 ( -0.63 ) 84.79 ( -0.27 ) 85.24 ( -0.09 ) - 0.07 r= 0:6 79.40 ( -0.06 ) 82.07(+0.27 ) 83.34 ( +0.34 ) 84.75 ( +0.66 ) 85.43 ( +0.37 ) 85.50 ( +0.17 ) + 0.29 r= 0:8 79.48 ( +0.02 ) 81.63(-0.17 ) 82.80 ( -0.20 ) 83.29 ( -0.80 ) 84.54 ( -0.52 ) 85.32 ( -0.01 ) - 0.28 r= 1:0 78.51 ( -0.95 ) 80.58(-1.22 ) 82.59 ( -0.41 ) 84.31 ( +0.22 ) 85.36 ( +0.30 ) 85.37 ( +0.04 ) - 0.34 Table 2 : The F1score with variant augment rate r.", "entities": []}, {"text": "The value in the parentheses is the difference with the average F1for corresponding data usage .", "entities": []}, {"text": "The last column presents the average F1difference for each learning rate r. 0.2 0.4 0.6 0.8 1.0 Data Usage0.650.700.750.800.85F1 score", "entities": [[9, 11, "HyperparameterName", "learning rate"]]}, {"text": "Random Least Confidence ( LC ) Normalized Token Entropy ( NTE ) Random + sub - sequence mixup LC + sub - sequence mixup NTE +", "entities": [[17, 18, "MethodName", "mixup"], [23, 24, "MethodName", "mixup"]]}, {"text": "sub - sequence mixup Figure 3 : The improvements to various active learning approaches provided by SeqMix .", "entities": [[3, 4, "MethodName", "mixup"], [11, 13, "TaskName", "active learning"]]}, {"text": "03 with 700 labeled sequences .", "entities": []}, {"text": "We use subsequence mixup with NTE sampling as the backbone and change the perplexity score range of the discriminator .", "entities": [[3, 4, "MethodName", "mixup"], [13, 14, "MetricName", "perplexity"]]}, {"text": "We start from the seed set with 200 labeled data , then actively query 100 data in each learning round and repeat 5 rounds in total .", "entities": []}, {"text": "The result in Table 1 demonstrates the discriminator provides a stable improvement for the last four data usage percentiles , and the discriminator with score range ( 0;500 ) can boost the model by 1:07%F1score , averaged by all the data usage percentiles .", "entities": []}, {"text": "The comparison between 3 different score thresholds demonstrates the lower the perplexity , the better the generation quality .", "entities": [[11, 12, "MetricName", "perplexity"]]}, {"text": "As a result , the \ufb01nalF1score becomes higher with the better generated tokens .", "entities": []}, {"text": "Actually , we can further narrow down the score range to get more performance improvement in return , but the too strict constraints will slow down the generation in practice and reduce the number of generated samples .", "entities": []}, {"text": "0.2 0.4 0.6 0.8 1.0 Data Usage0.780.800.820.840.86F1 score   s=4 , n=2 s=4 , n=3 s=5 , n=2 s=5 , n=3 s=5 , n=4 s=6 , n=3 s=6 , n=4(a)F1with several combination ofsandn 0.2 0.4 0.6 0.8 1.0 Data Usage0.780.800.820.840.86F1 score = 0.5 = 1 = 2 = 4 = 8 = 16 ( b)F1with different \u000b  Figure 4 : Parameter Search for SeqMix 4.4 Parameter Study", "entities": []}, {"text": "In this subsection , we study the effect of several key parameters .", "entities": []}, {"text": "Augment rate r. We vary the augment rate r= jL\u0003j", "entities": []}, {"text": "j ( U;K ;", "entities": []}, {"text": "( \u0001))jinf0:2;0:4;0:6;0:8;1:0gand keep the number of initial data usage same to investigate the effect of augment rate for data augmentation .", "entities": [[18, 20, "TaskName", "data augmentation"]]}, {"text": "Table 2 shows that r\u00140:6can provide betterF1improvement .", "entities": []}, {"text": "The model with r= 0:2 surpasses the model with r= 1:0by0:73 % , evaluated by the average F1score for all the data usage percentiles .", "entities": []}, {"text": "This result indicates that the model appreciates moderate augmentation more .", "entities": []}, {"text": "However , the performance variance based on the augment rate is not prominent compared to the improvement provided by SeqMix to the active learning framework .", "entities": [[22, 24, "TaskName", "active learning"]]}, {"text": "Valid tag density \u00110.We search the valid tag density\u00110as Section 3.2 de\ufb01ned by varying the sub - sequence window length sand the required number of valid tag nwithin the window .", "entities": []}, {"text": "The", "entities": []}, {"text": "8573results in Figure 4(a ) illustrate the combination ( s= 5;n= 3 ) outperforms other settings .", "entities": []}, {"text": "When sis too small , the window usually truncates the continuous clause , thus cutting off the local syntax or semantic information .", "entities": []}, {"text": "When sis too large , sub - sequence mixup tends to behave like wholesequence mixup , where the too long sub - sequence generation can hardly maintain the rationality of syntax and semantics as before .", "entities": [[8, 9, "MethodName", "mixup"], [14, 15, "MethodName", "mixup"]]}, {"text": "The high \u00110with long window length may result in an insuf\ufb01cient amount of eligible parent sequences .", "entities": []}, {"text": "Actually , even with a moderate augment rate \u000b = 0:2 , the combination ( s= 6;n= 5 ) has been unable to provide enough generation .", "entities": []}, {"text": "Mixing parameter \u000b .We show the performance with different \u000b in Figure 4(b ) .", "entities": []}, {"text": "The parameter \u000b  decides the distribution \u0015\u0018Beta ( \u000b ; \u000b ) , and the coef\ufb01cient\u0015directly involved the mixing of tokens and labels .", "entities": []}, {"text": "Among the values f0:5;1;2;4;8;16 g , we observed \u000b = 8presents the best performance .", "entities": []}, {"text": "It outperforms the second - best parameter setting 0:49 % by average .", "entities": []}, {"text": "From the perspective of Beta distribution , larger \u000b will make the sampled \u0015more concentrated around 0.5 , which assigns more balance weights to the parent samples to be mixed .", "entities": []}, {"text": "In this way , the interpolation produces encoded token with further distance to both the parent samples , thus introduces a more diverse generation .", "entities": []}, {"text": "4.5 Case Study Figure 5 presents a generation example via subsequence mixup .", "entities": [[11, 12, "MethodName", "mixup"]]}, {"text": "For the convenience of presentation , we set the length of sub - sequence s= 3 and the valid label density threshold \u00110=2 3 .", "entities": []}, {"text": "The two input sequences get paired for their eligible sub - sequences \u201c COLORADO 10 St \u201d and \u201c Slovenia , Kwasniewski \u201d .", "entities": []}, {"text": "The subsequences are mixed by \u0015= 0:39 in this case , which is sampled from Beta ( \u000b ; \u000b ) .", "entities": []}, {"text": "Then the generated sub - sequence \u201c Ohio ( novelist \u201d replaces the original parts in the two input sequences .", "entities": []}, {"text": "Among the generated tokens , \u201c Ohio \u201d inherits the label B - ORG from \u201c COLORADO \u201d and the label B - LOC from \u201c Slovenia \u201d , and the distribution Beta ( \u000b ; \u000b ) assigns the two labels with weights \u0015= 0:39and(1\u0000\u0015 )", "entities": []}, {"text": "= 0:61 .", "entities": []}, {"text": "The open parenthesis is produced by the mixing of a digit and a punctuation mark , and keeps the label Oshared by its parents .", "entities": []}, {"text": "Similarly , the token \u201c novelist \u201d generated by \u201c St \u201d and \u201c Kwasniewski \u201d gets a mixed label from B - ORG andB - PER .The discriminator then evaluates the two generated sequences .", "entities": []}, {"text": "The generated sequence iis not reasonable enough intuitively , and its perplexity score 877exceeds the threshold , so it is not added into the training set .", "entities": [[11, 12, "MetricName", "perplexity"]]}, {"text": "The generated sequence j retains the original syntax and semantic structure much better .", "entities": []}, {"text": "Although the open parenthesis seems strange , it plays a role as the comma in the original sequence to separate two clauses .", "entities": []}, {"text": "This generation behaves closely to a normal sequence and earns 332 perplexity score , which permits its incorporation into the training set .", "entities": [[11, 12, "MetricName", "perplexity"]]}, {"text": "5 Related Work Active Sequence Labeling Sequence labeling has been studied extensively for different NLP problems .", "entities": []}, {"text": "Different neural architectures has been proposed ( Huang et al . , 2015 ; Lample et al . , 2016 ; Peters et al . , 2018 ; Akbik et al . , 2018 ) in recent years , which have achieved state - of - the - art performance in a number of sequence labeling tasks .", "entities": []}, {"text": "However , these neural models usually require exhaustive human efforts for generating labels for each token , and may not perform well in lowresource settings .", "entities": []}, {"text": "To improve the performance of low - resource sequence labeling , several approaches have been applied including using semi - supervised methods ( Clark et al . , 2018 ; Chen et al . , 2020b ) , external weak supervision ( Lison et al . , 2020 ; Liang et al . , 2020 ;", "entities": []}, {"text": "Ren et al . , 2020 ; Zhang et al . , 2019 ; Yu et al . , 2020 ) and active learning ( Shen et al . , 2017 ; Hazra et al . , 2019 ; Liu et al . , 2018 ; Fang et al . , 2017 ; Gao et al . , 2019 ) .", "entities": [[22, 24, "TaskName", "active learning"]]}, {"text": "In this study , we mainly focus on active learning approaches which select samples based on the query policy design .", "entities": [[8, 10, "TaskName", "active learning"]]}, {"text": "So far , various uncertainty - based ( Scheffer et al . , 2001 ; Culotta and McCallum , 2005 ;", "entities": []}, {"text": "Kim et al . , 2006 ) and committee - based approaches ( Dagan and Engelson , 1995 ) have been proposed for improving the sample ef\ufb01ciency .", "entities": []}, {"text": "More recently , Shen et al .", "entities": []}, {"text": "( 2017 ) ; Hazra et al .", "entities": []}, {"text": "( 2019 ) ;", "entities": []}, {"text": "Liu et al . ( 2018 ) ; Fang et al .", "entities": []}, {"text": "( 2017 ) further improve the aforementioned active learning approaches to improve the sampling diversity as well as the generalization ability of models on low - resource scenarios .", "entities": [[7, 9, "TaskName", "active learning"]]}, {"text": "These works mainly claim the sample ef\ufb01ciency provided by the active learning approach but do not study data augmentation for active sequence labeling .", "entities": [[10, 12, "TaskName", "active learning"], [16, 18, "DatasetName", "study data"]]}, {"text": "Interpolation - based Regularizations Mixup implements interpolation in the input space to regularize models ( Zhang et al . , 2018 ) .", "entities": [[4, 5, "MethodName", "Mixup"]]}, {"text": "Recently ,", "entities": []}, {"text": "8574 DuringO hisO visitO to Slovenia , O B - LOC OCOLORADO 10 St Louis 5B - ORG O B - ORG I", "entities": []}, {"text": "- ORG O Input   Sequence \ud835\udc8bInput   Sequence \ud835\udc8a Kwasniewsk is also scheduled to meet Prime MinisterB - PER", "entities": []}, {"text": "O", "entities": []}, {"text": "O", "entities": []}, {"text": "O", "entities": []}, {"text": "O", "entities": []}, {"text": "O O ODuringO hisO visitO toO is also scheduled to Prime", "entities": []}, {"text": "MinisterO", "entities": []}, {"text": "O O", "entities": []}, {"text": "O O O OLouis5I - ORG O Ohio ( 0.39\u22c5B - ORG   +0.61\u22c5B - LOCO novelist0.39\u22c5B - ORG   +0.61\u22c5B - PERGenerated   Sequence \ud835\udc8a Generated   Sequence \ud835\udc8bScore = 877 - > Discarded Score = 332 - > Accepted meetOhio ( 0.39\u22c5B - ORG   +0.61\u22c5B - LOCO novelist0.39\u22c5B - ORG   +0.61\u22c5B - PEROhio ( 0.39\u22c5B - ORG   +0.61\u22c5B - LOCO novelist0.39\u22c5B - ORG   +0.61\u22c5B - PERFigure 5 : A generation case of sub - sequence mixup .", "entities": [[35, 36, "MetricName", "Score"], [81, 82, "MethodName", "mixup"]]}, {"text": "the Mixup variants ( Verma et al . , 2019 ; Summers and Dinneen , 2019 ; Guo et al . , 2019b ) turn to perform interpolation in the hidden space to capture higher - level information .", "entities": [[1, 2, "MethodName", "Mixup"]]}, {"text": "Guo et al . ( 2019a ) ; Chen et al .", "entities": []}, {"text": "( 2020a ) apply hidden - space Mixup for text classi\ufb01cation .", "entities": [[7, 8, "MethodName", "Mixup"]]}, {"text": "These works , however , have not explored how to perform mixup for sequences with token - level labels , nor do they consider the quality of the mixed - up samples .", "entities": [[11, 12, "MethodName", "mixup"]]}, {"text": "Text Augmentation Our work is also related to text data augmentation .", "entities": [[9, 11, "TaskName", "data augmentation"]]}, {"text": "Zhang et al . ( 2015 ) ; Wei and Zou ( 2019 ) utilize heuristic approaches including synonym replancement , random insertion , swap and deletion for text augmentation , Ka\ufb02e et al .", "entities": []}, {"text": "( 2017 ) ;", "entities": []}, {"text": "Silfverberg et al . ( 2017 ) employ heuristic rules based on speci\ufb01c task , Hu et al .", "entities": []}, {"text": "( 2017 ) propose to augment text data in an encoder - decoder manner .", "entities": []}, {"text": "Very recently , ( Anaby - Tavor et", "entities": []}, {"text": "al . , 2020 ; Kobayashi , 2018 ) harness the power of pre - trained language models and augmenting the text data based on contextual patterns .", "entities": []}, {"text": "Although these methods can augment the training set and improve the performance of text classi\ufb01cation model , they fail togenerate sequences and labels simultaneously , thus can not be adapted to our problem where tokenlevel labels are required during training .", "entities": []}, {"text": "Instead , in our study , we propose a new framework SeqMix for data augmentation to facilitate sequence labeling task .", "entities": [[13, 15, "TaskName", "data augmentation"]]}, {"text": "Our method can generate token - level labels and preserve the semantic information in the augmented sentences .", "entities": []}, {"text": "Moreover , it can be naturally combined with existing active learning approaches and further promote the performance.6 Conclusion We propose a simple data augmentation method SeqMix to enhance active sequence labeling .", "entities": [[9, 11, "TaskName", "active learning"], [22, 24, "TaskName", "data augmentation"]]}, {"text": "By performing sequence mixup in the latent space , SeqMix improves data diversity during active learning , while being able to generate plausible augmented sequences .", "entities": [[3, 4, "MethodName", "mixup"], [14, 16, "TaskName", "active learning"]]}, {"text": "This method is generic to different active learning policies and various sequence labeling tasks .", "entities": [[6, 8, "TaskName", "active learning"]]}, {"text": "Our experiments demonstrate that SeqMix can improve active learning baselines consistently for NER and event detection tasks ; and its bene\ufb01ts are especially prominent in low - data regimes .", "entities": [[7, 9, "TaskName", "active learning"], [12, 13, "TaskName", "NER"], [14, 16, "TaskName", "event detection"]]}, {"text": "For future research , it is interesting to enhance SeqMix with language models during the mixup process , and harness external knowledge for further improving diversity and plausibility .", "entities": [[15, 16, "MethodName", "mixup"]]}, {"text": "References Alan Akbik , Duncan Blythe , and Roland V ollgraf .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Contextual string embeddings for sequence labeling .", "entities": []}, {"text": "In Proceedings of the 27th International Conference on Computational Linguistics , pages 1638\u20131649 .", "entities": []}, {"text": "Ateret Anaby - Tavor , Boaz Carmeli , Esther Goldbraich , Amir Kantor , George Kour , Segev Shlomov , Naama Tepper , and Naama Zwerdling .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Do not have enough data ?", "entities": []}, {"text": "deep learning to the rescue !", "entities": []}, {"text": "In The Thirty - Fourth AAAI Conference on Arti\ufb01cial Intelligence , pages 7383\u20137390 .", "entities": []}, {"text": "Samuel R. Bowman , Luke Vilnis , Oriol Vinyals , Andrew Dai , Rafal Jozefowicz , and Samy Bengio .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Generating sentences from a continuous space .", "entities": []}, {"text": "In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning , pages 10\u201321 .", "entities": []}, {"text": "8575Jiaao Chen , Zichao Yang , and Diyi Yang . 2020a .", "entities": []}, {"text": "MixText : Linguistically - informed interpolation of hidden space for semi - supervised text classi\ufb01cation .", "entities": [[0, 1, "MethodName", "MixText"]]}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 2147 \u2013 2157 .", "entities": []}, {"text": "Luoxin Chen , Weitong Ruan , Xinyue Liu , and Jianhua Lu .", "entities": []}, {"text": "2020b .", "entities": []}, {"text": "SeqV", "entities": []}, {"text": "AT : Virtual adversarial training for semi - supervised sequence labeling .", "entities": []}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 8801\u20138811 .", "entities": []}, {"text": "Eunah Cho , He Xie , and William M. Campbell .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Paraphrase generation for semi - supervised learning in NLU .", "entities": [[0, 2, "TaskName", "Paraphrase generation"]]}, {"text": "In Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation , pages 45\u201354 .", "entities": []}, {"text": "Kevin Clark , Minh - Thang Luong , Christopher D. Manning , and Quoc Le .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Semi - supervised sequence modeling with cross - view training .", "entities": [[6, 10, "MethodName", "cross - view training"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 1914 \u2013 1925 .", "entities": []}, {"text": "Aron Culotta and Andrew McCallum .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Reducing labeling effort for structured prediction tasks .", "entities": [[4, 6, "TaskName", "structured prediction"]]}, {"text": "In Proceedings of the 20th AAAI conference on Arti\ufb01cial intelligence , volume 5 , pages 746\u2013751 .", "entities": []}, {"text": "Ido Dagan and Sean P Engelson .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "Committeebased sampling for training probabilistic classi\ufb01ers .", "entities": []}, {"text": "InMachine Learning Proceedings 1995 , pages 150 \u2013 157 .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "BERT : Pre - training of deep bidirectional transformers for language understanding .", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171\u20134186 .", "entities": []}, {"text": "Rotem Dror , Gili Baumer , Segev Shlomov , and Roi Reichart .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "The hitchhiker \u2019s guide to testing statistical signi\ufb01cance in natural language processing .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1383\u20131392 .", "entities": []}, {"text": "Meng Fang , Yuan Li , and Trevor Cohn . 2017 .", "entities": []}, {"text": "Learning how to active learn : A deep reinforcement learning approach .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 595\u2013605 .", "entities": []}, {"text": "Ning Gao , Nikos Karampatziakis , Rahul Potharaju , and Silviu Cucerzan .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Active entity recognition in low resource settings .", "entities": []}, {"text": "In Proceedings of the 28th ACM International Conference on Information and Knowledge Management , page 2261\u20132264.Hongyu Guo , Yongyi Mao , and Richong Zhang .", "entities": [[5, 6, "DatasetName", "ACM"], [12, 13, "TaskName", "Management"]]}, {"text": "2019a .", "entities": []}, {"text": "Augmenting data with mixup for sentence classi\ufb01cation : An empirical study .", "entities": [[3, 4, "MethodName", "mixup"]]}, {"text": "arXiv preprint arXiv:1905.08941 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Hongyu Guo , Yongyi Mao , and Richong Zhang .", "entities": []}, {"text": "2019b .", "entities": []}, {"text": "Mixup as locally linear out - of - manifold regularization .", "entities": [[0, 1, "MethodName", "Mixup"]]}, {"text": "In Proceedings of the AAAI Conference on Arti\ufb01cial Intelligence , volume 33 , pages 3714\u20133722 .", "entities": []}, {"text": "Rishi Hazra , Shubham Gupta , and Ambedkar Dukkipati .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Active2learning : Actively reducing redundancies in active learning methods for sequence tagging .", "entities": [[6, 8, "TaskName", "active learning"]]}, {"text": "arXiv preprint arXiv:1911.00234 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Zhiting Hu , Zichao Yang , Xiaodan Liang , Ruslan Salakhutdinov , and Eric P. Xing . 2017 .", "entities": [[9, 10, "DatasetName", "Ruslan"]]}, {"text": "Toward controlled generation of text .", "entities": []}, {"text": "In Proceedings of the 34th International Conference on Machine Learning , volume 70 of Proceedings of Machine Learning Research , pages 1587\u20131596 .", "entities": []}, {"text": "Zhiheng Huang , Wei Xu , and Kai Yu . 2015 .", "entities": []}, {"text": "Bidirectional lstm - crf models for sequence tagging .", "entities": [[0, 2, "MethodName", "Bidirectional lstm"], [3, 4, "MethodName", "crf"]]}, {"text": "arXiv preprint arXiv:1508.01991 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Kushal Ka\ufb02e , Mohammed Yousefhussien , and Christopher Kanan . 2017 .", "entities": []}, {"text": "Data augmentation for visual question answering .", "entities": [[0, 2, "TaskName", "Data augmentation"], [3, 6, "DatasetName", "visual question answering"]]}, {"text": "In Proceedings of the 10th International Conference on Natural Language Generation , pages 198\u2013202 .", "entities": []}, {"text": "Seokhwan Kim , Yu Song , Kyungduk Kim , Jeong - Won Cha , and Gary Geunbae Lee . 2006 .", "entities": []}, {"text": "MMR - based active machine learning for bio named entity recognition .", "entities": [[8, 11, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Human Language Technology Conference of the NAACL , , pages 69\u201372 .", "entities": []}, {"text": "Sosuke Kobayashi .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Contextual augmentation : Data augmentation by words with paradigmatic relations .", "entities": [[3, 5, "TaskName", "Data augmentation"]]}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 2 ( Short Papers ) , pages 452\u2013457 .", "entities": []}, {"text": "John D Lafferty , Andrew McCallum , and Fernando CN Pereira . 2001 .", "entities": []}, {"text": "Conditional random \ufb01elds : Probabilistic models for segmenting and labeling sequence data .", "entities": []}, {"text": "In Proceedings of the Eighteenth International Conference on Machine Learning , pages 282\u2013289 .", "entities": []}, {"text": "Guillaume Lample , Miguel Ballesteros , Sandeep Subramanian , Kazuya Kawakami , and Chris Dyer . 2016 .", "entities": []}, {"text": "Neural architectures for named entity recognition .", "entities": [[3, 6, "TaskName", "named entity recognition"]]}, {"text": "InProceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 260\u2013270 .", "entities": []}, {"text": "Chen Liang , Yue Yu , Haoming Jiang , Siawpeng Er , Ruijia Wang , Tuo Zhao , and Chao Zhang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Bond : Bert - assisted open - domain named entity recognition with distant supervision .", "entities": [[8, 11, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , page 1054\u20131064 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "8576Pierre Lison , Jeremy Barnes , Aliaksandr Hubin , and Samia Touileb .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Named entity recognition without labelled data : A weak supervision approach .", "entities": [[0, 3, "TaskName", "Named entity recognition"]]}, {"text": "InProceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 1518\u20131533 .", "entities": []}, {"text": "Ming Liu , Wray Buntine , and Gholamreza Haffari .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Learning how to actively learn : A deep imitation learning approach .", "entities": [[8, 10, "TaskName", "imitation learning"]]}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1874\u20131883 .", "entities": []}, {"text": "Llu\u00b4\u0131s M`arquez , Pere Comas , Jes \u00b4 us Gim \u00b4 enez , and Neus Catal ` a. 2005 .", "entities": []}, {"text": "Semantic role labeling as sequential tagging .", "entities": [[0, 3, "TaskName", "Semantic role labeling"]]}, {"text": "In Proceedings of the Ninth Conference on Computational Natural Language Learning ( CoNLL-2005 ) , pages 193\u2013196 .", "entities": []}, {"text": "Matthew Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Deep contextualized word representations .", "entities": []}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) , pages 2227 \u2013 2237 .", "entities": []}, {"text": "Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 .", "entities": []}, {"text": "Language models are unsupervised multitask learners .", "entities": []}, {"text": "OpenAI Blog , 1(8):9 .", "entities": []}, {"text": "Lev Ratinov and Dan Roth . 2009 .", "entities": []}, {"text": "Design challenges and misconceptions in named entity recognition .", "entities": [[3, 4, "TaskName", "misconceptions"], [5, 8, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning ( CoNLL-2009 ) , pages 147\u2013155 .", "entities": [[12, 13, "DatasetName", "CoNLL-2009"]]}, {"text": "Wendi Ren , Yinghao Li , Hanting Su , David Kartchner , Cassie Mitchell , and Chao Zhang .", "entities": [[0, 1, "DatasetName", "Wendi"]]}, {"text": "2020 .", "entities": []}, {"text": "Denoising multi - source weak supervision for neural text classi\ufb01cation .", "entities": [[0, 1, "TaskName", "Denoising"]]}, {"text": "In Findings of the 2020 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Tobias Scheffer , Christian Decomain , and Stefan Wrobel .", "entities": []}, {"text": "2001 .", "entities": []}, {"text": "Active hidden markov models for information extraction .", "entities": []}, {"text": "In International Symposium on Intelligent Data Analysis , pages 309\u2013318 .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "Burr Settles and Mark Craven .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "An analysis of active learning strategies for sequence labeling tasks .", "entities": [[3, 5, "TaskName", "active learning"]]}, {"text": "InProceedings of the 2008 Conference on Empirical Methods in Natural Language Processing , pages 1070\u20131079 .", "entities": []}, {"text": "H. S. Seung , M. Opper , and H. Sompolinsky .", "entities": []}, {"text": "1992 .", "entities": []}, {"text": "Query by committee .", "entities": []}, {"text": "In Proceedings of the Fifth Annual Workshop on Computational Learning Theory , page 287\u2013294 .", "entities": []}, {"text": "Yanyao Shen , Hyokun Yun , Zachary Lipton , Yakov Kronrod , and Animashree Anandkumar . 2017 .", "entities": []}, {"text": "Deep active learning for named entity recognition .", "entities": [[1, 3, "TaskName", "active learning"], [4, 7, "TaskName", "named entity recognition"]]}, {"text": "InProceedings of the 2nd Workshop on Representation Learning for NLP , pages 252\u2013256.Miikka Silfverberg , Adam Wiemerslage , Ling Liu , and Lingshuang Jack Mao . 2017 .", "entities": [[6, 8, "TaskName", "Representation Learning"], [15, 16, "MethodName", "Adam"]]}, {"text": "Data augmentation for morphological rein\ufb02ection .", "entities": [[0, 2, "TaskName", "Data augmentation"]]}, {"text": "In Proceedings of the CoNLL SIGMORPHON 2017 Shared Task : Universal Morphological Rein\ufb02ection , pages 90\u201399 .", "entities": []}, {"text": "Cecilia Summers and Michael J Dinneen .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Improved mixed - example data augmentation .", "entities": [[4, 6, "TaskName", "data augmentation"]]}, {"text": "In 2019 IEEE Winter Conference on Applications of Computer Vision , pages 1262\u20131270 .", "entities": []}, {"text": "Erik F. Tjong Kim Sang and Fien De Meulder .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Introduction to the CoNLL-2003 shared task : Language - independent named entity recognition .", "entities": [[3, 4, "DatasetName", "CoNLL-2003"], [10, 13, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Seventh Conference on Natural Language Learning at HLT - NAACL 2003 , pages 142\u2013147 .", "entities": []}, {"text": "Katrin Tomanek , Joachim Wermter , and Udo Hahn . 2007 .", "entities": []}, {"text": "An approach to text corpus construction which cuts annotation costs and maintains reusability of annotated data .", "entities": []}, {"text": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL ) , pages 486 \u2013 495 .", "entities": []}, {"text": "Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , \u0141 ukasz Kaiser , and Illia Polosukhin . 2017 .", "entities": []}, {"text": "Attention is all you need .", "entities": []}, {"text": "In Advances in Neural Information Processing Systems , pages 5998\u20136008 .", "entities": []}, {"text": "Vikas Verma , Alex Lamb , Christopher Beckham , Amir Naja\ufb01 , Ioannis Mitliagkas , David Lopez - Paz , and Yoshua Bengio .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Manifold mixup : Better representations by interpolating hidden states .", "entities": [[0, 2, "MethodName", "Manifold mixup"]]}, {"text": "In Proceedings of the 36th International Conference on Machine Learning , pages 6438\u20136447 .", "entities": []}, {"text": "PMLR .", "entities": []}, {"text": "Jason Wei and Kai Zou .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "EDA :", "entities": []}, {"text": "Easy data augmentation techniques for boosting performance on text classi\ufb01cation tasks .", "entities": [[1, 3, "TaskName", "data augmentation"]]}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 6382\u20136388 .", "entities": []}, {"text": "Frank Wilcoxon .", "entities": []}, {"text": "1992 .", "entities": []}, {"text": "Individual comparisons by ranking methods .", "entities": []}, {"text": "In Breakthroughs in statistics , pages 196\u2013202 .", "entities": []}, {"text": "Qizhe Xie , Zihang Dai , Eduard Hovy , Minh - Thang Luong , and Quoc V Le .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Unsupervised data augmentation for consistency training .", "entities": [[1, 3, "TaskName", "data augmentation"]]}, {"text": "arXiv preprint arXiv:1904.12848 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Sen Yang , Dawei Feng , Linbo Qiao , Zhigang Kan , and Dongsheng Li . 2019 .", "entities": []}, {"text": "Exploring pre - trained language models for event extraction and generation .", "entities": [[7, 9, "TaskName", "event extraction"]]}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 5284 \u2013 5294 .", "entities": []}, {"text": "8577Yue Yu , Yinghao Li , Jiaming Shen , Hao Feng , Jimeng Sun , and Chao Zhang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Steam : Selfsupervised taxonomy expansion with mini - paths .", "entities": []}, {"text": "In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , page 1026\u20131035 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Hongyi Zhang , Moustapha Cisse , Yann N. Dauphin , and David Lopez - Paz . 2018 .", "entities": []}, {"text": "mixup :", "entities": [[0, 1, "MethodName", "mixup"]]}, {"text": "Beyond empirical risk minimization .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Shanshan Zhang , Lihong He , Eduard Dragut , and Slobodan Vucetic .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "How to invest my time :", "entities": []}, {"text": "Lessons from human - in - the - loop entity extraction .", "entities": []}, {"text": "InProceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , page 2305\u20132313 .", "entities": [[4, 5, "DatasetName", "ACM"]]}, {"text": "Xiang Zhang , Junbo Zhao , and Yann LeCun . 2015 .", "entities": []}, {"text": "Character - level convolutional networks for text classi\ufb01cation .", "entities": []}, {"text": "In Advances in neural information processing systems , pages 649\u2013657 .", "entities": []}, {"text": "Yizhe Zhang , Zhe Gan , and Lawrence Carin .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Generating text via adversarial training .", "entities": []}, {"text": "In NIPS workshop on Adversarial Training .", "entities": []}, {"text": "Xiaoqing Zheng , Hanyang Chen , and Tianyu Xu .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Deep learning for Chinese word segmentation and POS tagging .", "entities": [[3, 6, "TaskName", "Chinese word segmentation"]]}, {"text": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 647\u2013657 .", "entities": []}, {"text": "8578A Information for Dataset A.1 Dataset Collection", "entities": []}, {"text": "Here we list the link to datasets used in our experiments .", "entities": []}, {"text": "\u000fCoNLL-03 :", "entities": []}, {"text": "https://github.com/ synalp / NER / tree / master / corpus/ CoNLL-2003 .", "entities": [[3, 4, "TaskName", "NER"], [10, 11, "DatasetName", "CoNLL-2003"]]}, {"text": "\u000fACE05 : We are unable to provide the downloadable version due to it is not public .", "entities": []}, {"text": "This corpus can be applied through the website of LDC : https://www.ldc.upenn.edu/ collaborations / past - projects/ ace .", "entities": []}, {"text": "\u000fWebpage : Please refer the link in the paper ( Ratinov and Roth , 2009 ) .", "entities": []}, {"text": "A.2 Dataset Split All the mentioned dataset has been split into train / validate / test set in the released version .", "entities": []}, {"text": "We keep consistent with the validation set and the test set in our experiment .", "entities": []}, {"text": "For the active learning paradigm , we split the training set as Table 3 .", "entities": [[2, 4, "TaskName", "active learning"]]}, {"text": "The active learners are initialized on the seed set , then they implement 5 active learning rounds .", "entities": [[14, 16, "TaskName", "active learning"]]}, {"text": "B Baseline Settings For the baselines , we take random sampling and 3 active learning approaches \u2013 LC sampling , NTE sampling , and QBC sampling as Section 2.2 .", "entities": [[13, 15, "TaskName", "active learning"]]}, {"text": "C Implementation Details of SeqMix", "entities": []}, {"text": "We implement bert - base - cased as the underlying model for the NER task and bert - base - multilingualcased as the underlying model for the event detection task .", "entities": [[13, 14, "TaskName", "NER"], [27, 29, "TaskName", "event detection"]]}, {"text": "We use the model from Huggingface Transformer codebase3 , and the repository4to \ufb01netune our model for sequence labeling task .", "entities": [[6, 7, "MethodName", "Transformer"]]}, {"text": "C.1 Number of Parameters In our model , we use bert - base - cased andbertbase - multilingual - cased both of them occupy 12layer , 768 - hidden , 12 - heads with 110 M parameters .", "entities": [[1, 4, "HyperparameterName", "Number of Parameters"]]}, {"text": "3https://github.com/huggingface/ transformers 4https://github.com/kamalkraj/BERT-NERC.2 Adapting BERT for sequence labeling task To \ufb01ne - tune on sequence labeling tasks , a dropout layer ( p= 0:1 ) and a linear ( token - level ) classi\ufb01cation layer is built upon the pre - trained model .", "entities": [[4, 5, "MethodName", "BERT"]]}, {"text": "C.3 SeqMix Details In Section 3.2 , we construct a table of tokens W and their corresponding contextual embedding E. For our underlying BERT model , we use the vocabulary provided by the tokenizer to build up W , and the embedding initialized on the training set as E. We also need to construct a special token collection to exclude some generation in the process of sequence mixing .", "entities": [[23, 24, "MethodName", "BERT"]]}, {"text": "For example , BERT places token", "entities": [[3, 4, "MethodName", "BERT"]]}, {"text": "[ CLS ] and[SEP ] at the starting position and the ending position for sentence , and pad the inputs with[PAD ] .", "entities": []}, {"text": "We exclude these disturbing tokens and the parent tokens .", "entities": []}, {"text": "C.4 Parameter Settings The key parameters setting in our framework are stated here : ( 1 ) The number of active learning round is 5 for all the three datasets , but the size of seed set and the number of samples in each round differs from the dataset .", "entities": [[20, 22, "TaskName", "active learning"], [39, 42, "HyperparameterName", "number of samples"]]}, {"text": "We list the speci\ufb01c numbers as Table 3 .", "entities": []}, {"text": "( 2 ) The sub - sequence window lengthsand the valid label density threshold \u00110 vary from the datasets .", "entities": []}, {"text": "For CoNLL-03 , s= 5 , \u00110= 0:6 ; for ACE05 , s=", "entities": []}, {"text": "5,\u00110= 0:2 ; for WebPage , s= 4,\u00110= 0:5 .", "entities": []}, {"text": "( 3 ) We set \u000b = 8 for theBeta distribution .", "entities": []}, {"text": "( 4 ) The discriminator score range is set as ( 0;500 ) for all the datasets .", "entities": []}, {"text": "( 5 ) For BERT con\ufb01guration , we choose 5e-5 for learning rate , 128 for padding length , 32 for batch size , 0.1 for dropout rate , 1e-8 for \u000fin Adam .", "entities": [[4, 5, "MethodName", "BERT"], [11, 13, "HyperparameterName", "learning rate"], [21, 23, "HyperparameterName", "batch size"], [32, 33, "MethodName", "Adam"]]}, {"text": "At each data usage point , we train the model for 10 Epochs .", "entities": []}, {"text": "( 6 ) We setC= 3for the QBC query policy .", "entities": []}, {"text": "D Details of Experiments We take following criteria to evaluate the sequence labeling task .", "entities": []}, {"text": "A named entity is correct only if it is an exact match of the corresponding entity in the data \ufb01le .", "entities": [[10, 12, "MetricName", "exact match"]]}, {"text": "An event trigger is correct only if the span and type match with golden labels .", "entities": []}, {"text": "Based on the above metric , we evaluate F1score in our experiments .", "entities": []}, {"text": "D.1 Performance on Development Set Table 4 to Table 6 shows the model performance on the validation set .", "entities": []}, {"text": "The data usage in these tables", "entities": []}, {"text": "8579Dataset # of Entity Types # of Seed Set Sampling Rounds # of Each Round Samples # of Dev # of Test CoNLL-03 4 200 5 100 3250 3453 ACE05 29 1k 5 f1k , 2k , 2k , 4k , 4k g 873 711 Webpage 4 85 5 60 99 135 Table 3 : The information for benchmarks in our experiments .", "entities": []}, {"text": "Data Usage 200 300 400 500 600 700 Random Sampling 69.03 83.28 84.93 85.50 85.79 86.62 LC Sampling 69.03 83.78 84.55 85.88 86.04 86.73 NTE Sampling 69.03 83.60 85.00 85.47 86.19 86.83 QBC Sampling 69.03 83.33 84.52 85.30 86.27 86.60 Sub - sequence mixup 81.69 85.28 85.95 86.52 87.07 87.44 Table 4 : Validation F1of CoNLL-03 Data Usage 1000 2000 4000 6000 10000 14000 Random Sampling 48.16 59.10 63.13 64.95 66.23 67.12 LC Sampling 48.16 59.33 63.22 65.04 66.24 66.92 NTE Sampling 48.16 59.72 63.17 65.53 66.78 67.24 QBC Sampling 48.16 59.01 62.79 64.89 66.20 66.91 Sub - sequence mixup 56.51 61.62 63.65 65.83 67.54 67.98 Table 5 : Validation F1of", "entities": [[43, 44, "MethodName", "mixup"], [99, 100, "MethodName", "mixup"]]}, {"text": "ACE05 refers to the number of labeled data , excluding the augmentation data .", "entities": []}, {"text": "Sub - sequence mixup is trained with ( 1 + \u000b ) times data , where the \u000b denotes the augment rate .", "entities": [[3, 4, "MethodName", "mixup"]]}, {"text": "Note that WebPage is a very limited dataset , there is a big difference between the performance on the validation set and the test set .", "entities": []}, {"text": "We average each experiment by 5 times .", "entities": []}, {"text": "D.2 Computing Infrastructure", "entities": []}, {"text": "We implement our system on Ubuntu 18.04.3 LTS system .", "entities": []}, {"text": "We run our experiments on an Intel(R ) Xeon(R ) CPU @ 2.30GHz and NVIDIA Tesla P100 - PCIe with 16 GB HBM2 memory .", "entities": []}, {"text": "The NVIDIA - SMI version is 418.67 and the CUDA version is 10.1 .", "entities": []}, {"text": "D.3 Average Runtime For the 5 - round active learning with SeqMix augmentation , our program runs about 500 seconds for WebPage dataset , 1700 seconds for the CoNLL slicing dataset , and 3.5 hours for ACE 2005 .", "entities": [[8, 10, "TaskName", "active learning"], [36, 38, "DatasetName", "ACE 2005"]]}, {"text": "If the QBC query policy used , all the runtime will be multiplied about 3 times .", "entities": []}, {"text": "D.4 Hyper parameter Search", "entities": []}, {"text": "For the discriminator score range , we \ufb01rst examine the perplexity score distribution of the CoNLL training set .", "entities": [[10, 11, "MetricName", "perplexity"]]}, {"text": "Then determine an approximate score range ( 0;2000 ) \ufb01rst .", "entities": []}, {"text": "We linearly split score ranges below 2000 to conduct parameter study and reportData Usage 85 145 205 265 325 385 Random Sampling 0 27.52 34.41", "entities": [[22, 23, "DatasetName", "0"]]}, {"text": "34.83 37.93 35.73 LC Sampling 0 28.84 32.88 34.22 38.78 38.11 NTE Sampling 0 22.44 34.81 33.74 36.59 38.27 QBC Sampling 0 23.88 32.18 34.17 36.56 35.66 Sub - sequence mixup 14.35 33.74 34.70 36.22 39.74 38.25 Table 6 : Validation F1of", "entities": [[5, 6, "DatasetName", "0"], [13, 14, "DatasetName", "0"], [21, 22, "DatasetName", "0"], [30, 31, "MethodName", "mixup"]]}, {"text": "WebPage the representative ranges in Section 4.3 .", "entities": []}, {"text": "Given the consideration to the generation speed and the augment rate setting , we \ufb01nally choose 500as the upper limit rather than a too narrow score range setting .", "entities": []}, {"text": "For the mixing coef\ufb01cient \u0015 , we follow ( Zhang et al . , 2018 ) to sample it from Beta ( \u000b ; \u000b ) and explore \u000b ranging from [ 0:5;16 ] .", "entities": []}, {"text": "We present this parameter study in Section 4.4 .", "entities": []}, {"text": "The result shows different \u000b did not in\ufb02uence the augmentation performance much .", "entities": []}, {"text": "For the augment rate and the valid tag density , we also have introduced the parameter study in Section 4.4 .", "entities": []}]