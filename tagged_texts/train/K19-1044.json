[{"text": "Proceedings of the 23rd Conference on Computational Natural Language Learning , pages 472\u2013481 Hong Kong , China , November 3 - 4 , 2019 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics472Active Learning via Membership Query Synthesis for Semi - supervised Sentence Classi\ufb01cation Raphael Schumann Institute for Computational Linguistics Heidelberg University , Germany rschuman@cl.uni - heidelberg.deInes", "entities": []}, {"text": "Rehbein Leibniz ScienceCampus Heidelberg / Mannheim rehbein@ids-mannheim.de Abstract Active learning ( AL ) is a technique for reducing manual annotation effort during the annotation of training data for machine learning classi\ufb01ers .", "entities": [[8, 10, "TaskName", "Active learning"]]}, {"text": "For NLP tasks , pool - based and stream - based sampling techniques have been used to select new instances for AL while generating new , arti\ufb01cial instances via Membership Query Synthesis was , up to know , considered to be infeasible for NLP problems .", "entities": []}, {"text": "We present the \ufb01rst successful attempt to use Membership Query Synthesis for generating AL queries for natural language processing , using Variational Autoencoders for query generation .", "entities": [[22, 23, "MethodName", "Autoencoders"]]}, {"text": "We evaluate our approach in a text classi\ufb01cation task and demonstrate that query synthesis shows competitive performance to pool - based AL strategies while substantially reducing annotation time .", "entities": []}, {"text": "1 Introduction Active learning ( AL ) has the potential to substantially reduce the amount of labeled instances needed to reach a certain classi\ufb01er performance in supervised machine learning .", "entities": [[2, 4, "TaskName", "Active learning"]]}, {"text": "It works by selecting new instances that are highly informative for the classi\ufb01er , so that comparable classi\ufb01cation accuracies can be obtained on a much smaller training set .", "entities": []}, {"text": "AL strategies can be categorized into pool - based sampling , stream - based sampling and Membership Query Synthesis ( MQS ) .", "entities": []}, {"text": "The \ufb01rst two strategies sample new instances either from a data pool or from a stream of data .", "entities": []}, {"text": "The third , MQS , generates arti\ufb01cial AL instances from the region of uncertainty of the classi\ufb01er .", "entities": []}, {"text": "While it is known that MQS can reduce the predictive error rate more quickly than pool - based sampling ( Ling and Du , 2008 ) , so far it has not been used for NLP tasks because arti\ufb01cially created textual instances are uninterpretable for human annotators .", "entities": []}, {"text": "We provide proof of concept that generating highly informative arti\ufb01cial training instances fortext classi\ufb01cation is feasible .", "entities": []}, {"text": "We use Variational Autoencoders ( V AE ) ( Kingma and Welling , 2013 ) to learn representations from unlabeled text in an unsupervised fashion by encoding individual sentences as low - dimensional vectors in latent space .", "entities": [[3, 4, "MethodName", "Autoencoders"], [6, 7, "MethodName", "AE"]]}, {"text": "In addition to mapping input sequences into latent space , the V AE can also learn to generate new instances from this space .", "entities": [[12, 13, "MethodName", "AE"]]}, {"text": "We utilize these abilities to generate new examples for active learning from a region in latent space where the classi\ufb01er is most uncertain , and hand them over to the annotator who then provides labels for the newly created instances .", "entities": [[9, 11, "TaskName", "active learning"]]}, {"text": "We test our approach in a text classi\ufb01cation setup with a real human annotator in the loop .", "entities": []}, {"text": "Our experiments show that query synthesis for NLP is not only feasible but can outperform other AL strategies in a sentiment classi\ufb01cation task with respect to annotation time .", "entities": []}, {"text": "The paper is structured as follows .", "entities": []}, {"text": "We \ufb01rst review related work ( x2 ) and introduce a formal description of the problem ( x3 ) .", "entities": []}, {"text": "Then we describe our approach ( x4 ) , present the experiments ( x5 ) and analyze the results ( x6 ) .", "entities": []}, {"text": "We discuss limitations and possible further experiments ( x7 ) and \ufb01nally conclude our \ufb01ndings ( x8 ) .", "entities": []}, {"text": "2 Related work Membership query synthesis was introduced by Angluin ( 1988 ) and describes a setting where the model generates new queries instead of selecting existing ones .", "entities": []}, {"text": "Early experiments in image processing ( Lang and Baum , 1992 ) , however , showed that the generated queries are hard to interpret by human annotators .", "entities": []}, {"text": "This holds true even for recent approaches using Generative Adversarial Networks ( GANs ) ( Goodfellow et", "entities": []}, {"text": "al . , 2014 ) to create uncertain instances ( Zhu and Bento , 2017 ; Huijser and van Gemert , 2017 ) .", "entities": []}, {"text": "In contrast to im-", "entities": []}, {"text": "473age processing , discrete domains like natural language do not exhibit a direct mapping from feature to instance space .", "entities": []}, {"text": "Strategies that circumvent this problem include the search for nearest ( observed ) neighbors in feature space ( Wang et al . , 2015 ) or crafting queries by switching words ( Awasthi and Kanade , 2012 ) .", "entities": []}, {"text": "Sentence representation learning ( Kiros et al . , 2015 ; Conneau et al . , 2017 ; Subramanian et al . , 2018 ; Wang et al . , 2019 ) in combination with new methods for semi - supervised learning ( Kingma et al . , 2014 ; Hu et al . , 2017 ; Xu et", "entities": [[1, 3, "TaskName", "representation learning"]]}, {"text": "al . , 2017 ; Odena , 2016 ; Radford et al . , 2017 ) have shown to improve classi\ufb01cation tasks by leveraging unlabeled text .", "entities": []}, {"text": "Methods based on deep generative models like GANs or V AEs are able to generate sentences from any point in representation space .", "entities": []}, {"text": "Mehrjou et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) use V AEs to learn structural information from unlabeled data and use it as an additional criterion in conventional active learning to make it more robust against outliers and noise .", "entities": [[22, 24, "TaskName", "active learning"]]}, {"text": "We use V AEs to generate AL queries from speci\ufb01c regions in latent space .", "entities": []}, {"text": "To ensure that the generated instances are not only informative for the ML classi\ufb01er but also meaningful for the human annotator , we adapt the approach of Wang et al . ( 2015 ) ( seex3.1 ) .", "entities": []}, {"text": "In contrast to their work , however , we do not sample existing instances from the pool that are similar to the synthetic ones but directly generate the new queries .", "entities": []}, {"text": "To our best knowledge , our work is the \ufb01rst to present positive results for Membership Query Synthesis for text classi\ufb01cation .", "entities": []}, {"text": "3 Background 3.1 Query Synthesis and Nearest Neighbors", "entities": []}, {"text": "Arbitrary points in feature space are hard to interpret for humans .", "entities": []}, {"text": "To evade this problem , Wang et al .", "entities": []}, {"text": "( 2015 ) use the nearest neighbor in a pool of unlabeled data as a representative which is then presented to the human annotator .", "entities": []}, {"text": "To identify uncertain points along the separating hyperplane of an SVM the following approach is proposed .", "entities": [[10, 11, "MethodName", "SVM"]]}, {"text": "First the location of the decision boundary is approximated by a binary - search like procedure .", "entities": []}, {"text": "An initialOpposite Pair ( z+;z\u0000)is formed by centroid c+and centroid c\u0000of positive and negative labeled instances respectively .", "entities": []}, {"text": "The mid point zs is queried and , depending on the annotated label l , replaces the corresponding zl .", "entities": []}, {"text": "This step is repeatedbtimes , reducing the distance between the Figure 1 : a)\ufb01nds", "entities": []}, {"text": "Opposite Pair close to the decision boundary .", "entities": []}, {"text": "b)identify points close to the decision boundary .", "entities": []}, {"text": "initial centroids by a factor of 2b .", "entities": []}, {"text": "Figure 1a depicts this process .", "entities": []}, {"text": "Then the mid - perpendicular vector of theOpposite Pair is calculated by using the GramSchmidt process to orthogonalize a random vectorzrand normalize its magnitude to \u0015. The new pointzs = zr+ ( z++z\u0000)=2is close to the decision boundary and queried for its class .", "entities": []}, {"text": "Depending on the receive label the point zsreplacesz+or z\u0000in the Opposite Pair .", "entities": []}, {"text": "This process ( Figure 1b ) is repeated until n\u0000bpoints along the separating hyperplane are queried .", "entities": []}, {"text": "3.2 V AE for Sentence Generation The Variational Autoencoder is a generative model \ufb01rst introduced by Kingma and Welling ( 2013 ) .", "entities": [[2, 3, "MethodName", "AE"], [7, 9, "MethodName", "Variational Autoencoder"]]}, {"text": "Like other autoencoders , V AEs learn a mapping q\u0012(zjx)from high dimensional input xto a low dimensional latent variable z.", "entities": [[2, 3, "MethodName", "autoencoders"]]}, {"text": "Instead of doing this in a deterministic way , the encoder learns the parameters of e.g. a normal distribution .", "entities": []}, {"text": "The desired effect is that each area in the latent space has a semantic meaning and thus samples from p(z ) can be decoded in a meaningful way .", "entities": []}, {"text": "The decoder p\u0012(xjz ) , also referred to as dec(z ) , is trained to reconstruct the input xbased on the latent variable z.", "entities": []}, {"text": "In order to approximate \u0012via gradient descent the reparametrization trick ( Kingma and Welling , 2013 ) was introduced .", "entities": []}, {"text": "This trick allows the gradient to \ufb02ow through non - deterministic zby separating the discrete sampling operation .", "entities": []}, {"text": "Let \u0016and\u001b be deterministic outputs of the encoder q\u0012(\u0016;\u001bjx ): z=\u0016+\u001b \f \u000fwhere\u000f\u0018N(0;I ) ( 1 ) and \f is the element - wise product .", "entities": []}, {"text": "To prevent the model from pushing \u001bclose to 0and thus falling back to a deterministic autoencoder , the objective is extended by the Kullback - Leibler ( KL ) diver-", "entities": [[15, 16, "MethodName", "autoencoder"]]}, {"text": "474gence between prior p(z)andq(zjx ): L(\u0012;x ) = \u0000KL(q\u0012(zjx)jjp(z ) )", "entities": []}, {"text": "+ Eq\u0012(zjx)[logp\u0012(xjz)]:(2 )", "entities": []}, {"text": "Bowman et al .", "entities": []}, {"text": "( 2016 ) apply this idea for sentence generation using an RNN as encoder and decoder .", "entities": []}, {"text": "They observe that a strong auto - regressive language modeling ability in the decoder reduces the information stored in the latent variable , right up to a complete collapse of the KL term .", "entities": []}, {"text": "They explore different techniques to weaken the decoder , like word dropout or KL term weight annealing , as possible solutions .", "entities": []}, {"text": "This guarantees a semantically rich latent variable and good sentence generation ability .", "entities": []}, {"text": "Below , we describe how to combine both techniques in order to generate meaningful queries for Membership Query Synthesis .", "entities": []}, {"text": "4 Active Learning Schedule We train a Variational Autoencoder on an unlabeled corpus of sentences .", "entities": [[1, 3, "TaskName", "Active Learning"], [7, 9, "MethodName", "Variational Autoencoder"]]}, {"text": "The text classi\ufb01cation task is performed on a binary sentiment dataset split into training , development and test set .", "entities": []}, {"text": "As depicted in Figure 2 , the sentences in the classi\ufb01cation dataset are vectorized using the V AE encoder which generates the latent variable zfor each sentencex .", "entities": [[17, 18, "MethodName", "AE"]]}, {"text": "This is done deterministically by dropping the\u001bterm in Equation 1 , further referred to asz = enc(x ) .", "entities": []}, {"text": "Next , a Learner is trained to \ufb01t a linear hyperplane to separate the positive from the negative instances .", "entities": []}, {"text": "We use the procedure described in x3.1 to select new query points for AL .", "entities": []}, {"text": "But instead of searching for the nearest neighbor in the pool , we decode the point x = dec(z)into a human readable sentence which is then handed over to the human annotator .", "entities": []}, {"text": "The annotator assigns a binary label to the instance and the next query point is calculated .", "entities": []}, {"text": "One important parameter for active learning determines how many new instances are to be selected in each AL iteration .", "entities": [[4, 6, "TaskName", "active learning"]]}, {"text": "Wang et al .", "entities": []}, {"text": "( 2015 ) use a prede\ufb01ned number of instances to be selected along the hyperplane .", "entities": []}, {"text": "Because we know that a Gaussian prior is imposed on the feature space , we instead stop the selection process when the magnitude of zsexceeds the expectation .", "entities": []}, {"text": "The expected distance of a point sampled from the k - dimensional Gaussian prior to the origin isq E [ \u001f 2 k ] = p k. Then the schedule restarts , learning a new decision boundary , and ultimately terFigure 2 : a)Instances in corpus are encoded to latent space .", "entities": []}, {"text": "b)Learner \ufb01ts a hyperplane to separate points .", "entities": []}, {"text": "c)Query points selected by method described in Fig.1 .", "entities": []}, {"text": "Decoder translates point in latent space to human readable sequence .", "entities": []}, {"text": "Annotator chooses label for instance .", "entities": []}, {"text": "minates when the annotation budget is exhausted .", "entities": []}, {"text": "We refer to this method as genwang .", "entities": []}, {"text": "When nearest neighbor search is used instead , we refer to the selection method as nnwang .", "entities": []}, {"text": "In addition , we explore a method , genuniform , where step b ) in Figure 1 is reduced to generating only one midperpendicular vector with a magnitude drawn from a uniform distribution .", "entities": []}, {"text": "In each iteration this vector will point to a random direction with a different magnitude , selecting diverse points close to the hyperplane .", "entities": []}, {"text": "The maximum magnitude is set in a way that the resulting point is not further away thanp kfrom the origin .", "entities": []}, {"text": "Similar to above we refer to this method as nnuniform when using nearest neighbor search .", "entities": []}, {"text": "The number of possible directions along the hyperplane grows with the size of the latent variable .", "entities": []}, {"text": "With this modi\ufb01cation we expect to explore more diverse points than following the same direction for several steps .", "entities": []}, {"text": "5 Experiments In this section we want to explore how the ability to generate human readable sentences from arbitrary points in the feature space affects active learning performance .", "entities": [[25, 27, "TaskName", "active learning"]]}, {"text": "We compare our approach to a number of baselines ( x5.3 ) , where in each experiment we select / generate 500 instances , present them to a human annotator to get a label and evaluate the performance of each setting in a sentiment classi\ufb01cation task .", "entities": []}, {"text": "We start the active learning process with two utterances in the seed set , namely \u2019 good movie \u2019 and \u2019 bad movie \u2019 .", "entities": [[3, 5, "TaskName", "active learning"]]}, {"text": "The classi\ufb01er is trained to separate instances with positive sentiment from negative ones .", "entities": []}, {"text": "The human anno-", "entities": []}, {"text": "475Parameter Value vocabulary size 20.000 RNN cell size 512 embedding size 512 latent variable size 50 dropout 0.3 dropword 0.5 learning rate 0.005 epochs 20 Table 1 : Training parameters for the Variational Autoencoder .", "entities": [[20, 22, "HyperparameterName", "learning rate"], [32, 34, "MethodName", "Variational Autoencoder"]]}, {"text": "tator can skip neutral or uninterpretable instances .", "entities": []}, {"text": "These skip actions also count towards the annotation budget .", "entities": []}, {"text": "5.1 Data The data used in our experiments comes from two sources , ( i ) the SST2 ( Socher et al . , 2013 ) and ( ii ) SAR14 ( Nguyen et al . , 2014 ) .", "entities": [[17, 18, "DatasetName", "SST2"]]}, {"text": "We limit sentence length to a maximum of 15 words .", "entities": []}, {"text": "This is motivated by lower training times and the tendency of vanilla V AEs not to perform well on longer sentences ( Shen et al . , 2019 ) .", "entities": []}, {"text": "Sentiment task SST2 ( Socher et al . , 2013 ) is a binary sentiment classi\ufb01cation dataset compiled from rottentomatoes.com .", "entities": [[2, 3, "DatasetName", "SST2"]]}, {"text": "As we only consider sentences with up to 15 words , the sizes of the training , development and test sets are 3103 , 380 and 814 instances , respectively .", "entities": []}, {"text": "Sentence pool The active learning pool consists of 1.2 M unique sentences from the SAR14 dataset ( Nguyen et al . , 2014 ) .", "entities": [[3, 5, "TaskName", "active learning"]]}, {"text": "SAR14 contains 234k movie reviews from IMDB .", "entities": [[6, 7, "DatasetName", "IMDB"]]}, {"text": "The data is annotated on review level , which prevents us from removing single neutral sentences .", "entities": []}, {"text": "Although the datasets stem from different sources , there is a small overlap .", "entities": []}, {"text": "These sentences are removed from the pool .", "entities": []}, {"text": "5.2 Training Variational Autoencoder Table 1 lists the parameter used for the V AE .", "entities": [[2, 4, "MethodName", "Variational Autoencoder"], [13, 14, "MethodName", "AE"]]}, {"text": "For training we limit the vocabulary of the V AE to the top 20k words .", "entities": [[9, 10, "MethodName", "AE"]]}, {"text": "Encoder and decoder RNN have layer normalized ( Ba et al . , 2016 )", "entities": []}, {"text": "LSTM cells ( Hochreiter and Schmidhuber , 1997 ) with size 512 .", "entities": [[0, 1, "MethodName", "LSTM"]]}, {"text": "As additional regularization we set weight dropout to 0.3 ( Srivastava et al . , 2014 ) .", "entities": []}, {"text": "Input embeddings are also of size 512 , which allows us to share the embed - ding weights with the softmax weights of the output layer ( Press and Wolf , 2016 ) .", "entities": [[20, 21, "MethodName", "softmax"]]}, {"text": "To prevent posterior collapse we use logistic annealing of the KL term weight and weaken the decoder by applying word dropout with probability 0.5 ( Bowman et al . , 2016 ) .", "entities": []}, {"text": "The model is trained using the Adam optimizer ( Kingma and Ba , 2014 ) with an initial learning rate of 0.005 .", "entities": [[6, 7, "MethodName", "Adam"], [7, 8, "HyperparameterName", "optimizer"], [18, 20, "HyperparameterName", "learning rate"]]}, {"text": "Once the KL term weight is close to 1 , the learning weight is linearly decreased to 0 .", "entities": [[17, 18, "DatasetName", "0"]]}, {"text": "The training stops after 20 epochs and the latent variable zhask= 50 dimensions .", "entities": []}, {"text": "The trained V AE achieves a reconstruction loss of 45.3 and KL divergence of 13.2 on the SST2 training set .", "entities": [[3, 4, "MethodName", "AE"], [7, 8, "MetricName", "loss"], [17, 18, "DatasetName", "SST2"]]}, {"text": "Learner The Learner is an SVM1with linear kernel .", "entities": []}, {"text": "Each instance is represented as the latent variablezlearned by the autoencoder .", "entities": [[10, 11, "MethodName", "autoencoder"]]}, {"text": "The latent variable is a vector with 50 dimensions and the SVM is trained on this representation .", "entities": [[11, 12, "MethodName", "SVM"]]}, {"text": "We calculate classi\ufb01cation performance on the reduced SST2 test set and report F1 - scores .", "entities": [[7, 8, "DatasetName", "SST2"], [12, 13, "MetricName", "F1"]]}, {"text": "Generator The generator is the decoder of the V AE described above .", "entities": [[9, 10, "MethodName", "AE"]]}, {"text": "Once a point zin feature space is selected , it is used as the input of the decoderx = dec(z)which generates the human readable sentence", "entities": []}, {"text": "xin an autoregressive way .", "entities": []}, {"text": "5.3 Baselines We compare our approach to Membership Query Synthesis for text classi\ufb01cation to four baselines .", "entities": []}, {"text": "The \ufb01rst baseline selects instances from the pool byrandom choice .", "entities": []}, {"text": "The least con\ufb01dence baseline computes the distance of the instances in the pool to the separating hyperplane and chooses the one closest to the hyperplane .", "entities": []}, {"text": "The third and fourth baseline follow the procedure described in x4 but search for the nearest neighbor ( nnuniform , nnwang ) instead of synthesising the exact query point .", "entities": []}, {"text": "Nearest neighbor is de\ufb01ned by the minimal euclidean distance between the query point and the latent representation of the pool instance .", "entities": []}, {"text": "5.4 Annotation The instances selected or generated by any model or baseline are annotated manually by one human coder.2Although the pool data has labels on the review level , we do not use these labels in our experiments .", "entities": []}, {"text": "Positive reviews can include negative 1https://scikit-learn.org/stable/ modules / generated / sklearn.svm .", "entities": []}, {"text": "SVC.html 2The \ufb01rst author of this paper .", "entities": []}, {"text": "476 Figure 3 : F1 - Score as a function of annotation steps ( including skipped queries ) .", "entities": [[4, 7, "MetricName", "F1 - Score"]]}, {"text": "Averaged over 3 runs .", "entities": []}, {"text": "sentences and vice versa .", "entities": []}, {"text": "This means that using document - level labels would introduce noise and might impair the baselines .", "entities": []}, {"text": "During each of the three experimental runs , all models and baselines are annotated simultaneously by the same person .", "entities": []}, {"text": "The annotator is presented with one instance at a time and has no information which of the models has produced each particular instance .", "entities": []}, {"text": "Once a label is selected , it is transmitted to the corresponding model and triggers the selection / generation of the next instance .", "entities": []}, {"text": "Thus , at any given time there is one unlabeled instance for each model or baseline .", "entities": []}, {"text": "From this set of unlabeled instances , one instance is chosen randomly and presented to the annotator .", "entities": []}, {"text": "This procedure is repeated until 500 instances are labeled for each model or baseline .", "entities": []}, {"text": "Hiding the instance source from the annotator is intended to prevent any bias during the annotation process .", "entities": []}, {"text": "6 Results and Analysis 6.1 Classi\ufb01cation Performance F - scores as a function of annotated instances Figure 3 shows learning curves for the different AL strategies and baselines as a function of the number of annotation instances added to the training data .", "entities": []}, {"text": "The random andleast conf baselines perform reasonably well .", "entities": []}, {"text": "Least conf struggles in the beginning , likely attributed to the minimal seed set .", "entities": []}, {"text": "Once enough instances are labeled it catches up .", "entities": []}, {"text": "Gen uniform has a strong start but , after around 200 instances , is outperformed by the nearest neighbor approaches which yield the highest F1 - scores .", "entities": [[24, 25, "MetricName", "F1"]]}, {"text": "Among the nearest neighbor approaches , the uniform schedule ranks better than wang .", "entities": []}, {"text": "The same behaviour is observed for the generation methods , although genwang produces Figure 4 : F1 - scores as a function of annotation time .", "entities": [[16, 17, "MetricName", "F1"]]}, {"text": "Results averaged over 3 runs .", "entities": []}, {"text": "the worst results overall .", "entities": []}, {"text": "Overall , genuniform is competitive with respect to F1 - scores and shows that sentences generated from points in the feature space are informative and useful for training a text classi\ufb01er .", "entities": [[8, 9, "MetricName", "F1"]]}, {"text": "F - scores as a function of annotation time AL simulations have often been criticized for reporting unrealistic results , based merely on the number of annotated instances ( see , e.g. , Settles ( 2009 ) , pp .", "entities": []}, {"text": "37 ff . ) .", "entities": []}, {"text": "It is well known , however , that the number of annotated instances is often not a good predictor for the real annotation costs .", "entities": []}, {"text": "AL strategies tend to select the hard nuts for human annotators and it is not unreasonable to assume that the annotation of Ninstances in an AL setup might take longer and thus might be more expensive than annotating the same number of randomly selected instances .", "entities": []}, {"text": "Therefore , we also show learning curves as a function of annotation time ( Figure 4 ) .", "entities": []}, {"text": "The results show a clear advantage for the generation models .", "entities": []}, {"text": "The reduction in annotation time is due to shorter query length and less neutral or noisy instances , as shown in Table 2 .", "entities": []}, {"text": "This speeds up the annotation by a signi\ufb01cant margin while providing the Learner with informative instances , despite their short length .", "entities": []}, {"text": "Figure 5 shows that the length of generated instances increase over time and further exploration also hints that the generated length is correlated with the length of the sentences in the seed set .", "entities": []}, {"text": "As listed in Table 2 , the random baseline reveals that 36.8 percent of sentences in the pool are neutral / artifacts and positive sentences outweigh negative ones by a factor of 2.6 .", "entities": []}, {"text": "This means that random sampling results in unbalanced datasets with far more positive examples .", "entities": []}, {"text": "Our generation", "entities": []}, {"text": "477 Figure 5 : Development of average length of selected / generated instances as more instances are annotated .", "entities": []}, {"text": "method does not show this disadvantage .", "entities": []}, {"text": "In contrast , the generated instances maintain a more balanced distribution of class labels and are less likely to be skipped .", "entities": []}, {"text": "These are indicators that the selected points are close to the hyperplane and the V AE is able to generate coherent and highly informative sentences from them .", "entities": [[15, 16, "MethodName", "AE"]]}, {"text": "6.2 Computational Complexity To assure a seamless annotation procedure , the supply of new instances has to be reasonably fast .", "entities": []}, {"text": "The generation and selection of the next instance is dependant on the label of the previous instance .", "entities": []}, {"text": "Because of this , there is no way to pre - fetch the next instance in the background and the annotator has to wait for the selection / generation process to \ufb01nish before the next instance is presented for annotation .", "entities": []}, {"text": "However , the runtime for pool - based AL methods is increasing with the pool \u2019s size .", "entities": []}, {"text": "In contrast , the generation method presented in this work does not have this limitation .", "entities": []}, {"text": "Theleast con\ufb01dence baseline has a complexity ofO(n)wherenis the number of instances in the pool .", "entities": []}, {"text": "The complexity of nearest neighbor search without any approximation techniques like preclustering is alsoO(n ) .", "entities": []}, {"text": "Query generation from an exact point with the decoder has a complexity ofO(m)wheremis the length of the sentence and n>>m .", "entities": []}, {"text": "Because sentences have a natural length limit and in this work are capped to 15 words , one could argue that the complexity is O(1 ) .", "entities": []}, {"text": "6.3 Generated Instances Table 3 shows examples of generated instances using the genuniform method .", "entities": []}, {"text": "Example 1 - 6 show% skips M sec M len", "entities": []}, {"text": "p / n genuniform 28.1 1.4 4 1.7 genwang 20.9 1.9 5 1.2 nnuniform 34.2 4.1 9 1.9 nnwang 35.8 4.1 10 2.4 least conf 39.0 4.2 10 2.1 random 36.8 4.1 9 2.6 Table 2 : Percentage of skips ( neutral or noisy sentences ) ; Median annotation time in seconds ; Median number of words in query ; Ratio of positive to negative labels .", "entities": []}, {"text": "prototypical positive and negative instances .", "entities": []}, {"text": "Example 7 is ambiguous , caused by the decoder generating an unknown ( UNK ) token at the position where one would normally expect an evaluative adjective .", "entities": []}, {"text": "We see this as an indicator that the point is positioned close to the hyperplane and thus the sentiment of the latent variable is ambiguous .", "entities": []}, {"text": "We also observe instances with UNK token which still express a sentiment , as seen in Example 8 an 9 .", "entities": []}, {"text": "This can be interpreted as a placeholder for a named entity or , in other cases , a speci\ufb01er like movie genre and does not impact the annotation process .", "entities": []}, {"text": "To explore the ability of the model to generate unseen instances we calculate the percentage of instances not seen in the pool .", "entities": []}, {"text": "We only look at instances with an annotated sentiment label , because skipped examples often include noise and thus are unlikely to be present in the pool .", "entities": []}, {"text": "41 and 51 percent of labeled instances are newly generated by genuniform andgenwang respectively .", "entities": []}, {"text": "This provides more evidence that the model is capable of generating new and informative instances .", "entities": []}, {"text": "No . Instance Label 1 .", "entities": []}, {"text": "the acting is excellent 1 2 . powerful and moving 1 3 .", "entities": []}, {"text": "this movie is very enjoyable 1 4 .", "entities": []}, {"text": "a complete mess 0 5 . nothing spectacular 0 6 . absolutely terrible !", "entities": [[3, 4, "DatasetName", "0"], [8, 9, "DatasetName", "0"]]}, {"text": "0", "entities": [[0, 1, "DatasetName", "0"]]}, {"text": "7 . the plot is UNK skip 8 .", "entities": []}, {"text": "well done by UNK 1 9 .", "entities": []}, {"text": "the UNK is a disappointment 0 Table 3 : Example instances generated by genuniform .", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "Label 1 for positive and 0 for negative class .", "entities": [[5, 6, "DatasetName", "0"]]}, {"text": "478 Figure 6 : Plot of the 2 most important dimensions of selected / generated instances in latent space .", "entities": []}, {"text": "Gray points indicate negative , black points positive labels .", "entities": []}, {"text": "The blue square denotes \u2019 bad movie \u2019 and the red cross \u2019 good movie \u2019 .", "entities": []}, {"text": "6.4 Latent Space To further analyze the behavior of the different AL strategies , we apply dimensionality reduction and visualize the instances in latent space ( Figure 6 ) .", "entities": [[16, 18, "TaskName", "dimensionality reduction"]]}, {"text": "The two largest absolute coef\ufb01cients of the trained SVM \u2019s linear kernel identify the most important dimensions .", "entities": [[8, 9, "MethodName", "SVM"]]}, {"text": "Figure 6 plots the points , represented by theses two dimensions , selected by different active learning schedules .", "entities": [[15, 17, "TaskName", "active learning"]]}, {"text": "The generated instances lie densely around the seed points , while pool instances are more distributed .", "entities": []}, {"text": "In genwang one can see how the instances are loosely following one direction similar to Figure1 .", "entities": []}, {"text": "As indicated in Figure 2 a pool instance is represented as z = enc(x ) .", "entities": []}, {"text": "The same is true for the instances in the development , test and seed set .", "entities": []}, {"text": "For the generated instances there are two options .", "entities": []}, {"text": "Ifzis a point selected in feature space and x = dec(z)is the decoded query sequence , the annotated instance can either be represented as zor as^z = enc(x ) .", "entities": []}, {"text": "In a perfect V AE zand^zshould be nearly identical .", "entities": [[4, 5, "MethodName", "AE"]]}, {"text": "In practice however ^zends up at a different location in feature space .", "entities": []}, {"text": "Figure 7 depicts the distribution of distances between zand^zgenerated with the genuniform method .", "entities": []}, {"text": "We observe that models trained on ^zperform better than those trained on z , presumably because the test instances are represented the same way .", "entities": []}, {"text": "To evaluate if ^zis still an informative point and not just positioned randomly in feature space , we train a model on actual randomly sampled points .", "entities": []}, {"text": "The sampled point z\u0018 N ( 0;I)is decoded to query sequence x , labeled and subsequently reFigure 7 : Distribution of euclidean distances between zbefore and ^zafter re - encoding during genuniform . encoded to ^z = enc(x ) .", "entities": []}, {"text": "With the same amount of instances , this model performs much worse than genuniform , indicating that point ^zstill preserves some of the informativeness of z. We thus assume that the closer ^zis to selected point z , the better the generation based active learning schedules will work .", "entities": [[43, 45, "TaskName", "active learning"]]}, {"text": "7 Discussion Related work in the context of semi - supervised learning has focused on developing methods to generate synthetic training instances for different tasks ( Sennrich et al . , 2016 ; Hayashi et al . , 2018 ; Alberti et al . , 2019 ;", "entities": []}, {"text": "Winata et", "entities": []}, {"text": "al . , 2019 ) , in order to accelerate the learning process .", "entities": []}, {"text": "Sennrich et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2016 ) create arti\ufb01cial training instances for machine translation , using monolingual data paired with automatic back - translations .", "entities": [[8, 10, "TaskName", "machine translation"]]}, {"text": "Their work obtains substantial improvements for several languages and has triggered many follow - up studies that apply the idea of back - translation to different tasks .", "entities": []}, {"text": "For example , Hayashi et al .", "entities": []}, {"text": "( 2018 ) augment the training data for attention - based end - to - end automatic speech recognition with synthetic instances , and Winata et", "entities": [[16, 19, "TaskName", "automatic speech recognition"]]}, {"text": "al .", "entities": []}, {"text": "( 2019 ) generate arti\ufb01cial training examples to improve automatic speech recognition on code - switching material .", "entities": [[9, 12, "TaskName", "automatic speech recognition"]]}, {"text": "Alberti et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2019 ) use a large number of synthetic instances to pre - train a Question Answering ( QA ) model that is then \ufb01ne - tuned on the target QA dataset .", "entities": [[15, 17, "TaskName", "Question Answering"]]}, {"text": "Their approach results in signi\ufb01cant improvements over models that are trained without the synthetic datapoints .", "entities": []}, {"text": "While these studies show that huge amounts of synthetic training data can crucially improve the", "entities": []}, {"text": "479learning process , our approach uses a different paradigm .", "entities": []}, {"text": "Instead of generating millions of synthetic data points , our method is data - lean and only needs a few hundred instances to improve the classi\ufb01er .", "entities": []}, {"text": "Another difference is that we do not rely on automatically generated labels but use human annotations instead .", "entities": []}, {"text": "Due to the practical constraints of the active learning process , we need to keep the training time short enough so that the human annotator does not have to wait for the next set of instances to annotate .", "entities": [[7, 9, "TaskName", "active learning"]]}, {"text": "This rules out the use of computation - intensive models and large training sets .", "entities": []}, {"text": "Given that we use an SVM for classi\ufb01cation , we do not expect a strong effect for adding large numbers of additional training instances , given that the majority of those data points will not be positioned close to the decision boundary .", "entities": [[5, 6, "MethodName", "SVM"]]}, {"text": "One of the main drawbacks of our work is its limitation to binary sentence classi\ufb01cation .", "entities": []}, {"text": "However , multi - class classi\ufb01cation in an one - vs - rest schema is compatible with our method and worth further exploration .", "entities": []}, {"text": "Another interesting direction for future work is the synthesis of data for more complex tasks like Natural Language Inference ( NLI ) or QA .", "entities": [[16, 19, "TaskName", "Natural Language Inference"]]}, {"text": "This , however , requires modi\ufb01cations to the structure of the autoencoder and exceeds the scope of this work .", "entities": [[11, 12, "MethodName", "autoencoder"]]}, {"text": "Membership Query Synthesis might also be an interesting approach for tasks where the automatic extraction of large amounts of unlabelled data is not straight - forward .", "entities": []}, {"text": "One example that comes to mind is the detection of offensive language or \u2019 hate speech \u2019 , where we have to deal with highly unbalanced training sets with only a small number of positive instances , and attempts to increase this number have been shown to result in systematically biased datasets ( Davidson et al . , 2019 ; Wiegand et al . , 2019 ) .", "entities": [[14, 16, "DatasetName", "hate speech"]]}, {"text": "Table 2 suggests that the generator produces instances with a more balanced class ratio ( 1.7 and 1.2 ) than the pool data ( 2.6 ) it was trained on .", "entities": []}, {"text": "It might be worthwhile to explore whether the generation of synthetic training instances can help to mitigate the problem to select instances from both classes in an highly imbalanced data pool .", "entities": []}, {"text": "8 Conclusion This work is the \ufb01rst to show that Membership Query Synthesis in an NLP setting is feasible .", "entities": []}, {"text": "Our approach uses a Variational Autoencoder as a representation learner and generates informative ac - tive learning queries from latent space .", "entities": [[4, 6, "MethodName", "Variational Autoencoder"]]}, {"text": "The classi\ufb01cation performance for the generated instances is competitive with pool - based active learning strategies and outperforms other AL strategies with regard to annotation cost ( time ) and computational complexity .", "entities": [[13, 15, "TaskName", "active learning"]]}, {"text": "The main advantage of Membership Query Synthesis for active learning is that it allows us to target speci\ufb01c points along the separating hyperplane and thus to provide the classi\ufb01er with information on speci\ufb01c areas of uncertainty in the data space .", "entities": [[8, 10, "TaskName", "active learning"]]}, {"text": "While pool - based active learning has the same objective , Membership Query Synthesis gives us a more precise tool to explore the data space and to generate exactly those instances that we need , making MQS a promising approach for future work in active learning .", "entities": [[4, 6, "TaskName", "active learning"], [44, 46, "TaskName", "active learning"]]}, {"text": "Acknowledgments Part of this research has been conducted within the Leibniz Science Campus \u201c Empirical Linguistics and Computational Modeling \u201d , funded by the Leibniz Association under grant no .", "entities": []}, {"text": "SAS-2015IDS - LWC and by the Ministry of Science , Research , and Art ( MWK ) of the state of BadenW\u00a8urttemberg .", "entities": []}, {"text": "References Chris Alberti , Daniel Andor , Emily Pitler , Jacob Devlin , and Michael Collins .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Synthetic QA corpora generation with roundtrip consistency .", "entities": []}, {"text": "In The 57th Conference of the Association for Computational Linguistics , ACL 2019 , pages 6168\u20136173 .", "entities": []}, {"text": "Dana Angluin .", "entities": []}, {"text": "1988 .", "entities": []}, {"text": "Queries and concept learning .", "entities": []}, {"text": "Machine Learning , 2(4):319\u2013342 .", "entities": []}, {"text": "Pranjal Awasthi and Varun Kanade .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Learning using local membership queries under smooth distributions .", "entities": []}, {"text": "CoRR , abs/1211.0996 .", "entities": []}, {"text": "Lei Jimmy Ba , Ryan Kiros , and Geoffrey E. Hinton .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Layer normalization .", "entities": [[0, 2, "MethodName", "Layer normalization"]]}, {"text": "CoRR , abs/1607.06450 .", "entities": []}, {"text": "Samuel R. Bowman , Luke Vilnis , Oriol Vinyals , Andrew Dai , Rafal Jozefowicz , and Samy Bengio .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Generating sentences from a continuous space .", "entities": []}, {"text": "In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning , pages 10\u201321 , Berlin , Germany .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Alexis Conneau , Douwe Kiela , Holger Schwenk , Lo\u00a8\u0131c Barrault , and Antoine Bordes .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Supervised learning of universal sentence representations from natural language inference data .", "entities": [[7, 10, "TaskName", "natural language inference"]]}, {"text": "CoRR , abs/1705.02364 .", "entities": []}, {"text": "480Thomas Davidson , Debasmita Bhattacharya , and Ingmar Weber .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Racial bias in hate speech and abusive language detection datasets .", "entities": [[3, 5, "DatasetName", "hate speech"], [6, 8, "TaskName", "abusive language"]]}, {"text": "In The Third Workshop on Abusive Language Online , pages 25 \u2013 35 .", "entities": [[5, 7, "TaskName", "Abusive Language"]]}, {"text": "Ian Goodfellow , Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron Courville , and Yoshua Bengio .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Generative adversarial nets .", "entities": []}, {"text": "In Z. Ghahramani , M. Welling , C. Cortes , N. D. Lawrence , and K. Q. Weinberger , editors , Advances in Neural Information Processing Systems 27 , pages 2672\u20132680 .", "entities": []}, {"text": "Curran Associates , Inc.", "entities": []}, {"text": "Tomoki Hayashi , Shinji Watanabe , Yu Zhang , Tomoki Toda , Takaaki Hori , Ram \u00b4 on Fern \u00b4 andez Astudillo , and Kazuya Takeda . 2018 .", "entities": []}, {"text": "Back - translation - style data augmentation for end - to - end ASR .", "entities": [[5, 7, "TaskName", "data augmentation"]]}, {"text": "In 2018 IEEE Spoken Language Technology Workshop , SLT 2018 , pages 426\u2013433 .", "entities": []}, {"text": "Sepp Hochreiter and J \u00a8urgen Schmidhuber .", "entities": []}, {"text": "1997 .", "entities": []}, {"text": "Long short - term memory .", "entities": [[0, 5, "MethodName", "Long short - term memory"]]}, {"text": "Neural Comput . , 9(8):1735 \u2013 1780 .", "entities": []}, {"text": "Zhiting Hu , Zichao Yang , Xiaodan Liang , Ruslan Salakhutdinov , and Eric P. Xing . 2017 .", "entities": [[9, 10, "DatasetName", "Ruslan"]]}, {"text": "Controllable text generation .", "entities": [[1, 3, "TaskName", "text generation"]]}, {"text": "CoRR , abs/1703.00955 .", "entities": []}, {"text": "Miriam W. Huijser and Jan C. van Gemert . 2017 .", "entities": []}, {"text": "Active decision boundary annotation with deep generative models .", "entities": []}, {"text": "CoRR , abs/1703.06971 .", "entities": []}, {"text": "Diederik P. Kingma and Jimmy Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "CoRR , abs/1412.6980 .", "entities": []}, {"text": "Diederik P. Kingma , Danilo Jimenez Rezende , Shakir Mohamed , and Max Welling .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Semisupervised learning with deep generative models .", "entities": []}, {"text": "CoRR , abs/1406.5298 .", "entities": []}, {"text": "Diederik P. Kingma and Max Welling .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Autoencoding variational bayes .", "entities": []}, {"text": "CoRR , abs/1312.6114 .", "entities": []}, {"text": "Ryan Kiros , Yukun Zhu , Ruslan Salakhutdinov , Richard S. Zemel , Antonio Torralba , Raquel Urtasun , and Sanja Fidler .", "entities": [[6, 7, "DatasetName", "Ruslan"]]}, {"text": "2015 .", "entities": []}, {"text": "Skip - thought vectors .", "entities": []}, {"text": "CoRR , abs/1506.06726 .", "entities": []}, {"text": "Kevin Lang and Eric Baum . 1992 .", "entities": []}, {"text": "Query learning can work poorly when a human oracle is used .", "entities": []}, {"text": "IEEE Intl .", "entities": []}, {"text": "JointConference on Neural Networks .", "entities": []}, {"text": "Charles X. Ling and Jun Du . 2008 .", "entities": []}, {"text": "Active learning with direct query construction .", "entities": [[0, 2, "TaskName", "Active learning"]]}, {"text": "In The 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD \u2019 08 , pages 480 \u2013 487 .", "entities": [[3, 4, "DatasetName", "ACM"]]}, {"text": "Arash Mehrjou , Mehran Khodabandeh , and Greg Mori . 2018 .", "entities": []}, {"text": "Distributionaware active learning .", "entities": [[1, 3, "TaskName", "active learning"]]}, {"text": "arXiv preprint , abs/1805.08916.Dai Quoc Nguyen , Dat Quoc Nguyen , Thanh Vu , and Son Bao Pham .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "2014 .", "entities": []}, {"text": "Sentiment classi\ufb01cation on polarity reviews : An empirical study using ratingbased features .", "entities": []}, {"text": "In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity , Sentiment and Social Media Analysis , pages 128\u2013135 .", "entities": []}, {"text": "Augustus Odena . 2016 .", "entities": []}, {"text": "Semi - supervised learning with generative adversarial networks .", "entities": []}, {"text": "CoRR , abs/1606.01583 .", "entities": []}, {"text": "O\ufb01r Press and Lior Wolf .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Using the output embedding to improve language models .", "entities": []}, {"text": "CoRR , abs/1608.05859 .", "entities": []}, {"text": "Alec Radford , Rafal J \u00b4 ozefowicz , and Ilya Sutskever . 2017 .", "entities": []}, {"text": "Learning to generate reviews and discovering sentiment .", "entities": []}, {"text": "CoRR , abs/1704.01444 .", "entities": []}, {"text": "Rico Sennrich , Barry Haddow , and Alexandra Birch . 2016 .", "entities": []}, {"text": "Improving neural machine translation models with monolingual data .", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "In The 54th Annual Meeting of the Association for Computational Linguistics , ACL 2016 .", "entities": []}, {"text": "Burr Settles .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Active learning literature survey .", "entities": [[0, 2, "TaskName", "Active learning"]]}, {"text": "Technical report , Computer Sciences Technical Report 1648 , University of Wisconsin - Madison .", "entities": [[11, 12, "DatasetName", "Wisconsin"]]}, {"text": "Dinghan Shen , Asli Celikyilmaz , Yizhe Zhang , Liqun Chen , Xin Wang , and Lawrence Carin .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Hierarchically - structured variational autoencoders for long text generation .", "entities": [[4, 5, "MethodName", "autoencoders"], [7, 9, "TaskName", "text generation"]]}, {"text": "Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D. Manning , Andrew Ng , and Christopher Potts . 2013 .", "entities": []}, {"text": "Recursive deep models for semantic compositionality over a sentiment treebank .", "entities": []}, {"text": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 1631\u20131642 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Nitish Srivastava , Geoffrey Hinton , Alex Krizhevsky , Ilya Sutskever , and Ruslan Salakhutdinov .", "entities": [[13, 14, "DatasetName", "Ruslan"]]}, {"text": "2014 .", "entities": []}, {"text": "Dropout : A simple way to prevent neural networks from over\ufb01tting .", "entities": [[0, 1, "MethodName", "Dropout"]]}, {"text": "J. Mach .", "entities": []}, {"text": "Learn .", "entities": []}, {"text": "Res . , 15(1):1929 \u2013 1958 .", "entities": []}, {"text": "Sandeep Subramanian , Adam Trischler , Yoshua Bengio , and Christopher J. Pal .", "entities": [[3, 4, "MethodName", "Adam"]]}, {"text": "2018 .", "entities": []}, {"text": "Learning general purpose distributed sentence representations via large scale multi - task learning .", "entities": [[9, 13, "TaskName", "multi - task learning"]]}, {"text": "CoRR , abs/1804.00079 .", "entities": []}, {"text": "Alex Wang , Amanpreet Singh , Julian Michael , Felix Hill , Omer Levy , and Samuel R. Bowman . 2019 .", "entities": []}, {"text": "GLUE :", "entities": [[0, 1, "DatasetName", "GLUE"]]}, {"text": "A multi - task benchmark and analysis platform for natural language understanding .", "entities": [[9, 12, "TaskName", "natural language understanding"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Liantao Wang , Xuelei Hu , bo Yuan , and Jianfeng Lu . 2015 .", "entities": []}, {"text": "Active learning via query synthesis and nearest neighbour search .", "entities": [[0, 2, "TaskName", "Active learning"]]}, {"text": "Neurocomputing , 147:426434 .", "entities": []}, {"text": "481Michael Wiegand , Josef Ruppenhofer , and Thomas Kleinbauer .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Detection of abusive language : the problem of biased datasets .", "entities": [[2, 4, "TaskName", "abusive language"]]}, {"text": "In The 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , NAACL - HLT 2019 , pages 602\u2013608 .", "entities": []}, {"text": "Genta Indra Winata , Andrea Madotto , Chien - Sheng Wu , and Pascale Fung .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Code - switched language models using neural based synthetic data from parallel sentences .", "entities": []}, {"text": "In The SIGNLL Conference on Computational Natural Language Learning , CoNLL 2019 .", "entities": []}, {"text": "Weidi Xu , Haoze Sun , Chao Deng , and Ying Tan . 2017 .", "entities": []}, {"text": "Variational autoencoder for semi - supervised text classi\ufb01cation .", "entities": [[0, 2, "MethodName", "Variational autoencoder"]]}, {"text": "In Thirty - First AAAI Conference on Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Jia - Jie Zhu and Jos \u00b4 e Bento . 2017 .", "entities": []}, {"text": "Generative adversarial active learning .", "entities": [[2, 4, "TaskName", "active learning"]]}, {"text": "CoRR , abs/1702.07956 .", "entities": []}]