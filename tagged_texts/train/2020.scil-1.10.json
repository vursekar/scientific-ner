[{"text": "Interpreting Verbal Irony : Linguistic Strategies and the Connection to the Type of Semantic Incongruity Debanjan Ghosh \u21e4 1 , Elena Musi2 , Kartikeya Upasani3 , Smaranda Muresan4 1McGovern Institute for Brain Research , MIT , Cambridge , MA 2University of Liverpool , Liverpool , UK 3Facebook Conversational AI , CA 4Data Science Institute , Columbia University , New York , NY dg513@mit.edu , elena.musi@liverpool.ac.uk , kart@fb.com , smara@columbia.edu", "entities": [[36, 37, "DatasetName", "Cambridge"]]}, {"text": "Abstract Human communication often involves the use of verbal irony or sarcasm , where the speakers usually mean the opposite of what they say .", "entities": []}, {"text": "To better understand how verbal irony is expressed by the speaker and interpreted by the hearer we conduct a crowdsourcing task : given an utterance expressing verbal irony , users are asked to verbalize their interpretation of the speaker \u2019s ironic message .", "entities": []}, {"text": "We propose a typology of linguistic strategies for verbal irony interpretation and link it to various theoretical linguistic frameworks .", "entities": []}, {"text": "We design computational models to capture these strategies and present empirical studies aimed to answer three questions : ( 1 ) what is the distribution of linguistic strategies used by hearers to interpret ironic messages ? ; ( 2 ) do hearers adopt similar strategies for interpreting the speaker \u2019s ironic intent ? ; and ( 3 ) does the type of semantic incongruity in the ironic message ( explicit vs. implicit ) in\ufb02uence the choice of interpretation strategies by the hearers ?", "entities": []}, {"text": "1 Introduction It is well understood that recognizing whether a speaker is ironic or sarcastic is essential to understanding their actual sentiments and beliefs .", "entities": []}, {"text": "For instance , the utterance \u201c pictures of holding animal carcasses are so \ufb02attering \u201d is an expression of verbal irony , where the speaker has a negative sentiment towards \u201c pictures of holding animal carcasses \u201d , but uses the positive sentiment word \u201c \ufb02attering \u201d .", "entities": []}, {"text": "This inherent characteristic of verbal irony is called semantic incongruity \u2014 incongruity between the literal evaluation and the context ( e.g. , between the positive sentiment words and the negative situation in this example ) .", "entities": []}, {"text": "Most NLP research on verbal irony or sarcasm has focused on the task of sarcasm detection treating \u21e4 Part of the research was carried out while Debanjan was a Ph.D. candidate at Rutgers University.it as a binary classi\ufb01cation task using either the utterance in isolation or adding contextual information such as conversation context , author context , visual context , or cognitive features ( Davidov et al . , 2010 ; Maynard and Greenwood , 2014 ; Wallace et", "entities": [[14, 16, "TaskName", "sarcasm detection"]]}, {"text": "al . , 2014 ; Joshi et al . , 2015 ; Bamman and Smith , 2015 ; Muresan et al . , 2016 ; Amir et", "entities": []}, {"text": "al . , 2016 ; Mishra et al . , 2016 ; Ghosh and Veale , 2017 ; Felbo et al . , 2017 ; Ghosh et al . , 2017 ; Hazarika et al . , 2018 ; Tay et", "entities": []}, {"text": "al . , 2018 ;", "entities": []}, {"text": "Ghosh et al . , 2018 ; Oprea and Magdy , 2019 ) .", "entities": []}, {"text": "Such approaches have focused their analysis on the speakers \u2019 beliefs and intentions for using irony ( Attardo , 2000 ) .", "entities": []}, {"text": "However , sarcasm and verbal irony are types of interactional phenomena with speci\ufb01c perlocutionary effects on the hearer ( Haverkate , 1990 ) .", "entities": []}, {"text": "Thus , we argue that , besides recognizing the speaker \u2019s sarcastic / ironic intent , it is equally important to understand how the hearer interprets the speaker \u2019s sarcastic / ironic message .", "entities": []}, {"text": "For the above utterance , the strength of negative sentiment perceived by the hearer depends on whether they interpret the speaker \u2019s actual meaning as \u201c picture . .", "entities": []}, {"text": ". are not \ufb02attering \u201d vs. \u201c pictures . .", "entities": []}, {"text": ". are so gross \u201d ( Table 1 ) .", "entities": []}, {"text": "The intensity of negative sentiment is higher in the latter interpretation than in the former .", "entities": []}, {"text": "Kreuz ( 2000 ) noted that most studies in linguistics and psychology have conducted experiments analyzing reaction times ( Gibbs , 1986 ; Katz et al . , 2004 ) or situational context ( Ivanko and Pexman , 2003 ) , featuring a setup with in vitro data aimed at testing the validity of speci\ufb01c theories of irony .", "entities": []}, {"text": "Instead , our study adopts a naturalistic approach to understand hearers \u2019 reception of irony looking at what linguistic strategies are recurrently used by hearers to interpret the non - literal meaning underlying ironic utterances .", "entities": []}, {"text": "We leverage the crowdsourcing task introduced byGhosh et al . ( 2015 ) for their work on detecting whether a word has a literal or sarcastic in-", "entities": []}, {"text": "terpretation , later adopted by Peled and Reichart ( 2017 ) .", "entities": []}, {"text": "The task is framed as follows : given a speaker \u2019s ironic message , \ufb01ve annotators ( e.g. , Turkers on Amazon Mechanical Turk ( MTurk ) ) are asked to verbalize their interpretation of the speaker \u2019s ironic message ( i.e. , their understanding of the speaker \u2019s intended meaning ) ( see Table1;Simdenotes the speaker \u2019s ironic message , while H intdenotes the hearer \u2019s interpretation of that ironic message ) .", "entities": []}, {"text": "The crowdsourcing experiments are reported in Section 2 .", "entities": []}, {"text": "The paper makes three contributions .", "entities": []}, {"text": "First , we propose a data - driven typology of linguistic strategies that hearers use to interpret ironic messages and discuss its relevance in verifying theoretical frameworks of irony ( Section 4 ) .", "entities": []}, {"text": "Second , we propose computational models to capture these strategies ( Section 5 ) .", "entities": []}, {"text": "Third , we present two studies that aim to answer two questions : ( 1 ) does the type of semantic incongruity in the ironic message ( explicit vs. implicit ; see Section 3 ) in\ufb02uence the choice of interpretation strategies by the hearers ?", "entities": []}, {"text": "( Section 6.2 ) ; ( 2 ) do interpretation strategies of verbal irony vary by hearers ?", "entities": []}, {"text": "We make all datasets and code available.1 2 Datasets of Speakers \u2019 Ironic Messages and Hearers \u2019 Interpretations To generate a parallel dataset of speakers \u2019 ironic messages and hearers \u2019 interpretations we conduct a crowdsourcing experiment .", "entities": []}, {"text": "Given a speaker \u2019s ironic message ( S i m ) , \ufb01ve Turkers ( hearers ) on MTurk are asked to verbalize their interpretation of the speaker \u2019s ironic message ( i.e. , their understanding of the speaker \u2019s intended meaning ) ( Hint ) .", "entities": []}, {"text": "The design of the MTurk task was \ufb01rst introduced by Ghosh et al . ( 2015 ) , who use the resulting dataset to identify words that can have both a literal and a sarcastic sense .", "entities": []}, {"text": "Peled and Reichart ( 2017 ) employed similar design to generate a parallel dataset to use for generating interpretations of sarcastic messages using machine translation approaches .", "entities": [[23, 25, "TaskName", "machine translation"]]}, {"text": "They use skilled annotators in comedy writing and literature paraphrasing and give them the option not to rephrase ( we refer to Peled and Reichart ( 2017 ) \u2019s dataset as SIGN ) .", "entities": []}, {"text": "We perform this new crowdsourcing task and do not rely entirely on the above two datasets for two reasons : ( 1 ) we focus on verbal irony , and ( 2 ) we always require an interpretation from the Turkers .", "entities": []}, {"text": "Un1https://github.com/debanjanghosh/interpreting verbal ironylike the above two studies , the main goal of our research is to analyze the linguistics strategies employed by hearers in interpreting verbal irony .", "entities": []}, {"text": "We collected messages that express verbal irony from Twitter using the hashtags # irony , # sarcastic , and # sarcasm .", "entities": []}, {"text": "We chose Twitter as a source since the presence of the hashtags allows us to select sentences where the speaker \u2019s intention was to be ironic .", "entities": []}, {"text": "Furthermore , even though Twitter users can not be considered representative of the entire population , they are unlikely to be skewed with respect to topics or gender .", "entities": []}, {"text": "We manually checked and kept 1,000 tweets that express verbal irony .", "entities": []}, {"text": "We do not draw any theoretical distinction between sarcasm and irony since we can not assume that Twitter users also differentiate between # irony and # sarcasm , blurred even in scholarly literature .", "entities": []}, {"text": "The Turkers were provided with detailed instructions and examples of the task including the standard de\ufb01nition of verbal irony taken from the Merriam - Webster dictionary ( \u201c use of words to express something other than and especially the opposite of the literal meaning \u201d ) .", "entities": []}, {"text": "We decided to suggest them a guiding de\ufb01nition for two reasons .", "entities": []}, {"text": "First , hearers do not usually focus on literal vs. non literal meaning , as shown by studies measuring processing times for both types of statements ( Inhoff et al . , 1984 ) .", "entities": []}, {"text": "Therefore , when asked to rephrase the speakers \u2019 intended meaning , hearers would have probably come up with sentences expressing the speaker \u2019s imagined discursive goals , rather than disclosing their perceived literal meaning .", "entities": []}, {"text": "Second , it is reasonable to assume that Turkers would have looked up the standard meaning of ironic utterance given by an online dictionary to ease up their task , possibly coming up with biased de\ufb01nitions .", "entities": []}, {"text": "The Turkers were instructed to consider the entire message in their verbalization to avoid asymmetry in length between the S imand H int .", "entities": []}, {"text": "W e obtained a dataset of 5,000 S im - Hintpairs where \ufb01ve Turkers rephrase each S", "entities": []}, {"text": "i m.", "entities": []}, {"text": "A total of 184 Turkers participated in the rephrasing task .", "entities": []}, {"text": "Table1shows examples of speaker \u2019s ironic messages ( Sim ) and their corresponding hearers \u2019 interpretations ( Hi int ) .", "entities": []}, {"text": "Next , we ran a second MTurk task to verify whether the generated H intmessages are plausible interpretations of the ironic messages .", "entities": []}, {"text": "This time we employ three Turkers per task and only Turkers who were not involved in the content generation task were allowed to perform this", "entities": []}, {"text": "Sim H1 int H2 int H3 int 1 .", "entities": []}, {"text": "Ed Davey is such a passionate , inspiring speakerEd Davey is a boring , uninspiring speakerEd Davey is such a dull , monotonous speakerEd Davey is not a passionate , inspiring speaker 2 . ca n\u2019t believe how much captain America looks like meI wish I looked like Captain America .", "entities": []}, {"text": "I need to lose weightscan\u2019t believe how much captain America looks different from meI do n\u2019t , but I wish I looked like Captain America 3 .", "entities": []}, {"text": "Pictures of you holding dead animal carcasses are so \ufb02atteringHate hunting season and the pictures of you holding dead animal are so grossPictures of you holding dead animal carcasses is an un\ufb02attering lookPictures of you holding dead animal carcasses are not \ufb02attering Table 1 : Examples of speaker \u2019s ironic messages ( S i m ) and interpretations given by 3 Turkers ( Hi int ) .", "entities": []}, {"text": "task .", "entities": []}, {"text": "We observe that Turkers labeled 5 % ( i.e. , 238 verbalizations ) of H ints as invalid and low quality ( e.g. , wrong interpretation ) .", "entities": []}, {"text": "For both tasks , we allowed only quali\ufb01ed Turkers ( i.e. , at least 95 % approval rate and 5,000 approved HITs ) , paid 7 cents / task and gave sixty minutes to complete each task .", "entities": []}, {"text": "The \ufb01nal dataset contains 4,762 pairs S imHint .", "entities": []}, {"text": "3 Semantic Incongruity in Ironic Messages : Explicit vs. Implicit Attardo ( 2000 ) and later Burgers ( 2010 ) distinguish between two theoretical aspects of irony : irony markers andirony factors .", "entities": []}, {"text": "Irony markers are meta - communicative signals , such as interjections or emoticons that alert the reader that an utterance might be ironic .", "entities": []}, {"text": "In contrast , irony factors can not be removed without destroying the irony , such as the incongruity between the literal evaluation and its context ( \u201c semantic incongruity \u201d ) .", "entities": []}, {"text": "Incongruity expresses the contrast between the conveyed sentiment ( usually , positive ) and the targeted situation ( usually , negative ) .", "entities": []}, {"text": "This contrast can be explicitly or implicitly expressed in the ironic message .", "entities": []}, {"text": "Following Karoui et al .", "entities": []}, {"text": "( 2017 ) , we consider that semantic incongruity is explicit , when it is lexicalized in the utterance itself ( e.g. , both the positive sentiment word(s ) and the negative situation are available to the reader explicitly ) .", "entities": []}, {"text": "On Twitter , beside sentiment words , users often make use of hashtags ( e.g. , \u201c Studying 5 subjects . . .", "entities": []}, {"text": "# worstsaturdaynight \u201d ) or an image ( e.g. , \u201c Encouraging how Police feel they \u2019re above the law .", "entities": []}, {"text": "URL \u201d", "entities": []}, {"text": "; the URL shows a police car not paying parking ) to express their sentiment .", "entities": []}, {"text": "We consider these cases as explicit , since the incongruity is present in the utterance even if via hashtags or other media .", "entities": []}, {"text": "For implicit incongruity , we consider cases where one of the two incongruent terms ( \u201c propositions \u201d in Karoui et", "entities": []}, {"text": "al . ( 2017 ) ) is not lexicalized and has to be reconstructed from the con - text ( either outside word knowledge or a larger conversational context ) .", "entities": []}, {"text": "For example \u201c You are such a nice friend ! ! ! \u201d , or \u201c Driving in Detroit is fun ;) \u201d are cases of ironic messages where the semantic incongruity is implicit .", "entities": []}, {"text": "Based on these definitions of explicit and implicit incongruity , two expert annotators annotated the S im - Hintdataset ( 1000 ironic messages ) as containing explicit or implicit semantic incongruity .", "entities": []}, {"text": "The inter - annotator agreement was \uf8ff=0.7 , which denotes good agreement similar to Karoui et", "entities": []}, {"text": "al . ( 2017 ) .", "entities": []}, {"text": "The annotation showed that 38.7 % of the ironic messages are explicit , while 61.3 % are implicit .", "entities": []}, {"text": "In the following section we propose a typology of linguistic strategies used in hearers \u2019 interpretations of speakers \u2019 ironic messages and in section 6.2we discuss the correlation of linguistic strategies with the type of semantic incongruity .", "entities": []}, {"text": "4 Interpreting Verbal Irony : A Typology of Linguistic Strategies Given the de\ufb01nition of verbal irony , we would expect that Turkers \u2019 interpretation of speaker \u2019s ironic message will contain some degree of opposite meaning with respect to what the speaker has said .", "entities": []}, {"text": "However , it is unclear what linguistic strategies the Turkers will use to express that .", "entities": []}, {"text": "To build our typology , from the total set of S im - Hint pairs obtained through crowdsourcing ( i.e. , 4,762 pairs ; see Section 2 ) we selected a devset of 500 Sim - Hintpairs .", "entities": []}, {"text": "Our approach does not assume any speci\ufb01c theory or irony , but it is data - driven : a linguist expert in semantics and pragmatics analyzed thedevset to formulate the lexical and pragmatic phenomena attested in the data .", "entities": []}, {"text": "The assembled typology is , thus , the result of a bottom - up procedure .", "entities": []}, {"text": "A S im - Hintpair can be annotated with more than one strategy .", "entities": []}, {"text": "The core linguistic strategies are explained below and synthesized in Table 2 .", "entities": []}, {"text": "Typology Distribution ( % ) Antonyms - lexical antonyms ( 42.2 ) - antonym phrases ( 6.0 ) Negation - simple negation ( 28.4 ) Antonyms OR Negation - weakening sentiment ( 23.2 ) - interrogative ! declarative ( 5.2 ) - desiderative constructions ( 2.8 ) Pragmatic inference ( 3.2 ) Table 2 : Typology of linguistic strategies and their distribution ( in % ) over the devset 4.1 Linguistic Strategies Lexical and phrasal antonyms :", "entities": []}, {"text": "This category contains lexical antonyms ( e.g. , \u201c love \u201d $ \u201c hate \u201d , \u201c great \u201d $ \u201c terrible \u201d ) as well as indirect antonyms ( Fellbaum , 1998 ) , where the opposite meaning can only be interpreted in context ( e.g. , \u201c passionate speaker \u201d !", "entities": []}, {"text": "\u201c boring speaker \u201d ; Table 1 ) .", "entities": []}, {"text": "Although the typical antonym of \u201c passionate \u201d is \u201c unpassionate \u201d , \u201c boring \u201d works in this context as a lexical opposite since a speaker who is passionate entails that he is not boring .", "entities": []}, {"text": "Besides lexical antonyms , Turkers sometimes use antonym phrases ( e.g. , \u201c I ca n\u2019t wait \u201d !", "entities": []}, {"text": "\u201c not looking forward \u201d , \u201c I like ( to visit ER ) \u201d !", "entities": []}, {"text": "\u201c I am upset ( to visit ER ) \u201d ) .", "entities": []}, {"text": "Negation : Here , Turkers negate the main predicate .", "entities": []}, {"text": "This strategy is used in the presence of copulative constructions where the predicative expression is an adjective / noun expressing sentiment ( e.g. , \u201c is great \u201d !", "entities": []}, {"text": "\u201c isnotgreat \u201d ) and of verbs expressing sentiment ( e.g. , \u201c love \u201d !", "entities": []}, {"text": "\u201c do not love \u201d ) or propositional attitudes ( e.g. , \u201c I wonder \u201d !", "entities": []}, {"text": "\u201c I do n\u2019t wonder \u201d ) .", "entities": []}, {"text": "Weakening the intensity of sentiment : The use of negation and antonyms is sometimes accompanied by two strategies that re\ufb02ect a weakening of sentiment intensity .", "entities": []}, {"text": "First , when S imcontains words expressing a high degree of positive sentiment , the hearer \u2019s interpretation replaces them with more neutral ones ( e.g. , \u201c I loveit\u201d!\u201cI do n\u2019t likeit \u201d ) .", "entities": []}, {"text": "Second , when S imcontains an intensi\ufb01er , it is eliminated in the Turkers \u2019 interpretation .", "entities": []}, {"text": "Intensi\ufb01ers specify the degree of value / quality expressed by the words they modify ( M\u00b4endez - Naya , 2008 ) ( e.g. , \u201c cake for breakfast .", "entities": []}, {"text": "sohealthy \u201d !", "entities": []}, {"text": "\u201c cake for breakfast .", "entities": []}, {"text": "nothealthy \u201d ) .", "entities": []}, {"text": "Interrogative to Declarative Transformation ( + Antonym / Negation ): This strategy , usedmostly in conjunction with the negation or antonym strategies , consists in replacing the interrogative form with a declarative form , when S imis a rhetorical question ( for brevity , RQ ) ( e.g. , \u201c do n\u2019t youlove\ufb01ghting ? \u201d !", "entities": []}, {"text": "\u201c Ihate \ufb01ghting \u201d ) .", "entities": []}, {"text": "Counterfactual Desiderative Constructions : When the ironic utterance expresses a positive / negative sentiment towards a past event ( e.g. , \u201c glad you relayed this news \u201d ) or an expressive speech act ( e.g. , \u201c thanks Xthat picture needed more copy \u201d ) the hearer \u2019s interpretation of intended meaning is expressed through the counterfactual desiderative constructions I wish ( that ) p ( \u201c I wish you had n\u2019t relayed . . .", "entities": []}, {"text": "\u201d , \u201c I wish Xdidn\u2019t copy . . . \u201d ) .", "entities": []}, {"text": "Differently from antonymic phrases , this strategy stresses on the failure of the speaker \u2019s expectation more than on their commitment to the opposite meaning .", "entities": []}, {"text": "Pragmatic Inference :", "entities": []}, {"text": "In addition to the above strategies , there are cases where the interpretation calls for an inferential process to be recognized .", "entities": []}, {"text": "For instance , \u201c made 174 this month . . .", "entities": []}, {"text": "I \u2019m gon na buy a yacht ! \u201d ! \u201c made 174 this month . . .", "entities": []}, {"text": "I am so poor \u201d .", "entities": []}, {"text": "The distribution of the strategies on the devset is represented in Table 2 . 4.2 Links to Theoretical Frameworks In linguistic literature many different approaches to irony have been provided .", "entities": []}, {"text": "Here we focus on the three accounts ( w.r.t . examples from S im - Hint corpus ) that bear a different views on pragmatic factors .", "entities": []}, {"text": "According to Grice ( 1975 ) , ironic messages are uttered to convey a meaning opposite to that literally expressed , \ufb02outing the conversational maxim of quality \u201c do not say what you believe to be false \u201d .", "entities": []}, {"text": "In verbal irony , the violation of the maxim is frequently signaled by \u201c the opposite \u201d of what is said literally ( e.g. , intended meaning of \u201c carcasses are \ufb02attering \u201d is they are gross ; Table 1 ) .", "entities": []}, {"text": "The linguistic strategies of antonyms ( e.g. \u201c worst day of my life \u201d ) and simple negation ( \u201c yeap we totally do nt drink alcohol every single day \u201d [ ... ] )", "entities": []}, {"text": "cover the majority of the S imHintcorpus and seem to \ufb01t the Gricean ( Grice , 1975 ) account of irony , since the hearer seems to have primarily recognized the presence of semantic incongruity .", "entities": []}, {"text": "However , as touched upon byGiora ( 1995 ) , antonyms anddirect negation are not always semantically equivalent strategies , since the second sometimes allows a graded interpretation : if \u201c x is not encouraging \u201d , it is not nec-", "entities": []}, {"text": "essarily bad , but simply \u201c x < encouraging \u201d .", "entities": []}, {"text": "Such an implicature is available exclusively with items allowing mediated contraries , such as sentiment words ( Horn , 1989 ) .", "entities": []}, {"text": "Direct negation with sentiment words implies that just one value in a set is negated , while the others are potentially af\ufb01rmed .", "entities": []}, {"text": "The spectrum of interpretations allowed by negation as a rephrasing strategy indicates that hearers recognize that the relevance of the ironic utterance in itself plays a role next to what the utterances refers to ( if the rephrased utterance is intended as \u201c x is not encouraging at all \u201d , the perceived irrelevance of the corresponding ironic utterance is more prominent than in \u201c x is not very encouraging \u201d ) .", "entities": []}, {"text": "The fact that the interpretation of irony has a propositional scope is even clearer when the ironic sentence in interrogative form ( \u201c and they all lived happily ever after ? \u201d ) is rephrased as a declarative ( e.g. \u201c I doubt they all lived happily ever after \u201d ): the hearers recognizes that the question has a rhetoric value since otherwise contextually irrelevant .", "entities": []}, {"text": "The intentional falsehood of Gricean analysis is also not deemed by Sperber and Wilson ( 1986 ) ; Wilson and Sperber ( 2012 ) as a necessary and suf\ufb01cient condition for irony .", "entities": []}, {"text": "According to their theory of echoic mentioning , irony presupposes the mention to the inappropriateness of the entire sentence : in asserting \u201c awesome weather in Scotland today \u201d the speaker does not simply want to express that the weather was horrible but he signals that assuming that the weather would be nice was irrelevant and , thus , ridiculous .", "entities": []}, {"text": "Kreuz and Glucksberg ( 1989 ) expand the Relevance Theory approach talking about echoic reminding to account for cases such as \u201c could you be just a little louder , please ?", "entities": []}, {"text": "My baby is n\u2019t trying to sleep \u201d where the extreme politeness reminds the hearer that the question is indeed a request and that the mother bears a certain stance and has certain expectations towards the addressee .", "entities": []}, {"text": "Similarly , the use of the pragmatic inference strategy can not be fully explained in Gricean terms : the rephrase \u201c made 174 this month . . .", "entities": []}, {"text": "I am so poor \u201d for \u201c made 174 this month . . .", "entities": []}, {"text": "I am gon na buy a yatch \u201d more than pointing to the presence of lexical incongruity , show that the hearers knows for background knowledge that the assertion of \u201c buying a yatch \u201d is completely irrelevant in the context of a low salary situation .", "entities": []}, {"text": "Rephrasing strategies using counterfactual desiderative constructions ( e.g. \u201c I really wish my friends and fam - ily would check up on my after yesterday \u2019s near death experience \u201d ) show , instead , that the interpretation of irony involves an echoic reminding to the speaker \u2019s ( social ) expectations which failed to be ful\ufb01lled .", "entities": []}, {"text": "Overall , using the results of our crowdsourcing experiment with main existing theories of irony , it turns out that the theories have a complementary explanatory power .", "entities": []}, {"text": "In Section 6.2we investigate weather this situation might relate to the presence of explicit / implicit irony .", "entities": []}, {"text": "5 Empirical Analysis of Interpretation Strategies Here our goal is to perform a comparative empirical analysis to understand how hearers interpret verbal irony .", "entities": []}, {"text": "To accomplish this , we propose computational models to automatically detect these linguistic strategies in two datasets : ( 1 ) Sim - Hintdataset and ( 2 ) the SIGN dataset .", "entities": []}, {"text": "As stated in Section 2 , albeit for a different purpose , the task designed in Peled and Reichart ( 2017 ) is identical to ours : they used a set of 3,000 sarcastic tweets and collected \ufb01ve interpretation verbalization , including an option to just copy the original message if it was not deemed ironic .", "entities": []}, {"text": "They used workers skilled in comedy writing and literature paraphrasing .", "entities": []}, {"text": "SIGN contains 14,970 pairs .", "entities": []}, {"text": "To evaluate our models , we asked two annotators to annotate two testsets of 500 pairs each from the S im - Hintand the SIGN dataset ( i.e. , denoted bySIGN test ) , respectively .", "entities": []}, {"text": "Note , the testset for the S im - Hinthas no overlap with the devset of 500 S im - Hintpairs used to identify the strategies ( Section 4 ) .", "entities": []}, {"text": "Agreement between the annotators for both sets is high with \uf8ff>0.9 .", "entities": []}, {"text": "In SIGN test , 79 instances were just copies of the original message , which we eliminated , thus the SIGN testcontains only 421 instances .", "entities": []}, {"text": "5.1 Computational Methods Lexical Antonyms .", "entities": []}, {"text": "To detect whether an S imHintpair uses the lexical antonyms strategy , we \ufb01rst need to build a resource of lexical antonyms .", "entities": []}, {"text": "We use the MPQA sentiment Lexicon ( Wilson et al . , 2005 ) , Hu and Liu ( 2004 ) \u2019s opinion lexicon , antonym pairs from Mohammad et al .", "entities": [[3, 4, "DatasetName", "MPQA"]]}, {"text": "( 2013 ) , antonyms from WordNet , and pairs of opposite verbs from Verbocean ( Chklovski and Pantel , 2004 ) .", "entities": []}, {"text": "Given this lexicon of lexical antonyms , the task is now to detect whether a given S im - Hintpair", "entities": []}, {"text": "dev test SIGN test Strategies P R F1 P R F1 P R F1 Lexant 89.0 95.7 92.2 97.2 89.9 93.4 89.4 97.9 93.5 Simple neg 92.0 89.4 90.7 88.3 88.3 88.3 93.3 91.2 92.2 ANweaksent 93.6 87.9 90.7 95.0 91.9 93.4 93.3 87.5 90.3 AN I!D 53.1 65.4 58.6 80.0 0.44 57.2 85.7 70.6 77.4 ANdesiderative 100.0 92.9 96.3 100.0 100.0 100.0 100.0 66.7 80.0 AntPhrase+PragInf 86.2 53.2 65.8 70.7 85.3 77.4 89.5 68.0 77.3 Table 3 : Evaluation of Computational Methods on dev , testandSIGN testset ( in % ) uses the lexical antonyms strategy .", "entities": [[7, 8, "MetricName", "F1"], [10, 11, "MetricName", "F1"], [13, 14, "MetricName", "F1"]]}, {"text": "We use a heuristic approach based on word - alignment and dependency parsing ( similar to contradiction detection ( De Marneffe et al . , 2008 ) ) .", "entities": [[11, 13, "TaskName", "dependency parsing"]]}, {"text": "Word - to - word alignments between S im - Hintare extracted using a statistical machine translation ( SMT ) alignment method - IBM Model 4 with HMM alignment from Giza++ ( Och and Ney , 2004 ) .", "entities": [[16, 18, "TaskName", "machine translation"]]}, {"text": "We consider a lexical antonym strategy if : 1 ) antonym words are aligned ; 2 ) they are the roots of the respective dependency trees or if the nodes modi\ufb01ed by the lexical antonyms are the same in their respective trees ( e.g. , \u2018 can you show any more of steelers \u201d !", "entities": []}, {"text": "\u201c show lessof steelers \u201d , the candidate lexical antonyms are more andlessand they are the objects of the same predicate in S im - Hint : show ) .", "entities": []}, {"text": "Out of 211 S im - Hintpairs that are marked as having lexical antonym strategy ( devset ) , 12 instances are identi\ufb01ed by only the dependency parses , 67 instances by the word - alignments , and 100 instances by both ( P / R / F1 scores are 92.1 % , 77.7 % and 84.3 % ) , respectively on devdataset .", "entities": [[48, 49, "MetricName", "F1"]]}, {"text": "However , sometimes both dependency and wordalignment methods fail .", "entities": []}, {"text": "In \u201c circling down the bowl .", "entities": []}, {"text": "Yay\u201d!\u201ccircling down the bowl .", "entities": []}, {"text": "awful \u201d , although the lexical antonyms yayandawfulexist , neither the alignment nor the dependency trees can detect it ( 25 such instances in the dev set ) .", "entities": []}, {"text": "To account for this , after having run the dependency and alignment methods , we also just search whether a S im - Hintpair contains a lexical antonym pair .", "entities": []}, {"text": "This improves the \ufb01nal recall and on thedevset we achieve 89.0 % precision , 95.7 % recall , and 92.2 % F1 on devdataset ( Lex ant Strategy ; Table 3show results both on devand the testsets ) .", "entities": [[21, 22, "MetricName", "F1"]]}, {"text": "Note , just searching whether a lexical antonym pair is present in a S im - Hintpair results in low precision ( 58.6 % ) but high recall ( 80 % ) .", "entities": []}, {"text": "Simple negation .", "entities": []}, {"text": "This strategy ( denoted as Simple neg in Table 3and Table 4 ) involves identifying the presence of negation and its scope .", "entities": []}, {"text": "Here , however , the scope of negation is con - strained since generally Turkers negated only a single word ( i.e. , \u201c love \u201d !", "entities": []}, {"text": "\u201c notlove \u201d ) .", "entities": []}, {"text": "Thus our problem is easier than the general problem of \ufb01nding the scope of negation ( Li and Lu , 2018 ; Qian et al . , 2016 ; Fancellu et al . , 2016 ) .", "entities": []}, {"text": "We use 30 negation markers from Reitan et al . ( 2015 ) to \ufb01nd negation scope in tweets .", "entities": []}, {"text": "We \ufb01rst detect whether a negation marker appears in either H intor", "entities": []}, {"text": "S i m , but not in both ( negation can appear in S imfor ironic blame )", "entities": []}, {"text": "If the marker is used , we extract its parent node from the dependency tree , and if this node is also present in the other utterance , then Negation strategy is selected .", "entities": []}, {"text": "For instance , in \u201c looks just like me \u201d ! \u201c does not look like me \u201d , the negation notis modifying the main predicate looks in H int , which is also the main predicate in S im(words are lemmatized ) .", "entities": []}, {"text": "In the next section , we discuss if the parent nodes are not the same but similar and with different sentiment strength .", "entities": []}, {"text": "Weakening the intensity of sentiment .", "entities": []}, {"text": "The \ufb01rst strategy \u2014 replacing words expressing a high degree of positive / negative sentiment with more neutral ones ( \u2018 I lovebeing sick \u201d !", "entities": []}, {"text": "\u201c Idon\u2019t like being sick ) \u2014 , is applied only in conjunction with the negation strategy .", "entities": []}, {"text": "We measure the difference in strength using the Dictionary of Affect ( Whissell et al . , 1986 ) .", "entities": []}, {"text": "Out of 31 S im - Hintpairs in the devset , we automatically identify 28 interpretations that use this approach .", "entities": []}, {"text": "For the second strategy \u2014 removing the intensi\ufb01er ( I am really happy \u201d !", "entities": []}, {"text": "\u201c I am disappointed \u2019 ) \u2014 , we \ufb01rst determine whether the intensi\ufb01er exists in S imand is eliminated from H int .", "entities": []}, {"text": "We use only adjective and adverb intensi\ufb01ers from Taboada et al .", "entities": []}, {"text": "( 2011 ) , primarily to discard conjunctions such as \u201c so \u201d ( \u201c no water soI ca n\u2019t wash . . . \u201d ) .", "entities": []}, {"text": "This strategy is used together with both lexical antonyms andSimple negation strategies .", "entities": []}, {"text": "For a candidate S im - Hintpair , if the lexical antonym strategy is selected and aS andaHare the lexical antonyms , we determine whether any intensi\ufb01er modi\ufb01es aSand", "entities": []}, {"text": "no intensi\ufb01er modi\ufb01es aH. If the Negation strategy is se-", "entities": []}, {"text": "lected , we identify the negated term in the H int and then search its aligned node from the S imusing the word - word alignment .", "entities": [[24, 26, "TaskName", "word alignment"]]}, {"text": "Next , we search in the S imif any intensi\ufb01er is intensifying the aligned term .", "entities": []}, {"text": "The strategies are denoted as AN weaksent in Table 3and Table 4 .", "entities": []}, {"text": "Interrogative to Declarative Transformation ( + Antonym / Neg ) .", "entities": []}, {"text": "To capture this strategy we need to determine \ufb01rst if the verbal irony was expressed as a rhetorical question .", "entities": []}, {"text": "To build a classi\ufb01er to detect RQ , we collect two categories of tweets ( 4 K each ) ( 1 ) tweets labeled with # sarcasm or # irony that also contain \u201c ? \u201d , and ( 2 ) information seeking tweets containing \u201c ? \u201d .", "entities": []}, {"text": "We train a binary classi\ufb01er using SVM RBF Kernel with default parameters .", "entities": [[6, 7, "MethodName", "SVM"]]}, {"text": "The features are Twitter - trained word embeddings ( Ghosh et al . , 2015 ) , modal verbs , pronouns , interrogative words , negations , and position of \u201c ? \u201d in a tweet .", "entities": [[6, 8, "TaskName", "word embeddings"]]}, {"text": "We evaluate the training model on the devdata and the P / R / F1 are 53.2 % , 65.4 % , and 58.6 % , respectively ( in future work we plan to develop more accurate models for RQ detection ) .", "entities": [[14, 15, "MetricName", "F1"]]}, {"text": "Once we detect the ironic message was expressed as a RQ , we identify the speci\ufb01c interpretation strategy accompanying the transformation from interrogative to declarative form : antonym or negation .", "entities": []}, {"text": "These combined strategies are denoted as AN I!Din Table 3and Table 4 .", "entities": []}, {"text": "Desiderative Constructions : Currently , we use a simple regular expression \u201c I [ w ] \u21e4 wish \u201d to capture counterfactual cases ( AN desiderative in Tables3and Table 4 ) .", "entities": []}, {"text": "Note , when the Simple negation and lexical antonyms strategies are combined with other strategy ( e.g. , removing of intensi\ufb01er ) , we consider this combined strategy for the interpretation of verbal irony and not the simple negation orlexical antonym strategy ( i.e. , we do not double count ) .", "entities": []}, {"text": "Phrasal antonyms and pragmatic inference : Identifying phrasal antonyms and pragmatic inference is a complex task , and thus we propose a method of phrase matching based on phrase extraction via unsupervised alignment technique in SMT .", "entities": []}, {"text": "We use IBM Model 4 with HMM ( Giza++ ; ( Och and Ney , 2000 ) ) , phrase extraction via Moses ( Koehn et al . , 2007 ) and the IRST tool to build the required language models .", "entities": []}, {"text": "As postprocessing , we \ufb01rst remove phrase pairs obtained from the S im - Hintbitext that are also present in the set of extracted phrases from the H int - HintStrategies S im - Hint SIGN Lexant 2,198 ( 40.0 ) 9,691 ( 51.8 ) Simple neg 1,596 ( 29.1 ) 3,827 ( 20.5 )", "entities": []}, {"text": "ANweaksent 895 ( 16.3 ) 2,160 ( 11.6 ) AN I!D 329 ( 6.0 ) 933 ( 5.0 ) ANdesiderative 92 ( 1.7 ) 86 ( 0.5 ) AntPhrase+PragInf 357 ( 6.5 ) 1912 ( 10.1 ) Table 4 : Distribution of interpretation strategies on two datasets ( in % ) bitext .", "entities": []}, {"text": "This increases the likelihood of retaining semantically opposite phrases , since phrases extracted from the H int - Hintbitext are more likely to be paraphrastic .", "entities": []}, {"text": "Second , based on the translation probability scores \u0000 , for phrase eif we have a set of aligned phrases fsetwe reject phrases that have \u0000scores less than1 size(fset ) .", "entities": []}, {"text": "Finally , 11,200 phrases are extracted from the S im - Hint bitext .", "entities": []}, {"text": "The low recall for this strategy is expected since there are too many ways that users can employ pragmatic inference or rephrase the utterance without directly using any antonym or negation .", "entities": []}, {"text": "In future , we will explore neural MT ( Cho et al . , 2014 ) and use external data to generate more phrases .", "entities": []}, {"text": "Since we have not manually evaluated these phrase pairs , we only use this strategy after we have tried all the remaining strategies ( AntPhrase+PragInf in Table 3and Table 4 ) .", "entities": []}, {"text": "5.2 Results and Distribution of Linguistic Strategies The performance of the models is similar on both testand SIGN testsets , showing consistently good performance ( Table 3 ; 90 % F1 for all strategies , except the AntPhrase+PragInf and AN I!D ) .", "entities": [[30, 31, "MetricName", "F1"]]}, {"text": "Given these results , we can now apply these models to study the distribution of these strategies in the entire datasets ( Table 4 ) .", "entities": []}, {"text": "The strategy distribution between our dataset S im - HintandSIGN dataset is similar and matches the distribution on the manual annotations on the devdataset in Table2 .", "entities": []}, {"text": "The sum of the strategies can exceed the total number of the pairs since a tweet can contain several ironic sentences that are interpreted by Turkers .", "entities": []}, {"text": "For instance , in \u201c Dave too nice ... a nicefella \u201d !", "entities": []}, {"text": "\u201c Dave not nice .", "entities": []}, {"text": ". .", "entities": []}, {"text": "a mean fella \u201d we observe the application of two strategies , lexical antonyms ( e.g. , nice!mean ) and negation ( e.g. , nice!not nice ) .", "entities": []}, {"text": "6 Discussion 6.1 Hearer - dependent Interpretation Strategies We investigate how hearers adopt strategies for interpreting the speaker \u2019s ironic intent .", "entities": []}, {"text": "To implement this study , we selected three Turkers ( e.g. , H1,H2 , and H3 ; In Table 1,Hi intare generated by the correspondent Turker Hi ) , from our crowdsourced data , who were able to rephrase at least \ufb01ve hundred identical S immessages .", "entities": []}, {"text": "Note , we can not carry this experiment on the SIGN dataset ( Peled and Reichart , 2017 ) because the annotators \u2019 information is absent there .", "entities": []}, {"text": "Although the three Turkers choose lexical antonym andsimple negation as two top choices , there is some variation among them .", "entities": []}, {"text": "H1and H2choose antonyms more frequently than negationwhile in contrary Turker H3choose negation more than antonyms , sometime combined with the weakening of sentiment strategy .", "entities": []}, {"text": "As we mentioned in Section 4.2 , antonyms and direct negation are not semantically equivalent strategies since the latter , allows a graded interpretation : if \u201c x is not inspiring \u201d , it is not necessarily bad , but simply \u201c x < inspiring \u201d ( Giora , 1995 ) .", "entities": []}, {"text": "In Table 1 , the S im - Hint pair \u201c passionate \u201d !", "entities": []}, {"text": "\u201c boring \u201d and \u201c \ufb02attering \u201d !", "entities": []}, {"text": "\u201c gross \u201d ( interpretation of H1 ) have more contrast than the pair \u201c passionate \u201d !", "entities": []}, {"text": "\u201c not passionate \u201d and \u201c so \ufb02attering \u201d !", "entities": []}, {"text": "\u201c not \ufb02attering \u201d ( interpretation of H3 ) .", "entities": []}, {"text": "This suggests that H1perceive the intensity of negative sentiment towards the target of irony ( \u201c Ed Davey \u201d and \u201c picture of dead animals \u201d , respectively ) higher than Turker H3 .", "entities": []}, {"text": "All three Turkers have chosen the remaining strategies with similar frequencies .", "entities": []}, {"text": "6.2 Message - dependent Interpretation Strategies Interpretation Strategies and the Type of Semantic Incongruity : We investigate whether the type of semantic incongruity in the ironic message ( explicit vs. implicit ; see Section 3 ) in\ufb02uences the choice of interpretation strategies by the hearers .", "entities": []}, {"text": "To do this , we looked at S im - level distribution of interpretation strategies used by the hearers for the same ironic message", "entities": []}, {"text": "S i m. Table 5represents", "entities": []}, {"text": "the correlation of linguistic strategies with the type of semantic incongruity ( explicit vs. implicit ) as well as the presence and absence of irony markers .", "entities": []}, {"text": "We notice that Turkers use lexical antonymsStrategies incongruity marker Exp .", "entities": []}, {"text": "Imp .", "entities": []}, {"text": "+ \u0000", "entities": []}, {"text": "Lexant 48.5 34.8 35.7 42.2 Simple neg 24.9 32.3 28.9 30.0 ANweaksent 14.3 17.6 15.7 16.8 AN I!D 5.9 6.1 12.3 3.1 ANdesiderative 1.3 1.9 0.9 2.0 AntPhrase+PragInf 5.2 7.1 6.2 6.6 Table 5 : Rephrasing Strategies against Incongruency and Irony Markers on S im - Hintdataset ( in % )", "entities": []}, {"text": "Figure 1 : Strategies selected per message ( in % ) as interpretation strategy more when the semantic incongruity is explicit than implicit ( 48.5 % vs. 34.8 % ): the presence of explicit sentiment triggered the use of the antonym strategy .", "entities": []}, {"text": "In contrary they use simple negation more when the semantic incongruity is implicit than explicit .", "entities": []}, {"text": "We also analyze the interpretation strategies w.r.t .", "entities": []}, {"text": "to the presence ( + ) or absence ( \u0000 ) of irony markers .", "entities": []}, {"text": "We implement various morpho - syntactic as well as typographic markers ( similar to ( Ghosh and Muresan , 2018 ) ) to identify the presence of markers .", "entities": []}, {"text": "We observe that Lexantstrategy is used more in cases where the markers are absent .", "entities": []}, {"text": "In S im - Hint , markers are present twice as much in the case of implicit ( 21 % ) than explicit incongruity ( 10 % ) .", "entities": []}, {"text": "This \ufb01nding validates ( Burgers et al . , 2012 ) who argued speakers will likely use markers to signal their ironic intent in implicit incongruity .", "entities": []}, {"text": "Message interpreted the same by all hearers : In Figure 1 , the vertical columns ( purple : S imHintand grey : SIGN ) depict the distribution ( in % ) of tweets strategy - wise .", "entities": []}, {"text": "In S im - Hintdataset , for 17 % of messages ( 124 S ims ) all \ufb01ve Turkers use the same strategy to interpret the S ims ( labeled as5on the X - axis ) , whereas for 26 % ( 188 S ims ) , 4 Turkers used same strategy ( labeled as 4,1 on Xaxis ) and so on .", "entities": []}, {"text": "We observe when the S ims are marked by strong subjective words e.g. , \u201c great \u201d , \u201c best \u201d , etc . ,", "entities": []}, {"text": "they", "entities": []}, {"text": "have been replaced in 90 % of cases as lexical antonyms ( e.g. , \u201c great \u201d !", "entities": []}, {"text": "\u201c terrible \u201d ) .", "entities": []}, {"text": "In addition , the majority of adjectives are used in attributive position ( i.e. , \u201c lovely neighbor is vacuuming at night \u201d ) , thus blocking paraphrases involving predicate negation .", "entities": []}, {"text": "However , not all strong subjective words guarantee the use of direct opposites in the H ints ( e.g. , \u201c \ufb02attering \u201d ! \u201c not \ufb02attering \u201d ; See Table 1 ) .", "entities": []}, {"text": "The choice of strategies may also depend upon the target of ironic situation ( Ivanko and Pexman , 2003 ) .", "entities": []}, {"text": "We implement the bootstrapping algorithm from Riloff et al .", "entities": []}, {"text": "( 2013 ) to identify ironic situations in S ims that are rephrased by Lexical antonym strategy .", "entities": []}, {"text": "We \ufb01nd utterances containing stereotypical negative situations regarding health issues ( e.g. , \u201c having migraines \u201d , \u201c getting killed by chemicals \u201d ) and other undesirable negative states such as \u201c oversleeping \u201d , \u201c luggage lost \u201d , \u201c stress in life \u201d are almost always interpreted via lexical antonym strategy .", "entities": []}, {"text": "Utterances where all \ufb01ve Turkers used simple negation , if negative particles are positioned in the ironic message with a sentential scope ( e.g. , \u201c not a biggie \u201d , \u201c not awkward \u201d ) then they are simply omitted in the interpretations .", "entities": []}, {"text": "This trend can be explained according to the inter - subjective account of negation types ( Verhagen , 2005 ) .", "entities": []}, {"text": "Sentential negation leads the addressee to open up an alternative mental space where an opposite predication is at stake .", "entities": []}, {"text": "7 Related Work Most NLP research on verbal irony or sarcasm has focused on the task of sarcasm detection treating it as a binary classi\ufb01cation task using either the utterance in isolation or adding contextual information such as conversation context , author context , visual context , or cognitive features ( Gonz \u00b4 alezIb\u00b4a\u02dcnez et al . , 2011 ; Liebrecht et al . , 2013 ; Wallace et", "entities": [[17, 19, "TaskName", "sarcasm detection"]]}, {"text": "al . , 2014 ; Zhang et al . , 2016 ; Ghosh and Veale , 2016 ; Schifanella et al . , 2016 ; Xiong et al . , 2019 ; Castro et al . , 2019 )", "entities": []}, {"text": ".", "entities": []}, {"text": "Unlike this line of work , our research focuses on how the hearer interprets an ironic message .", "entities": []}, {"text": "The \ufb01ndings from our study could have multiple impacts on the sarcasm detection task .", "entities": [[11, 13, "TaskName", "sarcasm detection"]]}, {"text": "First , interpretation strategies open up a scope of \u201c graded interpretation \u201d of irony instead of only a binary decision ( i.e. , predicting the strength of irony ) .", "entities": []}, {"text": "Second , nature of semantic incongruence and stereotype irony situations can be useful features in irony detection .", "entities": []}, {"text": "Recently , Peled and Reichart ( 2017 ) proposed a computational model based on SMT to generate interpretations of sarcastic messages .", "entities": []}, {"text": "We aim to deepen our understanding of such interpretations by introducing a typology of linguistic strategies .", "entities": []}, {"text": "We study the distribution of these strategies via both hearer - dependent and messagedependent interpretations .", "entities": []}, {"text": "Psycholinguistics studies that have dealt with the hearers \u2019 perception , have mainly focused on how ironic messages are processed : through the analysis of reaction times ( Gibbs , 1986 ; Katz et al . , 2004 ) , the role of situational context ( Ivanko and Pexman , 2003 ) and in tackling speaker - hearer social relations by annotating ironic texts from different genres ( Burgers , 2010 ) .", "entities": []}, {"text": "However , no attention has been paid to correlations between how ironic message is expressed and how it is interpreted by the hearer , including what linguistic strategies the hearers employ .", "entities": []}, {"text": "8 Conclusions We leveraged a crowdsourcing task to obtain a dataset of ironic utterances paired with the hearer \u2019s verbalization of their interpretation .", "entities": []}, {"text": "We proposed a typology of linguistic strategies for verbal irony interpretation and designed computational models to capture these strategies with good performance .", "entities": []}, {"text": "Our study shows ( 1 ) Turkers mostly adopt lexical antonym and negation strategies to interpret speaker \u2019s irony , ( 2 ) interpretations are correlated to stereotype ironic situations , and ( 3 ) irony expression ( explicit vs. implicit incongruity and absence or presence of markers ) in\ufb02uences the choice of interpretation strategies and match with different explanatory theories ( the Gricean approach links up better with explicit incongruity , while Relevance Theory with the implicit one ) .", "entities": []}, {"text": "The latter can have an impact on irony detection by bringing out more discriminative semantic and pragmatic features .", "entities": []}, {"text": "Acknowledgements We thank Rituparna Mukherjee , Daniel Chaparro , Pedro P \u00b4 erez S \u00b4 anchez , and Renato Augusto Vieira Nishimori who helped us in annotating as well as in running experiments .", "entities": []}, {"text": "This paper partially based on the work supported by the DARPA - DEFT program .", "entities": [[10, 11, "DatasetName", "DARPA"]]}, {"text": "The views expressed are those of the authors and do not re\ufb02ect the of\ufb01cial policy or position of the Department of Defense or the U.S. Government .", "entities": []}, {"text": "References Silvio Amir , Byron C Wallace , Hao Lyu , and Paula Carvalho M \u00b4 ario J Silva . 2016 .", "entities": []}, {"text": "Modelling context with user embeddings for sarcasm detection in social media .", "entities": [[6, 8, "TaskName", "sarcasm detection"]]}, {"text": "arXiv preprint arXiv:1607.00976 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Salvatore Attardo .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "Irony markers and functions : Towards a goal - oriented theory of irony and its processing .", "entities": []}, {"text": "Rask 12(1):3\u201320 .", "entities": []}, {"text": "David Bamman and Noah A Smith . 2015 .", "entities": []}, {"text": "Contextualized sarcasm detection on twitter .", "entities": [[1, 3, "TaskName", "sarcasm detection"]]}, {"text": "In Ninth International AAAI Conference on Web and Social Media .", "entities": []}, {"text": "Christian Burgers , Margot Van Mulken , and Peter Schellens . 2012 .", "entities": []}, {"text": "Verbal irony differences in usage across written genres .", "entities": []}, {"text": "Journal of Language and Social Psychology 31(3):290\u2013310 .", "entities": []}, {"text": "Christian Frederik Burgers .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Verbal irony : Use and effects in written discourse .", "entities": []}, {"text": "[ Sl : sn ] .", "entities": []}, {"text": "Santiago Castro , Devamanyu Hazarika , Ver \u00b4 onica P\u00b4erez - Rosas , Roger Zimmermann , Rada Mihalcea , and Soujanya Poria .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Towards multimodal sarcasm detection ( an obviously perfect paper ) .", "entities": [[2, 4, "TaskName", "sarcasm detection"]]}, {"text": "arXiv preprint arXiv:1906.01815 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Timothy Chklovski and Patrick Pantel .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Verbocean : Mining the web for \ufb01ne - grained semantic verb relations .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "volume 4 , pages 33\u201340 .", "entities": []}, {"text": "Kyunghyun Cho , Bart Van Merri \u00a8enboer , Caglar Gulcehre , Dzmitry Bahdanau , Fethi Bougares , Holger Schwenk , and Yoshua Bengio .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Learning phrase representations using rnn encoder - decoder for statistical machine translation .", "entities": [[10, 12, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1406.1078 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Dmitry Davidov , Oren Tsur , and Ari Rappoport .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Semi - supervised recognition of sarcastic sentences in twitter and amazon .", "entities": []}, {"text": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning .", "entities": []}, {"text": "CoNLL \u2019 10 .", "entities": []}, {"text": "Marie - Catherine De Marneffe , Anna N Rafferty , and Christopher D Manning .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Finding contradictions in text .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "volume 8 , pages 1039\u20131047 .", "entities": []}, {"text": "Federico Fancellu , Adam Lopez , and Bonnie Webber .", "entities": [[3, 4, "MethodName", "Adam"]]}, {"text": "2016 .", "entities": []}, {"text": "Neural networks for negation scope detection .", "entities": []}, {"text": "InProceedings of the 54th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "volume 1 , pages 495\u2013504 .", "entities": []}, {"text": "Bjarke Felbo , Alan Mislove , Anders S\u00f8gaard , Iyad Rahwan , and Sune Lehmann . 2017 .", "entities": []}, {"text": "Using millions of emoji occurrences to learn any - domain representations for detecting sentiment , emotion and sarcasm .", "entities": [[15, 16, "DatasetName", "emotion"]]}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , pages 1615\u20131625 .", "entities": []}, {"text": "https://doi.org/ 10.18653 / v1 / D17 - 1169 .Christiane Fellbaum .", "entities": []}, {"text": "1998 .", "entities": []}, {"text": "WordNet .", "entities": []}, {"text": "Wiley Online Library .", "entities": []}, {"text": "Aniruddha Ghosh and Tony Veale .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Fracking sarcasm using neural network .", "entities": []}, {"text": "In Proceedings of NAACL - HLT .", "entities": []}, {"text": "pages 161\u2013169 .", "entities": []}, {"text": "Aniruddha Ghosh and Tony Veale . 2017 .", "entities": []}, {"text": "Magnets for sarcasm : Making sarcasm detection timely , contextual and very personal .", "entities": [[5, 7, "TaskName", "sarcasm detection"]]}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , pages 482\u2013491 .", "entities": []}, {"text": "https:// doi.org/10.18653/v1/D17-1050 .", "entities": []}, {"text": "Debanjan Ghosh , Alexander R. Fabbri , and Smaranda Muresan .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Sarcasm analysis using conversation context .Computational", "entities": []}, {"text": "Linguistics 44(4):755 \u2013 792 . https://doi.org/10.1162/coli_a _ 00336 .", "entities": []}, {"text": "Debanjan Ghosh , Weiwei Guo , and Smaranda Muresan . 2015 .", "entities": []}, {"text": "Sarcastic or not : Word embeddings to predict the literal or sarcastic meaning of words .", "entities": [[4, 6, "TaskName", "Word embeddings"]]}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , Lisbon , Portugal , pages 1003\u20131012 .", "entities": []}, {"text": "http://aclweb.org/ anthology / D15 - 1116 .", "entities": []}, {"text": "Debanjan Ghosh and Smaranda Muresan .", "entities": []}, {"text": "2018 . \u201d", "entities": []}, {"text": "with 1 follower i must be awesome : P. \u201d exploring the role of irony markers in irony recognition .", "entities": []}, {"text": "In Twelfth International AAAI Conference on Web and Social Media .", "entities": []}, {"text": "Debanjan Ghosh , Alexander Richard Fabbri , and Smaranda Muresan . 2017 .", "entities": []}, {"text": "The role of conversation context for sarcasm detection in online interactions .", "entities": [[6, 8, "TaskName", "sarcasm detection"]]}, {"text": "In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue .", "entities": []}, {"text": "Association for Computational Linguistics , Saarbrcken , Germany , pages 186\u2013196 .", "entities": []}, {"text": "http://aclweb . org / anthology / W17 - 5523 .", "entities": []}, {"text": "Raymond W Gibbs .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "On the psycholinguistics of sarcasm .", "entities": []}, {"text": "Journal of Experimental Psychology : General 115(1):3 .", "entities": [[5, 6, "DatasetName", "General"]]}, {"text": "Rachel Giora .", "entities": []}, {"text": "1995 .", "entities": []}, {"text": "On irony and negation .", "entities": []}, {"text": "Discourse processes 19(2):239\u2013264 .", "entities": []}, {"text": "Roberto Gonz \u00b4 alez - Ib \u00b4 a\u02dcnez , Smaranda Muresan , and Nina Wacholder .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Identifying sarcasm in twitter : A closer look .", "entities": []}, {"text": "In ACL ( Short Papers ) .", "entities": []}, {"text": "Association for Computational Linguistics , pages 581\u2013586 .", "entities": []}, {"text": "H Paul Grice . 1975 . \u201d", "entities": []}, {"text": "logic and conversation \u201d in cole , p. , and morgan , j.(eds . ) .", "entities": []}, {"text": "Syntax & Semantics 3 . Henk Haverkate . 1990 .", "entities": []}, {"text": "A speech act analysis of irony .", "entities": []}, {"text": "Journal of Pragmatics 14(1):77\u2013109 .", "entities": []}, {"text": "Devamanyu Hazarika , Soujanya Poria , Sruthi Gorantla , Erik Cambria , Roger Zimmermann , and Rada Mihalcea .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Cascade :", "entities": []}, {"text": "Contextual sarcasm detection in online discussion forums .", "entities": [[1, 3, "TaskName", "sarcasm detection"]]}, {"text": "InProceedings of", "entities": []}, {"text": "the 27th International Conference on Computational Linguistics .", "entities": []}, {"text": "Association for Computational Linguistics , pages 1837\u20131848 .", "entities": []}, {"text": "http://aclweb.org/ anthology / C18 - 1156 .", "entities": []}, {"text": "Laurence Horn .", "entities": []}, {"text": "1989 .", "entities": []}, {"text": "A natural history of negation .", "entities": []}, {"text": "The University of Chicago Press .", "entities": []}, {"text": "Minqing Hu and Bing Liu .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Mining and summarizing customer reviews .", "entities": []}, {"text": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "ACM , pages 168 \u2013 177 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Albrecht Werner Inhoff , Susan D Lima , and Patrick J Carroll .", "entities": []}, {"text": "1984 .", "entities": []}, {"text": "Contextual effects on metaphor comprehension in reading .", "entities": []}, {"text": "Memory & Cognition 12(6):558\u2013567 .", "entities": []}, {"text": "Stacey L Ivanko and Penny M Pexman .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Context incongruity and irony processing .", "entities": []}, {"text": "Discourse Processes 35(3):241\u2013279 .", "entities": []}, {"text": "Aditya Joshi , Vinita Sharma , and Pushpak Bhattacharyya . 2015 .", "entities": []}, {"text": "Harnessing context incongruity for sarcasm detection .", "entities": [[4, 6, "TaskName", "sarcasm detection"]]}, {"text": "In ACL ( 2 ) .", "entities": []}, {"text": "pages 757\u2013762 .", "entities": []}, {"text": "Jihen Karoui , Farah Benamara , V \u00b4 eronique Moriceau , Viviana Patti , Cristina Bosco , and Nathalie Aussenac - Gilles . 2017 .", "entities": []}, {"text": "Exploring the impact of pragmatic phenomena on irony detection in tweets : A multilingual corpus study .", "entities": []}, {"text": "Association for Computational Linguistics ( ACL ) .", "entities": []}, {"text": "Albert N Katz , Dawn G Blasko , and Victoria A Kazmerski .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Saying what you do n\u2019t mean : Social in\ufb02uences on sarcastic language processing .", "entities": []}, {"text": "Current Directions in Psychological Science 13(5):186\u2013189 .", "entities": []}, {"text": "Philipp Koehn , Hieu Hoang , Alexandra Birch , Chris Callison - Burch , Marcello Federico , Nicola Bertoldi , Brooke Cowan , Wade Shen , Christine Moran , Richard Zens , et al . 2007 .", "entities": []}, {"text": "Moses : Open source toolkit for statistical machine translation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions .", "entities": []}, {"text": "Association for Computational Linguistics , pages 177 \u2013 180 .", "entities": []}, {"text": "Roger J Kreuz .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "The production and processing of verbal irony .", "entities": []}, {"text": "Metaphor and Symbol 15(1 - 2):99 \u2013 107 .", "entities": []}, {"text": "Roger J Kreuz and Sam Glucksberg .", "entities": []}, {"text": "1989 .", "entities": []}, {"text": "How to be sarcastic : The echoic reminder theory of verbal irony .", "entities": []}, {"text": "Journal of experimental psychology : General 118(4):374 .", "entities": [[5, 6, "DatasetName", "General"]]}, {"text": "Hao Li and Wei Lu .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Learning with structured representations for negation scope extraction .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Papers ) .", "entities": []}, {"text": "volume 2 , pages 533\u2013539.CC Liebrecht , FA Kunneman , and APJ van den Bosch .", "entities": [[7, 8, "MethodName", "FA"]]}, {"text": "2013 .", "entities": []}, {"text": "The perfect solution for detecting sarcasm in tweets # not .", "entities": []}, {"text": "In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity , Sentiment and Social Media Analysis .", "entities": []}, {"text": "Diana Maynard and Mark A Greenwood .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Who cares about sarcastic tweets ?", "entities": []}, {"text": "investigating the impact of sarcasm on sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of LREC .", "entities": []}, {"text": "Bel\u00b4en M \u00b4 endez - Naya . 2008 .", "entities": []}, {"text": "Special issue on english intensi\ufb01ers .", "entities": []}, {"text": "English Language and Linguistics 12(02):213\u2013219 .", "entities": []}, {"text": "Abhijit Mishra , Diptesh Kanojia , Seema Nagar , Kuntal Dey , and Pushpak Bhattacharyya .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Harnessing cognitive features for sarcasm detection .", "entities": [[4, 6, "TaskName", "sarcasm detection"]]}, {"text": "InProceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) .", "entities": []}, {"text": "Association for Computational Linguistics , Berlin , Germany , pages 1095\u20131104 .", "entities": []}, {"text": "https:// doi.org/10.18653/v1/P16-1104 .", "entities": []}, {"text": "Saif M. Mohammad , Bonnie J. Dorr , Graeme Hirst , and Peter D. Turney .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Computing lexical contrast .", "entities": []}, {"text": "Computational Linguistics 39(3):555\u2013590 .", "entities": []}, {"text": "Smaranda Muresan , Roberto Gonzalez - Ibanez , Debanjan Ghosh , and Nina Wacholder . 2016 .", "entities": []}, {"text": "Identi\ufb01cation of nonliteral language in social media : A case study on sarcasm .Journal of the Association for Information Science and Technology http://dx .", "entities": []}, {"text": "doi.org/10.1002/asi.23624 .", "entities": []}, {"text": "Franz Josef Och and Hermann Ney . 2000 .", "entities": []}, {"text": "Giza++ : Training of statistical translation models .", "entities": []}, {"text": "Franz Josef Och and Hermann Ney .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "The alignment template approach to statistical machine translation .", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "Computational linguistics 30(4):417\u2013449 .", "entities": []}, {"text": "Silviu Oprea and Walid Magdy .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Exploring author context for detecting intended vs perceived sarcasm .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "pages 2854\u20132859 .", "entities": []}, {"text": "Lotem Peled and Roi Reichart .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Sarcasm sign : Interpreting sarcasm with sentiment based monolingual machine translation .", "entities": [[9, 11, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1704.06836 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Zhong Qian , Peifeng Li , Qiaoming Zhu , Guodong Zhou , Zhunchen Luo , and Wei Luo . 2016 .", "entities": []}, {"text": "Speculation and negation scope detection via convolutional neural networks .", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "pages 815\u2013825 .", "entities": []}, {"text": "Johan Reitan , J\u00f8rgen Faret , Bj \u00a8orn Gamb \u00a8ack , and Lars Bungum . 2015 .", "entities": []}, {"text": "Negation scope detection for twitter sentiment analysis .", "entities": [[4, 7, "DatasetName", "twitter sentiment analysis"]]}, {"text": "In Proceedings of the 6th Workshop on Computational Approaches to Subjectivity , Sentiment and Social Media Analysis .", "entities": []}, {"text": "pages 99\u2013108 .", "entities": []}, {"text": "Ellen Riloff , Ashequl Qadir , Prafulla Surve , Lalindra De Silva , Nathan Gilbert , and Ruihong Huang .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Sarcasm as contrast between a positive sentiment and negative situation .", "entities": []}, {"text": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , pages 704\u2013714 .", "entities": []}, {"text": "Rossano Schifanella , Paloma de Juan , Joel Tetreault , and Liangliang Cao . 2016 .", "entities": []}, {"text": "Detecting sarcasm in multimodal social platforms .", "entities": []}, {"text": "In Proceedings of the 2016 ACM on Multimedia Conference .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "ACM , pages 1136\u20131145 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Dan Sperber and Deirdre Wilson .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "Relevance : Communication and cognition , volume 142 .", "entities": []}, {"text": "Harvard University Press Cambridge , MA .", "entities": [[3, 4, "DatasetName", "Cambridge"]]}, {"text": "Maite Taboada , Julian Brooke , Milan To\ufb01loski , Kimberly V oll , and Manfred Stede . 2011 .", "entities": []}, {"text": "Lexicon - based methods for sentiment analysis .", "entities": [[5, 7, "TaskName", "sentiment analysis"]]}, {"text": "Computational linguistics 37(2):267\u2013307 .", "entities": []}, {"text": "Yi Tay , Anh Tuan Luu , Siu Cheung Hui , and Jian Su . 2018 .", "entities": []}, {"text": "Reasoning with sarcasm by reading inbetween .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) .", "entities": []}, {"text": "Association for Computational Linguistics , pages 1010\u20131020 .", "entities": []}, {"text": "http : //aclweb.org / anthology / P18 - 1093 .", "entities": []}, {"text": "Arie Verhagen .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Constructions of intersubjectivity : Discourse , syntax , and cognition .", "entities": []}, {"text": "Oxford University Press on Demand .", "entities": []}, {"text": "Byron C Wallace , Do Kook Choe , Laura Kertz , and Eugene Charniak .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Humans require context to infer ironic intent ( so computers probably do , too ) .", "entities": []}, {"text": "InACL ( 2 ) .", "entities": []}, {"text": "pages 512\u2013516 .", "entities": []}, {"text": "Cynthia Whissell , Michael Fournier , Rene Pelland , Deborah Weir , and Katherine Makarec .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "A dictionary of affect in language : Iv . reliability , validity , and applications .", "entities": []}, {"text": "Perceptual and Motor Skills 62(3):875\u2013888 .", "entities": []}, {"text": "Deirdre Wilson and Dan Sperber .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Explaining irony .", "entities": []}, {"text": "Meaning and relevance pages 123\u2013145 .", "entities": []}, {"text": "Theresa Wilson , Janyce Wiebe , and Paul Hoffmann .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Recognizing contextual polarity in phraselevel sentiment analysis .", "entities": [[5, 7, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the conference on human language technology and empirical methods in natural language processing .", "entities": []}, {"text": "Association for Computational Linguistics , pages 347\u2013354 .", "entities": []}, {"text": "Tao Xiong , Peiran Zhang , Hongbo Zhu , and Yihui Yang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Sarcasm detection with self - matching networks and low - rank bilinear pooling .", "entities": [[0, 2, "TaskName", "Sarcasm detection"]]}, {"text": "In The World Wide Web Conference . ACM , pages 2115 \u2013 2124 .", "entities": [[7, 8, "DatasetName", "ACM"]]}, {"text": "Meishan Zhang , Yue Zhang , and Guohong Fu . 2016 .", "entities": []}, {"text": "Tweet sarcasm detection using deep neural network .", "entities": [[1, 3, "TaskName", "sarcasm detection"]]}, {"text": "InCOLING .", "entities": []}]