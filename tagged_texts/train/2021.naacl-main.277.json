[{"text": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 3536\u20133553 June 6\u201311 , 2021 .", "entities": []}, {"text": "\u00a9 2021 Association for Computational Linguistics3536Controllable Text Simpli\ufb01cation with Explicit Paraphrasing Mounica Maddela1 , Fernando Alva - Manchego2 , Wei Xu1 1School of Interactive Computing , Georgia Institute of Technology 2Department of Computer Science , University of Shef\ufb01eld { mounica.maddela , wei.xu}@cc.gatech.edu f.alva@sheffield.ac.uk Abstract Text Simpli\ufb01cation improves the readability of sentences through several rewriting transformations , such as lexical paraphrasing , deletion , and splitting .", "entities": []}, {"text": "Current simpli\ufb01cation systems are predominantly sequence - to - sequence models that are trained end - to - end to perform all these operations simultaneously .", "entities": []}, {"text": "However , such systems limit themselves to mostly deleting words and can not easily adapt to the requirements of different target audiences .", "entities": []}, {"text": "In this paper , we propose a novel hybrid approach that leverages linguistically - motivated rules for splitting and deletion , and couples them with a neural paraphrasing model to produce varied rewriting styles .", "entities": []}, {"text": "We introduce a new data augmentation method to improve the paraphrasing capability of our model .", "entities": [[4, 6, "TaskName", "data augmentation"]]}, {"text": "Through automatic and manual evaluations , we show that our proposed model establishes a new state - ofthe art for the task , paraphrasing more often than the existing systems , and can control the degree of each simpli\ufb01cation operation applied to the input texts.1 1 Introduction Text Simpli\ufb01cation aims to improve the readability of texts with simpler grammar and word choices while preserving meaning ( Saggion , 2017 ) .", "entities": []}, {"text": "It provides reading assistance to children ( Kajiwara et al . , 2013 ) , non - native speakers ( Petersen and Ostendorf , 2007 ; Pellow and Eskenazi , 2014 ; Paetzold , 2016 ) , and people with reading disabilities ( Rello et al . , 2013 ) .", "entities": []}, {"text": "It also helps with downstream natural language processing tasks , such as parsing ( Chandrasekar et al . , 1996 ) , semantic role labelling ( Vickrey and Koller , 2008 ) , information extraction ( Miwa et al . , 2010 ) , and machine translation ( MT , Chen et al . , 2012 ; \u0160tajner and Popovic , 2016 ) .", "entities": [[45, 47, "TaskName", "machine translation"]]}, {"text": "Since 2016 , nearly all text simpli\ufb01cation systems have been sequence - to - sequence ( seq2seq ) 1Our code and data are available at https://github . com / mounicam / controllable_simplification .OLen", "entities": [[16, 17, "MethodName", "seq2seq"]]}, {"text": "% new % eq % split Complex ( input ) 20.7 0.0 100.0 0.0 Narayan and Gardent ( 2014 ) y10.4 0.7 0.8 0.4 Zhang and Lapata ( 2017 ) y 13.8 8.1 16.8 0.0 Dong et al .", "entities": []}, {"text": "( 2019)y 10.9 8.4 4.6 0.0 Kriz et al .", "entities": []}, {"text": "( 2019)y 10.8 11.2 1.2 0.0 LSTM 17.0 6.1 28.4 1.2 Our Model 17.1 17.0 3.0 31.8 Simple ( reference ) 17.9 29.0 0.0 30.0 Table 1 : Output statistics of 500 random sentences from the Newsela test set .", "entities": [[6, 7, "MethodName", "LSTM"], [36, 37, "DatasetName", "Newsela"]]}, {"text": "Existing systems rely on deletion and do not paraphrase well .", "entities": []}, {"text": "OLen , % new , % eq and%split denote the average output length , percentage of new words added , percentage of system outputs that are identical to the inputs , and percentage of sentence splits , respectively .", "entities": []}, {"text": "yWe used the system outputs shared by their authors .", "entities": []}, {"text": "models trained end - to - end , which have greatly increased the \ufb02uency of the outputs ( Zhang and Lapata , 2017 ; Nisioi et al . , 2017 ; Zhao et", "entities": []}, {"text": "al . , 2018 ; Kriz et al . , 2019 ; Dong et al . , 2019 ; Jiang et al . , 2020 ) .", "entities": []}, {"text": "However , these systems mostly rely on deletion and tend to generate very short outputs at the cost of meaning preservation ( Alva - Manchego et al . , 2017 ) .", "entities": []}, {"text": "Table 1 shows that they neither split sentences nor paraphrase well as re\ufb02ected by the low percentage of splits ( < 1 % ) and new words introduced ( < 11.2 % ) .", "entities": []}, {"text": "While deleting words is a viable ( and the simplest ) way to reduce the complexity of sentences , it is suboptimal and unsatisfying .", "entities": []}, {"text": "Professional editors are known to use a sophisticated combination of deletion , paraphrasing , and sentence splitting to simplify texts ( Xu et", "entities": []}, {"text": "al . , 2015 ) .", "entities": []}, {"text": "Another drawback of these end - to - end neural systems is the lack of controllability .", "entities": []}, {"text": "Simpli\ufb01cation is highly audience dependant , and what constitutes simpli\ufb01ed text for one group of users may not be acceptable for other groups ( Xu et", "entities": []}, {"text": "al . , 2015 ; Lee and Yeung , 2018 ) .", "entities": []}, {"text": "An ideal simpli\ufb01cation system should be able to generate text with varied characteristics , such as different lengths , readability levels , and number of split sentences , which can be dif\ufb01cult to control in end - to - end systems .", "entities": []}, {"text": "3537 Figure 1 : Overview of our proposed model for text simpli\ufb01cation , which can perform a controlled combination of sentence splitting , deletion , and paraphrasing .", "entities": []}, {"text": "To address these issues , we propose a novel hybrid approach that combines linguisticallymotivated syntactic rules with data - driven neural models to improve the diversity and controllability of the simpli\ufb01cations .", "entities": []}, {"text": "We hypothesize that the seq2seq generation model will learn lexical and structural paraphrases more ef\ufb01ciently from the parallel corpus , when we of\ufb02oad some of the burden of sentence splitting ( e.g. , split at comma ) and deletion ( e.g. , remove trailing preposition phrases ) decisions to a separate component .", "entities": [[4, 5, "MethodName", "seq2seq"]]}, {"text": "Previous hybrid approaches for simpli\ufb01cation ( Narayan and Gardent , 2014 ; Siddharthan and Mandya , 2014 ; Sulem et al . , 2018c ) used splitting and deletion rules in a deterministic step before applying an MT - based paraphrasing model .", "entities": []}, {"text": "In contrast , our approach provides a more \ufb02exible and dynamic integration of linguistic rules with the neural models through ranking and data augmentation ( Figure 1 ) .", "entities": [[22, 24, "TaskName", "data augmentation"]]}, {"text": "We compare our method to several state - of - theart systems in both automatic and human evaluations .", "entities": []}, {"text": "Our model achieves overall better performance measured by SARI ( Xu et al . , 2016 ) and other metrics , showing that the generated outputs are more similar to those written by human editors .", "entities": []}, {"text": "We also demonstrate that our model can control the extent of each simpli\ufb01cation operation by : ( 1 ) imposing a soft constraint on the percentage of words to be copied from the input in the seq2seq model , thus limiting lexical paraphrasing ; and ( 2 ) selecting candidates that underwent a desired amount of splitting and/or deletion .", "entities": [[36, 37, "MethodName", "seq2seq"]]}, {"text": "Finally , we create a new test dataset with multiple human references for Newsela ( Xu et", "entities": [[13, 14, "DatasetName", "Newsela"]]}, {"text": "al . , 2015 ) , the widely used text simpli\ufb01cation corpus , to speci\ufb01cally evaluate lexical paraphrasing.2 Our Approach Figure 1 shows an overview of our hybrid approach .", "entities": []}, {"text": "We combine linguistic rules with data - driven neural models to improve the controllability and diversity of the outputs .", "entities": []}, {"text": "Given an input complex sentence x , we \ufb01rst generate a set of intermediate simpli\ufb01cationsV = fv1;v2;:::;vngthat have undergone splitting and deletion ( \u00a7 2.1 ) .", "entities": []}, {"text": "These intermediate sentences are then used for two purposes : ( 1 ) Selected by a pairwise neural ranking model ( \u00a7 2.2 ) based on the simpli\ufb01cation quality and then rewritten by the paraphrasing component ; ( 2 ) Used for data augmentation to improve the diversity of the paraphrasing model ( \u00a7 2.3 ) .", "entities": [[42, 44, "TaskName", "data augmentation"]]}, {"text": "2.1 Splitting and Deletion We leverage the state - of - the - art system for structural simpli\ufb01cation , called DisSim ( Niklaus et al . , 2019 ) , to generate candidate simpli\ufb01cations that focus on splitting and deletion.2The English version of DisSim applies 35 hand - crafted grammar rules to break down a complex sentence into a set of hierarchically organized sub - sentences ( see Figure 1 for an example ) .", "entities": []}, {"text": "We choose a rule - based approach for sentence splitting because it works really well .", "entities": []}, {"text": "In our pilot experiments , DisSim successfully split 92 % of 100 complex sentences from the training data with more than 20 words , and introduced errors for only 6.8 % of these splits .", "entities": []}, {"text": "We consider these sub - sentences as candidate simpli\ufb01cations for the later steps , except those that are extremely short or long ( compression ratio = 2[0.5 , 1.5 ] ) .", "entities": []}, {"text": "The compression ratio is calculated as the number of 2https://github.com/Lambda-3/ DiscourseSimplification", "entities": []}, {"text": "3538words in a candidate simpli\ufb01cation vi(which may contain one or more sub - sentences ) divided by that of the original sentence x.", "entities": []}, {"text": "To further increase the variety of generated candidates , we supplement DisSim with a Neural Deletion and Split module trained on the text simpli\ufb01cation corpus ( \u00a7 3.1 ) .", "entities": []}, {"text": "We use a Transformer seq2seq model with the same con\ufb01guration as the base model for paraphrasing ( \u00a7 2.3 ) .", "entities": [[3, 4, "MethodName", "Transformer"], [4, 5, "MethodName", "seq2seq"]]}, {"text": "Given the input sentence x , we constrain the beam search to generate 10 outputs with splitting and another 10 outputs without splitting .", "entities": []}, {"text": "Then , we select the outputs that do not deviate substantially from x(i.e . , Jaccard similarity > 0.5 ) .", "entities": []}, {"text": "We add outputs from the two systems to the candidate pool V. 2.2 Candidate Ranking", "entities": []}, {"text": "We design a neural ranking model to score all the candidates that underwent splitting and deletion , V = fv1;v2;:::;vng , then feed the top - ranked one to the lexical paraphrasing model for the \ufb01nal output .", "entities": []}, {"text": "We train the model on a standard text simpli\ufb01cation corpus consisting of pairs of complex sentence xand manually simpli\ufb01ed reference y. Scoring Function .", "entities": []}, {"text": "To assess the \u201c goodness \u201d of each candidate viduring training , we de\ufb01ne the gold scoring function g\u0003as a length - penalized BERTscore : g\u0003(vi;y )", "entities": []}, {"text": "= e\u0000\u0015jj \u001e vi\u0000 \u001e yjj\u0002 BERTScore ( vi;y)(1 ) BERTScore ( Zhang et al . , 2020b ) is a text similarity metric that uses BERT ( Devlin et al . , 2019 ) embeddings to \ufb01nd soft matches between word pieces ( Wu et al . , 2016 ) instead of exact string matching .", "entities": [[21, 23, "TaskName", "text similarity"], [26, 27, "MethodName", "BERT"]]}, {"text": "We introduce a length penalty to favor the candidates that are of similar length to the human reference yand penalize those that deviate from the target compression ratio \u001e y.\u0015de\ufb01nes the extent of penalization and is set to 1 in our experiments .", "entities": []}, {"text": "vi represents the compression ratios of vicompared to the input x.", "entities": []}, {"text": "In principle , other similarity metrics can also be used for scoring .", "entities": []}, {"text": "Pairwise Ranking Model .", "entities": []}, {"text": "We train the ranking model in a pairwise setup since BERTScore is sensitive to the relative rather than absolute similarity , when comparing multiple candidates with the same reference .", "entities": []}, {"text": "We transform the gold ranking of V ( jVj = n ) inton2pairwise comparisons for everycandidate pair , and learn to minimize the pairwise ranking violations using hinge loss : LMR=1 mmX k=11 n2 knkX i=1nkX j=1;i6 = jmax(0;1\u0000lk ijdk ij ) dk ij = g(vk i)\u0000g(vk j ) lk", "entities": [[28, 29, "MetricName", "loss"]]}, {"text": "ij = sign\u0010 g\u0003(vk i;yk)\u0000g\u0003(vk j;yk)\u0011 ( 2 ) whereg(:)is a feedforward neural network , mis the number of training complex - simple sentence pairs , kis the index of training examples , and nkrepresents the number of generated candidates ( \u00a7 2.1 ) .", "entities": []}, {"text": "On average , nkis about 14.5 for a sentence of 30 words , and can be larger for longer sentences .", "entities": []}, {"text": "We consider 10 randomly sampled candidates for each complex sentence during training .", "entities": []}, {"text": "Features .", "entities": []}, {"text": "For the feedforward network g (: ) , we use the following features : number of words in viandx , compression ratio of viwith respect to x , Jaccard similarity between viandx , the rules applied on xto obtain vi , and the number of rule applications .", "entities": [[2, 4, "MethodName", "feedforward network"]]}, {"text": "We vectorize all the real - valued features using Gaussian binning ( Maddela and Xu , 2018 ) , which has shown to help neural models trained on numerical features ( Liu et al . , 2016 ; Sil et al . , 2017 ; Zhong et al . , 2020 ) .", "entities": []}, {"text": "We concatenate these vectors before feeding them to the ranking model .", "entities": []}, {"text": "We score each candidate viseparately and rank them in the decreasing order of g(vi ) .", "entities": []}, {"text": "We provide implementation details in Appendix A. 2.3 Paraphrase Generation", "entities": [[8, 10, "TaskName", "Paraphrase Generation"]]}, {"text": "We then paraphrase the top - ranked candidate ^v2", "entities": []}, {"text": "Vto generate the \ufb01nal simpli\ufb01cation output ^ y. Our paraphrase generation model can explicitly control the extent of lexical paraphrasing by specifying the percentage of words to be copied from the input sentence as a soft constraint .", "entities": [[9, 11, "TaskName", "paraphrase generation"]]}, {"text": "We also introduce a data augmentation method to encourage our model to generate more diverse outputs .", "entities": [[4, 6, "TaskName", "data augmentation"]]}, {"text": "Base Model .", "entities": []}, {"text": "Our base generation model is a Transformer encoder - decoder initialized by the BERT checkpoint ( ? ) , which achieved the best reported performance on text simpli\ufb01cation in the recent work ( Jiang et al . , 2020 ) .", "entities": [[6, 7, "MethodName", "Transformer"], [13, 14, "MethodName", "BERT"]]}, {"text": "We enhance this model with an attention - based copy mechanism to encourage lexical paraphrasing , while remaining faithful to the input .", "entities": []}, {"text": "3539Copy Control .", "entities": []}, {"text": "Given the input candidate ^v=", "entities": []}, {"text": "( ^v1;^v2 ; : : : ; ^vl)oflwords and the percentage of copyingcp2(0;1 ] , our goal is to paraphrase the rest of ( 1\u0000cp)\u0002lwords in ^vto a simpler version .", "entities": []}, {"text": "To achieve this , we convert cpinto a vector of the same dimension as BERT embeddings using Gaussian binning ( Maddela and Xu , 2018 ) and add it to the beginning of the input sequence ^v .", "entities": [[14, 15, "MethodName", "BERT"]]}, {"text": "The Transformer encoder then produces a sequence of context - aware hidden states H= ( h1;h2:::hl ) , where hicorresponds to the hidden state of ^vi .", "entities": [[1, 2, "MethodName", "Transformer"]]}, {"text": "Eachhiis fed into the copy network which predicts the probability pithat word ^vishould be copied to output .", "entities": []}, {"text": "We create a new hidden state \u0016hiby adding hito a vector uscaled according to pi .", "entities": []}, {"text": "In other words , the scaled version of uinforms the decoder whether the word should be copied .", "entities": []}, {"text": "A single vectoruis used across all sentences and hidden states , and is randomly initialized then updated during training .", "entities": []}, {"text": "More formally , the encoding process can be described as follows : ( h1;h2;:::;hl ) = encoder ( [ cp ; ^v1;^v2 ; : : : ; ^vl ] ) \u0016hi = hi+pi\u0001u ; \u0016H= ( \u0016h1;\u0016h2 ; : : : ; \u0016hl ) ( 3 ) The Transformer decoder generates the output sequence from \u0016H. Our copy mechanism is incorporated into the encoder rather than copying the input words during the decoding steps ( Gu et al . , 2016 ; See et al . , 2017 ) .", "entities": [[48, 50, "MethodName", "Transformer decoder"]]}, {"text": "Unless otherwise speci\ufb01ed , we use the average copy ratio of the training dataset , 0.7 , for our experiments .", "entities": []}, {"text": "Multi - task Training .", "entities": []}, {"text": "We train the paraphrasing model and the copy network in a multi - task learning setup , where predicting whether a word should be copied serves as an auxiliary task .", "entities": [[11, 15, "TaskName", "multi - task learning"]]}, {"text": "The gold labels for this task are obtained by checking if each word in the input sentence also appears in the human reference .", "entities": []}, {"text": "When a word occurs multiple times in the input , we rely on the monolingual word alignment results from JacanaAlign ( Yao et al . , 2013 ) to determine which occurrence is the one that gets copied .", "entities": [[15, 17, "TaskName", "word alignment"]]}, {"text": "We train the Transformer model and the copy network jointly by minimizing the cross - entropy loss for both decoder generation and binary word classi\ufb01cation .", "entities": [[3, 4, "MethodName", "Transformer"], [16, 17, "MetricName", "loss"]]}, {"text": "We provide implementation and training details in Appendix A. Data Augmentation .", "entities": [[9, 11, "TaskName", "Data Augmentation"]]}, {"text": "The sentence pairs in the training corpus often exhibit a variable mix of splitting and deletion operations along with paraphras - ing ( see Figure 1 for an example ) , which makes it dif\ufb01cult for the encoder - decoder models to learn paraphrases .", "entities": []}, {"text": "Utilizing DisSim , we create additional training data that focuses on lexical paraphrasing For each sentence pair hx;yi , we \ufb01rst generate a set of candidates V = fv1;v2;:::;vngby applying DisSim to x , as described in \u00a7 2.1 .", "entities": []}, {"text": "Then , we select a a subset of V , calledV0 = fv0 1;v0 2;:::;v0 n0 g ( V02V ) that are fairly close to the reference y , but have only undergone splitting and deletion .", "entities": []}, {"text": "We score each candidate viusing the length - penalized BERTScore g\u0003(vi;y)in Eq .", "entities": []}, {"text": "( 1 ) , and discard those with scores lower than 0.5 .", "entities": []}, {"text": "While calculating g\u0003 , we set \u001e yand\u0015to 1 and 2 respectively to favor candidates of similar length to the reference y. We also discard the candidates that have different number of split sentences with respect to the reference .", "entities": []}, {"text": "Finally , we train our model on the \ufb01ltered candidate - reference sentence pairs hv0 1;yi , hv0 2;yi , : : : , hv0 n0;yi , which focus on lexical paraphrasing , in addition tohx;yi . 2.4 Controllable Generation We can control our model to concentrate on speci\ufb01c operations .", "entities": []}, {"text": "For split- or delete - focused simpli\ufb01cation , we select candidates with desirable length or number of splits during the candidate generation step .", "entities": []}, {"text": "We perform only the paraphrase generation step for paraphrase - focused simpli\ufb01cation .", "entities": [[4, 6, "TaskName", "paraphrase generation"]]}, {"text": "The paraphrasing model is designed speci\ufb01cally to paraphrase with minimal deletion and without splitting .", "entities": []}, {"text": "It retains the length and the number of split sentences in the output , thus preserving the extent of deletion and splitting controlled in the previous steps .", "entities": []}, {"text": "We control the degree of paraphrasing by changing the copy ratio .", "entities": []}, {"text": "3 Experiments In this section , we compare our approach to various sentence simpli\ufb01cation models using both automatic and manual evaluations .", "entities": []}, {"text": "We show that our model achieves a new state - of - the - art and can adapt easily to different simpli\ufb01cation styles , such as paraphrasing and splitting without deletion .", "entities": []}, {"text": "3.1 Data and Experiment Setup We train and evaluate our models on Newsela ( Xu et al . , 2015)3and Wikipedia copora ( Zhu et al . , 2010 ; Woodsend and Lapata , 2011 ; Coster and Kauchak , 2011 ) .", "entities": [[12, 13, "DatasetName", "Newsela"]]}, {"text": "Newsela consists of 1,882 news 3https://newsela.com/data/", "entities": [[0, 1, "DatasetName", "Newsela"]]}, {"text": "3540Models SARI add keep del FK SLen OLen CR % split s - BL % new", "entities": []}, {"text": "% eq Complex ( input ) 15.9 0.0 47.6 0.0 12.0 23.7 23.8 1.0 0.0 100.0 0.0 100.0 Simple ( reference ) 90.5", "entities": []}, {"text": "86.8 86.6 98.2 7.4 14.4 19.0 0.83 28.0 35.5 33.0 0.0 LSTM 35.0 1.6 45.5 57.8 8.9 17.6 17.9 0.8 1.9 66.5 5.0 20.2 Hybrid - NG 35.8 1.9 41.8 63.7 9.9 21.2 23.7 1.0 11.6 59.7 8.8 5.1 Transformer bert 37.0 3.1 43.6 64.4 8.1 15.6 20.2 0.87 24.1 58.8 12.8 10.2 EditNTS 38.1 1.6 45.8 66.5 8.5 16.0 21.4 0.92 32.0 71.4 8.3 0.2 Our Model 38.7 3.3 42.9 70.0 7.9 15.8 20.1 0.86 23.9 48.7 16.2 0.4 Table 2 : Automatic evaluation results on N EWSELA -AUTO test set .", "entities": [[11, 12, "MethodName", "LSTM"], [39, 40, "MethodName", "Transformer"]]}, {"text": "We report SARI , the main automatic metric for simpli\ufb01cation , and its three edit scores namely precision for delete ( del ) and F1 scores for add andkeep operations .", "entities": [[24, 25, "MetricName", "F1"]]}, {"text": "We also report FKGL ( FK ) , average sentence length ( SLen ) , output length ( OLen ) , compression ratio ( CR ) , self - BLEU ( s - BL ) , percentage of sentence splits ( % split ) , average percentage of new words added to the output ( % new ) , and percentage of sentences identical to the input ( % eq ) .Bold", "entities": [[29, 30, "MetricName", "BLEU"]]}, {"text": "typeface denotes the best performances ( i.e. , closest to the reference ) .", "entities": []}, {"text": "articles with each article rewritten by professional editors for students in different grades .", "entities": []}, {"text": "We used the complex - simple sentence pairs automatically aligned by Jiang et al .", "entities": []}, {"text": "( 2020 ) , called the NEWSELA AUTO dataset .", "entities": [[6, 7, "DatasetName", "NEWSELA"]]}, {"text": "To capture sentence splitting , we joined the adjacent sentences in the simple article that are aligned to the same sentence in the complex article .", "entities": []}, {"text": "Following \u0160tajner", "entities": []}, {"text": "et", "entities": []}, {"text": "al . ( 2015 ) , we removed the sentence pairs with high ( > 0.9 ) and low ( < 0.1 ) BLEU ( Papineni et", "entities": [[23, 24, "MetricName", "BLEU"]]}, {"text": "al . , 2002 ) scores , which mostly correspond to the near identical and semantically divergent sentence pairs respectively .", "entities": []}, {"text": "The \ufb01nal dataset consists of 259,778 train , 32,689 validation and 33,391 test complex - simple sentence pairs , where\u001830 % of pairs involve sentence splitting .", "entities": []}, {"text": "Besides Newsela , we also provide the details of experiments on Wikipedia corpus in Appendix F , which show similar trends .", "entities": [[1, 2, "DatasetName", "Newsela"]]}, {"text": "To demonstrate that our model can be controlled to generate diverse simpli\ufb01cations , we evaluate under the following settings : ( i ) Standard evaluation on the NEWSELA -AUTO test set similar to the methodology in the recent literature ( Jiang et al . , 2020 ;", "entities": [[27, 28, "DatasetName", "NEWSELA"]]}, {"text": "Dong et al . , 2019 ; Zhang and Lapata , 2017 ) , and ( ii ) Evaluation on different subsets of the NEWSELA -AUTO test set that concentrate on a speci\ufb01c operation .", "entities": [[24, 25, "DatasetName", "NEWSELA"]]}, {"text": "We selected 9,356 sentence pairs with sentence splits for split - focused evaluation .", "entities": []}, {"text": "Similarly , we chose 9,511 sentence pairs with compression ratio < 0.7 and without sentences splits to evaluate delete - focused simpli\ufb01cation .", "entities": []}, {"text": "We created a new dataset , called NEWSELA TURK , to evaluate lexical paraphrasing.4Similar to the WIKIPEDIA -TURK benchmark corpus ( Xu et al . , 2016 ) , NEWSELA -TURK consists of human - written references focused on lexical para4We also provide results on 8,371 sentence pairs of NEWSELA -AUTO test set with compression ratio > 0.9 and no splits in Appendix D , which show similar trends.phrasing .", "entities": [[7, 8, "DatasetName", "NEWSELA"], [29, 30, "DatasetName", "NEWSELA"], [49, 50, "DatasetName", "NEWSELA"]]}, {"text": "We \ufb01rst selected sentence pairs from the NEWSELA -AUTO test set of roughly similar length ( compression ratio between 0.8 and 1.2 ) and no sentence splits because they more likely involve paraphrasing .", "entities": [[7, 8, "DatasetName", "NEWSELA"]]}, {"text": "Then , we asked Amazon Mechanical Turk workers to simplify the complex sentence without any loss in meaning.5To ensure the quality of simpli\ufb01cations , we manually selected the workers using the quali\ufb01cation test proposed in AlvaManchego et al .", "entities": [[15, 16, "MetricName", "loss"]]}, {"text": "( 2020 ) , during which the workers were asked to simplify three sentences .", "entities": []}, {"text": "We selected top 35 % of the 300 workers that participated in the test .", "entities": []}, {"text": "We periodically checked the submissions and removed the bad workers .", "entities": []}, {"text": "In the end , we collected 500 sentences with 4 references for each sentence .", "entities": []}, {"text": "3.2 Existing Methods We use the following simpli\ufb01cation approaches as baselines : ( i ) BERT - Initialized Transfomer ( ? ) , where the encoder is initialized with BERT base checkpoint and the decoder is randomly initialized .", "entities": [[15, 16, "MethodName", "BERT"], [29, 30, "MethodName", "BERT"]]}, {"text": "It is the current state - of - the - art for text simpli\ufb01cation ( Jiang et al . , 2020 ) .", "entities": []}, {"text": "( ii ) EditNTS ( Dong et al . , 2019),6another state - of - the - art model that uses a neural programmer - interpreter ( Reed and de Freitas , 2016 ) to predict the edit operation on each word , and then generates the simpli\ufb01ed sentence .", "entities": []}, {"text": "( iii ) LSTM baseline , a vanilla encoderdecoder model used in Zhang and Lapata ( 2017 ) .", "entities": [[3, 4, "MethodName", "LSTM"]]}, {"text": "( iv)Hybrid - NG ( Narayan and Gardent , 2014),7 one of the best existing hybrid systems that performs splitting and deletion using a probabilistic model and lexical substitution with a phrase - based machine translation system .", "entities": [[34, 36, "TaskName", "machine translation"]]}, {"text": "We retrained all the models on the N EWSLA -AUTO dataset .", "entities": []}, {"text": "5We provide instructions in Appendix B 6https://github.com/yuedongP/EditNTS 7https://github.com/shashiongithub/ Sentence - Simplification - ACL14", "entities": []}, {"text": "3541Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 22.3 0.0 67.0 0.0 12.8 23.3 23.5 1.0 0.0 100.0 0.0 100.0 Simple ( reference )", "entities": []}, {"text": "62.3 44.8 68.3 73.9 11.1 23.8 23.5 1.01 0.0 48.5 24.1 0.0", "entities": []}, {"text": "Hybrid - NG 38.2 2.8 57.0 54.8 10.7 21.6 23.1 0.98 7.0 57.2 9.1 1.4 Transformer bert 36.0 3.3 54.9 49.8 8.9 16.1 20.2 0.87 23.0 58.7 13.3 7.6 EditNTS 37.4 1.6 61.0 49.6 9.5 16.9 21.9 0.94 0.0 73.1 5.8 0.0 Our Model 38.1 3.9 55.1 55.5 8.8 16.6 20.2 0.86 19.6 50.4 15.7 0.0", "entities": [[15, 16, "MethodName", "Transformer"]]}, {"text": "Our Model ( no split ; cp= 0.6 ) 39.0 3.8 57.7 55.6 11.2 22.1 22.9 0.98 0.2 55.9 18.0 1.0 Our Model ( no split ; cp= 0.7 ) 41.0 3.4 63.1 56.6 11.5 22.2 22.9 0.98 0.0 69.4 10.4 4.2", "entities": []}, {"text": "Our Model ( no split ; cp= 0.8 ) 40.6 2.9 65.0 54.0 11.8 22.4 23.2 0.99 0.0 77.7 6.6 10.8 Table 3 : Automatic evaluation results on N EWSELA -TURK that focuses on paraphrasing ( 500 complex sentences with 4 human written paraphrases ) .", "entities": []}, {"text": "We control the extent of paraphrasing of our models by specifying the percentage of words to be copied ( cp ) from the input as a soft constraint .", "entities": []}, {"text": "Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 17.0 0.0 51.1 0.0 14.6 30.0 30.2 1.0 0.0 100.0 0.0 100.0 Simple ( reference ) 93.0 89.9 91.6 97.5 7.0 13.4 28.6 0.98 100.0 36.8 29.7 0.0 Hybrid - NG 37.1 2.2 44.9 64.1 11.6 25.5 30.1 1.0 17.3 57.7 8.7 1.6 Transformer bert 39.5 4.2 47.3 67.0 8.8 17.1 25.3 0.85 39.7 57.7 11.9 5.2 EditNTS 38.9 1.5 49.1 66.2 9.1 16.9 26.2 0.88 50.3 71.2 7.2 0.2 Our Model 39.4 4.0 46.6 67.6 8.7 17.5 25.5 0.85 40.6 48.3 15.6 0.1 Our Model ( w/ split ) 42.1 5.6 50.6 70.1 8.1 15.3 30.3 1.02 93.5 60.7 12.4 1.1 Table 4 : Automatic evaluation results on a splitting - focused subset of the N EWSELA -AUTO test set ( 9,356 sentence pairs with splitting ) .", "entities": [[65, 66, "MethodName", "Transformer"]]}, {"text": "Our model chooses only candidates that have undergone splitting during the ranking step .", "entities": []}, {"text": "Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 9.6 0.0 28.8 0.0 12.9 25.8 26.0 1.0 0.0 100.0 0.0 100.0 Simple ( reference ) 85.7 82.7 76.0 98.6 6.7 12.6 12.6 0.5 0.0 19.6 32.6 0.0 Hybrid - NG 35.8 1.4 27.0 79.1 10.6 22.7 25.9 1.0 13.3 58.9 8.7 3.6 Transformer bert 36.8 2.2 29.6 78.7 8.4 16.2 21.7 0.85 27.7 57.9 12.3 8.2 EditNTS 37.1 1.0 29.7 80.7 8.8 16.6 23.1 0.91 36.6 71.8 7.8 0.6 Our Model 39.2 2.4 29.8 85.3 8.2 16.4 21.9 0.85 29.1", "entities": [[65, 66, "MethodName", "Transformer"]]}, {"text": "48.8 15.6 0.4", "entities": []}, {"text": "Our Model ( no split ; CR < 0.7 ) 38.2 2.0 28.5 84.1 8.6 16.8 17.5 0.68 0.1 42.0 12.5 0.2 Table 5 : Automatic evaluation results on a deletion - focused subset of the N EWSELA -AUTO test set ( 9,511 sentence pairs with compression ratio < 0.7 and no sentence splits ) .", "entities": []}, {"text": "Our model selects only candidates with similar compression ratio and no splits during ranking .", "entities": []}, {"text": "3.3 Automatic Evaluation Metrics .", "entities": []}, {"text": "We report SARI ( Xu et al . , 2016 ) , which averages the F1 / precision of n - grams ( n2 f1;2;3;4g)inserted , deleted and kept when compared to human references .", "entities": [[15, 16, "MetricName", "F1"]]}, {"text": "More speci\ufb01cally , it computes the F1 score for the n - grams that are added ( add),8which is an important indicator if a model is good at paraphrasing .", "entities": [[6, 8, "MetricName", "F1 score"]]}, {"text": "The model \u2019s deletion capability is measured by the F1 score for n - grams that are kept ( keep ) and precision for those deleted ( del).9To evaluate a model \u2019s para8We slightly improved the SARI implementation by Xu", "entities": [[9, 11, "MetricName", "F1 score"]]}, {"text": "et al .", "entities": []}, {"text": "( 2016 ) to exclude the spurious ngrams while calculating the F1 score for add .", "entities": [[11, 13, "MetricName", "F1 score"]]}, {"text": "For example , if the input contains the phrase \u201c is very beautiful \u201d , the phrase \u201c is beautiful \u201d is treated as a new phrase in the original implementation even though it is caused by the delete operation .", "entities": []}, {"text": "9SARI score of a reference with itself may not always be 100 as it considers 0 divided by 0 as 0 , instead of 1 , when calculating n - gram precision and recall .", "entities": [[15, 16, "DatasetName", "0"], [18, 19, "DatasetName", "0"], [20, 21, "DatasetName", "0"]]}, {"text": "This avoids the in\ufb02ation ofdelscores when the input is same as the output.phrasing capability and diversity , we calculate the BLEU score with respect to the input ( s - BL ) , the percentage of new words ( % new ) added , and the percentage of system outputs identical to the input ( % eq ) .", "entities": [[20, 22, "MetricName", "BLEU score"]]}, {"text": "Low s - BL , % eq , or high % new indicate that the system is less conservative .", "entities": []}, {"text": "We also report Flesch - Kincaid ( FK ) grade level readability ( Kincaid and Chissom , 1975 ) , average sentence length ( SLen ) , the percentage of splits ( % split ) , compression ratio ( CR ) , and average output length ( OLen ) .", "entities": []}, {"text": "We do not report BLEU because it often does not correlate with simplicity ( Sulem et al . , 2018a , b ; Xu et", "entities": [[4, 5, "MetricName", "BLEU"]]}, {"text": "al . , 2016 ) .", "entities": []}, {"text": "Results .", "entities": []}, {"text": "Table 2 shows the results on NEWSELA AUTO test set .", "entities": [[6, 7, "DatasetName", "NEWSELA"]]}, {"text": "Our model outperforms the state - ofthe - art Transformer bertand EditNTS models with respect to SARI.10EditNTS and LSTM focus on 10According to Jiang et al .", "entities": [[9, 10, "MethodName", "Transformer"], [18, 19, "MethodName", "LSTM"]]}, {"text": "( 2020 ) , a BERT - initialized Transformer performs better than EditNTS .", "entities": [[5, 6, "MethodName", "BERT"], [8, 9, "MethodName", "Transformer"]]}, {"text": "We see a different behavior here because we retained sentence splits from 0 - 1 , 1 - 2 ,", "entities": [[12, 13, "DatasetName", "0"]]}, {"text": "3542Overall Simpli\ufb01cation Structural Simpli\ufb01cation Model Fluency Adequacy Simplicity Average Fluency Adequacy Has Split Correct Split Hybrid - NG 3.23 * 2.96 * 3.40 * 3.19 * 3.25 *", "entities": []}, {"text": "3.53 * 42 % 15 % EditNTS 3.88 * 3.70 3.67 3.75 4.08 3.81 * 41 % 18 % Transformer bert 3.91 3.63 3.65 * 3.73 4.15 3.65 * 53 % 49 % Our Model 4.02 3.65 3.77 3.81 4.19 4.13 97 % 90 % Simple ( reference ) 4.12 3.64 3.97 3.84 4.41 4.10 100 % 100 % Table 6 : Human evaluation of 100 random simpli\ufb01cations from the N EWSELA -AUTO test set and the split - focused subset of the same test set .", "entities": [[19, 20, "MethodName", "Transformer"]]}, {"text": "Has Split andCorrect Split denote the percentage of the output sentences that have undergone splitting and the percentage of coherent splits respectively .", "entities": []}, {"text": "* denotes that our model is signi\ufb01cantly better than the corresponding baseline ( according to a t - test withp<0:05 ) .", "entities": []}, {"text": "deletion as they show high self - BLEU ( > 66.5 ) and FK ( > 8.8 ) scores despite having compression ratios similar to other systems .", "entities": [[7, 8, "MetricName", "BLEU"]]}, {"text": "Transformer model alone is rather conservative and copies 10.2 % of the sentences directly to the output .", "entities": [[0, 1, "MethodName", "Transformer"]]}, {"text": "Although HybridNG makes more changes than any other baselines , its SARI and add scores are 3.7 and 1.7 points lower than our model indicating that it generates more errors .", "entities": []}, {"text": "Our model achieves the lowest self - BLEU ( 48.7 ) , FK ( 7.9 ) , and percentage of sentences identical to the input ( 0.4 ) , and the highest add ( 3.3 ) score and percentage of new words ( 16.2 % ) .", "entities": [[7, 8, "MetricName", "BLEU"]]}, {"text": "In other words , our system is the least conservative , generates more good paraphrases , and mimics the human references better .", "entities": []}, {"text": "We provide examples of system outputs in Table 9 and Appendix C. Tables 3 , 4 , and 5 show the results on NEWSELA TURK , split - focused , and delete - focused subsets of NEWSELA -AUTO test set respectively .", "entities": [[23, 24, "DatasetName", "NEWSELA"], [36, 37, "DatasetName", "NEWSELA"]]}, {"text": "For these experiments , we con\ufb01gure our model to focus on speci\ufb01c operations ( details in \u00a7 2.4 ) .", "entities": []}, {"text": "Our model again outperforms the existing systems according to SARI , add score , and percentage of new words , which means that our model is performing more meaningful paraphrasing .", "entities": []}, {"text": "We show that we can control the extent of paraphrasing by varying the copy ratio ( cp ) .", "entities": []}, {"text": "Our model splits 93.5 % of the sentences , which is substantially better than the other models .", "entities": []}, {"text": "3.4 Human Evaluation We performed two human evaluations : one to measure the overall simpli\ufb01cation quality and the other to speci\ufb01cally capture sentence splitting.11For the \ufb01rst one , we asked \ufb01ve Amazon Mechanical Turk workers to evaluate \ufb02uency , adequacy and simplicity of 100 random simpli\ufb01cations from the NEWSELA -AUTO test set .", "entities": [[48, 49, "DatasetName", "NEWSELA"]]}, {"text": "We supplemented the 2 - 3 readability levels in NEWSELA -AUTO , which contained more lexical overlaps and in\ufb02ated the scores for EditNTS .", "entities": [[9, 10, "DatasetName", "NEWSELA"]]}, {"text": "11We provide instructions in Appendix E.\ufb02uency and adequacy ratings with binary questions described in Zhang", "entities": []}, {"text": "et al .", "entities": []}, {"text": "( 2020a ) for the second evaluation over another 100 simpli\ufb01cations from theNEWSELA -AUTO split - focused test set .", "entities": []}, {"text": "We asked if the output sentence exhibits spitting and if the splitting occurs at the correct place .", "entities": []}, {"text": "While \ufb02uency measures the grammaticality of the output , adequacy captures the extent of meaning preserved when compared to the input .", "entities": []}, {"text": "Simplicity evaluates if the output is simpler than the input .", "entities": []}, {"text": "Each sentence was rated on a 5 - point Likert scale and we averaged the ratings from the \ufb01ve workers .", "entities": []}, {"text": "We chose the majority value for the binary ratings .", "entities": []}, {"text": "We used the output of our model that is tailored for sentence splitting for the second evaluation .", "entities": []}, {"text": "Table 6 demonstrates that our model achieves the best \ufb02uency , simplicity , and overall ratings .", "entities": []}, {"text": "The adequacy rating is also very close to that of Transformer bertand EditNTS even though our model is performing more paraphrasing ( Table 2 ) , which veri\ufb01es that the changes made by our system are meaningful .", "entities": [[10, 11, "MethodName", "Transformer"]]}, {"text": "Our model achieves the most number of correct sentence splits ( 90 % ) , and the highest \ufb02uency ( 4.19 ) for syntactic simpli\ufb01cation , showing that it can generate more number of coherent sentence splits when compared to other models .", "entities": []}, {"text": "4 Model Analysis In this section , we analyze the contribution of each model component and examine the system errors .", "entities": []}, {"text": "4.1 System Ablations We evaluate our key design choices , namely candidate ranking that is based on length - penalized BERTScore and paraphrase generation that uses data augmentation and copy attention .", "entities": [[22, 24, "TaskName", "paraphrase generation"], [26, 28, "TaskName", "data augmentation"]]}, {"text": "Table 8 summarizes the results .", "entities": []}, {"text": "Our pairwise ranking model ( BERTScore len ) achieves an increase of 3.2 points in SARI when compared to choosing a random ( Random ) candidate .", "entities": []}, {"text": "Randomly selecting a candidate also performs fairly well , indicating that the", "entities": []}, {"text": "3543Examples Good ( 49 % )", "entities": []}, {"text": "Complex", "entities": []}, {"text": "The Seattle kids petitioned Washington state last year to adopt stricter science - based regulations to protect them against climate change .", "entities": []}, {"text": "Simple The eight kids from Seattle who petitioned Washington state last year are \ufb01ghting for the state to adopt stricter laws to protect their future against climate change .", "entities": []}, {"text": "Our Model The Seattle kids asked the Washington state last year to take tougher rules against climate change .", "entities": []}, {"text": "Hallucinations ( 13 % ) Complex \u201c It \u2019s more of a family than living outside , \u201d said Jessica Konczal , 33 , whose husband is Sgt .", "entities": []}, {"text": "Matthew Konczal .", "entities": []}, {"text": "Simple Jessica Konczal , age 33 , says the base is its own type of family .", "entities": []}, {"text": "Our Model \u201c It \u2019s more of a family than living outside , \u201d said Jessica Konczal , one of the protesters .", "entities": []}, {"text": "Fluency Errors ( 14 % ) Complex Parental feedback on the menu additions so far , from some of the early adopter markets , has been \u201c phenomenal , \u201d Leverton said .", "entities": []}, {"text": "Simple Leverton said parents love the new food .", "entities": []}, {"text": "Our Model So far , parents parents have feedback on the menu changes has been a great deal , he added .", "entities": []}, {"text": "Bad Substitution ( 15 % ) Complex One of the device \u2019s inventors explained to the president that the machine was a prototype .", "entities": []}, {"text": "Simple One of the girls explained it was just a prototype .", "entities": []}, {"text": "Our Model One of the inventors toldthe president that the \ufb01rst design was a design .", "entities": []}, {"text": "Anaphora Resolution / Entailment ( 12 % ) Complex Sea slugs dubbed sacoglossans are some of the most remarkable biological burglars on the planet .", "entities": []}, {"text": "Simple The sea slugs known as sacoglossans are some of the most interesting burglars on the planet .", "entities": []}, {"text": "Our Model Scientists say these are some of the most interesting creatures on the planet .", "entities": []}, {"text": "Human Reference Errors ( 4 % ) Complex", "entities": []}, {"text": "They \ufb02oat in and out of formations that combine the underwater world with the stage .", "entities": []}, {"text": "Simple In the dance on a round stage on the seabed , the dancers swim together and apart .", "entities": []}, {"text": "Our Model They \ufb02oat in and out of places that combine stage with the underwater .", "entities": []}, {"text": "Table 7 : Error analysis of 200 simpli\ufb01cations from N EWSELA -AUTO test set generated by our model .", "entities": [[3, 4, "MetricName", "Error"]]}, {"text": "Red marks the errors ; blue marks good paraphrases .", "entities": []}, {"text": "SARI FK CR % split % new Complex ( input ) 15.9 12.2 1.0 0.0 0.0 Simple ( reference ) 90.5 7.5 0.83 28.9 32.8 Random Candidate 33.7 8.1 0.81 34.4 5.5 BERTScore len 36.9 9.0 0.87 25.9 5.9 Our Model 38.6 8.4 0.88 26.1 18.9 \u0000augmentation 37.6 7.9 0.86 29.5 12.7 \u0000copy", "entities": []}, {"text": "attn 36.0 8.1 0.87 26.2 15.9 \u0000only Transformer 37.9 7.7 0.78 26.3 16.5 \u0000only DisSim 37.2 8.3 0.84 27.1 18.0 Table 8 : Model ablation study on dev set sentence splitting and deletion models we chose are of good quality .", "entities": [[7, 8, "MethodName", "Transformer"]]}, {"text": "Compared to our \ufb01nal model ( Our Model ) , its variants without data augmentation ( \u0000augmentation ) and copy mechanism ( \u0000copy attn ) suffer a drop of 1.0 and 2.6 points in SARI respectively and a decrease of at least 3.0 % of new words , which demonstrates that these components encourage the system to paraphrase .", "entities": [[13, 15, "TaskName", "data augmentation"]]}, {"text": "Our model trained on only DisSim ( \u0000only DisSim ) and Transformer ( \u0000only Transformer ) candidates performs close to our best model ( Our Model ) in terms of SARI .", "entities": [[11, 12, "MethodName", "Transformer"], [14, 15, "MethodName", "Transformer"]]}, {"text": "4.2 Error Analysis To understand the errors generated by our model , we manually classi\ufb01ed 200 simpli\ufb01cations from theNEWSELA -AUTO test set into the following categories : ( a ) Good , where the model generated meaningful simpli\ufb01cations , ( b ) Hallucinations , where the model introduced information not in the input , ( c)Fluency Errors , where the model generated ungrammatical output , ( d ) Anaphora Resolution , where it was dif\ufb01cult to resolve pronouns in the output .", "entities": [[1, 2, "MetricName", "Error"]]}, {"text": "( e ) Bad substitution , where the model inserted an incorrect simpler phrase , and ( e ) Human Reference Errors , where the reference does not re\ufb02ect the source sentence .", "entities": []}, {"text": "Note that a simpli\ufb01cation can belong to multiple error categories .", "entities": []}, {"text": "Table 7 shows the examples of each category .", "entities": []}, {"text": "5 Related Work Before the advent of neural networks , text simpli\ufb01cation approaches performed each operation separately in a pipeline manner using either handcrafted rules ( Carroll et al . , 1999 ; Siddharthan , 2002 ; Siddharthan et al . , 2004 ) or data - driven methods based on parallel corpora ( Zhu et al . , 2010 ; Woodsend and Lapata , 2011 ; Narayan and Gardent , 2014 ) .", "entities": []}, {"text": "Following neural machine translation , the trend changed to performing all the operations together end - toend ( Zhang and Lapata , 2017 ; Nisioi et al . , 2017 ; Zhao et al . , 2018 ; Alva - Manchego et al . , 2017 ; Vu", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "3544System Outputs Complex Since 2010 , project researchers have uncovered documents in Portugal that have revealed who owned the ship .", "entities": []}, {"text": "Simple Since 2010 , experts have been \ufb01guring out who owned the ship .", "entities": []}, {"text": "Hybrid - NG since 2010 , the project scientists have uncovered documents in portugal that have about who owns the ship .", "entities": []}, {"text": "LSTM since 2010 , scientists have uncovered documents in portugal that have revealed who owned the ship .", "entities": [[0, 1, "MethodName", "LSTM"]]}, {"text": "Transformer bert they discovered that the ship had been important .", "entities": [[0, 1, "MethodName", "Transformer"]]}, {"text": "EditNTS since 2010 , project researchers have uncovered documents in portugal .", "entities": []}, {"text": "have revealed who owned the ship .", "entities": []}, {"text": "Our Model ( cp= 0.6 ) scientists have found asecret deal .", "entities": []}, {"text": "they have discovered who owned the ship .", "entities": []}, {"text": "Our Model ( cp= 0.7 ) scientists have found documents in portugal .", "entities": []}, {"text": "they have also found out who owned the ship .", "entities": []}, {"text": "Our Model ( cp= 0.8 ) scientists have found documents in portugal .", "entities": []}, {"text": "they have discovered who owned the ship .", "entities": []}, {"text": "Complex Experts say China \u2019s air pollution exacts a tremendous toll on human health .", "entities": []}, {"text": "Simple China \u2019s air pollution is very unhealthy .", "entities": []}, {"text": "Hybrid - NG experts say the government \u2019s air pollution exacts a toll on human health .", "entities": []}, {"text": "LSTM experts say china \u2019s air pollution exacts a tremendous toll on human health .", "entities": [[0, 1, "MethodName", "LSTM"]]}, {"text": "Transformer bert experts say china \u2019s pollution has a tremendous effect on human health .", "entities": [[0, 1, "MethodName", "Transformer"]]}, {"text": "EditNTS experts say china \u2019s air pollution can cause human health .", "entities": []}, {"text": "Our Model ( cp= 0.6 ) experts say china \u2019s air pollution is a big problem for human health .", "entities": []}, {"text": "Our Model ( cp= 0.7 ) experts say china \u2019s air pollution can cause a lot of damage on human health .", "entities": []}, {"text": "Our Model ( cp= 0.8 ) experts say china \u2019s air pollution isahuge toll on human health .", "entities": []}, {"text": "Table 9 : Examples of system outputs .", "entities": []}, {"text": "Red marks the errors ; blue marks good paraphrases .", "entities": []}, {"text": "cpis a soft constraint that denotes the percentage of words that can be copied from the input .", "entities": []}, {"text": "et", "entities": []}, {"text": "al . , 2018 ; Kriz et al . , 2019 ; Dong et al . , 2019 ; Jiang et al . , 2020 ) at the cost of controllability and performance as shown in this paper .", "entities": []}, {"text": "Controllable text simpli\ufb01cation has been attempted before , but only with limited capability .", "entities": []}, {"text": "Scarton and Specia ( 2018 ) and Martin et al . ( 2020 ) added additional tokens to the input representing grade level , length , lexical , and structural complexity constraints .", "entities": []}, {"text": "Nishihara et al .", "entities": []}, {"text": "( 2019 ) proposed a loss which controls word complexity , while Mallinson and Lapata ( 2019 ) concatenated constraints to each word embedding .", "entities": [[5, 6, "MetricName", "loss"]]}, {"text": "Kumar et al .", "entities": [[0, 1, "DatasetName", "Kumar"]]}, {"text": "( 2020 ) proposed a linguistic scoring function to control the edits to the input .", "entities": []}, {"text": "Another long body of research focuses on a single simpli\ufb01cation operation and can be broadly divided into three categories : ( 1 ) Lexical Simpli\ufb01cation ( Specia et al . , 2012 ;", "entities": []}, {"text": "Horn et al . , 2014 ; Glava\u0161 and \u0160tajner , 2015 ; Paetzold and Specia , 2017 , 2015 ; Maddela and Xu , 2018 ; Qiang et al . , 2020 ) , where complex words are substituted with simpler words .", "entities": []}, {"text": "( 2 ) Syntactic Simpli\ufb01cation ( Siddharthan , 2006 ; Aharoni and Goldberg , 2018 ; Botha et al . , 2018 ; Niklaus et al . , 2019 ) , which deals exclusively with sentence splitting , and ( 3 ) Sentence Compression ( Filippova et al . , 2015 ; Rush et al . , 2015 ; Nallapati et al . , 2016 ; See et al . , 2017 ; Baziotis et al . , 2019 ) , where the goal is to shorten the input sentence by removing its irrelevant content.6 Conclusion We proposed a novel hybrid approach for sentence simpli\ufb01cation that performs better and produces more diverse outputs than the existing systems .", "entities": [[42, 44, "DatasetName", "Sentence Compression"]]}, {"text": "We designed a new data augmentation method to encourage the model to paraphrase .", "entities": [[4, 6, "TaskName", "data augmentation"]]}, {"text": "We created a new dataset , NEWSELA -TURK , to evaluate paraphrasing - focused simpli\ufb01cations .", "entities": [[6, 7, "DatasetName", "NEWSELA"]]}, {"text": "We showed that our model can control various attributes of the simpli\ufb01ed text , such as number of sentence splits , length , and number of words copied from the input .", "entities": []}, {"text": "Acknowledgments We thank the anonymous reviewers for their valuable feedback .", "entities": []}, {"text": "We thank Newsela for sharing the data and NVIDIA for providing GPU computing resources .", "entities": [[2, 3, "DatasetName", "Newsela"]]}, {"text": "This research is supported in part by the NSF award IIS-1822754 , ODNI and IARPA via the BETTER program contract 19051600004 .", "entities": []}, {"text": "The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the of\ufb01cial policies , either expressed or implied , of NSF , ODNI , IARPA , or the U.S. Government .", "entities": []}, {"text": "The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein .", "entities": []}, {"text": "3545References Roee Aharoni and Yoav Goldberg .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Split and rephrase : Better evaluation and stronger baselines .", "entities": []}, {"text": "InProceedings of the 56th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Fernando Alva - Manchego , Joachim Bingel , Gustavo Paetzold , Carolina Scarton , and Lucia Specia .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Learning how to simplify from explicit labeling of complex - simpli\ufb01ed text pairs .", "entities": []}, {"text": "In Proceedings of the Eighth International Joint Conference on Natural Language Processing .", "entities": []}, {"text": "Fernando Alva - Manchego , Louis Martin , Antoine Bordes , Carolina Scarton , Beno\u00eet Sagot , and Lucia Specia .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "ASSET :", "entities": [[0, 1, "DatasetName", "ASSET"]]}, {"text": "A dataset for tuning and evaluation of sentence simpli\ufb01cation models with multiple rewriting transformations .", "entities": []}, {"text": "In Proceedings of the Association for Computational Linguistics .", "entities": []}, {"text": "Christos Baziotis , Ion Androutsopoulos , Ioannis Konstas , and Alexandros Potamianos .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "SEQ\u02c63 :", "entities": []}, {"text": "Differentiable sequence - to - sequence - to - sequence autoencoder for unsupervised abstractive sentence compression .", "entities": [[10, 11, "MethodName", "autoencoder"], [14, 16, "DatasetName", "sentence compression"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .", "entities": []}, {"text": "Jan A. Botha , Manaal Faruqui , John Alex , Jason Baldridge , and Dipanjan Das . 2018 .", "entities": []}, {"text": "Learning to split and rephrase from Wikipedia edit history .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "John Carroll , Guido Minnen , Darren Pearce , Yvonne Canning , Siobhan Devlin , and John Tait . 1999 .", "entities": []}, {"text": "Simplifying text for language - impaired readers .", "entities": []}, {"text": "In Proceedings of the 9th Conference of the European Chapter of the ACL .", "entities": []}, {"text": "R. Chandrasekar , Christine Doran , and B. Srinivas .", "entities": []}, {"text": "1996 .", "entities": []}, {"text": "Motivations and methods for text simpli\ufb01cation .", "entities": []}, {"text": "In The 16th International Conference on Computational Linguistics .", "entities": []}, {"text": "Han - Bin Chen , Hen - Hsen Huang , Hsin - Hsi Chen , and Ching - Ting Tan . 2012 .", "entities": []}, {"text": "A simpli\ufb01cation - translationrestoration framework for cross - domain SMT applications .", "entities": []}, {"text": "In Proceedings of the 24th International Conference on Computational Linguistics .", "entities": []}, {"text": "William Coster and David Kauchak . 2011 .", "entities": []}, {"text": "Simple English Wikipedia : A new text simpli\ufb01cation task .", "entities": []}, {"text": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .", "entities": []}, {"text": "BERT : Pre - training of deep bidirectional transformers for language understanding .", "entities": [[0, 1, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .Yue", "entities": []}, {"text": "Dong , Zichao Li , Mehdi Rezagholizadeh , and Jackie Chi Kit Cheung .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "EditNTS : An neural programmer - interpreter model for sentence simpli\ufb01cation through explicit editing .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Katja Filippova , Enrique Alfonseca , Carlos Colmenares , Lukasz Kaiser , and Oriol Vinyals . 2015 .", "entities": []}, {"text": "Sentence compression by deletion with lstms .", "entities": [[0, 2, "DatasetName", "Sentence compression"]]}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Goran Glava\u0161 and Sanja \u0160tajner . 2015 .", "entities": []}, {"text": "Simplifying lexical simpli\ufb01cation : Do we need simpli\ufb01ed corpora ?", "entities": []}, {"text": "InProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing .", "entities": []}, {"text": "Jiatao Gu , Zhengdong Lu , Hang Li , and Victor O.K. Li . 2016 .", "entities": []}, {"text": "Incorporating copying mechanism in sequence - to - sequence learning .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Colby Horn , Cathryn Manduca , and David Kauchak .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Learning a lexical simpli\ufb01er using wikipedia .", "entities": []}, {"text": "InProceedings of the 52nd Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Chao Jiang , Mounica Maddela , Wuwei Lan , Yang Zhong , and Wei Xu . 2020 .", "entities": []}, {"text": "Neural CRF sentence alignment model for text simpli\ufb01cation .", "entities": [[1, 2, "MethodName", "CRF"]]}, {"text": "In Proceedings of the Association for Computational Linguistics .", "entities": []}, {"text": "Tomoyuki Kajiwara , Hiroshi Matsumoto , and Kazuhide Yamamoto .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Selecting proper lexical paraphrase for children .", "entities": []}, {"text": "In Proceedings of the 25th Conference on Computational Linguistics and Speech Processing .", "entities": []}, {"text": "Robert P. Jr. ; Rogers Richard L. ; Kincaid , J. Peter ; Fishburne and Brad S. Chissom .", "entities": []}, {"text": "1975 .", "entities": []}, {"text": "Derivation of new readability formulas ( automated readability index , fog count and \ufb02esch reading ease formula ) for navy enlisted personnel .", "entities": []}, {"text": "research branch report .", "entities": []}, {"text": "Diederik P. Kingma and Jimmy Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "CoRR , abs/1412.6980 .", "entities": []}, {"text": "Reno Kriz , Jo\u00e3o Sedoc , Marianna Apidianaki , Carolina Zheng , Gaurav Kumar , Eleni Miltsakaki , and Chris Callison - Burch .", "entities": [[13, 14, "DatasetName", "Kumar"]]}, {"text": "2019 .", "entities": []}, {"text": "Complexity - weighted loss and diverse reranking for sentence simpli\ufb01cation .", "entities": [[3, 4, "MetricName", "loss"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics .", "entities": []}, {"text": "Dhruv Kumar , Lili Mou , Lukasz Golab , and Vechtomova Olga . 2020 .", "entities": [[1, 2, "DatasetName", "Kumar"]]}, {"text": "Iterative edit - based unsupervised sentence simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the Association for Computational Linguistics .", "entities": []}, {"text": "3546John Lee and Chak Yan Yeung .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Personalizing lexical simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 27th International Conference on Computational Linguistics .", "entities": []}, {"text": "Dan Liu , Wei Lin , Shiliang Zhang , Si Wei , and Hui Jiang .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Neural networks models for entity discovery and linking .", "entities": []}, {"text": "CoRR , abs/1611.03558 .", "entities": []}, {"text": "Mounica Maddela and Wei Xu .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A wordcomplexity lexicon and a neural readability ranking model for lexical simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Jonathan Mallinson and Mirella Lapata .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Controllable sentence simpli\ufb01cation : Employing syntactic and lexical constraints .", "entities": []}, {"text": "Louis Martin , \u00c9ric de la Clergerie , Beno\u00eet Sagot , and Antoine Bordes .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Controllable sentence simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of The 12th Language Resources and Evaluation Conference .", "entities": []}, {"text": "Makoto Miwa , Rune S\u00e6tre , Yusuke Miyao , and Jun\u2019ichi Tsujii .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Entity - focused sentence simpli\ufb01cation for relation extraction .", "entities": [[6, 8, "TaskName", "relation extraction"]]}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics .", "entities": []}, {"text": "Ramesh Nallapati , Bowen Zhou , Cicero dos Santos , \u00c7a\u02d8glar Gu\u00cc\u2021l\u00e7ehre , and Bing Xiang .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Abstractive text summarization using sequence - to - sequence RNNs and beyond .", "entities": [[0, 3, "TaskName", "Abstractive text summarization"]]}, {"text": "In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning .", "entities": []}, {"text": "Shashi Narayan and Claire Gardent .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Hybrid simpli\ufb01cation using deep semantics and machine translation .", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Christina Niklaus , Matthias Cetto , Andr\u00e9 Freitas , and Siegfried Handschuh . 2019 .", "entities": []}, {"text": "Transforming complex sentences into a semantic hierarchy .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Daiki Nishihara , Tomoyuki Kajiwara , and Yuki Arase .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Controllable text simpli\ufb01cation with lexical constraint loss .", "entities": [[6, 7, "MetricName", "loss"]]}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics : Student Research Workshop .", "entities": []}, {"text": "Sergiu Nisioi , Sanja \u0160tajner , Simone Paolo Ponzetto , and Liviu P. Dinu . 2017 .", "entities": []}, {"text": "Exploring neural text simpli\ufb01cation models .", "entities": []}, {"text": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Gustavo Paetzold and Lucia Specia .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "LEXenstein : A framework for lexical simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of ACL - IJCNLP 2015 System Demonstrations .Gustavo", "entities": []}, {"text": "Paetzold and Lucia Specia .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Lexical simpli\ufb01cation with neural ranking .", "entities": []}, {"text": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics .", "entities": []}, {"text": "Gustavo Henrique Paetzold .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Lexical Simpli\ufb01cation for Non - Native English Speakers .", "entities": []}, {"text": "Ph.D. thesis , University of Shef\ufb01eld .", "entities": []}, {"text": "Kishore Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .", "entities": []}, {"text": "Bleu : A method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics .", "entities": []}, {"text": "David Pellow and Maxine Eskenazi .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "An open corpus of everyday documents for simpli\ufb01cation tasks .", "entities": []}, {"text": "In Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations .", "entities": []}, {"text": "Sarah E Petersen and Mari Ostendorf .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Text simpli\ufb01cation for language learners : A corpus analysis .", "entities": []}, {"text": "In Proceedings of Workshop on Speech and Language Technology for Education .", "entities": []}, {"text": "Jipeng Qiang , Yun Li , Zhu Yi , Yunhao Yuan , and Xindong Wu . 2020 .", "entities": []}, {"text": "Lexical simpli\ufb01cation with pretrained encoders .", "entities": []}, {"text": "Association for the Advancement of Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Scott E. Reed and Nando de Freitas .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Neural programmer - interpreters .", "entities": []}, {"text": "In 4th International Conference on Learning Representations .", "entities": []}, {"text": "Luz Rello , Ricardo Baeza - Yates , and Horacio Saggion .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "The impact of lexical simpli\ufb01cation by verbal paraphrases for people with and without dyslexia .", "entities": []}, {"text": "In Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing .", "entities": []}, {"text": "Alexander M. Rush , Sumit Chopra , and Jason Weston .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "A neural attention model for abstractive sentence summarization .", "entities": [[6, 8, "TaskName", "sentence summarization"]]}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Horacio Saggion .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Automatic text simpli\ufb01cation .", "entities": []}, {"text": "Synthesis Lectures on Human Language Technologies .", "entities": []}, {"text": "Carolina Scarton and Lucia Specia .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Learning simpli\ufb01cations for speci\ufb01c target audiences .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Abigail See , Peter J. Liu , and Christopher D. Manning .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Get to the point : Summarization with pointergenerator networks .", "entities": [[5, 6, "TaskName", "Summarization"]]}, {"text": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Advaith Siddharthan .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "An architecture for a text simpli\ufb01cation system .", "entities": []}, {"text": "In Proceedings of the Language Engineering Conference .", "entities": []}, {"text": "3547Advaith Siddharthan .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Syntactic simpli\ufb01cation and text cohesion .", "entities": []}, {"text": "Research on Language and Computation .", "entities": []}, {"text": "Advaith Siddharthan and Angrosh Mandya . 2014 .", "entities": []}, {"text": "Hybrid text simpli\ufb01cation using synchronous dependency grammars with hand - written and automatically harvested rules .", "entities": []}, {"text": "In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics .", "entities": []}, {"text": "Advaith Siddharthan , Ani Nenkova , and Kathleen McKeown .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Syntactic simpli\ufb01cation for improving content selection in multi - document summarization .", "entities": [[7, 11, "TaskName", "multi - document summarization"]]}, {"text": "In Proceedings of the 20th International Conference on Computational Linguistics .", "entities": []}, {"text": "Avirup Sil , Gourab Kundu , Radu Florian , and Wael Hamza . 2017 .", "entities": []}, {"text": "Neural cross - lingual entity linking .", "entities": [[1, 6, "TaskName", "cross - lingual entity linking"]]}, {"text": "InProceedings of the 30th Conference on Association for the Advancement of Arti\ufb01cial Intelligence .", "entities": []}, {"text": "Lucia Specia , Sujay Kumar Jauhar , and Rada Mihalcea .", "entities": [[4, 5, "DatasetName", "Kumar"]]}, {"text": "2012 .", "entities": []}, {"text": "Semeval-2012 task 1 : English lexical simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the First Joint Conference on Lexical and Computational Semantics : Proceedings of the Main Conference and the Shared Task and Proceedings of the Sixth International Workshop on Semantic Evaluation .", "entities": []}, {"text": "Sanja \u0160tajner , Hannah B\u00e9chara , and Horacio Saggion . 2015 .", "entities": []}, {"text": "A deeper exploration of the standard PB - SMT approach to text simpli\ufb01cation and its evaluation .", "entities": []}, {"text": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing .", "entities": []}, {"text": "Sanja \u0160tajner and Maja Popovic .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Can text simpli\ufb01cation help machine translation ?", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 19th Annual Conference of the European Association for Machine Translation .", "entities": [[12, 14, "TaskName", "Machine Translation"]]}, {"text": "Elior Sulem , Omri Abend , and Ari Rappoport . 2018a .", "entities": []}, {"text": "BLEU is not suitable for the evaluation of text simpli\ufb01cation .", "entities": [[0, 1, "MetricName", "BLEU"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Elior Sulem , Omri Abend , and Ari Rappoport .", "entities": []}, {"text": "2018b .", "entities": []}, {"text": "Semantic structural evaluation for text simpli\ufb01cation .", "entities": []}, {"text": "InProceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .", "entities": []}, {"text": "Elior Sulem , Omri Abend , and Ari Rappoport .", "entities": []}, {"text": "2018c .", "entities": []}, {"text": "Simple and effective text simpli\ufb01cation using semantic and neural methods .", "entities": []}, {"text": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "David Vickrey and Daphne Koller .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Sentence simpli\ufb01cation for semantic role labeling .", "entities": [[3, 6, "TaskName", "semantic role labeling"]]}, {"text": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics .Tu", "entities": []}, {"text": "Vu , Baotian Hu , Tsendsuren Munkhdalai , and Hong Yu .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Sentence simpli\ufb01cation with memoryaugmented neural networks .", "entities": []}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies .", "entities": []}, {"text": "Kristian Woodsend and Mirella Lapata .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Learning to simplify sentences with quasi - synchronous grammar and integer programming .", "entities": []}, {"text": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Yonghui Wu , Mike Schuster , Zhifeng Chen , Quoc V Le , Mohammad Norouzi , Wolfgang Macherey , Maxim Krikun , Yuan Cao , Qin Gao , Klaus Macherey , et al . 2016 .", "entities": []}, {"text": "Google \u2019s neural machine translation system : Bridging the gap between human and machine translation .", "entities": [[0, 1, "DatasetName", "Google"], [3, 5, "TaskName", "machine translation"], [13, 15, "TaskName", "machine translation"]]}, {"text": "arXiv preprint arXiv:1609.08144 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Wei Xu , Chris Callison - Burch , and Courtney Napoles .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Problems in current text simpli\ufb01cation research : New data can help .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics .", "entities": []}, {"text": "Wei Xu , Courtney Napoles , Ellie Pavlick , Quanze Chen , and Chris Callison - Burch . 2016 .", "entities": []}, {"text": "Optimizing statistical machine translation for text simpli\ufb01cation .", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "Transactions of the Association for Computational Linguistics .", "entities": []}, {"text": "Xuchen Yao , Benjamin Van Durme , Chris CallisonBurch , and Peter Clark .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "A lightweight and high performance monolingual word aligner .", "entities": []}, {"text": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Li Zhang , Huaiyu Zhu , Siddhartha Brahma , and Yunyao Li . 2020a .", "entities": []}, {"text": "Small but mighty : New benchmarks for split and rephrase .", "entities": []}, {"text": "Tianyi Zhang , Varsha Kishore , Felix Wu , Kilian Q. Weinberger , and Yoav Artzi .", "entities": []}, {"text": "2020b .", "entities": []}, {"text": "Bertscore :", "entities": []}, {"text": "Evaluating text generation with bert .", "entities": [[1, 3, "TaskName", "text generation"]]}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Xingxing Zhang and Mirella Lapata .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Sentence simpli\ufb01cation with deep reinforcement learning .", "entities": []}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Sanqiang Zhao , Rui Meng , Daqing He , Andi Saptono , and Bambang Parmanto .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Integrating transformer and paraphrase rules for sentence simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Yang Zhong , Chao Jiang , Wei Xu , and Junyi Jessy Li .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Discourse level factors for sentence deletion in text simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2020 Conference on Association for the Advancement of Arti\ufb01cial Intelligence .", "entities": []}, {"text": "3548Zhemin Zhu , Delphine Bernhard , and Iryna Gurevych .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "A monolingual tree - based translation model for sentence simpli\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics .", "entities": []}, {"text": "3549A Implementation and Training Details We implemented two separate Transformer models for neural deletion and split component ( \u00a7 2.1 ) and paraphrase generation ( \u00a7 2.3 ) using the Fairseq12 toolkit .", "entities": [[9, 10, "MethodName", "Transformer"], [22, 24, "TaskName", "paraphrase generation"]]}, {"text": "Both the encoder and decoder follow BERTbase13architecture , while the encoder is also initialized with BERT base checkpoint .", "entities": [[15, 16, "MethodName", "BERT"]]}, {"text": "For neural deletion and split component , we used a beam search of width 10 to generate candidates .", "entities": []}, {"text": "The copy attention mechanism is a feedforward network containing 3 hidden layers , 1000 nodes in each layer with tanh activation , and a single linear output node with sigmoid activation .", "entities": [[6, 8, "MethodName", "feedforward network"], [19, 21, "MethodName", "tanh activation"], [29, 31, "MethodName", "sigmoid activation"]]}, {"text": "We used Adam optimizer ( Kingma and Ba , 2014 ) with a learning rate of 0.0001 , linear learning rate warmup of 40k steps , and 100k training steps .", "entities": [[2, 3, "MethodName", "Adam"], [3, 4, "HyperparameterName", "optimizer"], [13, 15, "HyperparameterName", "learning rate"], [19, 21, "HyperparameterName", "learning rate"]]}, {"text": "We used a batch size of 64 .", "entities": [[3, 5, "HyperparameterName", "batch size"]]}, {"text": "We used BERT WordPiece tokenizer .", "entities": [[2, 3, "MethodName", "BERT"], [3, 4, "MethodName", "WordPiece"]]}, {"text": "During inference , we constrained the beam - search to not repeat trigrams and emitted sentences that avoided aggressive deletion ( compression ratio 2[0:9;1:2 ] .", "entities": []}, {"text": "We chose the best checkpoint based on the SARI score ( Xu et al . , 2016 ) on the dev set .", "entities": []}, {"text": "We saved a checkpoint after every epoch .", "entities": []}, {"text": "We did not perform any hyperparameter search and directly used the hyperparameters of the BERT - initialized Transformer described in ? .", "entities": [[14, 15, "MethodName", "BERT"], [17, 18, "MethodName", "Transformer"]]}, {"text": "The model takes 10 hours to train on 1 NVIDIA GeForce GPU .", "entities": []}, {"text": "Our pairwise ranking model , implemented using the PyTorch framework , consists of 3 hidden layers , 100 nodes in each layer , tanh activation , and a single linear output node .", "entities": [[23, 25, "MethodName", "tanh activation"]]}, {"text": "We used Adam optimizer with a learning rate of 0.01 and 10 epochs .", "entities": [[2, 3, "MethodName", "Adam"], [3, 4, "HyperparameterName", "optimizer"], [6, 8, "HyperparameterName", "learning rate"]]}, {"text": "We applied a dropout of 0.2 .", "entities": []}, {"text": "For Gaussian binning , we vectorized the numerical features into 10 dimensional vectors .", "entities": []}, {"text": "The model takes half hour to train on 1 NVIDIA GeForce GPU .", "entities": []}, {"text": "We do not perform any extensive hyperparameter tuning .", "entities": []}, {"text": "We just examined few values for learning rate ( 0.001 , 0.01 and 0.1 ) and chose the best based on the SARI score on the dev set .", "entities": [[6, 8, "HyperparameterName", "learning rate"]]}, {"text": "We used the original code for DisSim.14 12https://github.com/pytorch/fairseq 13https://github.com/google-research/ bert 14https://github.com/Lambda-3/ DiscourseSimplification", "entities": []}, {"text": "3550B Annotation Interface Figure 2 : Annotation guidelines for our N EWSELA -TURK corpus along with example questions .", "entities": []}, {"text": "3551C System Outputs System Outputs Complex", "entities": []}, {"text": "This year , the FAA has approved dozens of permits for agricultural drone businesses .", "entities": []}, {"text": "Simple This year , it approved dozens of permits for agricultural drone businesses .", "entities": []}, {"text": "Hybrid - NG this year , the government has approved dozens of drone permits for agricultural businesses .", "entities": []}, {"text": "LSTM this year , the faa has approved dozens of permits for agricultural drone businesses .", "entities": [[0, 1, "MethodName", "LSTM"]]}, {"text": "Transformer bert this year , the faa has approved dozens of permits for agricultural businesses .", "entities": [[0, 1, "MethodName", "Transformer"]]}, {"text": "EditNTS this year , the government has approved dozens of permits for drone businesses for no permission .", "entities": []}, {"text": "Our Model ( cp= 0.6 ) this year , the faa has allowed many businesses to use drones .", "entities": []}, {"text": "Our Model ( cp= 0.7 , 0.8 ) this year , the faa has approved dozens of permits for drones .", "entities": []}, {"text": "Complex The room echoed with the sounds of song , the beat of drums , the voices of young men .", "entities": []}, {"text": "Simple As she spoke , the building echoed with music and the beat of drums .", "entities": []}, {"text": "Hybrid - NG echoed the room .", "entities": []}, {"text": "LSTM the room echoed with the sounds of song , the voices of young men .", "entities": [[0, 1, "MethodName", "LSTM"]]}, {"text": "Transformer bert the room echoed with the sound of song , the beat of drums , the voices of young men .", "entities": [[0, 1, "MethodName", "Transformer"]]}, {"text": "EditNTS the room echoed with the sounds of song , the beat of drums , the voices of young men who are hungry and legs .", "entities": []}, {"text": "Our Model ( cp= 0.6 ) the sound of the room was full of sounds of young men and the voices of cellos .", "entities": []}, {"text": "Our Model ( cp= 0.7 ) the sound of the room sounded like a lot of music , and the voices of young men .", "entities": []}, {"text": "Our Model ( cp= 0.8 ) the sound of the room sounded like a song , the beat of drums , and the voices of young men .", "entities": []}, {"text": "Table 10 : Examples of system outputs by our paraphrase generation model and other baselines .", "entities": [[9, 11, "TaskName", "paraphrase generation"]]}, {"text": "Our model generates paraphrase - focused simpli\ufb01cations by skipping the splitting and deletion steps and running only the neural paraphrase generation component .", "entities": [[19, 21, "TaskName", "paraphrase generation"]]}, {"text": "( redmarks the errors ; blue marks good paraphrases ) .", "entities": []}, {"text": "cpis a soft constraint that denotes the extent of paraphrasing in terms of number of words that can be copied from the input .", "entities": []}, {"text": "D Additional Evaluation on Newsela Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 20.6 0.0 61.7 0.0 9.2 16.9 17.0 1.0 0.0 100.0 0.0 100.0 Simple ( reference ) 94.6 93.6 91.4 98.8 8.7 17.9 17.9 1.06 0.0 48.0 29.7 0.0 Hybrid - NG 35.0 2.3 52.7 50.1 7.8 16.1 17.0 1.0 5.6 61.7 9.3 9.1 Transformer bert 35.3 3.4 52.9 49.6 7.0 13.5 15.2 0.91 10.4 60.2 14.4 15.7 EditNTS 37.7 2.0 56.4 54.5 7.6 14.2 15.5 0.93 8.7 69.0 7.1 3.5 Our Model 37.9 4.4 51.3 58.0 6.7 13.6 15.3 0.92 9.7 49.2 19.2 0.9", "entities": [[4, 5, "DatasetName", "Newsela"], [70, 71, "MethodName", "Transformer"]]}, {"text": "Our Model ( no split ; cp= 0.6 ) 38.3 3.9 53.8 57.3 7.9 16.1 16.7 1.0 0.0 53.4 20.8 3.6 Our Model ( no split ; cp= 0.7 ) 39.1 3.7 58.5 55.2 8.3 16.2 16.8 1.0 0.0 67.6 12.4 11.0", "entities": []}, {"text": "Our Model ( no split ; cp= 0.8 ) 38.0 3.3 60.3 50.4 8.5 16.4 16.9 1.0 0.0 76.5 8.2 20.3 Table 11 : Automatic evaluation results on a subset of Newsela test set that focuses on paraphrasing ( 8371 complexsimple sentence with compression ratio > 0.9 and no splits ) .", "entities": [[31, 32, "DatasetName", "Newsela"]]}, {"text": "We control the extent of paraphrasing of our models by specifying the percentage of words to be copied ( cp ) from the input as a soft constraint .", "entities": []}, {"text": "3552E Human Evaluation Interface Figure 3 : Guidelines provided to the Amazon Mechanical Turk workers for evaluating simpli\ufb01ed sentences .", "entities": []}, {"text": "Our interface is based on the one proposed by Kriz et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "Figure 4 : Guidelines provided to the Amazon Mechanical Turk workers for evaluating simpli\ufb01ed sentences specifically for sentence splitting .", "entities": []}, {"text": "3553F Evaluation on Wikipedia Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 25.9 0.0 77.8 0.0 13.4 22.4 22.6 1.0 0.0 100.0 0.0 100.0 Simple ( reference ) 42.0 20.6 59.9 45.5 10.9 19.1 19.3 0.88 1.1 55.2 15.3 7.8 Hybrid - NG 25.4 0.1 42.7 33.5 9.0 13.3 13.4 0.6", "entities": []}, {"text": "0.8 38.2 1.4 3.1 LSTM 32.6 2.1 59.8 36.0 10.0 17.8 17.8 0.84 0.8 60.0 10.7 15.0 Transformer bert 35.1 4.3 61.8 39.2 10.4 16.7 18.8 0.85 10.9 62.1 11.1 11.1 EditNTS 36.1 2.5 67.4 38.5 11.7 20.9 22.4 1.02 6.4 63.5 13.5 0.0 Our Model 35.9 4.7 63.6 39.6 9.2 14.7 19.8 0.9 33.7 63.2 12.9 9.2 Our Model ( no split ; cp= 0.6 ) 36.5 4.9 63.2 41.4 10.8 18.6 19.9 0.89 6.7 61.9 12.4 3.9 Our Model ( no split ; cp= 0.7 ) 37.5 4.3 68.8 39.4 11.2 19.1 20.9 0.94 8.9 72.6 8.6 12.3 Our Model ( no split ; cp= 0.8 ) 37.0 3.8 72.0 35.3 11.7 19.8 21.7 0.97 8.4 80.4 6.6 24.5 Table 12 : Automatic evaluation results on T URK dataset ( Xu et al . , 2015 ) that focuses on lexical paraphrasing .", "entities": [[4, 5, "MethodName", "LSTM"], [17, 18, "MethodName", "Transformer"]]}, {"text": "Models SARI add keep del FK SLen OLen CR % split s - BL % new % eq Complex ( input ) 20.5 0.0 61.5 0.0 13.4 22.4 22.6 1.0 0.8 100.0 0.0 100.0 Simple ( reference ) 46.3 20.0 51.0 67.9 9.1 14.8 18.9 0.87 24.2 46.2 20.5 0.6 Hybrid - NG 29.8 0.1 37.0 52.2 9.0 13.3 13.4 0.6 0.8 38.2 1.4 3.1 LSTM 36.1 2.4 51.8 54.2 10.0 17.8 17.8 0.84 0.8 59.9 10.8 14.8 Transformer bert 38.7 5.0 53.5 57.7 10.4 16.7 18.8 0.85 10.9 62.1 11.2 11.1 EditNTS 37.8 2.7 56.0 54.9 11.7 20.9 22.4 1.02 6.4 63.6 13.4 0.0", "entities": [[65, 66, "MethodName", "LSTM"], [78, 79, "MethodName", "Transformer"]]}, {"text": "Our Model 39.7 5.3 55.1 58.8 9.2 14.7 19.8 0.9 33.7 63.1 14.0 8.9 Table 13 : Automatic evaluation results on ASSET ( Alva - Manchego et al . , 2020 ) dataset that contains all the three simpli\ufb01cation operations .", "entities": [[21, 22, "DatasetName", "ASSET"]]}, {"text": "We use the complex - simple sentence pairs from WIKI - AUTO ( Jiang et al . , 2020 ) , which contains 138,095 article pairs and 604k non - identical aligned and partially - aligned sentence pairs .", "entities": []}, {"text": "To capture sentence splitting , we join the sentences in the simple article mapped to the same sentence in the complex article .", "entities": []}, {"text": "Similar to Newsela , we remove the sentence pairs with high ( > 0.9 ) and low ( < 0.1 ) BLEU ( Papineni et al . , 2002 ) scores .", "entities": [[2, 3, "DatasetName", "Newsela"], [21, 22, "MetricName", "BLEU"]]}, {"text": "For validation and testing purposes , we use the followingtwo corpora : ( i ) TURK corpus ( Xu et", "entities": []}, {"text": "al . , 2015 ) for lexical paraphrasing and ( ii ) ASSET corpus ( AlvaManchego et al . , 2020 ) for multiple rewrite operations .", "entities": [[12, 14, "DatasetName", "ASSET corpus"]]}, {"text": "While the former corpus has 8 humanwritten references for 2000 validation and 359 test sentences , the latter corpus provides 10 references for the same sentences .", "entities": []}, {"text": "We remove the validation and test sentences from the training corpus .", "entities": []}, {"text": "Tables 12 and 13 show the results on TURK andASSET respectively .", "entities": []}]