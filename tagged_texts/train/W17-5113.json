[{"text": "Proceedings of the 4th Workshop on Argument Mining , pages 97\u2013107 Copenhagen , Denmark , September 8 , 2017 .", "entities": [[6, 8, "TaskName", "Argument Mining"]]}, {"text": "c", "entities": []}, {"text": "2017 Association for Computational Linguistics Unsupervised Detection of Argumentative Units though Topic Modeling Techniques Al\ufb01o Ferrara andStefano", "entities": []}, {"text": "Montanelli Dipartimento di Informatica , Universit ` a degli Studi di Milano Via Comelico 39 , 20135 - Milano , Italy { al\ufb01o.ferrara , stefano.montanelli } @unimi.it Georgios Petasis Institute of Informatics and Telecommunications , National Centre for Scienti\ufb01c Research ( N.C.S.R. )", "entities": []}, {"text": "\u201c Demokritos \u201d P.O. BOX 60228 , Aghia Paraskevi , GR-153 10 , Athens , Greece", "entities": []}, {"text": "petasis@iit.demokritos.gr Abstract In this paper we present a new unsupervised approach , \u201c Attraction to Topics \u201d \u2013 A2 T , for the detection of argumentative units , a sub - task of argument mining .", "entities": [[33, 35, "TaskName", "argument mining"]]}, {"text": "Motivated by the importance of topic identi\ufb01cation in manual annotation , we examine whether topic modeling can be used for performing unsupervised detection of argumentative sentences , and to what extend topic modeling can be used to classify sentences as claims and premises .", "entities": []}, {"text": "Preliminary evaluation results suggest that topic information can be successfully used for the detection of argumentative sentences , at least for corpora used in the evaluation .", "entities": []}, {"text": "Our approach has been evaluated on two English corpora , the \ufb01rst of which contains 90 persuasive essays , while the second is a collection of 340 documents from user generated content .", "entities": []}, {"text": "1 Introduction Argument mining involves the automatic discovery of argument components ( i.e. claims , premises ) and the argumentative relations ( i.e. supports , attacks ) among these components in texts .", "entities": [[2, 4, "TaskName", "Argument mining"]]}, {"text": "Primarily aiming to extract arguments from texts in order to provide structured data for computational models of argument and reasoning engines ( Lippi and Torroni , 2015a ) , argument mining has additionally the potential to support applications in various research \ufb01elds , such as opinion mining ( Goudas et al . , 2015 ) , stance detection ( Hasan and Ng,2014 ) , policy modelling ( Florou et al . , 2013 ;", "entities": [[29, 31, "TaskName", "argument mining"], [45, 47, "TaskName", "opinion mining"], [56, 58, "TaskName", "stance detection"]]}, {"text": "Goudas et al . , 2014 ) , legal information systems ( Palau and Moens , 2009 ) , etc . Argument mining is usually addressed as a pipeline of several sub - tasks .", "entities": [[21, 23, "TaskName", "Argument mining"]]}, {"text": "Typically the \ufb01rst sub - task is the separation between argumentative and non - argumentative text units , which can be performed at various granularity levels , from clauses to several sentences , usually depending on corpora characteristics .", "entities": []}, {"text": "Detection of argumentative units ( AU)1 , as discussed in Section 2 , is typically modeled as a fully - supervised classi\ufb01cation task , either a binary one , where units are separated in argumentative and non - argumentative ones with argumentative ones to be subsequently classi\ufb01ed in claims and premises as a second step , or as a multi - class one , where identi\ufb01cation of argumentative units and classi\ufb01cation into claims and premises are performed as a single step .", "entities": []}, {"text": "According to a recent survey ( Lippi and Torroni , 2015a ) , the performance of proposed approaches depends on highly engineered and sophisticated , manually constructed , features .", "entities": []}, {"text": "However , fully - supervised approaches rely on manually annotated datasets , the construction of which is a laborious , costly , and error - prone process , requiring signi\ufb01cant effort from human experts .", "entities": []}, {"text": "At the same time , reliance on sophisticated features may hinder the generalisation of an approach to new corpora types and domains ( Lippi and Torroni , 2015a ) .", "entities": []}, {"text": "The removal of manual supervision through exploitation of unsupervised approaches is a possible solution to both of the aforementioned problems .", "entities": []}, {"text": "1.1 Motivations of our work Topics seem to be related to the task of argument mining , at least for some types of corpora , as topic 1Also known as \u201c Argumentative Discourse Units \u2013 ADUs \u201d ( Peldszus and Stede , 2013 ) .97", "entities": [[14, 16, "TaskName", "argument mining"]]}, {"text": "identi\ufb01cation frequently appears as a step in the process of manual annotation of arguments in texts ( Stab and Gurevych , 2014a ) .", "entities": []}, {"text": "However , despite its apparent importance in manual annotation , only a small number of studies have examined the inclusion of topic information in sub - tasks of argument mining .", "entities": [[28, 30, "TaskName", "argument mining"]]}, {"text": "Habernal and Gurevych ( 2015 ) have included sentiment and topic information as features for classifying sentences as claims , premises , backing and non - argumentative units .", "entities": []}, {"text": "A less direct exploitation of topic information has been presented in ( Nguyen and Litman , 2015 ) , where topics have been used to extract lexicons of argument and domain words , which can provide evidence regarding the existence of argument components .", "entities": []}, {"text": "In this paper we propose \u201c Attraction to Topics \u201d \u2013 A2 T , an unsupervised approach based on topic modeling techniques for detecting argumentative discourse units at sentence - level granularity ( a sub - task known as \u201c argumentative sentence detection \u201d ) .", "entities": []}, {"text": "The goals of A2Tare twofold .", "entities": []}, {"text": "On the one side , A2Tenforces identi\ufb01cation of sentences that contain argument components , by also distinguishing them from the non - argumentative sentences that do not contain argument components .", "entities": []}, {"text": "On the other side , A2Tclassi\ufb01es the discovered argumentative sentences according to their role , as major claims , claims , and premises .", "entities": []}, {"text": "The rest of the paper is organized as follows : Section 2presents an overview of approaches related to argument mining focusing on the detection of argumentative units , while Section 3presents our approach on applying topic modeling for identifying sentences that contain argument components .", "entities": [[18, 20, "TaskName", "argument mining"]]}, {"text": "Section 4presents our experimental setting and evaluation results , with Section 5concluding this paper and proposing some directions for further research .", "entities": []}, {"text": "2 Related work Almost all argument mining frameworks proposed so far employ a pipeline of stages , each of which is addressing a sub - task of the argument mining problem ( Lippi and Torroni , 2015a ) .", "entities": [[5, 7, "TaskName", "argument mining"], [28, 30, "TaskName", "argument mining"]]}, {"text": "The segmentation of text into argumentative units is typically the \ufb01rst sub - task encountered in such an argument mining pipeline , aiming to segment texts into argumentative and non - argumentative text units ( i.e. segments that do contain or do not contain argument components , such as claims or premises ) .", "entities": [[18, 20, "TaskName", "argument mining"]]}, {"text": "The granularity of argument components is text - dependant .", "entities": []}, {"text": "For example , in Wikipedia articles studied in ( Rinott et al . , 2015 ) , argument components spanned from less than a sentence to more than a paragraph , although 90 % of the cases was up to 3 sentences , with 95 % of components being comprised of whole sentences .", "entities": []}, {"text": "Several approaches address the identi\ufb01cation of argumentative units at the sentence level , a subtask known as \u201c argumentative sentence detection \u201d , which typically models the task as a binary classi\ufb01cation problem .", "entities": []}, {"text": "Employing machine learning and a set of features representing sentences , the goal is to discard sentences that are not part ( or do not contain a component ) of an argument .", "entities": []}, {"text": "As reported also by Lippi and Torroni ( 2015a ) , the vast majority of existing approaches employ \u201c classic , off - the - self \u201d classi\ufb01ers , while most of the effort is devoted to highly engineered features .", "entities": []}, {"text": "A plethora of learning algorithms have been applied on the task , including Naive Bayes ( Moens et al . , 2007 ; Park and Cardie , 2014 ) , Support Vector Machines ( SVM ) ( Mochales and Moens , 2011 ; Rooney et al . , 2012 ; Park and Cardie , 2014 ; Stab and Gurevych , 2014b ; Lippi and Torroni , 2015b ) , Maximum Entropy ( Mochales and Moens , 2011 ) , Logistic Regression ( Goudas et al . , 2014 , 2015 ; Levy et al . , 2014 ) , Decision Trees and Random Forests ( Goudas et al . , 2014 , 2015 ; Stab and Gurevych , 2014b ) .", "entities": [[34, 35, "MethodName", "SVM"], [79, 81, "MethodName", "Logistic Regression"]]}, {"text": "However , approaches addressing this task in a semi - supervised or unsupervised manner are still scarce .", "entities": []}, {"text": "In ( Petasis and Karkaletsis , 2016 ) an unsupervised approach is presented , which addresses the sub - task of identifying the main claim in a document by exploiting evidence from an extractive summarization algorithm , TextRank ( Mihalcea and Tarau , 2004 ) .", "entities": [[33, 35, "TaskName", "extractive summarization"]]}, {"text": "In an attempt to study the overlap between graph - based approaches and approaches targeting extractive summarization with argument mining , evaluation results suggest a positive effect on the sub - task , achieving an accuracy of 50 % on the corpus compiled by Hasan and Ng(2014 ) from online debate forums and on a corpus of persuasive essays ( Stab and Gurevych , 2014a ) .", "entities": [[15, 17, "TaskName", "extractive summarization"], [18, 20, "TaskName", "argument mining"], [35, 36, "MetricName", "accuracy"]]}, {"text": "Regarding semi - supervised approaches , Habernal and Gurevych ( 2015 ) propose new unsupervised features that exploit clustering of unlabeled argumentative data from debate portals based on word embeddings , outperforming several baselines .", "entities": [[28, 30, "TaskName", "word embeddings"]]}, {"text": "This work employs also topic modeling as one of its features , by including as features the98", "entities": []}, {"text": "distributions of sentences from LDA ( Blei et al . , 2003 ) .", "entities": [[4, 5, "MethodName", "LDA"]]}, {"text": "Topic modeling has been mainly exploited for identi\ufb01cation of argumentative relations and for extraction of argument and domain lexicons .", "entities": []}, {"text": "In Lawrence et al .", "entities": []}, {"text": "( 2014 ) , LDA is used to decide whether a proposition can be attached to its previous proposition in order to identify non directional relations among propositions detected through classi\ufb01ers based on words and part - ofspeech tags .", "entities": [[4, 5, "MethodName", "LDA"]]}, {"text": "LDA has been also used to mine lexicons of argument ( words that are topic independent ) and domain words ( Nguyen and Litman , 2015 ) , by post - processing document topics generated by LDA .", "entities": [[0, 1, "MethodName", "LDA"], [36, 37, "MethodName", "LDA"]]}, {"text": "These lexicons have been used as features for supervised approaches for argument mining ( Nguyen and Litman , 2016a , b ) .", "entities": [[11, 13, "TaskName", "argument mining"]]}, {"text": "However , to the best of our knowledge , no prior approach has applied topic modeling to argumentative sentence detection in an unsupervised setting , which is the featuring aspect of the proposed A2Tapproach presented in the following .", "entities": []}, {"text": "3 Topic modeling for argument mining Given a document corpus , topic modeling techniques can be employed to discover the most representative topics throughout the corpus , and to provide an assignment of documents to topics , meaning that the higher is the assignment value of a document to a certain topic , the higher is the probability that the document is \u201c focused \u201d on that topic .", "entities": [[4, 6, "TaskName", "argument mining"]]}, {"text": "The idea ofA2Tis that an argumentative unit is a sentence highly focused on a speci\ufb01c topic , namely a sentence with high assignment value to a certain topic and low assignment value to the other topics .", "entities": []}, {"text": "To this end , A2Tintroduces the notion of attraction with the aim at recognizing the sentences highly focused on speci\ufb01c topics , that represent the recognized argumentative units .", "entities": []}, {"text": "In the following , theA2Tapproach and related techniques are described in detail .", "entities": []}, {"text": "3.1A2Tapproach", "entities": []}, {"text": "The schema of the A2Tapproach is shown in Figure 1 .", "entities": []}, {"text": "Consider a corpus of texts C= { c1 , . . .", "entities": []}, {"text": ", c n } , where a text ci\u2208C is a sequence of sentences , like for example an essay , a web page / post , or a scienti\ufb01c paper .", "entities": []}, {"text": "The ultimate goal of theA2Tapproach is to derive a set of argumentative unitsU={/angbracketlefts1 , c , l / angbracketright , . . .", "entities": []}, {"text": ", /angbracketleftsh , c , l / angbracketright } , where Corpus of   Texts ( C ) Argumentative   Units ( U)Sentence   Extraction Attraction   EvaluationTopic ModellingSentence Index ( S)Figure 1 : Schema of the A2Tapproach siis a sentence containing an argumentative unit , cis the text containing s , and lis the argumentative role expressed by the unit ( e.g. , major claim , claim , premise ) .", "entities": []}, {"text": "The A2Tapproach is articulated in the following activities : Sentence extraction .", "entities": []}, {"text": "A2Tapproach is characterized by the use of topic modeling at sentencelevel granularity .", "entities": []}, {"text": "For this reason , a pre - processing step of the corpusCis enforced based on conventional techniques for sentence tokenization , words tokenization , normalization , and indexing ( Manning et al . , 2008 ) .", "entities": []}, {"text": "The result is a sentence set S={/angbracketleft\u2212 \u2192s1 , c , pos 1 / angbracketright , . . .", "entities": []}, {"text": ", /angbracketleft\u2212 \u2192sm , c , pos m / angbracketright } , where\u2212 \u2192si is the vector representation of the sentence siand c , posare text and position in the text where the sentence appears , respectively .", "entities": []}, {"text": "The sentence set is stored in a sentence index for ef\ufb01cient access of S elements .", "entities": []}, {"text": "Topic modeling .", "entities": []}, {"text": "The set of extracted sentences Sis used as the document corpus on which topic modeling is applied .", "entities": []}, {"text": "The result of this activity is twofold .", "entities": []}, {"text": "First , topic modeling returns a set of topicsT={t0 , . . .", "entities": []}, {"text": ", t k}representing the latent variables that are most representative for the sentences S. Second , topic modeling returns a distribution of sentences over topics \u03b8={\u03b8s1 , . .", "entities": []}, {"text": ". , \u03b8 sm } .", "entities": [[2, 3, "HyperparameterName", "\u03b8"]]}, {"text": "In particular , \u03b8si= [ p(t0|si ) , . . .", "entities": []}, {"text": ", p ( tk|si)]is the probability distribution of the sentence siover the set of topicsT , where p(tj|si)represents the probability of the topic tjgiven the sentence si(i.e . , the so - called assignment value of sitotj ) .", "entities": []}, {"text": "Attraction evaluation .", "entities": []}, {"text": "The notion of attraction is introduced to measure the degree of focus that characterizes sentences with respect to the emerged topics .", "entities": []}, {"text": "To this end , the distribution of sentences over topics \u03b8is exploited with the aim at determining the best topic assignment for each sentence ofS.", "entities": []}, {"text": "The result is an attraction set A={/angbracketlefts1 , a1 / angbracketright , . . .", "entities": []}, {"text": ", /angbracketleftsm , am / angbracketright}where siis a sentence ofSandaiis its corresponding attraction99", "entities": []}, {"text": "value .", "entities": []}, {"text": "Sentence labeling .", "entities": []}, {"text": "By exploiting the attraction setA , labeling has the goal to determine the sentences ofSthat are more focused on a speci\ufb01c topic , according to the hypothesis that those sentences are the argumentative units .", "entities": []}, {"text": "In a basic scenario , labeling consists in distinguishing between sentences that are argumentative units ( l = au ) and sentences that are not argumentative units ( l= au ) .", "entities": []}, {"text": "In a more articulated scenario , labeling consists in assigning a role to sentences that are recognized as argumentative units .", "entities": []}, {"text": "For instance , it is possible to distinguish argumentative - unit sentences that are claims ( l = cl ) , major claims ( l = mc ) , or premises ( l = pr ) .", "entities": []}, {"text": "A sentence s recognized as argumentative unit is inserted in the \ufb01nal setUwith the assigned label and it is returned as a result ofA2T. 3.2A2Ttechniques InA2 T , the sentence extraction step is enforced by relying on standard techniques for representing documents in terms of feature vectors and bag of words ( using tf - idf as weighting scheme )", "entities": []}, {"text": "( Castano et al . , 2017 ) .", "entities": []}, {"text": "Probabilistic topic modeling is exploited to enforce the subsequent topic modelingstep .", "entities": []}, {"text": "Probabilistic topic models are a suite of algorithms whose aim is to discover the hidden thematic structure in large archives of documents , namely sentences inA2T. The idea is that documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words ( Blei et al . , 2003 ) .", "entities": [[1, 3, "TaskName", "topic models"]]}, {"text": "Probabilistic topic modeling algorithms infer the distribution \u03b8of documents over topics and the distribution \u03c6of words over topics , by sampling from the bag of words of each document .", "entities": []}, {"text": "In our approach , we choose to exploit the Hierarchical Dirichlet Process ( HDP ) .", "entities": []}, {"text": "With respect to other algorithms ( such as LDA ) , HDP has the advantage to provide the optimal number of topics instead of requiring to set such a number as input ( Teh et al . , 2006 ) .", "entities": [[8, 9, "MethodName", "LDA"]]}, {"text": "Attraction evaluation .", "entities": []}, {"text": "The notion of attraction is introduced inA2Tto capture the intuition that argumentative units are related to the distribution of sentences over topics .", "entities": []}, {"text": "Consider a set of sentencesSand the distribution \u03b8of sentences over the set of topicsT.", "entities": []}, {"text": "The more the distribution \u03b8si of a sentence siover the topics is unequal , the more siisfocused on a topic , thus suggesting sias a possible argumentative unit .", "entities": []}, {"text": "A further feature that attraction aims to capture is that argumentative units often appear either at the beginning or at the end of texts .", "entities": []}, {"text": "The attraction aiof a sentence si is calculated as follows : ai = K\u03d5si+ ( 1\u2212K)\u03c1si / summationtext sj\u2208c\u03c1sj , \u03d5si= max ( \u03b8si)is a measure of how much si is focused on a topic and \u03c1si = \u03b1f(posi)2 + \u03b2f(posi ) + \u03b3is a parabolic function over the position of the sentence in c. In particular , given L(c)as the number of sentences in c , f(posi )", "entities": []}, {"text": "= /vextendsingle / vextendsingle / vextendsingleL(c ) 2\u2212posi / vextendsingle / vextendsingle / vextendsinglesuch that f(posi)is higher when si appears either at the beginning or at the end of c.", "entities": []}, {"text": "The parameters \u03b1 , \u03b2 , \u03b3determine the shape of\u03c1si .", "entities": [[2, 3, "HyperparameterName", "\u03b1"], [4, 5, "HyperparameterName", "\u03b2"]]}, {"text": "K\u2208[0,1]is a constant value used to balance the role of focus and position in calculating the attraction .", "entities": []}, {"text": "The attraction aican be interpreted as the probability of a sentence sito contain an argumentative unit .", "entities": []}, {"text": "According to this interpretation , given si , also the contiguous sentences si\u22121andsi+1have a chance to be argumentative units .", "entities": []}, {"text": "As a result , given the calculated attraction setA , we update the attraction values ai through an interpolation mechanism based on the Savitzky - Golay smoothing \ufb01lter ( SGF ) ( Savitzky and Golay , 1964 ) , so thatA:=SGF ( A ) .", "entities": []}, {"text": "In Figure 2 , an example of attraction evaluation is provided by showing the values of \u03d5,\u03c1 , attraction , and interpolated attraction for all the sentences within one considered student essays included in the corpus from ( Stab and Gurevych , 2014a ) ( see Section 4 ) .", "entities": []}, {"text": "s", "entities": []}, {"text": "0 s 1 s 2 s 3 s 4 s 5 s 6 s 7 s 8 s 9 s 10 s 11 s 12 s 13 s 14 s 15 s 16 s 17 s 18 s 19 s 20 s 21 s 22 s 23 s 24 s 25 s 26 s 27 s 28 s 29 s 30 s 31 s 32 s 330.00.20.40.60.81.0si ( focus ) si ( position ) ai ( attraction ) ai : = SGF(ai ) Figure 2 : Attraction evaluation for the sentences of a considered text100", "entities": [[0, 1, "DatasetName", "0"]]}, {"text": "Sentence labeling .", "entities": []}, {"text": "Sentence labeling has the goal to turn attraction values into labeled categories .", "entities": []}, {"text": "Consider a set of possible labels L= { l1 , . .", "entities": []}, {"text": ". , l g } , each one denoting a possible argumentative role that can be assigned to a sentence .", "entities": []}, {"text": "Given a set of attraction values A , a thresholdbased mechanism is enforced to assign labels to sentences according to the following scheme : ai < \u03c4 1 :", "entities": []}, {"text": "si\u2190l1 \u03c41\u2264ai < \u03c4 2 : si\u2190l2 . . . . . . .", "entities": []}, {"text": ". .", "entities": []}, {"text": "ai\u2265\u03c4g\u22121 : si\u2190lg where \u03c41 < \u03c4 2 < ...", "entities": []}, {"text": "< \u03c4 g\u22121(\u03c41 , . . .", "entities": []}, {"text": "\u03c4 g\u22121\u2208(0,1 ] ) are pre\ufb01xed threshold values .", "entities": []}, {"text": "The result of sentence labeling is a partition of Sintogcategories with associated labels .", "entities": []}, {"text": "In the experiments , we discuss two different strategies for sentence labeling .", "entities": []}, {"text": "The \ufb01rst one is a two - class labeling strategy where the possible labels for a sentence are argumentative unit ( au ) and non - argumentative unit ( au .", "entities": []}, {"text": "The second strategy is amulti - class labeling in which the possible labels of a sentence are non - argumentative unit au , premise ( pr ) , claim ( cl ) , and major claim ( mc ) .", "entities": []}, {"text": "4 Experimental results For evaluation of the proposed A2Tapproach , we have used two English corpora .", "entities": []}, {"text": "The \ufb01rst corpus ( C1 in the following ) is a collection of 90 student persuasive essays ( Stab and Gurevych , 2014a ) which has been manually annotated with major claims ( one per essay ) , claims and premises at the clause level .", "entities": []}, {"text": "In addition , the corpus contains manual annotations of argumentative relations , where the claims and premises are linked , while claims are linked to the major claim either with a support or an attack relation .", "entities": []}, {"text": "Interannotation agreement has been measured to unitized alpha ( Krippendorff , 2004 ) \u03b1U= 0.724 .", "entities": [[7, 8, "HyperparameterName", "alpha"]]}, {"text": "These 90 essays consist of a total of 1,675sentences ( from which 19.3%contain no argument components ) , with an average length of 18.61\u00b17 sentences per essay , while the 5.4%of sentences contain a major claim , 26.4%contain a claim , and 61.1%contain a premise .", "entities": []}, {"text": "The second corpus ( C2 in the following ) has been compiled and manually annotated as described in ( Habernal and Gurevych , 2017 ) .", "entities": []}, {"text": "This corpus focuses on user generated content , including user comments , forum posts , blogs , and newspaper articles , covering several thematic domainsfrom educational controversies , such as homeschooling , private vs. public schools , or singlesex education .", "entities": []}, {"text": "Containing in total 340 documents , the corpus has been manually annotated with an argument scheme based on extended Toulmin \u2019s model , involving claims , premises , and backing , rebuttal , refutation argument units .", "entities": []}, {"text": "The corpus contains documents of various sizes , with a mean size of 11.44\u00b111.70sentences per document , while the inter - annotator agreement was measured as\u03b1U= 0.48 .", "entities": []}, {"text": "The corpus consists of 3,899 sentences , from which 2,214 sentences ( 57 % ) contain no argument components .", "entities": []}, {"text": "Both corpora have been preprocessed with NLTK ( Loper and Bird , 2002 ) in order to identify tokens and sentences .", "entities": []}, {"text": "Then , each sentence was annotated as argumentative or non - argumentative , depending on whether it contained an argument unit ( i.e. a text fragment annotated as major claim , claim , or premise ) .", "entities": []}, {"text": "In addition , each argumentative sentence was further annotated with one of major claim , claim , and premise , based on the type of the contained argumentative unit .", "entities": []}, {"text": "For the second corpus , which utilizes a richer argument scheme , we have considered backing , rebuttal and refutation units as premises .", "entities": []}, {"text": "This second corpus does not contain units annotated as major claims .", "entities": []}, {"text": "The following three tasks have been executed : \u2022Task 1 : Argumentative sentence identi\ufb01cation \u2013 given a sentence , classify whether or not it contains an argument component .", "entities": []}, {"text": "\u2022Task 2 : Major claim identi\ufb01cation \u2013 given a argumentative sentence , classify whether or not it contains a major claim .", "entities": []}, {"text": "\u2022Task 3 : Argumentative sentence classi\ufb01cation \u2013 given a sentence , classify the sentence as major claim , claim , premise , ornonargumentative .", "entities": []}, {"text": "Baseline .", "entities": []}, {"text": "As a baseline for comparison against our approach , we created a probabilistic classi\ufb01er of sentences which evaluates the probability p(l = au|si)as follows .", "entities": []}, {"text": "Given the text ccontaining L(c)sentences si , let be \u03b6c\u223cDir(\u03b1 ) the probability distribution of the sentences in c , such that \u03b6sic\u223cp(l = au|si ) .", "entities": []}, {"text": "The L(c)parameters \u03b1used to generate \u03b6care de\ufb01ned such that\u03b1i=/vextendsingle / vextendsingle / vextendsingleL(c ) 2\u2212posi / vextendsingle / vextendsingle / vextendsingle .", "entities": []}, {"text": "The rationale of this procedure is to bias the random assignment of a sentence to the aulabel in favor of sentences appearing either in the beginning or in the end of a text .", "entities": []}, {"text": "This bias attempts to model empirical evi-101", "entities": []}, {"text": "dence that in several types of documents , the density of argumentative units in various sections of documents depends on the structure of documents .", "entities": []}, {"text": "The beginning and end of a document are expected to contain argumentative units in structured documents like news , scienti\ufb01c publications , or argumentative essays ( Stab and Gurevych , 2017 ) , where major claims and supporting premises are frequently found in the beginning of documents , with documents frequently ending with repeating the major claims and supporting evidence .", "entities": []}, {"text": "4.1 Task 1 : Argumentative sentence identi\ufb01cation The goal of Task 1 is to associate each sentence of the corpora to a label in L={au , au}by following a two - class labeling strategy ( see Section 3 ) .", "entities": []}, {"text": "As a \ufb01rst experiment , we performed sentence labeling with different threshold ranging from 0to 1with step 0.05 .", "entities": []}, {"text": "In Figure 3 , we report the precision , recall , and F1 - measure for A2Tand for the baseline .", "entities": [[12, 13, "MetricName", "F1"]]}, {"text": "In addition , we report also the results of applying sentence labeling based on \u03d5and\u03c1 ( the components of attraction ) separately .", "entities": []}, {"text": "The parameter Kfor attraction calculation has been set to0.5 . SinceA2Tis an unsupervised method , there is no easy way to de\ufb01ne the threshold parameter \u03c4 , which has been empirically de\ufb01ned to \u03c4= 0.3 .", "entities": []}, {"text": "The different behavior of A2Twith respect to the baseline is shown in the confusion matrices reported in Figures 4and5 .", "entities": []}, {"text": "From Figure 3 , we can see that A2Tis signi\ufb01cantly better than the baseline , especially for the C1 corpus .", "entities": []}, {"text": "A characteristic of this corpus is that argumentative units are frequently located in the introduction or the conclusion of an essay , which is also re\ufb02ected by the baseline that achieved an F1 - measure of 0.35for a threshold", "entities": [[32, 33, "MetricName", "F1"]]}, {"text": "of\u03c4= 0.05(with", "entities": []}, {"text": "the baseline being particularly precise , suggesting that argumentative units are very frequently at the beginning and end of essays ) .", "entities": []}, {"text": "Both components of attraction ( \u03d5and\u03c1 ) perform well , with the topic component \u03d5being slightly better than position information \u03c1 , both in precision and recall .", "entities": []}, {"text": "The results are similar for corpus C2 , with A2Tsurpassing the baseline , althoughA2Tadvantage in precision is smaller .", "entities": []}, {"text": "As shown in the confusion matrix of Figure 5 , the main source of error is the large number of false positives for the auclass , proposing more argumentative units than what have been manu - ally identi\ufb01ed in corpus C2 .", "entities": []}, {"text": "This can be attributed to the sparseness of argumentative units in the C2 corpus , with almost 60 % of the sentences being non - argumentative .", "entities": []}, {"text": "4.2 Task 2 : Major claim identi\ufb01cation As a second experiment , we exploited probabilities associated with sentences to perform a ranked evaluation .", "entities": []}, {"text": "In particular , we calculated two measures , namely Pthat is the area the under the precision - recall curve and Rthat is the area under the receiver operating characteristic ( ROC ) curve .", "entities": []}, {"text": "In this experiments , we used different criteria for de\ufb01ning the true labels : in PCM , an annotated sentence in the corpus is considered a true argumentative unit if it is either a premise , a claim , or a major claim ; in CM only claims and major claims are taken as valid au ; inMonly major claims are taken into account .", "entities": []}, {"text": "Results are reported in Table 1 .", "entities": []}, {"text": "Table 1 : Area under the precision - recall ( P ) and the ROC ( R ) curves C1 C2 P PCM CM M PCM CM A2 T 0.79 0.31 0.08 0.26 0.19 \u03d5 0.84 0.29 0.06 0.19 0.1 \u03c1 0.68 0.29 0.09 0.24 0.19 Baseline 0.68 0.31 0.11 0.16 0.06 R PCM CM M PCM CM", "entities": []}, {"text": "A2 T 0.4 0.52 0.62 0.7 0.76 \u03d5 0.52 0.51 0.53 0.58 0.57 \u03c1 0.16 0.52 0.77 0.69 0.77 Baseline 0.16", "entities": []}, {"text": "0.53 0.79 0.31 0.18 4.3 Task 3 : Argumentative sentence classi\ufb01cation", "entities": []}, {"text": "The goal of Task 3 is to associate each sentence of the corpora to a label in L={au , pr , cl , mc } by following a multi - class labeling strategy ( see Section 3 ) .", "entities": []}, {"text": "In particular , we adopted the thresholds[0.1,0.3,0.5 ] .", "entities": []}, {"text": "This task is challenging since it is required to distinguish the different role played in argumentation by sentences that are often very similar from the terminological point of view .", "entities": []}, {"text": "The confusion matrix for corpus C1 is shown in Figure6 , while Figure 7shows the confusion matrix for corpus C2 .", "entities": []}, {"text": "Both A2Tand the baseline achieve low results , but the accuracy of A2Tis 0.3 against the 0.1 of the baseline .", "entities": [[10, 11, "MetricName", "accuracy"]]}, {"text": "From Figure 6we see thatA2Tachieved good results for premises , and quite good results for claims , although distinguishing between claims and premises is challenging for theA2Tapproach .", "entities": []}, {"text": "In particular , the role102", "entities": []}, {"text": "C1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Precision A2 T Baseline 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Recall 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 F1 - measure C2 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Precision A2 T Baseline 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Recall 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 F1 - measure Figure 3 : Precision , Recall and F1 - measure with different thresholds au au Predicted labelau auTrue label122 148 789 545A2 T au au Predicted labelau auTrue label228 42 1331 3Baseline 200300400500600700 20040060080010001200 Figure 4 : Two - class confusion matrices for corpus C1 ( Threshold \u03c4= 0.3 ) of sentences may change in different texts so that claims in one context are premises in another .", "entities": [[13, 14, "MetricName", "Precision"], [29, 30, "MetricName", "Recall"], [42, 43, "MetricName", "F1"], [58, 59, "MetricName", "Precision"], [74, 75, "MetricName", "Recall"], [87, 88, "MetricName", "F1"], [93, 94, "MetricName", "Precision"], [95, 96, "MetricName", "Recall"], [97, 98, "MetricName", "F1"]]}, {"text": "This kind of contextual shift is only partially addressed au au Predicted labelau auTrue", "entities": []}, {"text": "label1790 1504 152 430A2 T au au Predicted labelau auTrue label3037", "entities": []}, {"text": "257 515 67Baseline 2004006008001000120014001600 50010001500200025003000Figure 5 : Two - class confusion matrices for corpus C2", "entities": []}, {"text": "( Threshold \u03c4= 0.3 ) byA2 T , because the only contextual information we take into account is topic distribution .", "entities": []}, {"text": "To the end of improving the understanding of the context,103", "entities": []}, {"text": "auprclmc Predicted labelau pr cl mcTrue label31 91 94 54 213 313 232 101 84 145 104 55 4 30 36 17A2 T auprclmc Predicted labelau pr cl mcTrue label111 117 41 1 800 58 1 0 335 52 1 0 50 36 1 0Baseline 50100150200250300 0100200300400500600700800Figure 6 : Multi - class confusion matrices for corpus C1 auprclmc", "entities": [[36, 37, "DatasetName", "0"], [40, 41, "DatasetName", "0"]]}, {"text": "Predicted labelau pr cl mcTrue label1790 1033 469 2 111 104 60 0 41 136 129 1 0 0 0 0A2 T auprclmc Predicted labelau pr cl mcTrue label3037 18 93 146 230 0 5 40 285 0 5 17 0 0 0 0Baseline 02004006008001000120014001600 050010001500200025003000", "entities": [[12, 13, "DatasetName", "0"], [17, 18, "DatasetName", "0"], [18, 19, "DatasetName", "0"], [19, 20, "DatasetName", "0"], [33, 34, "DatasetName", "0"], [37, 38, "DatasetName", "0"], [40, 41, "DatasetName", "0"], [41, 42, "DatasetName", "0"], [42, 43, "DatasetName", "0"]]}, {"text": "Figure 7 : Multi - class confusion matrices for corpus", "entities": []}, {"text": "C2 it may be useful to work also on semantic relations holding among sentences .", "entities": []}, {"text": "This is actually one of the future tasks in our research work .", "entities": []}, {"text": "Another speci\ufb01c challenge emerges when we consider the corpus C2 .", "entities": []}, {"text": "Indeed , C2 contains a limited number of argumentative sentences with respect to the corpus size .", "entities": []}, {"text": "In this case , since we analyze all the sentences according to their bag of words , we tend to overestimate the number of argumentative units , collecting a relatively high number of false positives .", "entities": []}, {"text": "4.4 Lessons learned from error analysis A \ufb01rst evidence emerging from the analysis of confusion matrices for both corpora C1 and C2 is that the role of sentences is strictly dependent on the type of documents .", "entities": []}, {"text": "C1 contains structured essays of various topics , while C2 provides conversational texts extracted from blogs and chats .", "entities": []}, {"text": "In the \ufb01rst case , the number of argumentative units is higher than in the second one .", "entities": []}, {"text": "In particular , for C2 we overestimated the probability of sentences to be an argumentative unit .", "entities": []}, {"text": "This is mainly dueto the fact that those sentences contain words that are semantically related to the main topic of the conversation although they are not playing a role in the argumentation .", "entities": []}, {"text": "An example is the following sentence , taken from a document associated with the topic \u201c school \u201d : \u201c why do some parents not think their kids can attain ? \u201d .", "entities": []}, {"text": "The sentence is clearly part of a conversation and it has been annotated as a non argumentative unit because it is a question .", "entities": []}, {"text": "However , since it contains words that are relevant for the topic ( i.e. , parents , kids , attain),A2Tassociates the sentence with a good level of attraction , labeling it as a premise .", "entities": []}, {"text": "In order to address this kind of false positives , we aim in our future work to study the dependency relations among sentences in text ( such as questionanswers ) to the goal of achieving a better insight of the sentences role .", "entities": []}, {"text": "A second lesson learned from error analysis concerns the distinction between claims and premises .", "entities": []}, {"text": "This confusion is evident especially when dealing with corpus C1 .", "entities": []}, {"text": "An example is given by the following two sentences , taken from104", "entities": []}, {"text": "an essay about the role of sports in favor of peace .", "entities": []}, {"text": "\u2022(s1)for example , when Irak was hardly struck by the second gulf war , its citizens tried to catch any incoming news about the footballworld cup through their portable receivers .", "entities": []}, {"text": "\u2022(s2 ) thus , world sports events strongly participate in eventually pulling back people towards friendship and peace The sentence ( s1 ) has been annotated as a premise , while ( s2 ) as a claim .", "entities": []}, {"text": "In our classi\ufb01cation , they are both claims .", "entities": []}, {"text": "The reason is that they both contain topic - related words and their position in text is similar .", "entities": []}, {"text": "The main distinction is the presence of the expression \u201c for example \u201d in the \ufb01rst sentence which quali\ufb01es it as a premise .", "entities": []}, {"text": "To this end , in our future work we aim at adding some special words ( such as \u201c for example \u201d , \u201c therefore \u201d ) in the background knowledge of the classi\ufb01er , in order to improve the capability of discriminating premises and claims .", "entities": []}, {"text": "5 Concluding remarks In this paper , we present the \u201c Attraction to Topics \u201d \u2013 A2Tunsupervised approach for detecting argumentative discourse units , at sentence - level granularity .", "entities": []}, {"text": "Motivated by the observation that topic information is frequently employed as a sub - task in the process of manual annotation of arguments , we propose an approach that exploits topic modeling techniques in order to identify argumentative units .", "entities": []}, {"text": "Since manual supervision is not required , A2Thas the potential to be applicable on documents of various genres and domains .", "entities": []}, {"text": "Preliminary evaluation results on two different corpora are promising .", "entities": []}, {"text": "First , A2Tperforms significantly better than the baseline on argumentative sentence detection on both corpora .", "entities": []}, {"text": "Second , A2 T exhibits good results for classifying argumentative sentences as major claims , claims , premises , and non - argumentative units , at least for the \ufb01rst corpus , which has a low rate of non - argumentative sentences ( 20 % ) .", "entities": []}, {"text": "Regarding directions for further research , there are several axes that can be explored .", "entities": []}, {"text": "Evaluation on a larger set of annotation corpora will provide enhanced insights about the performance of the proposed approach on different document types .", "entities": []}, {"text": "Our preliminary results showed that despite good recall on multiple corpora , achieving also goodprecision can be a challenging task in documents where argumentative units are sparse , and false positives can be an issue .", "entities": []}, {"text": "In this context , we would like to also exploit other types of relations , and extend our method with other kinds of similarities over sentences .", "entities": []}, {"text": "References David M. Blei , Andrew Y .", "entities": []}, {"text": "Ng , and Michael I. Jordan .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Latent dirichlet allocation .J. Mach .", "entities": []}, {"text": "Learn .", "entities": []}, {"text": "Res .", "entities": []}, {"text": "3:993\u20131022 .", "entities": []}, {"text": "http://dl.acm.org/citation.cfm?id=944919.944937 .", "entities": []}, {"text": "Silvana Castano , Al\ufb01o Ferrara , and Stefano Montanelli . 2017 .", "entities": []}, {"text": "Exploratory analysis of textual data streams .", "entities": []}, {"text": "Future Generation Computer Systems 68:391\u2013406 .", "entities": []}, {"text": "Eirini Florou , Stasinos Konstantopoulos , Antonis Koukourikos , and Pythagoras Karampiperis .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Argument extraction for supporting public policy formulation .", "entities": []}, {"text": "In Piroska Lendvai and Kalliopi Zervanou , editors , Proceedings of the 7th Workshop on Language Technology for Cultural Heritage , Social Sciences , and Humanities , LaTeCH@ACL 2013 , August 8 , 2013 , So\ufb01a , Bulgaria .", "entities": []}, {"text": "The Association for Computer Linguistics , pages 49\u201354 .", "entities": []}, {"text": "http://aclweb.org/anthology/W/W13/W132707.pdf .", "entities": []}, {"text": "Theodosis Goudas , Christos Louizos , Georgios Petasis , and Vangelis Karkaletsis .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Argument extraction from news , blogs , and social media .", "entities": []}, {"text": "In Aristidis Likas , Konstantinos Blekas , and Dimitris Kalles , editors , Arti\ufb01cial Intelligence : Methods and Applications : 8th Hellenic Conference on AI , SETN 2014 , Ioannina , Greece , May 15 - 17 , 2014 .", "entities": []}, {"text": "Proceedings , Springer International Publishing , Cham , pages 287\u2013299 .", "entities": []}, {"text": "https://doi.org/10.1007/9783-319-07064-3 23 .", "entities": []}, {"text": "Theodosis Goudas , Christos Louizos , Georgios Petasis , and Vangelis Karkaletsis .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Argument extraction from news , blogs , and the social web .", "entities": []}, {"text": "International Journal on Arti\ufb01cial Intelligence Tools 24(05):1540024 .", "entities": []}, {"text": "https://doi.org/10.1142/S0218213015400242 .", "entities": []}, {"text": "Ivan Habernal and Iryna Gurevych . 2015 .", "entities": []}, {"text": "Exploiting debate portals for semi - supervised argumentation mining in user - generated web discourse .", "entities": []}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , Lisbon , Portugal , pages 2127\u20132137 .", "entities": []}, {"text": "http://aclweb.org/anthology/D15-1255 .", "entities": []}, {"text": "Ivan Habernal and Iryna Gurevych . 2017 .", "entities": []}, {"text": "Argumentation mining in user - generated web discourse .Computational", "entities": []}, {"text": "Linguistics 43(1):125\u2013179 .", "entities": []}, {"text": "https://doi.org/10.1162/COLI a00276 .105", "entities": []}, {"text": "Kazi Saidul Hasan and Vincent Ng . 2014 .", "entities": []}, {"text": "Why are you taking this stance ?", "entities": []}, {"text": "identifying and classifying reasons in ideological debates .", "entities": []}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .", "entities": []}, {"text": "Association for Computational Linguistics , Doha , Qatar , pages 751\u2013762 .", "entities": []}, {"text": "http://www.aclweb.org/anthology/D141083 .", "entities": []}, {"text": "Klaus Krippendorff .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Measuring the reliability of qualitative text analysis data .Quality and Quantity38(6):787\u2013800 . https://doi.org/10.1007/s11135004-8107-7 .", "entities": []}, {"text": "John Lawrence , Chris Reed , Colin Allen , Simon McAlister , and Andrew Ravenscroft .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Mining arguments from 19th century philosophical texts using topic based modelling .", "entities": []}, {"text": "In Proceedings of the First Workshop on Argumentation Mining . Association for Computational Linguistics , Baltimore , Maryland , pages 79\u201387 . http://www.aclweb.org/anthology/W/W14/W14-2111 .", "entities": []}, {"text": "Ran Levy , Yonatan Bilu , Daniel Hershcovich , Ehud Aharoni , and Noam Slonim .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Context dependent claim detection .", "entities": []}, {"text": "In Jan Hajic and Junichi Tsujii , editors , COLING 2014 , 25th International Conference on Computational Linguistics , Proceedings of the Conference : Technical Papers , August 2329 , 2014 , Dublin , Ireland .", "entities": []}, {"text": "ACL , pages 1489\u20131500 . http://aclweb.org/anthology/C/C14/C14-1141.pdf .", "entities": []}, {"text": "Marco Lippi and Paolo Torroni .", "entities": []}, {"text": "2015a .", "entities": []}, {"text": "Argument mining : A machine learning perspective .", "entities": [[0, 2, "TaskName", "Argument mining"]]}, {"text": "In Elizabeth Black , Sanjay Modgil , and Nir Oren , editors , Theory and Applications of Formal Argumentation : Third International Workshop , TAFA 2015 , Buenos Aires , Argentina , July 25 - 26 , 2015 , Revised Selected Papers .", "entities": []}, {"text": "Springer International Publishing , Cham , pages 163\u2013176 .", "entities": []}, {"text": "https://doi.org/10.1007/9783-319-28460-6 10 .", "entities": []}, {"text": "Marco Lippi and Paolo Torroni .", "entities": []}, {"text": "2015b .", "entities": []}, {"text": "Contextindependent claim detection for argument mining .", "entities": [[4, 6, "TaskName", "argument mining"]]}, {"text": "InProceedings of the 24th International Conference on Arti\ufb01cial Intelligence .", "entities": []}, {"text": "AAAI Press , IJCAI\u201915 , pages 185\u2013191 .", "entities": []}, {"text": "http://dl.acm.org/citation.cfm?id=2832249.2832275 .", "entities": []}, {"text": "Edward Loper and Steven Bird .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "Nltk : The natural language toolkit .", "entities": []}, {"text": "In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics - Volume 1 . Association for Computational Linguistics , Stroudsburg , PA , USA , ETMTNLP \u2019 02 , pages 63\u201370 . https://doi.org/10.3115/1118108.1118117 .", "entities": []}, {"text": "Christopher D Manning , Prabhakar Raghavan , and Hinrich Sch \u00a8utze . 2008 .", "entities": []}, {"text": "Introduction to information retrieval , volume 1 .", "entities": [[2, 4, "TaskName", "information retrieval"]]}, {"text": "Cambridge university press Cambridge .", "entities": [[0, 1, "DatasetName", "Cambridge"], [3, 4, "DatasetName", "Cambridge"]]}, {"text": "Rada Mihalcea and Paul Tarau .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Textrank : Bringing order into texts .", "entities": []}, {"text": "In Dekang Lin and DekaiWu , editors , Proceedings of EMNLP 2004 .", "entities": []}, {"text": "Association for Computational Linguistics , Barcelona , Spain , pages 404\u2013411 .", "entities": []}, {"text": "http://www.aclweb.org/anthology/W/W04/W04-3252.pdf .", "entities": []}, {"text": "Raquel Mochales and Marie - Francine Moens . 2011 .", "entities": []}, {"text": "Argumentation mining .Arti\ufb01cial Intelligence and Law 19(1):1\u201322 .", "entities": []}, {"text": "https://doi.org/10.1007/s10506010-9104-x .", "entities": []}, {"text": "Marie - Francine Moens , Erik Boiy , Raquel Mochales Palau , and Chris Reed .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Automatic detection of arguments in legal texts .", "entities": []}, {"text": "In Proceedings of the 11th International Conference on Arti\ufb01cial Intelligence and Law .", "entities": []}, {"text": "ACM , New York , NY , USA , ICAIL \u2019 07 , pages 225\u2013230 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "https://doi.org/10.1145/1276318.1276362 .", "entities": []}, {"text": "Huy Nguyen and Diane J. Litman .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Extracting argument and domain words for identifying argument components in texts .", "entities": []}, {"text": "In Proceedings of the 2nd Workshop on Argumentation Mining , ArgMining@HLT - NAACL 2015 , June 4 , 2015 , Denver , Colorado , USA .", "entities": []}, {"text": "The Association for Computational Linguistics , pages 22\u201328 . http://aclweb.org/anthology/W/W15/W15-0503.pdf .", "entities": []}, {"text": "Huy Nguyen and Diane J. Litman .", "entities": []}, {"text": "2016a .", "entities": []}, {"text": "Contextaware argumentative relation mining .", "entities": []}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , ACL 2016 , August 7 - 12 , 2016 , Berlin , Germany , Volume 1 : Long Papers .", "entities": []}, {"text": "The Association for Computer Linguistics . http://aclweb.org/anthology/P/P16/P16-1107.pdf .", "entities": []}, {"text": "Huy Nguyen and Diane J. Litman .", "entities": []}, {"text": "2016b .", "entities": []}, {"text": "Improving argument mining in student essays by learning and exploiting argument indicators versus essay topics .", "entities": [[1, 3, "TaskName", "argument mining"]]}, {"text": "In Zdravko Markov and Ingrid Russell , editors , Proceedings of the Twenty - Ninth International Florida Arti\ufb01cial Intelligence Research Society Conference , FLAIRS 2016 , Key Largo , Florida , May 16 - 18 , 2016 . .", "entities": []}, {"text": "AAAI Press , pages 485\u2013490 .", "entities": []}, {"text": "http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS16/paper/view/12791 .", "entities": []}, {"text": "Raquel Mochales Palau and Marie - Francine Moens .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Argumentation mining : The detection , classi\ufb01cation and structure of arguments in text .", "entities": []}, {"text": "InProceedings of the 12th International Conference on Arti\ufb01cial Intelligence and Law .", "entities": []}, {"text": "ACM , New York , NY , USA , ICAIL \u2019 09 , pages 98\u2013107 . https://doi.org/10.1145/1568234.1568246 .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Joonsuk Park and Claire Cardie .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Identifying appropriate support for propositions in online user comments .", "entities": []}, {"text": "In Proceedings of the First Workshop on Argumentation Mining .", "entities": []}, {"text": "Association for Computational Linguistics , Baltimore , Maryland , pages 29\u201338 .", "entities": []}, {"text": "http://www.aclweb.org/anthology/W/W14/W14-2105 .", "entities": []}, {"text": "Andreas Peldszus and Manfred Stede .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "From argument diagrams to argumentation mining in texts : A survey .", "entities": []}, {"text": "Int.106", "entities": []}, {"text": "J. Cogn .", "entities": []}, {"text": "Inform .", "entities": []}, {"text": "Nat . Intell .", "entities": []}, {"text": "7(1):1\u201331 . https://doi.org/10.4018/jcini.2013010101 .", "entities": []}, {"text": "Georgios Petasis and Vangelis Karkaletsis .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Identifying argument components through textrank .", "entities": []}, {"text": "In Proceedings of the 3rd Workshop on Argument Mining ( ArgMining2016 ) .", "entities": [[7, 9, "TaskName", "Argument Mining"]]}, {"text": "Association for Computational Linguistics , Berlin , Germany , pages 56\u201366 .", "entities": []}, {"text": "http://aclweb.org/anthology/W/W16/W162811.pdf .", "entities": []}, {"text": "Ruty Rinott , Lena Dankin , Carlos Alzate Perez , Mitesh M. Khapra , Ehud Aharoni , and Noam Slonim . 2015 .", "entities": []}, {"text": "Show me your evidence - an automatic method for context dependent evidence detection .", "entities": []}, {"text": "InProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .", "entities": []}, {"text": "Association for Computational Linguistics , Lisbon , Portugal , pages 440\u2013450 .", "entities": []}, {"text": "http://aclweb.org/anthology/D15-1050 .", "entities": []}, {"text": "Niall Rooney , Hui Wang , and Fiona Browne .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Applying kernel methods to argumentation mining .", "entities": []}, {"text": "In G. Michael Youngblood and Philip M. McCarthy , editors , Proceedings of the Twenty - Fifth International Florida Arti\ufb01cial Intelligence Research Society Conference , Marco Island , Florida .", "entities": []}, {"text": "May 23 - 25 , 2012 .", "entities": []}, {"text": "AAAI Press .", "entities": []}, {"text": "http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS12/paper/view/4366 .", "entities": []}, {"text": "Abraham Savitzky and Marcel JE Golay .", "entities": []}, {"text": "1964 .", "entities": []}, {"text": "Smoothing and differentiation of data by simpli\ufb01ed least squares procedures .", "entities": []}, {"text": "Analytical chemistry 36(8):1627\u20131639 .", "entities": []}, {"text": "Christian Stab and Iryna Gurevych .", "entities": []}, {"text": "2014a .", "entities": []}, {"text": "Annotating argument components and relations in persuasive essays .", "entities": []}, {"text": "In Junichi Tsujii and Jan Hajic , editors , Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) .", "entities": []}, {"text": "Dublin City University and Association for Computational Linguistics , Dublin , Ireland , pages 1501\u20131510 .", "entities": []}, {"text": "http://www.aclweb.org/anthology/C141142 .", "entities": []}, {"text": "Christian Stab and Iryna Gurevych .", "entities": []}, {"text": "2014b .", "entities": []}, {"text": "Identifying argumentative discourse structures in persuasive essays .", "entities": []}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .", "entities": []}, {"text": "Association for Computational Linguistics , Doha , Qatar , pages 46\u201356 . http://www.aclweb.org/anthology/D14-1006 .", "entities": []}, {"text": "Christian Stab and Iryna Gurevych . 2017 .", "entities": []}, {"text": "Parsing argumentation structures in persuasive essays .", "entities": []}, {"text": "Computational Linguistics 0(ja):1\u201362 .", "entities": []}, {"text": "https://doi.org/10.1162/COLI", "entities": []}, {"text": "a00295 .", "entities": []}, {"text": "Yee Whye Teh , Michael I Jordan , Matthew J Beal , and David M Blei .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Hierarchical dirichlet processes .Journal of the American Statistical Association 101(476):1566\u20131581 .", "entities": []}, {"text": "https://doi.org/10.1198/016214506000000302", "entities": []}, {"text": ".107", "entities": []}]