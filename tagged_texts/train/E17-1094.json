[{"text": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics : Volume 1 , Long Papers , pages 1002\u20131013 , Valencia , Spain , April 3 - 7 , 2017 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2017 Association for Computational Linguistics SMARTies : Sentiment Models for Arabic Target entities Noura Farra andKathleen McKeown Columbia University Department of Computer Science { noura,kathy}@cs.columbia.edu", "entities": []}, {"text": "Abstract We consider entity - level sentiment analysis in Arabic , a morphologically rich language with increasing resources .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "We present a system that is applied to complex posts written in response to Arabic newspaper articles .", "entities": []}, {"text": "Our goal is to identify important entity \u201c targets \u201d within the post along with the polarity expressed about each target .", "entities": []}, {"text": "We achieve significant improvements over multiple baselines , demonstrating that the use of speci\ufb01c morphological representations improves the performance of identifying both important targets and their sentiment , and that the use of distributional semantic clusters further boosts performances for these representations , especially when richer linguistic resources are not available .", "entities": []}, {"text": "1 Introduction Target - speci\ufb01c sentiment analysis has recently become a popular problem in natural language processing .", "entities": [[5, 7, "TaskName", "sentiment analysis"]]}, {"text": "In interpreting social media posts , analysis needs to include more than just whether people feel positively or negatively ; it also needs to include what they like or dislike .", "entities": []}, {"text": "The task of \ufb01nding all targets within the data has been called \u201c open - domain targeted sentiment \u201d ( Mitchell et al . , 2013 ; Zhang et al . , 2015 ) .", "entities": []}, {"text": "If we could successfully identify the targets of sentiment , it would be valuable for a number of applications including sentiment summarization , question answering , understanding public opinion during political con\ufb02ict , or assessing needs of populations during natural disasters .", "entities": [[21, 22, "TaskName", "summarization"], [23, 25, "TaskName", "question answering"]]}, {"text": "In this paper , we address the open - domain targeted sentiment task .", "entities": []}, {"text": "Input to our system consists of online posts , which can be comprised of one or multiple sentences , contain multiple entities with different sentiment , and have different Figure 1 : Online post with annotated target entities and sentiment ( green : pos , yellow : neg ) .", "entities": []}, {"text": "domains .", "entities": []}, {"text": "Our goal is to identify the important entities towards which opinions are expressed in the post ; these can include any nominal or noun phrase , including events , or concepts , and they are not restricted to named entities as has been the case in some previous work .", "entities": []}, {"text": "The only constraint is that the entities need to be explicitly mentioned in the text .", "entities": []}, {"text": "Our work also differs from much work on targeted sentiment analysis in that posts are long , complex , with many annotated targets and a lack of punctuation that is characteristic of Arabic online language .", "entities": [[9, 11, "TaskName", "sentiment analysis"]]}, {"text": "Figure 1 shows an example post , where targets are either labeled positive ( green ) if a positive opinion is expressed about them and negative ( yellow ) if a negative opinion is expressed .", "entities": []}, {"text": "To identify targets and sentiment , we develop two sequence labeling models , a target - speci\ufb01c model and a sentiment - speci\ufb01c model .", "entities": []}, {"text": "Our models try to learn syntactic relations between entities and opinion words , but they also make use of ( 1 ) Arabic morphology and ( 2 ) entity semantics .", "entities": []}, {"text": "Our use of morphology allows us to capture all \u201c words \u201d that play a role in identi\ufb01cation of the target , while our use of entity semantics allows us to group together similar entities which may all be targets of the same sentiment ; for example , if a commenter expresses negative sentiment towards1002", "entities": []}, {"text": "the United States , they may also express negative sentiment towards America or Obama .", "entities": []}, {"text": "Our results show that morphology matters when identifying entity targets and the sentiment expressed towards them .", "entities": []}, {"text": "We \ufb01nd for instance that the attaching Arabic de\ufb01nite article Al+ /charc8 / char40is an important indicator of the presence of a target entity and splitting it off boosts recall of targets , while sentiment models perform better when less tokens are split .", "entities": []}, {"text": "We also conduct a detailed analysis of errors revealing that the task generally entails hard problems such as a considerable amount of implicit sentiment and the presence of multiple targets with varying importance .", "entities": []}, {"text": "In what follows , we describe related work ( \u00a7 2 ) , data and models ( \u00a7 3 and \u00a7 4 ) , and linguistic decisions made for Arabic ( \u00a7 5 ) .", "entities": []}, {"text": "In \u00a7 6 , we describe our use of word vector clusters learned on a large Arabic corpus .", "entities": []}, {"text": "Finally , \u00a7 7 presents experiments and detailed error analysis .", "entities": []}, {"text": "2 Related Work Aspect - based and Entity - speci\ufb01c Analysis Early work in target - based sentiment looked at identifying aspects in a restricted domain : product or customer reviews .", "entities": []}, {"text": "Many of these systems used unsupervised and topical methods for determining aspects of products ; Hu and Liu ( 2004 ) used frequent feature mining to \ufb01nd noun phrase aspects , Brody and Elhadad ( 2010 ) used topic modeling to \ufb01nd important keywords in restaurant reviews , and Somasundaran and Wiebe ( 2009 ) mined the web to \ufb01nd important aspects associated with debate topics and their corresponding polarities .", "entities": []}, {"text": "SemEval 2014 Task 4 ( Pontiki et al . , 2014 ) ran several subtasks for identifying aspect terms and sentiment towards aspects and terms in restaurant and laptop reviews .", "entities": []}, {"text": "Entity - speci\ufb01c sentiment analysis has been frequently studied in social media and online posts .", "entities": [[3, 5, "TaskName", "sentiment analysis"]]}, {"text": "Jiang et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2011 ) proposed identifying sentiment of a tweet towards a speci\ufb01c named entity , taking into account multiple mentions of the given entity .", "entities": []}, {"text": "Biyani et al .", "entities": []}, {"text": "( 2015 ) studied sentiment towards entities in online posts , where the local part of the post that contained the entity or mentions of it was identi\ufb01ed and the sentiment was classi\ufb01ed using a number of linguistic features .", "entities": []}, {"text": "The entities were selected beforehand and consisted of known , named entities .", "entities": []}, {"text": "More recent work uses LSTM and RNN networks to determine sentiment toward aspects in product reviews ( Wang et al . , 2016 ) andtowards entities in Twitter ( Dong et", "entities": [[4, 5, "MethodName", "LSTM"]]}, {"text": "al . , 2014 ; Tang et al . , 2015 ) .", "entities": []}, {"text": "SemEval 2016 ran two tasks on sentiment analysis ( Nakov et al . , 2016 ) and stance ( Mohammad et al . , 2016 ) towards pre - de\ufb01ned topics in Twitter , both on English data .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "Open domain targeted analysis In early work .", "entities": []}, {"text": "Kim and Hovy ( 2006 ) proposed \ufb01nding opinion target and sources in news text by automatic labeling of semantic roles .", "entities": []}, {"text": "Here , opinion - target relationships were restricted to relations that can be captured using semantic roles .", "entities": []}, {"text": "Ruppenhofer et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2008 ) discussed the challenges of identifying targets in open - domain text which can not be addressed by semantic role labeling , such as implicitly conveyed sentiment , global and local targets related to the same entity , and the need for distinguishing between entity and proposition targets .", "entities": [[20, 23, "TaskName", "semantic role labeling"]]}, {"text": "Sequence labeling models became more popular for this problem : Mitchell et al .", "entities": []}, {"text": "( 2013 ) used CRF model combinations to identify named entity targets in English and Spanish , and Yang and Cardie ( 2013 ) used joint modeling to predict opinion expressions and their source and target spans in news articles , improving over several single CRF models .", "entities": [[4, 5, "MethodName", "CRF"], [45, 46, "MethodName", "CRF"]]}, {"text": "Their focus was on identifying directly subjective opinion expressions ( e.g \" I hate [ this dictator ] \" vs. \" [ This dictator ] is destroyinghis country . \" )", "entities": []}, {"text": "Recent work ( Deng and Wiebe , 2015 ) identi\ufb01es entity sources and targets , as well as the sentiment expressed by and towards these entities .", "entities": []}, {"text": "This work was based on probablistic soft logic models , also with a focus on direct subjective expressions .", "entities": []}, {"text": "There is also complementary work on using neural networks for tagging open - domain targets ( Zhang et al . , 2015 ; Liu et al . , 2015 ) in shorter posts .", "entities": []}, {"text": "Previous work listed did not consider word morphology , or explicitly model distributional entity semantics as indicative of the presence of sentiment targets .", "entities": []}, {"text": "Related work in Arabic Past work in Arabic machine translation ( Habash and Sadat , 2006 ) and named entity recognition ( Benajiba et al . , 2008 ) considered the tokenization of complex Arabic words as we do in our sequence labeling task .", "entities": [[8, 10, "TaskName", "machine translation"], [18, 21, "TaskName", "named entity recognition"]]}, {"text": "Analysis of such segmentation schemes has not been reported for Arabic sentiment tasks , which cover mostly sentence - level sentiment analysis and where the lemma or surface bag - of - word representations have typically been suf\ufb01cient .", "entities": [[20, 22, "TaskName", "sentiment analysis"], [25, 26, "DatasetName", "lemma"]]}, {"text": "There are now many studies on sentence - level1003", "entities": []}, {"text": "sentiment analysis in Arabic news and social media ( Abdul - Mageed and Diab , 2011 ; Mourad and Darwish , 2013 ; Refaee and Rieser , 2014 ; Salameh et al . , 2015 ) .", "entities": [[0, 2, "TaskName", "sentiment analysis"]]}, {"text": "Elarnaoty et al .", "entities": []}, {"text": "( 2012 ) proposed identifying sources of opinions in Arabic using a CRF with a number of patterns , lexical and subjectivity clues ; they did not discuss morphology or syntactic relations .", "entities": [[12, 13, "MethodName", "CRF"]]}, {"text": "Al - Smadi et al .", "entities": []}, {"text": "( 2015 ) developed a dataset and built a majority baseline for \ufb01nding targets in Arabic book reviews of known aspects ; Obaidat et al .", "entities": []}, {"text": "( 2015 ) also developed a lexicon - based approach to improve on this baseline .", "entities": []}, {"text": "Abu - Jbara et al .", "entities": []}, {"text": "( 2013 ) created a simple opinion - target system for Arabic by identifying noun phrases in polarized text ; this was done intrinsically as part of an effort to identify opinion subgroups in online discussions .", "entities": []}, {"text": "There are no other sentiment target studies in Arabic that we know of .", "entities": []}, {"text": "In our experiments , we compare to methods similar to these baseline systems , as well as to results of English work that is comparable to ours .", "entities": []}, {"text": "Entity Clusters It has been shown consistently that semantic word clusters improve the performance of named entity recognition ( T\u00e4ckstr\u00f6m et al . , 2012 ; Zirikly and Hagiwara , 2015 ; Turian et", "entities": [[15, 18, "TaskName", "named entity recognition"]]}, {"text": "al . , 2010 ) and semantic parsing ( Saleh et al . , 2014 ) ; we are not aware of such work for identifying entity targets of sentiment .", "entities": [[6, 8, "TaskName", "semantic parsing"]]}, {"text": "3 Data We use the Arabic Opinion Target dataset developed by Farra et al . ( 2015 ) , which is publicly available1 .", "entities": []}, {"text": "The data consists of 1177 online comments posted in response to Aljazeera Arabic newspaper articles and is part of the Qatar Arabic Language Bank ( QALB ) corpus ( Habash et al . , 2013 ; Zaghouani et al . , 2014 ) .", "entities": []}, {"text": "The comments are 1 - 3 sentences long with an average length of 51 words .", "entities": []}, {"text": "They were selected such that they included topics from three domains : politics , culture , and sports .", "entities": []}, {"text": "Targets are always noun phrases and they are either labeled positive if a positive opinion is expressed about them and negative if a negative opinion is expressed ( as shown in Figure 1 ) .", "entities": []}, {"text": "Targets were identi\ufb01ed using an incremental process where \ufb01rst important entities were identi\ufb01ed , and then entities agreed to be neutral were discarded ( the annotation does not distinguish between neutralandsubjective neutral ) .", "entities": []}, {"text": "The data also contains ambiguous or \u2018 undeter1www.cs.columbia.edu/~noura/Resources.htmlThe dictator is destroying his country T T", "entities": []}, {"text": "O", "entities": []}, {"text": "O", "entities": []}, {"text": "O", "entities": []}, {"text": "O N N\u2205 \u2205", "entities": []}, {"text": "\u2205 \u2205", "entities": []}, {"text": "Table 1 : Example of CRF annotations .", "entities": [[5, 6, "MethodName", "CRF"]]}, {"text": "mined \u2019 targets where annotators did agree they were targets , but did not agree on the polarity .", "entities": []}, {"text": "We use these targets for training our target model , but discard them when training our sentiment polarity model .", "entities": []}, {"text": "There are 4886 targets distributed as follows : 38.2 % positive , 50.5 % negative , and 11.3 % ambiguous .", "entities": []}, {"text": "We divide the dataset into a training set ( 80 % ) , development set ( 10 % ) , and blind test set ( 10 % ) , all of which represent the three different domains .", "entities": []}, {"text": "We make the splits available for researchers to run comparative experiments .", "entities": []}, {"text": "4 Sequence Labeling Models For modeling the data , we choose Conditional Random Fields ( CRF ) ( Lafferty et al . , 2001 ) for the ability to engineer Arabic linguistic features and because of the success of CRF models in the past for entity identi\ufb01cation and classi\ufb01cation related tasks .", "entities": [[15, 16, "MethodName", "CRF"], [39, 40, "MethodName", "CRF"]]}, {"text": "We build two linear chain CRF models : 1.Target Model", "entities": [[5, 6, "MethodName", "CRF"]]}, {"text": "This model predicts a sequence of labels /vectorEfor a sequence of input tokens /vector", "entities": []}, {"text": "x , where Ei\u2208{T(target ) , O(not_target ) } and each token xiis represented by a feature vector /vectorfit .", "entities": []}, {"text": "A token is labeled Tif it is part of a target ; a target can contain one or more consecutive tokens .", "entities": []}, {"text": "2.Sentiment", "entities": []}, {"text": "Model", "entities": []}, {"text": "This model predicts a sequence of labels /vectorSfor the sequence /vector", "entities": []}, {"text": "x , Si\u2208{P(pos ) , N(neg),\u2205(neutral ) } and", "entities": []}, {"text": "each token xiis represented by a feature vector : ( /vectorfis , Ei);Ei\u2208{T , O } Additionally , this model has the constraint :", "entities": []}, {"text": "ifE i = T , S i\u2208{P , N } and otherwise Si=\u22051004", "entities": []}, {"text": "The last constraint indicating that sentiment is either positive or negative is ensured by the training data , where we have no examples of target tokens having neutral sentiment .", "entities": []}, {"text": "The two models are trained independently .", "entities": []}, {"text": "Thus , if target words are already available for the data , the sentiment model can be run without training or running the target model .", "entities": []}, {"text": "Otherwise , the sentiment model can be run on the output of the target predictor .", "entities": []}, {"text": "The sentiment model uses knowledge of whether a word is a target and utilizes context from neighboring words whereby the entire sequence is optimized to predict sentiment polarities for the targets .", "entities": []}, {"text": "An example sequence is shown in Table 1 , where the dictator is an entity target towards which the writer implicitly expresses negative sentiment .", "entities": []}, {"text": "5 Arabic Morphology and Linguistics 5.1 Arabic Morphology In Arabic , clitics and af\ufb01xes can attach to the beginning and end of the word stem , making words complex .", "entities": []}, {"text": "For example , in the sentence /char41 / chareb / charf1 / charca / char4a / char2e / char10 / charae / char10 / char4a / char83 / char41 / char09 / charaf", "entities": []}, {"text": "\u2018 So they welcomed her \u2019 , the discourse conjuction ( so+/char09 / charac ) , the opinion target ( her /char41 / chareb+ ) , opinion holder ( they /charf0 / char40 / char2b ) , and the opinion expression itself ( welcomed /charc9 / char4a / char2e / char10 / charae / char10 / char4a / char83 / char40 ) are all collapsed in the same word .", "entities": []}, {"text": "Clitics , such as conjunctions + /charf0w+ , prepositions + /char48 / char2eb+ , the de\ufb01nite article /charc8 / char40 / char2bAl+ \u2018 the \u2019 ( all of which attach at the beginning ) , and possessive pronouns and object pronouns /chare8++h / char41 / chareb++hA \u2018 his / her \u2019 or\u2018him / her \u2019 ( which attach at the end ) can all function as individual words .", "entities": []}, {"text": "Thus , they can be represented as separate tokens in the CRF .", "entities": [[11, 12, "MethodName", "CRF"]]}, {"text": "The morphological analyzer MADAMIRA ( Pasha et al . , 2014 ) enables the tokenization of a word using multiple schemes .", "entities": []}, {"text": "We consider the following two schemes : \u2022D3 : the Declitization scheme which splits off conjunction clitics , particles and prepositions , Al+ , and all the enclitics at the end .", "entities": []}, {"text": "\u2022ATB : the Penn Arabic Treebank tokenization , which separates all clitics above except the de\ufb01nite article Al+ , which it keeps attached .", "entities": []}, {"text": "For a detailed description of Arabic concatenative morphology and tokenization schemes , the reader is referred to Habash ( 2010).For each token , we add a part of speech feature .", "entities": []}, {"text": "For word form ( non - clitic ) tokens , we use the part of speech ( POS ) feature produced by the morphological analyzer .", "entities": []}, {"text": "We consider the surface word and the lemma for representing the word form .", "entities": [[7, 8, "DatasetName", "lemma"]]}, {"text": "For the clitics that were split off , we use a detailed POS feature that is also extracted from the output of the analyzer and can take such forms as DET forAl+ orposs_pron_3MP for third person masculine possessive pronouns .", "entities": [[30, 31, "DatasetName", "DET"]]}, {"text": "Table 2 shows the words and part of speech for the input sentence /char41 / chareb / charf1 / charca / char4a / char2e / char10 / charae / char10 / char4a / char83 / char41 / char09 / charaf\u2018so they welcomed her \u2019 fa - istaqbalu - ha , using the lemma representation for the word form and the D3 tokenization scheme .", "entities": [[52, 53, "DatasetName", "lemma"], [60, 61, "DatasetName", "D3"]]}, {"text": "These lexical and POS features are added to both our target model and sentiment model .", "entities": []}, {"text": "5.2 Sentiment Features The choice of sentiment lexicon is an important consideration when developing systems for new and/or low - resource languages .", "entities": []}, {"text": "We consider three lexicons : ( 1 ) SIFAAT , a manually constructed Arabic lexicon of 3982 adjectives ( AbdulMageed and Diab , 2011 ) , ( 2 ) ArSenL , an Arabic lexicon developed by linking English SentiWordNet with Arabic WordNet and an Arabic lexical database ( Badaro et al . , 2014 ) , and ( 3 ) the English MPQA lexicon ( Wilson et al . , 2005 ) , where we look up words by matching on the English glosses produced by the morphological analyzer MADAMIRA .", "entities": [[62, 63, "DatasetName", "MPQA"]]}, {"text": "For the target model , we add token - level binary features representing subjectivity , and for the sentiment model , we add both subjectivity and polarity features .", "entities": []}, {"text": "We also add a feature specifying respectively the subjectivity or polarity of the parent word of the token in the dependency tree in the target or sentiment model .", "entities": []}, {"text": "5.3 Syntactic Dependencies We ran the CATiB ( Columbia Arabic Treebank ) dependency parser ( Shahrour et al . , 2015 ) on our data .", "entities": []}, {"text": "CATiB uses a number of intuitive labels specifying the token \u2019s syntactic role : e.g SBJ , OBJ , MOD , andIDF for the Arabic idafa construct ( e.g / char10 / chare9 / chard3 / charf1 / charba / char6d /charcc / char27 / char40 /char81 / char1c /char0a / char0d / char4b / char50president of government ) , as well as its part of speech role .", "entities": [[19, 20, "DatasetName", "MOD"]]}, {"text": "In addition to the sentiment dependency features specifying the sentiment of parent words , we added dependency features specifying the syntactic role of the token in relation to its parent , and the path from the token to the parent,1005", "entities": []}, {"text": "Word English Representation POS Token type f", "entities": []}, {"text": "so f+ conj clitic Astqblw welcomed - they isotaqobal_1 verb lemma hA her", "entities": [[10, 11, "DatasetName", "lemma"]]}, {"text": "+ hA ivsuff_do:3FS clitic Table 2 : Example of morphological representation .", "entities": []}, {"text": "The encoded features will be Representation and POS .", "entities": []}, {"text": "The POS for herrepresents an object pronoun .", "entities": []}, {"text": "The word form represented is the lemma .", "entities": [[6, 7, "DatasetName", "lemma"]]}, {"text": "e.gnom_obj_vrb ornom_idf_nom , as well as the sentiment path from the token to the parent , e.g nom(neutral ) _ obj_vrb ( negative ) .", "entities": []}, {"text": "5.4 Chunking and Named Entities", "entities": [[1, 2, "TaskName", "Chunking"]]}, {"text": "The morphological analyzer MADAMIRA also produces base phrase chunks ( BPC ) and named entity tags ( NER ) for each token .", "entities": [[17, 18, "TaskName", "NER"]]}, {"text": "We add features for these as well , based on the hypothesis that they will help de\ufb01ne the spans for entity targets , whether they are named entities or any noun phrases .", "entities": []}, {"text": "We refer to the sentiment and target models that utilize Arabic morphology , sentiment , syntactic relations and entity chunks as best - linguistic .", "entities": []}, {"text": "6 Word Clusters and Entity Semantics Similar entities which occur in the context of the same topic or the same larger entity are likely to occur as targets alongside each other and to have similar sentiment expressed towards them .", "entities": []}, {"text": "They may repeat frequently in a post even if they do not explicitly or lexically refer to the same person or object .", "entities": []}, {"text": "For example , someone writing about American foreign policy may frequently refer to entities such as { the United States , America , Obama , the Americans , Westerners } .", "entities": []}, {"text": "Such entities can cluster together semantically and it is likely that a person expressing positive or negative sentiment towards one of these entities may also express the same sentiment towards the other entities in this set .", "entities": []}, {"text": "Moreover , cluster features serve as a denser feature representation with a reduced feature space compared to Arabic lexical features .", "entities": []}, {"text": "Such features can bene\ufb01t the CRF where a limited amount of training data is available for target entities .", "entities": [[5, 6, "MethodName", "CRF"]]}, {"text": "To utilize the semantics of word clusters , we build word embedding vectors using the skip - gram method ( Mikolov et al . , 2013 ) and cluster them using the K - Means algorithm ( MacQueen , 1967 ) , with Euclidean distance as a metric .", "entities": []}, {"text": "Euclidean distance serves as a semantic similarity metric andhas been commonly used as a distance - based measure for clustering word vectors .", "entities": [[5, 7, "TaskName", "semantic similarity"]]}, {"text": "The vectors are built on Arabic Wikipedia2on a corpus of 137 M words resulting in a vocabulary of 254 K words .", "entities": []}, {"text": "We preprocess the corpus by tokenizing ( using the schemes described in section 5 ) and lemmatizing before building the word vectors .", "entities": []}, {"text": "We vary the number of clusters and use the clusters as binary features in our target and sentiment models .", "entities": []}, {"text": "7 Experiments and Results 7.1 Experiments Setup To build our sentiment and target models , we use CRF++ ( Kudo , 2005 ) to build linear - chain sequences .", "entities": []}, {"text": "We use a context window of + /-2 for all features except the syntactic dependencies , where we use a window of + /-4 to better capture syntactic relations in the posts .", "entities": []}, {"text": "For the sentiment model , we include the context of the previous predicted label , to avoid predicting consecutive tokens with opposite polarity .", "entities": []}, {"text": "We evaluate all our experiments on the development set which contains 116 posts and 442 targets , and present a \ufb01nal result with the best models on the unseen test .", "entities": []}, {"text": "For the SentiWordNetbased lexicon ArSenL , we tune for the sentiment score threshold and use t=0.2 .", "entities": []}, {"text": "We use Google \u2019s word2vec tool3for building and clustering word vectors with dimension 200 .", "entities": [[2, 3, "DatasetName", "Google"]]}, {"text": "We vary the number of clusters kbetween 10 ( 25 K words / cluster ) and 20 K ( 12 words / cluster ) .", "entities": []}, {"text": "Baselines For evaluating the predicted targets , we follow work in English ( Deng and Wiebe , 2015 ) and use the all - NP baseline , where all nouns and noun phrases in the post are predicted as important targets .", "entities": []}, {"text": "For evaluating sentiment towards targets , we consider four baselines : the majority baseline which always predicts negative , and the lexicon 2https://dumps.wikimedia.org/arwiki/20160920/arwiki20160920-pages-articles.xml.bz2 3https://github.com/dav/word2vec1006", "entities": []}, {"text": "baseline evaluated in the case of each of our three lexicons : manually created , WordNet - based , and English - translated .", "entities": []}, {"text": "The strong lexicon baseline splits the post into sentences or phrases by punctuation , \ufb01nds the phrase that contains the predicted target , and returns positive if there are more positive words than negative words , and negative otherwise .", "entities": []}, {"text": "These baselines are similar to the methods of previously published work for Arabic targeted sentiment ( Al - Smadi et al . , 2015 ; Obaidat et al . , 2015 ; Abu - Jbara et al . , 2013 ) .", "entities": []}, {"text": "We run our pipelined models for all morphological representation schemes : surface word ( no token splits ) , lemma ( no clitics ) , lemma with ATB clitics ( contain all token splits except Al+ ) , and lemma with D3 clitics ( contains all token splits ) .", "entities": [[19, 20, "DatasetName", "lemma"], [25, 26, "DatasetName", "lemma"], [39, 40, "DatasetName", "lemma"], [41, 42, "DatasetName", "D3"]]}, {"text": "We explore the effect of semantic word clusters in these scenarios .", "entities": []}, {"text": "Finally we show our bestlinguistic ( high - resource ) model , and the resulting integration with word clusters .", "entities": []}, {"text": "7.2 Results Tables 3 - 5 show the results .", "entities": []}, {"text": "Target F - measure is calculated using the subset metric ( similar to metrics used by Yang and Cardie ( 2013 ) , Irsoy and Cardie ( 2014 ) ) ; if either the predicted or gold target tokens are a subset of the other , the match is counted when computing F - measure .", "entities": [[1, 4, "MetricName", "F - measure"], [52, 55, "MetricName", "F - measure"]]}, {"text": "Overlapping matches that are not subsets do not count ( e.g /char51 / chare5 / char94 / chard3 / char09 / charad / char10 / charaf / charf1 / chard3Egypt \u2019s position and /charc9 / char4a / char0a / char0d / char4b / char40 / char51 / chare5 / char85 / char40 / char09 / charad / char10 / charaf / charf1 / chard3Israel \u2019s position do not match . ) .", "entities": []}, {"text": "For this task , in the case of multiple mentions of the same entity in the post , any mention will be considered correct if the subset matches4(e.g if / char09 / chare1 / char1e / char0a / chara2 / char82 / charca / char09 / charafPalestine is a gold target , and / char09 / chare1 / char1e / char0a / chara2 / char82 / charca / char09 / charaf / char10 / chare9 / charcb / charf0 / char58state of Palestine is predicted at a different position in the post , it is still correct ) .", "entities": []}, {"text": "This evaluation is driven from the sentiment summarization perspective : we want to predict the overall opinion in the post towards an entity .", "entities": [[7, 8, "TaskName", "summarization"]]}, {"text": "F - pos , F - neg , and Acc - sent show the performance of the sentiment model on only the correctly predicted targets5 .", "entities": [[9, 10, "MetricName", "Acc"]]}, {"text": "Since the target and sentiment models are trained separately , this is meant to give an idea of how the sentiment model would perform in standalone mode , if targets were already provided .", "entities": []}, {"text": "F - all shows the overall F - measure showing the 4We have also computed the performance for mentionoverlap ; the difference in target F - measure is 2 points and consistent across the different systems .", "entities": [[6, 9, "MetricName", "F - measure"], [24, 27, "MetricName", "F - measure"]]}, {"text": "5We exclude targets with ambiguous sentiment whose polarity was not agreed on by the annotators.performance of correctly predicted targets with correct sentiment compared to the total number of polar targets .", "entities": []}, {"text": "This evaluates the end - to - end scenario of both important target and sentiment prediction .", "entities": []}, {"text": "Best results are shown in bold .", "entities": []}, {"text": "Signi\ufb01cance thresholds are calculated for the best performing systems ( Tables 4 - 5 ) using the approximate randomization test ( Yeh , 2000 ) for target recall , precision , F - measure , Acc - sent andF - all .", "entities": [[31, 34, "MetricName", "F - measure"], [35, 36, "MetricName", "Acc"]]}, {"text": "Signi\ufb01cance over the method in the previous row is indicated by*(p < 0.05),**(p < 0.005 ) , * * ( p < 0.0005 ) .", "entities": []}, {"text": "A con\ufb01dence interval of almost four F - measure points is required to obtain p < 0.05 .", "entities": [[6, 9, "MetricName", "F - measure"]]}, {"text": "Our dataset is small ; nonetheless we get signi\ufb01cant results .", "entities": []}, {"text": "Comparing Sentiment Lexicons Table 3 shows the results comparing the different baselines .", "entities": []}, {"text": "All targets are retrieved using all - NP ; sentiment is determined using the lexical baselines .", "entities": []}, {"text": "As expected , theall - NP baseline shows near perfect recall and low precision in predicting important targets .", "entities": []}, {"text": "We observe that the gloss - translated MPQA lexicon outperforms the two other Arabic lexicons among the sentiment baselines .", "entities": [[7, 8, "DatasetName", "MPQA"]]}, {"text": "We believe that the hit rate of MPQA is higher than that of the smaller , manually - labeled SIFAAT , and it is more precise than the automatically generated WordNet - based lexicon ArSenL.", "entities": [[7, 8, "DatasetName", "MPQA"]]}, {"text": "The performance of MPQA is , however , reliant on the availability of high - quality English glosses .", "entities": [[3, 4, "DatasetName", "MPQA"]]}, {"text": "We found MPQA to consistently outperform in the model results , so in our best - linguistic models , we only show results using the MPQA lexicon .", "entities": [[2, 3, "DatasetName", "MPQA"], [25, 26, "DatasetName", "MPQA"]]}, {"text": "Comparing Morphology Representations Looking at table 4 , we can see that using the lemma representation easily outperforms the sparser surface word , and that adding tokenized clitics as separate tokens outperforms representations which only use the word form .", "entities": [[14, 15, "DatasetName", "lemma"]]}, {"text": "Moreover , upon using the D3decliticization method , we observe a signi\ufb01cant increase in recall of targets over the ATB representation .", "entities": []}, {"text": "This shows that the presence of the Arabic de\ufb01nite article /charc8 / char40Al+is an important indicator of a target entity ; thus , even if an entity is not named , Al+ indicates that it is a known entity and is likely more salient .", "entities": []}, {"text": "The more tokens are split off , the more targets are recalled , although this comes at the cost of a decrease in sentiment performance , where the lemma representation has the highest sentiment score and the D3 representation has the lowest af-1007", "entities": [[28, 29, "DatasetName", "lemma"], [37, 38, "DatasetName", "D3"]]}, {"text": "Target Sentiment All - NP Recall Precision F - score F - pos F - neg Acc - sent F - all Baseline1 Majority 98.4", "entities": [[5, 6, "MetricName", "Recall"], [6, 7, "MetricName", "Precision"], [16, 17, "MetricName", "Acc"]]}, {"text": "29.2 45 0 72.4 56.8 12.4 Baseline2 ArSenL 98.4 29.2 45 50.6 64.3 58.6 12.7 Baseline3 SIFAAT 98.4 29.2 45 61 58 59.5 13.1 Baseline4 MPQA 98.4 29.2 45 67 63.7 65.4 14.2 Table 3 : Target and sentiment results using baselines ; all - NP for targets and lexicons for sentiment .", "entities": [[2, 3, "DatasetName", "0"], [25, 26, "DatasetName", "MPQA"]]}, {"text": "Target Sentiment Recall Precision F - score F - pos F - neg Acc - sent F - all Surface + POS 41 60.6 48.9 62.2 73.6 68.9 32.6 Lemma + POS 48.2**60.5 53.7 * 65.4 77.6 72.8 38.1 * * + ATB tokens 52.4 * 59.5 55.7 61.3 75.7 70.1 38.2 + D3 tokens 59.6**55.7 * 57.6 64.1 73 69.2 36.1 Table 4 : Target and sentiment results using different morphological representations .", "entities": [[2, 3, "MetricName", "Recall"], [3, 4, "MetricName", "Precision"], [13, 14, "MetricName", "Acc"], [29, 30, "DatasetName", "Lemma"], [53, 54, "DatasetName", "D3"]]}, {"text": "All models use POS .", "entities": []}, {"text": "ter surface word .", "entities": []}, {"text": "We believe the addition of extra tokens in the sequence ( which are function words and have not much bearing on semantics ) generates noise with respect to the sentiment model .", "entities": []}, {"text": "All models signi\ufb01cantly improve the baselines on Fmeasure ; for Acc - sent , the surface word CRF does not signi\ufb01cantly outperform the MPQA baseline .", "entities": [[10, 11, "MetricName", "Acc"], [17, 18, "MethodName", "CRF"], [23, 24, "DatasetName", "MPQA"]]}, {"text": "Effect of Word Clusters Figures 2 - 5 show the performance of different morphological representations when varying the number of word vector clusters k.", "entities": []}, {"text": "( Higher kmeans more clusters and fewer entities per semantic cluster . )", "entities": []}, {"text": "Adding cluster features tends to further boost the recall of important targets for all morphological schemes , while more or less maintaining precision .", "entities": []}, {"text": "The difference in different schemes is consistent with the results of Table 4 ; the D3 representation maintains the highest recall of targets , while the opposite is true for identifying sentiment towards the targets .", "entities": [[15, 16, "DatasetName", "D3"]]}, {"text": "The ATB representation shows the best overall Fmeasure , peaking at 41.5 using k=250 ( compare with 38.2 using no clusters ) ; however , it recalls much fewer targets than the D3 representation .", "entities": [[32, 33, "DatasetName", "D3"]]}, {"text": "The effect of clusters on sentiment is less clear ; it seems to bene\ufb01t the D3 and ATB schemes more than lemma ( signi\ufb01cant boosts in sentiment accuracy ) .", "entities": [[15, 16, "DatasetName", "D3"], [21, 22, "DatasetName", "lemma"], [27, 28, "MetricName", "accuracy"]]}, {"text": "The improvements in F - measure and F - all observed by using the best value of kis statistically signi\ufb01cant for all schemes ( k=10 for lemma , k=250 for lemma+ATB , k=500 for lemma+D3 , with F - all values of 40.7 , 41.5 , and 39.1 respectively ) .", "entities": [[3, 6, "MetricName", "F - measure"], [26, 27, "DatasetName", "lemma"]]}, {"text": "In general , the cluster performances tend to peak at a certain value of kwhich balances thereduced sparsity of the model ( fewer clusters ) with the semantic closeness of entities within a cluster ( more clusters ) .", "entities": []}, {"text": "Figure 2 : Target recall vs clusters .", "entities": []}, {"text": "Figure 3 : Target precision vs clusters .", "entities": []}, {"text": "Performance of Best Linguistic Model Table 5 shows the performance of our best - linguistic model , which in addition to the word form and part of speech , contains named entity and base phrase chunks , the syntactic dependency features , and the sentiment lexicon features .", "entities": []}, {"text": "The best linguistic model is run using both ATB andD3tokenization schemes , and then using a combined ATB+D3 scheme where we use D3 for the target model and remove the extra clitics before piping in the output to the sentiment model .", "entities": [[22, 23, "DatasetName", "D3"]]}, {"text": "This combined1008", "entities": []}, {"text": "Target Sentiment Recall Precision F - score F - pos F - neg Acc - sent F - all best - linguistic -ATB 53 62.1 57.2 68.6 79.4 75.1 40.7 best - linguistic -D3 64.2***58.8 61.4 * 62.7 75.6 70.5 * 39.1 best - linguistic -D3+ATB 63.7 58.8 61.4 67.7 80 75.4***43.1 * * * best - linguistic + clusters 66.2 57.8 61.8 70 80 76 44.2 Table 5 : Performance of best linguistic model Figure 4 : Target F - score vs clusters .", "entities": [[2, 3, "MetricName", "Recall"], [3, 4, "MetricName", "Precision"], [13, 14, "MetricName", "Acc"]]}, {"text": "Figure 5 : Sentiment accuracy vs clusters .", "entities": [[4, 5, "MetricName", "accuracy"]]}, {"text": "scheme results in the best results overall : F - score of 61.4 for targets , accuracy of 75.4 for sentiment and overall F - measure of 43.1 .", "entities": [[16, 17, "MetricName", "accuracy"], [23, 26, "MetricName", "F - measure"]]}, {"text": "Adding the richer linguistic resources results in both improved target precision , recall , and sentiment scores , with F - measure for positive targets reaching 67.7 for positive targets and 80 for negative targets .", "entities": [[19, 22, "MetricName", "F - measure"]]}, {"text": "Performance exceeds that of the simpler models which use only POS and word clusters , but it is worth noting that using only the basic model with the word clusters can achieve signi\ufb01cant boosts in recall and F - measure bringing it closer to the rich linguistic model .", "entities": [[37, 40, "MetricName", "F - measure"]]}, {"text": "The last row shows the best linguistic model D3+ATB combined with the clusters ( best result for k=8000 , or about 30 words per cluster ) .", "entities": []}, {"text": "Adding the clusters improves target and Fmeasure scores , although this result is not statistically signi\ufb01cant .", "entities": []}, {"text": "We observe that it becomes more dif\ufb01cult to improve on the rich linguistic model using word clusters , which are more bene\ufb01cial for low resource scenarios .", "entities": []}, {"text": "Our results are comparable to published work for most similar tasks in English : e.g Yang and Cardie ( 2013 ) who reported target subset Fmeasure of ~65 , Pontiki et al .", "entities": []}, {"text": "( 2014 ) where best Figure 6 : Overall F - score vs clusters .", "entities": []}, {"text": "Target Sentiment R P F Acc F - all Best - D3 63.7 52.3 57.4 69.4 35.4 Best - D3+ATB 63.7 51.8 57.1 70.3 36.8 + clusters 65.6 50.2 56.9 73.6 38.1 Table 6 : Target and sentiment results on test data .", "entities": [[5, 6, "MetricName", "Acc"], [11, 12, "DatasetName", "D3"]]}, {"text": "performing SemEval systems reported 70 - 80 % for sentiment given de\ufb01ned aspects , and ( Mitchell et al . , 2013 ; Deng and Wiebe , 2015 ) for overall Fmeasure ; we note that our tasks differ as described in section 2 .", "entities": []}, {"text": "Results on blind test Table 6 shows the results on unseen test data for best - linguistic using D3 , D3+ATB and with clusters using k=8000 .", "entities": [[18, 19, "DatasetName", "D3"]]}, {"text": "The results are similar to what was observed in the development data .", "entities": []}, {"text": "7.3 Error Analysis We analyzed the output of our best linguistic models on the development set , and observed the following kind of errors : Implicit Sentiment This was the most common kind of error observed .", "entities": [[1, 2, "MetricName", "Error"]]}, {"text": "Commenters frequently expressed complex subjective language without using sentiment words , often resorting to sarcasm , metaphor , and argumentative language .", "entities": []}, {"text": "We also observed persistent errors where positive sentiment was identi\ufb01ed towards an entity because of misleading polar words ; e.g minds /charc8 / charf1 / char10 / charae / charaa / charcb / char40 was consistently predicted to be positive even though the post in question was using implicit language to express negative sentiment ; the English gloss1009", "entities": []}, {"text": "Example 1", "entities": []}, {"text": "Till when will [ the world]- wait before it intervenes against these [ crimes against humanity]- committed by this [ criminal bloody regime]- which will not stop doing that ... because its presence has always been associated with oppression and murder and crime ...", "entities": []}, {"text": "But now it \u2019s time for it to disappear and descend into [ the trash of history]- .", "entities": []}, {"text": "Output the world : neg crimes : neg criminal bloody regime : neg the trash of history : neg Example 2", "entities": []}, {"text": "[ Malaysia]+ is considered the most successful country in Eastern Asia , and its economic success has spread to other [ aspects of life in Malaysia]+ , for its [ services to its citizens]+ have improved , and there has been an increase in [ the quality of its health and educational and social and \ufb01nancial and touristic services]+ , which has made it excellent for foreign investments .", "entities": []}, {"text": "Output Malaysia : pos health : pos educational and social : neg \ufb01nancial : neg Table 7 : Good and bad examples of output by SMARTies .", "entities": []}, {"text": "Gold annotations for targets are provided in the text with \u2018 - \u2019 or \u2018 + \u2019 re\ufb02ecting negative and positive sentiment towards targets .", "entities": []}, {"text": "isbrains , which appears as a positive subjective word in the MPQA lexicon .", "entities": [[11, 12, "DatasetName", "MPQA"]]}, {"text": "The posts also contained cases of complex coreference where subjective statements were at long distances from the targets they discussed .", "entities": []}, {"text": "Annotation Errors Our models often correctly predicted targets with reasonable sentiment which were not marked as important targets by annotators ; this points to the subjective nature of the task .", "entities": []}, {"text": "Sentiment lexicon misses These errors resulted from mis - match between the sentiment of the English gloss and the intended Arabic meaning , leading to polar sentiment being missed .", "entities": []}, {"text": "Primary Targets The data contains multiple entity targets and not all are of equal importance .", "entities": []}, {"text": "Out of the \ufb01rst 50 posts manually analyzed on the dev set , we found that in 38 out of 50 cases ( 76 % ) the correct primary targets were identi\ufb01ed ( the most important topical sentiment target(s ) addressed by the post ) ; in 4 cases , a target was predicted where the annotations contained no polar targets at all , and in the remaining cases the primary target was missed .", "entities": []}, {"text": "Correct sentiment polarity was predicted for 31 out of the 38 correct targets ( 81.6 % ) .", "entities": []}, {"text": "In general , our analysis showed that our system does well on posts where targets and subjective language are well formed , but that the important target identi\ufb01cation task is dif\ufb01cult and made more complex by the long and repetitive nature of the posts .", "entities": []}, {"text": "Table 7 shows two examples of the translated output of SMARTies , the \ufb01rst on more wellformed text and the second on text that is more dif\ufb01cult to parse .", "entities": []}, {"text": "8 Conclusions We presented a linguistically inspired system that can recognize important entity targets along with sentiment in opinionated posts in Arabic .", "entities": []}, {"text": "The targets can be any type of entity or event , and they arenot known beforehand .", "entities": []}, {"text": "Both target and sentiment results signi\ufb01cantly improve multiple lexical baselines and are comparable to previously published results in similar tasks for English , a similarly hard task .", "entities": []}, {"text": "Our task is further complicated by the informal and very long sentences that are used in Arabic online posts .", "entities": []}, {"text": "We showed that the choice of morphological representation signi\ufb01cantly affects the performance of the target and sentiment models .", "entities": []}, {"text": "This could shed light on further research in target - speci\ufb01c sentiment analysis for morphologically complex languages , an area little investigated previously .", "entities": [[11, 13, "TaskName", "sentiment analysis"]]}, {"text": "We also showed that the use of semantic clusters boosts performance for both target and sentiment identi\ufb01cation .", "entities": []}, {"text": "Furthermore , semantic clusters alone can achieve performance close to a more resource - rich linguistic model relying on syntax and sentiment lexicons , and would thus be a good approach for low - resource languages .", "entities": []}, {"text": "Integrating different morphological preprocessing schemes along with clusters gives our best result .", "entities": []}, {"text": "Our code and data is publicly available6 .", "entities": []}, {"text": "Future work will consider cross - lingual clusters and morphologically different languages .", "entities": []}, {"text": "Acknowledgments This work was supported in part by grant NPRP 6 - 716 - 1 - 138 from the Qatar National Research Fund , by DARPA DEFT grant FA8750 - 12 - 2 - 0347 and by DARPA LORELEI grant HR0011 - 15 - 20041 .", "entities": [[25, 26, "DatasetName", "DARPA"], [37, 38, "DatasetName", "DARPA"]]}, {"text": "The views expressed are those of the authors and do not re\ufb02ect the of\ufb01cial policy or position of the Department of Defense or the U.S government .", "entities": []}, {"text": "We thank anonymous reviewers for their helpful comments .", "entities": []}, {"text": "We thank Yves Petinot for providing feedback on the paper .", "entities": []}, {"text": "We thank Nizar Habash and Mona Diab for helpful discussions .", "entities": []}, {"text": "6www.cs.columbia.edu/~noura/Resources.html1010", "entities": []}, {"text": "References Muhammad Abdul - Mageed and Mona T. Diab .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Subjectivity and sentiment annotation of modern standard Arabic newswire .", "entities": []}, {"text": "In Proceedings of the 5th Linguistic Annotation Workshop , pages 110 \u2013 118 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Amjad Abu - Jbara , Ben King , Mona T. Diab , and Dragomir R. Radev .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Identifying opinion subgroups in arabic online discussions .", "entities": []}, {"text": "In ACL ( 2 ) , pages 829\u2013835 .", "entities": []}, {"text": "Mohammad Al - Smadi , Omar Qawasmeh , Bashar Talafha , and Muhannad Quwaider .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Human annotated arabic dataset of book reviews for aspect based sentiment analysis .", "entities": [[10, 12, "TaskName", "sentiment analysis"]]}, {"text": "In Future Internet of Things and Cloud ( FiCloud ) , 2015 3rd International Conference on , pages 726\u2013730 .", "entities": []}, {"text": "IEEE .", "entities": []}, {"text": "Gilbert Badaro , Ramy Baly , Hazem Hajj , Nizar Habash , and Wassim El - Hajj .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "A large scale arabic sentiment lexicon for arabic opinion mining .", "entities": [[8, 10, "TaskName", "opinion mining"]]}, {"text": "ANLP 2014 , pages 165\u2013173 .", "entities": []}, {"text": "Yassine Benajiba , Mona Diab , and Paolo Rosso .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Arabic named entity recognition using optimized feature sets .", "entities": [[1, 4, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 284\u2013293 . Association for Computational Linguistics .", "entities": []}, {"text": "Prakhar Biyani , Cornelia Caragea , and Narayan Bhamidipati . 2015 .", "entities": []}, {"text": "Entity - speci\ufb01c sentiment classi\ufb01cation of yahoo news comments .", "entities": []}, {"text": "arXiv preprint arXiv:1506.03775 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Samuel Brody and Noemie Elhadad . 2010 .", "entities": []}, {"text": "An unsupervised aspect - sentiment model for online reviews .", "entities": []}, {"text": "InHuman Language Technologies : The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , pages 804\u2013812 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Lingjia Deng and Janyce Wiebe .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Joint prediction for entity / event - level sentiment analysis using probabilistic soft logic models .", "entities": [[8, 10, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 179\u2013189 .", "entities": []}, {"text": "Li Dong , Furu Wei , Chuanqi Tan , Duyu Tang , Ming Zhou , and Ke Xu .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Adaptive recursive neural network for target - dependent twitter sentiment classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , pages 49\u201354 .", "entities": []}, {"text": "Mohamed Elarnaoty , Samir AbdelRahman , and Aly Fahmy .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "A machine learning approach for opinion holder extraction in arabic language .", "entities": []}, {"text": "arXiv preprint arXiv:1206.1011 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Noura Farra , Kathleen McKeown , and Nizar Habash . 2015 .", "entities": []}, {"text": "Annotating targets of opinions in arabic using crowdsourcing .", "entities": []}, {"text": "In ANLP Workshop 2015 , page 89.Nizar Habash and Fatiha Sadat . 2006 .", "entities": []}, {"text": "Arabic preprocessing schemes for statistical machine translation .", "entities": [[5, 7, "TaskName", "machine translation"]]}, {"text": "Proceedings of the Human Language Technology Conference of the NAACL , Companion Volume : Short Papers , pages 49\u201352 .", "entities": []}, {"text": "Nizar Habash , Behrang Mohit , Ossama Obeid , Kemal O\ufb02azer , Nadi Tomeh , and Wajdi Zaghouani .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "QALB :", "entities": []}, {"text": "Qatar Arabic language bank .", "entities": []}, {"text": "In Proceedings of Qatar Annual Research Conference ( ARC2013 ) , pages ICTP\u2013032 , Doha , Qatar .", "entities": []}, {"text": "Nizar Y .", "entities": []}, {"text": "Habash .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Introduction to Arabic natural language processing .", "entities": []}, {"text": "Synthesis Lectures on Human Language Technologies , 3(1):1\u2013187 .", "entities": []}, {"text": "Minqing Hu and Bing Liu .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Mining and summarizing customer reviews .", "entities": []}, {"text": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 168\u2013177 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "ACM .", "entities": [[0, 1, "DatasetName", "ACM"]]}, {"text": "Ozan Irsoy and Claire Cardie .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Opinion mining with deep recurrent neural networks .", "entities": [[0, 2, "TaskName", "Opinion mining"]]}, {"text": "In EMNLP , pages 720\u2013728 .", "entities": []}, {"text": "Long Jiang , Mo Yu , Ming Zhou , Xiaohua Liu , and Tiejun Zhao . 2011 .", "entities": []}, {"text": "Target - dependent twitter sentiment classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics : Human Language TechnologiesVolume 1 , pages 151\u2013160 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Soo - Min Kim and Eduard Hovy .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Extracting opinions , opinion holders , and topics expressed in online news media text .", "entities": []}, {"text": "In Proceedings of the Workshop on Sentiment and Subjectivity in Text , pages 1 \u2013 8 . Association for Computational Linguistics .", "entities": []}, {"text": "Taku Kudo . 2005 .", "entities": []}, {"text": "Crf++ : Yet another crf toolkit .", "entities": [[4, 5, "MethodName", "crf"]]}, {"text": "Software available at http://crfpp .", "entities": []}, {"text": "sourceforge .", "entities": []}, {"text": "net .", "entities": []}, {"text": "John Lafferty , Andrew McCallum , and Fernando Pereira . 2001 .", "entities": []}, {"text": "Conditional random \ufb01elds : Probabilistic models for segmenting and labeling sequence data .", "entities": []}, {"text": "In Proceedings of the eighteenth international conference on machine learning , ICML , volume 1 , pages 282\u2013289 .", "entities": []}, {"text": "Pengfei Liu , Sha\ufb01q Joty , and Helen Meng . 2015 .", "entities": [[7, 8, "DatasetName", "Helen"]]}, {"text": "Finegrained opinion mining with recurrent neural networks and word embeddings .", "entities": [[1, 3, "TaskName", "opinion mining"], [8, 10, "TaskName", "word embeddings"]]}, {"text": "In Conference on Empirical Methods in Natural Language Processing ( EMNLP 2015 ) , pages 1433\u20131443 .", "entities": []}, {"text": "James MacQueen .", "entities": []}, {"text": "1967 .", "entities": []}, {"text": "Some methods for classi\ufb01cation and analysis of multivariate observations .", "entities": []}, {"text": "InProceedings of the \ufb01fth Berkeley symposium on mathematical statistics and probability , volume 1 , pages 281\u2013297 .", "entities": []}, {"text": "Oakland , CA , USA .", "entities": []}, {"text": "Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Ef\ufb01cient estimation of word representations in vector space .", "entities": []}, {"text": "arXiv preprint arXiv:1301.3781 .1011", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Margaret Mitchell , Jacqueline Aguilar , Theresa Wilson , and Benjamin Van Durme .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Open domain targeted sentiment .", "entities": []}, {"text": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 1643\u20131654 .", "entities": []}, {"text": "Saif M. Mohammad , Svetlana Kiritchenko , Parinaz Sobhani , Xiaodan Zhu , and Colin Cherry . 2016 .", "entities": []}, {"text": "Semeval-2016 task 6 : Detecting stance in tweets .", "entities": []}, {"text": "In Proceedings of the International Workshop on Semantic Evaluation , SemEval , volume 16 , pages 31 \u2013 41 .", "entities": []}, {"text": "Ahmed Mourad and Kareem Darwish .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Subjectivity and sentiment analysis of modern standard arabic and arabic microblogs .", "entities": [[2, 4, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 4th workshop on computational approaches to subjectivity , sentiment and social media analysis , pages 55\u201364 .", "entities": []}, {"text": "Preslav Nakov , Alan Ritter , Sara Rosenthal , Fabrizio Sebastiani , and Veselin Stoyanov .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Semeval2016 task 4 : Sentiment analysis in twitter .", "entities": [[4, 6, "TaskName", "Sentiment analysis"]]}, {"text": "In Proceedings of the 10th international workshop on semantic evaluation ( SemEval 2016 ) , San Diego , US ( forthcoming ) , pages 1\u201318 .", "entities": []}, {"text": "Islam Obaidat , Rami Mohawesh , Mahmoud AlAyyoub , Mohammad AL - Smadi , and Yaser Jararweh . 2015 .", "entities": []}, {"text": "Enhancing the determination of aspect categories and their polarities in arabic reviews using lexicon - based approaches .", "entities": []}, {"text": "In Applied Electrical Engineering and Computing Technologies ( AEECT ) , 2015 IEEE Jordan Conference on , pages 1\u20136 .", "entities": [[2, 4, "TaskName", "Electrical Engineering"]]}, {"text": "IEEE .", "entities": []}, {"text": "Arfath Pasha , Mohamed Al - Badrashiny , Mona Diab , Ahmed El Kholy , Ramy Eskander , Nizar Habash , Manoj Pooleery , Owen Rambow , and Ryan M Roth . 2014 .", "entities": []}, {"text": "Madamira : A fast , comprehensive tool for morphological analysis and disambiguation of Arabic .", "entities": [[8, 10, "TaskName", "morphological analysis"]]}, {"text": "In Proceedings of the Language Resources and Evaluation Conference ( LREC ) , Reykjavik , Iceland , volume 14 , pages 1094\u20131101 .", "entities": []}, {"text": "Maria Pontiki , Haris Papageorgiou , Dimitrios Galanis , Ion Androutsopoulos , John Pavlopoulos , and Suresh Manandhar .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Semeval-2014 task 4 : Aspect based sentiment analysis .", "entities": [[6, 8, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the 8th International Workshop on Semantic Evaluation ( SemEval 2014 ) , pages 27\u201335 .", "entities": []}, {"text": "Eshrag Refaee and Verena Rieser .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Subjectivity and sentiment analysis of arabic twitter feeds with limited resources .", "entities": [[2, 4, "TaskName", "sentiment analysis"]]}, {"text": "In Workshop on Free / OpenSource Arabic Corpora and Corpora Processing Tools Workshop Programme , pages 16\u201321 .", "entities": []}, {"text": "Josef Ruppenhofer , Swapna Somasundaran , and Janyce Wiebe .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Finding the sources and targets of subjective expressions .", "entities": []}, {"text": "In LREC , pages 2781\u20132788 .", "entities": []}, {"text": "Mohammad Salameh , Saif M. Mohammad , and Svetlana Kiritchenko .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Sentiment after translation : A case - study on arabic social media posts .", "entities": []}, {"text": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 767\u2013777 .", "entities": []}, {"text": "Iman Saleh , Alessandro Moschitti , Preslav Nakov , Llu\u00eds M\u00e0rquez , and Sha\ufb01q Joty .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Semantic kernels for semantic parsing .", "entities": [[3, 5, "TaskName", "semantic parsing"]]}, {"text": "In EMNLP , pages 436\u2013442 .", "entities": []}, {"text": "Anas Shahrour , Salam Khalifa , and Nizar Habash . 2015 .", "entities": []}, {"text": "Improving arabic diacritization through syntactic analysis .", "entities": []}, {"text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 1309\u20131315 .", "entities": []}, {"text": "Swapna Somasundaran and Janyce Wiebe .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Recognizing stances in online debates .", "entities": []}, {"text": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP : Volume 1 - Volume 1 , pages 226\u2013234 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Oscar T\u00e4ckstr\u00f6m , Ryan McDonald , and Jakob Uszkoreit .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "Cross - lingual word clusters for direct transfer of linguistic structure .", "entities": []}, {"text": "In Proceedings of the 2012 conference of the North American chapter of the association for computational linguistics : Human language technologies , pages 477\u2013487 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Duyu Tang , Bing Qin , Xiaocheng Feng , and Ting Liu . 2015 .", "entities": []}, {"text": "Effective lstms for targetdependent sentiment classi\ufb01cation .", "entities": []}, {"text": "arXiv preprint arXiv:1512.01100 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Joseph Turian , Lev Ratinov , and Yoshua Bengio .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Word representations : a simple and general method for semi - supervised learning .", "entities": []}, {"text": "In Proceedings of the 48th annual meeting of the association for computational linguistics , pages 384\u2013394 . Association for Computational Linguistics .", "entities": []}, {"text": "Yequan Wang , Minlie Huang , xiaoyan zhu , and Li Zhao .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Attention - based lstm for aspectlevel sentiment classi\ufb01cation .", "entities": [[3, 4, "MethodName", "lstm"]]}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 606\u2013615 , Austin , Texas , November .", "entities": [[19, 20, "DatasetName", "Texas"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Theresa Wilson , Janyce Wiebe , and Paul Hoffmann .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Recognizing contextual polarity in phraselevel sentiment analysis .", "entities": [[5, 7, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the conference on human language technology and empirical methods in natural language processing , pages 347\u2013354 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Bishan Yang and Claire Cardie .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Joint inference for \ufb01ne - grained opinion extraction .", "entities": []}, {"text": "In ACL ( 1 ) , pages 1640\u20131649.1012", "entities": []}, {"text": "Alexander Yeh .", "entities": []}, {"text": "2000 .", "entities": []}, {"text": "More accurate tests for the statistical signi\ufb01cance of result differences .", "entities": []}, {"text": "In Proceedings of the 18th conference on Computational linguistics - Volume 2 , pages 947\u2013953 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Wajdi Zaghouani , Behrang Mohit , Nizar Habash , Ossama Obeid , Nadi Tomeh , Alla Rozovskaya , Noura Farra , Sarah Alkuhlani , and Kemal O\ufb02azer .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Large scale arabic error annotation : Guidelines and framework .", "entities": []}, {"text": "In LREC , pages 2362\u20132369 .", "entities": []}, {"text": "Meishan Zhang , Yue Zhang , and Duy - Tin V o. 2015 .", "entities": []}, {"text": "Neural networks for open domain targeted sentiment .", "entities": []}, {"text": "In Proceedings of the 2015 Conference on EMNLP , pages 612\u2013621 .", "entities": []}, {"text": "Ayah Zirikly and Masato Hagiwara .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Crosslingual transfer of named entity recognizers without parallel corpora .", "entities": []}, {"text": "Volume 2 : Short Papers , pages 390\u2013396.1013", "entities": []}]