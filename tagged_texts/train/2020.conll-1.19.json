[{"text": "Proceedings of the 24th Conference on Computational Natural Language Learning , pages 256\u2013264 Online , November 19 - 20 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17256Relations between comprehensibility and adequacy errors in machine translation output Maja Popovi \u00b4 c ADAPT Centre , School of Computing Dublin City University , Ireland maja.popovic@adaptcentre.ie", "entities": [[12, 14, "TaskName", "machine translation"]]}, {"text": "Abstract", "entities": []}, {"text": "This work presents a detailed analysis of translation errors perceived by readers as comprehensibility and/or adequacy issues .", "entities": []}, {"text": "The main \ufb01nding is that good comprehensibility , similarly to good \ufb02uency , can mask a number of adequacy errors .", "entities": []}, {"text": "Of all major adequacy errors , 30 % were fully comprehensible , thus fully misleading the reader to accept the incorrect information .", "entities": []}, {"text": "Another 25 % of major adequacy errors were perceived as almost comprehensible , thus being potentially misleading .", "entities": []}, {"text": "Also , a vast majority of omissions ( about 70 % ) is hidden by comprehensibility .", "entities": []}, {"text": "Further analysis of misleading translations revealed that the most frequent error types are ambiguity , mistranslation , noun phrase error , word - by - word translation , untranslated word , subject - verb agreement , and spelling error in the source text .", "entities": [[25, 27, "TaskName", "word translation"]]}, {"text": "However , none of these error types appears exclusively in misleading translations , but are also frequent in fully incorrect ( incomprehensible inadequate ) and discarded correct ( incomprehensible adequate ) translations .", "entities": []}, {"text": "Deeper analysis is needed to potentially detect underlying phenomena speci\ufb01cally related to misleading translations .", "entities": []}, {"text": "1 Introduction While automatic evaluation metrics are very important and invaluable tools for rapid development of machine translation ( MT ) systems , they are only a substitution for human assessment of translation quality .", "entities": [[16, 18, "TaskName", "machine translation"]]}, {"text": "Various methods have been proposed and used for the human evaluation of MT quality by assigning overall scores to MT outputs , such as ( ALPAC , 1966 ; White et", "entities": []}, {"text": "al . , 1994 ; Koehn and Monz , 2006 ; Callison - Burch et al . , 2007 ; Roturier and Bensadoun , 2011 ; Graham et al . , 2013 ; Barrault et al . , 2019 ) , and all of them rely on at least one of the three translation quality criteria : comprehensibility ( comprehension , intelligibility ) , adequacy(\ufb01delity , semantic accuracy ) , and \ufb02uency ( grammaticality ) .", "entities": [[67, 68, "MetricName", "accuracy"]]}, {"text": "Comprehensibility re\ufb02ects the degree to which a translated text can be understood , adequacy re\ufb02ects the degree to which the translation conveys the meaning of the original text in the source language , and \ufb02uency re\ufb02ect the grammar of the translated text .", "entities": []}, {"text": "The raters are usually asked to assign an overall score for the given translation criterion .", "entities": []}, {"text": "In order to get more details about translation performance , error classi\ufb01cation and analysis emerged in the \ufb01eld of MT ( Vilar et al . , 2006 ; Lommel et al . , 2014 ; Klubi \u02c7cka et al . , 2018 ; Van Brussel et", "entities": []}, {"text": "al . , 2018 )", "entities": []}, {"text": ".", "entities": []}, {"text": "However , there is less work dealing with human perception of MT quality and errors .", "entities": []}, {"text": "For statistical phrase - based MT systems ( SMT ) , Kirchhoff et al . ( 2014 ) and Federico et al .", "entities": []}, {"text": "( 2014 ) were identifying error types which are mostly disliked by readers .", "entities": []}, {"text": "In the last \ufb01ve years , systems based on arti\ufb01cial neural networks ( NMT ) have become the new state of the art .", "entities": []}, {"text": "Several evaluation studies , such as ( Castilho et al . , 2017 ; Klubi \u02c7cka et al . , 2018 ; Van Brussel et al . , 2018 ) reported that these systems are able to produce more \ufb02uent and readable translations , but that they are still sufferring from adequacy issues .", "entities": []}, {"text": "In addition , many participants mentioned that good \ufb02uency of NMT outputs makes it more dif\ufb01cult to spot adequacy errors such as omissions or mistranslations .", "entities": []}, {"text": "Such \u201c \ufb02uently inadequate \u201d errors may mislead readers into trusting the content based on \ufb02uency alone , especially when surrounded by \ufb02uent and adequate parts of a text ( Martindale and Carpuat , 2018 ) .", "entities": []}, {"text": "Automatic identi\ufb01cation of such errors for both SMT and NMT systems has been investigated in ( Martindale et al . , 2019 ) and it is con\ufb01rmed that these errors appear much more often in NMT system .", "entities": []}, {"text": "To the best of our knowlegde , comprehensibility , while being a very important translation quality factor , has not been investigated in depth yet .", "entities": []}, {"text": "It", "entities": []}, {"text": "257should be stressed that comprehensibility is very different from \ufb02uency \u2013 a \ufb02uent text can be incomprehensible ( for example \u201c Colorless green ideas sleep furiously . \u201d ) , and vice versa ( for example \u201c All these experiment was carry out this year . \u201d ) .", "entities": []}, {"text": "Our main research questions are : RQ1 Are there \u201c comprehensible inadequate \u201d translations which are misleading human readers so that they fully trust the MT output despide adequacy errors ?", "entities": []}, {"text": "In other words : how many adequacy errots are perceived as comprehensible ?", "entities": []}, {"text": "RQ2 If the answer to the RQ1 is \u201c yes \u201d , which types of translation errors are mainly related to these translations ?", "entities": []}, {"text": "As a \ufb01rst step , a group of evaluators annotated problematic parts of the given machine translated text .", "entities": []}, {"text": "They were not asked to assign any error labels , only to mark the parts of the text which they perceived as problematic for the given translation criterion .", "entities": []}, {"text": "They \ufb01rst annotated all comprehensibility issues , and after about two weeks , all adequacy issues .", "entities": []}, {"text": "For each criterion , they were asked to distinguish major and minor issues .", "entities": []}, {"text": "We then analysed all major issues in order to examine relations between comprehensibility and adequacy and identify error types .", "entities": []}, {"text": "The analysis was carried out on English user reviews ( as a case of \u201c mid - way \u201d genre between formal and informal written language ) translated into Croatian and Serbian ( as a case of mid - size less - resourced morphologically rich European languages ) .", "entities": []}, {"text": "It is worth noting that the aim of this work is not to compare MT systems , nor to estimate their overall performance for the given language pairs and domain in order to potentially improve them .", "entities": []}, {"text": "The aim of this work is to explore relations between two aspects of human perception of translation quality .", "entities": []}, {"text": "2 Related work Lot of research on MT evaluation deals with classi\ufb01cation and analysis of MT errors , for example ( Vilar et al . , 2006 ; Farr \u00b4 us et al . , 2010 ; Stymne and Ahrenberg , 2012 ; Lommel et al . , 2014 ; Klubi \u02c7cka et al . , 2018 ) .", "entities": []}, {"text": "Few papers deal with human perception of these errors , but neither of them de\ufb01nes precisely which criterion is the translation quality based on .", "entities": []}, {"text": "Kirchhoff et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2014 ) uses conjoint analysis to investigate user preferences for error types of SMT systems .", "entities": []}, {"text": "First , the errors in MT outputs were annotated , and then MT outputs with different error types were given to the crowd evaluators .", "entities": []}, {"text": "They were asked to choose the MT output which they like best and to give the reason for their preference .", "entities": []}, {"text": "One of the \ufb01ndings is that the frequencies of error types are not related to the user preferences .", "entities": []}, {"text": "The most dispreferred error type was word order error , although it was the least frequent one .", "entities": []}, {"text": "It was followed by word sense errors ( ambiguity ) , then morphological errors ( most frequent ones ) , whereas errors in function words were the most tolerable .", "entities": []}, {"text": "A similar study on SMT outputs based on linear mixed - effects models is described in ( Federico et al . , 2014 ) , aiming to estimate the impact of different translation errors to the overall translation quality .", "entities": []}, {"text": "For each MT output , experts were asked to assign a score on a 5 - point scale while other experts annotated the errors .", "entities": []}, {"text": "The results con\ufb01rmed that the frequency of errors of a given type does not correlate with human preferences .", "entities": []}, {"text": "Another \ufb01nding is that omissions and mistranslations have the highest impact on the overall translation quality .", "entities": []}, {"text": "In addition , it is observed that certain combinations of errors have less impact than each of those error types ocurring in isolation .", "entities": []}, {"text": "In the last few years , with the emergence of NMT systems which generate much more \ufb02uent and readable outputs but still are prone to adequacy errors , some studies have concentrated on investigating adequacy and \ufb02uency errors .", "entities": []}, {"text": "Martindale and Carpuat ( 2018 ) carried out a survey to determine how users respond to good translations compared to translations that are either adequate but not \ufb02uent , or \ufb02uent but not adequate .", "entities": []}, {"text": "This study showed that users strongly disliked dis\ufb02uent translations , but were much less bothered with adequacy errors .", "entities": []}, {"text": "Therefore , it was concluded that \ufb02uent translations with adequacy errors can mislead the reader to trust an incorrect meaning .", "entities": []}, {"text": "Automatic identi\ufb01cation of these misleading \u201c \ufb02uently inadequate \u201d translations using source text , reference human translation and MT output was proposed in ( Martindale et al . , 2019 ) , and the main \ufb01nding was that NMT systems generate more misleading translations than SMT systems .", "entities": []}, {"text": "However , the question about how many adequacy errors are actually hidden by \ufb02uency remained open .", "entities": []}, {"text": "To the best of our knowledge , the relation be-", "entities": []}, {"text": "258tween adequacy and comprehensibility has not been investigated yet .", "entities": []}, {"text": "Comprehensibility , similarly to \ufb02uency , has an immediate effect on the reader , while adequacy problems can be perceived only if the reader has access to the source text or to a correct translation to \ufb01nd out that the meaning is wrong .", "entities": []}, {"text": "This means that comprehensibility may have the same misleading effect making the reader accept an incorrect information .", "entities": []}, {"text": "On the other hand , because comprehensibility is different than \ufb02uency ( \ufb02uent sentences can be incomprehensible and vice versa ) , the effects might be different .", "entities": []}, {"text": "3 Data set Our analysis has been carried out on written usergenerated content , namely user reviews .", "entities": []}, {"text": "Two types of publicly available user reviews written in English have been analysed : IMDb movie reviews1(Maas et al . , 2011 ) and Amazon product reviews2(McAuley et al . , 2015 ) .", "entities": [[14, 15, "DatasetName", "IMDb"]]}, {"text": "A set of those user reviews was translated into Croatian and Serbian , two closely related mid - size less - resourced morphologically rich European languages .", "entities": []}, {"text": "The reviews were translated3by three on - line systems : Google Translate4 , Bing5and Amazon translate6 .", "entities": [[10, 11, "DatasetName", "Google"]]}, {"text": "The analysed text consists of a mixture of MT outputs from the three systems including 222 translated reviews consisting of about 1500 sentences ( segments ) and 19837 untokenised words in total .", "entities": []}, {"text": "This text was then given to the annotators to mark comprehensibility and adequacy issues , and the process is described in details in the next section .", "entities": []}, {"text": "The annotated text is publicly available under the Creative Commons CC - BY licence.7 3.1 Annotating comprehensibility and adequacy issues As mentioned in Introduction , comprehensibility re\ufb02ects the degree to which a translated text can be understood , and adequacy re\ufb02ects the degree to which the translation conveys the meaning of 1https://ai.stanford.edu/ \u02dcamaas / data/ sentiment/ 2http://jmcauley.ucsd.edu/data/amazon/ 3at the end of January 2020", "entities": []}, {"text": "4https://translate.google.com/ 5https://www.bing.com/translator 6https://aws.amazon.com/translate/ 7https://github.com/m-popovic/ QRev - annotations / tree / master/ initial - analysisthe original text in the source language .", "entities": []}, {"text": "Comprehension should be assessed without access to the original text in the source language ( or a correct translation ) , while the original text ( or a correct translation ) is mandatory for adequacy .", "entities": []}, {"text": "Therefore , each annotator \ufb01rst completed the annotation of comprehension issues while reading only the translation .", "entities": []}, {"text": "After completing ( usually after about two weeks ) , they annotated adequacy issues by comparing the translation with the original source text .", "entities": []}, {"text": "For each criterion , the annotators were asked to distinguish two levels of issues : major issues and minor issues .", "entities": []}, {"text": "While for this particular study we are interested only in major issues , we did not want any errors to remain unannotated .", "entities": []}, {"text": "The following guidelines were given to the annotators : Comprehensibility : \u000fmark all parts of the text ( single words , small or long phrases , or entire sentences ) which are not understandable ( it does not make sense , it is not clear what it is about , etc . )", "entities": []}, {"text": "as major issues ; \u000fmark all parts of the text ( again : words , phrases or sentences ) which seem understandable but contain grammatical or stylistic errors as minor issues ; \u000fif it seems that something is missing , add \u201c XXX \u201d to the corresponding position .", "entities": []}, {"text": "Adequacy : \u000fmark all parts of the translation ( single words , small or long phrases , or entire sentences ) which have different meaning than the original English text as major issues ; \u000fmark all parts of the translation ( again : words , phrases or sentences ) which do not actually change the meaning of the source text , but contain sub - optimal lexical choices or grammar errors as minor issues ; \u000fif some parts of the original English text are missing in the translation , add \u201d XXX \u201d to the corresponding position in the translation ; \u000fif there are any errors in the source language8 ( spelling or grammar errors , etc . ) , mark its 8Detailed instructions for errors in the source text are particularly relevant for evaluating user generated content .", "entities": []}, {"text": "259translation as major or minor issue if it does not correspond to the intented English word even though it is a correct translation of the erroneous English word .", "entities": []}, {"text": "The annotators were seeing the entire reviews during the process , not only isolated segments or blocks of 2 - 3 segments .", "entities": []}, {"text": "In this way , it was ensured that the annotators were able to spot any contextdependent issues .", "entities": []}, {"text": "We wanted the texts to be annotated by a reliable group of readers which is neither too homogeneous as a group of professional translators nor too heterogeneous as crowd evaluators .", "entities": []}, {"text": "Therefore , the annotation was performed by computational linguistics researchers and students , \ufb02uent in the source language and native speakers of the target language .", "entities": []}, {"text": "They had different backgrounds , coming from technical studies , translation studies as well as from humanities .", "entities": []}, {"text": "Because the annotators were not asked to perform any \ufb01ne - grained categorisation , the interannotator agreement was high \u2013 annotators assigned identical issue tags to more than 70 % of words .", "entities": []}, {"text": "More details about the annotation process can be found in ( Popovi \u00b4 c , 2020 ) .", "entities": []}, {"text": "4 Analysis of comprehensibility and adequacy issues Table 1 presents overall percentages9of words perceived as issues , separately for each of the two translation criteria .", "entities": []}, {"text": "In total ( including both target languages and all three MT systems ) , 9.5 % words in the text were perceived as incomprehensible , and the meaning of 9.9 % words was changed in the translation process .", "entities": []}, {"text": "As for minor issues , 13.5 % words were perceived as slightly dif\ufb01cult to understand , and 12.8 % were not translated in the optimal way .", "entities": []}, {"text": "It can be noted that the overall amounts of comprehensibility and adequacy issues are similar .", "entities": []}, {"text": "However , it does not necessarily mean that the majority of words is perceived both as incomprehensible and inadequate .", "entities": []}, {"text": "Therefore , we examined major comprehensibility and adequacy issues in depth .", "entities": []}, {"text": "9raw counts divided by the total number of words in the text including those without issues and the omission marks \u201c XXX\u201dquality aspect grade raw count % words comprehension major 1887 9.5 minor 2673 13.5 adequacy major 1963 9.9 minor 2539 12.8 Table 1 : Raw counts and percentages of words ( normalised by the total number of words , including those without issues and the omission marks \u201c XXX \u201d ) perceived as problematic for comprehensibility and adequacy .", "entities": []}, {"text": "4.1 Relations between different types of issues In order to determine presence or absence of misleading translations , we explored the following cases of different relations between comprehensibility and adequacy errors : \u000fonly major adequacy issue A maj ( comprehensible inadequate translation ) \u2013 incorrect information is accepted \u2013 The meaning of the original text is changed but the translation is readable and comprehensible .", "entities": []}, {"text": "The reader feels comfortable with the text and does not notice any problem , thus accepting the incorrect meaning . \u000fAmaj+Cmin \u2013 major adequacy and minor comprehension issues ( almost comprehensible inadequate translation ) \u2013 incorrect information can be accepted \u2013 The meaning of the original text is changed , and the reader \ufb01nds this incorrect meanining slightly dif\ufb01cult to understand .", "entities": []}, {"text": "The reader is therefore susceptible to accept this incorrect meaning .", "entities": []}, {"text": "\u000fAmaj+Cmaj \u2013 both major issues ( incomprehensible inadequate translation ) \u2013 incorrect information is discarded \u2013 The meaning of the original text is changed , and the reader is not able to understand this changed meaning .", "entities": []}, {"text": "The reader clearly notices that there is something wrong with the text .", "entities": []}, {"text": "\u000fCmaj+Amin \u2013 major comprehension and minor adequacy issues ( incomprehensible almost adequate translation )", "entities": []}, {"text": "\u2013 almost correct information is discarded \u2013 The meaning of the original text is basically conveyed to the translation , only not in an", "entities": []}, {"text": "260affected words issue types raw count % words", "entities": []}, {"text": "% A maj only A maj 588 2.96 30.0 Amaj+Cmin 490 2.47 24.9 Amaj+Cmaj 885 4.46 45.1 Cmaj+Amin 342 1.72 only C maj 660 3.33 Cmin+Amin 1254 6.32 only C min 929 4.68 only A min 943 4.75 Table 2 : Raw counts and percentages of words ( normalised by the total number of words , including those without issues and the omission marks \u201c XXX \u201d ) of all combinations of perceived issue types .", "entities": []}, {"text": "For cases involving major adequacy issues , the percentages normalised by the total number of major adequacy issues are shown , too , in order to estimate the portion of hidden adequacy issues .", "entities": []}, {"text": "For the sake of completenes , the numbers are presented for minor issues , too , although they were not further analysed in this work .", "entities": []}, {"text": "optimal way , but the reader can not understand it .", "entities": []}, {"text": "The reader is thus missing some correct information .", "entities": []}, {"text": "\u000fonly major comprehension issue C maj ( incomprehensible adequate translation ) \u2013 correct information is discarded \u2013 The meaning of the original text is correctly conveyed to the translation , but the reader can not understand it .", "entities": []}, {"text": "The reader is therefore not able to get the fully correct information .", "entities": []}, {"text": "Table 2 presents raw counts and percentages of words perceived in the described ways .", "entities": []}, {"text": "For the sake of completeness , the numbers for minor issue types are shown as well .", "entities": []}, {"text": "The numbers are generally in line with the \ufb01ndings of the previous work ( Kirchhoff et al . , 2014 ; Federico et al . , 2014 ) regarding lack of correlation between the error frequency and perception of severity \u2013 in our texts , the frequencies of words perceived only as minor issues are higher than the frequencies of words perceived as major issues .", "entities": []}, {"text": "As already mentioned , minor issues were not further analysed in this work , because by de\ufb01nition they were not perceived as essential : either the meaning was preserved although not conveyed in the best way , or the translation was slightly dif\ufb01cult to understand , or both .", "entities": []}, {"text": "Misleading translations Table 2 shows that about 3 % of words in the translated text are mis - leading , and 2.5 % are potentially misleading .", "entities": []}, {"text": "This means that of every 100 words in the translation , 3 are fully accepted by the reader although their meaning is not correct , and 2 can be potentially accepted .", "entities": []}, {"text": "Furthermore , from all major adequacy errors in the text , only 45.5 % are incomprehensible .", "entities": []}, {"text": "About 30 % of adequacy errors are fully hidden so that the reader does not notice any problem , and about 25 % are partially hidden because the reader is not fully sure that s / he understands the text , but s / he is very susceptible to accept the meaning .", "entities": []}, {"text": "All in all , the portion of misleading translations is not negligible , so we continued our analysis by trying to identify error types associated with such translations .", "entities": []}, {"text": "Also , we wanted to explore whether there are error types related ( almost ) exclusively to them .", "entities": []}, {"text": "4.2 Error types For each ( group of ) word(s ) perceived as compreensibility or adequacy major issue , we assigned an error type .", "entities": [[1, 2, "MetricName", "Error"]]}, {"text": "The error types were not prede\ufb01ned by any particular error typology , but identi\ufb01ed while looking into the text .", "entities": []}, {"text": "It is worth noting that many error types were identi\ufb01ed , but most of them are ocurring rarely in the text .", "entities": []}, {"text": "Also , for some of the annotated words no particular error type could be de\ufb01ned , which is probably an effect of annotators \u2019 personal preferences .", "entities": []}, {"text": "The most frequent error types perceived as misleading translations can be de\ufb01ned as follows : \u000fambiguity The obtained translation for the given word is in principle correct , but not in the given context ( word sense error ) .", "entities": []}, {"text": "\u000fmistranslation The obtained translation for the given word is incorrect .", "entities": []}, {"text": "\u000fnoun phrase An English sequence consisting of a head noun and additional nouns and adjectives is incorrectly translated .", "entities": []}, {"text": "Formation rules for Serbian and Croatian are rather different than for English and there is often no unique solution .", "entities": []}, {"text": "The examples in the table below represent two English noun collocations and their reference translations into Serbian and Croatian together with the corresponding English glosses .", "entities": []}, {"text": "This", "entities": []}, {"text": "261type of issue is relevant for many Slavic languages .", "entities": []}, {"text": "language NP1 NP2 en grill cover chocolate cake sr / hr poklopac za ro \u02c7stilj \u02c7cokoladni kola \u02c7c gloss cover for grill \u2018 chocolaty \u2019 cake \u000fspelling error in source A word in the original text in the source language has spelling errors which result in incorrect translation .", "entities": []}, {"text": "This type of issue is especially relevant for user - generated content .", "entities": []}, {"text": "\u000fsubject - verb agreement A verb in\ufb02ection in the translation denoting person does not correspond to the subject .", "entities": []}, {"text": "\u000funtranslated", "entities": []}, {"text": "A word in the source language is simply copied to the translated text .", "entities": []}, {"text": "\u000fword - by - word translation A sequence of source words is translated as single words \u2013 the translation choice of each word looks random , both lexically and morphologically , without taking into account any context .", "entities": [[4, 6, "TaskName", "word translation"]]}, {"text": "Table 3 shows these error types and their percentages for misleading translations .", "entities": []}, {"text": "These error types are the certainly \u201c dangerous \u201d because they can easily mislead the reader to accept incorrect information .", "entities": []}, {"text": "However , the very same error types are often perceived as fully incorrect ( incomprehensible inadequate ) , too .", "entities": []}, {"text": "Furthermore , they ( except of untranslated words ) even often lead to discarding correct information ( incomprehensible adequate ) .", "entities": []}, {"text": "Further in - depth analysis is needed to determine whether there are some underlying phenomena related exclusively to the misleading translations .", "entities": []}, {"text": "Five examples of different perceptions of ambiguity errors , noun phrase errors and word - by - word translations are presented in Table 4 .", "entities": []}, {"text": "All sentences except 3 ) have misleading parts ( fully misleading marked as red and potentially misleading as green ) .", "entities": []}, {"text": "In the sentences 1 ) and 2 ) there is only one misleading ambiguous word .", "entities": []}, {"text": "The incorrectly chosen variants of these words are fully comprehensible so that without the source text , the reader was not able to \ufb01gure out that the information is not correct .", "entities": []}, {"text": "On the other hand , the ambiguous word in the sentence 3 ) , together with the noun phrase , is perceived asboth incomprehensible and inadequate ( marked as violet ) .", "entities": []}, {"text": "Sentences 4 ) and 5 ) illustrate how different parts of a phrase translated word - by - word are perceived in different ways : violet denotes fully incorrect , red denotes misleading , and cyan denotes discarding almost correct translation .", "entities": []}, {"text": "It might be worth noting that all sentences are perfectly \ufb02uent except the sentence 3 ) which is very dis\ufb02uent .", "entities": []}, {"text": "Propagation effect Table 3 also shows that there is a strong effect of propagation for comprehensibility \u2013 many correct words are perceived as incomprehensible because of errors in surrounding words .", "entities": []}, {"text": "In many cases , the reader \ufb01nds the whole sentence incomprehensible .", "entities": []}, {"text": "An example of propagation can be seen in Table 5 .", "entities": []}, {"text": "All words in bold are correct , but all were perceived as major comprehensibility issues due to different types of errors in surrounding words : a red misleading omission , a fully incorrect violet word , and an incomprehensible group of almost correct cyan words .", "entities": []}, {"text": "It should be mentioned that for some adequacy errors , annotators also marked one or two neighbouring words which were not really incorrect , but that happened very rarely .", "entities": []}, {"text": "Omissions Since several studies reported that the omissions are generally problematic to spot without access to the source text , we compared the frequencies of omissions percieved only as comprehensibility issue , only as adequacy issue , and as both ( regardless of the severity grade ) .", "entities": []}, {"text": "Table 6 con\ufb01rms the previous \ufb01ndings : a vast majority of omissions ( 71.5 % ) was perceived only as adequacy error .", "entities": []}, {"text": "Only 9 % of actual omissions were also perceived as comprehensibility issues .", "entities": []}, {"text": "Apart from this , 19 % of omissions were perceived as exclusively comprehensibility issues and are not related to anything actually omitted from the source text .", "entities": []}, {"text": "The most probable reason is the in\ufb02uence of other surrounding errors , but further analysis is needed to better understand this effect .", "entities": []}, {"text": "5 Conclusions This work presents the results of a detailed analysis of translation errors perceived by readers as major comprehensibility and/or major adequacy issues .", "entities": []}, {"text": "The main \ufb01nding is that good comprehensibility , similarly to good \ufb02uency , can mask a number of adequacy errors .", "entities": []}, {"text": "Of all major adequacy errors , 30 % were fully comprehensible , thus fully misleading the reader to accept the incorrect information .", "entities": []}, {"text": "An-", "entities": []}, {"text": "262incorrect information is : discarded information is : accepted potentially accepted discarded almost correct correct only A maj Amaj+Cmin Amaj+Cmaj Cmaj+Amin only C maj ambiguity 24.0 ambiguity 24.8 ambiguity 26.7 ambiguity 16.4 propagation 33.3 mistranslation 6.0 mistranslation 8.9 mistranslation 8.2 noun phrase 8.4 ambiguity 14.4 word - by - word 5.0 noun phrase 8.4 noun phrase 6.9 mistranslation 5.8 noun phrase 7.0 noun phrase 4.4 untranslated 8.2 untranslated 6.7 fnoun case 5.8 g word - by - word 4.1 source spelling 3.8 word - by - word 5.4 word - by - word 5.5 word - by - word 5.8 mistranslation 3.7 subject - verb 3.8 ( subject - verb 3.2 ) ( subject - verb 4.5 ) subject - verb 4.9 ( subject - verb 2.0 ) untranslated 3.8 ( source spelling 2.4 ) ( source spelling 3.5 ) fPOS ambiguity 3.5 g(source spelling 1.2 ) Table 3 : The most frequent error types perceived as a particular issue combination .", "entities": []}, {"text": "The numbers represent percentages of the error type perceived as the issue combination \u2013 24.0 % of all comprehensible inadequate translations ( accepted incorrect information ) are ambiguity errors , 6.0 % are mistranslations , etc .", "entities": []}, {"text": "Parentheses indicate that the error type was not in the top list for the given issue combination , but it is presented for comparison because it is in the top list for misleading traslations .", "entities": []}, {"text": "other 25 % of major adequacy errors were perceived as almost comprehensible , thus being potentially misleading .", "entities": []}, {"text": "In addition , a vast majority of omissions ( about 70 % ) is hidden by comprehensibility .", "entities": []}, {"text": "Further analysis of those misleading translations was carried out in order to \ufb01nd out which types of translation errors are perceived in this way .", "entities": []}, {"text": "Ambiguous words , mistranslations , noun phrases , untranslated words , word - by - word translations , subject - verb agreement and spelling errors in the original text were identi\ufb01ed as the most frequent error types in misleading translations .", "entities": []}, {"text": "Although noun phrase problems are typical for Slavic languages and errors in the source text are typical for user generated content , the rest of the error types is rather general .", "entities": []}, {"text": "However , none of these error types is exclusively related to misleading translations , but are also frequent in fully incorrect ( incomprehensible inadequate ) and discarded correct ( incomprehensible adequate ) translations .", "entities": []}, {"text": "Deeper analysis is needed to potentially detect underlying phenomena speci\ufb01cally related to misleading translations .", "entities": []}, {"text": "Apart from the obvious directions for future work such as analysing more texts and including more language pairs and domains , the presented analysis can be expanded in the following directions : including \ufb02uency in the analysis , including all minor issues in the analysis , further analysis of omissions , and investigating co - ocurrences of different error types .", "entities": []}, {"text": "Another experiment could include monolingual annotators for comprehensibility in order to completely eliminate potential in\ufb02uence of knowlegde of the source language .", "entities": []}, {"text": "Acknowledgments This research is being conducted with the \ufb01nancial support of the European Association for Machine Translation ( EAMT ) under its programme \u201c 2019 Sponsorship of Activities \u201d at the ADAPT Research Centre at Dublin City University .", "entities": [[15, 17, "TaskName", "Machine Translation"]]}, {"text": "The ADAPT SFI Centre for Digital Media Technology is funded by Science Foundation Ireland through the SFI Research Centres Programme and is co - funded under the European Regional Development Fund ( ERDF ) through Grant 13 / RC/2106 .", "entities": []}, {"text": "We would like to thank all the evaluators for providing us with annotations and feedback .", "entities": []}, {"text": "References ALPAC .", "entities": []}, {"text": "1966 .", "entities": []}, {"text": "Language and machines .", "entities": []}, {"text": "Computers in translation and linguistics .", "entities": []}, {"text": "Lo\u00a8\u0131c Barrault , Ond \u02c7rej Bojar , Marta R. Costa - juss ` a , Christian Federmann , Mark Fishel , Yvette Graham , Barry Haddow , Matthias Huck , Philipp Koehn , Shervin Malmasi , Christof Monz , Mathias M \u00a8uller , Santanu Pal , Matt Post , and Marcos Zampieri .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Findings of the 2019 conference on machine translation ( WMT19 ) .", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the Fourth Conference on Machine Translation ( Volume 2 : Shared Task Papers , Day 1 ) , pages 1\u201361 , Florence , Italy .", "entities": [[7, 9, "TaskName", "Machine Translation"], [24, 25, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chris Callison - Burch , Cameron Fordyce , Philipp Koehn , Christof Monz , and Josh Schroeder . 2007 .", "entities": []}, {"text": "( meta- ) evaluation of machine translation .", "entities": [[5, 7, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the Second Workshop on Statistical Machine Translation , pages 136\u2013158 , Prague , Czech Republic .", "entities": [[8, 10, "TaskName", "Machine Translation"]]}, {"text": "Sheila Castilho , Joss Moorkens , Federico Gaspari , Iacer Calixto , John Tinsley , and Andy Way .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Is neural machine translation the new state of the art ?", "entities": [[2, 4, "TaskName", "machine translation"]]}, {"text": "The Prague Bulletin of Mathematical Linguistics , 108(1):109 \u2013 120 .", "entities": []}, {"text": "2631 )", "entities": []}, {"text": "A maj(misleading ) source Extremely uncomfortable MT Izuzetno neprijatno AMB gloss Extremely awkward 2 ) A maj(misleading ) source The special effects with the mummy \u2019s ghost MT Specijalni efekti s duhom mame AMB gloss The special effects with the mother \u2019s ghost 3 ) A maj+Cmaj(fully incorrect ) source", "entities": []}, {"text": "Best readily available food coloring MT Najbolje lako AMB obojenje hrane NP gloss Best easy coloring of food 4 ) A maj(misleading ) , A maj+Cmin(potentially misleading ) source they \ufb01t easily under my snow pants and they do n\u2019t show through MT lako se uklapaju AMB ispod mojih sne \u02c7znih pantalona", "entities": []}, {"text": "i ne prolaze WBW kroz njih WBW gloss they concord easily under my snow pants and not they go through them 5 ) A maj(misleading ) , A maj+Cmaj(fully incorrect ) ,", "entities": []}, {"text": "A min+Cmaj(almost correct discarded ) source No matter how much care I used in throwing it MT Bez obzira koliko briga WBW sam koristio WBW u bacanju", "entities": []}, {"text": "WBW gloss", "entities": []}, {"text": "No matter how many cares I used in the throwing Table 4 : Examples of ambiguity errors ( AMB ) , noun phrase errors ( NP ) and word - by - word translations ( WBW ) perceived as comprehensible inadequate ( red ) , almost comprehensible inadequate ( green ) , incomprehensible almost adequate ( cyan ) and incomprehensible inadequate translations ( violet ) .", "entities": []}, {"text": "source For the kind of shipping they want it would be reasonable to expect a better presentation .", "entities": []}, {"text": "MT Za vrstu dostave XXX \u02c7zele da bi bilorazumno o \u02c7cekivati bolju prezentaciju .", "entities": []}, {"text": "gloss For the kind of shipping fwhich gthey want that would be reasonable to expect better presentation .", "entities": []}, {"text": "Table 5 : Example of propagation effect for major comprehensibility issues .", "entities": []}, {"text": "All words in bold are correct , but perceived as incomprehensible due to different types of errors in surrounding words ( presented in colour ) .", "entities": []}, {"text": "Mireia Farr \u00b4 us , Marta Ruiz Costa - Juss ` a , Jos \u00b4 e B. Mario , and Jos \u00b4 e Adri \u00b4 an R. Fonollosa . 2010 .", "entities": []}, {"text": "Linguisticbased evaluation criteria to identify statistical machine translation errors .", "entities": [[6, 8, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 14th Annual Conference of the European Association for Machine Translation ( EAMT 2010 ) , St. Rapha \u00a8el , France .", "entities": [[12, 14, "TaskName", "Machine Translation"]]}, {"text": "Marcello Federico , Matteo Negri , Luisa Bentivogli , and Marco Turchi .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Assessing the impact of translation errors on machine translation quality with mixed - effects models .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Naturalpercentage of omissions perceived : only as comprehensibility issues 19.2 only as adequacy issues 71.5 as both 9.3 Table 6 : Percentage of omissions perceived only as comprehensibility issues , only as adequacy issues , and as both types of issues .", "entities": []}, {"text": "Language Processing ( EMNLP 2014 ) , Doha , Qatar .", "entities": []}, {"text": "Yvette Graham , Timothy Baldwin , Alistair Moffat , and Justin Zobel .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Continuous measurement scales in human evaluation of machine translation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse , pages 33\u201341 , So\ufb01a , Bulgaria .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Katrin Kirchhoff , Daniel Capurro , and Anne M. Turner .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "A conjoint analysis framework for evaluating user preferences in machine translation .", "entities": [[9, 11, "TaskName", "machine translation"]]}, {"text": "Machine Translation , 28(1):117 .", "entities": [[0, 2, "TaskName", "Machine Translation"]]}, {"text": "Filip Klubi \u02c7cka , Antonio Toral , and V \u00b4 \u0131ctor M. S \u00b4 anchezCartagena . 2018 .", "entities": []}, {"text": "Quantitative Fine - grained Human Evaluation of Machine Translation Systems : A Case Study on English to Croatian .", "entities": [[7, 9, "TaskName", "Machine Translation"]]}, {"text": "Machine Translation , 32(3):195\u2013215 .", "entities": [[0, 2, "TaskName", "Machine Translation"]]}, {"text": "264Philipp Koehn and Christof Monz .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Manual and automatic evaluation of machine translation between European languages .", "entities": [[5, 7, "TaskName", "machine translation"]]}, {"text": "In Proceedings on the Workshop on Statistical Machine Translation , pages 102 \u2013 121 , New York City .", "entities": [[7, 9, "TaskName", "Machine Translation"]]}, {"text": "Arle Lommel , Aljoscha Burchardt , Maja Popovi \u00b4 c , Kim Harris , Eleftherios Avramidis , and Hans Uszkoreit .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Using a new analytic measure for the annotation and analysis of MT errors on real data .", "entities": []}, {"text": "In Proceedings of the 17th Annual Conference of the European Association for Machine Translation ( EAMT 2014 ) , pages 165\u2013172 .", "entities": [[12, 14, "TaskName", "Machine Translation"]]}, {"text": "Andrew L. Maas , Raymond E. Daly , Peter T. Pham , Dan Huang , Andrew Y .", "entities": []}, {"text": "Ng , and Christopher Potts . 2011 .", "entities": []}, {"text": "Learning Word Vectors for Sentiment Analysis .", "entities": [[4, 6, "TaskName", "Sentiment Analysis"]]}, {"text": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics and Human Language Technologies ( ACL - HLT 2011 ) , pages 142\u2013150 , Portland , Oregon , USA .", "entities": []}, {"text": "Marianna Martindale and Marine Carpuat .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Fluency over adequacy : A pilot study in measuring user trust in imperfect MT .", "entities": []}, {"text": "In Proceedings of the 13th Conference of the Association for Machine Translation in the Americas ( AMTA 2018 ) , pages 13\u201325 , Boston , MA .", "entities": [[10, 12, "TaskName", "Machine Translation"]]}, {"text": "Marianna Martindale , Marine Carpuat , Kevin Duh , and Paul McNamee .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Identifying \ufb02uently inadequate output in neural and statistical machine translation .", "entities": [[8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of Machine Translation Summit XVII , pages 233\u2013243 , Dublin , Ireland .", "entities": [[3, 5, "TaskName", "Machine Translation"]]}, {"text": "Julian McAuley , Christopher Targett , Qinfeng Shi , and Anton van den Hengel . 2015 .", "entities": []}, {"text": "Image - Based Recommendations on Styles and Substitutes .", "entities": []}, {"text": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval ( SIGIR 2015 ) , pages 43\u201352 , Santiago , Chile .", "entities": [[6, 7, "DatasetName", "ACM"], [14, 16, "TaskName", "Information Retrieval"]]}, {"text": "Maja Popovi \u00b4 c. 2020 .", "entities": []}, {"text": "Informative manual evaluation of machine translation output .", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 28th International Conference on Computational Linguistics ( COLING 2020 ) , Online .", "entities": []}, {"text": "Johann Roturier and Anthony Bensadoun .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Evaluation of MT Systems to Translate User Generated Content .", "entities": []}, {"text": "In Proceedings of the MT Summit XIII , Xiamen , China .", "entities": []}, {"text": "Sara Stymne and Lars Ahrenberg .", "entities": []}, {"text": "2012 .", "entities": []}, {"text": "On the practice of error analysis for machine translation evaluation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the Eighth International Conference on Language Resources and Evaluation ( LREC 2012 ) , pages 1785\u20131790 , Istanbul , Turkey .", "entities": []}, {"text": "Laura Van Brussel , Arda Tezcan , and Lieve Macken .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "A \ufb01ne - grained error analysis of NMT , SMT and RBMT output for English - to - Dutch .", "entities": []}, {"text": "In Proceedings of the Eleventh International Conference on Language Resources and Evaluation ( LREC 2018 ) , Miyazaki , Japan .", "entities": []}, {"text": "David Vilar , Jia Xu , Luis Fernando D\u2019Haro , and Hermann Ney . 2006 .", "entities": []}, {"text": "Error analysis of statistical machine translation output .", "entities": [[0, 1, "MetricName", "Error"], [4, 6, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the Fifth International Conference on Language Resources and Evaluation ( LREC\u201906 ) , Genoa , Italy .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "John White , Theresa O\u2019Connell , and Francis O\u2019Mara . 1994 .", "entities": []}, {"text": "The ARPA MT evaluation methodologies : evolution , lessons , and future approaches .", "entities": []}, {"text": "In Proceedings of the 1994 Conference , Association for Machine Translation in the Americas , pages 193 \u2013 205 .", "entities": [[9, 11, "TaskName", "Machine Translation"]]}]