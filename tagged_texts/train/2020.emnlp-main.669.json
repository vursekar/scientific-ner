[{"text": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 8328\u20138350 , November 16\u201320 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics8328CODEX : A Comprehensive Knowledge Graph Completion Benchmark Tara Safavi University of Michigan tsafavi@umich.eduDanai Koutra University of Michigan dkoutra@umich.edu", "entities": [[8, 11, "TaskName", "Knowledge Graph Completion"]]}, {"text": "Abstract We present C ODEX , a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of dif\ufb01culty .", "entities": [[9, 12, "TaskName", "knowledge graph COmpletion"], [22, 25, "TaskName", "knowledge graph completion"]]}, {"text": "In terms of scope , CODEXcomprises three knowledge graphs varying in size and structure , multilingual descriptions of entities and relations , and tens of thousands of hard negative triples that are plausible but veri\ufb01ed to be false .", "entities": [[7, 9, "TaskName", "knowledge graphs"]]}, {"text": "To characterize C ODEX , we contribute thorough empirical analyses and benchmarking experiments .", "entities": []}, {"text": "First , we analyze each C ODEXdataset in terms of logical relation patterns .", "entities": []}, {"text": "Next , we report baseline link prediction and triple classi\ufb01cation results on C ODEXfor \ufb01ve extensively tuned embedding models .", "entities": [[5, 7, "TaskName", "link prediction"]]}, {"text": "Finally , we differentiate CODEXfrom the popular FB15K-237 knowledge graph completion dataset by showing that CODEXcovers more diverse and interpretable content , and is a more dif\ufb01cult link prediction benchmark .", "entities": [[7, 8, "DatasetName", "FB15K-237"], [8, 11, "TaskName", "knowledge graph completion"], [27, 29, "TaskName", "link prediction"]]}, {"text": "Data , code , and pretrained models are available at https://bit.ly/2EPbrJs .", "entities": []}, {"text": "1 Introduction Knowledge graphs are multi - relational graphs that express facts about the world by connecting entities ( people , places , things , concepts ) via different types of relationships .", "entities": [[2, 4, "TaskName", "Knowledge graphs"]]}, {"text": "The \ufb01eld of automatic knowledge graph completion ( KGC ) , which is motivated by the fact that knowledge graphs are usually incomplete , is an active research direction spanning several sub\ufb01elds of arti\ufb01cial intelligence ( Nickel et al . , 2015 ; Wang et al . , 2017 ;", "entities": [[4, 7, "TaskName", "knowledge graph completion"], [18, 20, "TaskName", "knowledge graphs"]]}, {"text": "Ji et al . , 2020 ) .", "entities": []}, {"text": "As progress in arti\ufb01cial intelligence depends heavily on data , a relevant and high - quality benchmark is imperative to evaluating and advancing the state of the art in KGC .", "entities": []}, {"text": "However , the \ufb01eld has largely remained static in this regard over the past decade .", "entities": []}, {"text": "Outdated subsets of Freebase ( Bollackeret al . , 2008 ) are most commonly used for evaluation in KGC , even though Freebase had known quality issues ( Tanon et al . , 2016 ) and was eventually deprecated in favor of the more recent Wikidata knowledge base ( Vrande \u02c7ci\u00b4c and Kr\u00f6tzsch , 2014 ) .", "entities": []}, {"text": "Indeed , KGC benchmarks extracted from Freebase like FB15 K andFB15 K -237 ( Bordes et al . , 2013 ; Toutanova and Chen , 2015 ) are questionable in quality .", "entities": []}, {"text": "For example , FB15 K was shown to have train / test leakage ( Toutanova and Chen , 2015 ) .", "entities": []}, {"text": "Later in this paper ( \u00a7 6.2 ) , we will show that a relatively large proportion of relations in FB15 K -237 can be covered by a trivial frequency rule .", "entities": []}, {"text": "To address the need for a solid benchmark in KGC , we present CODEX , a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and its sister project Wikipedia .", "entities": [[18, 21, "TaskName", "knowledge graph COmpletion"]]}, {"text": "Inasmuch as Wikidata is considered the successor of Freebase , CODEXimproves upon existing Freebase - based KGC benchmarks in terms of scope and level of dif\ufb01culty ( Table 1 ) .", "entities": []}, {"text": "Our contributions include : Foundations We survey evaluation datasets in encyclopedic knowledge graph completion to motivate a new benchmark ( \u00a7 2 and Appendix A ) .", "entities": [[11, 14, "TaskName", "knowledge graph completion"]]}, {"text": "Data We introduce CODEX , a benchmark consisting of three knowledge graphs varying in size and structure , entity types , multilingual labels and descriptions , and \u2014 unique to CODEX \u2014 manually veri\ufb01ed hard negative triples ( \u00a7 3 ) .", "entities": [[10, 12, "TaskName", "knowledge graphs"]]}, {"text": "To better understand CODEX , we analyze the logical relation patterns in each of its datasets ( \u00a7 4 ) .", "entities": []}, {"text": "Benchmarking We conduct large - scale model selection and benchmarking experiments , reporting baseline link prediction and triple classi\ufb01cation results on CODEXfor \ufb01ve widely used embedding models from different architectural classes ( \u00a7 5 ) .", "entities": [[6, 8, "TaskName", "model selection"], [14, 16, "TaskName", "link prediction"]]}, {"text": "Comparative analysis Finally , to demonstrate the unique value of CODEX , we differentiate", "entities": []}, {"text": "8329Table 1 : Qualitative comparison of C ODEXdatasets to existing Freebase - based KGC datasets ( \u00a7 2.1 ) .", "entities": []}, {"text": "Freebase variants ( FB15 K , FB15K-237 ) CODEXdatasets Scope ( domains ) Multi - domain , with a strong focus on awards , entertainment , and sports ( \u00a7 6.1 and Appendix E)Multi - domain , with focuses on writing , entertainment , music , politics , journalism , academics , and science ( \u00a7 6.1 and Appendix E ) Scope ( auxiliary data )", "entities": [[6, 7, "DatasetName", "FB15K-237"]]}, {"text": "Various decentralized versions of FB15 K with , e.g. , entity types ( Xie et al . , 2016 ) , sampled negatives ( Socher et al . , 2013 ) , and more ( Table 8)Centralized repository of three datasets with entity types , multilingual text , and manually annotated hard negatives ( \u00a7 3 ) Level of dif\ufb01culty FB15 K has severe train / test leakage from inverse relations ( Toutanova and Chen , 2015 ) ; while removal of inverse relations makes FB15 K -237 harder than FB15 K , FB15 K -237 still has a high proportion of easy - to - predict relational patterns ( \u00a7 6.2)Inverse relations removed from all datasets to avoid train / test leakage ( \u00a7 3.2 ) ; manually annotated hard negatives for the task of triple classi\ufb01cation ( \u00a7 3.4 ) ; few trivial patterns for the task of link prediction ( \u00a7 6.2 ) CODEXfrom FB15 K -237 in terms of both content and dif\ufb01culty ( \u00a7 6 ) .", "entities": [[150, 152, "TaskName", "link prediction"]]}, {"text": "We show that CODEXcovers more diverse and interpretable content , and is a more challenging link prediction benchmark .", "entities": [[15, 17, "TaskName", "link prediction"]]}, {"text": "2 Existing datasets We begin by surveying existing KGC benchmarks .", "entities": []}, {"text": "Table 8 in Appendix A provides an overview of evaluation datasets and tasks on a per - paper basis across the arti\ufb01cial intelligence , machine learning , and natural language processing communities .", "entities": []}, {"text": "Note that we focus on data rather than models , so we only overview relevant evaluation benchmarks here .", "entities": []}, {"text": "For more on existing KGC models , both neural and symbolic , we refer the reader to ( Meilicke et al . , 2018 ) and ( Ji et al . , 2020 ) .", "entities": []}, {"text": "2.1 Freebase extracts These datasets , extracted from the Freebase knowledge graph ( Bollacker et al . , 2008 ) , are the most popular for KGC ( see Table 8 in Appendix A ) .", "entities": []}, {"text": "FB15 K was introduced by Bordes et al .", "entities": []}, {"text": "( 2013 ) .", "entities": []}, {"text": "It contains 14,951 entities , 1,345 relations , and 592,213 triples covering several domains , with a strong focus on awards , entertainment , and sports .", "entities": []}, {"text": "FB15K-237 was introduced by Toutanova and Chen ( 2015 ) to remedy data leakage in FB15 K , which contains many test triples that invert triples in the training set .", "entities": [[0, 1, "DatasetName", "FB15K-237"]]}, {"text": "FB15 K -237 contains 14,541 entities , 237 relations , and 310,116 triples .", "entities": []}, {"text": "We compare FB15K-237 to C ODEXin \u00a7 6 to assess each dataset \u2019s content and relative dif\ufb01culty .", "entities": [[2, 3, "DatasetName", "FB15K-237"]]}, {"text": "2.2 Other encyclopedic datasets NELL-995 ( Xiong et al . , 2017 ) was taken from the Never Ending Language Learner ( NELL ) sys - tem ( Mitchell et al . , 2018 ) , which continuously reads the web to obtain and update its knowledge .", "entities": [[4, 5, "DatasetName", "NELL-995"], [22, 23, "DatasetName", "NELL"]]}, {"text": "NELL-995 , a subset of the 995th iteration of NELL , contains 75,492 entities , 200 relations , and 154,213 triples .", "entities": [[0, 1, "DatasetName", "NELL-995"], [9, 10, "DatasetName", "NELL"]]}, {"text": "While NELL-995 is general and covers many domains , its mean average precision was less than 50 % around its 1000th iteration ( Mitchell et al . , 2018 ) .", "entities": [[1, 2, "DatasetName", "NELL-995"], [11, 13, "MetricName", "average precision"]]}, {"text": "A cursory inspection reveals that many of the triples in NELL-995 are nonsensical or overly generic , suggesting that NELL-995 is not a meaningful dataset for KGC evaluation.1 YAGO3 - 10 ( Dettmers et al . , 2018 ) is a subset of YAGO3 ( Mahdisoltani et al . , 2014 ) , which covers portions of Wikipedia , Wikidata , and WordNet .", "entities": [[10, 11, "DatasetName", "NELL-995"], [19, 20, "DatasetName", "NELL-995"], [28, 31, "DatasetName", "YAGO3 - 10"]]}, {"text": "YAGO3 - 10 has 123,182 entities , 37 relations , and 1,089,040 triples mostly limited to facts about people and locations .", "entities": [[0, 3, "DatasetName", "YAGO3 - 10"]]}, {"text": "While YAGO3 - 10 is a highprecision dataset , it was recently shown to be too easy for link prediction because it contains a large proportion of duplicate relations ( Akrami et al . , 2020 ;", "entities": [[1, 4, "DatasetName", "YAGO3 - 10"], [18, 20, "TaskName", "link prediction"]]}, {"text": "Pezeshkpour et al . , 2020 ) .", "entities": []}, {"text": "2.3 Domain - speci\ufb01c datasets In addition to large encyclopedic knowledge graphs , it is common to evaluate KGC methods on at least one smaller , domain - speci\ufb01c dataset , typically drawn from the WordNet semantic network ( Miller , 1998 ; Bordes et al . , 2013 ) .", "entities": [[10, 12, "TaskName", "knowledge graphs"]]}, {"text": "Other choices include the Uni\ufb01ed Medical Language System ( UMLS ) database ( McCray , 2003 ) , the Alyawarra kinship dataset ( Kemp et al . , 2006 ) , theCountries dataset ( Bouchard et al . , 2015 ) , and variants of a synthetic \u201c family tree \u201d ( Hinton , 1986 ) .", "entities": [[9, 10, "DatasetName", "UMLS"]]}, {"text": "As our focus in this paper is encyclopedic knowledge , we do not cover these datasets further .", "entities": []}, {"text": "1Some examples : ( politician : jobs , worksfor , county : god ) , ( person : buddha001 , parentofperson , person : jesus )", "entities": []}, {"text": "8330Table 2 : C ODEXdatasets .", "entities": []}, {"text": "( + ): Positive ( true ) triples .", "entities": []}, {"text": "( - ): Veri\ufb01ed negative ( false ) triples ( \u00a7 3.4 ) .", "entities": []}, {"text": "We compute multilingual coverage over all labels , descriptions , and entity Wikipedia extracts successfully retrieved for the respective dataset in Arabic ( ar ) , German ( de ) , English ( en ) , Spanish ( es ) , Russian ( ru ) , and Chinese ( zh ) .", "entities": []}, {"text": "jEj jRjTriples E\u0002R\u0002E Multilingual coverage Train ( + ) Valid ( + ) Test ( + ) Valid ( - ) Test ( - ) ar de en es ru zh CODEX - S 2,034 42 32,888 1827 1828 1827 1828 77.38 91.87 96.38 91.55 89.17 79.36 CODEX - M 17,050 51 185,584 10,310 10,311 10,310 10,311 75.80 95.20 96.95 87.91 81.88 69.63 CODEX - L 77,951 69 551,193 30,622 30,622 - - 67.47 90.84 92.40 81.30 71.12 61.06 3 Data collection In this section we describe the pipeline used to construct CODEX .", "entities": []}, {"text": "For reference , we de\ufb01ne a knowledge graph Gas a multi - relational graph consisting of a set of entities E , relations R , and factual statements in the form of ( head , relation , tail ) triples ( h ; r ; t ) 2E\u0002R\u0002E. 3.1 Seeding the collection We collected an initial set of triples using a type of snowball sampling ( Goodman , 1961 ) .", "entities": []}, {"text": "We \ufb01rst manually de\ufb01ned a broad seed set of entity and relation types common to 13 domains : Business , geography , literature , media and entertainment , medicine , music , news , politics , religion , science , sports , travel , and visual art .", "entities": []}, {"text": "Examples of seed entity types include airline , journalist , and religious text ; corresponding seed relation types in each respective domain include airline alliance , notable works , and language of work or name .", "entities": []}, {"text": "Table 9 in Appendix B gives all seed entity and relation types .", "entities": []}, {"text": "Using these seeds , we retrieved an initial set of 380,038 entities , 75 relations , and 1,156,222 triples by querying Wikidata for statements of the form ( head entity of seed type , seed relation type , ? ) .", "entities": [[2, 3, "DatasetName", "seeds"]]}, {"text": "3.2 Filtering the collection To create smaller data snapshots , we \ufb01ltered the initial 1.15 million triples to k - cores , which are maximal subgraphs G0of a given graph Gsuch that every node in G0has a degree of at least k(Batagelj and Zaver\u0161nik , 2011).2We constructed three C ODEXdatasets ( Table 2 ): \u000fCODEX - S(k= 15 ) , which has 36k triples .", "entities": []}, {"text": "Because of its smaller size , we recommend thatCODEX - Sbe used for model testing and debugging , as well as evaluation of methods that are less computationally ef\ufb01cient ( e.g. , symbolic search - based approaches ) .", "entities": []}, {"text": "2A similar approach was used to extract the FB15 K dataset from Freebase ( Bordes et al . , 2013).\u000fCODEX - M(k= 10 ) , which has 206k triples .", "entities": []}, {"text": "CODEX - Mis all - purpose , being comparable in size to FB15 K -237 ( \u00a7 2.1 ) , one of the most popular benchmarks for KGC evaluation .", "entities": []}, {"text": "\u000fCODEX - L(k= 5 ) , which has 612k triples .", "entities": []}, {"text": "CODEX - Lis comparable in size to FB15 K ( \u00a7 2.1 ) , and can be used for both general evaluation and \u201c few - shot \u201d evaluation .", "entities": []}, {"text": "We also release the raw dump that we collected via snowball sampling , but focus on CODEX - S through L for the remainder of this paper .", "entities": []}, {"text": "To minimize train / test leakage , we removed inverse relations from each dataset ( Toutanova and Chen , 2015 ) .", "entities": []}, {"text": "We computed ( head , tail ) and ( tail , head ) overlap between all pairs of relations , and removed each relation whose entity pair set overlapped with that of another relation more than 50%of the time .", "entities": []}, {"text": "Finally , we split each dataset into 90/5/5 train / validation / test triples such that the validation and test sets contained only entities and relations seen in the respective training sets .", "entities": []}, {"text": "3.3 Auxiliary information An advantage of Wikidata is that it links entities and relations to various sources of rich auxiliary information .", "entities": []}, {"text": "To enable tasks that involve joint learning over knowledge graph structure and such additional information , we collected : \u000fEntity types for each entity as given by Wikidata \u2019s instance of andsubclass of relations ; \u000fWikidata labels and descriptions for entities , relations , and entity types ; and \u000fWikipedia page extracts ( introduction sections ) for entities and entity types .", "entities": []}, {"text": "For the latter two , we collected text where available in Arabic , German , English , Spanish , Russian , and Chinese .", "entities": []}, {"text": "We chose these languages because they are all relatively well - represented on Wikidata ( Kaffee et al . , 2017 ) .", "entities": []}, {"text": "Table 2 provides the coverage by language for each C ODEXdataset .", "entities": []}, {"text": "8331Table 3 : Selected examples of hard negatives in C ODEXwith explanations .", "entities": []}, {"text": "Negative Explanation ( Fr\u00e9d\u00e9ric Chopin , occupation , conductor )", "entities": []}, {"text": "Chopin was a pianist and a composer , not a conductor .", "entities": []}, {"text": "( Lesotho , of\ufb01cial language , American English ) English , not American English , is an of\ufb01cial language of Lesotho .", "entities": []}, {"text": "( Senegal , part of , Middle East )", "entities": []}, {"text": "Senegal is part of West Africa .", "entities": []}, {"text": "( Simone de Beauvoir , \ufb01eld of work , astronomy )", "entities": []}, {"text": "Simone de Beauvoir \u2019s \ufb01eld of work was primarily philosophy .", "entities": []}, {"text": "( Vatican City , member of , UNESCO )", "entities": []}, {"text": "Vatican City is a UNESCO World Heritage Site but not a member state .", "entities": []}, {"text": "3.4 Hard negatives for evaluation Knowledge graphs are unique in that they only contain positive statements , meaning that triples not observed in a given knowledge graph are not necessarily false , but merely unseen ; this is called the Open World Assumption ( Gal\u00e1rraga et al . , 2013 ) .", "entities": [[5, 7, "TaskName", "Knowledge graphs"]]}, {"text": "However , most machine learning tasks on knowledge graphs require negatives in some capacity .", "entities": [[7, 9, "TaskName", "knowledge graphs"]]}, {"text": "While different negative sampling strategies exist ( Cai and Wang , 2018 ) , the most common approach is to randomly perturb observed triples to generate negatives , following Bordes et al .", "entities": []}, {"text": "( 2013 ) .", "entities": []}, {"text": "While random negative sampling is bene\ufb01cial and even necessary in the case where a large number of negatives is needed ( i.e. , training ) , it is not necessarily useful for evaluation .", "entities": []}, {"text": "For example , in the task of triple classi\ufb01cation , the goal is to discriminate between positive ( true ) and negative ( false ) triples .", "entities": []}, {"text": "As we show in \u00a7 5.5 , triple classi\ufb01cation over randomly generated negatives is trivially easy for state - of - the - art models because random negatives are generally not meaningful or plausible .", "entities": []}, {"text": "Therefore , we generate and manually evaluate hard negatives for KGC evaluation .", "entities": []}, {"text": "Generation To generate hard negatives , we used each pre - trained embedding model from \u00a7 5.2 to predict tail entities of triples in CODEX .", "entities": []}, {"text": "For each model , we took as candidate negatives the triples ( h ; r;^t)for which ( i ) the type of the predicted tail entity ^tmatched the type of the true tail entity t ; ( ii)^twas ranked in the top-10 predictions by that model ; and ( iii ) ( h ; r;^t)was not observed in G. Annotation We manually labeled all candidate negative triples generated for CODEX - Sand CODEX - Mastrue orfalse using the guidelines provided in Appendix C.3We randomly selected among the triples labeled as false to create validation and test negatives for C ODEX - S and CODEX - M , examples of which are given in Ta3We are currently investigating methods for obtaining highquality crowdsourced annotations of negatives for CODEX-L.ble 3 .", "entities": []}, {"text": "To assess the quality of our annotations , we gathered judgments from two independent native English speakers on a random selection of 100 candidate negatives .", "entities": []}, {"text": "The annotators were provided the instructions from Appendix C. On average , our labels agreed with those of the annotators 89.5 % of the time .", "entities": []}, {"text": "Among the disagreements , 81 % of the time we assigned the label truewhereas the annotator assigned the label false , meaning that we were comparatively conservative in labeling negatives .", "entities": []}, {"text": "4 Analysis of relation patterns To give an idea of the types of reasoning necessary for models to perform well on CODEX , we analyze the presence of learnable binary relation patterns within CODEX .", "entities": []}, {"text": "The three main types of such patterns in knowledge graphs are symmetry , inversion , and compositionality ( Trouillon et", "entities": [[8, 10, "TaskName", "knowledge graphs"]]}, {"text": "al . , 2019 ; Sun et al . , 2019 ) .", "entities": []}, {"text": "We address symmetry and compositionality here , and omit inversion because we speci\ufb01cally removed inverse relations to avoid train / test leakage ( \u00a7 3.2 ) .", "entities": []}, {"text": "4.1 Symmetry Symmetric relations are relations rfor which ( h ; r ; t ) 2Gimplies ( t ; r ; h ) 2G.", "entities": []}, {"text": "For each relation , we compute the number of its ( head , tail ) pairs that overlap with its ( tail , head ) pairs , divided by the total number of pairs , and take those with 50 % overlap or higher as symmetric .", "entities": []}, {"text": "CODEXdatasets have \ufb01ve such relations : diplomatic relation , shares border with , sibling , spouse , and unmarried partner .", "entities": []}, {"text": "Table 4 gives the proportion of triples containing symmetric relations per dataset .", "entities": []}, {"text": "Symmetric patterns are more prevalent in CODEX - S , whereas the larger datasets are mostly antisymmetric , i.e. , ( h ; r ; t ) 2Gimplies ( t ; r ; h ) 62G. 4.2 Composition Compositionality captures path rules of the form ( h ; r 1 ; x1 ) ; : : : ; ( xn ; rn ; t)!(h ; r ; t ) .", "entities": []}, {"text": "To learn these rules , models must be capable of \u201c multi - hop \u201d reasoning on knowledge graphs ( Guu et al . , 2015 ) .", "entities": [[17, 19, "TaskName", "knowledge graphs"]]}, {"text": "8332Table 4 : Relation patterns in C ODEX .", "entities": []}, {"text": "For symmetry , we give the proportion of triples containing a symmetric relation .", "entities": []}, {"text": "For composition , we give the proportion of triples participating in a rule of length two or three .", "entities": []}, {"text": "CODEX - S C ODEX - M C ODEX - L Symmetry 17.46 % 4.01 % 3.29 % Composition 10.09 % 16.55 % 31.84 % To identify compositional paths , we use the AMIE3 system ( Lajus et al . , 2020 ) , which outputs rules with con\ufb01dence scores that capture how many times those rules are seen versus violated , to identify paths of lengths two and three ; we omit longer paths as they are relatively costly to compute .", "entities": []}, {"text": "We identify 26 , 44 , and 93 rules in CODEX - S , CODEX - M , and CODEX - L , respectively , with average con\ufb01dence ( out of 1 ) of 0.630 , 0.556 , and 0.459 .", "entities": []}, {"text": "Table 4 gives the percentage of triples per dataset participating in a discovered rule .", "entities": []}, {"text": "Evidently , composition is especially prevalent in CODEX - L. An example rule in CODEX - Lis \u201c if Xwas founded by Y , and Y \u2019s country of citizenship is Z ,", "entities": []}, {"text": "then the country [ i.e. , of origin ] of Xis Z \u201d ( con\ufb01dence 0.709 ) .", "entities": []}, {"text": "We release these rules as part of CODEXfor further development of KGC methodologies that incorporate or learn rules .", "entities": []}, {"text": "5", "entities": []}, {"text": "Benchmarking Next , we benchmark performance on CODEXfor the tasks of link prediction and triple classi\ufb01cation .", "entities": [[11, 13, "TaskName", "link prediction"]]}, {"text": "To ensure that models are fairly and accurately compared , we follow Ruf\ufb01nelli et al .", "entities": []}, {"text": "( 2020 ) , who conducted what is ( to the best of our knowledge ) the largest - scale hyperparameter tuning study of knowledge graph embeddings to date .", "entities": [[24, 27, "TaskName", "knowledge graph embeddings"]]}, {"text": "Note that CODEXcan be used to evaluate any type of KGC method .", "entities": []}, {"text": "However , we focus on embeddings in this section due to their widespread usage in modern NLP ( Ji et al . , 2020 ) .", "entities": []}, {"text": "5.1 Tasks Link prediction The link prediction task is conducted as follows : Given a test triple ( h ; r ; t ) , we construct queries ( ? ; r ; t)and(h ; r ; ? ) .", "entities": [[2, 4, "TaskName", "Link prediction"], [5, 7, "TaskName", "link prediction"]]}, {"text": "For each query , a model scores candidate head ( tail ) entities ^h(^t ) according to its belief that ^h(^t ) completes the triple ( i.e. , answers the query ) .", "entities": []}, {"text": "The goal is of link prediction is to rank true triples ( ^h ; r ; t ) or(h ; r;^t ) higher than false and unseen triples .", "entities": [[4, 6, "TaskName", "link prediction"]]}, {"text": "Link prediction performance is evaluated withmean reciprocal rank ( MRR ) and hits@ k. MRR is the average reciprocal of each ground - truth entity \u2019s rank over all ( ? ; r ; t)and(h ; r;?)test triples .", "entities": [[0, 2, "TaskName", "Link prediction"], [9, 10, "MetricName", "MRR"], [14, 15, "MetricName", "MRR"]]}, {"text": "Hits@ kmeasures the proportion of test triples for which the ground - truth entity is ranked in the top - kpredicted entities .", "entities": []}, {"text": "In computing these metrics , we exclude the predicted entities for which ( ^h ; r ; t ) 2Gor(h ; r;^t)2Gso that known positive triples do not arti\ufb01cially lower ranking scores .", "entities": []}, {"text": "This is called \u201c \ufb01ltering \u201d ( Bordes et al . , 2013 ) .", "entities": []}, {"text": "Triple classi\ufb01cation Given a triple ( h ; r ; t ) , the goal of triple classi\ufb01cation is to predict a corresponding label y2 f\u0000 1;1 g. Since knowledge graph embedding models output real - valued scores for triples , we convert these scores into labels by selecting a decision threshold per relation on the validation set such that validation accuracy is maximized for the model in question .", "entities": [[29, 32, "TaskName", "knowledge graph embedding"], [61, 62, "MetricName", "accuracy"]]}, {"text": "A similar approach was used by Socher et al .", "entities": []}, {"text": "( 2013 ) .", "entities": []}, {"text": "We compare results on three sets of evaluation negatives : ( 1 ) We generate one negative per positive by replacing the positive triple \u2019s tail entity by a tail entity t0sampled uniformly at random ; ( 2 ) We generate negatives by sampling tail entities according to their relative frequency in the tail slotof all triples ; and ( 3 ) We use the CODEXhard negatives .", "entities": []}, {"text": "We measure accuracy andF1 score .", "entities": [[2, 3, "MetricName", "accuracy"]]}, {"text": "5.2 Models We compare the following embedding methods : RESCAL ( Nickel et al . , 2011 ) , TransE ( Bordes et al . , 2013 ) , ComplEx ( Trouillon et al . , 2016 ) , ConvE ( Dettmers et al . , 2018 ) , and TuckER ( Balazevic et al . , 2019b ) .", "entities": [[9, 10, "MethodName", "RESCAL"], [19, 20, "MethodName", "TransE"], [50, 51, "MethodName", "TuckER"]]}, {"text": "These models represent several classes of architecture , from linear ( RESCAL , TuckER , ComplEx ) to translational ( TransE ) to nonlinear / learned ( ConvE ) .", "entities": [[11, 12, "MethodName", "RESCAL"], [13, 14, "MethodName", "TuckER"], [20, 21, "MethodName", "TransE"]]}, {"text": "Appendix D provides more speci\ufb01cs on each model .", "entities": []}, {"text": "5.3 Model selection As recent studies have observed that training strategies are equally , if not more , important than architecture for link prediction ( Kadlec et al . , 2017 ; Lacroix et al . , 2018 ; Ruf\ufb01nelli et al . , 2020 ) , we search across a large range of hyperparameters to ensure a truly fair comparison .", "entities": [[1, 3, "TaskName", "Model selection"], [22, 24, "TaskName", "link prediction"]]}, {"text": "To this end we use the PyTorch - based LibKGE framework for training and selecting knowledge graph embeddings.4In the remainder of this section we outline the most important parameters of our model selection process .", "entities": [[31, 33, "TaskName", "model selection"]]}, {"text": "4https://github.com/uma-pi1/kge", "entities": []}, {"text": "8333Table 5 : Comparison of link prediction performance on C ODEX .", "entities": [[5, 7, "TaskName", "link prediction"]]}, {"text": "CODEX - S C ODEX - M C ODEX - L MRR Hits@1", "entities": [[11, 12, "MetricName", "MRR"], [12, 13, "MetricName", "Hits@1"]]}, {"text": "Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 RESCAL 0.404 0.293 0.623 0.317 0.244 0.456 0.304 0.242 0.419 TransE 0.354 0.219 0.634 0.303 0.223 0.454 0.187 0.116 0.317 ComplEx 0.465 0.372 0.646 0.337 0.262 0.476 0.294 0.237 0.400 ConvE 0.444 0.343 0.635 0.318 0.239 0.464 0.303 0.240 0.420 TuckER 0.444 0.339 0.638 0.328 0.259 0.458 0.309 0.244 0.430 Table 10 in Appendix F gives further details and all hyperparameter ranges and values .", "entities": [[0, 1, "MetricName", "Hits@10"], [1, 2, "MetricName", "MRR"], [2, 3, "MetricName", "Hits@1"], [3, 4, "MetricName", "Hits@10"], [4, 5, "MetricName", "MRR"], [5, 6, "MetricName", "Hits@1"], [6, 7, "MetricName", "Hits@10"], [7, 8, "MethodName", "RESCAL"], [17, 18, "MethodName", "TransE"], [47, 48, "MethodName", "TuckER"]]}, {"text": "All experiments were run on a single NVIDIA Tesla V100 GPU with 16 GB of RAM .", "entities": [[15, 16, "MethodName", "RAM"]]}, {"text": "Training negatives Given a set of positive training triplesf(h ; r ; t ) g , we compare three types of negative sampling strategy implemented by LibKGE : ( a ) NegSamp , or randomly corrupting head entities hor tail entities tto create negatives ; ( b)1vsAll , or treating allpossible head / tail corruptions of ( h ; r ; t ) as negatives , including the corruptions that are actually positives ; and ( c ) KvsAll , or treating batches of head / tail corruptions notseen in the knowledge graph as negatives .", "entities": []}, {"text": "Loss functions We consider the following loss functions : ( i ) MR or margin ranking , which aims to maximize a margin between positive and negative triples ; ( ii ) BCE or binary cross - entropy , which is computed by applying the logistic sigmoid to triple scores ; and ( iii ) CEor cross - entropy between the softmax over the entire distribution of triple scores and the label distribution over all triples , normalized to sum to one .", "entities": [[6, 7, "MetricName", "loss"], [12, 13, "DatasetName", "MR"], [61, 62, "MethodName", "softmax"]]}, {"text": "Search strategies We select models using the Ax platform , which supports hyperparameter search using both quasi - random sequences of generated con\ufb01gurations and Bayesian optimization ( BO ) with Gaussian processes.5At a high level , for each dataset and model , we generate both quasirandom and BO trials per negative sampling and loss function combination , ensuring that we search over a wide range of hyperparameters for different types of training strategy .", "entities": [[53, 54, "MetricName", "loss"]]}, {"text": "Appendix F provides speci\ufb01c details on the search strategy for each dataset , which was determined according to resource constraints and observed performance patterns .", "entities": []}, {"text": "5https://ax.dev/ Figure 1 : Distribution of validation MRR , C ODEX - M. 5.4 Link prediction results Table 5 gives link prediction results .", "entities": [[7, 8, "MetricName", "MRR"], [14, 16, "TaskName", "Link prediction"], [20, 22, "TaskName", "link prediction"]]}, {"text": "We \ufb01nd that ComplEx is the best at modeling symmetry and antisymmetry , and indeed it was designed speci\ufb01cally to improve upon bilinear models that do not capture symmetry , like DistMult ( Trouillon et al . , 2016 ) .", "entities": []}, {"text": "As such , it performs the best on CODEX - S , which has the highest proportion of symmetric relations .", "entities": []}, {"text": "For example , on the most frequent symmetric relation ( diplomatic relation ) , ComplEx achieves 0.859 MRR , compared to 0.793 for ConvE , 0.490 for RESCAL , and 0.281 for TransE.", "entities": [[17, 18, "MetricName", "MRR"], [27, 28, "MethodName", "RESCAL"]]}, {"text": "By contrast , TuckER is strongest at modeling compositional relations , so it performs best on CODEX - L , which has a high degree of compositionality .", "entities": [[3, 4, "MethodName", "TuckER"]]}, {"text": "For example , on the most frequent compositional relation in CODEX - L(languages spoken , written , or signed ) , TuckER achieves 0.465 MRR , compared to 0.464 for RESCAL , 0.463 for ConvE , 0.456 for ComplEx , and 0.385 for TransE.", "entities": [[21, 22, "MethodName", "TuckER"], [24, 25, "MetricName", "MRR"], [30, 31, "MethodName", "RESCAL"]]}, {"text": "By contrast , since CODEX - Mis mostly asymmetric and non - compositional , ComplEx performs best because of its ability to model asymmetry .", "entities": []}, {"text": "Effect of hyperparameters As shown by Figure 1 , hyperparameters have a strong impact on link prediction performance : Validation MRR for all models varies by over 30 percentage points depending on the training strategy and input con\ufb01guration .", "entities": [[15, 17, "TaskName", "link prediction"], [20, 21, "MetricName", "MRR"]]}, {"text": "This \ufb01nding is consistent with previous observations in the literature ( Kadlec et al . , 2017 ; Ruf\ufb01nelli et al . , 2020 ) .", "entities": []}, {"text": "Appendix F provides the best con\ufb01gurations for each model .", "entities": []}, {"text": "8334Table 6 : Comparison of triple classi\ufb01cation performance on C ODEXby negative generation strategy .", "entities": []}, {"text": "CODEX - S C ODEX - M Uniform Relative freq .", "entities": []}, {"text": "Hard neg .", "entities": []}, {"text": "Uniform Relative freq .", "entities": []}, {"text": "Hard neg .", "entities": []}, {"text": "Acc . F1 Acc . F1 Acc . F1 Acc . F1 Acc . F1 Acc .", "entities": [[0, 1, "MetricName", "Acc"], [2, 3, "MetricName", "F1"], [3, 4, "MetricName", "Acc"], [5, 6, "MetricName", "F1"], [6, 7, "MetricName", "Acc"], [8, 9, "MetricName", "F1"], [9, 10, "MetricName", "Acc"], [11, 12, "MetricName", "F1"], [12, 13, "MetricName", "Acc"], [14, 15, "MetricName", "F1"], [15, 16, "MetricName", "Acc"]]}, {"text": "F1 RESCAL", "entities": [[0, 1, "MetricName", "F1"], [1, 2, "MethodName", "RESCAL"]]}, {"text": "0.972 0.972 0.916 0.920 0.843 0.852 0.977 0.976 0.921 0.922 0.818 0.815", "entities": []}, {"text": "TransE 0.974 0.974", "entities": [[0, 1, "MethodName", "TransE"]]}, {"text": "0.919 0.923 0.829 0.837 0.986 0.986 0.932 0.933 0.797 0.803 ComplEx 0.975 0.975 0.927 0.930 0.836 0.846 0.984 0.984 0.930 0.933 0.824 0.818 ConvE 0.972 0.972 0.921 0.924 0.841 0.846 0.979 0.979 0.934 0.935 0.826 0.829 TuckER", "entities": [[36, 37, "MethodName", "TuckER"]]}, {"text": "0.973 0.973 0.917 0.920 0.840 0.846 0.977 0.977 0.920 0.922 0.823 0.816 Overall , we \ufb01nd that the choice of loss function in particular signi\ufb01cantly impacts model performance .", "entities": [[20, 21, "MetricName", "loss"]]}, {"text": "Each model consistently achieved its respective peak performance with cross - entropy ( CE ) loss , a \ufb01nding which is corroborated by several other KGC comparison papers ( Kadlec et al . , 2017 ; Ruf\ufb01nelli et al . , 2020 ; Jain et al . , 2020 ) .", "entities": [[15, 16, "MetricName", "loss"]]}, {"text": "As far as negative sampling techniques , we do not \ufb01nd that a single strategy is dominant , suggesting that the choice of loss function is more important .", "entities": [[23, 24, "MetricName", "loss"]]}, {"text": "5.5 Triple classi\ufb01cation results Table 6 gives triple classi\ufb01cation results .", "entities": []}, {"text": "Evidently , triple classi\ufb01cation on randomly generated negatives is a nearly - solved task .", "entities": []}, {"text": "On negatives generated uniformly at random , performance scores are nearly identical at almost 100 % accuracy .", "entities": [[16, 17, "MetricName", "accuracy"]]}, {"text": "Even with a negative sampling strategy \u201c smarter \u201d than uniform random , all models perform well .", "entities": []}, {"text": "Hard negatives Classi\ufb01cation performance degenerates considerably on our hard negatives , around 8 to 11 percentage points from relative frequency - based sampling and 13 to 19 percentage points from uniformly random sampling .", "entities": []}, {"text": "Relative performance also varies :", "entities": []}, {"text": "In contrast to our link prediction task in which ComplEx and TuckER were by far the strongest models , RESCAL is slightly stronger on the CODEX - Shard negatives , whereas ConvE performs best on the CODEX - Mhard negatives .", "entities": [[4, 6, "TaskName", "link prediction"], [11, 12, "MethodName", "TuckER"], [19, 20, "MethodName", "RESCAL"]]}, {"text": "These results indicate that triple classi\ufb01cation is indeed a distinct task that requires different architectures and , in many cases , different training strategies ( Appendix F ) .", "entities": []}, {"text": "We believe that few recent works use triple classi\ufb01cation as an evaluation task because of the lack of true hard negatives in existing benchmarks .", "entities": []}, {"text": "Early works reported high triple classi\ufb01cation accuracy on sampled negatives ( Socher et al . , 2013 ; Wang et al . , 2014 ) , perhaps leading the community to believe that the task was nearly solved .", "entities": [[6, 7, "MetricName", "accuracy"]]}, {"text": "However , our results demonstrate that the task is far from solvedwhen the negatives are plausible but truly false .", "entities": []}, {"text": "6 Comparative case study Finally , we conduct a comparative analysis between CODEX - Mand FB15 K -237 ( \u00a7 2.1 ) to demonstrate the unique value of CODEX .", "entities": []}, {"text": "We choose FB15 K -237 because it is the most popular encyclopedic KGC benchmark after FB15 K , which was already shown to be an easy dataset by Toutanova and Chen ( 2015 ) .", "entities": []}, {"text": "We choose CODEX - Mbecause it is the closest in size to FB15K-237 .", "entities": [[12, 13, "DatasetName", "FB15K-237"]]}, {"text": "6.1 Content We \ufb01rst compare the content in CODEX - M , which is extracted from Wikidata , with that of FB15 K 237 , which is extracted from Freebase .", "entities": []}, {"text": "For brevity , Figure 2 compares the top-15 relations by mention count in the two datasets .", "entities": []}, {"text": "Appendix E provides more content comparisons .", "entities": []}, {"text": "Diversity The most common relation in CODEXMisoccupation , which is because most people on Wikidata have multiple occupations listed .", "entities": []}, {"text": "By contrast , the frequent relations in FB15 K -237 are mostly related to awards and \ufb01lm .", "entities": []}, {"text": "In fact , over 25 % of all triples in FB15 K -237 belong to the /award relation domain , suggesting that C ODEXcovers a more diverse selection of content .", "entities": []}, {"text": "Interpretability The Freebase - style relations are also arguably less interpretable than those in Wikidata .", "entities": []}, {"text": "Whereas Wikidata relations have concise natural language labels , the Freebase relation labels are hierarchical , often at \ufb01ve or six levels of hierarchy ( Figure 2 ) .", "entities": []}, {"text": "Moreover , all relations in Wikidata are binary , whereas some Freebase relations aren - nary ( Tanon et al . , 2016 ) , meaning that they connect more than two entities .", "entities": []}, {"text": "The relations containing a dot ( \u201c . \u201d ) are such n - nary relations , and are dif\ufb01cult to reason about without understanding the structure of Freebase , which has been deprecated .", "entities": []}, {"text": "8335 Figure 2 : Top-15 most frequent relations in C ODEX - M and FB15K-237 .", "entities": [[14, 15, "DatasetName", "FB15K-237"]]}, {"text": "We further discuss the impact of such n - nary relations for link prediction in the following section .", "entities": [[12, 14, "TaskName", "link prediction"]]}, {"text": "6.2 Dif\ufb01culty Next , we compare the datasets in a link prediction task to show that C ODEX - M is more dif\ufb01cult .", "entities": [[10, 12, "TaskName", "link prediction"]]}, {"text": "Baseline We devise a \u201c non - learning \u201d link prediction baseline .", "entities": [[9, 11, "TaskName", "link prediction"]]}, {"text": "Let ( h ; r;?)be a test query .", "entities": []}, {"text": "Our baseline scores candidate tail entities by their relative frequency in the tail slot of all training triples mentioning r , \ufb01ltering out tail entities tfor which ( h ; r ; t ) is already observed in the training set .", "entities": []}, {"text": "If all tail entities tare \ufb01ltered out , we score entities by frequency before \ufb01ltering .", "entities": []}, {"text": "The logic of our approach works in reverse for ( ? ; r ; t)queries .", "entities": []}, {"text": "In evaluating our baseline , we follow LibKGE \u2019s protocol for breaking ties in ranking ( i.e. , for entities that appear with equal frequency ) by taking the mean rank of all entities with the same score .", "entities": []}, {"text": "Setup We compare our baseline to the best pretrained embedding model per dataset : RESCAL for FB15 K -237 , which was released by Ruf\ufb01nelli et al .", "entities": [[14, 15, "MethodName", "RESCAL"]]}, {"text": "( 2020 ) , and ComplEx for CODEX - M. We evaluate performance with MRR and Hits@10 .", "entities": [[14, 15, "MetricName", "MRR"], [16, 17, "MetricName", "Hits@10"]]}, {"text": "Beyond overall performance , we also compute per - relation improvement of the respective embedding over our baseline in terms of percentage points MRR .", "entities": [[23, 24, "MetricName", "MRR"]]}, {"text": "This measures the amount of learning beyond frequency statistics necessary for each relation .", "entities": []}, {"text": "Results and discussion Table 7 compares the overall performance of our baseline versus the best embedding per dataset , and Figure 3 shows the improvement of the respective embedding over our baseline per relation type on each dataset .", "entities": []}, {"text": "The improvement of the embedding is much smaller on FB15 K -237 than CODEX - M , and in fact our baseline performs on par with or even outperforms theTable 7 : Overall performance ( MRR ) of our frequency baseline versus the best embedding nodel per benchmark .", "entities": [[35, 36, "MetricName", "MRR"]]}, {"text": "\u201c Improvement \u201d refers to the improvement of the embedding over the baseline .", "entities": []}, {"text": "Baseline Embedding Improvement FB15K-237 0.236 0.356 +0.120 CODEX - M 0.135 0.337 +0.202 Figure 3 : Improvement in MRR of the embedding over our frequency baseline per relation type .", "entities": [[3, 4, "DatasetName", "FB15K-237"], [18, 19, "MetricName", "MRR"]]}, {"text": "Negative means that our baseline outperforms the embedding .", "entities": []}, {"text": "The medians are 8.27 and 20.04 percentage points on FB15K-237 and C ODEX - M , respectively .", "entities": [[9, 10, "DatasetName", "FB15K-237"]]}, {"text": "embedding on FB15 K -237 for some relation types .", "entities": []}, {"text": "To further explore these cases , Figure 4 gives the empirical cumulative distribution function of improvement , which shows the percentage of test triples for which the level of improvement is less than or equal to a given value on each dataset .", "entities": []}, {"text": "Surprisingly , the improvement for both MRR and Hits@10 is less than \ufb01ve percentage points for nearly 40 % ofFB15 K -237 \u2019s test set , and is zero or negative 15%of the time .", "entities": [[6, 7, "MetricName", "MRR"], [8, 9, "MetricName", "Hits@10"]]}, {"text": "By contrast , our baseline is signi\ufb01cantly weaker than the strongest embedding method on C ODEX - M.", "entities": []}, {"text": "The disparity in improvement is due to two relation patterns prevalent in FB15K-237 :", "entities": [[12, 13, "DatasetName", "FB15K-237"]]}, {"text": "8336 Figure 4 : Empirical CDF of improvement of the best embedding over our frequency baseline .", "entities": []}, {"text": "\u000fSkewed relations FB15 K -237 contains many relations that are skewed toward a single head or tail entity .", "entities": []}, {"text": "For example , our baseline achieves perfect performance over all ( h ; r ; ? ) queries for the /common / topic / webpage .", "entities": []}, {"text": "/common / webpage / category relation because this relation has only oneunique tail entity .", "entities": []}, {"text": "Another example of a highly skewed relation inFB15 K -237 is /people / person / gender , for which 78.41 % of tails are the entity male .", "entities": []}, {"text": "In fact , 11 relations in FB15 K -237 have only one unique tail entity , accounting for 3.22 % of all tail queries in FB15 K -237 .", "entities": []}, {"text": "Overall , 15.98 % of test triples in FB15 K -237 contain relations that are skewed 50 % or more toward a single head or tail entity , whereas only 1.26 % of test triples in CODEX - Mcontain such skewed relations .", "entities": []}, {"text": "\u000fFixed - set relations Around 12.7 % of test queries in FB15 K -237 contain relation types that connect entities to \ufb01xed sets of values .", "entities": []}, {"text": "As an example , each head entity that participates in the FB15 K -237 relation /travel / travel_destination / climate./travel/ travel_destination_monthly_climate / month is connected to the same 12 tails ( months of the year ) throughout train , validation , and test .", "entities": []}, {"text": "This makes prediction trivial with our baseline : By \ufb01ltering out the tail entities already seen in train , only a few ( or even one ) candidate tail(s ) are left in test , and the answer is guaranteed to be within these candidates .", "entities": []}, {"text": "These relations only occur in FB15 K -237 because of the way the dataset was constructed from Freebase .", "entities": []}, {"text": "Speci\ufb01cally , Freebase used a special type of entity called Compound Value Type ( CVT ) as an intermediary node connecting n - ary relations .", "entities": [[14, 15, "MethodName", "CVT"]]}, {"text": "Binary relations were created by traversing through CVTs , yielding some relations that connect entities to \ufb01xed sets of values .", "entities": []}, {"text": "We conclude that while FB15 K -237 is a valuable dataset , CODEXis more appropriately dif\ufb01cult for link prediction .", "entities": [[17, 19, "TaskName", "link prediction"]]}, {"text": "Additionally , we note that in FB15 K -237 , all validation and test triples containing entity pairs directly linked in the training set were deleted ( Toutanova and Chen , 2015 ) , meaning that symmetry can not be tested for in FB15 K -237 .", "entities": []}, {"text": "Given that CODEXdatasets contain both symmetry and compositionality , CODEXis more suitable for assessing how well models can learn relation patterns that go beyond frequency .", "entities": []}, {"text": "7 Conclusion and outlook We present CODEX , a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia , and show that CODEXis suitable for multiple KGC tasks .", "entities": [[11, 14, "TaskName", "knowledge graph COmpletion"]]}, {"text": "We release data , code , and pretrained models for use by the community at https://bit.ly/2EPbrJs .", "entities": []}, {"text": "Some promising future directions on C ODEXinclude : \u000fBetter model understanding CODEXcan be used to analyze the impact of hyperparameters , training strategies , and model architectures in KGC tasks .", "entities": []}, {"text": "\u000fRevival of triple classi\ufb01cation We encourage the use of triple classi\ufb01cation on CODEX in addition to link prediction because it directly tests discriminative power .", "entities": [[16, 18, "TaskName", "link prediction"]]}, {"text": "\u000fFusing text and structure Including text in both the link prediction and triple classi\ufb01cation tasks should substantially improve performance ( Toutanova et al . , 2015 ) .", "entities": [[9, 11, "TaskName", "link prediction"]]}, {"text": "Furthermore , text can be used for few - shot link prediction , an emerging research direction ( Xiong et al . , 2017 ; Shi and Weninger , 2017 ) .", "entities": [[10, 12, "TaskName", "link prediction"]]}, {"text": "Overall , we hope that CODEXwill provide a boost to research in KGC , which will in turn impact many other \ufb01elds of arti\ufb01cial intelligence .", "entities": []}, {"text": "Acknowledgments The authors thank Micha\u0142 Rybak and Xinyi ( Carol ) Zheng for their contributions .", "entities": []}, {"text": "This material is supported by the National Science Foundation under Grant No . IIS 1845491 , Army Young Investigator Award No . W911NF1810397 , and an NSF Graduate Research Fellowship .", "entities": []}, {"text": "8337References Farahnaz Akrami , Mohammed Samiul Saeef , Qingheng Zhang , Wei Hu , and Chengkai Li . 2020 .", "entities": []}, {"text": "Realistic re", "entities": []}, {"text": "-", "entities": []}, {"text": "evaluation of knowledge graph completion methods :", "entities": [[2, 5, "TaskName", "knowledge graph completion"]]}, {"text": "An experimental study .", "entities": []}, {"text": "In SIGMOD .", "entities": []}, {"text": "Ivana Balazevic , Carl Allen , and Timothy Hospedales . 2019a .", "entities": []}, {"text": "Multi - relational poincar\u00e9 graph embeddings .", "entities": []}, {"text": "InNeurIPS .", "entities": []}, {"text": "Ivana Balazevic , Carl Allen , and Timothy Hospedales . 2019b .", "entities": []}, {"text": "Tucker : Tensor factorization for knowledge graph completion .", "entities": [[5, 8, "TaskName", "knowledge graph completion"]]}, {"text": "In EMNLP - IJCNLP .", "entities": []}, {"text": "Trapit Bansal , Da - Cheng Juan , Sujith Ravi , and Andrew McCallum .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "A2n : Attending to neighbors for knowledge graph inference .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Vladimir Batagelj and Matja\u017e Zaver\u0161nik .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Fast algorithms for determining ( generalized ) core groups in social networks .", "entities": []}, {"text": "ADAC , 5(2 ) .", "entities": []}, {"text": "Kurt Bollacker , Colin Evans , Praveen Paritosh , Tim Sturge , and Jamie Taylor . 2008 .", "entities": []}, {"text": "Freebase : a collaboratively created graph database for structuring human knowledge .", "entities": []}, {"text": "In SIGMOD .", "entities": []}, {"text": "Antoine Bordes , Nicolas Usunier , Alberto GarciaDuran , Jason Weston , and Oksana Yakhnenko .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Translating embeddings for modeling multirelational data .", "entities": []}, {"text": "In NeurIPS .", "entities": []}, {"text": "Guillaume Bouchard , Sameer Singh , and Theo Trouillon .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "On approximate reasoning capabilities of low - rank vector spaces .", "entities": []}, {"text": "In AAAI Spring Symposium Series .", "entities": []}, {"text": "Liwei Cai and William Yang Wang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Kbgan : Adversarial learning for knowledge graph embeddings .", "entities": [[5, 8, "TaskName", "knowledge graph embeddings"]]}, {"text": "InNAACL - HLT .", "entities": []}, {"text": "Rajarshi Das , Shehzaad Dhuliawala , Manzil Zaheer , Luke Vilnis , Ishan Durugkar , Akshay Krishnamurthy , Alex Smola , and Andrew McCallum .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Go for a walk and arrive at the answer : Reasoning over paths in knowledge bases using reinforcement learning .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Tim Dettmers , Pasquale Minervini , Pontus Stenetorp , and Sebastian Riedel .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Convolutional 2d knowledge graph embeddings .", "entities": [[2, 5, "TaskName", "knowledge graph embeddings"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Takuma Ebisu and Ryutaro Ichise .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Toruse : Knowledge graph embedding on a lie group .", "entities": [[2, 5, "TaskName", "Knowledge graph embedding"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Luis Antonio Gal\u00e1rraga , Christina Te\ufb02ioudi , Katja Hose , and Fabian Suchanek .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Amie : association rule mining under incomplete evidence in ontological knowledge bases .", "entities": []}, {"text": "In WWW .", "entities": []}, {"text": "Alberto Garcia - Duran , Antoine Bordes , and Nicolas Usunier . 2015 .", "entities": []}, {"text": "Composing relationships with translations .", "entities": []}, {"text": "In EMNLP .Xavier Glorot and Yoshua Bengio . 2010 .", "entities": []}, {"text": "Understanding the dif\ufb01culty of training deep feedforward neural networks .", "entities": []}, {"text": "In AISTATS .", "entities": []}, {"text": "Leo A Goodman .", "entities": []}, {"text": "1961 .", "entities": []}, {"text": "Snowball sampling .", "entities": []}, {"text": "Ann .", "entities": []}, {"text": "Math .", "entities": []}, {"text": "Stat .", "entities": []}, {"text": "Lingbing Guo , Zequn Sun , and Wei Hu . 2019 .", "entities": []}, {"text": "Learning to exploit long - term relational dependencies in knowledge graphs .", "entities": [[9, 11, "TaskName", "knowledge graphs"]]}, {"text": "In ICML .", "entities": []}, {"text": "Shu Guo , Quan Wang , Bin Wang , Lihong Wang , and Li Guo . 2015 .", "entities": []}, {"text": "Semantically smooth knowledge graph embedding .", "entities": [[2, 5, "TaskName", "knowledge graph embedding"]]}, {"text": "In ACL - IJCNLP .", "entities": []}, {"text": "Shu Guo , Quan Wang , Lihong Wang , Bin Wang , and Li Guo .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Knowledge graph embedding with iterative guidance from soft rules .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Kelvin Guu , John Miller , and Percy Liang . 2015 .", "entities": []}, {"text": "Traversing knowledge graphs in vector space .", "entities": [[1, 3, "TaskName", "knowledge graphs"]]}, {"text": "In EMNLP .", "entities": []}, {"text": "Geoffrey E Hinton .", "entities": []}, {"text": "1986 .", "entities": []}, {"text": "Learning distributed representations of concepts .", "entities": []}, {"text": "In CogSci .", "entities": []}, {"text": "Prachi Jain , Sushant Rathi , Mausam , and Soumen Chakrabarti .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Knowledge base completion : Baseline strikes back ( again ) .", "entities": [[0, 3, "TaskName", "Knowledge base completion"]]}, {"text": "arXiv preprint arXiv:2005.00804 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Guoliang Ji , Shizhu He , Liheng Xu , Kang Liu , and Jun Zhao . 2015 .", "entities": []}, {"text": "Knowledge graph embedding via dynamic mapping matrix .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "In ACL - IJCNLP .", "entities": []}, {"text": "Shaoxiong Ji , Shirui Pan , Erik Cambria , Pekka Marttinen , and Philip S Yu . 2020 .", "entities": []}, {"text": "A survey on knowledge graphs : Representation , acquisition and applications .", "entities": [[3, 5, "TaskName", "knowledge graphs"]]}, {"text": "arXiv preprint arXiv:2002.00388 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Yantao Jia , Yuanzhuo Wang , Hailun Lin , Xiaolong Jin , and Xueqi Cheng . 2016 .", "entities": []}, {"text": "Locally adaptive translation for knowledge graph embedding .", "entities": [[4, 7, "TaskName", "knowledge graph embedding"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Xiaotian Jiang , Quan Wang , and Bin Wang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Adaptive convolution for multi - relational learning .", "entities": [[1, 2, "MethodName", "convolution"]]}, {"text": "InNAACL - HLT .", "entities": []}, {"text": "Rudolf Kadlec , Ondrej Bajgar , and Jan Kleindienst . 2017 .", "entities": []}, {"text": "Knowledge base completion : Baselines strike back .", "entities": [[0, 3, "TaskName", "Knowledge base completion"]]}, {"text": "In ACL RepL4NLP Workshop .", "entities": []}, {"text": "Lucie - Aim\u00e9e Kaffee , Alessandro Piscopo , Pavlos V ougiouklis , Elena Simperl , Leslie Carr , and Lydia Pintscher .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "A glimpse into babel : an analysis of multilinguality in wikidata .", "entities": []}, {"text": "In OpenSym .", "entities": []}, {"text": "Seyed Mehran Kazemi and David Poole .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Simple embedding for link prediction in knowledge graphs .", "entities": [[3, 5, "TaskName", "link prediction"], [6, 8, "TaskName", "knowledge graphs"]]}, {"text": "InNeurIPS .", "entities": []}, {"text": "Charles Kemp , Joshua B Tenenbaum , Thomas L Grif\ufb01ths , Takeshi Yamada , and Naonori Ueda . 2006 .", "entities": []}, {"text": "Learning systems of concepts with an in\ufb01nite relational model .", "entities": []}, {"text": "In AAAI .", "entities": []}, {"text": "8338Timothee", "entities": []}, {"text": "Lacroix , Nicolas Usunier , and Guillaume Obozinski .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Canonical tensor decomposition for knowledge base completion .", "entities": [[4, 7, "TaskName", "knowledge base completion"]]}, {"text": "In ICML .", "entities": []}, {"text": "Jonathan Lajus , Luis Gal\u00e1rraga , and Fabian M. Suchanek . 2020 .", "entities": []}, {"text": "Fast and exact rule mining with amie 3 .", "entities": []}, {"text": "In ESWC .", "entities": []}, {"text": "Xi Victoria Lin , Richard Socher , and Caiming Xiong .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Multi - hop knowledge graph reasoning with reward shaping .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Yankai Lin , Zhiyuan Liu , Huanbo Luan , Maosong Sun , Siwei Rao , and Song Liu . 2015a .", "entities": []}, {"text": "Modeling relation paths for representation learning of knowledge bases .", "entities": [[4, 6, "TaskName", "representation learning"]]}, {"text": "InEMNLP .", "entities": []}, {"text": "Yankai Lin , Zhiyuan Liu , and Maosong Sun . 2016 .", "entities": []}, {"text": "Knowledge representation learning with entities , attributes and relations .", "entities": [[1, 3, "TaskName", "representation learning"]]}, {"text": "In IJCAI .", "entities": []}, {"text": "Yankai Lin , Zhiyuan Liu , Maosong Sun , Yang Liu , and Xuan Zhu . 2015b .", "entities": []}, {"text": "Learning entity and relation embeddings for knowledge graph completion .", "entities": [[6, 9, "TaskName", "knowledge graph completion"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Hanxiao Liu , Yuexin Wu , and Yiming Yang .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Analogical inference for multi - relational embeddings .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "Farzaneh Mahdisoltani , Joanna Biega , and Fabian Suchanek . 2014 .", "entities": []}, {"text": "Yago3 :", "entities": []}, {"text": "A knowledge base from multilingual wikipedias .", "entities": []}, {"text": "In CIDR .", "entities": []}, {"text": "Alexa T McCray . 2003 .", "entities": []}, {"text": "An upper - level ontology for the biomedical domain .", "entities": [[4, 5, "MethodName", "ontology"]]}, {"text": "Comp .", "entities": []}, {"text": "Funct .", "entities": []}, {"text": "Genomics , 4(1 ) .", "entities": []}, {"text": "Christian Meilicke , Manuel Fink , Yanjie Wang , Daniel Ruf\ufb01nelli , Rainer Gemulla , and Heiner Stuckenschmidt .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Fine - grained evaluation of ruleand embedding - based systems for knowledge graph completion .", "entities": [[11, 14, "TaskName", "knowledge graph completion"]]}, {"text": "In ISWC .", "entities": []}, {"text": "George A Miller .", "entities": []}, {"text": "1998 .", "entities": []}, {"text": "WordNet :", "entities": []}, {"text": "An electronic lexical database .", "entities": []}, {"text": "MIT press .", "entities": []}, {"text": "Tom Mitchell , William Cohen , Estevam Hruschka , Partha Talukdar , Bishan Yang , Justin Betteridge , Andrew Carlson , Bhanava Dalvi , Matt Gardner , Bryan Kisiel , et al . 2018 .", "entities": []}, {"text": "Never - ending learning .", "entities": []}, {"text": "CACM , 61(5):103\u2013115 .", "entities": []}, {"text": "Deepak Nathani , Jatin Chauhan , Charu Sharma , and Manohar Kaul .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Learning attention - based embeddings for relation prediction in knowledge graphs .", "entities": [[9, 11, "TaskName", "knowledge graphs"]]}, {"text": "In ACL .", "entities": []}, {"text": "Dat Quoc Nguyen , Kairit Sirts , Lizhen Qu , and Mark Johnson .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Stranse : a novel embedding model of entities and relationships in knowledge bases .", "entities": []}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Tu Dinh Nguyen , Dat Quoc Nguyen , Dinh Phung , et al . 2018 .", "entities": []}, {"text": "A novel embedding model for knowledge base completion based on convolutional neural network .", "entities": [[5, 8, "TaskName", "knowledge base completion"]]}, {"text": "In NAACL - HLT .Maximilian", "entities": []}, {"text": "Nickel , Kevin Murphy , V olker Tresp , and Evgeniy Gabrilovich . 2015 .", "entities": []}, {"text": "A review of relational machine learning for knowledge graphs .", "entities": [[7, 9, "TaskName", "knowledge graphs"]]}, {"text": "Proc .", "entities": []}, {"text": "IEEE , 104(1 ) .", "entities": []}, {"text": "Maximilian Nickel , Lorenzo Rosasco , and Tomaso Poggio . 2016 .", "entities": []}, {"text": "Holographic embeddings of knowledge graphs .", "entities": [[3, 5, "TaskName", "knowledge graphs"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Maximilian Nickel , V olker Tresp , and Hans - Peter Kriegel . 2011 .", "entities": []}, {"text": "A three - way model for collective learning on multi - relational data .", "entities": []}, {"text": "In ICML .", "entities": []}, {"text": "Pouya Pezeshkpour , Yifan Tian , and Sameer Singh .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Revisiting evaluation of knowledge base completion models .", "entities": [[3, 6, "TaskName", "knowledge base completion"]]}, {"text": "In AKBC .", "entities": []}, {"text": "Daniel Ruf\ufb01nelli , Samuel Broscheit , and Rainer Gemulla .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "You can teach an old dog new tricks !", "entities": []}, {"text": "on training knowledge graph embeddings .", "entities": [[2, 5, "TaskName", "knowledge graph embeddings"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Baoxu Shi and Tim Weninger .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Proje : Embedding projection for knowledge graph completion .", "entities": [[5, 8, "TaskName", "knowledge graph completion"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Richard Socher , Danqi Chen , Christopher D Manning , and Andrew Ng . 2013 .", "entities": []}, {"text": "Reasoning with neural tensor networks for knowledge base completion .", "entities": [[6, 9, "TaskName", "knowledge base completion"]]}, {"text": "In NeurIPS .", "entities": []}, {"text": "Zhiqing Sun , Zhi - Hong Deng , Jian - Yun Nie , and Jian Tang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Rotate :", "entities": []}, {"text": "Knowledge graph embedding by relational rotation in complex space .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "In ICLR .", "entities": []}, {"text": "Thomas Pellissier Tanon , Denny Vrande \u02c7ci\u00b4c , Sebastian Schaffert , Thomas Steiner , and Lydia Pintscher .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "From freebase to wikidata : The great migration .", "entities": []}, {"text": "In WWW .", "entities": []}, {"text": "Kristina Toutanova and Danqi Chen . 2015 .", "entities": []}, {"text": "Observed versus latent features for knowledge base and text inference .", "entities": []}, {"text": "In ACL CVSC Workshop .", "entities": []}, {"text": "Kristina Toutanova , Danqi Chen , Patrick Pantel , Hoifung Poon , Pallavi Choudhury , and Michael Gamon . 2015 .", "entities": []}, {"text": "Representing text for joint embedding of text and knowledge bases .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Th\u00e9o Trouillon , \u00c9ric Gaussier , Christopher R Dance , and Guillaume Bouchard . 2019 .", "entities": []}, {"text": "On inductive abilities of latent factor models for relational learning .", "entities": []}, {"text": "JAIR , 64 .", "entities": []}, {"text": "Th\u00e9o Trouillon , Johannes Welbl , Sebastian Riedel , \u00c9ric Gaussier , and Guillaume Bouchard . 2016 .", "entities": []}, {"text": "Complex embeddings for simple link prediction .", "entities": [[4, 6, "TaskName", "link prediction"]]}, {"text": "In ICML .", "entities": []}, {"text": "Shikhar Vashishth , Soumya Sanyal , Vikram Nitin , Nilesh Agrawal , and Partha Talukdar . 2020a .", "entities": []}, {"text": "Interacte : Improving convolution - based knowledge graph embeddings by increasing feature interactions .", "entities": [[3, 4, "MethodName", "convolution"], [6, 9, "TaskName", "knowledge graph embeddings"]]}, {"text": "InAAAI .", "entities": []}, {"text": "Shikhar Vashishth , Soumya Sanyal , Vikram Nitin , and Partha Talukdar . 2020b .", "entities": []}, {"text": "Composition - based multirelational graph convolutional networks .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "8339Denny Vrande \u02c7ci\u00b4c and Markus Kr\u00f6tzsch .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Wikidata : a free collaborative knowledgebase .", "entities": []}, {"text": "CACM , 57(10 ) .", "entities": []}, {"text": "Thanh Vu , Tu Dinh Nguyen , Dat Quoc Nguyen , Dinh Phung , et al . 2019 .", "entities": []}, {"text": "A capsule network - based embedding model for knowledge graph completion and search personalization .", "entities": [[1, 3, "MethodName", "capsule network"], [8, 11, "TaskName", "knowledge graph completion"]]}, {"text": "In NAACL - HLT .", "entities": []}, {"text": "Quan Wang , Zhendong Mao , Bin Wang , and Li Guo . 2017 .", "entities": []}, {"text": "Knowledge graph embedding : A survey of approaches and applications .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "TKDE , 29(12 ) .", "entities": []}, {"text": "Quan Wang , Bin Wang , and Li Guo .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Knowledge base completion using embeddings and rules .", "entities": [[0, 3, "TaskName", "Knowledge base completion"]]}, {"text": "In IJCAI .", "entities": []}, {"text": "William Yang Wang and William W Cohen .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Learning \ufb01rst - order logic embeddings via matrix factorization .", "entities": []}, {"text": "In IJCAI .", "entities": []}, {"text": "Zhen Wang , Jianwen Zhang , Jianlin Feng , and Zheng Chen .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Knowledge graph embedding by translating on hyperplanes .", "entities": [[0, 3, "TaskName", "Knowledge graph embedding"]]}, {"text": "In AAAI .", "entities": []}, {"text": "Han Xiao , Minlie Huang , and Xiaoyan Zhu . 2016a .", "entities": []}, {"text": "From one point to a manifold : knowledge graph embedding for precise link prediction .", "entities": [[7, 10, "TaskName", "knowledge graph embedding"], [12, 14, "TaskName", "link prediction"]]}, {"text": "In IJCAI .Han", "entities": []}, {"text": "Xiao , Minlie Huang , and Xiaoyan Zhu . 2016b .", "entities": []}, {"text": "Transg :", "entities": []}, {"text": "A generative model for knowledge graph embedding .", "entities": [[4, 7, "TaskName", "knowledge graph embedding"]]}, {"text": "In ACL .", "entities": []}, {"text": "Ruobing Xie , Zhiyuan Liu , and Maosong Sun . 2016 .", "entities": []}, {"text": "Representation learning of knowledge graphs with hierarchical types .", "entities": [[0, 2, "TaskName", "Representation learning"], [3, 5, "TaskName", "knowledge graphs"]]}, {"text": "In IJCAI .", "entities": []}, {"text": "Wenhan Xiong , Thien Hoang , and William Yang Wang .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Deeppath :", "entities": []}, {"text": "A reinforcement learning method for knowledge graph reasoning .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Canran Xu and Ruijiang Li .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Relation embedding with dihedral group in knowledge graph .", "entities": []}, {"text": "In ACL .", "entities": []}, {"text": "Bishan Yang , Wen - tau Yih , Xiaodong He , Jianfeng Gao , and Li Deng . 2015 .", "entities": []}, {"text": "Embedding entities and relations for learning and inference in knowledge bases .", "entities": []}, {"text": "In ICLR .", "entities": []}, {"text": "Shuai Zhang , Yi Tay , Lina Yao , and Qi Liu .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Quaternion knowledge graph embeddings .", "entities": [[1, 4, "TaskName", "knowledge graph embeddings"]]}, {"text": "In NeurIPS .", "entities": []}, {"text": "Zhao Zhang , Fuzhen Zhuang , Hengshu Zhu , Zhiping Shi , Hui Xiong , and Qing He . 2020 .", "entities": []}, {"text": "Relational graph neural network with hierarchical attention for knowledge graph completion .", "entities": [[8, 11, "TaskName", "knowledge graph completion"]]}, {"text": "In AAAI .", "entities": []}, {"text": "8340A Literature review Table 8 provides an overview of knowledge graph embedding papers with respect to datasets and evaluation tasks .", "entities": [[9, 12, "TaskName", "knowledge graph embedding"]]}, {"text": "In our review , we only consider papers published between 2014 and 2020 in the main proceedings of conferences where KGC embedding papers are most likely to appear : Arti\ufb01cial intelligence ( AAAI , IJCAI ) , machine learning ( ICML , ICLR , NeurIPS ) , and natural language processing ( ACL , EMNLP , NAACL ) .", "entities": []}, {"text": "The main evaluation benchmarks are FB15 K ( Bordes et al . , 2013 ) , WN18 ( Bordes et al . , 2013 ) , FB15K-237 ( Toutanova and Chen , 2015 ) , WN18RR ( Dettmers et al . , 2018 ) , FB13 ( Socher et al . , 2013 ) , WN11 ( Socher et al . , 2013 ) , NELL995(Xiong et", "entities": [[16, 17, "DatasetName", "WN18"], [26, 27, "DatasetName", "FB15K-237"], [35, 36, "DatasetName", "WN18RR"]]}, {"text": "al . , 2017 ) , YAGO3 - 10 ( Dettmers et al . , 2018 ) , Countries ( Bouchard et al . , 2015 ) .", "entities": [[6, 9, "DatasetName", "YAGO3 - 10"]]}, {"text": "UMLS ( McCray , 2003 ) , Kinship ( Kemp et al . , 2006 ) , Families ( Hinton , 1986 ) , and other versions ofNELL ( Mitchell et al . , 2018 ) .", "entities": [[0, 1, "DatasetName", "UMLS"], [7, 8, "DatasetName", "Kinship"]]}, {"text": "B Seeds for data collection Table 9 provides all seed entity and relation types used to collect CODEX .", "entities": []}, {"text": "Each type is given \ufb01rst by its natural language label and then by its Wikidata unique ID : Entity IDs begin with Q , whereas relation ( property ) IDs begin with P.", "entities": []}, {"text": "For the entity types that apply to people ( e.g. , actor , musician , journalist ) , we retrieved seed entities by querying Wikidata using the occupation relation .", "entities": []}, {"text": "For the entity types that apply to things ( e.g. , airline , disease , tourist attraction ) , we retrieved seed entities by querying Wikidata using the instance of and subclass of relations .", "entities": []}, {"text": "C Negative annotation guidelines We provide the annotation guidelines we used to label candidate negative triples ( \u00a7 3.4 ) .", "entities": []}, {"text": "Task You must label each triple as either trueor false .", "entities": []}, {"text": "To help you \ufb01nd the answer , we have provided you with Wikipedia and Wikidata links for the entities and relations in each triple .", "entities": []}, {"text": "You may also search on Google for the answer , although most claims should be resolvable using Wikipedia and Wikidata alone .", "entities": [[5, 6, "DatasetName", "Google"]]}, {"text": "If you are not able to \ufb01nd any reliable , speci\ufb01c , clear information supporting the claim , choose false .", "entities": []}, {"text": "You may explain your reasoning if need be or provide sources to back up your answer in the optional explanation column .", "entities": []}, {"text": "Examples False triples may have problems with grammar , factual content , or both .", "entities": []}, {"text": "Examples of grammatically incorrect triples are those whose entity or relation types do not make sense , for example : \u000f(United States of America , continent , science \ufb01ction writer ) \u000f(Mohandas Karamchand Gandhi , medical condition , British Raj )", "entities": []}, {"text": "\u000f(Canada , foundational text , Vietnamese cuisine )", "entities": []}, {"text": "Examples of grammatically correct but factually false triples include : \u000f(United States of America , continent , Europe ) \u000f(Mohandas Karamchand Gandhi , country of citizenship , Argentina ) \u000f(Canada , foundational text , Harry Potter and the Goblet of Fire ) \u000f(Alexander Pushkin , in\ufb02uenced by , Leo Tolstoy ) \u2014 Pushkin died only a few years after Tolstoy was born , so this sentence is unlikely .", "entities": []}, {"text": "Notice that in the latter examples , the entity types match up , but the statements are still false .", "entities": []}, {"text": "Tips For triples about people \u2019s occupation and genre , try to be as speci\ufb01c as possible .", "entities": []}, {"text": "For example , if the triple says ( < person > , occupation , guitarist ) but that person is mainly known for their singing , choose false , even if that person plays the guitar .", "entities": []}, {"text": "Likewise , if a triple says ( < person > , genre , classical ) but they are mostly known for jazz music , choose false even if , for example , that person had classical training in their childhood .", "entities": []}, {"text": "D Embedding models We brie\ufb02y overview the \ufb01ve models compared in our link prediction and triple classi\ufb01cation tasks .", "entities": [[12, 14, "TaskName", "link prediction"]]}, {"text": "RESCAL ( Nickel et al . , 2011 ) was one of the \ufb01rst knowledge graph embedding models .", "entities": [[0, 1, "MethodName", "RESCAL"], [14, 17, "TaskName", "knowledge graph embedding"]]}, {"text": "Although it is not often used as a baseline , Ruf\ufb01nelli et al .", "entities": []}, {"text": "( 2020 ) showed that it is competitive when appropriately tuned .", "entities": []}, {"text": "RESCAL treats relational learning as tensor decomposition , scoring entity embeddings h;r2 Rdeand relation embeddings R2Rde\u0002dewith the bilinear form h > Rt .", "entities": [[0, 1, "MethodName", "RESCAL"], [9, 11, "TaskName", "entity embeddings"]]}, {"text": "8341Table 8 : An overview of knowledge graph embedding papers published between 2014 and 2020 with respect to datasets and evaluation tasks .", "entities": [[6, 9, "TaskName", "knowledge graph embedding"]]}, {"text": "Original citations for datasets are given in Appendix A. Link pred .", "entities": []}, {"text": "refers to link prediction , and triple class .", "entities": [[2, 4, "TaskName", "link prediction"]]}, {"text": "refers to triple classi\ufb01cation , both of which are covered in \u00a7 5 .", "entities": []}, {"text": "ReferenceDatasets Evaluation tasksFB15 K FB15K-237 FB13 WN18 WN18RR WN11 Other Link pred .", "entities": [[4, 5, "DatasetName", "FB15K-237"], [6, 7, "DatasetName", "WN18"], [7, 8, "DatasetName", "WN18RR"]]}, {"text": "Triple class .", "entities": []}, {"text": "OtherAAAI , IJCAI(Wang et", "entities": []}, {"text": "al . , 2014 ) 3 3 3 3 FB5 M 3 3relation extraction ( FB5 M ) ( Lin et al . , 2015b ) 3 3 3 3 FB40 K 3 3relation extraction ( FB40 K ) ( Wang et al . , 2015 ) NELL ( Location , Sports ) 3 ( Nickel et al . , 2016 ) 3 3 Countries 3 ( Lin et al . , 2016 )", "entities": [[47, 48, "DatasetName", "NELL"]]}, {"text": "FB24 K 3 ( Wang and Cohen , 2016 ) 3 3 3 ( Xiao et al . , 2016a )", "entities": []}, {"text": "3 3 3 3 3 3 ( Jia et al . , 2016 )", "entities": []}, {"text": "3 3 3 3 3 3 ( Xie et al . , 2016 ) 3 FB15K+ 3 3 ( Shi and Weninger , 2017 ) 3 SemMedDB , DBPedia 3fact checking ( not on FB15 K ) ( Dettmers et al . , 2018 ) 3 3 3 3 YAGO3 - 10 , Countries 3 ( Ebisu and Ichise , 2018 ) 3 3 3 ( Guo et al . , 2018 ) 3 YAGO37 3 ( Zhang et al . , 2020 ) 3 3 3 3 3 ( Vashishth et al . , 2020a ) 3 3 YAGO3 - 10 3ICML , ICLR , NeurIPS(Yang et", "entities": [[28, 29, "DatasetName", "DBPedia"], [49, 52, "DatasetName", "YAGO3 - 10"], [74, 75, "DatasetName", "YAGO37"], [99, 102, "DatasetName", "YAGO3 - 10"]]}, {"text": "al . , 2015 ) 3 3 FB15K-401 3rule extraction ( FB15K-401 ) ( Trouillon et al . , 2016 ) 3 3 3 ( Liu et al . , 2017 ) 3 3 3 ( Kazemi and Poole , 2018 ) 3 3 3 ( Das et al . , 2018 ) 3 3NELL-995 , UMLS , Kinship , Countries , WikiMovies3 QA ( WikiMovies ) ( Lacroix et al . , 2018 ) 3 3 3 3 YAGO3 - 10 3 ( Guo et al . , 2019 ) 3 3 3DBPedia - YAGO3 , DBPedia - Wikidata3entity alignment ( DBPedia graphs ) ( Sun et al . , 2019 )", "entities": [[56, 57, "DatasetName", "UMLS"], [58, 59, "DatasetName", "Kinship"], [65, 66, "DatasetName", "WikiMovies"], [79, 82, "DatasetName", "YAGO3 - 10"], [97, 98, "DatasetName", "DBPedia"], [102, 103, "DatasetName", "DBPedia"]]}, {"text": "3 3 3 3 3 ( Zhang et al . , 2019 ) 3 3 3 3 3 ( Balazevic et al . , 2019a ) 3 3 3 ( Vashishth et al . , 2020b ) 3 3 MUTAG , AM , PTC 3graph classi\ufb01cation ( MUTAG , AM , PTC)ACL , EMNLP , NAACL(Ji et", "entities": [[39, 40, "DatasetName", "MUTAG"], [43, 44, "DatasetName", "PTC"], [47, 48, "DatasetName", "MUTAG"]]}, {"text": "al . , 2015 ) 3 3 3 3 3 3 ( Guo et al . , 2015 ) NELL ( Location , Sports , Freq ) 3 3 ( Guu et al . , 2015 ) 3 3 3 3 ( Garcia - Duran et", "entities": [[19, 20, "DatasetName", "NELL"]]}, {"text": "al . , 2015 ) 3 Families 3 ( Lin et al . , 2015a ) 3 FB40 K 3relation extraction ( FB40 K ) ( Xiao et al . , 2016b )", "entities": []}, {"text": "3 3 3 3 3 3 ( Nguyen et al . , 2016 ) 3 3 3 ( Xiong et al . , 2017 ) 3 NELL-995 3 rule mining ( Lin et al . , 2018 ) 3 3 NELL-995 , UMLS , Kinship 3 ( Nguyen et al . , 2018 ) 3 3 3 ( Bansal et al . , 2019 ) 3 3 3 ( Xu and Li , 2019 ) 3 3 3 3 YAGO3 - 10 , Family 3 ( Balazevic et al . , 2019b ) 3 3 3 3 3 ( Vu et al . , 2019 ) 3 3 SEARCH17 3personalized search ( SEARCH17 ) ( Nathani et al . , 2019 ) 3 3 NELL-995 , UMLS , Kinship 3 ( Jiang et al . , 2019 ) 3 3 3 3 3", "entities": [[26, 27, "DatasetName", "NELL-995"], [40, 41, "DatasetName", "NELL-995"], [42, 43, "DatasetName", "UMLS"], [44, 45, "DatasetName", "Kinship"], [79, 82, "DatasetName", "YAGO3 - 10"], [124, 125, "DatasetName", "NELL-995"], [126, 127, "DatasetName", "UMLS"], [128, 129, "DatasetName", "Kinship"]]}, {"text": "8342Table 9 : The entity and relation types ( Wikidata IDs in parentheses ) used to seed C ODEX .", "entities": []}, {"text": "Seed typesEntitiesactor ( Q33999 ) , airline ( Q46970 ) , airport ( Q1248784 ) , athlete ( Q2066131 ) , book ( Q571 ) , businessperson ( Q43845 ) , city ( Q515 ) , company ( Q783794 ) , country ( Q6256 ) , disease ( Q12136 ) , engineer ( Q81096 ) , \ufb01lm ( Q11424 ) , government agency ( Q327333 ) , journalist ( Q1930187 ) , lake ( Q23397 ) , monarch ( Q116 ) , mountain ( Q8502 ) , musical group ( Q215380 ) , musician ( Q639669 ) , newspaper ( Q11032 ) , ocean ( Q9430 ) , politician ( Q82955 ) , record label ( Q18127 ) , religion ( Q9174 ) , religious leader ( Q15995642 ) , religious text ( Q179461 ) , scientist ( Q901 ) , sports league ( Q623109 ) , sports team ( Q12973014 ) , stadium ( Q483110 ) , television program ( Q15416 ) , tourist attraction ( Q570116 ) , visual artist ( Q3391743 ) , visual artwork ( Q4502142 ) , writer ( Q36180)Relationsairline alliance ( P114 ) , airline hub ( P113 ) , architect ( P84 ) , architectural style ( P149 ) , author ( P50 ) , capital ( P36 ) , cast member ( P161 ) , cause of death ( P509 ) , chairperson ( P488 ) , chief executive of\ufb01cer ( P169 ) , child ( P40 ) , continent ( P30 ) , country ( P17 ) , country of citizenship ( P27 ) , country of origin ( P495 ) , creator ( P170 ) , diplomatic relation ( P530 ) , director ( P57 ) , drug used for treatment ( P2176 ) , educated at ( P69 ) , employer ( P108 ) , ethnic group ( P172 ) , \ufb01eld of work ( P101 ) , foundational text ( P457 ) , founded by ( P112 ) , genre ( P136 ) , head of government ( P6 ) , head of state ( P35 ) , headquarters location ( P159 ) , health specialty ( P1995 ) , indigenous to ( P2341 ) , industry ( P452 ) , in\ufb02uenced by ( P737 ) , instance of ( P31 ) , instrument ( P1303 ) , language of work or name ( P407 ) , languages spoken , written , or signed ( P1412 ) , legal form ( P1454 ) , legislative body ( P194 ) , located in the administrative terroritorial entity ( P131 ) , location of formation ( P740 ) , medical condition ( P1050 ) , medical examinations ( P923 ) , member of ( P463 ) , member of political party ( P102 ) , member of sports team ( P54 ) , mountain range ( P4552 ) , movement ( P135 ) , named after ( P138 ) , narrative location ( P840 ) , notable works ( P800 ) , occupant ( P466 ) , occupation ( P106 ) , of\ufb01cial language ( P37 ) , parent organization ( P749 ) , part of ( P361 ) , place of birth ( P19 ) , place of burial ( P119 ) , place of death ( P20 ) , practiced by ( P3095 ) , product or material produced ( P1056 ) , publisher ( P123 ) , record label ( P264 ) , regulated by ( P3719 ) , religion ( P140 ) , residence ( P551 ) , shares border with ( P47 ) , sibling ( P3373 ) , sport ( P641 ) , spouse ( P26 ) , studies ( P2578 ) , subclass of ( P279 ) , symptoms ( P780 ) , time period ( P2348 ) , tributary ( P974 ) , unmarried partner ( P451 ) , use ( P366 ) , uses ( P2283 ) TransE ( Bordes et al . , 2013 ) treats relations as translations between entities , i.e. , h+r\u0019tfor h;r;t2Rde , and scores embeddings with negative Euclidean distance \u0000kh+r\u0000tk .", "entities": [[656, 657, "MethodName", "TransE"]]}, {"text": "TransE is likely the most popular baseline for KGC tasks and the most in\ufb02uential of all KGC embedding papers .", "entities": [[0, 1, "MethodName", "TransE"]]}, {"text": "ComplEx ( Trouillon et al . , 2016 ) uses a bilinear function to score triples with a diagonal relation embedding matrix and complex - valued embeddings .", "entities": []}, {"text": "Its scoring function is re\u0000 h > diag(r)t\u0001 , where tis the complex conjugate of tand", "entities": []}, {"text": "re denotes the real part of a complex number .", "entities": []}, {"text": "ConvE ( Dettmers et al . , 2018 ) is one of the \ufb01rst and most popular nonlinear models for KGC .", "entities": []}, {"text": "It concatenates head and relation embeddings h andrinto a two - dimensional \u201c image \u201d , applies a pointwise linearity over convolutional and fullyconnected layers , and multiplies the result with the tail embedding tto obtain a score .", "entities": []}, {"text": "Formally , its scoring function is given as f(vec(f([h;r]\u0003 ! ) ) W)t , where fis a nonlinearity ( originally , ReLU ) , [ h;r]denotes a concatenation and twodimensional reshaping of the head and relation embeddings , ! denotes the \ufb01lters of the convolutional layer , and vecdenotes the \ufb02attening of a two - dimensional matrix .", "entities": [[21, 22, "MethodName", "ReLU"]]}, {"text": "TuckER ( Balazevic et al . , 2019b ) is a linear model based on the Tucker tensor decomposition , which factorizes a tensor into three lower - rank matrices and a core tensor .", "entities": [[0, 1, "MethodName", "TuckER"]]}, {"text": "The TuckER scoring function for a single triple ( h ; r ; t ) is given asW\u0002 1h\u00022r\u00023 t , whereWis the mode - three core tensor that is shared among all entity and relation embeddings , and\u0002ndenotes the tensor product along the nth mode of the tensor .", "entities": [[1, 2, "MethodName", "TuckER"]]}, {"text": "TuckER can be seen as a generalized form of other linear KGC embedding models like RESCAL and ComplEx .", "entities": [[0, 1, "MethodName", "TuckER"], [15, 16, "MethodName", "RESCAL"]]}, {"text": "E Content comparison We provide additional comparison of the contents in C ODEX - M and FB15K-237 .", "entities": [[16, 17, "DatasetName", "FB15K-237"]]}, {"text": "Figure 5 , which plots the top-30 entities by frequency in the two benchmarks , demonstrates that both dataset are biased toward developed Western countries and cultures .", "entities": []}, {"text": "However , CODEX - Mis more diverse in domain .", "entities": []}, {"text": "It covers academia , entertainment , journalism , politics , science , and writing , whereas FB15 K -237 covers mostly entertaiment and sports .", "entities": []}, {"text": "FB15 K -237 is also much more biased toward the United States in particular , as \ufb01ve of its top-30 entities are speci\ufb01c to the US : United States of America , United States dollar , New York City ,", "entities": []}, {"text": "8343 Figure 5 : Top-30 most frequent entities in C ODEX - M and FB15K-237 .", "entities": [[14, 15, "DatasetName", "FB15K-237"]]}, {"text": "Figure 6 : Top-15 most frequent entity types in C ODEX - M and FB15K-237 .", "entities": [[14, 15, "DatasetName", "FB15K-237"]]}, {"text": "Los Angeles , and the United States Department of Housing and Urban Development .", "entities": []}, {"text": "Figure 6 compares the top-15 entity types in CODEX - MandFB15 K -237 .", "entities": []}, {"text": "Again , CODEX - M is diverse , covering people , places , organizations , movies , and abstract concepts , whereas FB15 K 237 has many overlapping entity types mostly about entertainment .", "entities": []}, {"text": "F Hyperparameter search Table 10 gives our hyperparameter search space .", "entities": []}, {"text": "Tables 11 , 12 , and 13 report the best hyperparameter con\ufb01gurations for link prediction on CODEX - S , CODEX - M , and CODEX - L , respectively .", "entities": [[13, 15, "TaskName", "link prediction"]]}, {"text": "Tables 14 and 15 report the best hyperparameter con\ufb01gurations for triple classi\ufb01cation on the hard negatives in C ODEX - S and C ODEX - M , respectively .", "entities": []}, {"text": "Terminology", "entities": []}, {"text": "For embedding initialization , Xv refers to Xavier initialization ( Glorot and Bengio , 2010 ) .", "entities": [[7, 9, "MethodName", "Xavier initialization"]]}, {"text": "The reciprocal relations model refers to learning separate relation embeddings for queries in the direction of ( h ; r;?)versus ( ? ; r ; t)(Kazemi and Poole , 2018 ) .", "entities": []}, {"text": "The frequency weighting regularization technique refers to regularizing embeddings by the relative frequency of the corresponding entity or relation in the training data .", "entities": []}, {"text": "8344Search strategies Recall that we select models using Ax , which supports hyperparameter search using both quasi - random sequences of generated con\ufb01gurations and Bayesian optimization ( BO ) .", "entities": [[2, 3, "MetricName", "Recall"]]}, {"text": "The search strategy for each CODEXdataset is as follows : \u000fCODEX - S : Per negative sampling type / loss combination , we generate 30 quasi - random trials followed by 10 BO trials .", "entities": [[19, 20, "MetricName", "loss"]]}, {"text": "We select the best - performing model by validation MRR over all such combinations .", "entities": [[9, 10, "MetricName", "MRR"]]}, {"text": "In each trial , the model is trained for a maximum of 400 epochs with an early stopping patience of 5 .", "entities": [[16, 18, "MethodName", "early stopping"]]}, {"text": "We also terminate a trial after 50 epochs if the model does not reach\u00150.05 MRR .", "entities": [[14, 15, "MetricName", "MRR"]]}, {"text": "\u000fCODEX - M : Per negative sampling type / loss combination , we generate 20 quasi - random trials .", "entities": [[9, 10, "MetricName", "loss"]]}, {"text": "The maximum number of epochs and early stopping criteria are the same as for CODEX - S.\u000fCODEX - L : Per negative sampling type / loss combination , we generate 10 quasi - random trials of 20 training epochs instead of 400 .", "entities": [[2, 5, "HyperparameterName", "number of epochs"], [6, 8, "MethodName", "early stopping"], [25, 26, "MetricName", "loss"]]}, {"text": "We reduce the number of epochs to limit resource usage .", "entities": [[3, 6, "HyperparameterName", "number of epochs"]]}, {"text": "In most cases , MRR plateaus after 2030 epochs , an observation which is consistent with ( Ruf\ufb01nelli et al . , 2020 ) .", "entities": [[4, 5, "MetricName", "MRR"]]}, {"text": "Then , we take the best - performing model by validation MRR over all such combinations , and retrain that model for a maximum of 400 epochs .", "entities": [[11, 12, "MetricName", "MRR"]]}, {"text": "Note that we search using MRR as our metric , but the triple classi\ufb01cation task measures 0/1 accuracy , not ranking performance .", "entities": [[5, 6, "MetricName", "MRR"], [17, 18, "MetricName", "accuracy"]]}, {"text": "For triple classi\ufb01cation , we choose the model with the highest validation accuracy among the pre - trained models across all negative sampling type / loss function combinations .", "entities": [[12, 13, "MetricName", "accuracy"], [25, 26, "MetricName", "loss"]]}, {"text": "We release all pretrained LibKGE models and accompanying con\ufb01guration \ufb01les in the centralized CODEXrepository .", "entities": []}, {"text": "8345Table 10 : Our hyperparameter search space .", "entities": []}, {"text": "We follow the naming conventions and ranges given by Ruf\ufb01nelli et al .", "entities": []}, {"text": "( 2020 ) , and explain the meanings of selected hyperparameter settings in Appendix F. As most KGC embedding models have a wide range of con\ufb01guration options , we encourage future work to follow this tabular scheme for transparent reporting of implementation details .", "entities": []}, {"text": "Hyperparameter Range Embedding size { 128;256;512 } Training type { NegSamp , 1vsAll , KvsAll } Reciprocal { True , False } # head samples ( NegSamp )", "entities": []}, {"text": "[ 1;1000 ] , log scale # tail samples ( NegSamp )", "entities": []}, {"text": "[ 1;1000 ] , log scale Label smoothing ( KvsAll )", "entities": [[6, 8, "MethodName", "Label smoothing"]]}, {"text": "[ 0;0:3 ] Loss { MR , BCE , CE } Margin ( MR )", "entities": [[5, 6, "DatasetName", "MR"], [13, 14, "DatasetName", "MR"]]}, {"text": "[ 0;10 ] ` pnorm ( TransE ) { 1;2 } Optimizer { Adam , Adagrad } Batch size { 128;256;512;1024 } Learning rate [ 10\u00004;1 ] , log scale LR scheduler patience [ 0;10 ] ` pregularization { 1;2;3;None } Entity embedding weight [ 1020;10\u00005 ] Relation embedding weight [ 1020;10\u00005 ] Frequency weighting { True , False } Embedding normalization ( TransE ) Entity { True , False } Relation { True , False } Dropout", "entities": [[6, 7, "MethodName", "TransE"], [11, 12, "HyperparameterName", "Optimizer"], [13, 14, "MethodName", "Adam"], [15, 16, "MethodName", "Adagrad"], [17, 19, "HyperparameterName", "Batch size"], [22, 24, "HyperparameterName", "Learning rate"], [63, 64, "MethodName", "TransE"], [77, 78, "MethodName", "Dropout"]]}, {"text": "Entity embedding [ 0:0;0:5 ] Relation embedding [ 0:0;0:5 ]", "entities": []}, {"text": "Feature map ( ConvE )", "entities": []}, {"text": "[ 0:0;0:5 ] Projection ( ConvE )", "entities": []}, {"text": "[ 0:0;0:5 ] Embedding initialization { Normal , Unif , XvNorm , XvUnif } Stdev ( Normal )", "entities": []}, {"text": "[ 10\u00005;1:0 ] Interval ( Unif )", "entities": []}, {"text": "[ \u00001:0;1:0 ] Gain ( XvNorm ) 1:0 Gain ( XvUnif ) 1:0", "entities": []}, {"text": "8346Table 11 : Best link prediction hyperparameter con\ufb01gurations on CODEX - S. RESCAL TransE ComplEx ConvE TuckER Best validation MRR 0:4076 0 : 3602 0 : 4752 0 : 4639 0 : 4574 Embedding size 512 512 512 256 512 Training type 1vsAll", "entities": [[4, 6, "TaskName", "link prediction"], [12, 13, "MethodName", "RESCAL"], [13, 14, "MethodName", "TransE"], [16, 17, "MethodName", "TuckER"], [19, 20, "MetricName", "MRR"], [21, 22, "DatasetName", "0"], [24, 25, "DatasetName", "0"], [27, 28, "DatasetName", "0"], [30, 31, "DatasetName", "0"]]}, {"text": "NegSamp 1vsAll 1vsAll KvsAll Reciprocal", "entities": []}, {"text": "No", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes # head samples ( NegSamp ) - 2 - - # tail samples ( NegSamp ) - 56 - - Label smoothing ( KvsAll ) - -", "entities": [[21, 23, "MethodName", "Label smoothing"]]}, {"text": "- - 0:0950", "entities": []}, {"text": "Loss CE CE CE CE CE Margin ( MR ) - - - - ` pnorm ( TransE ) - 2 - - Optimizer Adagrad Adagrad Adam Adagrad Adagrad Batch size 128 128 1024 512 256 Learning rate 0:0452 0 : 0412 0 : 0003 0 : 0117 0 : 0145 LR scheduler patience 7 6 7 3 1 ` pregularization 3 2 None 3 1 Entity embedding weight 2:18\u000210\u0000101:32\u000210\u000079:58\u000210\u0000133:11\u000210\u0000153:47\u000210\u000015 Relation embedding weight 3:37\u000210\u0000143:72\u000210\u0000180:0229 4 : 68\u000210\u000093:43\u000210\u000014 Frequency weighting False False True True True Embedding normalization ( TransE ) Entity - No - - Relation - No - - Dropout Entity embedding 0:0 0 :0 0 : 0793 0 :0 0 : 1895 Relation embedding 0:0804 0 :0 0 : 0564 0 :0 0 :0 Feature map ( ConvE ) - - - 0:2062", "entities": [[8, 9, "DatasetName", "MR"], [17, 18, "MethodName", "TransE"], [23, 24, "HyperparameterName", "Optimizer"], [24, 25, "MethodName", "Adagrad"], [25, 26, "MethodName", "Adagrad"], [26, 27, "MethodName", "Adam"], [27, 28, "MethodName", "Adagrad"], [28, 29, "MethodName", "Adagrad"], [29, 31, "HyperparameterName", "Batch size"], [36, 38, "HyperparameterName", "Learning rate"], [39, 40, "DatasetName", "0"], [42, 43, "DatasetName", "0"], [45, 46, "DatasetName", "0"], [48, 49, "DatasetName", "0"], [87, 88, "MethodName", "TransE"], [99, 100, "MethodName", "Dropout"], [103, 104, "DatasetName", "0"], [105, 106, "DatasetName", "0"], [108, 109, "DatasetName", "0"], [110, 111, "DatasetName", "0"], [116, 117, "DatasetName", "0"], [118, 119, "DatasetName", "0"], [121, 122, "DatasetName", "0"], [123, 124, "DatasetName", "0"]]}, {"text": "Projection ( ConvE ) - - - 0:1709", "entities": []}, {"text": "Embedding initialization Normal XvNorm XvNorm XvNorm XvNorm Stdev ( Normal ) 0:0622 - - - Interval ( Unif ) - - - - Gain ( XvNorm ) - 1:0 1 :0 1 :0 1 :0 Gain ( XvUnif ) - - - - -", "entities": []}, {"text": "8347Table 12 : Best link prediction hyperparameter con\ufb01gurations on CODEX - M. RESCAL TransE ComplEx ConvE TuckER", "entities": [[4, 6, "TaskName", "link prediction"], [12, 13, "MethodName", "RESCAL"], [13, 14, "MethodName", "TransE"], [16, 17, "MethodName", "TuckER"]]}, {"text": "Best validation MRR 0:3173 0", "entities": [[2, 3, "MetricName", "MRR"], [4, 5, "DatasetName", "0"]]}, {"text": ": 2993 0 : 3351 0 : 3146 0 :", "entities": [[2, 3, "DatasetName", "0"], [5, 6, "DatasetName", "0"], [8, 9, "DatasetName", "0"]]}, {"text": "3253 Embedding size 256 512 512 512 512 Training type 1vsAll", "entities": []}, {"text": "NegSamp KvsAll NegSamp KvsAll Reciprocal", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes # head samples ( NegSamp ) - 2 - 381 # tail samples ( NegSamp ) - 56 - 751 Label smoothing ( KvsAll ) - -", "entities": [[21, 23, "MethodName", "Label smoothing"]]}, {"text": "0:2081 - 0:0950", "entities": []}, {"text": "Loss CE CE CE CE CE Margin ( MR ) - - - - ` pnorm ( TransE ) - 2 - - Optimizer Adagrad Adagrad Adagrad Adagrad Adagrad Batch size 256 128 1024 128 256 Learning rate 0:0695 0 : 0412 0 : 2557 0 : 0024 0 : 0145 LR scheduler patience 8 6 6 9 1 ` pregularization 2 2 3 1 1 Entity embedding weight 9:56\u000210\u000071:32\u000210\u000071:34\u000210\u0000101:37\u000210\u0000103:47\u000210\u000015", "entities": [[8, 9, "DatasetName", "MR"], [17, 18, "MethodName", "TransE"], [23, 24, "HyperparameterName", "Optimizer"], [24, 25, "MethodName", "Adagrad"], [25, 26, "MethodName", "Adagrad"], [26, 27, "MethodName", "Adagrad"], [27, 28, "MethodName", "Adagrad"], [28, 29, "MethodName", "Adagrad"], [29, 31, "HyperparameterName", "Batch size"], [36, 38, "HyperparameterName", "Learning rate"], [39, 40, "DatasetName", "0"], [42, 43, "DatasetName", "0"], [45, 46, "DatasetName", "0"], [48, 49, "DatasetName", "0"]]}, {"text": "Relation embedding weight 2:56\u000210\u0000173:72\u000210\u0000186:38\u000210\u0000164:72\u000210\u000010 3 : 4\u000210\u000014 Frequency weighting False False True True True Embedding normalization ( TransE ) Entity - No - - Relation - No - - Dropout Entity embedding 0:0 0 :0 0 : 1196 0 :0 0 : 1895 Relation embedding 0:0 0 :0 0 : 3602 0 : 0348 0 :0 Feature map ( ConvE ) - - - 0:3042 Projection ( ConvE ) - - - 0:2343 Embedding initialization XvUnif XvUnif Unif XvNorm XvNorm Stdev ( Normal ) - - - - Interval ( Unif ) - - \u00000:8133 - Gain ( XvNorm ) - - - 1:0 1 :0 Gain ( XvUnif ) 1:0 1 :0 - - -", "entities": [[17, 18, "MethodName", "TransE"], [29, 30, "MethodName", "Dropout"], [33, 34, "DatasetName", "0"], [35, 36, "DatasetName", "0"], [38, 39, "DatasetName", "0"], [40, 41, "DatasetName", "0"], [46, 47, "DatasetName", "0"], [48, 49, "DatasetName", "0"], [51, 52, "DatasetName", "0"], [54, 55, "DatasetName", "0"]]}, {"text": "8348Table 13 : Best link prediction hyperparameter con\ufb01gurations on CODEX - L. RESCAL TransE ComplEx ConvE TuckER Best validation MRR 0:3030 0 : 1871 0 : 2943 0 : 3010 0 : 3091 Embedding size 128 128 128 256 256 Training type 1vsAll", "entities": [[4, 6, "TaskName", "link prediction"], [12, 13, "MethodName", "RESCAL"], [13, 14, "MethodName", "TransE"], [16, 17, "MethodName", "TuckER"], [19, 20, "MetricName", "MRR"], [21, 22, "DatasetName", "0"], [24, 25, "DatasetName", "0"], [27, 28, "DatasetName", "0"], [30, 31, "DatasetName", "0"]]}, {"text": "NegSamp 1vsAll 1vsAll 1vsAll Reciprocal", "entities": []}, {"text": "No", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes", "entities": []}, {"text": "Yes No # head samples ( NegSamp ) - 209 - - # tail samples ( NegSamp ) - 2 - - Label smoothing ( KvsAll ) - - - - Loss CE CE CE CE CE Margin ( MR ) - - - - ` pnorm ( TransE ) - 2 - - Optimizer Adagrad Adam Adagrad Adagrad Adagrad Batch size 1024 128 1024 256 512 Learning rate 0:2651 0 : 0009 0 : 2651 0 : 0329 0 : 0196 LR scheduler patience 7 9 7 1 4 ` pregularization 2 2 2 1 2 Entity embedding weight 2:01\u000210\u0000167:98\u000210\u0000142:01\u000210\u0000166:10\u000210\u0000168:06\u000210\u000011 Relation embedding weight 3:52\u000210\u0000133:42\u000210\u000093:52\u000210\u0000131:03\u000210\u0000167:19\u000210\u000019 Frequency weighting True False True True True Embedding normalization ( TransE ) Entity - No - - Relation - No - - Dropout Entity embedding 0:0 0 :0 0 :0 0 : 0064 0 : 1606 Relation embedding 0:0 0 :0 0 :0 0 :0 0 : 0857 Feature map ( ConvE ) - - - 0:1530 Projection ( ConvE ) - - - 0:4192", "entities": [[22, 24, "MethodName", "Label smoothing"], [39, 40, "DatasetName", "MR"], [48, 49, "MethodName", "TransE"], [54, 55, "HyperparameterName", "Optimizer"], [55, 56, "MethodName", "Adagrad"], [56, 57, "MethodName", "Adam"], [57, 58, "MethodName", "Adagrad"], [58, 59, "MethodName", "Adagrad"], [59, 60, "MethodName", "Adagrad"], [60, 62, "HyperparameterName", "Batch size"], [67, 69, "HyperparameterName", "Learning rate"], [70, 71, "DatasetName", "0"], [73, 74, "DatasetName", "0"], [76, 77, "DatasetName", "0"], [79, 80, "DatasetName", "0"], [115, 116, "MethodName", "TransE"], [127, 128, "MethodName", "Dropout"], [131, 132, "DatasetName", "0"], [133, 134, "DatasetName", "0"], [135, 136, "DatasetName", "0"], [138, 139, "DatasetName", "0"], [144, 145, "DatasetName", "0"], [146, 147, "DatasetName", "0"], [148, 149, "DatasetName", "0"], [150, 151, "DatasetName", "0"]]}, {"text": "Embedding initialization Normal Unif Normal XvNorm Normal Stdev ( Normal ) 0:0169 - 0:0169 - 0:0002 Interval ( Unif ) - \u00000:4464 - Gain ( XvNorm ) - - 1:0 Gain ( XvUnif ) - - - -", "entities": []}, {"text": "8349Table 14 : Best triple classi\ufb01cation hyperparameter con\ufb01gurations on CODEX - S(hard negatives ) .", "entities": []}, {"text": "RESCAL TransE ComplEx ConvE TuckER Best validation accuracy 0:8571 0 : 8511 0 : 8558 0 : 8607 0 : 8596 Embedding size See Tab . 11 See Tab . 11 See Tab .", "entities": [[0, 1, "MethodName", "RESCAL"], [1, 2, "MethodName", "TransE"], [4, 5, "MethodName", "TuckER"], [7, 8, "MetricName", "accuracy"], [9, 10, "DatasetName", "0"], [12, 13, "DatasetName", "0"], [15, 16, "DatasetName", "0"], [18, 19, "DatasetName", "0"]]}, {"text": "11 512 See Tab . 11 Training type 1vsAll", "entities": []}, {"text": "NegSamp 1vsAll 1vsAll KvsAll Reciprocal See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11", "entities": []}, {"text": "Yes See Tab .", "entities": []}, {"text": "11 # head samples ( NegSamp ) - See Tab . 11 - - # tail samples ( NegSamp ) - See Tab . 11 - - Label smoothing ( KvsAll ) - - - - Loss CE CE CE BCE CE Margin ( MR ) - - - - ` pnorm ( TransE ) - See Tab .", "entities": [[27, 29, "MethodName", "Label smoothing"], [44, 45, "DatasetName", "MR"], [53, 54, "MethodName", "TransE"]]}, {"text": "11 - - Optimizer See Tab . 11 See Tab . 11 See Tab .", "entities": [[3, 4, "HyperparameterName", "Optimizer"]]}, {"text": "11 Adagrad See Tab . 11 Batch size See Tab . 11 See Tab . 11 See Tab .", "entities": [[1, 2, "MethodName", "Adagrad"], [6, 8, "HyperparameterName", "Batch size"]]}, {"text": "11 256 See Tab . 11 Learning rate See Tab . 11 See Tab . 11 See Tab . 11 0:0263 See Tab . 11 LR scheduler patience See Tab . 11 See Tab . 11 See Tab .", "entities": [[6, 8, "HyperparameterName", "Learning rate"]]}, {"text": "11 7See Tab .", "entities": []}, {"text": "11 ` pregularization See Tab . 11 See Tab . 11 See Tab . 11 2See Tab .", "entities": []}, {"text": "11 Entity embedding weight See Tab . 11 See Tab . 11 See Tab . 11 9:62\u000210\u00006See Tab .", "entities": []}, {"text": "11 Relation embedding weight See Tab . 11 See Tab . 11 See Tab . 11 1:34\u000210\u000012See Tab . 11 Frequency weighting See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 False See Tab .", "entities": []}, {"text": "11 Embedding normalization ( TransE ) Entity - See Tab . 11 - - Relation - See Tab . 11 - - Dropout Entity embedding See Tab . 11 See Tab . 11 See Tab . 11 0:1620 See Tab .", "entities": [[4, 5, "MethodName", "TransE"], [22, 23, "MethodName", "Dropout"]]}, {"text": "11 Relation embedding See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 0:0031 See Tab . 11 Feature map ( ConvE ) - - - 0:0682 Projection ( ConvE ) - - - 0:2375", "entities": []}, {"text": "Embedding initialization See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 Normal See Tab . 11 Stdev ( Normal ) See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 0:0006 See Tab . 11 Interval ( Unif ) See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 - See Tab . 11 Gain ( XvNorm ) See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 - See Tab . 11 Gain ( XvUnif ) See Tab . 11 See Tab . 11 See Tab .", "entities": []}, {"text": "11 - See Tab .", "entities": []}, {"text": "11", "entities": []}, {"text": "8350Table 15 : Best triple classi\ufb01cation hyperparameter con\ufb01gurations on CODEX - M(hard negatives ) .", "entities": []}, {"text": "RESCAL TransE ComplEx ConvE TuckER Best validation accuracy 0:8232 0 : 8002 0 : 8267 0 : 8292 0 : 8267 Embedding size 512 See Tab . 12 512 512 See Tab .", "entities": [[0, 1, "MethodName", "RESCAL"], [1, 2, "MethodName", "TransE"], [4, 5, "MethodName", "TuckER"], [7, 8, "MetricName", "accuracy"], [9, 10, "DatasetName", "0"], [12, 13, "DatasetName", "0"], [15, 16, "DatasetName", "0"], [18, 19, "DatasetName", "0"]]}, {"text": "12 Training type KvsAll NegSamp KvsAll KvsAll KvsAll Reciprocal Yes See Tab .", "entities": []}, {"text": "12", "entities": []}, {"text": "Yes Yes See Tab .", "entities": []}, {"text": "12 # head samples ( NegSamp ) - See Tab . 12 - - # tail samples ( NegSamp ) - See Tab . 12 - - Label smoothing ( KvsAll ) 0:0949 - 0:2081 0 : 0847 Loss CE CE CE CE CE Margin ( MR ) - - - - ` pnorm ( TransE ) - See Tab . 12 - - Optimizer Adagrad See Tab .", "entities": [[27, 29, "MethodName", "Label smoothing"], [35, 36, "DatasetName", "0"], [46, 47, "DatasetName", "MR"], [55, 56, "MethodName", "TransE"], [64, 65, "HyperparameterName", "Optimizer"], [65, 66, "MethodName", "Adagrad"]]}, {"text": "12 Adagrad Adagrad See Tab . 12 Batch size 256 See Tab . 12 1024 1024 See Tab . 12 Learning rate 0:0144", "entities": [[1, 2, "MethodName", "Adagrad"], [2, 3, "MethodName", "Adagrad"], [7, 9, "HyperparameterName", "Batch size"], [20, 22, "HyperparameterName", "Learning rate"]]}, {"text": "See Tab .", "entities": []}, {"text": "12 0:2557 0 : 0378 See Tab . 12 LR scheduler patience 1See Tab .", "entities": [[2, 3, "DatasetName", "0"]]}, {"text": "12 6 6 See Tab . 12 ` pregularization 1See Tab . 12 3 3 See Tab .", "entities": []}, {"text": "12 Entity embedding weight 3:47\u000210\u000015See Tab . 12 1:34\u000210\u0000101:03\u000210\u000016See Tab .", "entities": []}, {"text": "12 Relation embedding weight 3:43\u000210\u000014See Tab . 12 6:38\u000210\u0000160:0052 See Tab . 12 Frequency weighting True See Tab .", "entities": []}, {"text": "12 True True See Tab .", "entities": []}, {"text": "12 Embedding normalization ( TransE ) Entity - See Tab . 12 - - Relation - See Tab . 12 - - Dropout Entity embedding 0:1895", "entities": [[4, 5, "MethodName", "TransE"], [22, 23, "MethodName", "Dropout"]]}, {"text": "See Tab .", "entities": []}, {"text": "12 0:1196 0 : 4828 See Tab .", "entities": [[2, 3, "DatasetName", "0"]]}, {"text": "12 Relation embedding 0:0See Tab . 12 0:3602 0 : 0See Tab . 12 Feature map ( ConvE ) - - - 0:2649 Projection ( ConvE ) - - - 0:2790 Embedding initialization XvNorm See Tab . 12 Unif XvUnif See Tab . 12 Stdev ( Normal ) - See Tab . 12 - - See Tab . 12 Interval ( Unif ) - See Tab . 12 \u00000:8133 - See Tab . 12 Gain ( XvNorm ) 1:0See Tab . 12 - - See Tab . 12 Gain ( XvUnif ) - See Tab . 12 - 1:0See Tab .", "entities": [[8, 9, "DatasetName", "0"]]}, {"text": "12", "entities": []}]