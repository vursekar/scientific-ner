[{"text": "Proceedings of the First Conference on Machine Translation , Volume 2 : Shared Task Papers , pages 456\u2013462 , Berlin , Germany , August 11 - 12 , 2016 .", "entities": [[6, 8, "TaskName", "Machine Translation"]]}, {"text": "c", "entities": []}, {"text": "2016 Association for Computational Linguistics English - Portuguese Biomedical Translation Task Using a Genuine Phrase - Based Statistical Machine Translation Approach Jos\u00b4e Aires1,2Gabriel Pereira Lopes1,2 1NOV", "entities": [[9, 10, "TaskName", "Translation"], [18, 20, "TaskName", "Machine Translation"]]}, {"text": "A LINCS , Faculdade de Ci \u02c6encias e Tecnologia , Universidade Nova de Lisboa , Portugal 2ISTRION BOX , Translation and Revision , Lda , Portugal { jose.aires , gabriel.lopes , luis.gomes } @istrionbox.comLu\u00b4\u0131s Gomes1,2", "entities": [[19, 20, "TaskName", "Translation"]]}, {"text": "Abstract", "entities": []}, {"text": "Our approach to produce translations for the ACL-2016 Biomedical Translation Task on the English - Portuguese language pair , in both directions , is described .", "entities": [[9, 10, "TaskName", "Translation"]]}, {"text": "Own preliminary tests results and \ufb01nal results , measured by the shared task organizers , are also presented .", "entities": []}, {"text": "1 Introduction This paper shows how we obtained our results using our patented Machine Translation system ( Lopes et al . , 2015 ) to produce translations for the English - Portuguese language pair from the Biomedical Translation Task .", "entities": [[13, 15, "TaskName", "Machine Translation"], [37, 38, "TaskName", "Translation"]]}, {"text": "Our approach differs from common Statistical Machine Translation approaches like Moses ( Koehn et al . , 2007 ) in several aspects : \u2022phrases are not analyzed at their word level in any model ; \u2022the language model depends on the target alternatives of given adjacent sources and does not try to avoid null scores to phrases that do not occur ; \u2022the translation score is not log - linear , but instead a tuned weighted average between the translation model and the language model , and so no smoothing techniques are required ; \u2022several models can be used with different relevances or weights ; and \u2022instead of simply relying on statistics , we include human validation and correction on several stages of the system , namely for validating extracted term translations , to improve the quality of the source data used in the automatically produced translations .", "entities": [[6, 8, "TaskName", "Machine Translation"]]}, {"text": "As requested , the translation results were produced using the sentence - aligned training data described below ( for the English - Portuguese language pair , in our case ) , provided by the shared task organizers : \u2022medline - pubmed : parallel corpora from medline ; \u2022scielo - gma - biological : parallel biological documents from the Scielo database ( Neves et al . , 2016 ) ; and \u2022scielo - gma - health : parallel health documents from the Scielo database ( Neves et al . , 2016 ) .", "entities": []}, {"text": "Table 1 shows the features of the English ( en ) and Portuguese ( pt ) languages of each provided corpora , namely their number of lines and words .", "entities": []}, {"text": "corpus lines words medline - pubmed - en 74,645 917,307 medline - pubmed - pt 74,645 1,041,079 scielo - gma - biological - en 120,301 3,338,244 scielo - gma - biological - pt 120,301 3,736,817 scielo - gma - health - en 507,987 13,443,076 scielo - gma - health - pt 507,987 14,901,240 Table 1 : Training corpora data after normalization .", "entities": []}, {"text": "The translation task then consisted in translating one document from English to Portuguese and another from Portuguese to English , for both the biological and the health domains , with the number of lines and words from those test documents shown in Table 2 .", "entities": []}, {"text": "Besides the provided training data , we have also included our English and European Portuguese bilingual lexicon ( described in \u00a7 2.3.2 ) , as well as our named entities database , for additional term coverage.456", "entities": []}, {"text": "document lines words biological pt2en 4,029 119,410 biological en2pt 4,333 111,038 health pt2en 3,826 111,073 health en2pt 3,858 96,240 Table 2 : Test documents data after normalization .", "entities": []}, {"text": "The training corpora had to undergo several processing stages in order to support the production of the intended translations , as described in the following section .", "entities": []}, {"text": "2 Data Processing In order to produce translations , our system ( like any other Statistical Machine Translation system ) requires a translation model and a language model to support the translation decoding stage .", "entities": [[16, 18, "TaskName", "Machine Translation"]]}, {"text": "To calculate such models the available data had to go through several processing steps described in the following subsections .", "entities": []}, {"text": "Since each of the training corpus has been made available separately , we also opted to process each of them separately so that we were then able to use them with different weights , assigning more or less weight to models with higher or lower relevance , respectively .", "entities": []}, {"text": "See extended explanation in \u00a7 4 . 2.1 Considerations about the provided data It should be noted that we have detected a few \ufb02aws in the provided data , namely several sentences incorrectly considered as parallel , as well as the existence of many spelling errors , not only in the training data , but also in the testing documents .", "entities": []}, {"text": "We believe that many of the typos result from PDF extraction and/or OCR processes , which are never perfect , having found and corrected a total of 127,198 misspellings .", "entities": []}, {"text": "Yet , it should be noted that some misspelling errors are easy to correct , but errors which still produce correct words require sentence analysis which was not carried out .", "entities": []}, {"text": "Some of the parallel problems are illustrated , for instance , by having the \ufb01rst Portuguese line from medline - pubmed \u201c ERRATA . \u201d", "entities": []}, {"text": "aligned with the \ufb01rst English line \u201c Inequalities in self - rated health : an analysis of the Brazilian and Portuguese populations . \u201d , which should be \u201c ERRATA . \u201d", "entities": []}, {"text": "instead .", "entities": []}, {"text": "Filtering wrong translation units as the oneabove , as well as translation units which the language was not Portuguese , reduced this corpora by almost 2,000 translation units .", "entities": []}, {"text": "Some errors were simply detected by chance , like \ufb01rst and last entries of medline - pubmed , while other errors were detected by looking at the untranslated terms in the initial testing \u00a7 3 and realizing that some terms were misspellings , as well as spelling and vocabulary differences between European and Brazilian Portuguese .", "entities": []}, {"text": "corpus lines words medline - pubmed - en 74,645 917,307 medline - pubmed - rev - en 72,651 898,051 medline - pubmed - pt 74,645 1,041,079 medline - pubmed - rev - pt 72,651 1,006,069 Table 3 : medline - pubmed revision impact .", "entities": []}, {"text": "Table 3 shows the differences between the original version medline - pubmed and its revised version medline - pubmed - rev .", "entities": []}, {"text": "The reduction in size towards the revised version is mainly due to the removal of non - parallel sentences .", "entities": []}, {"text": "However , efforts to correct such situations were only made over the mentioned medline - pubmed parallel document set , since the other sets were signi\ufb01cantly larger , as shown in Table 1 .", "entities": []}, {"text": "Also , no corrections were applied to the testing documents because we assumed they were not supposed to be edited .", "entities": []}, {"text": "Yet , another \u201c noise \u201d element was the already mentioned difference in spelling and vocabulary between European Portuguese ( which has been our main focus of attention throughout our research experience ) and Brazilian Portuguese ( the version of the provided biomedical data ) , which can also impact results negatively .", "entities": []}, {"text": "2.2 Text tokenization and normalization Text tokenization ensures that words are properly separated by a single blank space , while normalization ensures that they are represented by a \u201c standard \u201d version .", "entities": []}, {"text": "In English , this means that cases like \u201c was n\u2019t \u201d or \u201c is n\u2019t \u201d are going to be replaced by \u201c was not \u201d and \u201c is not \u201d , respectively .", "entities": []}, {"text": "In Portuguese , this means that cases like \u201c do \u201d ( of the ) or \u201c nas \u201d ( in the ) are going to be replaced by \u201c de o \u201d ( of the ) and \u201c em as \u201d ( in the ) , respectively .", "entities": []}, {"text": "These tokenization and normalization changes are reverted when presenting the \ufb01nal translation results.457", "entities": []}, {"text": "Whipple disease and central nervous system .Doen\u00e7a", "entities": []}, {"text": "de Whipple e sistema nervoso", "entities": []}, {"text": "central .", "entities": []}, {"text": "Figure 1 : Example lexicon- and cognate - based alignment of a short sentence from the medlinepubmed corpus .", "entities": []}, {"text": "Gray-\ufb01lled rectangles represent word- and phrasal - matches from the lexicon while the checkerboard-\ufb01lled rectangle shows a cognaticity - based match .", "entities": []}, {"text": "2.3 Phrase alignment Phrase - level alignment was obtained with a modi\ufb01ed version of the lexicon - based aligner proposed by Gomes ( 2009 ) .", "entities": []}, {"text": "The aligner matches bilingual phrase pairs provided in an input lexicon ( described ahead in\u00a72.3.2 ) and selects a maximalcoverage1subset of coherent alignments .", "entities": []}, {"text": "While the original method imposed a monotonicity constraint , i.e. it selected a maximal - coverage chain of phrase alignments without allowing phrase reorderings , the new method applied has a more relaxed coherency criteria : it only requires that a source - language phrase is not simultaneously aligned with two distinct target - language phrases .", "entities": []}, {"text": "Therefore , it allows phrase reordering as shown in the example in Figure 1 . 2.3.1 Alignment as an optimization problem Similar to the ILP ( Integer Linear Programming ) solution proposed by ( DeNero and Klein , 2008 ) , we treat the alignment problem as an optimization problem , but we employ a greedy optimization algorithm which allows us to align longer sentences with reasonable time and memory .", "entities": []}, {"text": "The algorithm 1Maximal - coverage means that the selected phrase alignments cover as much text as possible from both sentencesconstructs a solution ( a set of coherent alignments ) incrementally .", "entities": []}, {"text": "It starts by settling alignments of longer phrases , which tend to be more reliable , and progresses towards shorter phrases or words , which are allowed to align only if they are coherent with previously settled alignments .", "entities": []}, {"text": "2.3.2", "entities": []}, {"text": "Input bilingual lexicon Our EN - PT input lexicon has 931,568 manually validated translations ( words and phrases ) .", "entities": []}, {"text": "This lexicon has been compiled in a long term effort started in the context of project ISTRION2 .", "entities": []}, {"text": "The translations were extracted automatically from several corpora , including Europarl ( Koehn and Monz , 2005 ) , JRC - Acquis ( Steinberger et al . , 2006 ) , OPUS EMEA ( Tiedemann , 2009 ) and others , using a combination of complementary alignment and extraction methods : GIZA ( Och and Ney , 2003 ) , Anymalign ( Lardilleux and Lepage , 2009 ) , spelling similarity measure SpSim ( Gomes and Lopes , 2011 ) combined with co - occurrence Dice measure , and others .", "entities": [[32, 33, "MethodName", "EMEA"], [85, 86, "MetricName", "Dice"]]}, {"text": "The automatically extracted word and phrasal translations were automatically classi\ufb01ed , prior to human validation , using an SVM classi\ufb01er trained on previously validated translations as described by Mahesh et", "entities": [[18, 19, "MethodName", "SVM"]]}, {"text": "al . ( 2015 ) .", "entities": []}, {"text": "The automatic classi\ufb01cation speeds up human validation because very few translations ( less than 5 % ) are incorrectly classi\ufb01ed , and only those need to be manually labeled as correct or incorrect .", "entities": []}, {"text": "We did not perform any extraction or validation of new translations from the corpus provided for this shared task .", "entities": []}, {"text": "We did , however , complement our lexicon with cognate and homograph alignments using the SpSim ( Gomes and Lopes , 2011 ) spelling similarity measure .", "entities": []}, {"text": "2.3.3 Lexicon coverage Our lexicon covers 59.5 % of the EN corpus tokens and 55.4 % of the PT corpus tokens .", "entities": []}, {"text": "There were 143,317 unique phrasal translations matched out of 931,568 in our lexicon .", "entities": []}, {"text": "The cognaticity - based matching was responsible for aligning 8 % of the EN corpus and 7.2 % of the PT corpus3 .", "entities": []}, {"text": "The remainder 32.5 % of the EN corpus and 37.4 % of the PT corpus were left unaligned .", "entities": []}, {"text": "These unaligned tokens are handled as gaps by the phrase table extraction algorithm described in ( Aires et al . , 2009 ) .", "entities": []}, {"text": "2Project ISTRION was funded by the Portuguese Foundation for Science and Technology under contract PTDC / EIAEIA/114521/2009 3cognaticity alignment was applied only to tokens not covered by the input lexicon458", "entities": []}, {"text": "2.4 Language model training The language model used is supported by the indexation of the texts in each language of the provided corpora .", "entities": []}, {"text": "Such indexation will support determining the likelihood of the occurrence of phrases in the target language for the several adjacent translation fragments in decoding , a process based on the structures presented in ( Aires et al . , 2008 ) .", "entities": []}, {"text": "2.5 Translation model training The translation model depends on the alignment to determine phrase translation equivalents by establishing phrase relations between source and target languages , as well as to determine a degree of likelihood of those same relations , to be used in decoding to produce new translations , a process based on the methodology presented in ( Aires et al . , 2009 ) .", "entities": [[1, 2, "TaskName", "Translation"]]}, {"text": "2.6 Decoding The decoding stage is the one that will \ufb01nally produce the actual translations .", "entities": []}, {"text": "First , an original text is fragmented into smaller pieces of text , which will then be used to retrieve their corresponding translations .", "entities": []}, {"text": "The several combinations of the translations of those smaller pieces will represent many possible translations and the purpose of decoding is to \ufb01nd the most likely one , according to the provided scores from the language and the translation models .", "entities": []}, {"text": "As mentioned before , separate models can be obtained from separate corpora and be assigned with different relevances or weights , according to their importance to the translation in question .", "entities": []}, {"text": "As such , and as explained in Lopes et al . ( 2015 ) , decoding is carried out as a best path \ufb01nding in a directed acyclic graph , where its edges are weighed by : the translation model score between source and target phrases ; and the language model scores between adjacent target phrases .", "entities": []}, {"text": "Each complete path will represent a possible translation in which the \ufb01nal score is a composition of the scores of the several edges that compose the given path .", "entities": []}, {"text": "An additional penalty is introduced to provide lower scores to larger paths , which are known to produce worse results .", "entities": []}, {"text": "3 Initial Testing Preparation Since no development data was supplied , we took the initiative to prepare some development sets in order to have an idea of the most promising set ofparameters to be used in our system over the provided data to produce the intended translations .", "entities": []}, {"text": "As such , several documents were removed from the original training data , composed by the medlinepubmed , biological and health sets , applying the training methods on the remaining documents and using the selected ones to translate and compare the translations against their originals by determining their BLEU ( Papineni et", "entities": [[48, 49, "MetricName", "BLEU"]]}, {"text": "al . , 2002 ) scores .", "entities": []}, {"text": "However , in order to get a clearer picture of the type of results that could be expected , some additional tests were carried out including the selected set of documents in the training data .", "entities": []}, {"text": "Our translation model supports : a conservative extraction approach , which is more restrictive , allowing fewer translation equivalents , having a lower recall but a higher precision ; and a \ufb02exible extraction approach , which is more permissive , allowing a larger number of equivalents but at the cost of an increase of incorrect ones .", "entities": []}, {"text": "We were interested in evaluating the impact of both approaches on results .", "entities": []}, {"text": "Table 4 shows the average results on both translation directions of those preliminary tests , consisting of the average BLEU scores for the conservative ( cons . )", "entities": [[19, 20, "MetricName", "BLEU"]]}, {"text": "and \ufb02exible ( \ufb02ex . )", "entities": []}, {"text": "approaches , as well as the average times taken to translate the documents on either extraction approaches .", "entities": []}, {"text": "Those results concern the following con\ufb01gurations : \u2022full : the documents used for testing were not removed from the training set ( medlinepubmed , biological and health ) ; \u2022dev : the documents used for testing were removed form the training set ; \u2022dev - europarl : the same as dev , but including the europarl corpus ; and \u2022dev - europarl - low : the same as dev - europarl , but assigned a lower relevance to the europarl corpus .", "entities": []}, {"text": "con\ufb01guration cons .", "entities": []}, {"text": "\ufb02ex . time full 83.98 81.97 15.1 s dev 51.72 55.46 3.5 s dev - europarl 52.34 55.98 49.9 s dev - europarl - low 52.54 56.21 46.8 s Table 4 : Initial testing results.459", "entities": []}, {"text": "These preliminary tests have shown that the \ufb02exible extraction approach produced on average better translation results when the reference documents were not included in the test set , which is the normal testing situation , so we used the \ufb02exible approach .", "entities": []}, {"text": "The Europarl corpus4 , which is signi\ufb01cantly larger ( 54,543,044 words in English and 60,375,477 words in Portuguese ) , was tested as a source of additional term coverage , which allowed a translation quality improvement lower than 1 BLEU point .", "entities": [[39, 40, "MetricName", "BLEU"]]}, {"text": "However , given its signi\ufb01cant increase in processing time because of its large size , a time increase around 14 times larger , we had to drop it from the submission tests due to deadline constraints .", "entities": []}, {"text": "Additionally , these results show that assigning a lower relevance to a corpus from a totally different domain may have some positive impact on average results .", "entities": []}, {"text": "Once we have decided , from this initial testing preparation , which would be the most promising and interesting features to use in the \ufb01nal runs , we ran the training processes again to include the documents that have been left out , this way using the full data provided by the organizers for the runs to be submitted .", "entities": []}, {"text": "4 Submitted Results Considering that the test documents to be translated , provided by the shared task organization , share their domain with the training data , we decided to propose for submission the three possible translation runs for each document according to the criteria described in each of the following subsections .", "entities": []}, {"text": "4.1 Run 1 This run uses the medline - pubmed , biological and health training corpora with the same relevance to translate every translation test document .", "entities": []}, {"text": "These can be considered our simplest set of tests since the possible model relevance difference is not explored and no additional sources are included .", "entities": []}, {"text": "In this case we achieved a total of 7228 unique untranslated terms5 .", "entities": []}, {"text": "4.2 Run 2 This run also uses the medline - pubmed , biological and health training corpora , but assigns a higher 4http://www.statmt.org/europarl/ 5Terms can have one or more wordsrelevance to the biological corpora to translate the biological test documents and then assigns a higher relevance to the health corpora to translate the health test documents .", "entities": []}, {"text": "Because the changes introduced in this set of tests only concerned the relevance of the models , the total of 7228 unique untranslated terms did not change .", "entities": []}, {"text": "4.3 Run 3", "entities": []}, {"text": "This last run shares the same features as the previous run ( assigning higher relevances to corresponding corpora ) but this time our bilingual lexicon and named entities database was included for term coverage improvement , and an alignment based on cognates ( Gomes and Lopes , 2011 ) is used .", "entities": []}, {"text": "About our bilingual lexicon , considering that it was built mainly from the European legislation , it was given a lower relevance because past experiences have shown us that , when the domain is not shared with the texts to be translated , it should not have the same relevance in order to reduce the probability of using inadequate terms for the intended translation domain or subject .", "entities": []}, {"text": "Again , this is a situation that has also been con\ufb01rmed and noted in Table 4 between dev - europarl and deveuroparl - low : reducing the relevance of europarl contributed to a slight score increase compared to when the relevance is the same .", "entities": []}, {"text": "As a side note , translating the tests took nearly 14 hours for each run6 .", "entities": []}, {"text": "Had we included europarl , judging by Table 4 , we would have taken nearly 200 hours , which is more than a week , expecting to simply gain 0.75 BLEU points , on average , so we had no other option than leaving it out .", "entities": [[30, 31, "MetricName", "BLEU"]]}, {"text": "Such increase in translation time is due to the substantial increase of translation equivalents available for decoding from such a large corpus .", "entities": []}, {"text": "The decision to carry out the alignment based on cognates was taken because after a \ufb01rst run of tests we realized that many of the untranslated terms referred to medical terms and diseases , which shared many letters between both languages and therefore had a high level of cognaticity .", "entities": []}, {"text": "All these changes allowed a signi\ufb01cant reduction of the unique untranslated terms to a total of 4700 , and for all the reasons in this subsection , we have considered this run as being our best .", "entities": []}, {"text": "6On a 3.3GHz CPU with 32 GB RAM and 4 TB disk460", "entities": [[7, 8, "MethodName", "RAM"]]}, {"text": "5 Conclusions and Future Work", "entities": []}, {"text": "The scores of our submitted translations are shown in Table 5 . .run", "entities": []}, {"text": "score Istrionbox run1 biological en2pt 17.55 Istrionbox run2 biological en2pt 16.47 Istrionbox run3 biological en2pt 16.45 Average 16.80 Istrionbox run1 biological pt2en 20.88 Istrionbox run2 biological pt2en 20.17 Istrionbox run3 biological pt2en 20.14 Average 20.40 Istrionbox run1 health en2pt 19.01 Istrionbox run2 health en2pt 18.33 Istrionbox run3 health en2pt 18.37 Average 18.57 Istrionbox run1 health pt2en 21.50 Istrionbox run2 health pt2en 20.17 Istrionbox run3 health pt2en 20.62 Average 20.76 Table 5 : Initial testing results .", "entities": []}, {"text": "The results obtained were clearly below what we had expected .", "entities": []}, {"text": "And what is most disturbing is the negative impact of features we expected to improve results , an expectation backed by our own tests .", "entities": []}, {"text": "However , there are a few reasons we can think of for these values , namely the way the BLEU measure has been calculated ( case sensitivity and synonyms penalty - translating \u201c home \u201d instead of \u201c house \u201d might be perfectly \ufb01ne ) , the differences between European Portuguese and Brazilian Portuguese , and the presence of several spelling and alignment errors in the training data .", "entities": [[19, 20, "MetricName", "BLEU"]]}, {"text": "Nonetheless , we can still take several actions to improve our system : namely testing both parallel corpora , health and biology , with identical weights : using Europarl and eventually EMEA corpus ; the re\ufb01nement of our phrase translation extraction ; the extraction of speci\ufb01c bilingual terminology , additionally to the use of cognaticity ; subsentence realignment after the bilingual terminology extraction , and a more ef\ufb01cient implementation of the patterns ( comparable to a hierarchical translation ) application .", "entities": [[31, 32, "MethodName", "EMEA"]]}, {"text": "Acknowledgments This work was supported by ISTRION BOX , Fundac \u00b8 \u02dcao para a Ci \u02c6encia e Tecnologia through research project ISTRION ( contract PTDC / EIAEIA/114521/2009 ) , individual PhD grants SFRH / BD/48839/2008 , SFRH / BD/65059/2009 , SFRH / BD/64371/2009 , and NOV A LINCS ( ref .", "entities": []}, {"text": "UID / CEC/04516/2013 ) .", "entities": []}, {"text": "We would also like to thank Hugo Delgado for his support .", "entities": []}, {"text": "References J. Aires , G. P. Lopes , and J. F. da Silva . 2008 .", "entities": []}, {"text": "Ef\ufb01cient multi - word expressions extractor using suf\ufb01x arrays and related structures .", "entities": []}, {"text": "pages 1\u20138 .", "entities": []}, {"text": "CIKM - ACM .", "entities": [[2, 3, "DatasetName", "ACM"]]}, {"text": "J. Aires , G. P. Lopes , and L. Gomes . 2009 .", "entities": []}, {"text": "Phrase translation extraction from aligned parallel corpora using suf\ufb01x arrays and related structures .", "entities": []}, {"text": "In Progress in Arti\ufb01cial Intelligence , volume 5816 of LNAI , pages 587\u2013597 .", "entities": []}, {"text": "Springer - Verlag Berlin Heidelberg .", "entities": []}, {"text": "J. DeNero and D. Klein .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "The complexity of phrase alignment problems .", "entities": []}, {"text": "In Proceedings of ACL08 : HLT , Short Papers , pages 25\u201328 , Columbus , Ohio , June .", "entities": []}, {"text": "ACL .", "entities": []}, {"text": "L. Gomes and G. P. Lopes .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Measuring spelling similarity for cognate identi\ufb01cation .", "entities": []}, {"text": "In Progress in Arti\ufb01cial Intelligence , volume 7026 of LNAI , pages 624\u2013633 , Lisbon , Portugal , October .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "L. Gomes . 2009 .", "entities": []}, {"text": "Parallel texts alignment .", "entities": []}, {"text": "Master \u2019s thesis , Faculdade de Ci \u02c6encias e Tecnologia , Universidade Nova de Lisboa , Monte de Caparica , Portugal .", "entities": []}, {"text": "P. Koehn and C. Monz .", "entities": []}, {"text": "2005 .", "entities": []}, {"text": "Shared task : Statistical machine translation between european languages .", "entities": [[4, 6, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the ACL Workshop on Building and Using Parallel Texts , pages 119\u2013124 .", "entities": []}, {"text": "ACL .", "entities": []}, {"text": "P. Koehn , H. Hoang , A. Birch , C. Callison - Burch , M. Federico , N. Bertoldi , B. Cowan , W. Shen , C. Moran , R. Zens , C. Dyer , O. Bojar , A. Constantin , and E. Herbst .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Moses : Open source toolkit for statistical machine translation .", "entities": [[7, 9, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions , ACL \u2019 07 , pages 177\u2013180 , Stroudsburg , PA , USA .", "entities": []}, {"text": "ACL .", "entities": []}, {"text": "A.n Lardilleux and Y .", "entities": []}, {"text": "Lepage .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Sampling - based multilingual alignment .", "entities": []}, {"text": "In Proceedings of Recent Advances in Natural Language Processing , pages 214\u2013218 , Borovets Bulgaria , 09 .", "entities": []}, {"text": "G. P. Lopes , J. Aires , and L. Gomes . 2015 .", "entities": []}, {"text": "Statistical machine translation computer system and method .", "entities": [[1, 3, "TaskName", "machine translation"]]}, {"text": "Submitted at National ( Portugal ) Level ( INPI ) , 8 .", "entities": []}, {"text": "Provisional Patent Request No . 0151000065353.461", "entities": []}, {"text": "K. Mahesh , L. Gomes , J. Aires , and G. P. Lopes . 2015 .", "entities": []}, {"text": "Selecting translation candidates for parallel corpora alignment .", "entities": []}, {"text": "In Progress in Arti\ufb01cial Intelligence , volume 9273 of LNAI , pages 723\u2013734 , Coimbra , Portugal , September .", "entities": []}, {"text": "Springer .", "entities": []}, {"text": "M. Neves , A. J. Yepes , and A. N \u00b4 ev\u00b4eol . 2016 .", "entities": []}, {"text": "The scielo corpus : a parallel corpus of scienti\ufb01c publications for biomedicine .", "entities": []}, {"text": "In Nicoletta Calzolari ( Conference Chair ) , Khalid Choukri , Thierry Declerck , Sara Goggi , Marko Grobelnik , Bente Maegaard , Joseph Mariani , Helene Mazo , Asuncion Moreno , Jan Odijk , and Stelios Piperidis , editors , Proceedings of the Tenth International Conference on Language Resources and Evaluation ( LREC 2016 ) , Paris , France , may .", "entities": []}, {"text": "European Language Resources Association ( ELRA ) .", "entities": []}, {"text": "F. J. Och and H. Ney .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "A systematic comparison of various statistical alignment models .", "entities": []}, {"text": "Computational Linguistics , 29(1):19\u201351 .", "entities": []}, {"text": "K. Papineni , S. Roukos , T. Ward , and Wei - Jing Zhu . 2002 .", "entities": []}, {"text": "Bleu : A method for automatic evaluation of machine translation .", "entities": [[0, 1, "MetricName", "Bleu"], [8, 10, "TaskName", "machine translation"]]}, {"text": "In Proceedings of the 40th Annual Meeting on ACL , ACL \u2019 02 , pages 311\u2013318 , Stroudsburg , PA , USA .", "entities": []}, {"text": "ACL .", "entities": []}, {"text": "R. Steinberger , B. Pouliquen , A. Widiger , C. Ignat , T. Erjavec , D. Tu\ufb01s , and D. Varga .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "The jrcacquis : A multilingual aligned parallel corpus with 20 + languages .", "entities": []}, {"text": "In Proceedings of LREC\u20192006 pp .", "entities": []}, {"text": "2142 - 2147 .", "entities": []}, {"text": "Genoa , Italy , 24 - 26 May 2006 , Genoa , Italy , 5 . ELRA .", "entities": []}, {"text": "J. Tiedemann .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "News from opus - a collection of multilingual parallel corpora with tools and interfaces .", "entities": []}, {"text": "In Recent advances in natural language processing , volume 5 , pages 237\u2013248.462", "entities": []}]