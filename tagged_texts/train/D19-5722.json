[{"text": "Proceedings of the 5th Workshop on BioNLP Open Shared Tasks , pages 150\u2013157 Hong Kong , China , November 4 , 2019 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2019 Association for Computational Linguistics150BOUN - ISIK Participation : An Unsupervised Approach for the Named Entity Normalization and Relation Extraction of Bacteria Biotopes", "entities": [[18, 20, "TaskName", "Relation Extraction"]]}, {"text": "\u02d9Ilknur Karadeniz Is \u00b8\u0131k University ilknur.karadeniz @isikun.edu.tr\u00a8Omer Faruk Tuna Is \u00b8\u0131k University 218DCS8074 @isik.edu.trArzucan \u00a8Ozg\u00a8ur", "entities": []}, {"text": "Bo\u02d8gazic \u00b8i University arzucan.ozgur @boun.edu.tr", "entities": []}, {"text": "Abstract This paper presents our participation at the Bacteria Biotope Task of the BioNLP Shared Task 2019 .", "entities": []}, {"text": "Our participation includes two systems for the two subtasks of the Bacteria Biotope Task : the normalization of entities ( BB - norm ) and the identi\ufb01cation of the relations between the entities given a biomedical text ( BB - rel ) .", "entities": []}, {"text": "For the normalization of entities , we utilized word embeddings and syntactic re - ranking .", "entities": [[8, 10, "TaskName", "word embeddings"]]}, {"text": "For the relation extraction task , pre - de\ufb01ned rules are used .", "entities": [[2, 4, "TaskName", "relation extraction"]]}, {"text": "Although both approaches are unsupervised , in the sense that they do not need any labeled data , they achieved promising results .", "entities": []}, {"text": "Especially , for the BB - norm task , the results have shown that the proposed method performs as good as deep learning based methods , which require labeled data .", "entities": []}, {"text": "1 Introduction The amount of electronic resources in the biomedical domain and its rapid growth are major challenges for the scientists who make research in this domain .", "entities": []}, {"text": "Text mining methods which aim to automatically extract useful information from the text of these electronic resources provide convenience to the researchers .", "entities": []}, {"text": "A number of shared tasks , including the BioNLP Shared Tasks , have been conducted with the goal of developing biomedical text mining methods .", "entities": []}, {"text": "In 2011 , the Bacteria Biotope Task has been conducted for the \ufb01rst time as a part of the BioNLP Shared Task targeting the extraction of useful information regarding bacteria and their habitats ( Bossy et al . , 2011 ) .", "entities": []}, {"text": "Since then , the participant teams of the following shared task series developed various solutions for the problem of bacteria biotopes ( Bossy et al . , 2015 ; Deleger et al . , 2016 ) .", "entities": []}, {"text": "The Bacteria Biotope Task of the BioNLP Shared Task 2019 ( Bossy et al . , 2019 ) is the \ufb01nal version of the tasks that have been conducteduntil now readdressing the problem of extraction of the information regarding the bacteria biotopes .", "entities": []}, {"text": "This year \u2019s task has presented the opportunity to the participants to develop solutions for three subproblems : normalization ( BB - norm ) , relation extraction ( BB - rel ) , and knowledge base extraction ( BB - kb ) .", "entities": [[25, 27, "TaskName", "relation extraction"]]}, {"text": "For the BB - norm task of the Bacteria Biotope Task of the BioNLP Shared Task 2019 , the participants are expected to develop systems to link the named entities ( Microorganism , Habitat , and Phenotype ) in a given text through a given ontology , when the entities are given with their boundaries .", "entities": [[45, 46, "MethodName", "ontology"]]}, {"text": "For instance , the sample sentence \u201c Atypical mycobacteria causing non - pulmonary disease in Queensland . \u201d consists of the following mentions : \u201c mycobacteria \u201d microorganism mention , \u201c causing non - pulmonary disease \u201d phenotype mention , and \u201c pulmonary \u201d habitat mention , which should be normalized to the \u201c Mycobacteria \u201d term in the NCBI taxonomy , and \u201c human pathogen \u201d and\u201clung \u201d terms in the Onto - Biotope ontology , respectively .", "entities": [[75, 76, "MethodName", "ontology"]]}, {"text": "For the BB - rel task of the Bacteria Biotopes Task of the BioNLP Shared Task 2019 , the participants are required to extract the relations between the entities when the entities are given .", "entities": []}, {"text": "There are two types of relations : Lives inrelation , which indicates a localization relation between a Microorganism entity and a Habitat / Geographical entity , and Exhibits relation , which indicates a property relation between a Phenotype entity and a Microorganism entity .", "entities": []}, {"text": "For instance , the sample sentence above indicates two relations : a Lives inrelation between the \u201c Mycobacteria \u201d Microorganism entity and the \u201c Queensland \u201d Geographical entity , and an Exhibits relation between the \u201c Mycobacteria \u201d Microorganism entity and the \u201c causing nonpulmonary disease \u201d Phenotype entity .", "entities": []}, {"text": "We participated at the Bacteria Biotope Task in the BioNLP Shared Task 2019 with our system ( named as the BOUN - ISIK system ) and ob-", "entities": []}, {"text": "151tained promising results in the of\ufb01cial evaluation .", "entities": []}, {"text": "This paper presents our participating system for two sub - tasks : one for the BB - norm ( Entity Normalization ) sub - task and one for the BB - rel ( Relation Extraction ) sub - task .", "entities": [[33, 35, "TaskName", "Relation Extraction"]]}, {"text": "For the entity normalization sub - task , we utilized word embeddings and syntactic re - ranking to normalize the entities .", "entities": [[10, 12, "TaskName", "word embeddings"]]}, {"text": "On the other hand , for the relation extraction sub - task , we proposed a rule - based method .", "entities": [[7, 9, "TaskName", "relation extraction"]]}, {"text": "Although both systems are unsupervised , they achieved promising results .", "entities": []}, {"text": "For the BB - norm sub - task , the of\ufb01cial results of our system achieved state - of - the - art results on the BioNLP Shared Task 2019 Bacteria Biotope task test data set .", "entities": []}, {"text": "The results have shown that our unsupervised approach , which does not require labeled data , performs as good as the deep learning based methods , which require labeled data .", "entities": []}, {"text": "1.1 Related Work 1.1.1 Named Entity Normalization Among the previous series ( 2011 , 2013 , 2016 ) of the BioNLP Shared Task , the Bacteria Biotope Task in 2013 is the \ufb01rst shared task that addressed the problem of normalization of the entities in the bacteria biotopes domain .", "entities": []}, {"text": "In 2013 , the participant teams proposed rule - based methods and similarity - based methods .", "entities": []}, {"text": "According to the of\ufb01cial results of the Bacteria Biotope Task of 2013 , for the habitat mention normalization , the best precision was obtained by the BOUN system , which utilized syntactic rules and shallow linguistic knowledge ( Karadeniz and Ozg \u00a8ur , 2013 ; Karadeniz and \u00a8Ozg\u00a8ur , 2015 ) .", "entities": []}, {"text": "In the following series of the Bacteria Biotopes task , the habitat mention normalization sub - task continued to attract the attention of the researchers .", "entities": []}, {"text": "In the Bacteria Biotope task of the BioNLP Shared Task 2016 , the best precision for the habitat normalization task was obtained by the BOUN system , which utilized both approximate string matching and cosine similarity of word - vectors weighted with Term FrequencyInverse Document Frequency ( TF - IDF ) ( Tiftikci et al . , 2016 ) .", "entities": []}, {"text": "After the Shared Tasks , the researchers continued to search for a solution for the problem of Bacteria Biotopes normalization ( Ferr \u00b4 e et al . , 2017 ; Mehryary et al . , 2017 ; Karadeniz and \u00a8Ozg\u00a8ur , 2019 ) .", "entities": []}, {"text": "Although promising results have been obtained by these approaches , the results showed thatthere is still room for improvement for the normalization task of bacteria biotopes .", "entities": []}, {"text": "Besides the bacteria biotopes , there exist a signi\ufb01cant amount of prior work on biomedical named entity normalization for different types of biomedical entities including genes / proteins ( Morgan et al . , 2008 ; Hakenberg et al . , 2008 ; Wermter et al . , 2009 ; Lu et", "entities": []}, {"text": "al . , 2011 ; Wei and Kao , 2011 ) and diseases ( Leaman et al . , 2013 ; Li et al . , 2017 ) .", "entities": []}, {"text": "However , the need for manually annotated training data makes the adaptation of such methods to new entities dif\ufb01cult .", "entities": []}, {"text": "1.1.2 Relation Extraction Several approaches , which consider the extraction of relations between various biomedical entities such as protein / protein ( Giuliano et al . , 2006 ; Airola et al . , 2008 ; Choi , 2018 ) , drug / drug ( Segura - Bedmar et al . , 2011 ; Kim et al . , 2015 ) , and gene / disease ( Bravo et al . , 2015 ) from biomedical text , have been presented in the literature .", "entities": [[1, 3, "TaskName", "Relation Extraction"]]}, {"text": "Relation extraction in the bacteria biotopes domain has also attracted considerable attention owing to the BioNLP Bacteria Biotope Shared Tasks .", "entities": [[0, 2, "TaskName", "Relation extraction"]]}, {"text": "Previous work in the bacteria biotopes domain consists of the extraction of relations between bacteria entities and habitat entities ( Localization Relation Extraction ) and of relations between two habitat entities ( Part Of Relation Extraction ) .", "entities": [[21, 23, "TaskName", "Relation Extraction"], [34, 36, "TaskName", "Relation Extraction"]]}, {"text": "The participants of the BioNLP Shared Task 2011 , which is the \ufb01rst shared task that addressed the relation extraction task of bacteria biotopes , utilized both machine learning and rule - based approaches for detecting the Localization and Part - of relations among bacteria and habitats ( Bossy et al . , 2011 ) .", "entities": [[18, 20, "TaskName", "relation extraction"], [39, 42, "DatasetName", "Part - of"]]}, {"text": "Sub - task 2 of the Bacteria Biotope ( BB ) Task in the BioNLP Shared Task 2013 also gave another opportunity to scientists to address the task of extracting the Localization and Part Of relations in the bacteria biotopes domain .", "entities": []}, {"text": "For this subtask , the best F - score ( 42 % ) was obtained by the TEES 2.1 system ( Bj \u00a8orne and Salakoski , 2013 ) , which used support vector machine classi\ufb01cation .", "entities": [[31, 34, "MethodName", "support vector machine"]]}, {"text": "After the shared task , a new sentence - level cooccurrence approach with an anaphora resolution component in order to handle relations that span multiple sentences has been developed in ( Karadeniz and \u00a8Ozg\u00a8ur , 2015 ) , which resulted in an improved F - score performance of 53 % on Sub - task 2 .", "entities": []}, {"text": "In the BioNLP Shared Task 2016 , the VERSE", "entities": [[8, 9, "MethodName", "VERSE"]]}, {"text": "152team ( Lever and Jones , 2016 ) achieved the best F - score , which is 56 % , on the relation extraction sub - task of Bacteria Biotopes by utilizing support vector machines .", "entities": [[22, 24, "TaskName", "relation extraction"]]}, {"text": "2 Data Set The data set , which was created by collecting titles and abstracts related to microorganisms from PubMed and extracts from full - text articles related to microorganisms living in food products , is provided by the BioNLP Shared Task 2019 BB Task organizers to the participants .", "entities": []}, {"text": "The data set , consisting of 132 training , 67 development , and 97 test documents , was annotated by the bioinformaticians of the Bibliome team of MIG Laboratory at the Institut National de Recherche Agronomique ( INRA ) .", "entities": []}, {"text": "For the training and development phases of BB - norm , document texts with manually annotated named entities and the concepts assigned to them through the OntoBiotope ontology ( INRA , 2013 ) and NCBI taxonomy ( NCBI , 2018 ) were provided , while in the test phase , only the entity boundaries and the entity types were given by the task organizers .", "entities": [[27, 28, "MethodName", "ontology"]]}, {"text": "For the training and development phases of BBrel , document texts with manually annotated Microorganism , Habitat , Phenotype andGeographicalentities , as well as the Lives inandExhibits relations were provided , while in the test phase , document texts annotated only for Microorganism , Habitat , Phenotype andGeographical entities were given .", "entities": []}, {"text": "Since our system for the named entity normalization and relation extraction of bacteria biotopes is based on unsupervised approaches and does not require any labeled training data , the errors of the developed system are analyzed on the provided training and the development sets .", "entities": [[9, 11, "TaskName", "relation extraction"]]}, {"text": "The test set is used for the evaluation of the performance of the system .", "entities": []}, {"text": "3 Named Entity Normalization In this section of the paper , the utilized methods for the BB - norm task are explained in detail .", "entities": []}, {"text": "The BB - norm task includes the normalization of Habitatentities and Phenotype entities in a given set of documents through the Onto - Biotope ontology and the normalization of Microorganism entities through the NCBI Taxonomy .", "entities": [[24, 25, "MethodName", "ontology"]]}, {"text": "The methods developed for the normalizationof the named entities can be categorized into two according to the type of the entities : Habitat and Phenotype Normalization and Microorganism Normalization .", "entities": []}, {"text": "3.1 Habitat and Phenotype Entities For the normalization of semantically meaningful entities such as Habitat and Phenotype entities , a two - step approach that we have previously proposed in ( Karadeniz and \u00a8Ozg\u00a8ur , 2019 ) is adapted to this new data set .", "entities": []}, {"text": "According to this approach , for the normalization of an entity mention , the top k semantically most similar ontology concepts are found at the \ufb01rst step using the word embedding representations of the entity mention and the ontology concepts .", "entities": [[19, 20, "MethodName", "ontology"], [38, 39, "MethodName", "ontology"]]}, {"text": "At the second step , these top k semantically most similar concepts are re - ranked according to a similarity metric that utilizes the constituency parses of the entity mention and ontology concept phrases .", "entities": [[31, 32, "MethodName", "ontology"]]}, {"text": "The resulting most similar ontology concept is assigned as the normalized concept for the corresponding mention .", "entities": [[4, 5, "MethodName", "ontology"]]}, {"text": "The details of this approach are explained in the following subsections .", "entities": []}, {"text": "3.1.1 Named Entity and Ontology Concept Representations In the pre - processing step , the named entity mentions and the ontology concept names are tokenized , and the stop - words are removed from the mentions and the ontology concept names .", "entities": [[4, 5, "MethodName", "Ontology"], [20, 21, "MethodName", "ontology"], [38, 39, "MethodName", "ontology"]]}, {"text": "The intuition behind the adapted method is that semantically similar words have similar word vectors .", "entities": []}, {"text": "Following this intuition , the semantic similarity between named entity mentions and ontology concept terms would be higher for the similar pairs , and lower for the dissimilar pairs , if the words can be converted into a machine processable format such as real - valued vectors .", "entities": [[5, 7, "TaskName", "semantic similarity"], [12, 13, "MethodName", "ontology"]]}, {"text": "After pre - processing , to convert each word into a real - valued vector , we utilized a pre - trained word embedding model ( Chiu et al . , 2016 ) , which has been trained on PubMed by using the Word2Vec tool ( Mikolov et al . , 2013 ) .", "entities": []}, {"text": "The corresponding word vectors are obtained for each word by using this previously trained model .", "entities": []}, {"text": "For the multiword named entity mentions and ontology concept terms , the vector representations are obtained by averaging the real - valued vectors of their composing words .", "entities": [[7, 8, "MethodName", "ontology"]]}, {"text": "1533.1.2 Semantic Filtering After the vector representations are obtained for each entity mention and for each ontology concept term , the semantic similarity between each pair is computed by using the cosine similarity .", "entities": [[16, 17, "MethodName", "ontology"], [21, 23, "TaskName", "semantic similarity"]]}, {"text": "For each entity mention , the top kmost similar ontology concepts are retained as candidates for further processing , i.e. , for syntactic weighting based re - ranking .", "entities": [[9, 10, "MethodName", "ontology"]]}, {"text": "kis chosen as 5 based on the results obtained in our previous study ( Karadeniz and \u00a8Ozg\u00a8ur , 2019 ) .", "entities": []}, {"text": "3.1.3 Syntactic Re - ranking For our re - ranking approach , the assumption is that the entity mentions are noun phrases and the most informative words in the mentions are the heads of the noun phrases .", "entities": []}, {"text": "We used the Stanford Parser ( version 3.8.0 ) ( Klein and Manning , 2003 ) to obtain the corresponding head words of the entity mentions by providing the entity mentions as input and extracting the syntactic parses of the mentions as output .", "entities": []}, {"text": "Next , the top level rightmost \u201c noun \u201d is searched in the tree structured syntactic parse and assigned as the head of the mention phrase .", "entities": []}, {"text": "The semantic similarities are recomputed using the mathematical formulation shown in Equation ( 1 ) , which considers also the similarity between the head words of the entity mention and ontology concept pair .", "entities": [[30, 31, "MethodName", "ontology"]]}, {"text": "In Equation ( 1 ) , SRR(m , c ) is the \ufb01nal computed similarity between mention m and the candidate concept c , and SSis the semantic similarity , in which mheadis the head word of the mention mandcheadis the head word of the conceptc , SS(m , c ) is the similarity between mention mand concept ccomputed as described in Section 3.1.1 , and wis a weighting parameter which can take values between 0 and 1 . wis chosen as 0.25 based on the results reported in our previous study ( Karadeniz and \u00a8Ozg\u00a8ur , 2019 ) .", "entities": [[27, 29, "TaskName", "semantic similarity"], [75, 76, "DatasetName", "0"]]}, {"text": "SRR(m , c ) = ( w * S S(mhead , chead))+((1 - w )", "entities": []}, {"text": "* S S(m , c))(1 ) 3.2 Microorganism Entities The normalization of Microorganism entities component of our system is based on exact matching against the names and synonyms of the concepts in the NCBI taxonomy .", "entities": []}, {"text": "Error analysis on the training and developments data sets revealed that applying some rules may improve the results .", "entities": [[0, 1, "MetricName", "Error"]]}, {"text": "Forinstance , \u201c Escherichia coli \u201d has an exact match that can be successfully normalized to the referent concept with an ID \u201c 562 \u201d in the NCBI taxonomy .", "entities": [[8, 10, "MetricName", "exact match"]]}, {"text": "In the following parts of the document , although the \u201c E. coli \u201d mention indicates a clear reference to the same concept , it can not be normalized to the \u201c Escherichia coli \u201d concept with an exact matching approach .", "entities": []}, {"text": "In this kind of cases , if an exact match does not exist , the previously mentioned similar entities in the text are searched .", "entities": [[8, 10, "MetricName", "exact match"]]}, {"text": "If a match is found , the same concept is assigned as the normalized concept for the corresponding mention \u201c E. coli \u201d .", "entities": []}, {"text": "If there does not exist a match with the previously normalized concepts , the root concept with an ID \u201c 2\u201dis assigned .", "entities": []}, {"text": "4 Relation Extraction 4.1 Localization Relation Extraction Our system for the relation extraction sub - task is based on the naive assumption that the related entities for most of the relations appear within the same sentence .", "entities": [[1, 3, "TaskName", "Relation Extraction"], [5, 7, "TaskName", "Relation Extraction"], [11, 13, "TaskName", "relation extraction"]]}, {"text": "Therefore , \ufb01rstly , the input texts are split into sentences using the NLTK library .", "entities": []}, {"text": "For the extraction of Lives inrelations , all the sentences in the related document are searched to determine whether there exists a Microorganism entity and a Habitat entity or a Microorganism entity and a Geographical entity in the corresponding sentence .", "entities": []}, {"text": "If there exists such a pair , this will be a sign of a Lives inrelation .", "entities": []}, {"text": "For any given sentence , there can be more than oneHabitat entity and Microorganism entity .", "entities": []}, {"text": "For this kind of sentences , two different approaches , which are called smart matching anddistributed matching , are applied .", "entities": []}, {"text": "In smart matching , each Habitat entity is paired with the closest Microorganism entity .", "entities": []}, {"text": "In other words , the locations of each type of entities in the sentences are checked , and then the pairing process of the Microorganismand the Habitat entities are done based on the proximity criteria .", "entities": []}, {"text": "In distributed matching , on the other hand , each Habitat entity is paired with everyMicroorganism entity in the sentence .", "entities": []}, {"text": "Distributed matching can be seen as a type of N x N matching , while smart matching 1 x 1 matching .", "entities": []}, {"text": "The performance of each approach is tested on the development data set .", "entities": []}, {"text": "While there is slight increase in the precision , the recall is observed to decrease considerably for the smart matching method ( see Table 1 ) .", "entities": []}, {"text": "As a result , the distributed matching approach is used in the \ufb01nal submission .", "entities": []}, {"text": "154Table 1 : Distributed vs Smart Matching for relation extraction .", "entities": [[8, 10, "TaskName", "relation extraction"]]}, {"text": "Precision , Recall , F - measure values for the development data set are reported .", "entities": [[0, 1, "MetricName", "Precision"], [2, 3, "MetricName", "Recall"], [4, 7, "MetricName", "F - measure"]]}, {"text": "Distributed Matching Smart Matching Precision 0.491 0.576", "entities": [[4, 5, "MetricName", "Precision"]]}, {"text": "Recall 0.785 0.515 F - measure 0.604 0.544 For the overlapping entities in which one entity contains another , some relations can be ignored .", "entities": [[0, 1, "MetricName", "Recall"], [3, 6, "MetricName", "F - measure"]]}, {"text": "For instance , for the sample sentence \u201c An example of this fact is the presence of Psychrobacter DNA on the surface of Formaggio di Fossa cheeses \u201d , the Habitat entity \u201c surface of Formaggio di Fossa cheeses \u201d , Habitat entity \u201c Formaggio di Fossa cheeses \u201d , and Habitat entity\u201ccheeses \u201d are overlapping entities .", "entities": []}, {"text": "In this case , it would not be appropriate to build three relations such as \u201c Psychrobacter \u201d -\u201csurface of Formaggio di Fossa cheeses \u201d , \u201c Psychrobacter \u201d \u201c Formaggio di Fossa cheeses \u201d , and \u201c Psychrobacter \u201d -\u201ccheeses \u201d .", "entities": []}, {"text": "Instead of extracting multiple relations , \u201c cheeses \u201d can be ignored and two relations between \u201c Psychrobacter \u201d -\u201csurface of Formaggio di Fossa cheeses \u201d and\u201cPsychrobacter \u201d \u201c Formaggio di Fossa cheeses \u201d are extracted .", "entities": []}, {"text": "This strategy , where the shortest overlapping entity is ignored , is called as the soft \ufb01lter operation .", "entities": []}, {"text": "On the other hand , the strategy when only the longest overlapping entity is retained and the remaining ones are ignored , is named as the hard \ufb01lter operation .", "entities": []}, {"text": "In hard \ufb01ltering , \u201c Psychrobacter \u201d -\u201cFormaggio di Fossa cheeses \u201d and\u201cPsychrobacter \u201d \u201c cheeses \u201d are ignored and only one relation between \u201c Psychrobacter \u201d -\u201csurface of Formaggio di Fossa cheeses \u201d is extracted .", "entities": []}, {"text": "The performance of each approach is tested on the development data set ( see Table 2 ) .", "entities": []}, {"text": "Table 2 : Soft Filter vs Hard Filter for relation extraction .", "entities": [[9, 11, "TaskName", "relation extraction"]]}, {"text": "Precision , Recall , F - measure values for the development data set are reported .", "entities": [[0, 1, "MetricName", "Precision"], [2, 3, "MetricName", "Recall"], [4, 7, "MetricName", "F - measure"]]}, {"text": "Soft Filter Hard Filter Precision 0.584 0.575 Recall 0.768 0.639 F - measure 0.616 0.561", "entities": [[4, 5, "MetricName", "Precision"], [7, 8, "MetricName", "Recall"], [10, 13, "MetricName", "F - measure"]]}, {"text": "Since our rule - based system for relation extraction is based on the assumption that most of the relations appear within the same sentences , our system is not able to catch the relations that cross sentence boundaries .", "entities": [[7, 9, "TaskName", "relation extraction"]]}, {"text": "To overcome this problem , a new rule , which is called remote matching , is integrated into the system .", "entities": []}, {"text": "According to this rule , if there exists only one entity type ( Microorganism ) in a sentence , and within a context window of three sentences there exists only one entity ( Habitat or Geographical ) , then there is a relation between these two entities .", "entities": []}, {"text": "The performance of the remote matching rule is tested on the development data set .", "entities": []}, {"text": "The results show that the number of the predicted relations increased , which also led to an increase in recall .", "entities": []}, {"text": "The obtained precision and recall values are 51.4 % and 78.5 % , respectively .", "entities": []}, {"text": "4.2 Exhibits Relation Extraction Similar to the extraction of localization relations , for the extraction of Exhibits relations , all the sentences are searched for whether there exist a Microorganism entity and a Phenotype entity .", "entities": [[2, 4, "TaskName", "Relation Extraction"]]}, {"text": "The same rules that are explained in the previous subsection are applied for the extraction of the Exhibits relations .", "entities": []}, {"text": "5 Evaluation In the BioNLP Shared Task 2019 Bacteria Biotopes normalization sub - task , entities are given with their boundaries in the text and the participants are required to predict the normalization of the entities .", "entities": []}, {"text": "In the of\ufb01cial evaluation , for each normalized Habitat / Phenotype entity , Wang similarity W(Wang et", "entities": []}, {"text": "al . , 2007 ) is calculated to measure the similarity between the reference concept and the predicted concept for the normalization .", "entities": []}, {"text": "The performances of the submitted systems are evaluated with their Precision values , which are calculated as : Precision = X Sp/ N ( 2 ) where Spindicates the total Wang similarity W for all predictions ( Deleger et al . , 2016 ) , and Nis the number of predicted entities .", "entities": [[10, 11, "MetricName", "Precision"], [18, 19, "MetricName", "Precision"]]}, {"text": "In the BioNLP Shared Task 2019 Bacteria Biotopes relation extraction sub - task , entities are given with their boundaries in the text and the participants are asked to predict the relations between the entities .", "entities": [[8, 10, "TaskName", "relation extraction"]]}, {"text": "The performances of the submitted systems are evaluated with their F1 ( F - measure ) , recall and precision values .", "entities": [[10, 11, "MetricName", "F1"], [12, 15, "MetricName", "F - measure"]]}, {"text": "1555.1 Results of BB - norm The of\ufb01cial results obtained by our system and the other participants for the BB - norm sub - task are shown in Table 3 .", "entities": []}, {"text": "Our system ( BOUN - ISIK-2 ) achieved the best performance with 67:9 % Precision in the BB - norm sub - task ( Entity Normalization ) .", "entities": [[14, 15, "MetricName", "Precision"]]}, {"text": "Table 3 : Comparison with the participant systems for the normalization task of bacteria biotopes .", "entities": []}, {"text": "Precision values for the test data set are reported .", "entities": [[0, 1, "MetricName", "Precision"]]}, {"text": "kis set to 5and wto0:25for the proposed system ( BOUN - ISIK ) .", "entities": []}, {"text": "System Precision BOUN - ISIK-2 ( Our system ) 0.679 BLAIR GMU-2 0.678 BOUN - ISIK-1 ( Our system ) 0.675 BLAIR GMU-1 0.661 PADIA BacReader-1 0.633 BASELINE-1 0.531 AmritaCen healthcare-1 0.514 As the results in Table 4 demonstrate , our system performs signi\ufb01cantly better than the other systems for the normalization of new Phenotype entities in the test set ( Precision : 70:8 % ) .", "entities": [[1, 2, "MetricName", "Precision"], [61, 62, "MetricName", "Precision"]]}, {"text": "Table 4 : Comparison with the participant systems for the normalization task considering only Phenotype entities .", "entities": []}, {"text": "Precision values for the test data set are reported .", "entities": [[0, 1, "MetricName", "Precision"]]}, {"text": "System Phenotypes Phenotypes ( new in test )", "entities": []}, {"text": "BOUN - ISIK ( Our system ) 0.566 0.708 PADIA BacReader-1 0.758 0.156 BASELINE-1 0.582 0.116 BLAIR GMU-2 0.646 0.03 BLAIR GMU-1 0.628 0.03 AmritaCen healthcare-1 0.646 0.0 5.2 Results of BB - rel The of\ufb01cial results obtained by our system and the other participants for the BB - rel task are demonstrated in Table 5", "entities": []}, {"text": ". 6 Conclusion In this study , we presented two systems that are implemented in the scope of the BioNLP Shared Task 2019 - Bacteria Biotope Task .", "entities": []}, {"text": "The aim of the \ufb01rst system is the normalization of the entity mentions in a biomedical text through the corresponding ontology , whereas the goal of the secondTable 5 : Comparison with the participant systems for the relation extraction task of bacteria biotopes .", "entities": [[20, 21, "MethodName", "ontology"], [37, 39, "TaskName", "relation extraction"]]}, {"text": "F1 , Recall and Precision values for the test data set are reported .", "entities": [[0, 1, "MetricName", "F1"], [2, 3, "MetricName", "Recall"], [4, 5, "MetricName", "Precision"]]}, {"text": "System F1 Recall Precision whunlp-1 0.664 0.702 0.629 AliAI-1 0.650 0.620 0.682 BASELINE-1 0.635 0.801 0.525 Yuhang", "entities": [[1, 2, "MetricName", "F1"], [2, 3, "MetricName", "Recall"], [3, 4, "MetricName", "Precision"]]}, {"text": "Wu-1 0.605 0.670 0.551", "entities": []}, {"text": "BOUN - ISIK-1 ( soft \ufb01lter ) 0.604 0.731 0.514 BLAIR GMU-2 0.594 0.650 0.548 BOUN - ISIK-2 ( hard \ufb01lter ) 0.575 0.601 0.552 BLAIR GMU-1 0.549 0.496 0.617 UTU-2 0.550 0.474 0.655 UTU-1 0.529 0.428 0.694 Amrita Cen-1", "entities": []}, {"text": "0.499 0.617 0.419", "entities": []}, {"text": "Amrita Cen-2 0.493 0.610 0.414 system is the extraction of localization and property relations between the related entities when the entities are given .", "entities": []}, {"text": "Both systems are unsupervised in the sense that they do not require domainspeci\ufb01c labeled data , while the normalization system makes use of word embeddings and syntactic re - ranking .", "entities": [[23, 25, "TaskName", "word embeddings"]]}, {"text": "According to the of\ufb01cial evaluation , both of our systems achieved promising results , which have shown that the proposed methods are comparable to or better than the labeled data driven deep learning based approaches used in the shared task .", "entities": []}, {"text": "Acknowledgments We would like to thank the BioNLP shared task organizers , especially , Robert Bossy for their help with the questions .", "entities": []}, {"text": "References Antti Airola , Sampo Pyysalo , Jari Bj \u00a8orne , Tapio Pahikkala , Filip Ginter , and Tapio Salakoski . 2008 .", "entities": []}, {"text": "A graph kernel for protein - protein interaction extraction .", "entities": []}, {"text": "In Proceedings of the workshop on current trends in biomedical natural language processing , pages 1\u20139 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Jari Bj \u00a8orne and Tapio Salakoski .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Tees 2.1 : Automated annotation scheme learning in the bionlp 2013 shared task .", "entities": []}, {"text": "In Proceedings of the BioNLP shared task 2013 workshop , pages 16\u201325 .", "entities": []}, {"text": "Robert Bossy , Louise Del \u00b4 eger , Estelle Chaix , Mouhamadou Ba , and Claire Nedellec .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Bacteria Biotope at BioNLP Open Shared Tasks 2019 .", "entities": []}, {"text": "In Proceedings of the BioNLP Open Shared Tasks 2019 Workshop .", "entities": []}, {"text": "Robert Bossy , Wiktoria Golik , Zorana Ratkovic , Dialekti Valsamou , Philippe Bessieres , and Claire", "entities": []}, {"text": "156N\u00b4edellec .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Overview of the gene regulation network and the bacteria biotope tasks in bionlp\u201913 shared task .", "entities": []}, {"text": "BMC bioinformatics , 16(10):S1 .", "entities": []}, {"text": "Robert Bossy , Julien Jourde , Philippe Bessieres , Maarten Van De Guchte , and Claire N \u00b4 edellec .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Bionlp shared task 2011 : bacteria biotope .", "entities": []}, {"text": "In Proceedings of the BioNLP Shared Task 2011 Workshop , pages 56\u201364 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "` Alex Bravo , Janet Pi \u02dcnero , N \u00b4 uria Queralt - Rosinach , Michael Rautschka , and Laura I Furlong .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Extraction of relations between genes and diseases from text and large - scale data analysis : implications for translational research .", "entities": []}, {"text": "BMC bioinformatics , 16(1):55 .", "entities": []}, {"text": "Billy Chiu , Gamal Crichton , Anna Korhonen , and Sampo Pyysalo . 2016 .", "entities": []}, {"text": "How to train good word embeddings for biomedical nlp .", "entities": [[4, 6, "TaskName", "word embeddings"]]}, {"text": "Proceedings of BioNLP16 , page 166 .", "entities": []}, {"text": "Sung - Pil Choi .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Extraction of protein \u2013 protein interactions ( ppis ) from the literature by deep convolutional neural networks with various feature embeddings .", "entities": []}, {"text": "Journal of Information Science , 44(1):60\u201373 .", "entities": []}, {"text": "Louise Deleger , Robert Bossy , Estelle Chaix , Mouhamadou Ba , Arnaud Ferre , Philippe Bessieres , and Claire Nedellec . 2016 .", "entities": []}, {"text": "Overview of the bacteria biotope task at bionlp shared task 2016 .", "entities": []}, {"text": "In Proceedings of the 4th BioNLP Shared Task Workshop , pages 12\u201322 .", "entities": []}, {"text": "Arnaud Ferr \u00b4 e , Pierre Zweigenbaum , and Claire N\u00b4edellec .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Representation of complex terms in a vector space structured by an ontology for a normalization task .", "entities": [[11, 12, "MethodName", "ontology"]]}, {"text": "BioNLP 2017 , pages 99\u2013106 .", "entities": []}, {"text": "Claudio Giuliano , Alberto Lavelli , and Lorenza Romano .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Exploiting shallow linguistic information for relation extraction from biomedical literature .", "entities": [[5, 7, "TaskName", "relation extraction"]]}, {"text": "In 11th Conference of the European Chapter of the Association for Computational Linguistics .", "entities": []}, {"text": "J\u00a8org Hakenberg , Conrad Plake , Robert Leaman , Michael Schroeder , and Graciela Gonzalez . 2008 .", "entities": []}, {"text": "Inter - species normalization of gene mentions with gnat .", "entities": []}, {"text": "Bioinformatics , 24(16):i126 \u2013 i132 .", "entities": []}, {"text": "INRA .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Onto - Biotope Ontology .", "entities": [[3, 4, "MethodName", "Ontology"]]}, {"text": "Accessed at December 2018 .", "entities": []}, {"text": "Ilknur Karadeniz and Arzucan Ozg \u00a8ur .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Bacteria biotope detection , ontology - based normalization , and relation extraction using syntactic rules .", "entities": [[4, 5, "MethodName", "ontology"], [10, 12, "TaskName", "relation extraction"]]}, {"text": "In Proceedings of the BioNLP Shared Task 2013 Workshop , pages 170\u2013177 .", "entities": []}, {"text": "\u02d9Ilknur Karadeniz and Arzucan \u00a8Ozg\u00a8ur . 2015 .", "entities": []}, {"text": "Detection and categorization of bacteria habitats using shallow linguistic analysis .", "entities": []}, {"text": "BMC bioinformatics , 16(10):S5.Ilknur Karadeniz and Arzucan \u00a8Ozg\u00a8ur . 2019 .", "entities": []}, {"text": "Linking entities through an ontology using word embeddings and syntactic re - ranking .", "entities": [[4, 5, "MethodName", "ontology"], [6, 8, "TaskName", "word embeddings"]]}, {"text": "BMC bioinformatics , 20(1):156 .", "entities": []}, {"text": "Sun Kim , Haibin Liu , Lana Yeganova , and W John Wilbur . 2015 .", "entities": []}, {"text": "Extracting drug \u2013 drug interactions from literature using a rich feature - based linear kernel approach .", "entities": []}, {"text": "Journal of biomedical informatics , 55:23\u201330 .", "entities": []}, {"text": "Dan Klein and Christopher D Manning .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Accurate unlexicalized parsing .", "entities": []}, {"text": "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1 , pages 423\u2013430 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Robert Leaman , Rezarta Islamaj Do \u02d8gan , and Zhiyong Lu . 2013 .", "entities": []}, {"text": "Dnorm : disease name normalization with pairwise learning to rank .", "entities": []}, {"text": "Bioinformatics , 29(22):2909\u20132917 .", "entities": []}, {"text": "Jake Lever and Steven JM Jones .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Verse : Event and relation extraction in the bionlp 2016 shared task .", "entities": [[0, 1, "DatasetName", "Verse"], [4, 6, "TaskName", "relation extraction"]]}, {"text": "In Proceedings of the 4th BioNLP shared task workshop , pages 42\u201349 .", "entities": []}, {"text": "Haodi Li , Qingcai Chen , Buzhou Tang , Xiaolong Wang , Hua Xu , Baohua Wang , and Dong Huang . 2017 .", "entities": []}, {"text": "Cnn - based ranking for biomedical entity normalization .", "entities": []}, {"text": "BMC bioinformatics , 18(11):385 .", "entities": []}, {"text": "Zhiyong Lu , Hung - Yu Kao , Chih - Hsuan Wei , Minlie Huang , Jingchen Liu , Cheng - Ju Kuo , ChunNan Hsu , Richard Tzong - Han Tsai , Hong - Jie Dai , Naoaki Okazaki , et al . 2011 .", "entities": []}, {"text": "The gene normalization task in biocreative iii .", "entities": []}, {"text": "BMC bioinformatics , 12(8):S2 .", "entities": []}, {"text": "Farrokh Mehryary , Kai Hakala , Suwisa Kaewphan , Jari Bj\u00a8orne , Tapio Salakoski , and Filip Ginter . 2017 .", "entities": []}, {"text": "End - to - end system for bacteria habitat extraction .", "entities": []}, {"text": "BioNLP 2017 , pages 80\u201390 .", "entities": []}, {"text": "Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Jeff Dean .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Distributed representations of words and phrases and their compositionality .", "entities": []}, {"text": "In Advances in neural information processing systems , pages 3111\u20133119 .", "entities": []}, {"text": "Alexander A Morgan , Zhiyong Lu , Xinglong Wang , Aaron M Cohen , Juliane Fluck , Patrick Ruch , Anna Divoli , Katrin Fundel , Robert Leaman , J \u00a8org Hakenberg , et al . 2008 .", "entities": []}, {"text": "Overview of biocreative ii gene normalization .", "entities": []}, {"text": "Genome biology , 9(2):S3 .", "entities": []}, {"text": "NCBI .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "NCBI Taxonomy .", "entities": []}, {"text": "Accessed at December 2018 .", "entities": []}, {"text": "Isabel Segura - Bedmar , Paloma Martinez , and Cesar de Pablo - S \u00b4 anchez .", "entities": []}, {"text": "2011 .", "entities": []}, {"text": "Using a shallow linguistic kernel for drug \u2013 drug interaction extraction .", "entities": [[6, 11, "TaskName", "drug \u2013 drug interaction extraction"]]}, {"text": "Journal of biomedical informatics , 44(5):789\u2013804 .", "entities": []}, {"text": "157Mert Tiftikci , Hakan S \u00b8ahin , Berfu B \u00a8uy\u00a8uk\u00a8oz , Alper Yay\u0131kc \u00b8\u0131 , and Arzucan \u00a8Ozg\u00a8ur . 2016 .", "entities": []}, {"text": "Ontology - based categorization of bacteria and habitat entities using information retrieval techniques .", "entities": [[0, 1, "MethodName", "Ontology"], [10, 12, "TaskName", "information retrieval"]]}, {"text": "In Proceedings of the 4th BioNLP Shared Task Workshop , pages 56 \u2013 63 .", "entities": []}, {"text": "James Z Wang , Zhidian Du , Rapeeporn Payattakool , Philip S Yu , and Chin - Fu Chen .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "A new method to measure the semantic similarity of go terms .", "entities": [[6, 8, "TaskName", "semantic similarity"]]}, {"text": "Bioinformatics , 23(10):1274\u20131281 .", "entities": []}, {"text": "Chih - Hsuan Wei and Hung - Yu Kao . 2011 .", "entities": []}, {"text": "Crossspecies gene normalization by species inference .", "entities": []}, {"text": "BMC bioinformatics , 12(8):S5 .", "entities": []}, {"text": "Joachim Wermter , Katrin Tomanek , and Udo Hahn .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "High - performance gene name normalization with geno .", "entities": []}, {"text": "Bioinformatics , 25(6):815\u2013821 .", "entities": []}]