[{"text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 8476\u20138488 July 5 - 10 , 2020 .", "entities": []}, {"text": "c", "entities": []}, {"text": "2020 Association for Computational Linguistics8476Multi - Domain Named Entity Recognition with Genre - Aware and Agnostic Inference Jing Wang\u0003 , Mayank Kulkarni\u0003 , Daniel Preot \u00b8iuc - Pietro Bloomberg New York , New York , USA fjwang1621,mkulkarni24,dpreotiucpie g@bloomberg.net Abstract Named entity recognition is a key component of many text processing pipelines and it is thus essential for this component to be robust to different types of input .", "entities": [[7, 10, "TaskName", "Named Entity Recognition"], [39, 42, "TaskName", "Named entity recognition"]]}, {"text": "However , domain transfer of NER models with data from multiple genres has not been widely studied .", "entities": [[5, 6, "TaskName", "NER"]]}, {"text": "To this end , we conduct NER experiments in three predictive setups on data from : a ) multiple domains ; b ) multiple domains where the genre label is unknown at inference time ; c ) domains not encountered in training .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "We introduce a new architecture tailored to this task by using shared and private domain parameters and multi - task learning .", "entities": [[17, 21, "TaskName", "multi - task learning"]]}, {"text": "This consistently outperforms all other baseline and competitive methods on all three experimental setups , with differences ranging between +1.95 to +3.11 average F1 across multiple genres when compared to standard approaches .", "entities": [[22, 24, "MetricName", "average F1"]]}, {"text": "These results illustrate the challenges that need to be taken into account when building real - world NLP applications that are robust to various types of text and the methods that can help , at least partially , alleviate these issues .", "entities": []}, {"text": "1 Introduction Accurately identifying named entities and their type in texts is a key processing step for many NLP applications .", "entities": []}, {"text": "Named entity recognition ( NER ) is an important component in several tasks including named entity linking ( Cucerzan , 2007 ) , co - reference resolution ( Ng and Cardie , 2002 ) , question answering ( Krishnamurthy and Mitchell , 2015 ) , relation extraction ( Culotta and Sorensen , 2004 ) and usually sits upstream of analytics such as sentiment ( Pang and Lee , 2004 ) or stance ( Mohammad et al . , 2016 ) .", "entities": [[0, 3, "TaskName", "Named entity recognition"], [4, 5, "TaskName", "NER"], [15, 17, "TaskName", "entity linking"], [35, 37, "TaskName", "question answering"], [45, 47, "TaskName", "relation extraction"]]}, {"text": "Building robust NER models to accurately tag and adapt to heterogeneous types of text is thus paramount .", "entities": [[2, 3, "TaskName", "NER"]]}, {"text": "Recent research focused on \u0003*Equal Contributionimproving the overall performance of NER models on speci\ufb01c data sets .", "entities": [[10, 11, "TaskName", "NER"]]}, {"text": "Yet NER models show relatively high variance even when trained on the same data ( Reimers and Gurevych , 2017 ) and poorly generalize when tested on data from different genres1 , especially if these contain entity mentions unseen in the test data ( Augenstein et al . , 2017 ; Agarwal et al . , 2020 ) .", "entities": [[1, 2, "TaskName", "NER"]]}, {"text": "Despite this , research on NER models robust to different types of input is usually limited to the standard domain adaptation scenario : a single source domain rich in training data and a single target domain with limited or no training data ( Lin and Lu , 2018 ) .", "entities": [[5, 6, "TaskName", "NER"], [19, 21, "TaskName", "domain adaptation"]]}, {"text": "We argue that this is an over - simpli\ufb01ed experimental setup that is not typical for how NER models are used in real - world applications .", "entities": [[17, 18, "TaskName", "NER"]]}, {"text": "Ideally , NER models use all available data , regardless of genre , and perform inference on data from any genre , even if this was not encountered in training .", "entities": [[2, 3, "TaskName", "NER"]]}, {"text": "In this scenario , simply pooling all the available data is likely sub - optimal as genre - speci\ufb01c differences in named entity mentions are useful to model .", "entities": []}, {"text": "Conversely , models limited to only data from the same genre as the test set are likely to underperform , as using more data is usually bene\ufb01cial .", "entities": []}, {"text": "This work introduces three experimental setups for the NER task where models are trained on data from multiple genres and evaluated as follows : a)Multi - Domain \u2013 evaluation is performed across multiple genres , all seen in training .", "entities": [[8, 9, "TaskName", "NER"]]}, {"text": "b)Multi - Domain with Unknown Domain Labels \u2013 evaluation is carried out across multiple genres , all seen in training , but the genre label for each document is unknown at inference time .", "entities": []}, {"text": "c)Zero - shot Domain \u2013 evaluation is performed on documents from genres unseen in training .", "entities": []}, {"text": "1Throughout this paper , we refer by genre to a collection of documents with variations in style or structure that might impact modelling ( Santini et al . , 2006 ) ; we use domain when referring to modeling concepts .", "entities": []}, {"text": "8477We propose a neural architecture for NER tailored to these three experimental setups , based on the popular BiLSTM - CRF architecture ( Lample et al . , 2016 ) .", "entities": [[6, 7, "TaskName", "NER"], [18, 19, "MethodName", "BiLSTM"], [20, 21, "MethodName", "CRF"]]}, {"text": "We augment the base architecture to learn both domain - speci\ufb01c and independent features through shared and private domain components including projections and CRFs .", "entities": []}, {"text": "Further , we add a multi - task learning objective for domain prediction to guide this separation .", "entities": [[5, 9, "TaskName", "multi - task learning"]]}, {"text": "This model can perform inference on a text without knowledge of its corresponding domain label by using the shared components .", "entities": []}, {"text": "We compare this model with several competitive methods that use a similar base architecture while holding the embeddings constant ( i.e. GloVe embeddings ) .", "entities": [[21, 23, "MethodName", "GloVe embeddings"]]}, {"text": "These include models trained on data from each domain independently , models that pool all data and models that use domain identities as features through to source - target domain adaptation methods .", "entities": [[29, 31, "TaskName", "domain adaptation"]]}, {"text": "Extensive results on all three experimental setups on a collection of data from a total of twelve genres demonstrate that our proposed architecture outperforms all others by a respectable margin .", "entities": []}, {"text": "Finally , through an error analysis of our results , we aim to understand the contributions of each proposed component and the margins for future improvements .", "entities": []}, {"text": "2 Related Work Setups for Domain Adaptation Domain adaptation , formulated as learning a single model for the same task across multiple domains , is a wellstudied research area in NLP ( Chelba and Acero , 2004 ; Florian et", "entities": [[5, 7, "TaskName", "Domain Adaptation"], [7, 9, "TaskName", "Domain adaptation"]]}, {"text": "al . , 2004 ; Blitzer et al . , 2006 ; Daum \u00b4 e III , 2007 ) .", "entities": []}, {"text": "The standard setup for domain adaptation is to maximize performance on data from a single low - resource ( target ) domain , by using data from a single high - resource ( source ) domain ( Blitzer et al . , 2007 ; Peng and Dredze , 2017 ) .", "entities": [[4, 6, "TaskName", "domain adaptation"]]}, {"text": "Extensions consider a single source and multiple different target domains ( Yang and Eisenstein , 2015 ) or multiple sources and a single target domain ( Mansour et al . , 2009 ) .", "entities": []}, {"text": "The multi - domain text classi\ufb01cation task studied in ( Li and Zong , 2008 ; Wu and Huang , 2015 ; Chen and Cardie , 2018 ) is the analogous setup for the text classi\ufb01cation task to the \ufb01rst experimental setup we propose for NER .", "entities": [[45, 46, "TaskName", "NER"]]}, {"text": "Under this setup , training and evaluation is done across data from multiple domains .", "entities": []}, {"text": "Multi - Domain Adaptation Methods for multidomain text classi\ufb01cation use data fusion either at the feature or classi\ufb01er level ( Li and Zong,2008 ) , decomposing the classi\ufb01er into a shared one and multiple domain - speci\ufb01c ones ( Wu and Huang , 2015 ) , further guided by a domain discriminator ( Chen and Cardie , 2018 ) which is also used in multi - lingual NER ( Chen et al . , 2019 ) .", "entities": [[2, 4, "TaskName", "Domain Adaptation"], [67, 68, "TaskName", "NER"]]}, {"text": "Further , McClosky et al .", "entities": []}, {"text": "( 2010 ) explored sequence tagging tasks on data from unknown domains and Chen and Cardie ( 2018 ) experiment with sentiment classi\ufb01cation on data from unknown domains , similar to our third experimental setup for NER .", "entities": [[36, 37, "TaskName", "NER"]]}, {"text": "To the best of our knowledge , our second setup where the domain label is not available at inference time was never explicitly studied .", "entities": []}, {"text": "We note that most of these approaches make use of additional unlabeled data from each domain to learn domain - speci\ufb01c representations .", "entities": []}, {"text": "We do not use these resources in our methods , as we assume the end - user of the model is agnostic to the data used in training and wants to run inference without having to provide entire comparable corpora .", "entities": []}, {"text": "Domain Adaptation for NER Models for domain adaptation in NER using neural architectures were studied recently , albeit mostly for covering the single - source and single - target setup .", "entities": [[0, 2, "TaskName", "Domain Adaptation"], [3, 4, "TaskName", "NER"], [6, 8, "TaskName", "domain adaptation"], [9, 10, "TaskName", "NER"]]}, {"text": "The INIT method trains a model using the source domain data , and its parameters are used to initialize a target model which is \ufb01ne - tuned on the target data ( Mou et al . , 2016 ) .", "entities": []}, {"text": "The MULT method trains jointly one model for each domain with shared parameters ( Lee et al . , 2018 ) .", "entities": []}, {"text": "For sequence tagging , one CRF for each of the two domains is used to obtain the predictions ( Yang et al . , 2017 ) .", "entities": [[5, 6, "MethodName", "CRF"]]}, {"text": "Adaptation can also be made at the embeddings stage ( Lin and Lu , 2018 ) or by using additional unlabeled data from the source domain and out - of - domain annotated data ( He and Sun , 2017 ) .", "entities": []}, {"text": "However , as mentioned above , this assumes that unlabeled training data can be provided for each domain , which may not be realistic .", "entities": []}, {"text": "The model adds layers between embeddings and the BiLSTM layers , between the BiLSTM and the CRF for the target domain and separate CRF layers , the latter two of which we adapt to our proposed architecture for multi - domain adaptation .", "entities": [[8, 9, "MethodName", "BiLSTM"], [13, 14, "MethodName", "BiLSTM"], [16, 17, "MethodName", "CRF"], [23, 24, "MethodName", "CRF"], [40, 42, "TaskName", "domain adaptation"]]}, {"text": "A hierarchical Bayesian prior approach is used in ( Finkel and Manning , 2009 ) to tie feature weights across domains when information is sparse and also allow the model to take advantage if substantial data is available in one domain .", "entities": []}, {"text": "Their experiments on NER focused only on three data sets : CoNLL , MUC-6 and MUC-7 and only the \ufb01rst of our three setups .", "entities": [[3, 4, "TaskName", "NER"]]}, {"text": "A multi - task domain adaptation", "entities": [[4, 6, "TaskName", "domain adaptation"]]}, {"text": "8478method for NER and word segmentation is used in ( Peng and Dredze , 2017 ) .", "entities": [[2, 3, "TaskName", "NER"]]}, {"text": "The proposed architecture learns a shared representation across domains and experiments with linear domain projections for each domain to guide learning of shared representations .", "entities": []}, {"text": "The output of these linear layers is fed to a CRF .", "entities": [[10, 11, "MethodName", "CRF"]]}, {"text": "We adopt the linear domain projection method , but extend this to also include a shared projection , followed by domain - speci\ufb01c CRFs and multi - task learning .", "entities": [[25, 29, "TaskName", "multi - task learning"]]}, {"text": "Finally , another type of domain adaptation is temporal adaptation of models tested on data that is more recent than the training data , when each temporal slice can be considered as a different domain ( Rijwhani and Preo t \u00b8iuc - Pietro , 2020 ) .", "entities": [[5, 7, "TaskName", "domain adaptation"]]}, {"text": "3 Methods This section describes the proposed NER architecture tailored the architecture to our multi - domain experimental setups , which is independent of input embedding representation .", "entities": [[7, 8, "TaskName", "NER"]]}, {"text": "3.1 Base Architecture The basic component of our NER models is an architecture which has reached state - of - the - art performance several times over the last few years ( Lample et al . , 2016 ; Peters et al . , 2018 ; Akbik et al . , 2018 ) .", "entities": [[8, 9, "TaskName", "NER"]]}, {"text": "Named entity recognition task is a structured prediction task and earlier statistical approaches are based models like Conditional Random Fields ( Lafferty et al . , 2001 ) , which rely on features often designed based on domain - speci\ufb01c knowledge ( Luo et al . , 2015 ) .", "entities": [[0, 3, "TaskName", "Named entity recognition"], [6, 8, "TaskName", "structured prediction"]]}, {"text": "The current dominant approach to the NER task consists of neural architectures based on recurrent neural networks with different choices of input representations ( Huang et al . , 2015 ; Ma and Hovy , 2016 ; Lample et al . , 2016 ; Peters et al . , 2018 ; Akbik et al . , 2018 , 2019 ) .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "The input consists of a concatenation of pretrained word embeddings and character embeddings .", "entities": [[8, 10, "TaskName", "word embeddings"]]}, {"text": "Character embeddings are trained using an LSTM from randomly initialized vectors as in ( Lample et al . , 2016 ) .", "entities": [[6, 7, "MethodName", "LSTM"]]}, {"text": "Word embeddings are derived from a combination GloVe ( Pennington et al . , 2014 ) and FastText ( Bojanowski et al . , 2017 ) pre - trained word embeddings , as used in ( Ma and Hovy , 2016 ) .", "entities": [[0, 2, "TaskName", "Word embeddings"], [7, 8, "MethodName", "GloVe"], [17, 18, "MethodName", "FastText"], [29, 31, "TaskName", "word embeddings"]]}, {"text": "The choice of embeddings is orthogonal to the architecture and thus , we hold these constant in all experiments .", "entities": []}, {"text": "This representation is passed through two LSTM layers that process the input sequence in differFigure 1 : MultDomain \u2013 SP \u2013 Aux Architecture for 2 domains ( A & B ) and shared layers denoted by Sh ent directions ( Huang et al . , 2015 ) .", "entities": [[6, 7, "MethodName", "LSTM"]]}, {"text": "The outputs of these layers are concatenated and , in order to map the word representation obtained from the LSTM module into the label distribution , passed to a one - layer feed - forward network .", "entities": [[19, 20, "MethodName", "LSTM"]]}, {"text": "A Conditional Random Field is applied to the class predictions to jointly assign the sequence tags using a transition matrix .", "entities": [[1, 4, "MethodName", "Conditional Random Field"]]}, {"text": "This CRF layer improves performance of the model ( Lample et al . , 2016 ) as it ensures the output sequence takes into account dependencies between the tags and also models the constraints the output sequence adheres to ( e.g. I - PER can not follow B - LOC ) .", "entities": [[1, 2, "MethodName", "CRF"]]}, {"text": "3.2 Proposed Architecture ( MultDomain \u2013 SP \u2013 Aux ) We propose a new architecture based on the BiLSTM \u2013 CRF model tailored to the three proposed experimental setups .", "entities": [[18, 19, "MethodName", "BiLSTM"], [20, 21, "MethodName", "CRF"]]}, {"text": "Our proposed architecture enhances the base architecture with three components : a ) domain -speci\ufb01c and -independent feed - forward layers that process the BiLSTM outputs ; b ) domain -speci\ufb01c and -independent feed forward layers CRFs ; c ) a multi - task learning objective that learns domain labels as an auxiliary task .", "entities": [[24, 25, "MethodName", "BiLSTM"], [41, 45, "TaskName", "multi - task learning"]]}, {"text": "The proposed architecture changes are motivated by the aim of capturing commonalities in which named entities are referred to , in any given genre , while still allowing for the model to tease apart and exploit domain - speci\ufb01c aspects .", "entities": []}, {"text": "The architecture is also designed to capture these commonalities across label relationships , which can vary across domains .", "entities": []}, {"text": "In addition , the multi - task objective further assists the model to leverage domaindependent and -independent components .", "entities": []}, {"text": "The choice of input representation is orthogonal to the proposed architecture and our extensions to the architecture can be combined with any input repre-", "entities": []}, {"text": "8479sentation .", "entities": []}, {"text": "The model architecture is presented in Figure 1 and described below :", "entities": []}, {"text": "Private and Shared Layers", "entities": []}, {"text": "We rely on the shared - private paradigm where the model learns both a shared representation across all domains and is useful when the domain of the input is unknown or unseen in training , and a private domain representation that mostly helps tagging in that domain .", "entities": []}, {"text": "We model the shared and private features at both the feature mapping stage connecting the BiLSTM outputs to the CRF(s ) and at the CRF level .", "entities": [[15, 16, "MethodName", "BiLSTM"], [24, 25, "MethodName", "CRF"]]}, {"text": "We expect the features extracted by the BiLSTM layers to model the structure of the input across all domains .", "entities": [[7, 8, "MethodName", "BiLSTM"]]}, {"text": "The feed - forward layers capture the domainspeci\ufb01c and -independent information by using private output layers for each domain and one shared output layer .", "entities": []}, {"text": "In training , the BiLSTM outputs are projected to both the shared layer and the private layer based on the domain label provided in training .", "entities": [[4, 5, "MethodName", "BiLSTM"]]}, {"text": "The CRF layer is used to make a global decision for the entire tag sequence by modelling label dependencies .", "entities": [[1, 2, "MethodName", "CRF"]]}, {"text": "We expect that this decision is , at least partially , dependent on domain - speci\ufb01c relationships in the label space .", "entities": []}, {"text": "Hence , each feedforward layer feeds into either private CRFs ( one for each domain ) or a shared CRF .", "entities": [[19, 20, "MethodName", "CRF"]]}, {"text": "The separation of the shared and private layers could happen before the CRF stage ( late separation ) or before the feed - forward layer stage ( early separation ) .", "entities": [[12, 13, "MethodName", "CRF"]]}, {"text": "We investigate the in\ufb02uence of each individual addition on the multi - domain performance in our analysis section through ablation studies .", "entities": []}, {"text": "Given an input , both the shared and the private parameters are used in learning to predict the output .", "entities": []}, {"text": "The set of private parameters for each domain are only updated by data from the same domain while the set of shared parameters are updated in a pooled way by taking all available data points in the training stage regardless of the domain characteristics .", "entities": []}, {"text": "For a given data point , inference can be run either by : a ) passing it though the private components if the domain label is known ; b ) through the shared components if the domain label in unknown or the domain of the data is unseen in training .", "entities": []}, {"text": "To this end , the objective function for the private and shared layers is : LNER SP(x ; y )", "entities": []}, {"text": "= LNER S(x ; y ) + LNER P(x ; y)(1 )", "entities": []}, {"text": "where LNER SandLNER", "entities": []}, {"text": "Pstand for the shared layer loss and private layer loss respectively .", "entities": [[5, 6, "MetricName", "loss"], [9, 10, "MetricName", "loss"]]}, {"text": "Multi - Task Learning of Domain Labels Further , to better guide the learning process , we augment our architecture with a multi - task learning objective .", "entities": [[0, 4, "TaskName", "Multi - Task Learning"], [22, 26, "TaskName", "multi - task learning"]]}, {"text": "Through this , the model learns to predict the domain label of each sample in training as an auxiliary task .", "entities": []}, {"text": "The architecture uses average pooling on BiLSTM outputs followed by a fully connected layer .", "entities": [[3, 5, "MethodName", "average pooling"], [6, 7, "MethodName", "BiLSTM"]]}, {"text": "Finally , softmax is applied over the learned domain feature to obtain a probability distribution of all domain labels .", "entities": [[2, 3, "MethodName", "softmax"]]}, {"text": "The domain classi\ufb01cation objective is to minimize the crossentropy loss Ldomain ( x;yd)for an input xwith domain label yd .", "entities": [[9, 10, "MetricName", "loss"]]}, {"text": "The global objective function is the combination of the NER loss function and domain loss : L(x;y ; yd ) = LNER SP(x ; y ) + Ldomain ( x ; yd)(2 ) 4 Experimental setup 4.1 Data We use a collection of data sets spanning eight genres to evaluate our methods .", "entities": [[9, 10, "TaskName", "NER"], [10, 11, "MetricName", "loss"], [14, 15, "MetricName", "loss"]]}, {"text": "In addition , in order to test the feasibility of NER tagging in a zero - shot domain setup , we present additional data covering four other genres .", "entities": [[10, 11, "TaskName", "NER"]]}, {"text": "Each genre of documents is considered a domain in modelling .", "entities": []}, {"text": "4.1.1 Data Sets The data set collection used in learning the multidomain models ( denoted as \u2018 Open Data \u2019 in the rest of the paper ) includes the following three data sets : CoNLL 2003 We use the data set released as part of CoNLL 2003 shared task for English ( Tjong Kim Sang and De Meulder , 2003 ) , which is arguably the most popular data set for NER and is regularly used as a benchmark for this task .", "entities": [[34, 36, "DatasetName", "CoNLL 2003"], [45, 47, "DatasetName", "CoNLL 2003"], [71, 72, "TaskName", "NER"]]}, {"text": "This data is a collection of news articles from the Reuters Corpus .", "entities": []}, {"text": "Twitter The Twitter data set consists of 22,000 tweets representative of multiple English - speaking locales and a variety of topics that span 11 years of Twitter posts ( 2009\u20132019 ) .", "entities": []}, {"text": "This data was annotated with Organizations ( ORG ) , Persons ( PER ) and Locations ( LOC ) , using the annotation guidelines used in annotating past data sets ( Tjong Kim Sang and De Meulder , 2003 ) supplemented with examples that are speci\ufb01c to Twitter data .", "entities": []}, {"text": "OntoNotes ( six genres ) The OntoNotes data set ( Hovy et al . , 2006 ) consists for six different genres annotated , amongst others , with named entities and their types .", "entities": [[0, 1, "DatasetName", "OntoNotes"], [6, 7, "DatasetName", "OntoNotes"]]}, {"text": "In this data , each genre refers to a different source , which includes newswire ( NW ) ,", "entities": []}, {"text": "8480Data Set # Tokens DensityEntity Distribution ORG PER LOC CoNLL 2003 302811 14.52 % 33.2 % 38.8 % 28.0 % Twitter 227019 8.02 % 36.9 % 46.5 % 16.5 % OntoNotes - NW 490738 8.89 % 55.1 % 21.1 % 23.8 % OntoNotes - BN 258625 9.06 % 27.5 % 37.2 % 35.3 % OntoNotes - MZ 197520 7.84 % 28.1 % 41.9 % 30.0 % OntoNotes - BC 239236 5.49 % 27.5 % 39.8 % 32.8 % OntoNotes - TC 114463 1.59 % 12.3 % 45.6 % 42.1 % OntoNotes - WB 490738 2.17 % 25.5 % 44.4 % 30.1 % Zero - Shot - A 103992 3.10 % 53.3 % 24.4 % 22.2 % Zero - Shot - B 794199 8.48 % 55.5 % 28.4 % 16.1 % Zero - Shot - C 156032 10.06 % 64.4 % 14.4 % 21.1 % Zero - Shot - D 27522 5.84 % 38.8 % 31.9 % 29.4 % Table 1 : Size of data sets , NE density ( tokens that are named entities ) and distributions across entity types for both open and zero - shot data sets .", "entities": [[9, 11, "DatasetName", "CoNLL 2003"], [30, 31, "DatasetName", "OntoNotes"], [42, 43, "DatasetName", "OntoNotes"], [54, 55, "DatasetName", "OntoNotes"], [66, 67, "DatasetName", "OntoNotes"], [78, 79, "DatasetName", "OntoNotes"], [90, 91, "DatasetName", "OntoNotes"]]}, {"text": "broadcast news ( BN ) , broadcast conversation ( BC ) , magazine ( MZ ) , telephone conversation ( TC ) and web data ( WB ) ( Pradhan et al . , 2013 ) .", "entities": []}, {"text": "Note that we replace the \u2018 LOC \u2019 , \u2018 FAC \u2019 and \u2018 GPE \u2019 tags in the OntoNotes data with the \u2018 LOC \u2019 type in order to be consistent with the de\ufb01nition of \u2018 LOC \u2019 in CoNLL 2003 , as also done in ( Augenstein et al . , 2017 ) .", "entities": [[19, 20, "DatasetName", "OntoNotes"], [40, 42, "DatasetName", "CoNLL 2003"]]}, {"text": "Zero Shot Genres Finally , for zero - shot genre NER , we use a collection of internal data sets from four different genres spanning news , closed captions and other documents .", "entities": [[10, 11, "TaskName", "NER"]]}, {"text": "All four genres were annotated with the same entity types and using similar guidelines .", "entities": []}, {"text": "4.1.2 Data Set Statistics Data set statistics are presented in Table 1 .", "entities": []}, {"text": "This shows that all domains are represented with a substantial number of sentences , although the prevalence of named entities and their distribution across types varies , as expected from data sets collected from different sources and genres .", "entities": []}, {"text": "We also see that the zero - shot domains are signi\ufb01cantly different in entity type distribution and density than the training data , making them well - suited for this setting .", "entities": []}, {"text": "4.1.3 Data Processing In order to present comparable results across all different data sets , we limit our experiments to three different types of entities that are present in all the above data sets and annotated using similar guidelines : organizations ( including geo - political entities and facilities ) , persons and locations .", "entities": []}, {"text": "In case other types of entities exist in the data ( e.g. MISC for CoNLL , dates for OntoNotes ) , these are considered to be not an entity , similar to ( Augenstein et al . , 2017).We used the BIO tagging scheme in all our experiments , as this is arguably the most popular and differences in results between this tagging scheme and others , such as the BILOU scheme , are very small in practice ( Ratinov and Roth , 2009 ) .", "entities": [[18, 19, "DatasetName", "OntoNotes"]]}, {"text": "4.1.4 Data Splits We train our models using the open data sets from CoNLL , Twitter and OntoNotes .", "entities": [[17, 18, "DatasetName", "OntoNotes"]]}, {"text": "The training , development and test splits of CoNLL and OntoNotes follows the standard splits .", "entities": [[10, 11, "DatasetName", "OntoNotes"]]}, {"text": "Similarly , we randomly split the Twitter data set randomly into 70 % for training , 10 % for development and 20 % for testing .", "entities": []}, {"text": "The \ufb01nal train , dev and test sets are obtained by joining all the respective splits across the individual data sets .", "entities": []}, {"text": "4.2 Other Methods We evaluate several baseline methods and other competitive methods introduced in past research and compare to our proposed architecture ( MultDomain \u2013 SP \u2013 Aux ) described in Section 3.2 .", "entities": []}, {"text": "These methods focus on different variations of the neural model architecture , while holding the input embeddings constant .", "entities": []}, {"text": "InDomain trains an individual NER model using the base architecture for each of the known domains .", "entities": [[4, 5, "TaskName", "NER"]]}, {"text": "In inference , the corresponding in - domain model is used .", "entities": []}, {"text": "This allows us to establish the baseline individual domain performance when no information is shared between the domains in training .", "entities": []}, {"text": "InDomain - DomainClassi\ufb01er uses the same NER models as the InDomain model .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "The InDomain approach is however unable to directly perform inference on sentences where the domain label is unknown at inference time .", "entities": []}, {"text": "We thus build a separate domain classi\ufb01er using a Bi - LSTM recurrent neural network that feeds the \ufb01nal hidden state into a feed - forward network to recognize the domain of a given input sentence and route it to the appropriate InDomain NER model .", "entities": [[11, 12, "MethodName", "LSTM"], [43, 44, "TaskName", "NER"]]}, {"text": "PoolDomain naively pools all available data , disregarding the domain information and trains a model using the base architecture .", "entities": []}, {"text": "This model thus ignores the domain information when training , albeit uses all available training data .", "entities": []}, {"text": "Data pooling is the standard baseline in most domain adaptation experiments .", "entities": [[8, 10, "TaskName", "domain adaptation"]]}, {"text": "PoolDomain - Init uses all available data and uses the domain information to train models on data from one domain at once .", "entities": []}, {"text": "After training on data from each domain , the model uses the weights as", "entities": []}, {"text": "8481initialization for training on next domain .", "entities": []}, {"text": "This is similar to the INIT strategy for domain adaptation used in ( Mou et al . , 2016 ; Lee et al . , 2018 ) .", "entities": [[8, 10, "TaskName", "domain adaptation"]]}, {"text": "We perform this weight initialization and \ufb01ne - tuning process over all the domains consecutively , where the order is de\ufb01ned by the density of entities , starting with the highest one .", "entities": []}, {"text": "PoolDomain - GradRev trains the base architecture using a gradient reversal layer ( Ganin and Lempitsky , 2014 ) .", "entities": []}, {"text": "The gradient reversal technique aims to confuse the domain discriminator while learning NER with the combination of the training data from all domains .", "entities": [[12, 13, "TaskName", "NER"]]}, {"text": "PoolDomain+DomainFeat trains a base architecture model over all available data and , in addition to the text - based features , the domain information is explicitly represented by passing it through a domain embedding .", "entities": []}, {"text": "This is appended to the word - level features that are used as input to the BiLSTM layers .", "entities": [[16, 17, "MethodName", "BiLSTM"]]}, {"text": "The domain embeddings are randomly initialized .", "entities": []}, {"text": "MultDomain - SP extends the MULT method ( Yang et al . , 2017 ) to the multi - domain setup .", "entities": []}, {"text": "This method uses a domain - speci\ufb01c CRF for each domain and a shared CRF for all domains .", "entities": [[7, 8, "MethodName", "CRF"], [14, 15, "MethodName", "CRF"]]}, {"text": "Both the BiLSTM and the feed - forward layers are shared across all domains .", "entities": [[2, 3, "MethodName", "BiLSTM"]]}, {"text": "Inference can be done either through the private layer corresponding to the domain of the input \u2013 denoted asMultDomain - MultCRF ( P ) \u2013 or through the shared layer \u2013 denoted as MultDomain - MultCRF ( S ) \u2013 in which case this can be used when the domain label is unknown in inference .", "entities": []}, {"text": "4.3 Implementation Details For our experiments , we largely follow the training and evaluation procedure used in ( Akbik et al . , 2018 ) .", "entities": []}, {"text": "As hyperparameters , we follow most suggestions outlined in the in - depth study on model robustness ( Reimers and Gurevych , 2017 ) .", "entities": []}, {"text": "Our training uses 256 hidden states for BiLSTM with mini - batch size of 32 .", "entities": [[7, 8, "MethodName", "BiLSTM"], [9, 13, "HyperparameterName", "mini - batch size"]]}, {"text": "The model parameters are updated using back - propagation and Adam optimizer ( Kingma and Ba , 2014 ) .", "entities": [[10, 11, "MethodName", "Adam"], [11, 12, "HyperparameterName", "optimizer"]]}, {"text": "The learning rate is 1e\u00003with weight decay value 1e\u00005 .", "entities": [[1, 3, "HyperparameterName", "learning rate"], [5, 7, "MethodName", "weight decay"]]}, {"text": "The model is regularized with a locked dropout rate of 0.5 .", "entities": []}, {"text": "We use 300 - dimensional pre - trained word embeddings as described in Section 3.1 , whereas the character LSTM is randomly initialized and has a hidden dimension of 64 .", "entities": [[8, 10, "TaskName", "word embeddings"], [19, 20, "MethodName", "LSTM"]]}, {"text": "The embeddings are updated on the training data .", "entities": []}, {"text": "When training the domain features together with the NER ( PoolDomain+DomainFeat ) , we set the domain embedding size to 128 .", "entities": [[8, 9, "TaskName", "NER"]]}, {"text": "We train all models for 20 epochs and report the results for the model performing best on the joint development set of the open data set collection .", "entities": []}, {"text": "5 Results In this section , we present and compare the results of all the methods introduced previously .", "entities": []}, {"text": "Experiments are conducted \ufb01rst on the open data collection introduced in Section 4.1 in the Multi - Domain and Multi - Domain with Unknown Label setups .", "entities": []}, {"text": "Following , we evaluate the performance of our model on the data used for zero - shot genre NER .", "entities": [[18, 19, "TaskName", "NER"]]}, {"text": "The goal of these experiments is to examine the NER performance across the three proposed experimental setups which focus on model generalizability across multiple domains .", "entities": [[9, 10, "TaskName", "NER"]]}, {"text": "We note that the results below can not be directly compared to the state - of - the - art results on each data set , as we restrict the entity types to PER , ORG , LOC , such that these types are constant across all data sets .", "entities": []}, {"text": "5.1 Multi - Domain with Known Domain Labels First , we compare models when assuming the domain label of each test document is known at inference time .", "entities": []}, {"text": "The results are listed in Table 2 .", "entities": []}, {"text": "Our proposed method \u2013 MultDomain - SP - Aux ( P ) \u2013 obtains the best results across the entire test collection in both micro - average ( +0.43 ) and macro - average ( +1.94 ) compared to all other approaches and performs best on 7 out of the 8 domains .", "entities": []}, {"text": "The second best method is the PoolDomain+DomainFeat which uses the domain feature as input .", "entities": []}, {"text": "Our method consistently surpasses the in - domain classi\ufb01ers ( InDomain ) on microaverage ( +1.48 ) and macro - average ( +3.11 ) , showing the limitations of naive modeling approaches .", "entities": []}, {"text": "Although increases exist across all domains , these are most prominent in domains like TC ( +5.36 ) that have a low density of named entities and where indomain models have access to limited amounts of data .", "entities": []}, {"text": "However , the in - domain performance is better than the pooled method of training , which shows consistent drops in performance on some domains ( -8.69 on WB , -6.77 on BC , - 1.98 on CoNLL ) , where information from other domains did not bene\ufb01t the model .", "entities": []}, {"text": "8482ModelWorks on Unknown Domain LabelsCoNLL", "entities": []}, {"text": "Twitter NW BN MZ BC TC WB\u0016\u2013Avg M \u2013 Avg InDomain 7 89.91 67.36 91.09 91.09 86.90 84.41 77.06 64.74 85.29 81.57 InDomain+DomainClassi\ufb01er 3 88.92 66.98 90.48 90.21 85.63 84.64 76.28 59.62 83.93 80.35 PoolDomain 3 87.93 66.21 90.86 92.76 87.73 89.06 70.29 56.05 83.94 80.11 PoolDomain \u2013 Init 3 31.31 15.74 63.34 67.63 47.30 63.30 33.93 57.55 47.00 47.55 PoolDomain \u2013 GradRev 3 83.49 54.55 83.95 86.87 77.46 83.93 77.78 50.88 77.29 74.86 PoolDomain+DomainFeat 7 90.74 67.80 90.32 92.27 89.12 89.86 78.40 63.37 86.34 82.74 MultDomain \u2013 SP ( P ) 7 87.70 59.16 88.96 93.51 88.52 89.95 77.97 55.51 82.12 80.16 MultDomain \u2013 SP ( S ) 3 87.41 57.98 88.64 93.47 88.39 89.00 55.51 54.39 81.73 80.08 MultDomain \u2013 SP \u2013 Aux ( P ) 7 90.21 69.15 91.09 93.64 91.38 90.67 82.42 67.44 86.77 84.68 MultDomain \u2013 SP \u2013 Aux ( S ) 3 88.43 67.13 91.26 93.59 87.67 89.54 78.77 59.63 84.68 82.30 Table 2 : Experimental results on the eight data sets , as well as micro ( \u0016- ) and macro ( M- ) averaged across data sets .", "entities": []}, {"text": "Performance is measured using micro F1 score .", "entities": [[4, 6, "MetricName", "micro F1"]]}, {"text": "The rows with 3indicate methods that can be applied when the domain label is not known at inference time .", "entities": []}, {"text": "( S ) and ( P ) denote if inference is done through the shared ( S ) or private ( P ) layers of the architecture .", "entities": []}, {"text": "Results in bold are the best across all models , those underlined are best across methods that work with unknown domain labels .", "entities": []}, {"text": "5.2 Multi - Domain with Unknown Domain Labels We now focus on the experimental setup where domain labels are unknown for each data point at inference time .", "entities": []}, {"text": "This is akin to a setup where the user is agnostic to the data the model was trained on .", "entities": []}, {"text": "As only a subset of the models can perform inference in this scenario , the results are a subset of those in Table 2 .", "entities": []}, {"text": "Our model \u2013 MultDomain - SP - Aux ( S ) \u2013 gains the best overall performance in this setup , with 1:95macro - average F1 increase over the next best method ( InDomain+DomainClassi\ufb01er ) .", "entities": [[24, 26, "MetricName", "average F1"]]}, {"text": "The other standard baseline for domain adaptation ( PoolDomain ) obtains a similar performance ( \u00002:19compared to our method ) to the in - domain approach , which shows the bene\ufb01ts of multidomain adaptation .", "entities": [[5, 7, "TaskName", "domain adaptation"]]}, {"text": "PoolDomain - Init is performing overall poorly , which shows that the INIT transfer learning strategy that is somewhat effective for source - target domain adaptation does not work well in the multidomain setup .", "entities": [[13, 15, "TaskName", "transfer learning"], [24, 26, "TaskName", "domain adaptation"]]}, {"text": "Our intuition is that this technique is unable to learn robust features sequentially across N domains , as it performs poorly on the initial trained domains .", "entities": []}, {"text": "PoolDomain - GradRev gains relatively weak performance overall , lower than the in - domain baseline .", "entities": []}, {"text": "5.3 Zero - Shot Domain Finally , we show the results on the experimental setup where the test data is the four \u2018 Zero - Shot Genres \u2019 , which were not used in during training .", "entities": []}, {"text": "Table 3 shows the experimental results of all methods that can run inference with unknown domainModelsZero - Shot GenresM \u2013 Avg A B C D InDomain+DomainClassi\ufb01er 47.16 60.04 62.00 59.50 57.17 PoolDomain 52.61 62.53 63.53 61.55 60.05 PoolDomain - Init 24.38 36.92 47.13 19.47 31.98 PoolDomain - GradRev 49.48 68.97 67.95 57.41 60.95 MultDomain - SP ( S ) 50.9 72.27 68.19 61.86 63.30 MultDomain - SP - Aux ( S ) 54.50 67.77 70.30 64.02 64.15 Table 3 : Evaluation results on data from genres unseen in training .", "entities": []}, {"text": "labels , as we assume that in this setup , the end - user does not have knowledge about the domains used in training and which of these are most similar to the test point .", "entities": []}, {"text": "Results show that our proposed method obtains again the best results , with a consistent margin of 2.24 macro - average F1 improvement over the next method .", "entities": [[20, 22, "MetricName", "average F1"]]}, {"text": "Pooling all data ( PoolDomain ) obtains better performance than building in - domain classi\ufb01ers with domain classi\ufb01cation ( InDomain+DomainClassi\ufb01er ) unlike in the other setups .", "entities": []}, {"text": "This also shows that the zero - shot domains we used are indeed different to any of the ones in training and pooling all data manages to build a slightly more robust model than individual ones trained on less data .", "entities": []}, {"text": "The in - domain models perform 5.21 F1 points lower than our approach , the largest gap in all experimental setups , highlighting the robustness of the multi - domain modeling approach .", "entities": [[7, 8, "MetricName", "F1"]]}, {"text": "The MultDomain - SP ( S ) model is second best , and as this is the base for our method , we discuss its performance in the ablation study from the next section .", "entities": []}, {"text": "84836 Analysis 6.1 Ablation Experiments We \ufb01rst focus on understanding the impact of each component added to our proposed method over the base architecture through an ablation study .", "entities": []}, {"text": "Table 4 shows results using the private layer ( MultDomain - SP - Aux ( P ) ) when each of the three components are alternatively turned off : SharedPrivate Linear layer , Shared - Private CRF and the domain prediction auxiliary task .", "entities": [[30, 32, "MethodName", "Linear layer"], [36, 37, "MethodName", "CRF"]]}, {"text": "Shared vs. Shared - Private CRF With the rest of the architecture \ufb01xed , the results show that the shared - private CRF performs close to the shared CRF when the shared linear layer is used ( 80.08 vs. 80.16 ; 82.04 vs. 82.74 ; all comparisons in this section are on macro - average ) .", "entities": [[5, 6, "MethodName", "CRF"], [22, 23, "MethodName", "CRF"], [28, 29, "MethodName", "CRF"], [32, 34, "MethodName", "linear layer"]]}, {"text": "However , once we use a separate linear layer between the BiLSTM and each CRF , the difference between having the shared and the shared - private CRFs increases drastically ( 81.36 vs. 83.11 ; 82.30 vs. 84.68 ) .", "entities": [[7, 9, "MethodName", "linear layer"], [11, 12, "MethodName", "BiLSTM"], [14, 15, "MethodName", "CRF"]]}, {"text": "With only this late separation , the inputs to CRF decoders are still domain - independent features , which makes it hard for the linear CRF to adapt .", "entities": [[9, 10, "MethodName", "CRF"], [25, 26, "MethodName", "CRF"]]}, {"text": "When the inputs are already domain - dependent , the linear CRF can better use this information in performing the joint inference of the sequence .", "entities": [[11, 12, "MethodName", "CRF"]]}, {"text": "We note that only using shared - private CRF with the base architecture is equivalent to the MultDomain - SP method ( Yang et al . , 2017 ) .", "entities": [[8, 9, "MethodName", "CRF"]]}, {"text": "Shared vs. Shared - Private Linear Projections", "entities": []}, {"text": "The results show that regardless of the other parameters , adding shared and private linear layers between the BiLSTM layers and the CRF(s ) is always bene\ufb01cial ( 80.08 vs. 81.36 ; 80.16 vs. 83.11 ; 82.04 vs. 82.30 ; 82.74 vs. 84.68 ) .", "entities": [[18, 19, "MethodName", "BiLSTM"]]}, {"text": "The improvements are relatively larger when combined with shared and private CRF , as previously seen .", "entities": [[11, 12, "MethodName", "CRF"]]}, {"text": "Multi - Task Learning of Domain Labels", "entities": [[0, 4, "TaskName", "Multi - Task Learning"]]}, {"text": "Finally , we compare the impact of adding the multi - task learning objective .", "entities": [[9, 13, "TaskName", "multi - task learning"]]}, {"text": "We \ufb01nd that , similar to the linear layers , adding the domain prediction task is always bene\ufb01cial for the model with the increase being larger if is only a shared linear layer .", "entities": [[31, 33, "MethodName", "linear layer"]]}, {"text": "We expect that the two tasks at different levels of granularity rely on shared structure in the original semantic space .", "entities": []}, {"text": "The document - level domain labels can help regularize the training , providing generic information about which low - level features are valuable to entity - level recognition.6.2 InDomain with Oracle Choice", "entities": []}, {"text": "In order to understand the limitations of the multidomain setup , we study whether the models we can build from the available data could theoretically achieve better overall performance .", "entities": []}, {"text": "We use an oracle - based selection technique on the in - domain models to select , after the prediction and using the gold labels the model which performed best for each test instance , as selected using F1 score or , if there are no entities , the model with most O predictions .", "entities": [[38, 40, "MetricName", "F1 score"]]}, {"text": "If multiple models are tied , we choose one at random .", "entities": []}, {"text": "The oracle thus provides the counterfactually \u201c Optimal \u201d strategy of model selection for each test instance and represents an upper bound on strategies relying on InDomain models .", "entities": [[11, 13, "TaskName", "model selection"]]}, {"text": "Table 5 compares the oracle strategy predictions with the InDomain+DomainClassi\ufb01er and the MultDomain - SP - Aux model .", "entities": []}, {"text": "The results show that even though our model improves substantially over the in - domain models , an oracle selection method would push performance much higher ( +6.73 F1 on the open data ) .", "entities": [[28, 29, "MetricName", "F1"]]}, {"text": "This highlights both the variability of NER models trained on different data sets and that there is potentially more room for improvements in the multi - domain setup .", "entities": [[6, 7, "TaskName", "NER"]]}, {"text": "6.3 InDomain Models The Supplementary Material shows a breakdown of the domain prediction labels for three methods : domain classi\ufb01cation , domain prediction in the proposed MultDomain - SP - Aux model and the oracle in - domain choice on gold data .", "entities": [[4, 6, "DatasetName", "Supplementary Material"]]}, {"text": "The oracle strategy selects the predictions from all in - domain models .", "entities": []}, {"text": "Based on this , we analyzed the performance of each individual in - domain model when tested on all domains in Table 6 .", "entities": []}, {"text": "We \ufb01nd that although the Oracle strategy uses a mix of models , any model alone is unable to generalize to other domains ( 67.19 vs. 84.68 best InDomain model compared to the best overall model ) .", "entities": []}, {"text": "In the zero - shot genres , the Twitter model performs close to the MultDomain - SP - Aux model ( -0.56 F1 ) , albeit it is 24 F1 lower on the multi - domain setup .", "entities": [[22, 23, "MetricName", "F1"], [29, 30, "MetricName", "F1"]]}, {"text": "This reinforces that learning shared domain features as opposed to learning individual models helps boost performance and is more robust to different types of inputs .", "entities": []}, {"text": "7 Runtime Comparison Finally , we compare the runtime difference across various methods listed in the experiment section to test the practical implications of using our pro-", "entities": []}, {"text": "8484Auxiliary Task Linear CRF CoNLL Twitter NW BN MZ BC TC WB\u0016\u2013Avg M \u2013 Avg 7 SharedShared 87.41 57.98 88.64 93.47 88.39 89.00 55.51 54.39 81.73 80.08 Sh - Private 87.70 59.16 88.96 93.51 88.52 89.95 77.97 55.51 82.12 80.16 7 Sh - PrivateShared 87.65 64.45 90.88 92.82 87.92 88.75 80.60 57.81 83.77 81.36 Sh - Private 89.57 67.78 90.98 92.45 90.10 88.75 80.86 64.38 85.95 83.11 3 SharedShared 89.00 67.27 91.10 93.00 89.15 89.00 78.36 59.48 85.69 82.04 Sh - Private 89.48 67.19 91.31 93.48 89.99 89.48 79.18 61.84 86.55 82.74 3 Sh - PrivateShared 88.43 67.13 91.26 93.59 87.67 89.54 78.77 59.63 84.68 82.30 Sh - Private 90.21 69.15 91.09 93.64 91.38 90.67 82.42 67.44 86.77 84.68 Table 4 : Ablation study comparing the performance ( F1 score ) of models trained with and without : shared - private linear projections of BiLSTM outputs , shared - private CRF heads and multi - task domain classi\ufb01cation .", "entities": [[3, 4, "MethodName", "CRF"], [128, 130, "MetricName", "F1 score"], [144, 145, "MethodName", "BiLSTM"], [150, 151, "MethodName", "CRF"]]}, {"text": "Model Open Data Zero - Shot InDomain + DomainClassi\ufb01er 80.35 57.17 MultDomain - SP - Aux 84.68 64.15 Oracle with InDomain 91.41 80.27 Table 5 : Performance in macro - average F1 of the InDomain models with an oracle model selection strategy using gold test data compared to selected methods .", "entities": [[30, 32, "MetricName", "average F1"], [39, 41, "TaskName", "model selection"]]}, {"text": "Model Open Data Zero - Shot CoNLL 64.26 61.40 Twitter 60.59 63.59 NW 67.19 59.00 BN 66.08 54.82", "entities": []}, {"text": "MZ 57.52 48.62 BC 59.19 46.30", "entities": []}, {"text": "TC 47.25 37.41 WB 44.09 25.41 Table 6 : Results of InDomain models trained on each domain independently on the open data set collection and the zero - shot genres reported in macro average of F1 for each domain .", "entities": [[35, 36, "MetricName", "F1"]]}, {"text": "posed multi - domain modelling approach .", "entities": []}, {"text": "In test phase , we set the batch size as 128 .", "entities": [[7, 9, "HyperparameterName", "batch size"]]}, {"text": "Table 7 shows the average time of inference time used for each model .", "entities": []}, {"text": "Our proposed model architecture takes 0.15 ms ( 33 % increase ) longer for inference than InDomain orPoolDomain models , which is a result of more model parameters .", "entities": []}, {"text": "However , our proposed architecture is still 0.19 ms faster than using the InDomain+DomainClassi\ufb01er approach .", "entities": []}, {"text": "In addition to inference runtime , we also \ufb01nd that the training time is not signi\ufb01cantly more than the combined training time of N in - domain models .", "entities": []}, {"text": "The main additions are that of the shared layers and the auxiliary task to the components of the N in - domain models and is thus a constant addition in the number of parameters to the total of N indomain models .", "entities": [[31, 34, "HyperparameterName", "number of parameters"]]}, {"text": "Hence , the model would scale by a constant with respect to the number of input domains ( N+1 number of components , where N is the number of domains ) .", "entities": []}, {"text": "This should allow our pro - posed model to scale to a large number of domains .", "entities": []}, {"text": "This highlights that the proposed MultDomain \u2013 SP \u2013 Aux model is a viable option for real - world applications .", "entities": []}, {"text": "Model Runtime ( ms ) InDomain 0.45 InDomain+DomainClassi\ufb01er 0.79 PoolDomain 0.45 PoolDomain \u2013 Init 0.43 PoolDomain \u2013 GradRev 0.47 PoolDomain+DomainFeat 0.45 MultDomain \u2013 SP 0.56 MultDomain \u2013 SP \u2013 Aux 0.60 Table 7 : Averaged inference time ( in ms ) per sentence query on Open Dataset .", "entities": []}, {"text": "8 Conclusions Robustness of NLP models is essential to their wider adoption and usability .", "entities": []}, {"text": "Existing NER approaches are widely faced with limited scalability when applied to data that spans multiple domains .", "entities": [[1, 2, "TaskName", "NER"]]}, {"text": "This paper introduced three experimental setups that provide a framework for evaluating the robustness of NER models .", "entities": [[15, 16, "TaskName", "NER"]]}, {"text": "These include learning from data in multiple domains and testing on all domains , when the domain label of the test point is unknown and when this does not belong to a domain seen in training .", "entities": []}, {"text": "Building on past research , we proposed a new neural architecture that achieves substantial improvements of up to 5 F1 points when compared to standard methods .", "entities": [[19, 20, "MetricName", "F1"]]}, {"text": "Future work will focus on domain adaptation at the embedding layer .", "entities": [[5, 7, "TaskName", "domain adaptation"]]}, {"text": "References Oshin Agarwal , Yinfei Yang , Byron C. Wallace , and Ani Nenkova .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Interpretability analysis for named entity recognition to understand sys-", "entities": [[3, 6, "TaskName", "named entity recognition"]]}, {"text": "8485tem predictions and how they can improve .", "entities": []}, {"text": "ArXiv , abs/2004.04564 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Alan Akbik , Tanja Bergmann , and Roland V ollgraf .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Pooled contextualized embeddings for named entity recognition .", "entities": [[4, 7, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 724\u2013728 , Minneapolis , Minnesota .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Alan Akbik , Duncan Blythe , and Roland V ollgraf .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Contextual string embeddings for sequence labeling .", "entities": []}, {"text": "In Proceedings of the 27th International Conference on Computational Linguistics , pages 1638 \u2013 1649 , Santa Fe , New Mexico , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Isabelle Augenstein , Leon Derczynski , and Kalina Bontcheva . 2017 .", "entities": [[4, 5, "DatasetName", "Derczynski"]]}, {"text": "Generalisation in named entity recognition : A quantitative analysis .", "entities": [[2, 5, "TaskName", "named entity recognition"]]}, {"text": "Computer Speech & Language , 44:61\u201383 .", "entities": []}, {"text": "John Blitzer , Mark Dredze , and Fernando Pereira . 2007 .", "entities": []}, {"text": "Biographies , Bollywood , boom - boxes and blenders : Domain adaptation for sentiment classi\ufb01cation .", "entities": [[10, 12, "TaskName", "Domain adaptation"]]}, {"text": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 440\u2013447 , Prague , Czech Republic . Association for Computational Linguistics .", "entities": []}, {"text": "John Blitzer , Ryan McDonald , and Fernando Pereira . 2006 .", "entities": []}, {"text": "Domain adaptation with structural correspondence learning .", "entities": [[0, 2, "TaskName", "Domain adaptation"]]}, {"text": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing , pages 120\u2013128 , Sydney , Australia . Association for Computational Linguistics .", "entities": []}, {"text": "Piotr Bojanowski , Edouard Grave , Armand Joulin , and Tomas Mikolov .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Enriching word vectors with subword information .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics , 5:135\u2013146 .", "entities": []}, {"text": "Ciprian Chelba and Alex Acero .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Adaptation of maximum entropy capitalizer : Little data can help a lo .", "entities": []}, {"text": "In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing , pages 285\u2013292 , Barcelona , Spain .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Xilun Chen , Ahmed Hassan Awadallah , Hany Hassan , Wei Wang , and Claire Cardie .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Multi - source cross - lingual model transfer : Learning what to share .", "entities": []}, {"text": "InProceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 3098 \u2013 3112 , Florence , Italy .", "entities": [[18, 19, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Xilun Chen and Claire Cardie .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Multinomial adversarial networks for multi - domain text classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) , pages 1226\u20131240,New Orleans , Louisiana .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Silviu Cucerzan .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Large - scale named entity disambiguation based on Wikipedia data .", "entities": [[4, 6, "TaskName", "entity disambiguation"]]}, {"text": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLPCoNLL ) , pages 708\u2013716 , Prague , Czech Republic . Association for Computational Linguistics .", "entities": []}, {"text": "Aron Culotta and Jeffrey Sorensen .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "Dependency tree kernels for relation extraction .", "entities": [[4, 6, "TaskName", "relation extraction"]]}, {"text": "In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL-04 ) , pages 423\u2013429 , Barcelona , Spain .", "entities": []}, {"text": "Hal Daum \u00b4 e III .", "entities": []}, {"text": "2007 .", "entities": []}, {"text": "Frustratingly easy domain adaptation .", "entities": [[2, 4, "TaskName", "domain adaptation"]]}, {"text": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 256\u2013263 , Prague , Czech Republic . Association for Computational Linguistics .", "entities": []}, {"text": "Jenny Rose Finkel and Christopher D Manning .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Hierarchical bayesian domain adaptation .", "entities": [[2, 4, "TaskName", "domain adaptation"]]}, {"text": "In Proceedings of Human Language Technologies : The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics , pages 602\u2013610 .", "entities": []}, {"text": "R Florian , H Hassan , A Ittycheriah , H Jing , N Kambhatla , X Luo , N Nicolov , and S Roukos .", "entities": []}, {"text": "2004 .", "entities": []}, {"text": "A statistical model for multilingual entity detection and tracking .", "entities": []}, {"text": "In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics : HLT - NAACL 2004 , pages 1\u20138 , Boston , Massachusetts , USA .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yaroslav Ganin and Victor Lempitsky .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Unsupervised domain adaptation by backpropagation .", "entities": [[0, 3, "TaskName", "Unsupervised domain adaptation"]]}, {"text": "arXiv preprint arXiv:1409.7495 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "Hangfeng He and Xu Sun . 2017 .", "entities": []}, {"text": "A uni\ufb01ed model for cross - domain and semi - supervised named entity recognition in chinese social media .", "entities": [[11, 14, "TaskName", "named entity recognition"]]}, {"text": "In Thirty - First AAAI Conference on Arti\ufb01cial Intelligence , AAAI .", "entities": []}, {"text": "Eduard Hovy , Mitchell Marcus , Martha Palmer , Lance Ramshaw , and Ralph Weischedel .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "OntoNotes : The 90 % solution .", "entities": [[0, 1, "DatasetName", "OntoNotes"]]}, {"text": "In Proceedings of the Human Language Technology Conference of the NAACL , Companion Volume : Short Papers , pages 57\u201360 , New York City , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Zhiheng Huang , Wei Xu , and Kai Yu . 2015 .", "entities": []}, {"text": "Bidirectional LSTM - CRF models for sequence tagging .", "entities": [[0, 2, "MethodName", "Bidirectional LSTM"], [3, 4, "MethodName", "CRF"]]}, {"text": "ArXiv , abs/1508.01991 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Diederik P Kingma and Jimmy Ba . 2014 .", "entities": []}, {"text": "Adam : A method for stochastic optimization .", "entities": [[0, 1, "MethodName", "Adam"], [5, 7, "TaskName", "stochastic optimization"]]}, {"text": "arXiv preprint arXiv:1412.6980 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "8486Jayant Krishnamurthy and Tom M. Mitchell . 2015 .", "entities": []}, {"text": "Learning a compositional semantics for Freebase with an open predicate vocabulary .", "entities": []}, {"text": "Transactions of the Association for Computational Linguistics , 3:257\u2013270 .", "entities": []}, {"text": "John D. Lafferty , Andrew McCallum , and Fernando C. N. Pereira . 2001 .", "entities": []}, {"text": "Conditional random \ufb01elds : Probabilistic models for segmenting and labeling sequence data .", "entities": []}, {"text": "In Proceedings of the Eighteenth International Conference on Machine Learning , ICML , pages 282\u2013289 .", "entities": []}, {"text": "Guillaume Lample , Miguel Ballesteros , Sandeep Subramanian , Kazuya Kawakami , and Chris Dyer . 2016 .", "entities": []}, {"text": "Neural architectures for named entity recognition .", "entities": [[3, 6, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 260\u2013270 , San Diego , California . Association for Computational Linguistics .", "entities": []}, {"text": "Ji Young Lee , Franck Dernoncourt , and Peter Szolovits . 2018 .", "entities": []}, {"text": "Transfer learning for named - entity recognition with neural networks .", "entities": [[0, 2, "TaskName", "Transfer learning"]]}, {"text": "In Proceedings of the Eleventh International Conference on Language Resources and Evaluation ( LREC-2018 ) , Miyazaki , Japan .", "entities": []}, {"text": "European Languages Resources Association ( ELRA ) .", "entities": []}, {"text": "Shoushan Li and Chengqing Zong .", "entities": []}, {"text": "2008 .", "entities": []}, {"text": "Multidomain sentiment classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of ACL-08 : HLT , Short Papers , pages 257\u2013260 , Columbus , Ohio .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Bill Yuchen Lin and Wei Lu .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Neural adaptation layers for cross - domain named entity recognition .", "entities": [[4, 10, "TaskName", "cross - domain named entity recognition"]]}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2012\u20132022 , Brussels , Belgium . Association for Computational Linguistics .", "entities": []}, {"text": "Gang Luo , Xiaojiang Huang , Chin - Yew Lin , and Zaiqing Nie . 2015 .", "entities": []}, {"text": "Joint entity recognition and disambiguation .", "entities": []}, {"text": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 879\u2013888 , Lisbon , Portugal . Association for Computational Linguistics .", "entities": []}, {"text": "Xuezhe Ma and Eduard Hovy .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "End - to - end sequence labeling via bi - directional LSTM - CNNsCRF .", "entities": [[11, 12, "MethodName", "LSTM"]]}, {"text": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1064\u20131074 , Berlin , Germany .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Yishay Mansour , Mehryar Mohri , and Afshin Rostamizadeh .", "entities": []}, {"text": "2009 .", "entities": []}, {"text": "Domain adaptation with multiple sources .", "entities": [[0, 2, "TaskName", "Domain adaptation"]]}, {"text": "In Advances in Neural Information Processing Systems , NeurIPS , pages 1041\u20131048 .", "entities": []}, {"text": "David McClosky , Eugene Charniak , and Mark Johnson .", "entities": []}, {"text": "2010 .", "entities": []}, {"text": "Automatic domain adaptation for parsing .", "entities": [[1, 3, "TaskName", "domain adaptation"]]}, {"text": "In Human Language Technologies : The 2010 AnnualConference of the North American Chapter of the Association for Computational Linguistics , pages 28 \u2013 36 . Association for Computational Linguistics .", "entities": []}, {"text": "Saif Mohammad , Svetlana Kiritchenko , Parinaz Sobhani , Xiaodan Zhu , and Colin Cherry . 2016 .", "entities": []}, {"text": "SemEval-2016 task 6 : Detecting stance in tweets .", "entities": []}, {"text": "InProceedings of the 10th International Workshop on Semantic Evaluation ( SemEval-2016 ) , pages 31 \u2013 41 , San Diego , California .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Lili Mou , Zhao Meng , Rui Yan , Ge Li , Yan Xu , Lu Zhang , and Zhi Jin .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "How transferable are neural networks in NLP applications ?", "entities": []}, {"text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 479\u2013489 , Austin , Texas . Association for Computational Linguistics .", "entities": [[19, 20, "DatasetName", "Texas"]]}, {"text": "Vincent Ng and Claire Cardie .", "entities": []}, {"text": "2002 .", "entities": []}, {"text": "Improving machine learning approaches to coreference resolution .", "entities": [[5, 7, "TaskName", "coreference resolution"]]}, {"text": "InProceedings of the 40th Annual Meeting of the Association for Computational Linguistics , pages 104 \u2013 111 , Philadelphia , Pennsylvania , USA . Association for Computational Linguistics .", "entities": []}, {"text": "Bo Pang and Lillian Lee . 2004 .", "entities": []}, {"text": "A sentimental education : Sentiment analysis using subjectivity summarization based on minimum cuts .", "entities": [[4, 6, "TaskName", "Sentiment analysis"], [8, 9, "TaskName", "summarization"]]}, {"text": "In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL-04 ) , pages 271\u2013278 , Barcelona , Spain .", "entities": []}, {"text": "Nanyun Peng and Mark Dredze . 2017 .", "entities": []}, {"text": "Multi - task domain adaptation for sequence tagging .", "entities": [[3, 5, "TaskName", "domain adaptation"]]}, {"text": "In Proceedings of the 2nd Workshop on Representation Learning for NLP , pages 91\u2013100 , Vancouver , Canada . Association for Computational Linguistics .", "entities": [[7, 9, "TaskName", "Representation Learning"]]}, {"text": "Jeffrey Pennington , Richard Socher , and Christopher Manning .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Glove : Global vectors for word representation .", "entities": []}, {"text": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1532\u20131543 , Doha , Qatar .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Matthew Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Deep contextualized word representations .", "entities": []}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) , pages 2227\u20132237 , New Orleans , Louisiana .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Sameer Pradhan , Alessandro Moschitti , Nianwen Xue , Hwee Tou Ng , Anders Bj \u00a8orkelund , Olga Uryupina , Yuchen Zhang , and Zhi Zhong .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Towards robust linguistic analysis using OntoNotes .", "entities": [[5, 6, "DatasetName", "OntoNotes"]]}, {"text": "In Proceedings of the Seventeenth Conference on Computational Natural Language Learning , pages 143\u2013152 , So\ufb01a , Bulgaria . Association for Computational Linguistics .", "entities": []}, {"text": "8487Lev Ratinov and Dan Roth . 2009 .", "entities": []}, {"text": "Design challenges and misconceptions in named entity recognition .", "entities": [[3, 4, "TaskName", "misconceptions"], [5, 8, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning ( CoNLL-2009 ) , pages 147\u2013155 , Boulder , Colorado . Association for Computational Linguistics .", "entities": [[12, 13, "DatasetName", "CoNLL-2009"]]}, {"text": "Nils Reimers and Iryna Gurevych .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Reporting score distributions makes a difference : Performance study of LSTM - networks for sequence tagging .", "entities": [[10, 11, "MethodName", "LSTM"]]}, {"text": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 338\u2013348 , Copenhagen , Denmark . Association for Computational Linguistics .", "entities": []}, {"text": "Shruti Rijwhani and Daniel Preot \u00b8iuc - Pietro .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Temporally - informed analysis of named entity recognition .", "entities": [[5, 8, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics .", "entities": []}, {"text": "Marina Santini , Richard Power , and Roger Evans .", "entities": []}, {"text": "2006 .", "entities": []}, {"text": "Implementing a characterization of genre for automatic genre identi\ufb01cation of web pages .", "entities": []}, {"text": "In Proceedings of the COLING / ACL 2006 Main Conference Poster Sessions , pages 699\u2013706 , Sydney , Australia .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Erik F. Tjong Kim Sang and Fien De Meulder .", "entities": []}, {"text": "2003 .", "entities": []}, {"text": "Introduction to the CoNLL-2003 shared task : Language - independent named entity recognition .", "entities": [[3, 4, "DatasetName", "CoNLL-2003"], [10, 13, "TaskName", "named entity recognition"]]}, {"text": "In Proceedings of the Seventh Conference on Natural Language Learning at HLT - NAACL 2003 , pages 142\u2013147 .", "entities": []}, {"text": "Fangzhao Wu and Yongfeng Huang . 2015 .", "entities": []}, {"text": "Collaborative multi - domain sentiment classi\ufb01cation .", "entities": []}, {"text": "In 2015 IEEE International Conference on Data Mining , pages 459\u2013468 . IEEE .", "entities": []}, {"text": "Yi Yang and Jacob Eisenstein .", "entities": []}, {"text": "2015 .", "entities": []}, {"text": "Unsupervised multi - domain adaptation with feature embeddings .", "entities": [[3, 5, "TaskName", "domain adaptation"]]}, {"text": "InProceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 672\u2013682 , Denver , Colorado .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Zhilin Yang , Ruslan Salakhutdinov , and William W. Cohen . 2017 .", "entities": [[3, 4, "DatasetName", "Ruslan"]]}, {"text": "Transfer learning for sequence tagging with hierarchical recurrent networks .", "entities": [[0, 2, "TaskName", "Transfer learning"]]}, {"text": "ICLR .", "entities": []}, {"text": "A Domain Prediction We further study the domains that are selected by the methods above by creating confusion matrices between the domain predictions of three setups : domain classi\ufb01cation , domain prediction in the proposed MultDomain - SP - Aux model and the oracle in - domain choice on gold data .", "entities": []}, {"text": "Figure 2 shows that the Oracle model relies on the corresponding InDomain model to only a limited extent Figure 2 : Domain label confusion matrices on the CoNLL - Twitter - OntoNotes data collection .", "entities": [[31, 32, "DatasetName", "OntoNotes"]]}, {"text": "for each model .", "entities": []}, {"text": "In uniformly many cases , predictions from other in - domain models are better than the existing in - domain one , showing the variability of the NER models .", "entities": [[27, 28, "TaskName", "NER"]]}, {"text": "The domain classi\ufb01er predictions align closer to the actual domains .", "entities": []}, {"text": "The MultDomain - SP - Aux model also tends to predict the domain correctly , but we see that it better learns the NW , WB and BN domains .", "entities": []}, {"text": "Note noting that the MultDomain - SP - Aux model does not use these domain predictions in inference and the model uses the shared components for unknown domains or", "entities": []}, {"text": "8488 Figure 3 : Zero - Shot Domain data domain - label frequency prediction comparison labels .", "entities": []}, {"text": "Finally , we plot the domain prediction distribution on the zero - shot genre data in Figure 3 .", "entities": []}, {"text": "We \ufb01nd that similar to the confusion matrices , the oracle strategy has a more even spread in domain selection .", "entities": []}, {"text": "We observe similar patterns to the confusion matrices for the InDomain+DomainClassi\ufb01er andMultDomain - SP - Aux models .", "entities": []}]