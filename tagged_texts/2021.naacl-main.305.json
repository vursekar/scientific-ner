[{"text": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 3899\u20133916 June 6\u201311 , 2021 .", "entities": []}, {"text": "\u00a9 2021 Association for Computational Linguistics3899Double Perturbation : On the Robustness of Robustness and Counterfactual Bias Evaluation Chong Zhang", "entities": []}, {"text": "Jieyu Zhao Huan Zhang Kai - Wei Chang Cho - Jui Hsieh Department of Computer Science , UCLA { chongz , jyzhao , kwchang , chohsieh}@cs.ucla.edu , huan@huan-zhang.com Abstract Robustness and counterfactual bias are usually evaluated on a test dataset .", "entities": []}, {"text": "However , are these evaluations robust ?", "entities": []}, {"text": "If the test dataset is perturbed slightly , will the evaluation results keep the same ?", "entities": []}, {"text": "In this paper , we propose a \u201c double perturbation \u201d framework to uncover model weaknesses beyond the test dataset .", "entities": []}, {"text": "The framework \ufb01rst perturbs the test dataset to construct abundant natural sentences similar to the test data , and then diagnoses the prediction change regarding a single - word substitution .", "entities": []}, {"text": "We apply this framework to study two perturbation - based approaches that are used to analyze models \u2019 robustness and counterfactual bias in English .", "entities": []}, {"text": "( 1 ) For robustness , we focus on synonym substitutions and identify vulnerable examples where prediction can be altered .", "entities": []}, {"text": "Our proposed attack attains high success rates ( 96:0%\u201399:8 % ) in \ufb01nding vulnerable examples on both original and robustly trained CNNs and Transformers .", "entities": []}, {"text": "( 2 ) For counterfactual bias , we focus on substituting demographic tokens ( e.g. , gender , race ) and measure the shift of theexpected prediction among constructed sentences .", "entities": []}, {"text": "Our method is able to reveal the hidden model biases not directly shown in the test dataset .", "entities": []}, {"text": "Our code is available at https://github.com/chong-z/ nlp - second - order - attack .", "entities": []}, {"text": "1 Introduction Recent studies show that NLP models are vulnerable to adversarial perturbations .", "entities": []}, {"text": "A seemingly \u201c invariance transformation \u201d ( a.k.a . adversarial perturbation ) such as synonym substitutions ( Alzantot et al . , 2018 ; Zang et al . , 2020 ) or syntax - guided paraphrasing ( Iyyer et al . , 2018 ; Huang and Chang , 2021 ) can alter the prediction .", "entities": []}, {"text": "To mitigate the model vulnerability , robust training methods have been proposed and shown effective ( Miyato et al . , 2017 ;", "entities": []}, {"text": "Jia et al . , 2019 ; Huang et al . , 2019 ; Zhou et", "entities": []}, {"text": "al . , 2020).x0=\"a deep and meaningful \ufb01lm ( movie ) .\"Xtest", "entities": []}, {"text": "~x0=\"a short and moving \ufb01lm ( movie ) . \"", "entities": []}, {"text": "73 % positive ( 70 % negative)(99 % positive )", "entities": []}, {"text": "99 % positive perturb Figure 1 : A vulnerable example beyond the test dataset .", "entities": []}, {"text": "Numbers on the bottom right are the sentiment predictions for film andmovie .", "entities": []}, {"text": "Bluex0comes from the test dataset and its prediction can not be altered by the substitution film!movie ( robust ) .", "entities": []}, {"text": "Yellow example ~ x0is slightly perturbed but remains natural .", "entities": []}, {"text": "Its prediction can be altered by the substitution ( vulnerable ) .", "entities": []}, {"text": "In most studies , model robustness is evaluated based on a given test dataset or synthetic sentences constructed from templates ( Ribeiro et al . , 2020 ) .", "entities": []}, {"text": "Speci\ufb01cally , the robustness of a model is often evaluated by the ratio of test examples where the model prediction can not be altered by semantic - invariant perturbation .", "entities": []}, {"text": "We refer to this type of evaluations as the \ufb01rst - order robustness evaluation .", "entities": []}, {"text": "However , even if a model is \ufb01rst - order robust on an input sentencex0 , it is possible that the model is not robust on a natural sentence ~x0that is slightly modi\ufb01ed fromx0 .", "entities": []}, {"text": "In that case , adversarial examples still exist even if \ufb01rst - order attacks can not \ufb01nd any of them from the given test dataset .", "entities": []}, {"text": "Throughout this paper , we call ~x0avulnerable example .", "entities": []}, {"text": "The existence of such examples exposes weaknesses in models \u2019 understanding and presents challenges for model deployment .", "entities": []}, {"text": "Fig .", "entities": []}, {"text": "1 illustrates an example .", "entities": []}, {"text": "In this paper , we propose the double perturbation framework for evaluating a stronger notion ofsecond - order robustness .", "entities": []}, {"text": "Given a test dataset , we consider a model to be second - order robust if there is no vulnerable example that can be identi\ufb01ed in the neighborhood of given test instances", "entities": []}, {"text": "3900(\u00a72.2 ) .", "entities": []}, {"text": "In particular , our framework \ufb01rst perturbs the test set to construct the neighborhood , and then diagnoses the robustness regarding a single - word synonym substitution .", "entities": []}, {"text": "Taking Fig .", "entities": []}, {"text": "2 as an example , the model is \ufb01rst - order robust on the input sentence x0(the prediction can not be altered ) , but it is not second - order robust due to the existence of the vulnerable example ~x0 .", "entities": []}, {"text": "Our framework is designed to identify ~x0 .", "entities": []}, {"text": "We apply the proposed framework and quantify second - order robustness through two second - order attacks ( \u00a7 3 ) .", "entities": []}, {"text": "We experiment with English sentiment classi\ufb01cation on the SST-2 dataset ( Socher et al . , 2013 ) across various model architectures .", "entities": [[8, 9, "DatasetName", "SST-2"]]}, {"text": "Surprisingly , although robustly trained CNN ( Jia et al . , 2019 ) and Transformer ( Xu et", "entities": [[15, 16, "MethodName", "Transformer"]]}, {"text": "al . , 2020 ) can achieve high robustness under strong attacks ( Alzantot et al . , 2018 ; Garg and Ramakrishnan , 2020 ) ( 23:0%\u201371:6%success rates ) , for around 96:0%of the test examples our attacks can \ufb01nd a vulnerable example by perturbing 1.3 words on average .", "entities": []}, {"text": "This \ufb01nding indicates that these robustly trained models , despite being \ufb01rst - order robust , are not second - order robust .", "entities": []}, {"text": "Furthermore , we extend the double perturbation framework to evaluate counterfactual biases ( Kusner et al . , 2017 ) ( \u00a7 4 ) in English .", "entities": []}, {"text": "When the test dataset is small , our framework can help improve the evaluation robustness by revealing the hidden biases not directly shown in the test dataset .", "entities": []}, {"text": "Intuitively , a fair model should make the same prediction for nearly identical examples referencing different groups ( Garg et al . , 2019 ) with different protected attributes ( e.g. , gender , race ) .", "entities": []}, {"text": "In our evaluation , we consider a model biased if substituting tokens associated with protected attributes changes theexpected prediction , which is the average prediction among all examples within the neighborhood .", "entities": []}, {"text": "For instance , a toxicity classi\ufb01er is biased if it tends to increase the toxicity if we substitute straight!gay in an input sentence ( Dixon et al . , 2018 ) .", "entities": []}, {"text": "In the experiments , we evaluate the expected sentiment predictions on pairs of protected tokens ( e.g. , ( he , she ) , ( gay , straight ) ) , and demonstrate that our method is able to reveal the hidden model biases .", "entities": []}, {"text": "Our main contributions are : ( 1 ) We propose the double perturbation framework to diagnose the robustness of existing robustness and fairness evaluation methods .", "entities": []}, {"text": "( 2 ) We propose two second - order attacks to quantify the stronger notion of second - x0 ~ x0 ~ x0 0 ~ x1negativepositive Figure 2 : An illustration of the decision boundary .", "entities": [[23, 24, "DatasetName", "0"]]}, {"text": "Diamond area denotes invariance transformations .", "entities": []}, {"text": "Blue x0 is a robust input example ( the entire diamond is green ) .", "entities": []}, {"text": "Yellow ~x0is avulnerable example in the neighborhood ofx0 .", "entities": []}, {"text": "Red ~x0 0is an adversarial example to ~x0 .", "entities": []}, {"text": "Note : ~x0 0isnotan adversarial example to x0since they have different meanings to human ( outside the diamond ) .", "entities": []}, {"text": "order robustness and reveal the models \u2019 vulnerabilities that can not be identi\ufb01ed by previous attacks .", "entities": []}, {"text": "( 3 ) We propose a counterfactual bias evaluation method to reveal the hidden model bias based on our double perturbation framework .", "entities": []}, {"text": "2 The Double Perturbation Framework In this section , we describe the double perturbation framework which focuses on identifying vulnerable examples within a small neighborhood of the test dataset .", "entities": []}, {"text": "The framework consists of a neighborhood perturbation and a word substitution .", "entities": []}, {"text": "We start with de\ufb01ning word substitutions .", "entities": []}, {"text": "2.1 Existing Word Substitution Strategy We focus our study on word - level substitution , where existing works evaluate robustness and counterfactual bias by directly perturbing the test dataset .", "entities": []}, {"text": "For instance , adversarial attacks alter the prediction by making synonym substitutions , and the fairness literature evaluates counterfactual fairness by substituting protected tokens .", "entities": []}, {"text": "We integrate the word substitution strategy into our framework as the component for evaluating robustness and fairness .", "entities": []}, {"text": "For simplicity , we consider a single - word substitution and denote it with the operator \b. LetX\u0012", "entities": []}, {"text": "Vlbe the input space where Vis the vocabulary and lis the sentence length , p= ( p(1);p(2))2V2be a pair of synonyms ( called patch words ) , Xp\u0012X denotes sentences with a single occurrence of p(1 ) ( for simplicity we skip other sentences ) , x02Xp be an input sentence , then x0\bpmeans \u201c substitute p(1)!p(2)inx0 \u201d .", "entities": []}, {"text": "The result after substitution is : x0 0 = x0\bp :", "entities": [[7, 8, "DatasetName", "0"]]}, {"text": "3901Taking Fig .", "entities": []}, {"text": "1 as an example ,", "entities": []}, {"text": "where p= ( film , movie ) andx0 = a deep and meaningful film , the perturbed sentence is x0 0 = a deep and meaningful movie .", "entities": [[20, 21, "DatasetName", "0"]]}, {"text": "Now we introduce other components in our framework .", "entities": []}, {"text": "2.2 Proposed Neighborhood Perturbation Instead of applying the aforementioned word substitutions directly to the original test dataset , our framework perturbs the test dataset within a small neighborhood to construct similar natural sentences .", "entities": []}, {"text": "This is to identify vulnerable examples with respect to the model .", "entities": []}, {"text": "Note that examples in the neighborhood are not required to have the same meaning as the original example , since we only study the prediction difference caused by applying synonym substitution p(\u00a72.1 ) .", "entities": []}, {"text": "Constraints on the neighborhood .", "entities": []}, {"text": "We limit the neighborhood sentences within a small ` 0norm ball ( regarding the test instance ) to ensure syntactic similarity , and empirically ensure the naturalness through a language model .", "entities": []}, {"text": "The neighborhood of an input sentence x02X is : Neighbork(x0)\u0012Ballk(x0)\\X natural ; ( 1 ) where Ballk(x0 )", "entities": []}, {"text": "= fxjkx\u0000x0k0\u0014k;x2Xg is the`0norm ball around x0(i.e . , at most kdifferent tokens ) , andXnatural denotes natural sentences that satisfy a certain language model score which will be discussed next .", "entities": []}, {"text": "Construction with masked language model .", "entities": []}, {"text": "We construct neighborhood sentences from x0by substituting at most ktokens .", "entities": []}, {"text": "As shown in Algorithm 1 , the construction employs a recursive approach and replaces one token at a time .", "entities": []}, {"text": "For each recursion , the algorithm \ufb01rst masks each token of the input sentence ( may be the original x0or the ~ xfrom last recursion ) separately and predicts likely replacements with a masked language model ( e.g. , DistilBERT , Sanh et al . 2019 ) .", "entities": [[39, 40, "MethodName", "DistilBERT"]]}, {"text": "To ensure the naturalness , we keep the top 20tokens for each mask with the largest logit ( subject to a threshold , Line 9 ) .", "entities": []}, {"text": "Then , the algorithm constructs neighborhood sentences by replacing the mask with found tokens .", "entities": []}, {"text": "We use the notation ~xin the following sections to denote the constructed sentences within the neighborhood .", "entities": []}, {"text": "Algorithm 1 : Neighborhood construction Data : Input sentence x0 , masked language model LM , max distance k. 1Function Neighbork(x0 ): 2 ifk= 0then", "entities": []}, {"text": "returnfx0 g ; 3 ifk\u00152then 4 returnS ~x2Neighbor1(x0)Neighbork\u00001(~x ) ; 5Xneighbor ? ; 6 fori 0 ; : : : ; len(x0)\u00001do 7T;L LM.\ufb01llmask ( x0;i ) ; .Maskithtoken and return candidate tokens and corresponding logits .", "entities": [[15, 16, "DatasetName", "0"]]}, {"text": "8L SortDecreasing ( L ) ; 9lmin maxfL(\u0014 ) ; L(0)\u0000\u000eg ; .", "entities": []}, {"text": "L(i)denotes the ithelement .", "entities": []}, {"text": "We empirically set \u0014 20and\u000e 3 . 10Tnew ftjl >", "entities": []}, {"text": "l min;(t;l)2T\u0002Lg ; 11Xnew fx0jx(i ) 0 t ; t2Tnewg ; .Construct new sentences by replacing the ithtoken .", "entities": [[6, 7, "DatasetName", "0"]]}, {"text": "12Xneighbor X neighbor[X new ; 13 returnXneighbor ; 3 Evaluating Second - Order Robustness With the proposed double perturbation framework , we design two black - box attacks1to identify vulnerable examples within the neighborhood of the test set .", "entities": []}, {"text": "We aim at evaluating the robustness for inputs beyond the test set .", "entities": []}, {"text": "3.1 Previous First - Order Attacks Adversarial attacks search for small and invariant perturbations on the model input that can alter the prediction .", "entities": []}, {"text": "To simplify the discussion , in the following , we take a binary classi\ufb01er f(x ) :X !", "entities": []}, {"text": "f0;1gas an example to describe our framework .", "entities": []}, {"text": "Letx0be the sentence from the test set with label y0 , then the smallest perturbation \u000e\u0003under`0norm distance is:2 \u000e\u0003:= argmin \u000ek\u000ek0s.t.f(x0\b\u000e)6 = y0 : Here\u000e=p1\b\u0001\u0001\u0001\b pldenotes a series of substitutions .", "entities": []}, {"text": "In contrast , our second - order attacks \ufb01x \u000e=pand search for the vulnerable x0 .", "entities": []}, {"text": "3.2 Proposed Second - Order Attacks Second - order attacks study the prediction difference caused by applying p.", "entities": []}, {"text": "For notation convenience we de\ufb01ne the prediction difference F(x;p ) : 1Black - box attacks only observe the model outputs and do not know the model parameters or the gradient .", "entities": []}, {"text": "2For simplicity , we use ` 0norm distance to measure the similarity , but other distance metrics can be applied .", "entities": []}, {"text": "3902x0 = a deep and meaningful \ufb01lm .", "entities": []}, {"text": "p=\ufb01lm , movie x(i= 2 ) a short and moving \ufb01lm ( movie ) .", "entities": []}, {"text": "a slow and moving \ufb01lm ( movie ) .", "entities": []}, {"text": "a dramatic or meaningful \ufb01lm ( movie ) .", "entities": []}, {"text": "\u0001\u0001\u0001fsoft(x ) .730 ( .303 ) .519 ( .151 ) .487 ( .168)x(i= 1 ) a deep and disturbing \ufb01lm ( movie ) .", "entities": []}, {"text": "a deep and moving \ufb01lm ( movie ) .", "entities": []}, {"text": "a dramatic and meaningful \ufb01lm ( movie ) .", "entities": []}, {"text": "\u0001\u0001\u0001fsoft(x ) .990 ( .989 ) .999 ( .999 ) .999 ( .999 ) \ufb01lm , movie story , tale fool , silly \u0001\u0001\u0001SynonymsFindpforx0 : Find vulnerable example through beam search.palters the prediction .", "entities": []}, {"text": "~x0=\"a short and moving \ufb01lm ( movie ) . \"", "entities": []}, {"text": "( 70 % negative )", "entities": []}, {"text": "73 % positive Figure 3 : The attack \ufb02ow for SO - Beam ( Algorithm 2 ) .", "entities": []}, {"text": "Blue x0is the input sentence and yellow ~x0is our constructed vulnerable example ( the prediction can be altered by substituting film!movie ) .", "entities": []}, {"text": "Green boxes in the middle show intermediate sentences , and fsoft(x)denotes the probability outputs for film andmovie .", "entities": []}, {"text": "X\u0002V2!f\u0000 1;0;1gby:3 F(x;p ) :", "entities": []}, {"text": "= f(x\bp)\u0000f(x ): ( 2 ) Taking Fig .", "entities": []}, {"text": "1 as an example , the prediction difference for ~x0onpisF(~x0;p ) = f( ... moving movie .)\u0000f( ... moving film . )", "entities": []}, {"text": "= \u00001 .", "entities": []}, {"text": "Given an input sentence x0 , we want to \ufb01nd patch words pand a vulnerable example ~x0such thatf(~x0\bp)6 = f(~x0 ) .", "entities": []}, {"text": "Follow Alzantot", "entities": []}, {"text": "et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2018 ) , we choose pfrom a prede\ufb01ned list of counter-\ufb01tted synonyms ( Mrk\u0161i \u00b4 c et al . , 2016 ) that maximizesjfsoft(p(2))\u0000fsoft(p(1))j . Herefsoft(x ) : X !", "entities": []}, {"text": "[ 0;1]denotes probability output ( e.g. , after the softmax layer but before the \ufb01nal argmax ) , fsoft(p(1))andfsoft(p(2))denote the predictions for the single word , and we enumerate through all possiblepforx0 .", "entities": [[9, 10, "MethodName", "softmax"]]}, {"text": "Letkbe the neighborhood distance , then the attack is equivalent to solving : ~x0= argmax x2Neighbork(x0)jF(x;p)j : ( 3 ) Brute - force attack ( SO - Enum ) .", "entities": []}, {"text": "A naive approach for solving Eq .", "entities": []}, {"text": "( 3 ) is to enumerate through Neighbork(x0 ) .", "entities": []}, {"text": "The enumeration \ufb01nds the smallest perturbation , but is only applicable for small k ( e.g. ,k\u00142 ) given the exponential complexity .", "entities": []}, {"text": "Beam - search attack ( SO - Beam )", "entities": []}, {"text": ".", "entities": []}, {"text": "The ef\ufb01ciency can be improved by utilizing the probability output , where we solve Eq .", "entities": []}, {"text": "( 3 ) by minimizing the crossentropy loss with regard to x2Neighbork(x0 ): L(x;p ) :", "entities": [[7, 8, "MetricName", "loss"]]}, {"text": "= \u0000log(1\u0000fmin)\u0000log(fmax);(4 ) wherefminandfmaxare the smaller and the larger output probability between fsoft(x)andfsoft(x\b 3We assume a binary classi\ufb01cation task , but our framework is general and can be extended to multi - class classi\ufb01cation.p ) , respectively .", "entities": []}, {"text": "Minimizing Eq .", "entities": []}, {"text": "( 4 ) effectively leads tofmin!0andfmax!1 , and we use a beam search to \ufb01nd the best x. At each iteration , we construct sentences through Neighbor1(x)and only keep the top 20 sentences with the smallest L(x;p ) .", "entities": []}, {"text": "We run at most kiterations , and stop earlier if we \ufb01nd a vulnerable example .", "entities": []}, {"text": "We provide the detailed implementation in Algorithm 2 and a \ufb02owchart in Fig .", "entities": []}, {"text": "3 . Algorithm 2 : Beam - search attack ( SOBeam ) Data : Input sentence x0 , synonymsP , model functionsFandfsoft , lossL , max distance k. 1Function SO - Beam k(x0 ): 2 p argmax p2P s.t.x02Xpjfsoft(p(2))\u0000fsoft(p(1))j ; 3Xbeam fx0 g ; 4 fori 1;:::;k do 5Xnew S ~x2X beamNeighbor1(~x ) ; 6 ~x0 argmaxx2X newjF(x;p)j ; 7 ifF(~x0;p)6= 0then return ~x0 ; 8Xnew SortIncreasing ( Xnew;L ) ; 9Xbeam fX(0 ) new;:::;X ( \f \u00001 ) newg ; .Keep the best beam .", "entities": []}, {"text": "We set \f  20 . 10 return None ; 3.3 Experimental Results In this section , we evaluate the second - order robustness of existing models and show the quality of our constructed vulnerable examples .", "entities": []}, {"text": "3.3.1 Setup We follow the setup from the robust training literature ( Jia et al . , 2019 ; Xu et", "entities": []}, {"text": "al . , 2020 ) and experiment with both the base ( non - robust ) and robustly trained models .", "entities": []}, {"text": "We train the binary sentiment classi\ufb01ers on the SST-2 dataset with bag - ofwords ( BoW ) , CNN , LSTM , and attention - based", "entities": [[8, 9, "DatasetName", "SST-2"], [20, 21, "MethodName", "LSTM"]]}, {"text": "3903Original : 70 % Negative Input Example : in its best moments , resembles a bad high school production of grease , without bene\ufb01t of song .", "entities": []}, {"text": "Genetic : 56 % Positive Adversarial Example : in its best moment , recalling a naughty high school production of lubrication , unless bene\ufb01t of song .", "entities": []}, {"text": "BAE : 56 % Positive Adversarial Example : in its best moments , resembles a great high school production of grease , without bene\ufb01t of song .", "entities": []}, {"text": "SO - Enum and SO - Beam ( ours ): 60 % Negative ( 67 % Positive )", "entities": []}, {"text": "Vulnerable Example", "entities": []}, {"text": ": in its best moments , resembles a bad ( unhealthy ) high school production of musicals , without bene\ufb01t of song .", "entities": []}, {"text": "Table 1 : Sampled attack results on the robust BoW.", "entities": []}, {"text": "For Genetic and BAE the goal is to \ufb01nd an adversarial example that alters the original prediction , whereas for SO - Enum and SO - Beam the goal is to \ufb01nd a vulnerable example beyond the test set such that the prediction can be altered by substituting bad!unhealthy .", "entities": []}, {"text": "models .", "entities": []}, {"text": "Base models .", "entities": []}, {"text": "For BoW , CNN , and LSTM , all models use pre - trained GloVe embeddings ( Pennington et al . , 2014 ) , and have one hidden layer of the corresponding type with 100 hidden size .", "entities": [[6, 7, "MethodName", "LSTM"], [14, 16, "MethodName", "GloVe embeddings"]]}, {"text": "Similar to the baseline performance reported in GLUE ( Wang et al . , 2019 ) , our trained models have an evaluation accuracy of 81.4 % , 82.5 % , and 81.7 % , respectively .", "entities": [[7, 8, "DatasetName", "GLUE"], [23, 24, "MetricName", "accuracy"]]}, {"text": "For attention - based models , we train a 3 - layer Transformer ( the largest size in Shi et al . 2020 ) and \ufb01ne - tune a pre - trained bertbase - uncased from HuggingFace ( Wolf et al . , 2020 ) .", "entities": [[12, 13, "MethodName", "Transformer"]]}, {"text": "The Transformer uses 4 attention heads and 64 hidden size , and obtains 82.1 % accuracy .", "entities": [[1, 2, "MethodName", "Transformer"], [15, 16, "MetricName", "accuracy"]]}, {"text": "The BERT - base uses the default con\ufb01guration and obtains 92.7 % accuracy .", "entities": [[1, 2, "MethodName", "BERT"], [12, 13, "MetricName", "accuracy"]]}, {"text": "Robust models ( \ufb01rst - order ) .", "entities": []}, {"text": "With the same setup as base models , we apply robust training methods to improve the resistance to word substitution attacks .", "entities": []}, {"text": "Jia et al .", "entities": []}, {"text": "( 2019 ) provide a provably robust training method through Interval Bound Propagation ( IBP , Dvijotham et al . 2018 ) for all word substitutions on BoW , CNN and LSTM .", "entities": [[31, 32, "MethodName", "LSTM"]]}, {"text": "Xu et", "entities": []}, {"text": "al .", "entities": []}, {"text": "( 2020 ) provide a provably robust training method on general computational graphs through a combination of forward and backward linear bound propagation , and the resulting 3 - layer Transformer is robust to up to 6 word substitutions .", "entities": [[30, 31, "MethodName", "Transformer"]]}, {"text": "For both works we use the same set of counter-\ufb01tted synonyms provided in Jia et al .", "entities": []}, {"text": "( 2019 ) .", "entities": []}, {"text": "We skip BERT - base due to the lack of an effective robust training method .", "entities": [[2, 3, "MethodName", "BERT"]]}, {"text": "Attack success rate ( \ufb01rst - order ) .", "entities": []}, {"text": "We quantify \ufb01rst - order robustness through attack success rate , which measures the ratio of test examples that an adversarial example can be found .", "entities": []}, {"text": "We use \ufb01rstorder attacks as a reference due to the lack of a direct baseline .", "entities": []}, {"text": "We experiment with two black - box attacks : ( 1 ) The Genetic attack ( Alzantot et al . , 2018 ; Jia et al . , 2019 ) uses a population - based op - timization algorithm that generates both syntactically and semantically similar adversarial examples , by replacing words within the list of counter\ufb01tted synonyms .", "entities": []}, {"text": "( 2 ) The BAE attack ( Garg and Ramakrishnan , 2020 ) generates coherent adversarial examples by masking and replacing words using BERT .", "entities": [[23, 24, "MethodName", "BERT"]]}, {"text": "For both methods we use the implementation provided by TextAttack ( Morris et al . , 2020 ) .", "entities": []}, {"text": "Attack success rate ( second - order ) .", "entities": []}, {"text": "We also quantify second - order robustness through attack success rate , which measures the ratio of test examples that a vulnerable example can be found .", "entities": []}, {"text": "To evaluate the impact of neighborhood size , we experiment with two con\ufb01gurations : ( 1 ) For the small neighborhood ( k= 2 ) , we use SO - Enum that \ufb01nds the most similar vulnerable example .", "entities": []}, {"text": "( 2 ) For the large neighborhood ( k= 6 ) , SO - Enum is not applicable and we use SO - Beam to \ufb01nd vulnerable examples .", "entities": []}, {"text": "We consider the most challenging setup and use patch words pfrom the same set of counter-\ufb01tted synonyms as robust models ( they are provably robust to these synonyms on the test set ) .", "entities": []}, {"text": "We also provide a random baseline to validate the effectiveness of minimizing Eq .", "entities": []}, {"text": "( 4 ) ( Appendix A.1 ) .", "entities": []}, {"text": "Quality metrics ( perplexity and similarity ) .", "entities": [[3, 4, "MetricName", "perplexity"]]}, {"text": "We quantify the quality of our constructed vulnerable examples through two metrics : ( 1 ) GPT-2 ( Radford et al . , 2019 ) perplexity quanti\ufb01es the naturalness of a sentence ( smaller is better ) .", "entities": [[16, 17, "MethodName", "GPT-2"], [25, 26, "MetricName", "perplexity"]]}, {"text": "We report the perplexity for both the original input examples and the constructed vulnerable examples .", "entities": [[3, 4, "MetricName", "perplexity"]]}, {"text": "( 2 ) ` 0norm distance quanti\ufb01es the disparity between two sentences ( smaller is better ) .", "entities": []}, {"text": "We report the distance between the input and the vulnerable example .", "entities": []}, {"text": "Note that \ufb01rst - order attacks have different objectives and thus can not be compared directly .", "entities": []}, {"text": "3904Attack Success Rate ( % ) Genetic BAE SO - Enum SO - Beam Base Models : BoW 57.0 69.7 95.3 99.7 CNN 62.0 71.0 95.3 99.8 LSTM 60.0 68.3 95.8 99.5 Transformer 73.0 74.3 95.4 98.0 BERT - base 41.0 61.5 94.3 98.7 Robust Models : BoW 28.0 63.1 81.5 88.4 CNN 23.0 64.4 91.0 96.0 LSTM 24.0 61.0 62.9 77.5 Transformer 56.0 71.6 91.2 96.2 Table 2 : The average rates over 872 examples ( 100 for Genetic due to long running time ) .", "entities": [[27, 28, "MethodName", "LSTM"], [32, 33, "MethodName", "Transformer"], [37, 38, "MethodName", "BERT"], [57, 58, "MethodName", "LSTM"], [62, 63, "MethodName", "Transformer"]]}, {"text": "Second - order attacks achieve higher successful rate since they are able to search beyond the test set .", "entities": []}, {"text": "3.3.2 Results We experiment with the validation split ( 872 examples ) on a single RTX 3090 .", "entities": []}, {"text": "The average running time per example ( in seconds ) on base LSTM is 31.9 for Genetic , 1.1 for BAE , 7.0 for SO - Enum ( k= 2 ) , and 1.9 for SO - Beam ( k= 6 ) .", "entities": [[12, 13, "MethodName", "LSTM"]]}, {"text": "We provide additional running time results in Appendix A.3 .", "entities": []}, {"text": "Table 1 provides an example of the attack result where all attacks are successful ( additional examples in Appendix A.5 ) .", "entities": []}, {"text": "As shown , our secondorder attacks \ufb01nd a vulnerable example by replacinggrease!musicals , and the vulnerable example has different predictions for bad andunhealthy .", "entities": []}, {"text": "Note that , Genetic and BAE have different objectives from second - order attacks and focus on \ufb01nding the adversarial example .", "entities": []}, {"text": "Next we discuss the results from two perspectives .", "entities": []}, {"text": "Second - order robustness .", "entities": []}, {"text": "We observe that existing robustly trained models are not second - order robust .", "entities": []}, {"text": "As shown in Table 2 , our second - order attacks attain high success rates not only on the base models but also on the robustly trained models .", "entities": []}, {"text": "For instance , on the robustly trained CNN and Transformer , SO - Beam \ufb01nds vulnerable examples within a small neighborhood for around 96:0%of the test examples , even though these models have improved resistance to strong \ufb01rst - order attacks ( success rates drop from 62:0%\u201374:3%to 23:0%\u201371:6%for Genetic and BAE).4This phenomenon can be explained by the fact that both \ufb01rstorder attacks and robust training methods focus on synonym substitutions on the test set , whereas our attacks , due to their second - order nature , \ufb01nd vul4BAE is more effective on robust models as it may use replacement words outside the counter-\ufb01tted synonyms .", "entities": [[9, 10, "MethodName", "Transformer"]]}, {"text": "SO - Enum SO - Beam Original PPLPerturb PPL`0Original PPLPerturb PPL`0 Base Models : BoW 168 202 1.1 166 202 1.2 CNN 170 204 1.1 166 201 1.2 LSTM 168 204 1.1 166 204 1.2 Transformer 165 193 1.0 165 195 1.1 BERT - base 170 229 1.3 168 222 1.4 Robust Models : BoW 170 212 1.2 171 222 1.4 CNN 166 209 1.2 168 210 1.3 LSTM 194 251 1.3 185 260 1.8 Transformer 170 213 1.2 165 208 1.3 Table 3 : The quality metrics for second - order methods .", "entities": [[28, 29, "MethodName", "LSTM"], [35, 36, "MethodName", "Transformer"], [42, 43, "MethodName", "BERT"], [68, 69, "MethodName", "LSTM"], [75, 76, "MethodName", "Transformer"]]}, {"text": "We report the median perplexity ( PPL ) and average`0norm distance .", "entities": [[4, 5, "MetricName", "perplexity"]]}, {"text": "The original PPL may differ across models since we only count successful attacks .", "entities": []}, {"text": "nerable examples beyond the test set , and the search is not required to maintain semantic similarity .", "entities": [[15, 17, "TaskName", "semantic similarity"]]}, {"text": "Our methods provide a way to further investigate the robustness ( or \ufb01nd vulnerable and adversarial examples ) even when the model is robust to the test set .", "entities": []}, {"text": "Quality of constructed vulnerable examples .", "entities": []}, {"text": "As shown in Table 3 , second - order attacks are able to construct vulnerable examples by perturbing 1.3 words on average , with a slightly increased perplexity .", "entities": [[27, 28, "MetricName", "perplexity"]]}, {"text": "For instance , on the robustly trained CNN and Transformer , SO - Beam constructs vulnerable examples by perturbing 1.3 words on average , with the median5perplexity increased from around 165 to around 210 .", "entities": [[9, 10, "MethodName", "Transformer"]]}, {"text": "We provide metrics for \ufb01rst - order attacks in Appendix A.5 as they have different objectives and are not directly comparable .", "entities": []}, {"text": "Furthermore , applying existing attacks on the vulnerable examples constructed by our method will lead to much smaller perturbations .", "entities": []}, {"text": "As a reference , on the robustly trained CNN , Genetic attack constructs adversarial examples by perturbing 2.7 words on average ( starting from the input examples ) .", "entities": []}, {"text": "However , if Genetic starts from our vulnerable examples , it would only need to perturb a single word ( i.e. , the patch words p ) to alter the prediction .", "entities": []}, {"text": "These results demonstrate the weakness of the models ( even robustly trained ) for those inputs beyond the test set .", "entities": []}, {"text": "3.3.3 Human Evaluation We perform human evaluation on the examples constructed by SO - Beam .", "entities": []}, {"text": "Speci\ufb01cally , we randomly 5We report median due to the unreasonably large perplexity on certain sentences .", "entities": [[12, 13, "MetricName", "perplexity"]]}, {"text": "e.g. , 395 for that \u2019s a cheat .", "entities": []}, {"text": "but 6740 for that proves perfect cheat .", "entities": []}, {"text": "3905Naturalness ( 1 - 5 ) Semantic Similarity ( % ) Original Perturb Original Perturb 3.87 3.63 85 71 Table 4 : The quality metrics from human evaluation .", "entities": [[6, 8, "TaskName", "Semantic Similarity"]]}, {"text": "select 100 successful attacks and evaluate both the original examples and the vulnerable examples .", "entities": []}, {"text": "To evaluate the naturalness of the constructed examples , we ask the annotators to score the likelihood ( on a Likert scale of 1 - 5 , 5 to be the most likely ) of being an original example based on the grammar correctness .", "entities": []}, {"text": "To evaluate the semantic similarity after applying the synonym substitution p , we ask the annotators to predict the sentiment of each example , and calculate the ratio of examples that maintain the same sentiment prediction after the synonym substitution .", "entities": [[3, 5, "TaskName", "semantic similarity"]]}, {"text": "For both metrics , we take the median from 3 independent annotations .", "entities": []}, {"text": "We use US - based annotators on Amazon \u2019s Mechanical Turk6and pay $ 0.03 per annotation , and expect each annotation to take 10 seconds on average ( effectively , the hourly rate is about $ 11 ) .", "entities": []}, {"text": "See Appendix A.2 for more details .", "entities": []}, {"text": "As shown in Table 4 , the naturalness score only drop slightly after the perturbation , indicating that our constructed vulnerable examples have similar naturalness as the original examples .", "entities": []}, {"text": "As for the semantic similarity , we observe that 85 % of the original examples maintain the same meaning after the synonym substitution , and the corresponding ratio is 71 % for vulnerable examples .", "entities": [[3, 5, "TaskName", "semantic similarity"]]}, {"text": "This indicates that the synonym substitution is an invariance transformation for most examples .", "entities": []}, {"text": "4 Evaluating Counterfactual Bias In addition to evaluating second - order robustness , we further extend the double perturbation framework ( \u00a7 2 ) to evaluate counterfactual biases by settingpto pairs of protected tokens .", "entities": []}, {"text": "We show that our method can reveal the hidden model bias .", "entities": []}, {"text": "4.1 Counterfactual Bias In contrast to second - order robustness , where we consider the model vulnerable as long as there existsonevulnerable example , counterfactual bias focuses on the expected prediction , which is the average prediction among all examples within the neighborhood .", "entities": []}, {"text": "We consider a model biased if", "entities": []}, {"text": "the 6https://www.mturk.com xx\bp   xx\bp Figure 4 : An illustration of an unbiased model vs. a biased model .", "entities": []}, {"text": "Green and gray indicate the probability of positive and negative predictions , respectively .", "entities": []}, {"text": "Left : An unbiased model where the ( x;x\bp)pair ( yellowred dots ) is relatively parallel to the decision boundary .", "entities": []}, {"text": "Right : A biased model where the predictions for x\bp ( red ) are usually more negative ( gray ) than x(yellow ) .", "entities": []}, {"text": "expected predictions for protected groups are different ( assuming the model is not intended to discriminate between these groups ) .", "entities": []}, {"text": "For instance , a sentiment classi\ufb01er is biased if the expected prediction for inputs containing woman is more positive ( or negative ) than inputs containing man .", "entities": []}, {"text": "Such bias is harmful as they may make unfair decisions based on protected attributes , for example in situations such as hiring and college admission .", "entities": []}, {"text": "Counterfactual token bias .", "entities": []}, {"text": "We study a narrow case of counterfactual bias , where counterfactual examples are constructed by substituting protected tokens in the input .", "entities": []}, {"text": "A naive approach of measuring this bias is to construct counterfactual examples directly from the test set , however such evaluation may not be robust since test examples are only a small subset of natural sentences .", "entities": []}, {"text": "Formally , let p be a pair of protected tokens such as ( he , she ) or ( Asian , American ) , Xtest\u0012X pbe a test set ( as in \u00a7 2.1 ) , we de\ufb01ne counterfactual token bias by : Bp;k:= E x2Neighbork(Xtest)Fsoft(x;p ): ( 5 ) We calculate Eq .", "entities": []}, {"text": "( 5 ) through an enumeration across all natural sentences within the neighborhood.7 Here Neighbork(Xtest )", "entities": []}, {"text": "= S x2X testNeighbork(x ) denotes the union of neighborhood examples ( of distancek ) around the test set , and Fsoft(x;p ) :", "entities": []}, {"text": "X\u0002V2![\u00001;1]denotes the difference between probability outputs fsoft(similar to Eq .", "entities": []}, {"text": "( 2 ) ): Fsoft(x;p ) :", "entities": []}, {"text": "= fsoft(x\bp)\u0000fsoft(x):(6 ) 7For gender bias , we employ a blacklist to avoid adding gendered tokens during the neighborhood construction .", "entities": []}, {"text": "This is to avoid semantic shift when , for example , p= ( he;she ) such that it may refer to different tokens after the substitution .", "entities": []}, {"text": "3906Patch Words # Original # Perturbed he , she 5 325;401 his , her 4 255;245 him , her 4 233;803 men , women 3 192;504 man , woman 3 222;981 actor , actress 2 141;780 : : : Total 34 2;317;635 Table 5 : The number of original examples ( k= 0 ) and the number of perturbed examples ( k= 3 ) inX\ufb01lter .", "entities": [[52, 53, "DatasetName", "0"]]}, {"text": "The model is unbiased on pifBp;k\u00190 , whereas a positive or negative Bp;kindicates that the model shows preference or against to p(2 ) , respectively .", "entities": []}, {"text": "Fig .", "entities": []}, {"text": "4 illustrates the distribution of ( x;x\bp)for both an unbiased model and a biased model .", "entities": []}, {"text": "The aforementioned neighborhood construction does not introduce additional bias .", "entities": []}, {"text": "For instance , letx0be a sentence containing he , even though it is possible for Neighbor1(x0)to contain many stereotyping sentences ( e.g. , contains tokens such asdoctor anddriving ) that affect the distribution offsoft(x ) , but it does not bias Eq .", "entities": []}, {"text": "( 6 ) as we only care about the prediction difference of replacing he!she .", "entities": []}, {"text": "The construction has no information about the model objective , thus it would be dif\ufb01cult to bias fsoft(x)andfsoft(x\bp)differently .", "entities": []}, {"text": "4.2 Experimental Results In this section , we use gender bias as a running example , and demonstrate the effectiveness of our method by revealing the hidden model bias .", "entities": []}, {"text": "We provide additional results in Appendix A.4 .", "entities": []}, {"text": "4.2.1", "entities": []}, {"text": "Setup We evaluate counterfactual token bias on the SST-2 dataset with both the base and debiased models .", "entities": [[8, 9, "DatasetName", "SST-2"]]}, {"text": "We focus on binary gender bias and set pto pairs of gendered pronouns from Zhao et al . ( 2018a ) .", "entities": []}, {"text": "Base Model .", "entities": []}, {"text": "We train a single layer LSTM with pre - trained GloVe embeddings and 75 hidden size ( from TextAttack , Morris et al . 2020 ) .", "entities": [[5, 6, "MethodName", "LSTM"], [10, 12, "MethodName", "GloVe embeddings"]]}, {"text": "The model has 82.9 % accuracy similar to the baseline performance reported in GLUE .", "entities": [[5, 6, "MetricName", "accuracy"], [13, 14, "DatasetName", "GLUE"]]}, {"text": "Debiased Model .", "entities": []}, {"text": "Data - augmentation with gender swapping has been shown effective in mitigating gender bias ( Zhao et al . , 2018a , 2019 ) .", "entities": []}, {"text": "We augment the training split by swapping all male entities with the corresponding female entities and vice - versa .", "entities": []}, {"text": "We use the same setup as the base LSTM and attain 82.45 % accuracy .", "entities": [[8, 9, "MethodName", "LSTM"], [13, 14, "MetricName", "accuracy"]]}, {"text": "Figure 5 : Our proposed Bp;kmeasured onX\ufb01lter .", "entities": []}, {"text": "Here \u201c original \u201d is equivalent to k= 0 , \u201c perturbed \u201d is equivalent tok= 3,pis in the form of ( male;female ) .", "entities": [[8, 9, "DatasetName", "0"]]}, {"text": "Metrics .", "entities": []}, {"text": "We evaluate model bias through the proposedBp;kfork= 0 ; : : : ; 3 .", "entities": [[7, 8, "DatasetName", "0"]]}, {"text": "Here the bias for k= 0is effectively measured on the original test set , and the bias for k\u00151is measured on our constructed neighborhood .", "entities": []}, {"text": "We randomly sample a subset of constructed examples when k= 3due to the exponential complexity .", "entities": []}, {"text": "Filtered test set .", "entities": []}, {"text": "To investigate whether our method is able to reveal model bias that was hidden in the test set , we construct a \ufb01ltered test set on which the bias can not be observed directly .", "entities": []}, {"text": "Let Xtestbe the original validation split , we construct X\ufb01lterby the equation below and empirically set \u000f= 0:005 .", "entities": []}, {"text": "We provide statistics in Table 5 .", "entities": []}, {"text": "X\ufb01lter:=fxjjFsoft(x;p)j<\u000f ; x2X testg : 4.2.2 Results", "entities": []}, {"text": "Our method is able to reveal the hidden model bias onX\ufb01lter , which is not visible with naive measurements .", "entities": []}, {"text": "In Fig .", "entities": []}, {"text": "5 , the naive approach ( k= 0 ) observes very small biases on most tokens ( as constructed ) .", "entities": [[7, 8, "DatasetName", "0"]]}, {"text": "In contrast , when evaluated by our double perturbation framework ( k= 3 ) , we are able to observe noticeable bias , where most phas a positive bias on the base model .", "entities": []}, {"text": "This observed bias is in line with the measurements on the original Xtest(Appendix A.4 ) , indicating that we reveal the correct model bias .", "entities": []}, {"text": "Furthermore , we observe mitigated biases in the debiased model , which demonstrates the effectiveness of data augmentation .", "entities": [[16, 18, "TaskName", "data augmentation"]]}, {"text": "To demonstrate how our method reveals hidden bias , we conduct a case study with p= ( actor ; actress ) and show the relationship between the biasBp;kand the neighborhood distance k.", "entities": []}, {"text": "We present the histograms for Fsoft(x;p)in Fig .", "entities": []}, {"text": "6 and plot the corresponding Bp;kvs.kin the right - most panel .", "entities": []}, {"text": "Surprisingly , for the base model , the bias is", "entities": []}, {"text": "3907 Figure 6 : Left and Middle : Histograms for Fsoft(x;p)(x - axis ) with p= ( actor;actress ) .Right :", "entities": []}, {"text": "The plot for the average Fsoft(x;p)(i.e . , counterfactual token bias ) vs. neighborhood distance k. Results show that the counterfactual bias on pcan be revealed when increasing k. negative when k= 0 , but becomes positive when k= 3 .", "entities": [[32, 33, "DatasetName", "0"]]}, {"text": "This is because the naive approach only has two test examples ( Table 5 ) thus the measurement is not robust .", "entities": []}, {"text": "In contrast , our method is able to construct 141;780similar natural sentences when k= 3and shifts the distribution to the right ( positive ) .", "entities": []}, {"text": "As shown in the right - most panel , the bias is small when k= 1 , and becomes more signi\ufb01cant askincreases ( larger neighborhood ) .", "entities": []}, {"text": "As discussed in \u00a7 4.1 , the neighborhood construction does not introduce additional bias , and these results demonstrate the effectiveness of our method in revealing hidden model bias .", "entities": []}, {"text": "5 Related Work First - order robustness evaluation .", "entities": []}, {"text": "A line of work has been proposed to study the vulnerability of natural language models , through transformations such as character - level perturbations ( Ebrahimi et al . , 2018 ) , word - level perturbations ( Jin et al . , 2019 ; Ren et al . , 2019 ; Yang et al . , 2020 ; Hsieh et al . , 2019 ; Cheng et al . , 2020 ; Li et", "entities": []}, {"text": "al . , 2020 ) , prepending or appending a sequence ( Jia and Liang , 2017 ; Wallace et al . , 2019a ) , and generative models ( Zhao et al . , 2018b ) .", "entities": []}, {"text": "They focus on constructing adversarial examples from the test set that alter the prediction , whereas our methods focus on \ufb01nding vulnerable examples beyond the test set whose prediction can be altered .", "entities": []}, {"text": "Robustness beyond the test set .", "entities": []}, {"text": "Several works have studied model robustness beyond test sets but mostly focused on computer vision tasks .", "entities": []}, {"text": "Zhang et al .", "entities": []}, {"text": "( 2019 ) demonstrate that a robustly trained model could still be vulnerable to small perturbations if the input comes from a distribution only slightly different than a normal test set ( e.g. , images with slightly different contrasts ) .", "entities": []}, {"text": "Hendrycks and Dietterich ( 2019 ) study more sources of common corruptions such as brightness , motion blur and fog .", "entities": []}, {"text": "Unlike in computer vision where simpleimage transformations can be used , in our natural language setting , generating a valid example beyond test set is more challenging because language semantics and grammar must be maintained .", "entities": []}, {"text": "Counterfactual fairness .", "entities": []}, {"text": "Kusner et al .", "entities": []}, {"text": "( 2017 ) propose counterfactual fairness and consider a model fair if changing the protected attributes does not affect the distribution of prediction .", "entities": []}, {"text": "We follow the de\ufb01nition and focus on evaluating the counterfactual bias between pairs of protected tokens .", "entities": []}, {"text": "Existing literature quanti\ufb01es fairness on a test dataset or through templates ( Feldman et al . , 2015 ;", "entities": []}, {"text": "Kiritchenko and Mohammad , 2018 ; May et al . , 2019 ; Huang et al . , 2020 ) .", "entities": []}, {"text": "For instance , Garg et al .", "entities": []}, {"text": "( 2019 ) quantify the absolute counterfactual token fairness gap on the test set ; Prabhakaran et al .", "entities": []}, {"text": "( 2019 ) study perturbation sensitivity for named entities on a given set of corpus .", "entities": []}, {"text": "Wallace et", "entities": []}, {"text": "al . ( 2019b ) ; Sheng et al .", "entities": []}, {"text": "( 2019 , 2020 ) study how language generation models respond differently to prompt sentences containing mentions of different demographic groups .", "entities": []}, {"text": "In contrast , our method quanti\ufb01es the bias on the constructed neighborhood .", "entities": []}, {"text": "6 Conclusion This work proposes the double perturbation framework to identify model weaknesses beyond the test dataset , and study a stronger notion of robustness and counterfactual bias .", "entities": []}, {"text": "We hope that our work can stimulate the research on further improving the robustness and fairness of natural language models .", "entities": []}, {"text": "Acknowledgments We thank anonymous reviewers for their helpful feedback .", "entities": []}, {"text": "We thank UCLA - NLP group for the valuable discussions and comments .", "entities": []}, {"text": "The research is supported NSF # 1927554 , # 1901527 , # 2008173 and # 2048280 and an Amazon Research Award .", "entities": []}, {"text": "3908Ethical Considerations Intended use .", "entities": []}, {"text": "One primary goal of NLP models is the generalization to real - world inputs .", "entities": []}, {"text": "However , existing test datasets and templates are often not comprehensive , and thus it is dif\ufb01cult to evaluate real - world performance ( Recht et", "entities": []}, {"text": "al . , 2019 ; Ribeiro et al . , 2020 ) .", "entities": []}, {"text": "Our work sheds a light on quantifying performance for inputs beyond the test dataset and help uncover model weaknesses prior to the realworld deployment .", "entities": []}, {"text": "Misuse potential .", "entities": []}, {"text": "Similar to other existing adversarial attack methods ( Ebrahimi et al . , 2018 ; Jin et al . , 2019 ; Zhao et al . , 2018b ) , our second - order attacks can be used for \ufb01nding vulnerable examples to a NLP system .", "entities": [[4, 6, "TaskName", "adversarial attack"]]}, {"text": "Therefore , it is essential to study how to improve the robustness of NLP models against second - order attacks .", "entities": []}, {"text": "Limitations .", "entities": []}, {"text": "While the core idea about the double perturbation framework is general , in \u00a7 4 , we consider only binary gender in the analysis of counterfactual fairness due to the restriction of the English corpus we used , which only have words associated with binary gender such as he / she , waiter / waitress , etc .", "entities": []}, {"text": "References Moustafa Alzantot , Yash Sharma , Ahmed Elgohary , Bo - Jhang Ho , Mani Srivastava , and Kai - Wei Chang .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Generating natural language adversarial examples .", "entities": []}, {"text": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2890\u20132896 , Brussels , Belgium .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Minhao Cheng , Jinfeng Yi , Pin - Yu Chen , Huan Zhang , and Cho - Jui Hsieh . 2020 .", "entities": []}, {"text": "Seq2sick : Evaluating the robustness of sequence - to - sequence models with adversarial examples .", "entities": []}, {"text": "Proceedings of the AAAI Conference on Arti\ufb01cial Intelligence , 34(04):3601\u20133608 .", "entities": []}, {"text": "Lucas Dixon , John Li , Jeffrey Sorensen , Nithum Thain , and Lucy Vasserman .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Measuring and mitigating unintended bias in text classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the 2018 AAAI / ACM Conference on AI , Ethics , and Society , AIES \u2019 18 , page 67\u201373 , New York , NY , USA .", "entities": [[7, 8, "DatasetName", "ACM"], [12, 13, "DatasetName", "Ethics"]]}, {"text": "Association for Computing Machinery .", "entities": []}, {"text": "Krishnamurthy Dvijotham , Sven Gowal , Robert Stanforth , Relja Arandjelovic , Brendan O\u2019Donoghue , Jonathan Uesato , and Pushmeet Kohli .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Training veri\ufb01ed learners with learned veri\ufb01ers .", "entities": []}, {"text": "Javid Ebrahimi , Anyi Rao , Daniel Lowd , and", "entities": []}, {"text": "Dejing Dou . 2018 .", "entities": []}, {"text": "HotFlip : White - box adversarial examples for text classi\ufb01cation .", "entities": []}, {"text": "In Proceedings of the56th Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Papers ) , pages 31\u201336 , Melbourne , Australia .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Michael Feldman , Sorelle A Friedler , John Moeller , Carlos Scheidegger , and Suresh Venkatasubramanian . 2015 .", "entities": []}, {"text": "Certifying and removing disparate impact .", "entities": []}, {"text": "In proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining , pages 259\u2013268 .", "entities": [[5, 6, "DatasetName", "ACM"]]}, {"text": "Sahaj Garg , Vincent Perot , Nicole Limtiaco , Ankur Taly , Ed H. Chi , and Alex Beutel .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Counterfactual fairness in text classi\ufb01cation through robustness .", "entities": []}, {"text": "InProceedings of the 2019 AAAI / ACM Conference on AI , Ethics , and Society , AIES \u2019 19 , page 219\u2013226 , New York , NY , USA .", "entities": [[6, 7, "DatasetName", "ACM"], [11, 12, "DatasetName", "Ethics"]]}, {"text": "Association for Computing Machinery .", "entities": []}, {"text": "Siddhant Garg and Goutham Ramakrishnan .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "BAE : BERT - based adversarial examples for text classi\ufb01cation .", "entities": [[2, 3, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 6174\u20136181 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Dan Hendrycks and Thomas Dietterich .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Benchmarking neural network robustness to common corruptions and perturbations .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Yu - Lun Hsieh , Minhao Cheng , Da - Cheng Juan , Wei Wei , Wen - Lian Hsu , and Cho - Jui Hsieh . 2019 .", "entities": []}, {"text": "On the robustness of self - attentive models .", "entities": []}, {"text": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 1520\u20131529 .", "entities": []}, {"text": "Kuan - Hao Huang and Kai - Wei Chang .", "entities": []}, {"text": "2021 .", "entities": []}, {"text": "Generating syntactically controlled paraphrases without using annotated parallel pairs .", "entities": []}, {"text": "In EACL .", "entities": []}, {"text": "Po - Sen Huang , Robert Stanforth , Johannes Welbl , Chris Dyer , Dani Yogatama , Sven Gowal , Krishnamurthy Dvijotham , and Pushmeet Kohli .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Achieving veri\ufb01ed robustness to symbol substitutions via interval bound propagation .", "entities": []}, {"text": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) .", "entities": []}, {"text": "Po - Sen Huang , Huan Zhang , Ray Jiang , Robert Stanforth , Johannes Welbl , Jack Rae , Vishal Maini , Dani Yogatama , and Pushmeet Kohli .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Reducing sentiment bias in language models via counterfactual evaluation .", "entities": []}, {"text": "Findings in EMNLP .", "entities": []}, {"text": "Mohit Iyyer , J. Wieting , Kevin Gimpel , and Luke Zettlemoyer .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Adversarial example generation with syntactically controlled paraphrase networks .", "entities": []}, {"text": "ArXiv , abs/1804.06059 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Robin Jia and Percy Liang . 2017 .", "entities": []}, {"text": "Adversarial examples for evaluating reading comprehension systems .", "entities": [[4, 6, "TaskName", "reading comprehension"]]}, {"text": "In Proceedings of the 2017 Conference on", "entities": []}, {"text": "3909Empirical Methods in Natural Language Processing , EMNLP 2017 , Copenhagen , Denmark , September 911 , 2017 , pages 2021\u20132031 .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Robin Jia , Aditi Raghunathan , Kerem G\u00f6ksel , and Percy Liang . 2019 .", "entities": []}, {"text": "Certi\ufb01ed robustness to adversarial word substitutions .", "entities": []}, {"text": "In EMNLP / IJCNLP .", "entities": []}, {"text": "Di Jin , Zhijing Jin , Joey Tianyi Zhou , and Peter Szolovits . 2019 .", "entities": []}, {"text": "Is bert really robust ?", "entities": []}, {"text": "a strong baseline for natural language attack on text classi\ufb01cation and entailment .", "entities": []}, {"text": "Svetlana Kiritchenko and Saif Mohammad .", "entities": []}, {"text": "2018 .", "entities": []}, {"text": "Examining gender and race bias in two hundred sentiment analysis systems .", "entities": [[8, 10, "TaskName", "sentiment analysis"]]}, {"text": "In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics , pages 43\u201353 , New Orleans , Louisiana .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Matt J Kusner , Joshua Loftus , Chris Russell , and Ricardo Silva . 2017 .", "entities": []}, {"text": "Counterfactual fairness .", "entities": []}, {"text": "In I. Guyon , U. V .", "entities": []}, {"text": "Luxburg , S. Bengio , H. Wallach , R. Fergus , S. Vishwanathan , and R. Garnett , editors , Advances in Neural Information Processing Systems 30 , pages 4066\u20134076 .", "entities": []}, {"text": "Curran Associates , Inc.", "entities": []}, {"text": "Linyang Li , Ruotian Ma , Qipeng Guo , Xiangyang Xue , and Xipeng Qiu . 2020 .", "entities": []}, {"text": "BERT - ATTACK : Adversarial attack against BERT using BERT .", "entities": [[0, 1, "MethodName", "BERT"], [4, 6, "TaskName", "Adversarial attack"], [7, 8, "MethodName", "BERT"], [9, 10, "MethodName", "BERT"]]}, {"text": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 6193\u20136202 , Online .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Chandler May , Alex Wang , Shikha Bordia , Samuel R. Bowman , and Rachel Rudinger .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "On measuring social biases in sentence encoders .", "entities": []}, {"text": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 622\u2013628 , Minneapolis , Minnesota .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Takeru Miyato , Andrew M. Dai , and Ian Goodfellow .", "entities": []}, {"text": "2017 .", "entities": []}, {"text": "Adversarial training methods for semisupervised text classi\ufb01cation .", "entities": []}, {"text": "ICLR .", "entities": []}, {"text": "John X. Morris , Eli Li\ufb02and , Jin Yong Yoo , Jake Grigsby , Di Jin , and Yanjun Qi . 2020 .", "entities": []}, {"text": "Textattack : A framework for adversarial attacks , data augmentation , and adversarial training in nlp .", "entities": [[8, 10, "TaskName", "data augmentation"]]}, {"text": "Nikola Mrk\u0161i \u00b4 c , Diarmuid \u00d3 S\u00e9aghdha , Blaise Thomson ,", "entities": []}, {"text": "Milica Ga\u0161i \u00b4 c , Lina M. Rojas - Barahona , PeiHao Su , David Vandyke , Tsung - Hsien Wen , and Steve Young .", "entities": []}, {"text": "2016 .", "entities": []}, {"text": "Counter-\ufb01tting word vectors to linguistic constraints .", "entities": []}, {"text": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 142\u2013148 , San Diego , California . Association for Computational Linguistics .", "entities": []}, {"text": "Jeffrey Pennington , Richard Socher , and Christopher D. Manning .", "entities": []}, {"text": "2014 .", "entities": []}, {"text": "Glove : Global vectors for word representation .", "entities": []}, {"text": "In Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1532\u20131543 .", "entities": []}, {"text": "Vinodkumar Prabhakaran , Ben Hutchinson , and Margaret Mitchell .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Perturbation sensitivity analysis to detect unintended model biases .", "entities": []}, {"text": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) , pages 5740\u20135745 , Hong Kong , China .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Alec Radford , Jeff Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 .", "entities": []}, {"text": "Language models are unsupervised multitask learners .", "entities": []}, {"text": "Benjamin Recht , Rebecca Roelofs , Ludwig Schmidt , and Vaishaal Shankar . 2019 .", "entities": []}, {"text": "Do ImageNet classi\ufb01ers generalize to ImageNet ?", "entities": [[1, 2, "DatasetName", "ImageNet"], [5, 6, "DatasetName", "ImageNet"]]}, {"text": "volume 97 of Proceedings of Machine Learning Research , pages 5389\u20135400 , Long Beach , California , USA . PMLR .", "entities": []}, {"text": "Shuhuai Ren , Yihe Deng , Kun He , and Wanxiang Che . 2019 .", "entities": []}, {"text": "Generating natural language adversarial examples through probability weighted word saliency .", "entities": []}, {"text": "InProceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 1085\u20131097 , Florence , Italy .", "entities": [[16, 17, "MethodName", "Florence"]]}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Marco Tulio Ribeiro , Tongshuang Wu , Carlos Guestrin , and Sameer Singh .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Beyond accuracy : Behavioral testing of nlp models with checklist .", "entities": [[1, 2, "MetricName", "accuracy"]]}, {"text": "In Association for Computational Linguistics ( ACL ) .", "entities": []}, {"text": "Victor Sanh , Lysandre Debut , Julien Chaumond , and Thomas Wolf .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Distilbert , a distilled version of bert : smaller , faster , cheaper and lighter .", "entities": [[0, 1, "MethodName", "Distilbert"]]}, {"text": "ArXiv , abs/1910.01108 .", "entities": [[0, 1, "DatasetName", "ArXiv"]]}, {"text": "Emily Sheng , Kai - Wei Chang , Premkumar Natarajan , and Nanyun Peng .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "The woman worked as a babysitter :", "entities": []}, {"text": "On biases in language generation .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Emily Sheng , Kai - Wei Chang , Premkumar Natarajan , and Nanyun Peng . 2020 .", "entities": []}, {"text": "Towards controllable biases in language generation .", "entities": []}, {"text": "In EMNLP - Finding .", "entities": []}, {"text": "Zhouxing Shi , Huan Zhang , Kai - Wei Chang , Minlie Huang , and Cho - Jui Hsieh .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Robustness veri\ufb01cation for transformers .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D. Manning , Andrew Ng , and Christopher Potts .", "entities": []}, {"text": "2013 .", "entities": []}, {"text": "Recursive deep models for semantic compositionality over a sentiment treebank .", "entities": []}, {"text": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 1631\u20131642 , Seattle , Washington , USA . Association for Computational Linguistics .", "entities": []}, {"text": "3910Eric Wallace , Shi Feng , Nikhil Kandpal , Matt Gardner , and Sameer Singh . 2019a .", "entities": []}, {"text": "Universal adversarial triggers for attacking and analyzing nlp .", "entities": []}, {"text": "In EMNLP / IJCNLP .", "entities": []}, {"text": "Eric Wallace , Shi Feng , Nikhil Kandpal , Matt Gardner , and Sameer Singh .", "entities": []}, {"text": "2019b .", "entities": []}, {"text": "Universal adversarial triggers for attacking and analyzing NLP .", "entities": []}, {"text": "In EMNLP .", "entities": []}, {"text": "Alex Wang , Amanpreet Singh , Julian Michael , Felix Hill , Omer Levy , and Samuel R. Bowman .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Glue : A multi - task benchmark and analysis platform for natural language understanding .", "entities": [[11, 14, "TaskName", "natural language understanding"]]}, {"text": "Thomas Wolf , Lysandre Debut , Victor Sanh , Julien Chaumond , Clement Delangue , Anthony Moi , Pierric Cistac , Tim Rault , R\u00e9mi Louf , Morgan Funtowicz , Joe Davison , Sam Shleifer , Patrick von Platen , Clara Ma , Yacine Jernite , Julien Plu , Canwen Xu , Teven Le Scao , Sylvain Gugger , Mariama Drame , Quentin Lhoest , and Alexander M. Rush .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Huggingface \u2019s transformers : State - of - the - art natural language processing .", "entities": []}, {"text": "Kaidi Xu , Zhouxing Shi , Huan Zhang , Yihan Wang , Kai - Wei Chang , Minlie Huang , Bhavya Kailkhura , Xue Lin , and Cho - Jui Hsieh . 2020 .", "entities": []}, {"text": "Automatic perturbation analysis for scalable certi\ufb01ed robustness and beyond .", "entities": []}, {"text": "Puyudi Yang , Jianbo Chen , Cho - Jui Hsieh , Jane - Ling Wang , and Michael I. Jordan .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Greedy attack and gumbel attack : Generating adversarial examples for discrete data .", "entities": []}, {"text": "Journal of Machine Learning Research , 21(43):1\u201336 .", "entities": []}, {"text": "Yuan Zang , Fanchao Qi , Chenghao Yang , Zhiyuan Liu , Meng Zhang , Qun Liu , and Maosong Sun . 2020 .", "entities": []}, {"text": "Word - level textual adversarial attacking as combinatorial optimization .", "entities": [[7, 9, "TaskName", "combinatorial optimization"]]}, {"text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics .", "entities": []}, {"text": "Huan Zhang , Hongge Chen , Zhao Song , Duane Boning , inderjit dhillon , and Cho - Jui Hsieh . 2019 .", "entities": []}, {"text": "The limitations of adversarial training and the blind - spot attack .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Jieyu Zhao , Tianlu Wang , Mark Yatskar , Ryan Cotterell , Vicente Ordonez , and Kai - Wei Chang .", "entities": []}, {"text": "2019 .", "entities": []}, {"text": "Gender bias in contextualized word embeddings .", "entities": [[4, 6, "TaskName", "word embeddings"]]}, {"text": "In NAACL .", "entities": []}, {"text": "Jieyu Zhao , Tianlu Wang , Mark Yatskar , Vicente Ordonez , and Kai - Wei Chang .", "entities": []}, {"text": "2018a .", "entities": []}, {"text": "Gender bias in coreference resolution : Evaluation and debiasing methods .", "entities": [[3, 5, "TaskName", "coreference resolution"]]}, {"text": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 2 ( Short Papers ) , pages 15\u201320 , New Orleans , Louisiana .", "entities": []}, {"text": "Association for Computational Linguistics .", "entities": []}, {"text": "Zhengli Zhao , Dheeru Dua , and Sameer Singh .", "entities": []}, {"text": "2018b .", "entities": []}, {"text": "Generating natural adversarial examples .", "entities": []}, {"text": "In International Conference on Learning Representations .", "entities": []}, {"text": "Yi Zhou , Xiaoqing Zheng , Cho - Jui Hsieh , Kai - Wei Chang , and Xuanjing Huang .", "entities": []}, {"text": "2020 .", "entities": []}, {"text": "Defense against adversarial attacks in nlp via dirichlet neighborhood ensemble .", "entities": []}, {"text": "arXiv preprint arXiv:2006.11627 .", "entities": [[0, 1, "DatasetName", "arXiv"]]}, {"text": "3911A Supplemental Material A.1 Random Baseline To validate the effectiveness of minimizing Eq .", "entities": []}, {"text": "( 4 ) , we also experiment on a second - order baseline that constructs vulnerable examples by randomly replacing up to 6 words .", "entities": []}, {"text": "We use the same masked language model and threshold as SO - Beam such that they share a similar neighborhood .", "entities": []}, {"text": "We perform the attack on the same models as Table 2 , and the attack success rates on robustly trained BoW , CNN , LSTM , and Transformers are 18.8 % , 22.3 % , 15.2 % , and 25.1 % , respectively .", "entities": [[24, 25, "MethodName", "LSTM"]]}, {"text": "Despite being a second - order attack , the random baseline has low attack success rates thus demonstrates the effectiveness of SO - Beam .", "entities": []}, {"text": "A.2 Human Evaluation We randomly select 100 successful attacks from SO - Beam and consider four types of examples ( for a total of 400 examples ): The original examples with and without synonym substitution p , and the vulnerable examples with and without synonym substitution p.", "entities": []}, {"text": "For each example , we annotate the naturalness and sentiment separately as described below .", "entities": []}, {"text": "Naturalness of vulnerable examples .", "entities": []}, {"text": "We ask the annotators to score the likelihood of being an original example ( i.e. , not altered by computer ) based on grammar correctness and naturalness , with a Likert scale of 1 - 5 : ( 1 ) Sure adversarial example .", "entities": []}, {"text": "( 2 ) Likely an adversarial example .", "entities": []}, {"text": "( 3 ) Neutral .", "entities": []}, {"text": "( 4 ) Likely an original example .", "entities": []}, {"text": "( 5 ) Sure original example .", "entities": []}, {"text": "Semantic similarity after the synonym substitution .", "entities": [[0, 2, "TaskName", "Semantic similarity"]]}, {"text": "We \ufb01rst ask the annotators to predict the sentiment on a Likert scale of 1 - 5 , and then map the prediction to three categories : negative , neutral , and positive .", "entities": []}, {"text": "We consider two examples to have the same semantic meaning if and only if they are both positive or negative .", "entities": []}, {"text": "A.3 Running Time We experiment with the validation split on a single RTX 3090 , and measure the average running time per example .", "entities": []}, {"text": "As shown in Table 6 , SO - Beam runs faster than SO - Enum since it utilizes the probability output .", "entities": []}, {"text": "The running time may increase if the model has improved second - order robustness .", "entities": []}, {"text": "Running Time ( seconds )", "entities": []}, {"text": "Genetic BAE SO - Enum SO - Beam Base Models : BoW 31.6 0.9 6.2 1.8 CNN 28.8 1.0 5.9 1.7 LSTM 31.9 1.1 7.0 1.9 Transformer 51.9 0.5 6.5 2.5 BERT - base 65.6 1.1 35.4 7.1 Robust Models : BoW 103.9 1.0 8.0 3.5 CNN 129.4 1.0 6.7 2.6 LSTM 116.4 1.1 10.7 5.3 Transformer 66.4 0.5 5.9 2.6 Table 6 : The average running time over 872 examples ( 100 for Genetic due to long running time ) .", "entities": [[21, 22, "MethodName", "LSTM"], [26, 27, "MethodName", "Transformer"], [31, 32, "MethodName", "BERT"], [51, 52, "MethodName", "LSTM"], [56, 57, "MethodName", "Transformer"]]}, {"text": "A.4 Additional Results on Protected Tokens Fig .", "entities": []}, {"text": "7 presents the experimental results with additional protected tokens such as nationality , religion , and sexual orientation ( from Ribeiro et", "entities": []}, {"text": "al . ( 2020 ) )", "entities": []}, {"text": ".", "entities": []}, {"text": "We use the same base LSTM as described in \u00a7 4.2 .", "entities": [[5, 6, "MethodName", "LSTM"]]}, {"text": "One interesting observation is whenp= ( gay;straight ) where the bias is negative , indicating that the sentiment classi\ufb01er tends to give more negative prediction when substituting gay!straight in the input .", "entities": []}, {"text": "This phenomenon is opposite to the behavior of toxicity classi\ufb01ers ( Dixon et al . , 2018 ) , and we hypothesize that it may be caused by the different distribution of training data .", "entities": []}, {"text": "To verify the hypothesis , we count the number of training examples containing each word , and observe that we have far more negative examples than positive examples among those containing straight ( Table 7 ) .", "entities": []}, {"text": "After looking into the training set , it turns out that straight to video is a common phrase to criticize a \ufb01lm , thus the classi\ufb01er incorrectly correlates straight with negative sentiment .", "entities": []}, {"text": "This also reveals the limitation of our method on polysemous words .", "entities": []}, {"text": "#", "entities": []}, {"text": "Negative # Positive gay 37 20 straight 71 18 Table 7 : Number of negative and positive examples containing gay andstraight in the training set .", "entities": []}, {"text": "In Fig . 8 , we measure the bias on Xtestand observe positive bias on most tokens for both k= 0 andk= 3 , which indicates that the model \u201c tends \u201d to make more positive predictions for examples containing certain female pronouns than male pro-", "entities": [[20, 21, "DatasetName", "0"]]}, {"text": "3912 Figure 7 : Additional counterfactual token bias measured on the original validation split with base LSTM .", "entities": [[16, 17, "MethodName", "LSTM"]]}, {"text": "nouns .", "entities": []}, {"text": "Notice that even though gender swap mitigates the bias to some extent , it is still dif\ufb01cult to fully eliminate the bias .", "entities": []}, {"text": "This is probably caused by tuples like ( him , his , her ) which can not be swapped perfectly , and requires additional processing such as part - of - speech resolving ( Zhao et al . , 2018a ) .", "entities": [[27, 30, "DatasetName", "part - of"]]}, {"text": "Figure 8 : Full results for gendered tokens measured on the original validation split .", "entities": []}, {"text": "To help evaluate the naturalness of our constructed examples used in \u00a7 4 , we provide sample sentences in Table 9 and Table 10 .", "entities": []}, {"text": "Bold words are the corresponding patch words p , taken from the prede\ufb01ned list of gendered pronouns .", "entities": []}, {"text": "A.5 Additional Results on Robustness Table 8 provides the quality metrics for \ufb01rst - order attacks , where we measure the GPT-2 perplexity and`0norm distance between the input and the adversarial example .", "entities": [[21, 22, "MethodName", "GPT-2"], [22, 23, "MetricName", "perplexity"]]}, {"text": "For BAE we evaluate on 872 validation examples , and for Genetic we evaluate on 100 validation examples due to the long running time .", "entities": []}, {"text": "Table 11 shows additional attack results fromGenetic BAE Original PPLPerturb PPL`0Original PPLPerturb PPL`0 Base Models : BoW 145 258 3.3 192 268 1.6 CNN 146 282 3.0 186 254 1.5 LSTM 131 238 2.9 190 263 1.6 Transformer 137 232 2.8 185 254 1.4 BERT - base 201 342 3.4 189 277 1.6 Robust Models : BoW 132 177 2.4 214 269 1.5 CNN 136 236 2.7 211 279 1.5 LSTM 163 267 2.5 220 302 1.6 Transformer 118 200 2.8 196 261 1.4 Table 8 : The quality metrics for \ufb01rst - order attacks from successful attacks .", "entities": [[30, 31, "MethodName", "LSTM"], [37, 38, "MethodName", "Transformer"], [44, 45, "MethodName", "BERT"], [70, 71, "MethodName", "LSTM"], [77, 78, "MethodName", "Transformer"]]}, {"text": "We compare median perplexities ( PPL ) and average ` 0norm distances .", "entities": []}, {"text": "SO - Beam on base LSTM , and Table 12 shows additional attack results from SO - Beam on robust CNN .", "entities": [[5, 6, "MethodName", "LSTM"]]}, {"text": "Bold words are the corresponding patch words p , taken from the prede\ufb01ned list of counter-\ufb01tted synonyms .", "entities": []}, {"text": "3913Type Predictions Text Original 95 % Negative 94 % Negative it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "Distancek= 1 97 % Negative ( 97 % Negative )", "entities": []}, {"text": "it \u2019s hampered by a lifetime - channel kind of plot and lone lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "56 % Negative ( 55 % Positive )", "entities": []}, {"text": "it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) who is out of creative depth .", "entities": []}, {"text": "89 % Negative ( 84 % Negative ) it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) who talks out of their depth .", "entities": []}, {"text": "98 % Negative ( 98 % Negative ) it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) who is out of production depth .", "entities": []}, {"text": "96 % Negative ( 96 % Negative ) it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) that is out of their depth .", "entities": []}, {"text": "Distancek= 2 88 % Negative ( 87 % Negative )", "entities": []}, {"text": "it \u2019s hampered by a lifetime - channel cast of stars and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "96 % Negative ( 95 % Negative ) it \u2019s hampered by a simple set of plot and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "54 % Negative ( 54 % Negative ) it \u2019s framed about a lifetime - channel kind of plot and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "90 % Negative ( 88 % Negative ) it \u2019s hampered by a lifetime - channel mix between plot and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "78 % Negative ( 68 % Negative ) it \u2019s hampered by a lifetime - channel kind of plot and a lead actor ( actress ) who storms out of their mind .", "entities": []}, {"text": "Distancek= 3 52 % Positive ( 64 % Positive )", "entities": []}, {"text": "it \u2019s characterized by a lifetime - channel combination comedy plot and a lead actor ( actress ) who is out of their depth .", "entities": []}, {"text": "93 % Negative ( 93 % Negative ) it \u2019s hampered by a lifetime - channel kind of star and a lead actor ( actress ) who falls out of their depth .", "entities": []}, {"text": "58 % Negative ( 57 % Negative ) it \u2019s hampered by a tough kind of singer and a lead actor ( actress ) who is out of their teens .", "entities": []}, {"text": "70 % Negative ( 52 % Negative ) it \u2019s hampered with a lifetime - channel kind of plot and a lead actor ( actress ) who operates regardless of their depth .", "entities": []}, {"text": "58 % Negative ( 53 % Positive )", "entities": []}, {"text": "it \u2019s hampered with a lifetime - channel cast of plot and a lead actor ( actress ) who is out of creative depth .", "entities": []}, {"text": "Table 9 : Additional counterfactual bias examples on base LSTM with p= ( actor;actress ) .", "entities": [[9, 10, "MethodName", "LSTM"]]}, {"text": "We only present 5 examples per kdue to space constrain .", "entities": []}, {"text": "3914Type Predictions Text Original 55 % Positive ( 67 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator of an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "Distancek= 1 52 % Positive ( 66 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator of an extended cheap shot from the mason - dixon line .", "entities": []}, {"text": "73 % Positive ( 79 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator gives an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "56 % Negative ( 58 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator of an extended cheap shot across the phone line .", "entities": []}, {"text": "75 % Positive ( 83 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator of an extended chase shot across the mason - dixon line .", "entities": []}, {"text": "75 % Positive ( 81 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) our hapless facilitator of an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "Distancek= 2 85 % Positive ( 85 % Positive ) a hilarious romantic comedy that makes our boy ( girl ) the hapless facilitator of an emotionally cheap shot across the mason - dixon line .", "entities": []}, {"text": "81 % Positive ( 86 % Positive ) a ham\ufb01sted romantic comedy romance makes our boy ( girl ) the hapless facilitator of an extended cheap delivery across the mason - dixon line .", "entities": []}, {"text": "84 % Positive ( 87 % Positive ) a ham\ufb01sted romantic romance adventure makes our boy ( girl ) the hapless facilitator of an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "50 % Negative ( 62 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless boss of an extended cheap shot behind the mason - dixon line .", "entities": []}, {"text": "77 % Negative ( 71 % Negative ) a ham\ufb01sted lesbian comedy that makes our boy ( girl ) the hapless facilitator of an extended slap shot across the mason - dixon line .", "entities": []}, {"text": "Distancek= 3 97 % Positive ( 97 % Positive ) a darkly romantic comedy romance makes our boy ( girl ) the hapless facilitator delivers an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "69 % Positive ( 74 % Positive ) a ham\ufb01sted romantic comedy \ufb01lm makes our boy ( girl ) the hapless facilitator of an extended cheap shot across the production line .", "entities": []}, {"text": "87 % Positive ( 89 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the exclusive focus of an extended cheap shot across the mason - dixon line .", "entities": []}, {"text": "64 % Positive ( 76 % Positive ) a ham\ufb01sted romantic comedy that makes our boy ( girl ) the hapless facilitator shoots an extended \ufb02ash shot across the camera line .", "entities": []}, {"text": "99 % Positive ( 99 % Positive ) a compelling romantic comedy that makes our boy ( girl ) the perfect facilitator of an extended story shot across the mason - dixon line .", "entities": []}, {"text": "Table 10 : Additional counterfactual bias examples on base LSTM with p=", "entities": [[9, 10, "MethodName", "LSTM"]]}, {"text": "( boy;girl ) .", "entities": []}, {"text": "We only present 5 examples per kdue to space constrain .", "entities": []}, {"text": "3915Type Predictions Text Original 99 % Positive ( 99 % Positive )", "entities": []}, {"text": "it \u2019s a charming and sometimes ( often ) affecting journey .", "entities": []}, {"text": "Vulnerable 59 % Negative ( 56 % Positive )", "entities": []}, {"text": "it \u2019s a charming and sometimes ( often ) painful journey .", "entities": []}, {"text": "Original 99 % Negative ( 97 % Negative ) un\ufb02inchingly bleak ( somber ) and desperate Vulnerable 80 % Negative ( 79 % Positive ) un\ufb02inchingly bleak ( somber ) and mysterious Original 99 % Positive ( 93 % Positive ) allows us to hope that nolan is poised to embark a major career ( quarry ) as a commercial yet inventive \ufb01lmmaker .", "entities": []}, {"text": "Vulnerable 76 % Positive ( 75 % Negative ) allows us to hope that nolan is poised to embark a major career ( quarry ) as a commercial yet amateur \ufb01lmmaker .", "entities": []}, {"text": "Original 94 % Positive ( 68 % Positive ) the acting , costumes , music , cinematography and sound are all astounding ( staggering ) given the production \u2019s austere locales .", "entities": []}, {"text": "Vulnerable 87 % Positive ( 66 % Negative ) the acting , costumes , music , cinematography and sound are largely astounding ( staggering ) given the production \u2019s austere locales .", "entities": []}, {"text": "Original 99 % Positive ( 97 % Positive ) although laced with humor and a few fanciful touches , the \ufb01lm is a refreshingly serious look at young ( juvenile ) women .", "entities": []}, {"text": "Vulnerable 94 % Positive ( 81 % Negative ) although laced with humor and a few fanciful touches , the \ufb01lm is a moderately serious look at young ( juvenile ) women .", "entities": []}, {"text": "Original 99 % Negative ( 98 % Negative ) a sometimes ( occasionally ) tedious \ufb01lm .", "entities": []}, {"text": "Vulnerable 62 % Negative ( 55 % Positive )", "entities": []}, {"text": "a sometimes ( occasionally ) disturbing \ufb01lm .", "entities": []}, {"text": "Original 100 % Negative ( 100 % Negative ) in exactly 89 minutes , most of which passed as slowly as if i \u2019d been sitting naked on an igloo , formula 51 sank from quirky ( lunatic ) to jerky to utter turkey .", "entities": []}, {"text": "Vulnerable 51 % Positive ( 65 % Negative ) lasting exactly 89 minutes , most of which passed as slowly as if i \u2019d been sitting naked on an igloo , but 51 ranges from quirky ( lunatic ) to delicious to crisp turkey .", "entities": []}, {"text": "Original 97 % Positive ( 100 % Positive ) thescintillating ( mesmerizing ) performances of the leads keep the \ufb01lm grounded and keep the audience riveted .", "entities": []}, {"text": "Vulnerable 91 % Negative ( 90 % Positive ) thescintillating ( mesmerizing ) performances of the leads keep the \ufb01lm grounded and keep the plot predictable .", "entities": []}, {"text": "Original 89 % Negative ( 96 % Negative ) it takes a uncanny ( strange ) kind of laziness to waste the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie .", "entities": []}, {"text": "Vulnerable 80 % Positive ( 76 % Negative ) it takes a uncanny ( strange ) kind of humour to waste the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie .", "entities": []}, {"text": "Original 100 % Negative ( 100 % Negative ) ...", "entities": []}, {"text": "the \ufb01lm suffers from a lack of humor ( something needed to balance ( equilibrium ) out the violence ) ...", "entities": []}, {"text": "Vulnerable 76 % Positive ( 86 % Negative ) ...", "entities": []}, {"text": "the \ufb01lm derives from a lot of humor ( something clever to balance ( equilibrium ) out the violence ) ...", "entities": []}, {"text": "Original 55 % Positive ( 97 % Positive ) we root for ( clara and paul ) , even like them , though perhaps it \u2019s an emotion closer to pity ( compassion ) .", "entities": [[27, 28, "DatasetName", "emotion"]]}, {"text": "Vulnerable 89 % Negative ( 91 % Positive ) we root for ( clara and paul ) , even like them , though perhaps it \u2019s an explanation closer to pity ( compassion ) .", "entities": []}, {"text": "Original 95 % Negative ( 97 % Negative ) even horror fans ( stalkers ) will most likely not \ufb01nd what they \u2019re seeking with trouble every day ; the movie lacks both thrills and humor .", "entities": []}, {"text": "Vulnerable 61 % Positive ( 59 % Negative ) even horror fans ( stalkers ) will most likely not \ufb01nd what they \u2019re seeking with trouble every day ; the movie has both thrills and humor .", "entities": []}, {"text": "Original 100 % Positive ( 100 % Positive ) a gorgeous , high - spirited musical from india that exquisitely mixed ( blends ) music , dance , song , and high drama .", "entities": []}, {"text": "Vulnerable 87 % Negative ( 81 % Positive ) a dark , high - spirited musical from nowhere that loosely mixed ( blends ) music , dance , song , and high drama .", "entities": []}, {"text": "Original 99 % Negative ( 94 % Negative ) ...", "entities": []}, {"text": "the movie is just a plain old ( longtime ) monster .", "entities": []}, {"text": "Vulnerable 94 % Negative ( 94 % Positive ) ...", "entities": []}, {"text": "the movie is just a pretty old ( longtime ) monster .", "entities": []}, {"text": "Table 11 : Additional sentiment classi\ufb01cation results from SO - Beam on base LSTM .", "entities": [[13, 14, "MethodName", "LSTM"]]}, {"text": "3916Type Predictions Text Original 54 % Positive ( 69 % Positive ) for the most part , director anne - sophie birot \u2019s \ufb01rst feature is a sensitive , overly ( extraordinarily ) well - acted drama .", "entities": []}, {"text": "Vulnerable 53 % Negative ( 62 % Positive ) for the most part , director anne - sophie benoit \u2019s \ufb01rst feature is a sensitive , overly ( extraordinarily ) well - acted drama .", "entities": []}, {"text": "Original 66 % Positive ( 72 % Positive )", "entities": []}, {"text": "mr . tsai is a very original painter ( artist ) in his medium , and what time is it there ?", "entities": []}, {"text": "Vulnerable 52 % Negative ( 55 % Positive )", "entities": []}, {"text": "mr . tsai is a very original painter ( artist ) in his medium , and what time was it there ?", "entities": []}, {"text": "Original 80 % Positive ( 64 % Positive ) sade is an engaging ( engage ) look at the controversial eponymous and \ufb01ercely atheistic hero .", "entities": []}, {"text": "Vulnerable 53 % Positive ( 66 % Negative ) sade is an engaging ( engage ) look at the controversial eponymous or \ufb01ercely atheistic hero .", "entities": []}, {"text": "Original 50 % Negative ( 57 % Negative ) so devoid of any kind of comprehensible ( intelligible ) story that it makes \ufb01lms like xxx and collateral damage seem like thoughtful treatises Vulnerable 53 % Positive ( 54 % Negative )", "entities": []}, {"text": "so devoid of any kind of comprehensible ( intelligible ) story that it makes \ufb01lms like xxx and collateral 2 seem like thoughtful treatises Original 90 % Positive ( 87 % Positive ) a tender , heartfelt ( deepest ) family drama .", "entities": []}, {"text": "Vulnerable 60 % Positive ( 61 % Negative ) a somber , heartfelt ( deepest ) funeral drama .", "entities": []}, {"text": "Original 57 % Positive ( 69 % Positive ) ...", "entities": []}, {"text": "a hollow joke ( giggle ) told by a cinematic gymnast having too much fun embellishing the misanthropic tale to actually engage it .", "entities": []}, {"text": "Vulnerable 56 % Negative ( 56 % Positive ) ...", "entities": []}, {"text": "a hollow joke ( giggle ) told by a cinematic gymnast having too much fun embellishing the misanthropic tale can not actually engage it .", "entities": []}, {"text": "Original 73 % Negative ( 56 % Negative ) the cold ( colder ) turkey would \u2019 ve been a far better title .", "entities": []}, {"text": "Vulnerable 61 % Negative ( 62 % Positive ) the cold ( colder ) turkey might \u2019 ve been a far better title .", "entities": []}, {"text": "Original 70 % Negative ( 65 % Negative )", "entities": []}, {"text": "it \u2019s just disappointingly super\ufb01cial \u2013 a movie that has all the elements necessary to be a fascinating , involving character study , but never does more than scratch the shallow ( surface ) .", "entities": []}, {"text": "Vulnerable 52 % Negative ( 55 % Positive )", "entities": []}, {"text": "it \u2019s just disappointingly short \u2013 a movie that has all the elements necessary to be a fascinating , involving character study , but never does more than scratch the shallow ( surface ) .", "entities": []}, {"text": "Original 79 % Negative ( 72 % Negative ) schaeffer has to \ufb01nd some hook on which to hang his persistently useless movies , and it might as well be the resuscitation ( revival ) of the middleaged character .", "entities": []}, {"text": "Vulnerable 57 % Negative ( 57 % Positive ) schaeffer has to \ufb01nd some hook on which to hang his persistently entertaining movies , and it might as well be the resuscitation ( revival ) of the middleaged character .", "entities": []}, {"text": "Original 64 % Positive ( 58 % Positive ) the primitive force of this \ufb01lm seems to bubble up from the vast collective memory of the combatants ( militants ) .", "entities": []}, {"text": "Vulnerable 52 % Positive ( 53 % Negative ) the primitive force of this \ufb01lm seems to bubble down from the vast collective memory of the combatants ( militants ) .", "entities": []}, {"text": "Original 64 % Positive ( 74 % Positive ) on this troublesome ( tricky ) topic , tadpole is very much a step in the right direction , with its blend of frankness , civility and compassion .", "entities": []}, {"text": "Vulnerable 55 % Negative ( 56 % Positive ) on this troublesome ( tricky ) topic , tadpole is very much a step in the right direction , losing its blend of frankness , civility and compassion .", "entities": []}, {"text": "Original 74 % Positive ( 60 % Positive ) if you \u2019re hard ( laborious ) up for raunchy college humor , this is your ticket right here .", "entities": []}, {"text": "Vulnerable 60 % Positive ( 57 % Negative ) if you \u2019re hard ( laborious ) up for raunchy college humor , this is your ticket holder here .", "entities": []}, {"text": "Original 94 % Positive ( 97 % Positive ) a fast , funny , highly fun ( enjoyable ) movie .", "entities": []}, {"text": "Vulnerable 54 % Negative ( 65 % Positive ) a dirty , violent , highly fun ( enjoyable ) movie .", "entities": []}, {"text": "Original 86 % Positive ( 88 % Positive ) good old - fashioned slash - and - hack is back ( backwards ) !", "entities": []}, {"text": "Vulnerable 52 % Negative ( 55 % Positive ) a old - fashioned slash - and - hack is back ( backwards ) !", "entities": []}, {"text": "Table 12 : Additional sentiment classi\ufb01cation results from SO - Beam on robust CNN .", "entities": []}]