Proceedings of the 4th Workshop on Argument Mining , pages 97–107 Copenhagen , Denmark , September 8 , 2017 .
c  2017 Association for Computational Linguistics Unsupervised Detection of Argumentative Units though Topic Modeling Techniques Alﬁo Ferrara andStefano
Montanelli Dipartimento di Informatica , Universit ` a degli Studi di Milano Via Comelico 39 , 20135 - Milano , Italy { alﬁo.ferrara , stefano.montanelli } @unimi.it Georgios Petasis Institute of Informatics and Telecommunications , National Centre for Scientiﬁc Research ( N.C.S.R. )
“ Demokritos ” P.O. BOX 60228 , Aghia Paraskevi , GR-153 10 , Athens , Greece
petasis@iit.demokritos.gr Abstract In this paper we present a new unsupervised approach , “ Attraction to Topics ” – A2 T , for the detection of argumentative units , a sub - task of argument mining .
Motivated by the importance of topic identiﬁcation in manual annotation , we examine whether topic modeling can be used for performing unsupervised detection of argumentative sentences , and to what extend topic modeling can be used to classify sentences as claims and premises .
Preliminary evaluation results suggest that topic information can be successfully used for the detection of argumentative sentences , at least for corpora used in the evaluation .
Our approach has been evaluated on two English corpora , the ﬁrst of which contains 90 persuasive essays , while the second is a collection of 340 documents from user generated content .
1 Introduction Argument mining involves the automatic discovery of argument components ( i.e. claims , premises ) and the argumentative relations ( i.e. supports , attacks ) among these components in texts .
Primarily aiming to extract arguments from texts in order to provide structured data for computational models of argument and reasoning engines ( Lippi and Torroni , 2015a ) , argument mining has additionally the potential to support applications in various research ﬁelds , such as opinion mining ( Goudas et al . , 2015 ) , stance detection ( Hasan and Ng,2014 ) , policy modelling ( Florou et al . , 2013 ;
Goudas et al . , 2014 ) , legal information systems ( Palau and Moens , 2009 ) , etc . Argument mining is usually addressed as a pipeline of several sub - tasks .
Typically the ﬁrst sub - task is the separation between argumentative and non - argumentative text units , which can be performed at various granularity levels , from clauses to several sentences , usually depending on corpora characteristics .
Detection of argumentative units ( AU)1 , as discussed in Section 2 , is typically modeled as a fully - supervised classiﬁcation task , either a binary one , where units are separated in argumentative and non - argumentative ones with argumentative ones to be subsequently classiﬁed in claims and premises as a second step , or as a multi - class one , where identiﬁcation of argumentative units and classiﬁcation into claims and premises are performed as a single step .
According to a recent survey ( Lippi and Torroni , 2015a ) , the performance of proposed approaches depends on highly engineered and sophisticated , manually constructed , features .
However , fully - supervised approaches rely on manually annotated datasets , the construction of which is a laborious , costly , and error - prone process , requiring signiﬁcant effort from human experts .
At the same time , reliance on sophisticated features may hinder the generalisation of an approach to new corpora types and domains ( Lippi and Torroni , 2015a ) .
The removal of manual supervision through exploitation of unsupervised approaches is a possible solution to both of the aforementioned problems .
1.1 Motivations of our work Topics seem to be related to the task of argument mining , at least for some types of corpora , as topic 1Also known as “ Argumentative Discourse Units – ADUs ” ( Peldszus and Stede , 2013 ) .97
identiﬁcation frequently appears as a step in the process of manual annotation of arguments in texts ( Stab and Gurevych , 2014a ) .
However , despite its apparent importance in manual annotation , only a small number of studies have examined the inclusion of topic information in sub - tasks of argument mining .
Habernal and Gurevych ( 2015 ) have included sentiment and topic information as features for classifying sentences as claims , premises , backing and non - argumentative units .
A less direct exploitation of topic information has been presented in ( Nguyen and Litman , 2015 ) , where topics have been used to extract lexicons of argument and domain words , which can provide evidence regarding the existence of argument components .
In this paper we propose “ Attraction to Topics ” – A2 T , an unsupervised approach based on topic modeling techniques for detecting argumentative discourse units at sentence - level granularity ( a sub - task known as “ argumentative sentence detection ” ) .
The goals of A2Tare twofold .
On the one side , A2Tenforces identiﬁcation of sentences that contain argument components , by also distinguishing them from the non - argumentative sentences that do not contain argument components .
On the other side , A2Tclassiﬁes the discovered argumentative sentences according to their role , as major claims , claims , and premises .
The rest of the paper is organized as follows : Section 2presents an overview of approaches related to argument mining focusing on the detection of argumentative units , while Section 3presents our approach on applying topic modeling for identifying sentences that contain argument components .
Section 4presents our experimental setting and evaluation results , with Section 5concluding this paper and proposing some directions for further research .
2 Related work Almost all argument mining frameworks proposed so far employ a pipeline of stages , each of which is addressing a sub - task of the argument mining problem ( Lippi and Torroni , 2015a ) .
The segmentation of text into argumentative units is typically the ﬁrst sub - task encountered in such an argument mining pipeline , aiming to segment texts into argumentative and non - argumentative text units ( i.e. segments that do contain or do not contain argument components , such as claims or premises ) .
The granularity of argument components is text - dependant .
For example , in Wikipedia articles studied in ( Rinott et al . , 2015 ) , argument components spanned from less than a sentence to more than a paragraph , although 90 % of the cases was up to 3 sentences , with 95 % of components being comprised of whole sentences .
Several approaches address the identiﬁcation of argumentative units at the sentence level , a subtask known as “ argumentative sentence detection ” , which typically models the task as a binary classiﬁcation problem .
Employing machine learning and a set of features representing sentences , the goal is to discard sentences that are not part ( or do not contain a component ) of an argument .
As reported also by Lippi and Torroni ( 2015a ) , the vast majority of existing approaches employ “ classic , off - the - self ” classiﬁers , while most of the effort is devoted to highly engineered features .
A plethora of learning algorithms have been applied on the task , including Naive Bayes ( Moens et al . , 2007 ; Park and Cardie , 2014 ) , Support Vector Machines ( SVM ) ( Mochales and Moens , 2011 ; Rooney et al . , 2012 ; Park and Cardie , 2014 ; Stab and Gurevych , 2014b ; Lippi and Torroni , 2015b ) , Maximum Entropy ( Mochales and Moens , 2011 ) , Logistic Regression ( Goudas et al . , 2014 , 2015 ; Levy et al . , 2014 ) , Decision Trees and Random Forests ( Goudas et al . , 2014 , 2015 ; Stab and Gurevych , 2014b ) .
However , approaches addressing this task in a semi - supervised or unsupervised manner are still scarce .
In ( Petasis and Karkaletsis , 2016 ) an unsupervised approach is presented , which addresses the sub - task of identifying the main claim in a document by exploiting evidence from an extractive summarization algorithm , TextRank ( Mihalcea and Tarau , 2004 ) .
In an attempt to study the overlap between graph - based approaches and approaches targeting extractive summarization with argument mining , evaluation results suggest a positive effect on the sub - task , achieving an accuracy of 50 % on the corpus compiled by Hasan and Ng(2014 ) from online debate forums and on a corpus of persuasive essays ( Stab and Gurevych , 2014a ) .
Regarding semi - supervised approaches , Habernal and Gurevych ( 2015 ) propose new unsupervised features that exploit clustering of unlabeled argumentative data from debate portals based on word embeddings , outperforming several baselines .
This work employs also topic modeling as one of its features , by including as features the98
distributions of sentences from LDA ( Blei et al . , 2003 ) .
Topic modeling has been mainly exploited for identiﬁcation of argumentative relations and for extraction of argument and domain lexicons .
In Lawrence et al .
( 2014 ) , LDA is used to decide whether a proposition can be attached to its previous proposition in order to identify non directional relations among propositions detected through classiﬁers based on words and part - ofspeech tags .
LDA has been also used to mine lexicons of argument ( words that are topic independent ) and domain words ( Nguyen and Litman , 2015 ) , by post - processing document topics generated by LDA .
These lexicons have been used as features for supervised approaches for argument mining ( Nguyen and Litman , 2016a , b ) .
However , to the best of our knowledge , no prior approach has applied topic modeling to argumentative sentence detection in an unsupervised setting , which is the featuring aspect of the proposed A2Tapproach presented in the following .
3 Topic modeling for argument mining Given a document corpus , topic modeling techniques can be employed to discover the most representative topics throughout the corpus , and to provide an assignment of documents to topics , meaning that the higher is the assignment value of a document to a certain topic , the higher is the probability that the document is “ focused ” on that topic .
The idea ofA2Tis that an argumentative unit is a sentence highly focused on a speciﬁc topic , namely a sentence with high assignment value to a certain topic and low assignment value to the other topics .
To this end , A2Tintroduces the notion of attraction with the aim at recognizing the sentences highly focused on speciﬁc topics , that represent the recognized argumentative units .
In the following , theA2Tapproach and related techniques are described in detail .
3.1A2Tapproach
The schema of the A2Tapproach is shown in Figure 1 .
Consider a corpus of texts C= { c1 , . . .
, c n } , where a text ci∈C is a sequence of sentences , like for example an essay , a web page / post , or a scientiﬁc paper .
The ultimate goal of theA2Tapproach is to derive a set of argumentative unitsU={/angbracketlefts1 , c , l / angbracketright , . . .
, /angbracketleftsh , c , l / angbracketright } , where Corpus of   Texts ( C ) Argumentative   Units ( U)Sentence   Extraction Attraction   EvaluationTopic ModellingSentence Index ( S)Figure 1 : Schema of the A2Tapproach siis a sentence containing an argumentative unit , cis the text containing s , and lis the argumentative role expressed by the unit ( e.g. , major claim , claim , premise ) .
The A2Tapproach is articulated in the following activities : Sentence extraction .
A2Tapproach is characterized by the use of topic modeling at sentencelevel granularity .
For this reason , a pre - processing step of the corpusCis enforced based on conventional techniques for sentence tokenization , words tokenization , normalization , and indexing ( Manning et al . , 2008 ) .
The result is a sentence set S={/angbracketleft− →s1 , c , pos 1 / angbracketright , . . .
, /angbracketleft− →sm , c , pos m / angbracketright } , where− →si is the vector representation of the sentence siand c , posare text and position in the text where the sentence appears , respectively .
The sentence set is stored in a sentence index for efﬁcient access of S elements .
Topic modeling .
The set of extracted sentences Sis used as the document corpus on which topic modeling is applied .
The result of this activity is twofold .
First , topic modeling returns a set of topicsT={t0 , . . .
, t k}representing the latent variables that are most representative for the sentences S. Second , topic modeling returns a distribution of sentences over topics θ={θs1 , . .
. , θ sm } .
In particular , θsi= [ p(t0|si ) , . . .
, p ( tk|si)]is the probability distribution of the sentence siover the set of topicsT , where p(tj|si)represents the probability of the topic tjgiven the sentence si(i.e . , the so - called assignment value of sitotj ) .
Attraction evaluation .
The notion of attraction is introduced to measure the degree of focus that characterizes sentences with respect to the emerged topics .
To this end , the distribution of sentences over topics θis exploited with the aim at determining the best topic assignment for each sentence ofS.
The result is an attraction set A={/angbracketlefts1 , a1 / angbracketright , . . .
, /angbracketleftsm , am / angbracketright}where siis a sentence ofSandaiis its corresponding attraction99
value .
Sentence labeling .
By exploiting the attraction setA , labeling has the goal to determine the sentences ofSthat are more focused on a speciﬁc topic , according to the hypothesis that those sentences are the argumentative units .
In a basic scenario , labeling consists in distinguishing between sentences that are argumentative units ( l = au ) and sentences that are not argumentative units ( l= au ) .
In a more articulated scenario , labeling consists in assigning a role to sentences that are recognized as argumentative units .
For instance , it is possible to distinguish argumentative - unit sentences that are claims ( l = cl ) , major claims ( l = mc ) , or premises ( l = pr ) .
A sentence s recognized as argumentative unit is inserted in the ﬁnal setUwith the assigned label and it is returned as a result ofA2T. 3.2A2Ttechniques InA2 T , the sentence extraction step is enforced by relying on standard techniques for representing documents in terms of feature vectors and bag of words ( using tf - idf as weighting scheme )
( Castano et al . , 2017 ) .
Probabilistic topic modeling is exploited to enforce the subsequent topic modelingstep .
Probabilistic topic models are a suite of algorithms whose aim is to discover the hidden thematic structure in large archives of documents , namely sentences inA2T. The idea is that documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over words ( Blei et al . , 2003 ) .
Probabilistic topic modeling algorithms infer the distribution θof documents over topics and the distribution φof words over topics , by sampling from the bag of words of each document .
In our approach , we choose to exploit the Hierarchical Dirichlet Process ( HDP ) .
With respect to other algorithms ( such as LDA ) , HDP has the advantage to provide the optimal number of topics instead of requiring to set such a number as input ( Teh et al . , 2006 ) .
Attraction evaluation .
The notion of attraction is introduced inA2Tto capture the intuition that argumentative units are related to the distribution of sentences over topics .
Consider a set of sentencesSand the distribution θof sentences over the set of topicsT.
The more the distribution θsi of a sentence siover the topics is unequal , the more siisfocused on a topic , thus suggesting sias a possible argumentative unit .
A further feature that attraction aims to capture is that argumentative units often appear either at the beginning or at the end of texts .
The attraction aiof a sentence si is calculated as follows : ai = Kϕsi+ ( 1−K)ρsi / summationtext sj∈cρsj , ϕsi= max ( θsi)is a measure of how much si is focused on a topic and ρsi = αf(posi)2 + βf(posi ) + γis a parabolic function over the position of the sentence in c. In particular , given L(c)as the number of sentences in c , f(posi )
= /vextendsingle / vextendsingle / vextendsingleL(c ) 2−posi / vextendsingle / vextendsingle / vextendsinglesuch that f(posi)is higher when si appears either at the beginning or at the end of c.
The parameters α , β , γdetermine the shape ofρsi .
K∈[0,1]is a constant value used to balance the role of focus and position in calculating the attraction .
The attraction aican be interpreted as the probability of a sentence sito contain an argumentative unit .
According to this interpretation , given si , also the contiguous sentences si−1andsi+1have a chance to be argumentative units .
As a result , given the calculated attraction setA , we update the attraction values ai through an interpolation mechanism based on the Savitzky - Golay smoothing ﬁlter ( SGF ) ( Savitzky and Golay , 1964 ) , so thatA:=SGF ( A ) .
In Figure 2 , an example of attraction evaluation is provided by showing the values of ϕ,ρ , attraction , and interpolated attraction for all the sentences within one considered student essays included in the corpus from ( Stab and Gurevych , 2014a ) ( see Section 4 ) .
s
0 s 1 s 2 s 3 s 4 s 5 s 6 s 7 s 8 s 9 s 10 s 11 s 12 s 13 s 14 s 15 s 16 s 17 s 18 s 19 s 20 s 21 s 22 s 23 s 24 s 25 s 26 s 27 s 28 s 29 s 30 s 31 s 32 s 330.00.20.40.60.81.0si ( focus ) si ( position ) ai ( attraction ) ai : = SGF(ai ) Figure 2 : Attraction evaluation for the sentences of a considered text100
Sentence labeling .
Sentence labeling has the goal to turn attraction values into labeled categories .
Consider a set of possible labels L= { l1 , . .
. , l g } , each one denoting a possible argumentative role that can be assigned to a sentence .
Given a set of attraction values A , a thresholdbased mechanism is enforced to assign labels to sentences according to the following scheme : ai < τ 1 :
si←l1 τ1≤ai < τ 2 : si←l2 . . . . . . .
. .
ai≥τg−1 : si←lg where τ1 < τ 2 < ...
< τ g−1(τ1 , . . .
τ g−1∈(0,1 ] ) are preﬁxed threshold values .
The result of sentence labeling is a partition of Sintogcategories with associated labels .
In the experiments , we discuss two different strategies for sentence labeling .
The ﬁrst one is a two - class labeling strategy where the possible labels for a sentence are argumentative unit ( au ) and non - argumentative unit ( au .
The second strategy is amulti - class labeling in which the possible labels of a sentence are non - argumentative unit au , premise ( pr ) , claim ( cl ) , and major claim ( mc ) .
4 Experimental results For evaluation of the proposed A2Tapproach , we have used two English corpora .
The ﬁrst corpus ( C1 in the following ) is a collection of 90 student persuasive essays ( Stab and Gurevych , 2014a ) which has been manually annotated with major claims ( one per essay ) , claims and premises at the clause level .
In addition , the corpus contains manual annotations of argumentative relations , where the claims and premises are linked , while claims are linked to the major claim either with a support or an attack relation .
Interannotation agreement has been measured to unitized alpha ( Krippendorff , 2004 ) αU= 0.724 .
These 90 essays consist of a total of 1,675sentences ( from which 19.3%contain no argument components ) , with an average length of 18.61±7 sentences per essay , while the 5.4%of sentences contain a major claim , 26.4%contain a claim , and 61.1%contain a premise .
The second corpus ( C2 in the following ) has been compiled and manually annotated as described in ( Habernal and Gurevych , 2017 ) .
This corpus focuses on user generated content , including user comments , forum posts , blogs , and newspaper articles , covering several thematic domainsfrom educational controversies , such as homeschooling , private vs. public schools , or singlesex education .
Containing in total 340 documents , the corpus has been manually annotated with an argument scheme based on extended Toulmin ’s model , involving claims , premises , and backing , rebuttal , refutation argument units .
The corpus contains documents of various sizes , with a mean size of 11.44±11.70sentences per document , while the inter - annotator agreement was measured asαU= 0.48 .
The corpus consists of 3,899 sentences , from which 2,214 sentences ( 57 % ) contain no argument components .
Both corpora have been preprocessed with NLTK ( Loper and Bird , 2002 ) in order to identify tokens and sentences .
Then , each sentence was annotated as argumentative or non - argumentative , depending on whether it contained an argument unit ( i.e. a text fragment annotated as major claim , claim , or premise ) .
In addition , each argumentative sentence was further annotated with one of major claim , claim , and premise , based on the type of the contained argumentative unit .
For the second corpus , which utilizes a richer argument scheme , we have considered backing , rebuttal and refutation units as premises .
This second corpus does not contain units annotated as major claims .
The following three tasks have been executed : •Task 1 : Argumentative sentence identiﬁcation – given a sentence , classify whether or not it contains an argument component .
•Task 2 : Major claim identiﬁcation – given a argumentative sentence , classify whether or not it contains a major claim .
•Task 3 : Argumentative sentence classiﬁcation – given a sentence , classify the sentence as major claim , claim , premise , ornonargumentative .
Baseline .
As a baseline for comparison against our approach , we created a probabilistic classiﬁer of sentences which evaluates the probability p(l = au|si)as follows .
Given the text ccontaining L(c)sentences si , let be ζc∼Dir(α ) the probability distribution of the sentences in c , such that ζsic∼p(l = au|si ) .
The L(c)parameters αused to generate ζcare deﬁned such thatαi=/vextendsingle / vextendsingle / vextendsingleL(c ) 2−posi / vextendsingle / vextendsingle / vextendsingle .
The rationale of this procedure is to bias the random assignment of a sentence to the aulabel in favor of sentences appearing either in the beginning or in the end of a text .
This bias attempts to model empirical evi-101
dence that in several types of documents , the density of argumentative units in various sections of documents depends on the structure of documents .
The beginning and end of a document are expected to contain argumentative units in structured documents like news , scientiﬁc publications , or argumentative essays ( Stab and Gurevych , 2017 ) , where major claims and supporting premises are frequently found in the beginning of documents , with documents frequently ending with repeating the major claims and supporting evidence .
4.1 Task 1 : Argumentative sentence identiﬁcation The goal of Task 1 is to associate each sentence of the corpora to a label in L={au , au}by following a two - class labeling strategy ( see Section 3 ) .
As a ﬁrst experiment , we performed sentence labeling with different threshold ranging from 0to 1with step 0.05 .
In Figure 3 , we report the precision , recall , and F1 - measure for A2Tand for the baseline .
In addition , we report also the results of applying sentence labeling based on ϕandρ ( the components of attraction ) separately .
The parameter Kfor attraction calculation has been set to0.5 . SinceA2Tis an unsupervised method , there is no easy way to deﬁne the threshold parameter τ , which has been empirically deﬁned to τ= 0.3 .
The different behavior of A2Twith respect to the baseline is shown in the confusion matrices reported in Figures 4and5 .
From Figure 3 , we can see that A2Tis signiﬁcantly better than the baseline , especially for the C1 corpus .
A characteristic of this corpus is that argumentative units are frequently located in the introduction or the conclusion of an essay , which is also reﬂected by the baseline that achieved an F1 - measure of 0.35for a threshold
ofτ= 0.05(with
the baseline being particularly precise , suggesting that argumentative units are very frequently at the beginning and end of essays ) .
Both components of attraction ( ϕandρ ) perform well , with the topic component ϕbeing slightly better than position information ρ , both in precision and recall .
The results are similar for corpus C2 , with A2Tsurpassing the baseline , althoughA2Tadvantage in precision is smaller .
As shown in the confusion matrix of Figure 5 , the main source of error is the large number of false positives for the auclass , proposing more argumentative units than what have been manu - ally identiﬁed in corpus C2 .
This can be attributed to the sparseness of argumentative units in the C2 corpus , with almost 60 % of the sentences being non - argumentative .
4.2 Task 2 : Major claim identiﬁcation As a second experiment , we exploited probabilities associated with sentences to perform a ranked evaluation .
In particular , we calculated two measures , namely Pthat is the area the under the precision - recall curve and Rthat is the area under the receiver operating characteristic ( ROC ) curve .
In this experiments , we used different criteria for deﬁning the true labels : in PCM , an annotated sentence in the corpus is considered a true argumentative unit if it is either a premise , a claim , or a major claim ; in CM only claims and major claims are taken as valid au ; inMonly major claims are taken into account .
Results are reported in Table 1 .
Table 1 : Area under the precision - recall ( P ) and the ROC ( R ) curves C1 C2 P PCM CM M PCM CM A2 T 0.79 0.31 0.08 0.26 0.19 ϕ 0.84 0.29 0.06 0.19 0.1 ρ 0.68 0.29 0.09 0.24 0.19 Baseline 0.68 0.31 0.11 0.16 0.06 R PCM CM M PCM CM
A2 T 0.4 0.52 0.62 0.7 0.76 ϕ 0.52 0.51 0.53 0.58 0.57 ρ 0.16 0.52 0.77 0.69 0.77 Baseline 0.16
0.53 0.79 0.31 0.18 4.3 Task 3 : Argumentative sentence classiﬁcation
The goal of Task 3 is to associate each sentence of the corpora to a label in L={au , pr , cl , mc } by following a multi - class labeling strategy ( see Section 3 ) .
In particular , we adopted the thresholds[0.1,0.3,0.5 ] .
This task is challenging since it is required to distinguish the different role played in argumentation by sentences that are often very similar from the terminological point of view .
The confusion matrix for corpus C1 is shown in Figure6 , while Figure 7shows the confusion matrix for corpus C2 .
Both A2Tand the baseline achieve low results , but the accuracy of A2Tis 0.3 against the 0.1 of the baseline .
From Figure 6we see thatA2Tachieved good results for premises , and quite good results for claims , although distinguishing between claims and premises is challenging for theA2Tapproach .
In particular , the role102
C1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Precision A2 T Baseline 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Recall 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 F1 - measure C2 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Precision A2 T Baseline 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 Recall 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Threshold0.00.10.20.30.40.50.60.70.80.91.0 F1 - measure Figure 3 : Precision , Recall and F1 - measure with different thresholds au au Predicted labelau auTrue label122 148 789 545A2 T au au Predicted labelau auTrue label228 42 1331 3Baseline 200300400500600700 20040060080010001200 Figure 4 : Two - class confusion matrices for corpus C1 ( Threshold τ= 0.3 ) of sentences may change in different texts so that claims in one context are premises in another .
This kind of contextual shift is only partially addressed au au Predicted labelau auTrue
label1790 1504 152 430A2 T au au Predicted labelau auTrue label3037
257 515 67Baseline 2004006008001000120014001600 50010001500200025003000Figure 5 : Two - class confusion matrices for corpus C2
( Threshold τ= 0.3 ) byA2 T , because the only contextual information we take into account is topic distribution .
To the end of improving the understanding of the context,103
auprclmc Predicted labelau pr cl mcTrue label31 91 94 54 213 313 232 101 84 145 104 55 4 30 36 17A2 T auprclmc Predicted labelau pr cl mcTrue label111 117 41 1 800 58 1 0 335 52 1 0 50 36 1 0Baseline 50100150200250300 0100200300400500600700800Figure 6 : Multi - class confusion matrices for corpus C1 auprclmc
Predicted labelau pr cl mcTrue label1790 1033 469 2 111 104 60 0 41 136 129 1 0 0 0 0A2 T auprclmc Predicted labelau pr cl mcTrue label3037 18 93 146 230 0 5 40 285 0 5 17 0 0 0 0Baseline 02004006008001000120014001600 050010001500200025003000
Figure 7 : Multi - class confusion matrices for corpus
C2 it may be useful to work also on semantic relations holding among sentences .
This is actually one of the future tasks in our research work .
Another speciﬁc challenge emerges when we consider the corpus C2 .
Indeed , C2 contains a limited number of argumentative sentences with respect to the corpus size .
In this case , since we analyze all the sentences according to their bag of words , we tend to overestimate the number of argumentative units , collecting a relatively high number of false positives .
4.4 Lessons learned from error analysis A ﬁrst evidence emerging from the analysis of confusion matrices for both corpora C1 and C2 is that the role of sentences is strictly dependent on the type of documents .
C1 contains structured essays of various topics , while C2 provides conversational texts extracted from blogs and chats .
In the ﬁrst case , the number of argumentative units is higher than in the second one .
In particular , for C2 we overestimated the probability of sentences to be an argumentative unit .
This is mainly dueto the fact that those sentences contain words that are semantically related to the main topic of the conversation although they are not playing a role in the argumentation .
An example is the following sentence , taken from a document associated with the topic “ school ” : “ why do some parents not think their kids can attain ? ” .
The sentence is clearly part of a conversation and it has been annotated as a non argumentative unit because it is a question .
However , since it contains words that are relevant for the topic ( i.e. , parents , kids , attain),A2Tassociates the sentence with a good level of attraction , labeling it as a premise .
In order to address this kind of false positives , we aim in our future work to study the dependency relations among sentences in text ( such as questionanswers ) to the goal of achieving a better insight of the sentences role .
A second lesson learned from error analysis concerns the distinction between claims and premises .
This confusion is evident especially when dealing with corpus C1 .
An example is given by the following two sentences , taken from104
an essay about the role of sports in favor of peace .
•(s1)for example , when Irak was hardly struck by the second gulf war , its citizens tried to catch any incoming news about the footballworld cup through their portable receivers .
•(s2 ) thus , world sports events strongly participate in eventually pulling back people towards friendship and peace The sentence ( s1 ) has been annotated as a premise , while ( s2 ) as a claim .
In our classiﬁcation , they are both claims .
The reason is that they both contain topic - related words and their position in text is similar .
The main distinction is the presence of the expression “ for example ” in the ﬁrst sentence which qualiﬁes it as a premise .
To this end , in our future work we aim at adding some special words ( such as “ for example ” , “ therefore ” ) in the background knowledge of the classiﬁer , in order to improve the capability of discriminating premises and claims .
5 Concluding remarks In this paper , we present the “ Attraction to Topics ” – A2Tunsupervised approach for detecting argumentative discourse units , at sentence - level granularity .
Motivated by the observation that topic information is frequently employed as a sub - task in the process of manual annotation of arguments , we propose an approach that exploits topic modeling techniques in order to identify argumentative units .
Since manual supervision is not required , A2Thas the potential to be applicable on documents of various genres and domains .
Preliminary evaluation results on two different corpora are promising .
First , A2Tperforms significantly better than the baseline on argumentative sentence detection on both corpora .
Second , A2 T exhibits good results for classifying argumentative sentences as major claims , claims , premises , and non - argumentative units , at least for the ﬁrst corpus , which has a low rate of non - argumentative sentences ( 20 % ) .
Regarding directions for further research , there are several axes that can be explored .
Evaluation on a larger set of annotation corpora will provide enhanced insights about the performance of the proposed approach on different document types .
Our preliminary results showed that despite good recall on multiple corpora , achieving also goodprecision can be a challenging task in documents where argumentative units are sparse , and false positives can be an issue .
In this context , we would like to also exploit other types of relations , and extend our method with other kinds of similarities over sentences .
References David M. Blei , Andrew Y .
Ng , and Michael I. Jordan .
2003 .
Latent dirichlet allocation .J. Mach .
Learn .
Res .
3:993–1022 .
http://dl.acm.org/citation.cfm?id=944919.944937 .
Silvana Castano , Alﬁo Ferrara , and Stefano Montanelli . 2017 .
Exploratory analysis of textual data streams .
Future Generation Computer Systems 68:391–406 .
Eirini Florou , Stasinos Konstantopoulos , Antonis Koukourikos , and Pythagoras Karampiperis .
2013 .
Argument extraction for supporting public policy formulation .
In Piroska Lendvai and Kalliopi Zervanou , editors , Proceedings of the 7th Workshop on Language Technology for Cultural Heritage , Social Sciences , and Humanities , LaTeCH@ACL 2013 , August 8 , 2013 , Soﬁa , Bulgaria .
The Association for Computer Linguistics , pages 49–54 .
http://aclweb.org/anthology/W/W13/W132707.pdf .
Theodosis Goudas , Christos Louizos , Georgios Petasis , and Vangelis Karkaletsis .
2014 .
Argument extraction from news , blogs , and social media .
In Aristidis Likas , Konstantinos Blekas , and Dimitris Kalles , editors , Artiﬁcial Intelligence : Methods and Applications : 8th Hellenic Conference on AI , SETN 2014 , Ioannina , Greece , May 15 - 17 , 2014 .
Proceedings , Springer International Publishing , Cham , pages 287–299 .
https://doi.org/10.1007/9783-319-07064-3 23 .
Theodosis Goudas , Christos Louizos , Georgios Petasis , and Vangelis Karkaletsis .
2015 .
Argument extraction from news , blogs , and the social web .
International Journal on Artiﬁcial Intelligence Tools 24(05):1540024 .
https://doi.org/10.1142/S0218213015400242 .
Ivan Habernal and Iryna Gurevych . 2015 .
Exploiting debate portals for semi - supervised argumentation mining in user - generated web discourse .
In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .
Association for Computational Linguistics , Lisbon , Portugal , pages 2127–2137 .
http://aclweb.org/anthology/D15-1255 .
Ivan Habernal and Iryna Gurevych . 2017 .
Argumentation mining in user - generated web discourse .Computational
Linguistics 43(1):125–179 .
https://doi.org/10.1162/COLI a00276 .105
Kazi Saidul Hasan and Vincent Ng . 2014 .
Why are you taking this stance ?
identifying and classifying reasons in ideological debates .
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .
Association for Computational Linguistics , Doha , Qatar , pages 751–762 .
http://www.aclweb.org/anthology/D141083 .
Klaus Krippendorff .
2004 .
Measuring the reliability of qualitative text analysis data .Quality and Quantity38(6):787–800 . https://doi.org/10.1007/s11135004-8107-7 .
John Lawrence , Chris Reed , Colin Allen , Simon McAlister , and Andrew Ravenscroft .
2014 .
Mining arguments from 19th century philosophical texts using topic based modelling .
In Proceedings of the First Workshop on Argumentation Mining . Association for Computational Linguistics , Baltimore , Maryland , pages 79–87 . http://www.aclweb.org/anthology/W/W14/W14-2111 .
Ran Levy , Yonatan Bilu , Daniel Hershcovich , Ehud Aharoni , and Noam Slonim .
2014 .
Context dependent claim detection .
In Jan Hajic and Junichi Tsujii , editors , COLING 2014 , 25th International Conference on Computational Linguistics , Proceedings of the Conference : Technical Papers , August 2329 , 2014 , Dublin , Ireland .
ACL , pages 1489–1500 . http://aclweb.org/anthology/C/C14/C14-1141.pdf .
Marco Lippi and Paolo Torroni .
2015a .
Argument mining : A machine learning perspective .
In Elizabeth Black , Sanjay Modgil , and Nir Oren , editors , Theory and Applications of Formal Argumentation : Third International Workshop , TAFA 2015 , Buenos Aires , Argentina , July 25 - 26 , 2015 , Revised Selected Papers .
Springer International Publishing , Cham , pages 163–176 .
https://doi.org/10.1007/9783-319-28460-6 10 .
Marco Lippi and Paolo Torroni .
2015b .
Contextindependent claim detection for argument mining .
InProceedings of the 24th International Conference on Artiﬁcial Intelligence .
AAAI Press , IJCAI’15 , pages 185–191 .
http://dl.acm.org/citation.cfm?id=2832249.2832275 .
Edward Loper and Steven Bird .
2002 .
Nltk : The natural language toolkit .
In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics - Volume 1 . Association for Computational Linguistics , Stroudsburg , PA , USA , ETMTNLP ’ 02 , pages 63–70 . https://doi.org/10.3115/1118108.1118117 .
Christopher D Manning , Prabhakar Raghavan , and Hinrich Sch ¨utze . 2008 .
Introduction to information retrieval , volume 1 .
Cambridge university press Cambridge .
Rada Mihalcea and Paul Tarau .
2004 .
Textrank : Bringing order into texts .
In Dekang Lin and DekaiWu , editors , Proceedings of EMNLP 2004 .
Association for Computational Linguistics , Barcelona , Spain , pages 404–411 .
http://www.aclweb.org/anthology/W/W04/W04-3252.pdf .
Raquel Mochales and Marie - Francine Moens . 2011 .
Argumentation mining .Artiﬁcial Intelligence and Law 19(1):1–22 .
https://doi.org/10.1007/s10506010-9104-x .
Marie - Francine Moens , Erik Boiy , Raquel Mochales Palau , and Chris Reed .
2007 .
Automatic detection of arguments in legal texts .
In Proceedings of the 11th International Conference on Artiﬁcial Intelligence and Law .
ACM , New York , NY , USA , ICAIL ’ 07 , pages 225–230 .
https://doi.org/10.1145/1276318.1276362 .
Huy Nguyen and Diane J. Litman .
2015 .
Extracting argument and domain words for identifying argument components in texts .
In Proceedings of the 2nd Workshop on Argumentation Mining , ArgMining@HLT - NAACL 2015 , June 4 , 2015 , Denver , Colorado , USA .
The Association for Computational Linguistics , pages 22–28 . http://aclweb.org/anthology/W/W15/W15-0503.pdf .
Huy Nguyen and Diane J. Litman .
2016a .
Contextaware argumentative relation mining .
In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , ACL 2016 , August 7 - 12 , 2016 , Berlin , Germany , Volume 1 : Long Papers .
The Association for Computer Linguistics . http://aclweb.org/anthology/P/P16/P16-1107.pdf .
Huy Nguyen and Diane J. Litman .
2016b .
Improving argument mining in student essays by learning and exploiting argument indicators versus essay topics .
In Zdravko Markov and Ingrid Russell , editors , Proceedings of the Twenty - Ninth International Florida Artiﬁcial Intelligence Research Society Conference , FLAIRS 2016 , Key Largo , Florida , May 16 - 18 , 2016 . .
AAAI Press , pages 485–490 .
http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS16/paper/view/12791 .
Raquel Mochales Palau and Marie - Francine Moens .
2009 .
Argumentation mining : The detection , classiﬁcation and structure of arguments in text .
InProceedings of the 12th International Conference on Artiﬁcial Intelligence and Law .
ACM , New York , NY , USA , ICAIL ’ 09 , pages 98–107 . https://doi.org/10.1145/1568234.1568246 .
Joonsuk Park and Claire Cardie .
2014 .
Identifying appropriate support for propositions in online user comments .
In Proceedings of the First Workshop on Argumentation Mining .
Association for Computational Linguistics , Baltimore , Maryland , pages 29–38 .
http://www.aclweb.org/anthology/W/W14/W14-2105 .
Andreas Peldszus and Manfred Stede .
2013 .
From argument diagrams to argumentation mining in texts : A survey .
Int.106
J. Cogn .
Inform .
Nat . Intell .
7(1):1–31 . https://doi.org/10.4018/jcini.2013010101 .
Georgios Petasis and Vangelis Karkaletsis .
2016 .
Identifying argument components through textrank .
In Proceedings of the 3rd Workshop on Argument Mining ( ArgMining2016 ) .
Association for Computational Linguistics , Berlin , Germany , pages 56–66 .
http://aclweb.org/anthology/W/W16/W162811.pdf .
Ruty Rinott , Lena Dankin , Carlos Alzate Perez , Mitesh M. Khapra , Ehud Aharoni , and Noam Slonim . 2015 .
Show me your evidence - an automatic method for context dependent evidence detection .
InProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing .
Association for Computational Linguistics , Lisbon , Portugal , pages 440–450 .
http://aclweb.org/anthology/D15-1050 .
Niall Rooney , Hui Wang , and Fiona Browne .
2012 .
Applying kernel methods to argumentation mining .
In G. Michael Youngblood and Philip M. McCarthy , editors , Proceedings of the Twenty - Fifth International Florida Artiﬁcial Intelligence Research Society Conference , Marco Island , Florida .
May 23 - 25 , 2012 .
AAAI Press .
http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS12/paper/view/4366 .
Abraham Savitzky and Marcel JE Golay .
1964 .
Smoothing and differentiation of data by simpliﬁed least squares procedures .
Analytical chemistry 36(8):1627–1639 .
Christian Stab and Iryna Gurevych .
2014a .
Annotating argument components and relations in persuasive essays .
In Junichi Tsujii and Jan Hajic , editors , Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) .
Dublin City University and Association for Computational Linguistics , Dublin , Ireland , pages 1501–1510 .
http://www.aclweb.org/anthology/C141142 .
Christian Stab and Iryna Gurevych .
2014b .
Identifying argumentative discourse structures in persuasive essays .
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .
Association for Computational Linguistics , Doha , Qatar , pages 46–56 . http://www.aclweb.org/anthology/D14-1006 .
Christian Stab and Iryna Gurevych . 2017 .
Parsing argumentation structures in persuasive essays .
Computational Linguistics 0(ja):1–62 .
https://doi.org/10.1162/COLI
a00295 .
Yee Whye Teh , Michael I Jordan , Matthew J Beal , and David M Blei .
2006 .
Hierarchical dirichlet processes .Journal of the American Statistical Association 101(476):1566–1581 .
https://doi.org/10.1198/016214506000000302
.107
