Proceedings of NAACL - HLT 2019 , pages 4077–4085 Minneapolis , Minnesota , June 2 - June 7 , 2019 .
c  2019 Association for Computational Linguistics4077Benchmarking Hierarchical Script Knowledge Yonatan Bisk1Jan Buys1Karl PichottaYejin Choi1;2 1Paul G. Allen School of Computer Science and Engineering , University of Washington 2Allen Institute for Artiﬁcial Intelligence fybisk , jbuysg@cs.washington.edu Abstract Understanding procedural language requires reasoning about both hierarchical and temporal relations between events .
For example , “ boiling pasta ” is a sub - event of “ making a pasta dish ” , typically happens before “ draining pasta , ” and requires the use of omitted tools ( e.g. a strainer , sink ... ) .
While people are able to choose when and how to use abstract versus concrete instructions , the NLP community lacks corpora and tasks for evaluating if our models can do the same .
In this paper , we introduce KIDSCOOK , a parallel script corpus , as well as a cloze task which matches video captions with missing procedural details .
Experimental results show that state - of - the - art models struggle at this task , which requires inducing functional commonsense knowledge not explicitly stated in text .
1 Introduction The level of detail used in natural language communication varies : descriptive or instructive text for experts may elide over details the reader can seamlessly infer , while text for more novice audiences may be more verbose .
A given document typically adheres to a single level of verbosity suited to its presumed audience ( Grice , 1975 ) , so learning correspondences between abstract and detailed descriptions of similar concepts from text is a challenging problem .
Commonsense knowledge of how complex events decompose into stereotypical sequences of simpler events is a necessary component of a system that can automatically understand and reason about different types of discourse .
Hierarchical correspondences between abstract and detailed representations of concepts and events were an important aspect of the original formulation of scripts for natural language understanding ( Schank and Author now at Google .
Work done while unafﬁliated .
1.Take the strainer with the pasta and pour the pasta into the sauce.2.Stir the pasta into sauce while it is in the pan.3.Let the pasta and sauce simmer for a few minutes .
Add pasta to the sauce t2 < latexit sha1_base64="P4+gfywhwn2dG1TBnMWEEbekCJE=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64="P4+gfywhwn2dG1TBnMWEEbekCJE=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64="P4+gfywhwn2dG1TBnMWEEbekCJE=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit><latexit sha1_base64="P4+gfywhwn2dG1TBnMWEEbekCJE=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0mKUI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7 / Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzioDcoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE / YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ / Xi / F8NrPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+1a1XOr3v1VpXGTx1GEMziHS / CgDg24gya0gMEInuEV3hzpvDjvzseyteDkM6fwB87nDwccjZ0=</latexit>1.Put a   large   pot   half   full of   water   on the   stove.2.Turn   the heat on under the pot and   wait   for the   water   to boil hard.3.Pour the pasta into the boiling   water .
Cook the pastat0
< latexit sha1_base64="apCCl0QQ / pUAKLQ3uBGKSWYytus=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64="apCCl0QQ / pUAKLQ3uBGKSWYytus=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64="apCCl0QQ / pUAKLQ3uBGKSWYytus=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit><latexit sha1_base64="apCCl0QQ / pUAKLQ3uBGKSWYytus=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAfte3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAQUjZs=</latexit > … … Drain the pasta1.Put the strainer in the sink .
2.Once the pot with pasta is cool enough , grab it by the handles .
3.Pour the pasta and water into the strainer in the sink.4.Pick up the strainer and shake it a little bit so more water comes out.t1 < latexit sha1_base64="FVaQdjUWZVLyUUalbbTR1NMDoKM=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64="FVaQdjUWZVLyUUalbbTR1NMDoKM=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64="FVaQdjUWZVLyUUalbbTR1NMDoKM=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit><latexit sha1_base64="FVaQdjUWZVLyUUalbbTR1NMDoKM=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z9wD49aJsk0402WyER3Qmq4FIo3UaDknVRzGoeSt8Px7cxvP3FtRKIecZLyIKZDJSLBKFrpAft+3616NW8Oskr8glShQKPvfvUGCctirpBJakzX91IMcqpRMMmnlV5meErZmA5511JFY26CfH7qlJxZZUCiRNtSSObq74mcxsZM4tB2xhRHZtmbif953Qyj6yAXKs2QK7ZYFGWSYEJmf5OB0JyhnFhCmRb2VsJGVFOGNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzZHOi / PufCxaS04xcwx/4Hz+AAWYjZw=</latexit > Figure 1 : An example KIDSCOOK sequence with multiple types of hierarchy and abstraction : the example contains sequences of complex instructions , given both as sentences and sequences of simpler instructions .
Abelson , 1977 ; DeJong , 1981 ) but required handwritten data structures encoding world knowledge .
However , the automatic induction of such commonsense knowledge from open - domain noisy text corpora remains an open problem ( Chambers , 2013 ; Weber et al . , 2018 ; Zellers et al . , 2018 ) .
As a step towards solving this problem we consider textual descriptions of actions in a cooking domain .
We introduce a dataset , KIDSCOOK , targeted at exploring the automatic acquisition of correspondences between abstract and concrete descriptions of actions .
The dataset consists of higher - level single - sentence imperative descriptions paired with lower - level descriptions with elided details included .
Descriptions come from real grounded actions , built on top of the YouCookII video caption dataset ( Zhou et al . , 2017 ) .
Figure 1 gives an example annotation from the dataset : the phrase “ drain the pasta , ” presented to an annotator with its corresponding video clip , was annotated as corresponding to four constituent steps appropriate as instruction for a child .
The constituent steps are “ simpler ” in the sense that they correspond to more atomic actions , but not necessarily in their linguistic complexity .
We identify over 1,500 procedures and tools which KIDSCOOK makes explicit but are assumed as
4078commonsense world knowledge by YouCookII .
The KIDSCOOK dataset allows us to learn mappings between abstract and concrete descriptions via sequence - to - sequence prediction .
We apply several standard neural sequence - to - sequence models ; however , since these models do not expose explicit , interpretable correspondences between abstract and concrete descriptions , we also propose the application of neural transduction models which capture correspondences with latent hard alignment variables .
We deﬁne a cloze - style evaluation to complement our dataset , in which models must predict the values of held - out tokens which target knowledge of tool usage , temporal ordering , and kitchen commonsense .
We ﬁnd that our neural transduction models are able to match the predictive power of traditional neural sequence models while providing interpretable alignments between abstract and concrete subsequences useful for our primary goal of analysis of implicit hierarchical script knowledge .
2 Data & Task Our approach situates script learning as a case of grounding .
For simplicity of exposition , let us assume there are three levels of abstraction to grounding : abstract!concrete!motor control .
Most prior work in grounding treats language monolithically1and ignores the issue of audience .
In practice , this means the task formulation or exposed API may implicitly bias the language to be more concrete .
By viewing the task as purely linguistic , we have no API or robot that constrains our language ; instead , we deﬁne our audience as children .
By eliciting child - directed instructions , we collect concrete language capturing otherwise implicit world knowledge that a child would not know .
Because annotators assume a smart and capable but uninformed listener , we posit this language corresponds closely to the most “ concrete ” form in which language naturally occurs .
2.1 Data Collection We construct a task on Amazon ’s Mechanical Turk , where workers are asked to explain a video action caption to a child.2Every instruction is paired with the original YouTube video and YouCook caption so the annotator could see how 1Notable exceptions include the hierarchical instructions of ( Regneri et al . , 2013 ) and ( Bisk et al . , 2016 ) .
2Pay was calculated based on $ 15 / hr and assuming workers took 1.5x as long to complete a task as the experimenters .
Avg Len Seqs Tokens V ocab YC KC Train 8,125 307,573 3,573 10.0 37.9 Valid 1,014 36,830 1,479 8.8 36.3 Test 1,020 37,156 1,489 8.8 36.4 Table 1 : KIDSCOOK corpus statistics the action was performed , rather than hallucinating additional details .
All captions received three simpliﬁcations .
The instructions ask users to focus on missing information and allow them up to ﬁve steps .
Finally , we explicitly asked annotators to simplify complex actions ( e.g. dice ) that can be deﬁned by a series of more basic actions ( e.g. cut ) .
OurKIDSCOOK corpus statistics are shown in Table 1 .
In total we collected over 10 K action sequences ( 400 K tokens ) .
The average caption is approximately 4x longer than a YouCook caption .
Most importantly 1,536 lemmas and 2,316 lexical types from KIDSCOOK ’s vocabulary do not appear in any of the original captions .
This indicates that there are over 1,500 new concepts , tools , and procedures that were assumed by YouCookII but are now explicit in KIDSCOOK .
2.2 Cloze Task To investigate what new knowledge is being introduced and whether a model has captured it , we construct a cloze - style slot-ﬁlling task ( Chambers , 2017 ; Hermann et al . , 2015 ) .
We drop key content words from the concrete realization of an abstract instruction and ask the model to predict them .
Several examples from the validation set are shown in Table 2 .
Correctly predicting the missing words requires knowledge of the manner of executing a task and the tools required .
To choose candidate words to drop , we only allow words that occur primarily in the concrete instructions .
Additionally , we do not drop stop words , numbers , or words occurring fewer than ﬁve times .
We do , however , drop units of measure ( cup , minute , etc . ) .
This ensures we create blanks whose answers are previously omitted concrete details .
Relatedly , under this ﬁlter the answer to a blank is very rarely an ingredient , as our goal is not to memorize recipes , but to infer the tool knowledge necessary to execute them .
In total , we whitelist1,000 words that can be dropped to create blanks .
We prefer longer blanks when available to give preference to compound nouns ( e.g. wire whisk ) .
Finally , we do not drop any words
4079ABSchop garlic into small pieces .
CONput garlic on cutting board .press
on back of knife with hand , cutting into small pieces .
ABSadd some parmesan cheese into the bowl and mix them well .
CONuse a grater tograte some parmesan cheese into the bowl .
use a wire whisk tostirthe cheese in .
ABSadd the tofu to the wok .
CONdrain the waterfrom the tofu using a strainer .
add the tofu into the pan . use a spoon tostirthe tofu in the mixture .
Table 2 : Example abstract / concrete pairs with blanks ( red ) where predictions and surprisal are computed .
from the concrete sentence if they occur in the abstract description .
This restriction eliminates any beneﬁts that might have been achieved via models with copy mechanisms .
Examples that do not meet our criteria are removed from the corpus .
3 Models We investigate the utility of sequence - to - sequence models with attention ( Bahdanau et al . , 2015 ) to generate concrete realizations of abstract task descriptions .
We hypothesize that models that learn explicit alignments are particularly amenable to interpretable analysis on the task .
Therefore , in addition to using the global attention model of ( Luong et al . , 2015 ) , we adapt the transducer model proposed by Yu et al . ( 2016 ) , which uses learned latent discrete variables to model phraseto - phrase alignments .
In contrast to many standard neural models , this approach enables us to incorporate prior knowledge about the alignment structure , and to extract interpretable alignments between task phrases .
Closely related architectures have been proposed for segmental sequence modeling ( Wang et al . , 2017 ) and phrase - based neural machine translation ( Huang et al . , 2018 ) .
We train the transducer models using Viterbi EM ( after doing marginal likelihood training for the initial iterations ) , as we found it gave higher predictive accuracy than marginal likelihood training only .
Following Yu et al .
( 2016 ) we experiment with both a ﬁxed alignment transition probability model and a transition model with a neural parameterization .
Cloze task prediction is performed greedily.3At each slot the Viterbi alignment of the preﬁx of the sequence up to that slot is computed .
See appendix 7 for model details.4 We also evaluate the performance of a language modelling baseline and a seq2seq model without attention ( Sutskever et al . , 2014 ) , to compare the 3During preliminary experiments beam search did not improve performance .
4All code and data is available at https://github . com / janmbuys / ScriptTransduction .effect of not modeling alignment at all .
We expect all the models to implicitly capture aspects of world knowledge .
However , the discrete latent variable models provide Viterbi alignments over the training data , from which we can compile a look - up table with the extracted knowledge .
In neural attention models , this knowledge is only weakly recoverable : extracting information requires hand tuning attention thresholds and there is no direct way to extract contiguous alignments for multi - word phrases .
4 Results 4.1 Evaluation Metrics During generation , we provide the model with the number of words in each blank to be predicted .
We consider two setups for evaluating examples with multiple blanks , both assuming that predictions are made left - to - right : Oracle , where the gold prediction of each blank is fed into the model to condition on for future predictions , and Greedy , where the model prediction is used for future predictions .
We compute the proportion of exact word matches over each blank and the precision of the top k= 5 predictions for both setups .
Additionally we compute the average surprisal of the gold prediction ( conditioning on oracle predictions ) .
The surprisal of a word ( Attneave , 1959 ; Hale , 2001 ) is its negative log probability under the model :  log(P(wijw1 : i 1 ) ) .
The higher the probability of the ground truth , the lower the model ’s “ surprise ” at seeing it in that context .
Finally , as a quantitative proxy for interpretability , we report the length of the transducer models ’ average Viterbi alignment span : our goal is a model which balances low average alignment lengths and high matching or ranking scores .
4.2 Cloze Task Results
We report results on the prediction task in Table 4 .
First we consider models trained only on our dataset : All the models that incorporate a notion of alignment do substantially better than those who
4080abstract!concrete concrete !
abstract parmesan sprinkle grated , grate , hold a grater , ... whisk eggs , mayonnaise , milk , combine , pour , stir , ...
macaroni stove on high heat , large pot , bowl , ... spatula colors , thickens , coated , simmer , grill , ... egg place the boiled , gently crack the , crack , ... tongs shrimp , bratwurst , turn , bun , marinate , ... sauce stir hot , pour gravy , lower setting , ﬁnd a spoon , ... cutting board onions , bell pepper , meat , bok choy , ... oil spray cooking , splashing , slowly pour , ... preheat oven , broil , medium , degrees , ...
Table 3 : Example Viterbi Alignments .
For concrete to abstract , we match any phrase containing the word(s ) .
Oracle Greedy Model Match Top-5 Match Top-5 Surp Language Model 21.59 52.32 21.72 43.33 3.970 Seq2seq 23.57 53.38 23.44 45.76 3.755 + Att 24.52 53.98 24.57 47.34 3.780 Transducer 24.72 55.09 24.91 47.80 4.780 + ParamTran 23.81
53.98 24.00 46.19 3.547 OpenAI GPT 23.19 42.43 15.55 32.86 4.781 + ﬁne - tuning 38.01 63.69 31.05 57.05 3.151 Table 4 : Results on the Cloze prediction task ( Match = Exact Match , Top-5 = Precision of Top 5 predictions , Surp = Surprisal ) .
Transducer results are reported for models with unparameterized and parameterized ( + ParamTran ) alignment transition models .
The best andsecond best results are emphasized .
do not .
We see that our transducer model with ﬁxed alignment transition probabilities performs best in terms of predictive accuracy ( exact match and top-5 precision ) , while the seqseq model with attention is the next best in most comparisons .
The model with parameterized transitions has the lowest surprisal though , as it is more conﬁdent about the alignment predictions it is making .
Using average alignment length to quantify whether the phrase alignments exhibit desirable structure , we see that the alignments found by the unparameterized transition model ( average length 6.18 ) are signiﬁcantly shorter than those of the parameterized model ( average length 16.61 ) .
Investigation shows that the paramaterized model mostly learns degenerate alignments , aligning most of the concrete sequence to either the start or end of the abstract sentence .
In contrast , qualitative analysis of the unparameterized transition model show that its alignments learn desirable correspondences ( see Figure 2 ) .
Therefore among our proposed models ( trained on in - domain data only ) the transducer with unparameterized transitions satisﬁes our desiderata of displaying both good predictive power for word generation , and learning interpretable alignments .
Given the recent success of massively precut the dough in half and shape each half into a ball .<S > place the dough on a cutting board .  
using a sharp tool such as a   knife   ,   cut   the   dough   in   half   .   shape   each   half   of   the   dough   into   a   ball   .
weigh the   cabbage   and   add   salt   .<S >   pour the   cabbage   into   the   big   bowl   .  
use   a   spoon   and   scoop   some   salt   into   the   bowlplace the bread over high ﬂame .<S > take the tongs and pick up the bread .  
set the bread on a grill .   put   on the   grill   over   the   high   ﬂame   .... < latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit > e0 < latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit > e6 < latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit> ... <latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit><latexit sha1_base64="Ul1zjHMk9xZA8oyRXJLJOxn4TQw=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0hE0GPRi8eK9gPaUDbbTbt0swm7E6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSg+u6 / WrNc705yCrxC1KDAo1 + 9as3SFgWc4VMUmO6vpdikFONgkk+rfQyw1PKxnTIu5YqGnMT5PNTp+TMKgMSJdqWQjJXf0 / kNDZmEoe2M6Y4MsveTPzP62YYXQe5UGmGXLHFoiiTBBMy+5sMhOYM5cQSyrSwtxI2opoytOlUbAj+8surpHXh+p7r31 / W6jdFHGU4gVM4Bx+uoA530IAmMBjCM7zCmyOdF+fd+Vi0lpxi5hj+wPn8AUvkjSI=</latexit > e0 < latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit><latexit sha1_base64="1NSVA7XC5wla7NGfXitfHcXtZN8=">AAAB6nicbVBNS8NAEJ3Ur1q / oh69LBbBU0lE0GPRi8eK9gPaUDbbSbt0swm7G6GE / gQvHhTx6i / y5r9x2+agrQ8GHu / NMDMvTAXXxvO+ndLa+sbmVnm7srO7t3 / gHh61dJIphk2WiER1QqpRcIlNw43ATqqQxqHAdji+nfntJ1SaJ / LRTFIMYjqUPOKMGis9YN / ru1Wv5s1BVolfkCoUaPTdr94gYVmM0jBBte76XmqCnCrDmcBppZdpTCkb0yF2LZU0Rh3k81On5MwqAxIlypY0ZK7+nshprPUkDm1nTM1IL3sz8T+vm5noOsi5TDODki0WRZkgJiGzv8mAK2RGTCyhTHF7K2EjqigzNp2KDcFffnmVtC5qvlfz7y+r9ZsijjKcwCmcgw9XUIc7aEATGAzhGV7hzRHOi / PufCxaS04xcwx/4Hz+AO0rjYw=</latexit > e6 < latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit><latexit sha1_base64="12MfjmJDqM21J4rd2GarPcwFAso=">AAAB6nicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ / QlePCji1V / kzX / jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0gP1av1xxq+4cZJV4OalAjka//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMTXvsZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3v1lpX6Tx1GEEziFc / DgCupwBw1oAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH / ZDjZI=</latexit > Figure 2 : Example Viterbi alignments trained language models ( Peters et al . , 2018 ) , we are interested if these approaches transfer to our cloze task .
We evaluate the OpenAI GPT transformer language model ( Radford et al . , 2018 ) with and without ﬁne - tuning .
Without ﬁne - tuning this model does slightly worse than our best domainspeciﬁc model .
With ﬁne - tuning , its accuracy is substantially higher , but it still suffers from the same fundamental limitations as our other models ( see Table 5 ) .
The transformer ( Vaswani et al . , 2017 ) attention is multi - headed and multi - layered which prohibits direct interpretability .
5 Qualitative Analysis We visualize alignments of our transduction model over two partial sequences in Fig .
2 .
This shows which hidden vector of the abstract sentence aligned to every region of the concrete sequence .
Speciﬁcally , we see how tools like the big bowl , spoon , and tongs are introduced to facilitate the actions .
There are also implications , e.g. that high indicates grill .
For further analysis we extract alignments over the training corpus , linking each decoded phrase with the word from the encoding it used during generation .
We then aggregate these tuples into a table which we can ﬁlter ( based on our whitelist ) and sort ( with PMI ) .
This process is imprecise as it discards the context in which the alignment occurs , but it nonetheless extracts many
4081Abs shape each dough ball into a circle and add tomato sauce .
Pred ﬂatten out your dough into a ﬂat circle using your hands .
take a knife to add tomato sauce to the center of your dough .
use the back side of the knife tocutthe sauce out .
make sure you keep the sauce about aninch from the edges .
Gold ﬂatten out your dough into a ﬂat circle using your hands .
take a spoon to add tomato sauce to the center of your dough .
use the back side of the spoon tospread the sauce out .
make sure you keep the sauce about aninch from the edges .
Abs place the kale cucumber bell peppers carrots and radishes on the wrapper .
Pred put the cuton a cutting .
put a cutting amount of kale on the cutting .
add a cutamount of cucumber ...
Gold put the wrap on a plate .
put a small amount of kale on the wrap .
add a small amount of cucumber ...
Abs wrap the pizza .
Pred ﬁnd a large piece to put the pizza om .
place the pizza in the center for it not to stick around .
grab the plastic wrap and start wrap ping theentirething and pizza .
wrap all around until completely covered on all corners .
put in freezer on a cold waterand freeze overnight Gold ﬁnd a hard surface to put the pizza om .
place the pizza in the center for it not to slide around .
grab the plastic wrap and start wrap ping thehard surface and pizza .
wrap all around until fully covered on all corners .
put in freezer on aﬂatsurface and freeze overnight Table 5 : Above is the output of OpenAI GPT when forced to greedily decode answers to blanks in validation .
of the phenomena we would hope to see ( Table 3 ) .
The left - hand side of the table shows words from the abstract YouCook annotations and corresponding phrases in the concrete annotation .
For the righthand side we searched for common concrete terms that may be preceded or followed by other terms , and present the abstract terms they were most often generated by .
Finally , Table 5 shows three randomly chosen examples ( from the validation set ) of greedy decodings for slot ﬁlling with GPT ﬁne - tuned on our dataset .
These examples demonstrate that , ﬁrst , there are cases where GPT is successful or produces a semantically valid answer ( e.g. fully vs completely ) .
Second , as is common with greedy decoding , the model can get stuck in a loop ( e.g. cut , cutting , cutting , ... ) .
Finally , note there are nonsensical cases where the model appears to have discarded the abstract context ( e.g. knife to add tomato sauce orfreezer on a cold water ) .
6 Related Work Many script learning systems are based on event co - occurrence and language modeling in large text corpora , and can infer implicit events without creating explicit situation - speciﬁc frame structures ( Chambers and Jurafsky , 2008 ; Rudinger et al . , 2015 ; Pichotta and Mooney , 2016 ) .
Other systems induce situation - speciﬁc frames from text ( Cheung et al . , 2013 ;
Balasubramanian et al . , 2013 ) .
However , these methods do not explicitly target the commonsense correspondence between differing levels of detail of complex events .
Most relevant to this paper is the pioneering work of Regneri et al .
( 2013 ) as extended by Senina
et al .
( 2014 ) and Rohrbach et al .
( 2014).These papers present the TACOS corpus , consisting of natural language descriptions of activities in videos paired with low - level activity labels .
Senina et al .
( 2014 ) collect an additional level of multi - sentence annotations on the corpus , which allowing for video caption generation at multiple levels of detail .
Rohrbach et al .
( 2014 ) describe a similar corpus of natural descriptions of composite actions , useful for activity recognition in video .
These corpora differ in a number of important ways from KIDSCOOK ; in particular , the language has somewhat limited complexity and “ naturalness ” when describing complex scenarios , a phenomenon also observed in the robotics literature ( Scalise et al . , 2018 ) .
Our data collection process avoids more formulaic language by eliciting “ child - directed ” descriptions .
7 Conclusion We introduce a new hierarchical script learning dataset and cloze task in which models must learn commonsense world knowledge about tools , procedures and even basic physics to perform well .
Our aim is to begin a conversation about abstraction in language , how it is modeled , and what is implicitly hidden .
Our abstract and concrete instructions are grounded in the same videos yet differ dramatically due to their assumed audiences .
We show that a neural transduction model produces interpretable alignments for analyzing these otherwise latent correlations and phenomena .
Acknowledgements This work was supported in part by NSF ( IIS1524371 & 1703166 ) and through DARPA ’s CwC program through ARO ( W911NF-15 - 1 - 0543 ) .
4082References Fred Attneave .
1959 .
Applications of information theory to psychology : A summary of basic concepts , methods , and results .
Henry Holt .
Dzmitry Bahdanau , KyungHyun Cho , and Yoshua Bengio .
2015 .
Neural machine translation by jointly learning to align and translate .
In ICLR .
Niranjan Balasubramanian , Stephen Soderland , Mausam , and Oren Etzioni .
2013 .
Generating coherent event schemas at scale .
In EMNLP .
Yonatan Bisk , Daniel Marcu , and William Wong . 2016 .
Towards a dataset for human computer communication via grounded language acquisition .
In Proceedings of the AAAI 2016 Workshop on Symbiotic Cognitive Systems , pages 729–732 , Phoenix , AZ .
Peter F Brown , Vincent J Della Pietra , Stephen A Della Pietra , and Robert L Mercer .
1993 .
The mathematics of statistical machine translation : Parameter estimation .
CL , 19(2):263–311 .
Nathanael Chambers .
2013 .
Event schema induction with a probabilistic entity - driven model .
In EMNLP .
Nathanael Chambers . 2017 .
Behind the scenes of an evolving event cloze test .
In LSDSem .
Nathanael Chambers and Dan Jurafsky .
2008 .
Unsupervised learning of narrative event chains .
In ACL .
Jackie Chi Kit Cheung , Hoifung Poon , and Lucy Vanderwende .
2013 .
Probabilistic frame induction .
In NAACL .
Gerald F. DeJong .
1981 .
Generalizations based on explanations .
In IJCAI .
Arthur P Dempster , Nan M Laird , and Donald B Rubin .
1977 .
Maximum likelihood from incomplete data via the em algorithm .
Journal of the royal statistical society . , pages 1–38 .
Jason Eisner .
2016 .
Inside - outside and forwardbackward algorithms are just backprop ( tutorial paper ) .
In Workshop on Structured Prediction for NLP .
H. Paul Grice . 1975 .
Logic and conversation .
Syntax and Semantics 3 : Speech Acts , pages 41–58 .
John Hale .
2001 .
A probabilistic earley parser as a psycholinguistic model .
In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies , pages 1–8 .
Association for Computational Linguistics .
Karl Moritz Hermann , Tomas Kocisky , Edward Grefenstette , Lasse Espeholt , Will Kay , Mustafa Suleyman , and Phil Blunsom .
2015 .
Teaching machines to read and comprehend .
In NIPS .
Sepp Hochreiter and J ¨urgen Schmidhuber .
1997 .
Long short - term memory .
Neural Computation , 9(8):1735–1780.Po - Sen Huang , Chong Wang , Sitao Huang , Dengyong Zhou , and Li Deng .
2018 .
Towards neural phrasebased machine translation .
In ICLR .
Thang Luong , Hieu Pham , and Christopher D Manning .
2015 .
Effective approaches to attention - based neural machine translation .
In EMNLP .
Jeffrey Pennington , Richard Socher , and Christopher Manning .
2014 .
GloVe : Global vectors for word representation .
In EMNLP .
Matthew Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer .
2018 .
Deep contextualized word representations .
In NAACL .
Karl Pichotta and Raymond J Mooney . 2016 .
Learning statistical scripts with LSTM recurrent neural networks .
In AAAI .
Alex Radford , Karthik Narasimhan , Tim Salimans , and Ilya Sutskever . 2018 .
Improving language understanding by generative pre - training .
Technical report , OpenAI .
Mechaela Regneri , Marcus Rohrbach , Dominikus Wetzel , Stefan Thater , Bernt Schiele , and Manfred Pinkal .
2013 .
Grounding action descriptions in videos .
TACL , 1 . Anna Rohrbach , Marcus Rohrbach , Wei Qiu , Annemarie Friedrich , Manfred Pinkal , and Bernt Schiele .
2014 .
Coherent multi - sentence video description with variable level of detail .
In GCPR .
Rachel Rudinger , Vera Demberg , Ashutosh Modi , Benjamin Van Durme , and Manfred Pinkal . 2015 .
Learning to predict script events from domainspeciﬁc text .
In * Sem .
Rosario Scalise , Yonatan Bisk , Maxwell Forbes , Daqing Yi , Yejin Choi , and Siddhartha Srinivasa .
2018 .
Balancing shared autonomy with human - robot communication .
arXiv preprint arXiv:1805.07719 .
Roger C. Schank and Robert P. Abelson .
1977 .
Scripts , Plans , Goals and Understanding : An Inquiry into Human Knowledge Structures .
LEA .
Anna Senina , Marcus Rohrbach , Wei Qiu , Annemarie Friedrich , Sikandar Amin , Mykhaylo Andriluka , Manfred Pinkal , and Bernt Schiele .
2014 .
Coherent multi - sentence video description with variable level of detail .
arXiv preprint arXiv:1403.6173 .
Valentin I Spitkovsky , Hiyan Alshawi , and Daniel Jurafsky .
2011 .
Lateen EM : Unsupervised training with multiple objectives , applied to dependency grammar induction .
In EMNLP .
Valentin I Spitkovsky , Hiyan Alshawi , Daniel Jurafsky , and Christopher D Manning .
2010 .
Viterbi training improves unsupervised dependency parsing .
In CoNLL .
4083Ilya Sutskever , Oriol Vinyals , and Quoc V .
Le . 2014 .
Sequence to sequence learning with neural networks .
In NIPS .
Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 .
Attention is all you need .
In Advances in Neural Information Processing Systems , pages 5998–6008 .
Chong Wang , Yining Wang , Po - Sen Huang , Abdelrahman Mohamed , Dengyong Zhou , and Li Deng . 2017 .
Sequence modeling via segmentations .
In ICML .
Noah Weber , Leena Shekhar , Niranjan Balasubramanian , and Nathanael Chambers .
2018 .
Hierarchical quantized representations for script generation .
In EMNLP .
Lei Yu , Phil Blunsom , Chris Dyer , Edward Grefenstette , and Tomas Kocisky . 2017 .
The neural noisy channel .
In ICLR .
Lei Yu , Jan Buys , and Phil Blunsom .
2016 .
Online segment to segment neural transduction .
In EMNLP .
Rowan Zellers , Yonatan Bisk , Roy Schwartz , and Yejin Choi .
2018 .
Swag : A large - scale adversarial dataset for grounded commonsense inference .
In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) .
Luowei Zhou , Chenliang Xu , and Jason J Corso . 2017 .
Towards automatic learning of procedures from web instructional videos .
arXiv preprint arXiv:1703.09788 .
4084A Transducer Model We brieﬂy describe the model of Yu , Buys , and Blunsom ( 2016 ) and our minor modiﬁcations thereto .
A.1 Alignment with Latent Variables
We model the conditional probability of a concrete sequenceygiven abstract sequence xthrough
a latent alignment variable abetweenxandy , which is a sequence of variables aj , withaj = isignifying thatyjis aligned to xi .
The marginal probability ofygivenxis p(yjx )
= X ap(y;ajx ): ( 1 ) In the following , we use mto denote the length ofxandnto denote the length of y.
The model formulation restricts alignments to be monotonic , i.e.aj+1ajfor allj .
The model factorizes over timesteps into alignment and word prediction probabilities , such that the word prediction at each timestep is informed by its alignment : p(y;ajx )
= Y jp(ajjaj 1;x1 : aj 1;y1 : j 1 ) p(yjjaj;x1 : aj;y1 : j 1)(2 )
The abstract and concrete sequences are both encoded with LSTM Recurrent Neural Networks ( Hochreiter and Schmidhuber , 1997 ) .
In contrast to standard attention - based models , the aligned encoder representation is not fed into the decoder RNN state , but only used to make next word predictions .
Due to the small size of the training data , words in both sequences are embedded using ﬁxed GloVe embeddings ( Pennington et al . , 2014 ) .
The word emission probability is then deﬁned as p(yjjaj;x1 : aj;y1 : j 1 ) = softmax(MLP ( eaj;dj ) ) ( 3 ) withethe encoder hidden states and dthe decoder hidden states .
The alignment probability factorizes into shift andemit probabilities , where a shift action increments the alignment to the next word in the input sequence , and an emit action generates the next output word .
We refer to these as transition probabilities .
This formulation enables us to restrict the hard alignment to be monotonic .
We consider two parameterizations of this distribution .
In the ﬁrst , the probabilities are parameterized by the neural network , using the encoderand decoder hidden state in a similar manner to how the word emission probability was computed .
The alignment probability at a given timestep is therefore parameterized as p(ajjaj 1;x1 : aj 1;y1 : j 1 )
= p(emitjaj;x1 : aj;y1 : j 1 ) aj 1Y i = aj 1p(shiftji;x1 : i;y1 : j 1);(4 )
where p(shiftji;x1 : i;y1 : j 1 ) = (MLP ( ei;dj ) ) ; ( 5 ) p(emitji;x1 : i;y1 : j 1 ) = 1 p(shiftji;x1 : i;y1 : j 1):(6 ) We also consider using the simpler , ﬁxed alignment parameterization in Yu , Buys , and Blunsom ( 2016 ) , where the transition probability is conditioned only on sequence length , not on xory , and can therefore be estimated using the ratio between input and output sentence lengths .
The alignment probabilities are not updated during training , and consequently the posterior distribution over the alignments is biased towards this prior , favoring alignments close to the diagonal .
The parameterized alignment model contains as special cases two degenerate solutions : ( 1 ) an unconditional language model and ( 2 ) a seq2seq model .
These occur if the model performs all emits before shifting or all shifts before emitting , respectively .
To prevent the creation of a language model we force the last output word to be aligned to the last word in the abstract sequence , similar to Yu et al . ( 2017 ) .
However , the parameterized transition model could still in practice revert to a pure sequence - to - sequence model .
A.2 Marginalization Next we brieﬂy describe the dynamic program used to marginalize over alignments during training and to ﬁnd the most likely alignments of a given alignment during inference ; we refer the reader to Yu , Buys , and Blunsom ( 2016 ) for a more thorough treatment .
The forward variable  i(j)representing p(y1 : j;aj = ijx1 : i)is recursively as  i(j )
= p(yjji;x1 : i;y1 : j 1 ) iX k=1  k(j 1)p(aj = ijk;x 1 : k;y1 : j 1):(7 ) The marginal likelihood objective is to train the model to optimize  m(n )
= p(y1 : n;an=
4085mjx1 : m ) .
The gradients are computed with automatic differentiation ; as this is is equivalent to using the forward - backward algorithm to estimate the gradients ( Eisner , 2016 ) , only the forward algorithm has to be implemented .
To make the implementation GPU - efﬁcient , we vectorize the computation of  .
The computation iterates through decoding steps , each of which can be generated from an alignment to any of the encoder tokens .
We can efﬁciently construct a transition matrix T , corresponding to all possible encoder states performing all possible shifts , and emission matrix Ejwhich is a gather by word indexj .
To compute the forward probabilities at each timestep , the current forward probabilities are ﬁrst multiplied by all possible transitions .
A sum in logspace collapses all paths , and the emission ( word generation ) probabilities are multiplied to obtain the new forward probabilities .
When ﬁxed transition probabilities are used , Tis precomputed .
A.3 Viterbi EM Training Latent variable models can be trained either through directly optimizing the likelihood objective through gradient descent ( as described above ) , or with the Expectation Maximization ( EM ) algorithm ( Dempster et al . , 1977 ) , which alternates between calculating expectations over the values of the latent variables given the current parameters , and maximizing the expected complete data log likelihood given those expectations .
We consider training our alignment model with Viterbi EM ( Brown et al . , 1993 ) , also known as “ hard ” EM , where at each iteration the most likely assignment of the hidden variables ( alignments ) are found and the parameters are updated to optimize the log likelihood given those alignments .
Viterbi EM has been shown to give superior performance to standard EM on unsupervised parsing ( Spitkovsky et al . , 2010 ) , due to better convergence properties in practice by making the distribution more peaked .
We perform batched Viterbi EM training by computing the Viterbi alignments for a batch , and then performing a gradient step based on treating those alignments as observations .
We follow a two - stage training procedure : we ﬁrst directly optimize the marginal likelihood with batched SGD to ﬁnd a reasonable initial distribu - tion over alignments , before switching to Viterbi EM training .
Such a strategy has been shown to reduce the chance that the model will get stuck in local optima ( Spitkovsky et
al . , 2011 ) .
A.4 Inference
We apply the trained models to multiple inference problems to evaluate how well they are capturing script knowledge .
The ﬁrst is ﬁnding the most likely alignment given a pair of abstract and concrete sequences .
We use the standard Viterbi algorithm , in which we replace the sum in equation ( 7 ) with max , and keep track of the index corresponding to each value of  during the forward computation .
The most likely alignment can then be traced back from an = m. The second inference problem is slot-ﬁlling , for application to the cloze task .
Given an abstract sentence and a partially-ﬁlled concrete sequence , we want to use the model to predict words to ﬁll the given blanks .
To make the prediction , we sample 5 candidate sequences by predicting words for each slot , in left - to - right order , and then choosing the sequence with the highest overall probability .
Words are predicted by sampling with temperature 0:1 , in order to peak the distribution while still allowing some diversity in the samples .
The motivation for selecting the ﬁnal output from multiple samples is that the original samples are biased , as they are only conditioned on the left context .
At the start of the prediction for each slot , the Viterbi alignment of the preﬁx of the sequence up to the start of that slot is re - predicted , independent of previous alignment predictions .
Consequently alignment decisions can be revised , and the slot alignments are no longer constrained to be monotonic , which makes the slot prediction model more ﬂexible .
For the parameterized transition model , the slot alignment is predicted greedily by incrementing the last predicted alignment while the shift probability is greater than 0:5 .
The ﬁxed transition model assumes that the alignment of the word preceding the slot is shared across the slot .
