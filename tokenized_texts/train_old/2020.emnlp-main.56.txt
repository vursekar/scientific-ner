Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 763â€“780 , November 16â€“20 , 2020 .
c  2020 Association for Computational Linguistics763De - Biased Court â€™s View Generation with Causality Yiquan Wu1 , Kun Kuang1 , Yating Zhang2 , Xiaozhong Liu3
Changlong Sun2 , Jun Xiao1 , Yueting Zhuang1 , Luo Si2 , Fei Wu1 1Zhejiang University , Hangzhou , China 2Alibaba Group , Hangzhou , China 3Indiana University Bloomington , USA fwuyiquan , kunkuang , yzhuang g@zju.edu.cn yatingz89@gmail.com , changlong.scl@taobao.com , liu237@indiana.edu fjunx , wufei g@cs.zju.edu.cn , luo.si@alibaba-inc.com
Abstract Court â€™s view generation is a novel but essential task for legal AI , aiming at improving the interpretability of judgment prediction results and enabling automatic legal document generation .
While prior text - to - text natural language generation ( NLG ) approaches can be used to address this problem , neglecting the confounding bias from the data generation mechanism can limit the model performance , and the bias may pollute the learning outcomes .
In this paper , we propose a novel Attentional and Counterfactual based Natural Language Generation ( ACNLG ) method , consisting of an attentional encoder and a pair of innovative counterfactual decoders .
The attentional encoder leverages the plaintiff â€™s claim and fact description as input to learn a claim - aware encoder from which the claim - related information in fact description can be emphasized .
The counterfactual decoders are employed to eliminate the confounding bias in data and generate judgmentdiscriminative court â€™s views ( both supportive and non - supportive views ) by incorporating with a synergistic judgment predictive model .
Comprehensive experiments show the effectiveness of our method under both quantitative and qualitative evaluation metrics .
1 Introduction Owing to the prosperity of machine learning , especially the natural language processing ( NLP ) techniques , many legal assistant systems have been proposed to improve the effectiveness and efï¬ciency of a judge from different aspects , such as relevant case retrieval ( Chen et al . , 2013 ) , applicable law articles recommendation ( Chen et al . , 2019 ) , controversy focus mining ( Duan et al . , 2019 ) , and judgment prediction ( Lin et al . , 2012 ; Zhong et al . , 2018 ; Hu et al . , 2018 ; Jiang et al . , 2018 ; Chalkidis et al . , Corresponding Authors .
ğ‘«(ğ‘±)ğ‘°ğ‘½ğ’–Figure 1 : Confounding bias from the data generation mechanism .
urefers to the unobserved mechanism ( i.e. , plaintiffs sue when they have a high probability to be supported ) that causes the judgment in dataset D(J ) to be imbalanced .
D(J)!Idenotes that the imbalanced dataD(J)has a causal effect on the representation of input I(i.e . , plaintiff â€™s claim and fact description ) , andD(J)!Vdenotes that D(J)has a causal effect on the representation of court â€™s view V. Such imbalance inD(J)leads to the confounding bias that the representations of IandVtend to be supportive , and blind the conventional training on P(VjI ) . 2019 ) .
Court â€™s view can be regarded as the interpretation for the sentence of a case .
Being an important portion of verdict , court â€™s view is difï¬cult to generate due to its logic reasoning in the content .
Therefore court â€™s view generation is regarded as one of the most critical functions in a legal assistant system .
Court â€™s view consists of two main parts , including the judgment and the rationales , where the judgment is a response to the plaintiff â€™s claims in civil cases or charges in criminal cases , and the rationales are summarized from the fact description to derive and explain the judgment .
Recently , Ye et al .
( 2018 ) investigated the problem of court â€™s view generation for the criminal cases , but it focused on the generation of rationales in the court â€™s view based on the given criminal charge and fact description of a case .
Such an experimental scenario is not applicable to the practical situation since the rationales should be concluded before reaching the ï¬nal judgment .
Moreover , dif-
764 PLAINTIFFâ€™SCLAIMTheplaintiffAclaimedthatthedefendantBshouldreturntheloanof$29,500PrincipleClaimandthecorrespondinginterestInterestClaim .
FACTDESCRIPTIONAfterthehearing , thecourtheldthefactsasfollows : ThedefendantBborrowed$29,500fromtheplaintiffA , andagreedtoreturnafteronemonth .
Aftertheloanexpired , thedefendantfailedtoreturnFact . COURTâ€™SVIEWThecourtconcludedthattheloanrelationshipbetweentheplaintiffAandthedefendantBisvalid .
ThedefendantfailedtoreturnthemoneyontimeRa tiona le .
Therefore , theplaintiffâ€™sclaimonprinciplewassupportedAcceptanceaccordingtolaw .
Thecourtdidnotsupporttheplaintiffâ€™sclaimoninterestRejectionbecausetheevidencewasinsufficientRationale .
Figure 2 : An example of plaintiff â€™s claim , fact description , and court â€™s view from a legal document in a civil case .
The judgment is non - support since there exists a rejection on one of the plaintiff â€™s claims in the court â€™s view .
ferent from the criminal cases , in civil cases , the judgment depends not only on the facts recognized but also on the claims that the plaintiff declared .
In this paper , we focus on the problem of automatically generating the court â€™s view in civil cases by injecting the plaintiff â€™s claim and fact description , as shown in Fig .
2 . In such a context , the problem of the court â€™s view generation can be formulated as a text - to - text natural language generation ( NLG ) problem , where the input is the plaintiff â€™s claim and the fact description , and the output is the corresponding court â€™s view that contains the judgment and the rationales1 .
Although classical text generative models ( e.g. , sequence - tosequence model Sutskever et al . , 2014 , attentionbased model , and pointer - generator networks See et al . , 2017 ) have been applied to many text generation tasks , yet , in the task of the court â€™s view generation , such techniques can not be simply applied for the following reasons : ( 1 ) There exists â€œ no claim , no trial â€ principle in civil legal systems : The judgment in the real court â€™s view is the response to the claims declared by the plaintiff , where its rationales summarize the corresponding facts .
In other words , there exists a correspondence relationship between the input ( claims and facts ) and the generated text ( court â€™s view ) .
For example , the plaintiff â€™s claims shown in Fig .
2 mentioned the principal and the interest , respectively .
Hence , the court â€™s view of this case would and might only focus on the facts about the principal and the interest .
( 2 ) The imbalance of judgment in civil cases : The distribution of judgment results of civil cases is very imbalanced .
For example , over 76 % of cases were supported in private lending , which is the most frequent category in civil cases .
Such an imbalance of judgment would blind the training 1Since the claims are various , for simpliï¬cation , the judgment of a civil case is deï¬ned as supported if all its claims are accepted , otherwise , deï¬ned as non-supported.of the model by focusing on the supported cases while ignoring the non - supported cases , leading to incorrect judgment generation of court â€™s view .
From the perspective of causality ( Pearl , 2009 ; Kuang et al . , 2020 ) , the imbalance of judgment reveals the confounding bias induced by the data generation mechanism that plaintiffs sue when they have a high probability to be supported .
Such imbalanced data would cause the learned representation of both inputs ( claims and recognized facts ) and output ( court â€™s view ) to be supported , leading to confounding bias between inputs and output , and blinding the training process of conventional NLG models as we demonstrated in Fig .
1 . To address these challenges , we propose an Attentional and Counterfactual based Natural Language Generation ( AC - NLG ) method by jointly optimizing a claim - aware encoder , a pair of counterfactual decoders to generate judgmentdiscriminative court â€™s views ( both supportive and non - supportive views ) and a synergistic judgment predictive model .
Speciï¬cally , the claim - aware encoder is designed to represent the fact description which emphasizes on the declared claims .
The counterfactual decoder is inspired by the backdoor adjustment in causal inference ( Pearl et al . , 2016 ; Kuang et al . , 2020 ) to address the confounding bias and the imbalance problem in judgment .
To determine the judgment result of each case , a judgment predictive model is jointly learned with the two decoders and decides which output to be selected as the ï¬nal generated court â€™s view .
We validate the effectiveness of our AC - NLG method with extensive experiments on real legal documents .
Comprehensive experiments show the effectiveness of our method under both quantitative and qualitative evaluation metrics .
Since legal AI is a sensitive ï¬eld , we make ethical discussion in the penultimate section(Sec . 6 ) .
The main contributions of this paper can be sum-
765marized as follows : We investigate the problem of de - biased court â€™s view generation in civil cases from a causal perspective , considering the issue of confounding bias from judgment imbalance .
We propose a novel AC - NLG model to jointly optimize a claim - aware encoder and a pair of counterfactual decoders for generating a judgment - discriminative court â€™s view by incorporating with a judgment predictive model .
We construct a dataset based on raw civil legal documents , where each case is objectively split into three parts : plaintiff â€™s claim , fact description , and court â€™s view with human annotation on the judgment .
To motivate other scholars to investigate this novel but important problem , we make the experiment dataset publicly available2 .
We validate the superior performance of the proposed method with extensive experiments .
Our method can be applied to other natural language generation tasks with confounding bias or data imbalance .
2 Related Work 2.1 Legal Assistant
In recent years , many researchers from both law and computer science ï¬elds have been exploring the potential and methods to perform judicial decisions and auxiliary tasks , aiming at helping lawyers and lower court judges .
In recent work , judicial intelligence is also applied to various tasks of natural language processing .
Since most of the legal documents appear in textual form , many NLP technologies have been brought into the legal ï¬eld to improve the efï¬ciency of legal work .
Charge prediction is a common task of judgment prediction , considered as a text classiï¬cation problem ( Lin et al . , 2012 ; Zhong et
al . , 2018 ; Hu et al . , 2018 ; Jiang et al . , 2018 ; Chalkidis et al . , 2019 ) .
Besides , there are also works on legal questions classiï¬cation ( Xiao et al . , 2017 ) , law articles recommendation ( Chen et al . , 2019 ) , controversy focus mining ( Duan et al . , 2019 ) and relevant case retrieval ( Chen et al . , 2013 ) .
Ye et
al .
( 2018 ) explored the court â€™s view generation in criminal cases , where the input is only fact description , and the court â€™s view generation is conditioned on the known judgment results , which is not applicable in real cases .
2https://github.com/wuyiquan/AC-NLG2.2 Natural Language Generation Our task aims at generating the court â€™s view based on the plaintiff â€™s claim and the fact description , which can be regarded as a NLG task .
NLG has been widely studied and applied to many tasks , such as machine translation ( Wu et al . , 2016 ) , question answering ( McCann et al . , 2018 ; Bagchi and Wynter , 2013 ) and text summarization ( Rush et al . , 2015 ) .
The recent success of sequence - to - sequence models ( Sutskever et al . , 2014 ) , in which recurrent neural networks ( RNNs ) reading and generating text simultaneously , has made the generation task feasible .
Bahdanau et
al .
( 2014 ) ï¬rstly applied the attention mechanism into the NLG task .
See et al .
( 2017 ) proposed a Pointer - Generator Networks ( PGN ) , which can effectively solve the OutOf - V ocabulary ( OOV ) problem .
Although the previous work on NLG can produce ï¬‚uent sentences , they are struggling to be directly applied to our task since a good court â€™s view considers not only the text ï¬‚uency but also the logical correctness .
2.3 Causal Inference Causal Inference ( Pearl , 2009 ; Kuang et al . , 2020 ) is a powerful statistical modeling tool for explanatory analysis by removing confounding bias in data .
That bias might bring a spurious correlation or confounding effect among variables .
Recently , many methods have been proposed to remove confounding bias in the literature of causal inference , including do - operation based on structure causal model ( Pearl , 2009 ) and counterfactual outcome prediction based on potential outcome framework ( Imbens and Rubin , 2015 ) .
With dooperation , the backdoor adjustment ( Pearl et al . , 2016 ) have been proposed for data de - bias .
In this paper , we sketch the causal structure model of our problem , as shown in Fig .
1 , and adopt backdoor for confounding bias reduction .
3 Problem Formulation In this work , we focus on the problem of the court â€™s view generation in civil cases , where the input is the plaintiff â€™s claim and the fact description , and the output is the corresponding court â€™s view .
We formulate our problem with the deï¬nition of the plaintiff â€™s claim , the fact description , and the court â€™s view , as shown in Fig .
2 . Plaintiff â€™s claim ( C ) is a descriptive sentence that depicts the claims from the plaintiff .
In a civil case , it often appears multiple claims from the
766 Claim - aware Encoderğ‘—Attention LayerAttention LayerCounterfactual Decoderğ¯ğ§(j=0)ğ¯ğ¬(j=1)JudgmentPredictor = addc = claimsf = factsğ¡ğ±=hidden states of xğ¯ğ¬ 	 = supported viewğ¯ğ§=non - supported viewğ¬ğ¯ğ±=decode states of ğ¯ğ± 	 j = judgmentFC LayerPointer GeneratorPointer Generatorğ‘¤#ğ’—ğ’ğ‘¤%ğ’—ğ’ğ‘¤&ğ’—ğ’ğ‘¤#ğ’—ğ’”ğ‘¤%ğ’—ğ’”ğ‘¤&ğ’—ğ’”</s>ğ‘¤%ğ’—ğ’ Sigmoid</s>ğ‘¤&ğ’—ğ’” â€¦ â€¦ ğ¬ğ¯ğ§ğ¬ğ¯ğ¬s%ğ¯ğ¬s#ğ¯ğ§ ğ‘¤#(ğ‘¤%(ğ‘¤&(ğ‘¤)(ğ‘¤*(Attention Layerğ‘¤#+ğ‘¤%+ğ‘¤&+ğ‘¤,+ ğŸğœğ¡ğŸğ¡ğœâ„% ( â€¦ â€¦ Figure 3 : The architecture of AC - NLG , which consists of a claim - aware encoder , a pair of counterfactual decoders , and a judgment predictor .
plaintiff .
For example , the plaintiff â€™s claim demonstrated in Fig .
2 contains the principal claim and the interest claim .
Here , we denote the plaintiff â€™s claim in a case as a sentence form c = fwc tgm t=1 , wherewc trepresents one word , and mis the number of words in plaintiff â€™s claim .
Fact description ( F ) is also a descriptive sentence , which describes the identiï¬ed facts ( relevant events that have happened ) in a case , as Fig .
2 shows .
Here , we denote the fact description in a case as f = fwf tgn t=1 , wherenis the length .
Court â€™s view ( V ) contains two main components , judgment and rationales , where the judgment is to respond the plaintiff â€™s claims , and the rationales are the claim - related summarization on the fact description to determine and interpret the judgment .
Here , we denote the court â€™s view as v = fwv tgl t=1 , wherelis the length .
Moreover , we use a variable jto denote the judgment in the court â€™s view .
For simplicity , we set j= 1to denote supported judgment ( all the claims are judged to be accepted ) , and j= 0to denote non - supported judgment .
Then , the problem of court â€™s view generation can be denoted as follow : Problem 1 ( Court â€™s View Generation ) .Given
the plaintiff â€™s claim c =
fwc tgm t=1and the fact
description f = fwf tgn t=1 , our task is to generate the court â€™s view v = fwv tgl t=1 .
4 Method In this section , we ï¬rst introduce the effect of mechanism confounding bias on the court â€™s view generation and propose a backdoor - inspired method to eliminate that bias .
Then , we describe our Attentional and Counterfactual based Natural LanguageGeneration ( AC - NLG ) model in detail .
Fig .
3 shows the overall framework .
4.1 Backdoor Adjustment As shown in Fig .
1 , the confounding bias from the data generation mechanism would blind the conventional training on P(VjI ) , and current sequenceto - sequence models struggle to solve this problem .
Here , we see through why these models fail mathematically .
For a certain case , given the input I= ( c;f ) , using Bayes rule , we would train the model to generate the court â€™s view Vas follow : P(VjI )
= X jP(VjI;j)P(jjI ) ( 1 ) If the supported cases dominate our training data , e.g. ,P(j= 1jI)1 .
Thus , P(VjI)degrades toP(VjI;j= 1 ) , which would ignore the representation of non - supported cases , leading to the learned representations of inputs Iand outputV tend to be supported .
Thus , the model tends to build a strong connection between inputs and the supported court â€™s view , even for the cases that are non - supported .
In this way , the representation of inputIis contaminated by the confounding bias fromI D(J)!V. Backdoor adjustment is a main de - confounding technique in causal inference ( Pearl et al . , 2016 ; Pearl , 2009 ) .
De - confounding seeks the exact causal effect of one variable on another , which appeals for our court â€™s view generation task since the court â€™s view should be faithful only to the content of the plaintiff â€™s claims and fact descriptions .
The backdoor adjustment makes a do - operation onI , which promotes the posterior probability from passive observation to active intervention .
767The backdoor adjustment addresses the confounding bias by computing the interventional posterior P(Vjdo(I))and controlling the confounder as : P(Vjdo(I ) )
= X jP(VjI;j)P(j)(2 ) In our problem , the variable jis a binary variable ( support or non - support ) , hence , P(Vjdo(I ) )
= P(VjI;j= 0)P(j= 0 )
+ P(VjI;j= 1)P(j= 1)(3 )
The main difference between traditional posterior in Eq . 1 and interventional posterior in Eq . 2 is that P(jjI)is changed to P(j ) .
Since the backdooor adjustment help to cut the dependence between D(J)andI , we can eliminate the confounding bias from data generation mechanism and learn a interventional model for de - biased court â€™s view generation .
4.2 Backdoor In Implementation As shown in Fig .
3 , to optimize Eq .
3 , we use a pair of counterfactual decoders to learn the likelihood P(VjI;j)for eachj .
At inference , we propose to use a predictor to approximate P(j ) .
Note that our implementation on backdoor - adjustment can be easily applied for multi - valued confounding with multiple counterfactual decoders .
4.3 Model Architecture Our model is conducted in a multi - task learning manner which consists of a shared encoder , a predictor , and a pair of counterfactual decoders .
The predictor and the decoders take the output of the encoder as input .
Our model looks like SHAPED(Zhang et al . , 2018 ) ( several decoders with a classiï¬er ) , but the motivations and mechanisms behind the model are different .
Claim - aware Encoder Intuitively , the plaintiff â€™s claimcand the fact description fare sequences of words .
Therefore , the encoder ï¬rstly transforms the words to embeddings .
Then the embedding sequences are fed to the Bi - LSTM , producing two sequences of hidden states hc , hfcorresponding to the plaintiff â€™s claim and the fact description respectively .
After that , we use a claim - aware attention mechanism to fuse hcandhf .
For each hidden state hf iinhf , ei kis its attention weight on hc k , and the attention distribution qiis calculated as follow : ei k = vTtanh(Wchc k+Wfhf i+battn ) ( 4)qi = softmax ( ei ) ( 5 ) wherev , Wc , Wf , battnare learnable parameters .
The attention distribution can be regarded as the importance of each word in the plaintiff â€™s claim for a word in fact description .
Next , the new representation of fact description is produced as follows : hf i = hf i+X kqi khc k ( 6 ) After feeding to another Bi - LSTM layer , we get the claim - aware representation of fact h. Judgment Predictor Given the claim - aware representation of fact h , the judgment predictor produces the probability of support Psupthrough a fully connected layer and a sigmoid operation .
The prediction result jis obtained as follow : j= ( 1Psup>0:5 0Psup<= 0:5(7 ) where 1 means support , and 0 means non - support .
Counterfactual Decoder To eliminate the effect of data bias , here we use a pair of counterfactual decoders , which contains two decoders , one is for supported cases , and the other is for non - supported cases .
The two decoders have the same structure but aim to generate the court â€™s view with different judgments .
We name them as counterfactual decoders because every time there is only one of the two generated court â€™s views correct .
Still , we apply the attention - mechanism .
At each step t , given the encoder â€™s output h , and the decode state st , the attention distribution atis calculated the same way asqiin Eq . 5 , but with different parameters .
The context vector h tis then a weighted sum of h : h t = X iat ihi ( 8) The context vector h t , which can be regarded as a representation of the input for this step , is concatenated with the decode state stand fed to linear layers to produce the vocabulary distribution pvocab : pvocab = softmax ( V0(V[st;h t ] )
+ b ) + b0)(9 )
whereV , V0,b , b0are all learnable parameters .
Then we add a generation probability ( See et al . , 2017 ) to solve the OOV problem .
Given the context
768h t , the decode state stand the decoder â€™s input ( the word embedding of the previous word ) xt , the generation probability pgencan be calculated : Pgen=(wT
hh t+wT
sst+wT xxt+bptr)(10 ) wherewh,ws , wxandbptrare learnable , and is the sigmoid function .
The ï¬nal probability for a wordwin time step is obtained : P(w ) = Pgenpvocab(w ) + ( 1 Pgen)X i : wi = wat i ( 11 ) We introduce how to alienate the two decoders in the training part .
Training For predictor , we use cross - entropy as the loss function : Lpred= ^jlog(Psup) (1 ^j)log(1 Psup ) ( 12 ) where ^jis the real judgment .
For decoders , the previous word in training is the word in real court â€™s view , and the loss for timestep tis the negative log - likelihood of the target word w t : Lt= logP(w t ) ( 13 ) and the overall generation loss is : Lgen=1
TTX t=0Lt ( 14 ) where T is the length of real court â€™s view .
Since we aim to make the two decoders generate two different court â€™s views , we take a mask operation when calculating the loss of each decoder .
The exact loss for the support decoder is : Lsup= ( Lgen^j= 1 0 ^j= 0(15 ) the loss for the non - support decoder Lnsup is obtained by the opposite way .
Thus , the total loss is : Ltotal = Lsup+Lnsup+Lpred ( 16 ) where we set to 0.1 in our model .
Inference In inference , the counterfactual decoders apply beam search to generate two court â€™s views , and one of them will be selected as the ï¬nal output , depending on the result of the predictor j. Table 1
: Statistics of private lending dataset Type Result # Supported case 51087(76 % ) #
Non - supported case 15817(24 % ) Avg . # tokens in claim 77.9 Avg . # tokens in fact 158.0 Avg . # tokens in court â€™s view 194.4 5 Experiments 5.1 Data Construction Since there is no publicly available court â€™s view generation dataset in civil cases , we build a dataset based on raw civil legal documents3 .
Speciï¬cally , we choose private lending , which is the most frequent category in civil cases , to construct the dataset .
We process the legal documents as following steps : 1 ) Split legal documents into three parts : plaintiff â€™s claim , facts description , and court â€™s view , which can be objectively split by keywords ( subtitles ) .
2 ) Human annotation .
We employ experts with legal backgrounds to annotate the judgment ( deï¬ned in Sec . 3 ) on the court â€™s view .
3 ) Annotation veriï¬cation .
We use random sampling test to ensure that the annotation accuracy is over 95 % .
After that , we get the dataset as shown in Tab .
1 .
We randomly separate the dataset into a training set , a validation set , and a test set according to a ratio of 8 : 1 : 1 , the ratio of supported cases is about 76 % in each set .
5.2 Baselines We implement the following baselines for comparison : S2SSequence - to - sequence model ( Sutskever et al . , 2014 ) is a classic model for NLG task .
We concatenate the plaintiff claims and facts descriptions as input .
PGN Pointer Generator Networks ( See et al . , 2017 ) utilizes a pointer network to solve the outof - vocabulary ( OOV ) problem , which is essential for the court â€™s view generation since many nouns occur there .
Oversampling is a common method to alleviate data imbalance .
We oversample the non - supported cases so that the ratio between supported cases and non - supported cases become 1 : 1 . S2SwS Apply oversampling to S2S. 3https://wenshu.court.gov.cn/
769Table 2 : Results on court â€™s view generation .
MethodROUGE BLEU BERT SCORE R-1 R-2 R - L B-1 B-2 B - N p r f1 S2S 54.0 35.7 48.3 65.0 57.6 50.5 89.6 89.5 89.6 S2SwS 51.5 32.0 45.0 63.3 55.6 47.9 83.8 88.8 86.2 PGN 53.3 37.1 48.8 62.0 56.1 50.0 94.0 91.2 92.6 PGNwS 53.2 36.0 48.0 63.1 56.7 50.2 95.7 94.0 94.8 AC - NLGw / oBA
54.1 38.1 49.9 61.8 55.9 49.9 93.6 91.9 92.8 AC - NLGw / oCA 53.7 36.7 49.1 62.1 56.0 49.7 94.5 92.6 93.5 AC - NLGwS 53.7 36.4
48.5 62.8 56.5 50.0 94.0 92.1 93.0 AC - NLG 55.1 38.6 50.8 63.2 57.1 51.0 96.5 94.6 95.5 Table 3 : Results on judgment prediction .
MethodPrediction Acc .
Support Non - support p r f1 p r f1 w / oD
72.1 81.0 76.3 56.9 44.3 49.8 w / oCA 92.0 97.2 94.5 85.6 66.0 74.5 wS 86.0 94.3 90.0 62.8 38.6 47.8 AC - NLG 93.4 95.9 94.6 81.5 72.9 76.9 Table 4 : Results of human evaluation .
MethodJudgmentRational Flu . Support Non - support PGN 3.34 1.78 3.11 3.41 AC - NLG 3.52 3.24 3.25 3.50 PGNwS Apply oversampling to PGN .
AC - NLGwS Apply oversampling to ACNLG .
We do ablation experiments as follows : AC - NLGw / oD
We remove the decoder and train the remaining model ( encoder and predictor ) as a classiï¬cation task for judgment prediction .
AC - NLGw / oBA
We remove the backdoor adjustment by replacing the pair of counterfactual decoders and predictor with a single decoder , but keep the claim - aware attention mechanism .
AC - NLGw / oCA We remove the claim - aware attention , and concatenate the claims and the facts instead .
5.3 Metrics ROUGE4is a set of metrics used in the NLP task .
We keep the results of ROUGE-1 , ROUGE-2 , and ROUGE - L. ROUGE-1 and ROUGE-2 refer to the overlap of unigram and bigram between the generated and reference documents , respectively .
ROUGE - L is a Longest Common Subsequence ( LCS ) based statistics .
BLEU5(Papineni et
al . , 2002 ) is a method of au4https://pypi.org/project/rouge/ 5http://www.nltk.org/api/nltk.test .
unit.translate.htmltomatic text - generation evaluation that highly correlates with human evaluation .
We use BLEU-1 , BLEU-2 to evaluate from the perspectives of unigram , bigram .
BLEU - N is an average of BLEU-1 , BLEU2 , BLEU-3 , BLEU-4 .
BERT SCORE6(Zhang et
al . , 2019 ) computes a similarity score by using contextual embedding of the tokens .
We calculate the precision ( p),recall ( r ) andf1 - score to evaluate the information matching degree .
Accuracy of judgment prediction To evaluate the performance of the predictor , we calculate the precision ( p),recall ( r ) and , f1 - score of supported and non - supported cases , respectively .
Human Evaluation We conduct a human evaluation to better analyze the quality of the generated court â€™s view .
First , we randomly sample 500 test cases , where the ratio of the supported and nonsupported cases are 1:1 .
For each case , we present the generated court â€™s views from each method7 with the ground truth to 5 human annotators with legal backgrounds .
The evaluation is conducted following three perspectives : ( 1 ) Judgment level .
Annotators are asked to give a score ( 1 - 5 ) on the judgment in the generated court â€™s view .
1 for totally wrong and 5 for totally correct .
( 2 ) Rational level .
Annotators are asked to give a score ( 1 - 5 ) on the rationals in the generated court â€™s view .
1 for the worst and 5 for the best .
( 3 ) Fluency level .
Annotators are asked to give a score ( 1 - 5 ) on the ï¬‚uency of the generated court â€™s view .
1 for the worst and 5 for the best .
5.4 Experimental Results Tab . 2 demonstrates the results of court â€™s view generation with ROUGE , BLEU , and BERT SCORE .
Also , we report the results on the judgment prediction of our predictor component with precision 6https://github.com/Tiiiger/bert_score 7We shufï¬‚e all the results to be fair for all the methods
770 PLAINTIFFâ€™SCLAIMThedefendantBreturntheloanof$495,000.ThedefendantCreturntheloantogether .
FACTDESCRIPTIONAfterthehearing , thecourtheldthefactsasfollows : FromNovember20,2010toMarch23,2011,thedefendantBsuccessivelyborrowedatotalof$495,000fromtheplaintiffAandissuedfourseparateborrowings . ThedefendantBhasnotrepaidtheaboveloan .
PGNThecourtconcludedthat : TheprivatelendingrelationshipbetweenPlaintiffAandDefendantB , wherethesubjectwasappropriate , thecontentwaslegitimate , andthemeaningwastrue , shouldbeconfirmedtobelegalandvalid .
Thetwosidesdidnotagreedinwritingonaloanperiod , sothedefendantshouldreturntheplaintiff'sloaninatimelymannerwithinareasonableperiodaftertheplaintiffurged . Thedefendantâ€™sfailuretoreturntheloantimelyconstitutedabreachofcontractandshouldbearcorrespondingcivilliabilities .
Therefore , the plaintiff 's claim was reasonable and legal , and the court supported it Acceptance .
AC - NLGThecourtconcludedthatthesubjectoftheprivatelendingrelationshipbetweenPlaintiffAandDefendantBwasqualified , thecontentwaslegal , andthemeaningwastrue .
Itshouldbedeemedvalid .
Thetwosidesdidnotagreedinwritingonaloanperiod , thedefendantshallreturntheloanwithinareasonableperiodaftertheplaintiffurged .
The plaintiff â€™s claim requesting the defendant to return the loan of $ 495,000 was in compliance with the law and the court supported it Acceptance .
However , the court did not support the claim requesting the defendant C to bear the guarantee liability because   the evidence was insufficient Rejection .
REALThecourtconcludedthat : ThesubjectoftheprivatelendingrelationshipbetweenPlaintiffAandDefendantBwasqualified , thecontentwaslegal , andthemeaningwastrue .
Itshouldbedeemedvalid .
Defendantshouldrepaytheplaintiff'sloanwithinareasonableperiodaftertheplaintiffurged .
Therefore , Defendant B should bear the civil liability of returning the plaintiff 's loan of $ 495,000 and paying overdue interest Acceptance .
The court did not support the plaintiff â€™s claim requesting the defendant C to return the loan together because the evidence was insufficientRejection .
DefendantBfailedtoappearincourtafterbeinglegallysummonedbythecourt .
Figure 4 : Case study .
( p),recall ( r ) , andf1 - score ( f1 ) in Tab .
3 .
To demonstrate that our method is de - biased on judgment generation , we report the result of human evaluation in Tab .
4 . Results of court â€™s view generation : From Tab . 2 , we can conclude that : ( 1 ) S2S tends to repeat words , which makes it get high BLEU but low BERT SCORE .
( 2 ) Oversampling strategy does nâ€™t beneï¬t the models , hence , it can not address the confounding bias .
( 3 ) With claim - aware encoder and backdoor - inspired counterfactual decoders , our AC - NLG achieves better performance on court â€™s view generation compared with baselines .
( 4 ) The performance gap between AC - NLGw / oCA and AC - NLG demonstrates the effectiveness of our proposed claim - aware encoder , and the gap between AC - NLGw / oBA andAC - NLG illustrates the superiority of our counterfactual decoders .
Results of judgment prediction : From Tab . 3 , we have the following observations : ( 1 ) The counterfactual decoders in our model can signiï¬cantly eliminate the confounding bias , hence , achieve remarkable improvement on the non - supported cases , for example boosting f1from 49.8 % to 76.9 % .
( 2 ) The proposed claim - aware encoder has a limited effect on judgment prediction since it â€™s designed for improving the quality of generation as shown in Tab .
2 . ( 3 ) Still , oversampling brings no improvement to the model .
Results of human evaluation : From Tab . 4 , we have the following observations : ( 1 ) due to the confounding bias in data , the performance of judgment generation in PGN is poor for non - supported cases , and its performance gap between supported and non - supported cases is huge ( 1.56 ) .
( 2 ) Bydebiasing with backdoor - inspired counterfactual decoders , our AC - NLG signiï¬cantly improves the performance of judgment generation , especially for non - supported cases , and achieves a smaller performance gap ( only 0.28 ) between the supported and non - supported cases .
( 3 ) With a claim - aware encoder , our AC - NLG also achieves better performance on the generation of rational and generated court â€™s view ï¬‚uency .
( 4 ) Kappa coefï¬cient  is more than 0.8 between any two judges , which proves the validation of human evaluation .
Overall , thanks to the proposed claim - aware encoder , counterfactual decoders , and a synergistic judgment predictor , our model achieves better performance than single - task baselines on the task of judgment prediction , judgment generation in court â€™s view and court â€™s view generation .
5.5 Experiment Details We use Gensim ( Ë‡RehËšuË‡rek and Sojka , 2010 ) with a large - scale generic corpus to train a language model as the pre - trained model , then use it to initialize the word embeddings , which is in the dimension of 300.8 5.6 Case Study Figure 4 shows three court â€™s views for a certain case : the court â€™s view generated by PGN , by the proposed AC - NLG method , and the real court â€™s view .
We ï¬nd that the one generated by PGN accepts the claim for principal , but ignores other claims such as issue related to guarantee .
Compared with the real court â€™s view , our model accu8Source code , data , more experiment details and results can be found in supplementary materials .
771rately responds to both claims and produces the correct judgment .
6 Ethical Discussion While AI is gaining adoption in legal justice(Lin et
al . , 2012 ; Zhong et al . , 2018 ; Hu et al . , 2018 ; Jiang et al . , 2018 ; Chalkidis et al . , 2019 ) , any subtle statistical miscalculation may trigger serious consequences .
From a fairness perspective , prior studies suggested that global ( statistical ) optimization6 = individual ( demographic ) fairness ( Zemel et al . , 2013 ) , and this ethical concern should be further investigated .
In this section , we explore the following ethical issues .
Target User :
According to the report of statistics , a typical active trial judge closed around 250 cases in a year .
Trial judges suffering from â€˜ daunting workload â€™ is becoming an critical issue(Duan et al . , 2019 ) .
The proposed algorithm is designed for generating the court â€™s view draft for assisting the trial judges for decision making .
This work is an algorithmic investigation , but such algorithm should never â€˜ replace â€™ human judges .
Human knowledge / judgment should be the ï¬nal safeguard to protect social justice and individual fairness .
Potential Error : The potential error would be as follows : a ) generating a wrong judgment and b ) generating a wrong rationale .
The goal of our algorithm is to generate a draft of court â€™s view for trail judge as a reference , and judges need to proofread the content generated from algorithm .
Demographic Bias : In this paper , we focus on addressing the bias problem from the data generation by treating the variable of data generation as confounder in back - door adjustment .
The model adoption can face potential demographic bias / unfairness challenges , such as gender and race bias in the training data .
To further ensure the model fairness , in the future , algorithm adoption should be empowered with de - biased legal content pretraining , which could avoid potential demographic bias .
For instance , in order to remove gender / race bias , system could use ( Bolukbasi et al . , 2016 ) algorithm to debias the sensitive gender / race information , e.g. , replace â€˜ he / she â€™ and â€˜ asian / hispanic â€™ with gender / race neutral words for pretraining , which can be vital for legal domain .
7 Conclusion and Future Work
In this paper , we propose a novel Attentional and Counterfactual based Natural Language Genera - tion ( AC - NLG ) method to solve the task of court â€™s view generation in civil cases and ensure the fairness of the judgment .
We design a claim - aware encoder to represent the fact description which emphasizes on the plaintiff â€™s claim , as well as a pair of backdoor - inspired counterfactual decoders to generate judgment - discriminative court â€™s views ( both supportive and non - supportive views ) and to eliminate the bias that arose from the data generation mechanism by connecting with a synergistic judgment predictive model .
The experimental results show the effectiveness of our method .
Based on the AC - NLG method , in the future , we can explore the following directions : ( 1 ) Improve the accuracy of judgment on a claim - level .
( 2 ) Add external knowledge ( e.g. a logic graph ) to the predictor for the interpretability of the model .
Acknowledgments This work was supported by National Natural Science Foundation of China ( No . 62006207 , 61625107 ) , National Key R&D Program of China ( No . 2018AAA0101900 , 2018YFC0830200 , 2018YFC0830206 , 2020YFC0832500 ) , the Fundamental Research Funds for the Central Universities .
Finally , we would like to thank the anonymous reviewers for their helpful feedback and suggestions .
References Sugato Bagchi and Laura Wynter .
2013 .
Method for a natural language question - answering system to complement decision - support in a real - time command center .
US Patent 8,601,030 .
Dzmitry Bahdanau , Kyunghyun Cho , and Yoshua Bengio .
2014 .
Neural machine translation by jointly learning to align and translate .
arXiv preprint arXiv:1409.0473 .
Tolga Bolukbasi , Kai - Wei Chang , James Y Zou , Venkatesh Saligrama , and Adam T Kalai .
2016 .
Man is to computer programmer as woman is to homemaker ?
debiasing word embeddings .
In Advances in neural information processing systems , pages 4349â€“4357 .
Ilias Chalkidis , Ion Androutsopoulos , and Nikolaos Aletras .
2019 .
Neural legal judgment prediction in english .
arXiv preprint arXiv:1906.02059 .
Yen - Liang Chen , Yi - Hung Liu , and Wu - Liang Ho .
2013 .
A text mining approach to assist the general public in the retrieval of legal documents .
Journal of the American Society for Information Science and Technology , 64(2):280â€“290 .
772Yuh - Shyan Chen , Shin - Wei Chiang , and Tong - Ying Juang .
2019 .
A few - shot transfer learning approach using text - label embedding with legal attributes for law article prediction .
Technical report , EasyChair .
Xinyu Duan , Yating Zhang , Lin Yuan , Xin Zhou , Xiaozhong Liu , Tianyi Wang , Ruocheng Wang , Qiong Zhang , Changlong Sun , and Fei Wu . 2019 .
Legal summarization for multi - role debate dialogue via controversy focus mining and multi - task learning .
In Proceedings of the 28th ACM International Conference on Information and Knowledge Management , pages 1361â€“1370 .
Zikun Hu , Xiang Li , Cunchao Tu , Zhiyuan Liu , and Maosong Sun .
2018 .
Few - shot charge prediction with discriminative legal attributes .
In Proceedings of the 27th International Conference on Computational Linguistics , pages 487â€“498 .
Guido W Imbens and Donald B Rubin .
2015 .
Causal inference in statistics , social , and biomedical sciences .
Cambridge University Press .
Xin Jiang , Hai Ye , Zhunchen Luo , Wenhan Chao , and Wenjia Ma . 2018 .
Interpretable rationale augmented charge prediction system .
In Proceedings of the 27th International Conference on Computational Linguistics : System Demonstrations , pages 146â€“151 .
Kun Kuang , Lian Li , Zhi Geng , Lei Xu , Kun Zhang , Beishui Liao , Huaxin Huang , Peng Ding , Wang Miao , and Zhichao Jiang .
2020 .
Causal inference .
Engineering , 6(3):253â€“263 .
Wan - Chen Lin , Tsung - Ting Kuo , Tung - Jia Chang , Chueh - An Yen , Chao - Ju Chen , and Shou - de Lin .
2012 .
Exploiting machine learning models for chinese legal documents labeling , case classiï¬cation , and sentencing prediction .
Processdings of ROCLING , page 140 .
Bryan McCann , Nitish Shirish Keskar , Caiming Xiong , and Richard Socher .
2018 .
The natural language decathlon : Multitask learning as question answering .
arXiv preprint arXiv:1806.08730 .
Kishore Papineni , Salim Roukos , Todd Ward , and WeiJing Zhu . 2002 .
Bleu : a method for automatic evaluation of machine translation .
In Proceedings of the 40th annual meeting on association for computational linguistics , pages 311â€“318 .
Association for Computational Linguistics .
Judea Pearl .
2009 .
Causality .
Cambridge university press .
Judea Pearl , Madelyn Glymour , and Nicholas P Jewell . 2016 .
Causal inference in statistics : A primer .
John Wiley & Sons .
Radim Ë‡RehËšuË‡rek and Petr Sojka .
2010 .
Software Framework for Topic Modelling with Large Corpora .
In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks , pages 45 â€“ 50 , Valletta , Malta .
ELRA .
http://is.muni.cz/ publication/884893 / en .Alexander
M Rush , Sumit Chopra , and Jason Weston .
2015 .
A neural attention model for abstractive sentence summarization .
arXiv preprint arXiv:1509.00685 .
Abigail See , Peter J Liu , and Christopher D Manning .
2017 .
Get to the point : Summarization with pointer - generator networks .
arXiv preprint arXiv:1704.04368 .
I Sutskever , O Vinyals , and QV Le . 2014 .
Sequence to sequence learning with neural networks .
Advances in NIPS .
Yonghui Wu , Mike Schuster , Zhifeng Chen , Quoc V Le , Mohammad Norouzi , Wolfgang Macherey , Maxim Krikun , Yuan Cao , Qin Gao , Klaus Macherey , et al . 2016 .
Google â€™s neural machine translation system : Bridging the gap between human and machine translation .
arXiv preprint arXiv:1609.08144 .
Guangyi Xiao , Even Chow , Hao Chen , Jiqian Mo , Jingzhi Guo , and Zhiguo Gong .
2017 .
Chinese questions classiï¬cation in the law domain .
In 2017 IEEE 14th International Conference on e - Business Engineering ( ICEBE ) , pages 214â€“219 . IEEE .
Hai Ye , Xin Jiang , Zhunchen Luo , and Wenhan Chao .
2018 .
Interpretable charge predictions for criminal cases : Learning to generate court views from fact descriptions .
arXiv preprint arXiv:1802.08504 .
Rich Zemel , Yu Wu , Kevin Swersky , Toni Pitassi , and Cynthia Dwork .
2013 .
Learning fair representations .
InInternational Conference on Machine Learning , pages 325â€“333 .
Tianyi Zhang , Varsha Kishore , Felix Wu , Kilian Q Weinberger , and Yoav Artzi .
2019 .
Bertscore : Evaluating text generation with bert .
arXiv preprint arXiv:1904.09675 .
Ye Zhang , Nan Ding , and Radu Soricut .
2018 .
Shaped : Shared - private encoder - decoder for text style adaptation .
arXiv preprint arXiv:1804.04093 .
Haoxi Zhong , Zhipeng Guo , Cunchao Tu , Chaojun Xiao , Zhiyuan Liu , and Maosong Sun .
2018 .
Legal judgment prediction via topological learning .
In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 3540â€“3549 .
A Appendices All models are trained on 2 V100 GPU(16 GB ) .
773Table 5 : Experiment details for each model .
Method Avg Runtime # of Paras . S2S(wS ) 22h
30,789,836 PGN(wS )
25h 30,791,161 AC - NLGw / oD 7h 19,972,418 AC - NLGw / oBA 28h 34,622,843 AC - NLGw / oCA 27h 45,244,852 AC - NLG(wS ) 29h 49,010,612 Table 6 : The hyperparameters of AC - NLG .
Name value Note hidden dim 256 dimension of RNN hidden states emb dim 300 dimension of word embeddings batch size 16 minibatch size max encsteps 300 max timesteps of encoder ( max source text tokens ) max decsteps 150 max timesteps of decoder ( max generated text tokens ) beam size 4 beam size for beam search decoding min decsteps 35 Minimum sequence length of generated text .
vocab size 50000 Size of vocabulary lr 0.15 learning rate keep prob 0.5 keep prob adagrad initacc 0.1 initial accumulator value for Adagrad rand unif initmag 0.02 magnitude for lstm cells random uniform inititalization trunc norm initstd 0.1 std of trunc norm init , used for initializing everything else max grad norm 2.0 for gradient clipping
774 PLAINTIFFâ€™SCLAIM1.ThedefendantBshallreturntheplaintiff'sloanof$30,000andpaytheoverdueinterestattheinterestrateof2.4%permonthfromthedateofprosecutiontothedateofrepayment.2.ThedefendantBshallpaythelitigationcostsofthiscase .
FACTDESCRIPTIONAfterthehearing , thecourtheldthefactsasfollows : OnDecember11,2013,thedefendantBborrowed$30,000fromtheplaintiffA.ThedefendantBreceivedtheloanandgaveareceiptofthisloan .
Note : Ihaveborrowed$30,000fromAtoday .
PGNThecourtconcludedthat : ThefactsthatdefendantBborrowed$30,000fromtheplaintiffAareclear . TheprivatelendingrelationshipbetweenPlaintiffAandDefendantBislegitimateandvalid , itshallbeprotectedbythelaw .
Theplaintiffnowdemandsthatthedefendantrepaytheloanof$30,000 .
This demand is justified and should be supported Acceptance .
DefendantBrefusedtoappearincourtwithoutjustificationafterbeinglegallysummonedbythecourt .
AC - NLGThecourtconcludedthat : Thelegitimateprivatelendingrelationshipsareprotectedbylaw . TheactofborrowingbetweentheplaintiffAandthedefendantBdidnotviolatetheprohibitiveprovisionsofstatelawsandregulations , soitshouldbevalid .
ThefactthatthedefendantBowedtheplaintiffAaloanof$30,000isclear , andtheevidenceissufficient .
The defendant was supposed to repay the loan in time , and his failure to repay in time constituted a breach of contract , and he shall assume corresponding civil liabilities according to law Acceptance .
The receipt of this loan provided by the plaintiff A does not have agreed interest , as not to pay interest .
So the court does not support the claim that the plaintiff A asked the defendant B to calculate the interest from the date of the loan Rejection .
Thedefendantwassummonedbythecourtandrefusedtoappearincourtwithoutjustification .
REALThecourtconcludedthat : thelendingagreementbetweentheplaintiffAandthedefendantBcontainsthetruemeaninganddoesnotviolatetheprohibitiveprovisionsofstatelawsandregulations , itislegalandvalid .
Althoughtheplaintiffandthedefendantdidnotspecificallyagreeonthetimeforrepayment , afterthedefendantreceivedtheloan , it shall be returned within a reasonable period after being appealed by the plaintiff .
If the defendant fails to return it within a reasonable period after being called , the defendant shall be responsible to pay the overdue interest from the date of prosecution Acceptance .
Forthecalculationstandardforoverdueinterest , theplaintiffclaimedthatthemonthlyinterestratewas2.4%,butitdidnotprovideacorrespondingevidence .
Therefore , the court does not support this claim of overdue interest Rejection .
WithreferencetotheloaninterestrateannouncedbythePeople'sBankofChinaforthesameperiod , thecourtdeterminedthatoverdueinterestiscalculatedatanannualinterestrateof5.6%.Thefactthatthedefendanthasnotreturnedtheloanof$30,000isclear . Sothecourtsupportsthereasonablepartoftheplaintiffâ€™sclaimrequestingthedefendanttoreturntheloanandpaytheoverdueinterest .
DefendantBrefusedtoappearincourtwithoutjustificationafterbeinglegallysummonedbythecourt .
Figure 5 : Show case 1 .
775 Figure 6 : Show case 2 .
776 Figure 7 : Show case 3 .
777 Figure 8 : Show case 4 .
778 Figure 9 : Show case 5 .
779 Figure 10 : Show case 6 .
780 PLAINTIFFâ€™SCLAIM1.ThedefendantBshallpay$28,000andinterest$2560.Paymentofinterestiscalculatedfromthedateofprosecutiontotheactualsettlementdate , basedonthebaserateofthePeopleâ€˜sBankofChinaofthesameperiodattheamountof$28,000.2.Thelitigationcostsinthiscaseshallbepaidbythedefendant .
FACTDESCRIPTIONAfterthehearing , thecourtheldthefactsasfollows : OnSeptember30,2013andAugust25,2014,thedefendantBborrowed$10,000eachtimefromtheplaintiffA.Thedefendantissuedaloanreceipttotheplaintiffforeachofthetwoloans .
Therewasnowrittenagreementontheinterestandloanperiod .
Later , thedefendantdidnotreturntheloan , thenitcausedadispute .
Theabovefactsareprovedbytworeceiptsoftheloanprovidedbytheplaintiffandtheplaintiff'sstatementinthecourt .
PGNThecourtconcludedthat : Theprivatelendingrelationshipbetweentheplaintiffandthedefendantisestablishedaccordingtolaw , andiseffectivefromthedatetheplaintiffprovidesthedefendantwiththeloan .
Aftertheplaintiffprovidedtheloantothedefendant , thedefendantfailedtoreturntheloanasagreed , itwasobviouslyabreachofcontract .
Therefore , the plaintiffâ€˜s claim requesting the defendant to return the loan principal of $ 28,000 was justified , and the court supports it Acceptance .
Thedefendantwaslegallysummonedbythecourtandrefusedtoappearincourtwithoutjustifiablereasonstoparticipateintheproceedings .
AC - NLGThecourtconcludedthat : Theprivatelendingrelationshipbetweentheplaintiffanddefendantisestablishedaccordingtolawandshouldbeprotectedbylaw . Thedefendantborrowed$10,000fromtheplaintiff .
Thefactswereclearandtheevidencewassufficient .
The plaintiff now requires the defendant to repay the loan of $ 10,000 .
The reasons are justified , and the court supports it Acceptance .
But the court does not support the plaintiff â€™s claim requesting the defendant to pay interest on the loan because the plaintiff failed to provide evidence to prove the fact that both of them agreed on the interest of the loan Rejection .
Thedefendantwaslegallysummonedbythiscourtandrefusedtoappearincourtwithoutjustifiablereasonstoparticipateintheproceedings .
REALThecourtconcludedthat : Theprivatelendingrelationshipbetweentheplaintiffandthedefendantisestablishedandeffective , andshallbeprotectedaccordingtolaw .
Thedefendantshouldrepaytheloanafterreceivingit , butnowhedidnotrepay , itisobviouslyabreachofcontract .
Therefore , this court supports the claim of the plaintiff that the defendant should return the loan of $ 20,000 and the corresponding loss of interest Acceptance .
The plaintiff claimed that the defendant should pay interest , but did not provide evidence to prove that both of them clearly agreed on the interest , so the court does not support the plaintiffâ€˜s claim for interest Rejection .
Theplaintiffwithdrewsomeoftheclaimsinthecourthearing , andthiscourtpermittedit .
Figure 11 : Show case 7 .
