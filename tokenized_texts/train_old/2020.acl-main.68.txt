Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 742â€“751 July 5 - 10 , 2020 .
c  2020 Association for Computational Linguistics742Rigid Formats Controlled Text Generation Piji
Li Haisong Zhang Xiaojiang Liu Shuming Shi Tencent AI Lab , Shenzhen , China fpijili , hansonzhang , kieranliu , shumingshi g@tencent.com
Abstract Neural text generation has made tremendous progress in various tasks .
One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating .
However , we may confront some special text paradigms such as Lyrics ( assume the music score is given ) , Sonnet , SongCi ( classical Chinese poetry of the Song dynasty ) , etc .
The typical characteristics of these texts are in three folds : ( 1 ) They must comply fully with the rigid predeï¬ned formats .
( 2 ) They must obey some rhyming schemes .
( 3 ) Although they are restricted to some formats , the sentence integrity must be guaranteed .
To the best of our knowledge , text generation based on the predeï¬ned rigid formats has not been well investigated .
Therefore , we propose a simple and elegant framework named SongNet to tackle this problem .
The backbone of the framework is a Transformer - based auto - regressive language model .
Sets of symbols are tailor - designed to improve the modeling performance especially on format , rhyme , and sentence integrity .
We improve the attention mechanism to impel the model to capture some future information on the format .
A pre - training and ï¬ne - tuning framework is designed to further improve the generation quality .
Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates signiï¬cantly better results in terms of both automatic metrics and the human evaluation.1 1 Introduction Recent years have seen the tremendous progress in the area of natural language generation especially beneï¬ting by the neural network models such as Recurrent Neural Networks ( RNN ) or Convolutional Neural Networks ( CNN ) based sequence - tosequence ( seq2seq ) frameworks ( Bahdanau et al . , 1Code : http://github.com/lipiji/SongNet æ©”à ‰Ş×™à¬†Í«ã…“ã…«Ş—ÚĞŸæ¾Ş©Ùà¯°ã¨¡à£à¨˜ã—˜Í«Ş¾à©‹à¯Õ¹à®§æ¾ Û Ş—à¨´Ğ¶Ş¦Í« â–² Ñ à§©å· â½” æ¾à®©à©ŠÛ¨ä€²ä¬¦ÒØ¸Í«Õ‘ß„à¯šİ»×²æ¾
Let me not to the marriage of true minds
Admit impediments , love is not love Which alters when it alteration finds Or bends with the remover to remove .  
Lyrics SongCi SonnetFigure 1 : Examples of text with rigid formats .
In lyrics , the syllables of the lyric words must align with the tones of the notation .
In SongCi and Sonnet , there are strict rhyming schemes and the rhyming words are labeled in red color and italic font .
2014 ; Gehring et al . , 2017 ) , Transformer and its variants ( Vaswani et al . , 2017 ; Dai et al . , 2019 ) , pre - trained auto - regressive language models such as XLNet ( Yang et al . , 2019 ) and GPT2 ( Radford et al . , 2019 ) , etc .
Performance has been improved signiï¬cantly in lots of tasks such as machine translation ( Bahdanau et al . , 2014 ; Vaswani et
al . , 2017 ) , dialogue systems ( Vinyals and Le , 2015 ; Shang et al . , 2015 ; Li , 2020 ) , text summarization ( Rush et al . , 2015 ; Li et al . , 2017 ; See et al . , 2017 ) , story telling ( Fan et al . , 2018 ; See et al . , 2019 ) ,
poetry writing ( Zhang and Lapata , 2014 ; Lau et al . , 2018 ; Liao et al . , 2019 ) , etc .
Generally , most of the above mentioned tasks can be regarded as free text generation , which means that no constraints on the format and structure , say the number of words and rhyming rules .
Note that tasks of dialogue generation and story telling are almost in an open - ending generation style as long as the generated content is relevant with the conditional input text .
Although there are
743formats constraints on the poetry text , the proposed models just treat the formats as kind of latent information and let the model capture this feature implicitly during training ( Liao et al . , 2019 ) .
The model trained on the ï¬ve - character quatrain corpus can not generate seven - character verses .
Moreover , it is impossible to trigger these models to generate satisfying results according to arbitrary new deï¬ned formats .
In practice we will confront some special text paradigms such as Lyrics ( assume the music score is given ) , Sonnet ( say Shakespeare â€™s Sonnets ( Shakespeare , 2000 ) ) , SongCi ( a kind of Ci .
Ci is a type of lyric poetry in the tradition of Classical Chinese poetry.2 , SongCi is the Ci created during Song dynasty ) , etc . , and some examples are illustrated in Figure 1 .
The typical characteristics of these text can be categorized into three folds : ( 1 ) The assembling of text must comply fully with the predeï¬ned rigid formats .
Assume that the music score is composed , then the lyricist must ï¬ll the lyric content strictly tally with the schemes lie in the notation .
Take partial of song â€œ Edelweiss â€ as shown in the ï¬rst row of Figure 1 as example , the syllables of the lyric words must align with the tones of the notation .
The second row of Figure 1 depicts the content of a SongCi created based on the CiPai of â€œ Bu Suan Zi â€ .
Given the CiPai , the number of characters and the syntactical structure of the content are also deï¬ned ( e.g. , the number of characters of each clause : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 . ) .
( 2 ) The arrangement of the content must obey the deï¬ned rhyming schemes .
For example , all the ï¬nal words ( words in red color and italic font ) of the SongCi content in Figure1 are rhyming ( the spelling of each word is : â€œ zhu â€ , â€œ yu â€ , â€œ du â€ , and â€œ gu â€ . ) .
The example in the third row of Figure 1 comes from Shakespeare â€™s â€œ Sonnet 116 â€ ( Shakespeare , 2000 ) , the ï¬rst four sentences .
Usually , the rhyming schemes of Shakespeare â€™s Sonnets is â€œ ABAB CDCD EFEF GG â€ 3 .
In the example , the rhyming words in scheme â€œ ABAB â€ are â€œ minds â€ , â€œ love â€ , â€œ ï¬nds â€ , and â€œ remove â€ .
( 3 ) Even though the format is rigid , the sentence integrity must always be guaranteed .
Incomplete sentence such as â€œ love is not the â€ is inappropriate .
To the best of our knowledge , text generation based on the predeï¬ned rigid formats constraints has not been well investigated yet .
In this work , 2http://en.wikipedia.org/wiki/Ci ( poetry ) 3http://en.wikipedia.org/wiki/Shakespeare%27s sonnetswe propose a simple and elegant framework named SongNet to address this challenging problem .
The backbone of the framework is a Transformer - based auto - regressive language model .
Considering the three folds characteristics mentioned above , we introduce sets of tailor - designed indicating symbols to improve the modeling performance , especially for the robustness of the format , rhyme , as well as sentence integrity .
We improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity .
Inspired by BERT ( Devlin et al . , 2019 ) and GPT ( Radford et al . , 2018 , 2019 ) , a pretraining and ï¬ne - tuning framework is designed to further improve the generation quality .
To verify the performance of our framework , we collect two corpora , SongCi and Sonnet , in Chinese and English respectively .
Extensive experiments on the collected datasets demonstrate that our proposed framework can generate satisfying results in terms of both the tailor - designed automatic metrics including format accuracy , rhyming accuracy , sentence integrity , as well as the human evaluation results on relevance , ï¬‚uency , and style .
In summary , our contributions are as follows : We propose to tackle a new challenging task : rigid formats controlled text generation .
A pre - training and ï¬ne - tuning framework named SongNet is designed to address the problem .
Sets of symbols are tailor - designed to improve the modeling performance .
We improve the attention mechanism to impel the model to capture the future information to further enhance the sentence integrity .
To verify the performance of our framework SongNet , we collect two corpora , SongCi and Sonnet , in Chinese and English respectively .
We design several automatic evaluation metrics and human evaluation metrics to conduct the performance evaluation .
Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates signiï¬cantly better results given arbitrary formats , including the cold - start formats or even the formats newly deï¬ned by ourselves .
2 Task Deï¬nition
The task of rigid formats controlled text generation is deï¬ned as follows :
744 love is not love , < /s > bends with remove < /s > < bos > InputToken EmbeddingsFormat & Rhyme EmbeddingsSegment
EmbeddingsGlobal Position Embeddings Intra Position Embeddings ç€–ç€– .ç€–ç€–ç€–ç€–
Û³à­ªà­­à­´à­£ Û³à­§à­±Û³à­¬à­­à­²Û³à­ªà­­à­´à­£
Û³Ç¡Û³à®´È€à­±à®µÛ³à­ à­£à­¬à­¢à­±
Û³à­µà­§à­²à­¦ Û³ à­° à­£à­« Û³Ç¤Û³à®´È€à­±à®µ Û³à®´à­ à­­à­±à®µÛ³à¯–à°¬Û³à¯–à°¬Û³à¯–à°¬Û³à¯–à°®Û³à¯–à°­Û³à¯–à°¬Û³à®´È€à­±à®µÛ³à®´È€à­±à®µÛ³à®´È€à­±à®µ Û³à¯–à°¬Û³à¯–à°®Û³à¯–à°­Û³à®´È€à­±à®µÛ³à®´È€à­±à®µÛ³à®´È€à­±à®µ Û³à®´à­£à­­à­±à®µÛ³à®´à­£à­­à­±à®µÛ³à®´à­£à­­à­±à®µ Û³à¯£à°°Û³à¯£à°¯Û³à¯£à°®Û³à¯£à°­Û³à¯£à°¬ Û³à¯£à°²Û³à¯£à°±Û³à¯£à°­Û³à¯£à°¬Û³à¯¦à°¬Û³à¯¦à°¬Û³à¯¦à°¬Û³à¯¦à°¬Û³à¯¦à°¬Û³à¯¦à°­Û³à¯¦à°­Û³à¯¦à°­Û³à¯¦à°­Û³à¯šà°¬Û³à¯šà°­Û³à¯šà°®Û³à¯šà°¯Û³à¯šà°°Û³à¯šà°±Û³à¯šà°²Û³à¯šà°³Û³à¯šà°­à°­Û³à¯šà°­à°®Û³à¯šà°­à°¯Û³à¯šà°­à°°love is not love , < /s > bends with remove < /s >
< eos > Output ç€– .
æ¿æ¿•æ¿§æ¿Ÿæ¿™æ¿˜æ¾”æ¿æ¿©æ¿ æ¿¨æ¿æ¾¡æ¾¼æ¿™æ¿•æ¿˜æ¾”æ¾µæ¿¨æ¿¨æ¿™æ¿¢æ¿¨æ¿æ¿£æ¿¢ æ¾»æ¿ æ¿£æ¿–æ¿•æ¿ æ¾”æ¿æ¿©æ¿ æ¿¨æ¿æ¾¡æ¾¼æ¿™æ¿•æ¿˜æ¾”æ¾µæ¿¨æ¿¨æ¿™æ¿¢æ¿¨æ¿æ¿£æ¿¢Figure 2 : The framework of our proposed model .
Input : a rigid format C2C : C = fc0c1c2c3 ; c0c1c2c3c4c5 : g ( 1 ) whereCis the set of all possible formats .
Note that we can deï¬ne arbitrary new formats not restricted to the ones pre - deï¬ned in the corpus , thus jCj!1 .
Format token cidenotes a place - holder symbol of Cwhich need to be translated into a real word token .
Format Ccontains 10words plus two extra punctuation characters â€œ , â€ and â€œ . â€
Output : a natural language sentence Y2Y which tally with the deï¬ned format C : Y = loveisnotlove ; bendswiththeremovertoremove : where the example sentences are extracted from the Shakespeare â€™s Sonnets ( Shakespeare , 2000 ) .
From the resultYwe can observe that the count of words is 10 which is consistent with the format C. The punctuation characters â€œ , â€ and â€œ . â€ are also correct .
Thus , we claim that it is a 100 % format accuracy result .
Also , since the two clause sentences are complete , we can get a good sentence integrity score .
IfCis deï¬ned on the literary genres of SongCi or Sonnet which have rhyming constraints , the rhyming performance should be evaluated as well .
Recall thatCcan be arbitrary and ï¬‚exible , thus we can rebuild a new format C0based on the generated result Yby masking partial content , say C0 = fc0c1c2love ; c 0c1c2c3c4remove : g , then we may obtain better results by re - generating based onC0 .
We name this operation as polishing .
Finally , the target of this problem is to ï¬nd a mapping function Gto conduct the rigid formats controlled text generation : Y = G(C ) ( 2)3 Framework Description 3.1 Overview As shown in Figure 2 , the backbone of our framework is a Transformer - based auto - regressive language model .
The input can be the whole token sequences of samples from SongCi or Sonnet .
We tailor - design several sets of indicating symbols to enhance the performance in terms of accuracy on format , rhyme , and sentence integrity .
Speciï¬cally , symbols C = fcigare introduced for format and rhyming modeling ; Intra - position symbols P = fpigare designed to represent the local positions of the tokens within each sentence aiming to improve the rhyming performance and the sentence integrity .
Segment symbols S = fsigare employed to identify the sentence border to further improve the sentence quality .
Attention mechanism is improved to impel the model to capture the future format information such as the sentence ending markers .
Similar to BERT ( Devlin et al . , 2019 ) and GPT ( Radford et al . , 2018 , 2019 ) , pre - training and ï¬ne - tuning paradigm is utilized to boost the performance of the original models .
3.2 Details We use two sentences ( as shown in Figure 1 ) â€œ love is not love , ... , bends with the remover to remove â€ extracted from the Shakespeare â€™s Sonnets ( Shakespeare , 2000 ) as examples to describe the details of our framework SongNet .
Since our basic model is a Transformer - based auto - regressive language model , during training , the input is â€œ hbosilove is not love , h = si ... , bends with the remover to remove.h = si â€ , and the corresponding output is a left - shifting version of the input ( tokenized , and
we
745ignore â€œ ... â€ for convenience and clarity ): love is not love ; h = si bends with the remover to remove : h = si heosi whereh = sidenotes the clause or sentence separator , andheosiis the ending marker of the whole sequence .
The target of our framework is to conduct the formats controlled text generation .
Therefore , the indicating symbols for format and rhyme as well as the sentence integrity are designed based on the target output sequence .
Format and Rhyme Symbols : C = fc0;c0;c0;c2;c1;h = si c0;c0;c0;c0;c0;c2;c1;h = si;heosig(3 ) where we usefc0gto represent the general tokens ; fc1gdepict the punctuation characters ; fc2grepresent the rhyming tokens â€œ love â€ and â€œ remove â€ .
h = si andheosiare kept .
Intra - Position Symbols : P = fp4;p3;p2;p1;p0;h = si p6;p5;p4;p3;p2;p1;p0;h = si;heosig(4 ) fpigdenote the local positions of tokens within the same clause or sentence .
Note that we align the position symbol indices in a descending order .
The aim is to improve the sentence integrity by impelling the symbols capture the sentence dynamic information , precisely , the sense to end a sequence .
For example , fp0gusually denote punctuation characters , thus fp1gshould be the ending words of sentences .
Segment Symbols : S = fs0;s0;s0;s0;s0;h = si s1;s1;s1;s1;s1;s1;s1;h = si;heosig(5 ) wheresiis the symbol index for
sentence i.
The purpose is to enhance the interactions between different sentences in different positions by deï¬ning the sentence index features .
During training , all the symbols as well as the input tokens are fed into the transformer - based language model .
Contrast to Transformer ( Vaswani et al . , 2017 ) , BERT ( Devlin et al . , 2019 ) , and GPT2 ( Radford et al . , 2019 ) , we modify the traditional attention strategies slightly to ï¬t our problem .
Speciï¬cally , for the input , we ï¬rst obtain the representations by summing all the embeddings of the input tokens and symbols , as shown in the red solid box of Figure 2 : H0 t = Ewt+Ect+Ept+Est+Egt(6)where 0is the layer index and tis the state index .
Eis the embedding vector for input .wt is the real token at position t.c , p , andsare three pre - deï¬ned symbols .
gis the global position index same as position symbols used in Transformer ( Vaswani et al . , 2017 ) .
Moreover , the state at time tneed to know some future information to grasp the global sequence dynamic information .
For example , the model may want to know if it should close the decoding progress by generating the last word and a punctuation character to end the sentence .
To represent the global dynamic information , we introduce another variable F0by only summing the pre - deï¬ned symbols as shown in the blue dash box of Figure 2 : F0 t = Ect+Ept+Est ( 7 ) After processing the input , two blocks of attention mechanisms are introduced to conduct the feature learning procedure .
The ï¬rst block is a masking multi - head self - attention component , and the second block is named global multi - head attention .
Masking Multi - Head Self - Attention : C1 t = LN  FFN(C1 t ) + C1 t C1 t = LN  SLF - ATT(Q0 t;K0 t;V0 t ) + H0 t Q0 = H0WQ K0;V0 = H0WK;H0WV ( 8) where SLF - ATT(),LN( ) , and FFN( ) represent self - attention mechanism , layer normalization , and feed - forward network respectively .
Note that we only use the states whose indices tas the attention context .
After obtaining C1 tfrom Equation ( 8) , we feed it into the second attention block to capture the global dynamic information from F0 .
Global Multi - Head Attention : H1 t = LN  FFN(H1 t ) + H1 t H1 t = LN  GLOBAL -ATT(Q1
t;K1;V1 )
+ C1 t Q1 = C1WQ K1;V1 = F0WK;F0WV ( 9 ) We can observe that all the context information fromF0are considered .
This is the reason why we name it as â€œ global attention â€ and why the input real token information Ewtis NOT considered .
Then
746the calculation of the uniï¬ed ï¬rst model layer is ï¬nished .
We can iteratively apply these two attention blocks on the whole Lmodel layers until obtain the ï¬nal representations HL .
Note that His renewed layerly , however the global variable F0is ï¬xed .
Finally , the training objective is to minimize the negative log - likelihood over the whole sequence : Lnll= nX t=1logP(ytjy < t ) ( 10 ) 3.3 Pre - training and Fine - tuning Although our framework can be trained purely on the training dataset of the target corpus , usually the scale of the corpus is limited .
For example , there are only about 150 samples in the corpus of Shakespeare â€™s Sonnets ( Shakespeare , 2000 ) .
Therefore , we also design a pre - training and ï¬ne - tuning framework to further improve the generation quality .
Recall that in the task deï¬nition in Section 2 , we claim that our model owns the ability of reï¬ning and polishing .
To achieve this goal , we adjust the masking strategy used in BERT ( Devlin et al . , 2019 ) to our framework according to our deï¬nitions .
Speciï¬cally , we randomly ( say 20 % ) select partial of the original content and keep them not changed when building the format symbols
C.
For example , we will get a new symbol set C0for
the example sentences : C0 = fc0 ; c0 ; c0 ; love ; c 1;h = si bends ; c 0 ; c0 ; c0 ; c0 ; remove ; c 1;h = si;heosig where â€œ love â€ , â€œ bends â€ and â€œ remove â€ are kept in the formatC0 .
After the pre - training stage , we can conduct the ï¬ne - tuning procedure directly on the target corpus without adjusting any model structure .
3.4 Generation We can assign any format and rhyming symbols C to control the generation .
Given C , we will obtain PandSautomatically .
And the model can conduct generation starting from the special token hbosiiteratively until meet the ending marker heosi .
Both beam - search algorithm ( Koehn , 2004 ) and truncated top - k sampling ( Fan et al . , 2018 ; Radford et
al . , 2019 ) method are utilized to conduct the decoding.4 Experimental Setup 4.1 Settings The parameter size of our model are ï¬xed in both the pre - training stage and the ï¬ne - tuning stage .
The number of layers L= 12 , and hidden size is 768 .
We employ 12 heads in both the masking multihead self - attention block and the global attention block .
Adam ( Kingma and Ba , 2014 ) optimization method with Noam learning - rate decay strategy and 10,000 warmup steps is employed to conduct the pre - training .
4.2 Datasets We conduct all the experiments on two collected corpus with different literary genres : SongCi and Sonnet , in Chinese and English respectively .
The statistic number are shown in Table 3 .
We can see that Sonnet is in small size since we only utilize the samples from the Shakespeare â€™s Sonnets ( Shakespeare , 2000 ) .
Since SongCi and Sonnet are in different languages , thus we conduct the pre - training procedure on two large scale corpus in the corresponding languages respectively .
For Chinese , we collect Chinese Wikipedia ( 1700 M Characters ) and a merged Chinese News ( 9200 M Characters ) corpus from the Internet .
We did not conduct the word segmenting operations on the Chinese datasets , which means that we just use the characters to build the vocabulary , and the size is 27681 .
For English , same as BERT , we employ English Wikipedia ( 2400 M words ) and BooksCorpus ( 980 M words )
( Zhu et al . , 2015 ) to conduct the pre - training .
We did not use BPE operation ( Sennrich et al . , 2015 ) on this corpus considering the format controlling purpose .
We keep the most frequent 50,000 words to build the vocabulary .
4.3 Evaluation Metrics Besides PPL andDistinct ( Li et al . , 2016 ) , we also tailor - design several metrics for our task to conduct the evaluation for format , rhyme , and sentence integrity .
Format Assume that there are msentences deï¬ned in the format C = fCs 1;Cs 2;:::;Cs mg , and the generated results YcontainsnsentencesY= fYs 1;Ys 2;:::;Ys ng .
Without loss of generality , we alignCandYfrom the beginning , and calculate the format quality according to the following rules : ( 1 ) the length difference jjCs ij jYs ijj ; ( 2 ) the punctuation characters must be same .
For SongCi , we let= 0 and rule ( 2 ) must be conforming .
747ModelPPL # Diversity ( Distinct ) " VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 S2S 19.61 20.43 75.35 2.48 98.35 36.23 GPT2 148.11 104.99 - - - GPT2 w/ Fine - tuning 18.25 17.00 73.87 2.57 96.07 33.92 SongNet ( only Pre - training ) 24.41 16.23 74.84 4.59 95.09 54.98 SongNet ( only Fine - tuning ) 12.75 14.73 75.96 2.69 97.59 37.26 SongNet 11.56 12.64 75.04 2.66 97.29 36.78 ModelFormat " Rhyme"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 S2S 44.32 38.16 53.80 52.27 8.302.06 GPT2 w/ Fine - tuning 35.70 35.20 53.48 52.50 45.9220.12 SongNet ( only Pre - training ) 29.12 29.46 53.77 53.13 30.9814.06
SongNet ( only Fine - tuning ) 99.81 99.83 79.23 78.63 2.140.10
SongNet 99.88 99.89 73.21 72.59 1.770.16 Table 1 : Automatic evaluation results on SongCi ModelPPL # Diversity ( Distinct ) " VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 GPT2 w/ Fine - tuning 31.47 31.03 73.87 2.57 96.07 33.92 SongNet ( only Pre - training ) 28.56 28.07 49.92 25.14 85.35 65.70 SongNet ( only Fine - tuning ) 34.62 34.53 42.31 4.96 90.76 47.26 SongNet 27.46 27.63 43.01 10.43 80.06 56.14 ModelFormat " Rhyme"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 GPT2 w/ Fine - tuning 2.03 1.91 5.20 6.24 15.773.63
SongNet ( only Pre - training ) 99.99 99.99 3.93 4.01 15.282.04 SongNet ( only Fine - tuning ) 99.25 99.99 7.50 7.41 18.862.59 SongNet 98.73 98.73 11.46 11.41 11.863.01 Table 2 : Automatic evaluation results on Sonnet Corpus # Train # Dev # Test # V ocab SongCi 19,244 847 962 5310 Sonnet 100 27 27 2801 Table 3 : Statistics of the datasets SongCi and Sonnet .
For Sonnet , we relax the condition where we let = 1 and ignore rule ( 2 ) .
Assume that the number of format - correct sentences is n0 , then we can obtain Precision p = n0 = n , Recallr = n0 = m , and F1 - measure .
We report both the Macro - F1 and Micro - F1 in the results tables .
Rhyme For SongCi , usually , there is only one group of rhyming words in one sample .
As the example shown in Table 1 , the pronunciation of the red rhyming words are â€œ zhu â€ , â€œ y Â¨u â€ , â€œ du â€ , and â€œ gu â€ respectively , and the rhyming phoneme is â€œ u â€ .
For the generated samples , we ï¬rst use the toolpinyin4to get the pronunciations ( PinYin ) of the words in the rhyming positions , and then conduct the evaluation .
For Shakespeare â€™s Sonnets corpus , the rhyming rule is clear â€œ ABAB CDCD EFEF GG â€ and there are 7 groups of rhyming tokens .
For the generated samples , we employ the CMU Pronouncing Dictionary5(Speech@CMU , 1998 ) to obtain the phonemes of the words in the rhyming positions .
For example , the phonemes for word â€œ asleep â€ and â€œ steep â€ are [ â€™ AH0 â€™ , â€™S â€™ , â€™ L â€™ , â€™ IY1 â€™ , â€™ P â€™ ] and [ â€™S â€™ , â€™ T â€™ , â€™ IY1 â€™ , â€™ P â€™ ] respectively .
And then we can conduct the evaluation by counting the overlapping units from both the original words and the extracted phonemes group by group .
We report the Macro - F1 and Micro - F1 numbers in the results tables as well .
Integrity Since the format in our task is strict and 4http://github.com/mozillazg/python-pinyin 5http://www.speech.cs.cmu.edu/cgi-bin/cmudict
748ModelPPL # Diversity ( Distinct ) " VAL TEST MA - D-1 M I - D-1 MA - D-2 M I - D-2 SongNet 12.75 14.73 75.96 2.69 97.59 37.26 SongNet - GRU 16.52 20.49 74.73 1.77 98.30 28.98 SongNet w/o C 13.51 15.38 75.42 2.48 97.36 34.85 SongNet w/o P 14.16 17.16 73.73 2.56 97.52 34.82
SongNet w/ inverse - P 13.40 15.13 74.95 2.54 97.76 35.65 SongNet w/o S 13.23 15.44 75.38 2.74 97.31 37.50 ModelFormat " Rhyme"Integrity#MA - F1 M I - F1 MA - F1 M I - F1 SongNet 99.81 99.83 79.23 78.63 2.140.10
SongNet - GRU 98.99 98.99 52.13 50.93 3.281.67 SongNet w/o C 84.73 85.39 78.59 78.24 1.770.53 SongNet w/o P 99.61 99.59 67.85 67.29 3.330.18
SongNet w/ inverse - P 99.68 99.69 65.89 65.43 2.240.21 SongNet w/o S 99.84 99.86 80.43 80.13 1.990.10 Table 4 : Ablation analysis on SongCi rigid
, thus the number of words to be predicted is also pre - deï¬ned .
Our model must organize the language using the limited positions , thus sentence integrity may become a serious issue .
For example , the integrity of â€œ love is not love .
h = si â€ is much better thanâ€œlove is not the .
h = si â€ .
To conduct the evaluation of sentence integrity , we design a straightforward method by calculating the prediction probability of the punctuation characters beforeh = sigiven the preï¬x tokens : Integrity = 2 1 jYjjYjP i=1log(P(yi puncjyi 0;yi 1;:::;yi < punc ) )
( 11 ) whereYis the generated sequence of sentences .
Smaller integrity metric value indicates higher sentence quality .
To achieve this goal , we conduct pre - trainings for two GPT2 ( Radford et al . , 2019 ) models on the large scale Chinese corpus and English corpus respectively .
Then we utilize the GPT2 models to conduct the evaluation for sentence integrity .
Human Evaluations For SongCi , we sampled 50 samples for 25 CiPais .
For Sonnet , the whole 27 samples in the test set are selected for human evaluation .
We recruit three helpers to score the Relevance , Fluency , and Style .
The rating criteria are as follows : Relevance : +2 : all the sentences are relevant to the same topic ; +1 : partial sentences are relevant ; 0 : not relevant at all .
Fluency : +2 : ï¬‚uent;+1 : readable but with some grammar mistakes ; 0 : unreadable .
Style : +2 : match with SongCi orSonnet genres ; +1 : partially match ; 0 : mismatch .
4.4 Comparison Methods S2SSequence - to - sequence framework with attention mechanism ( Bahdanau et al . , 2014 ) .
We regard the format and rhyme symbols Cas the input sequence , and the target as the output sequence .
GPT2
We ï¬ne - tune the GPT2 models ( the pretraining versions are used for sentence integrity evaluation ) on SongCi and Sonnet respectively .
SongNet Out proposed framework with both the per - training and ï¬ne - tuning stages .
We also conduct ablation analysis to verify the performance of the deï¬ned symbols as well as the variants of model structures .
SongNet ( only pre - tuning )
Without the ï¬netuning stage .
SongNet ( only ï¬ne - tuning )
Without the pretraining stage .
SongNet - GRU Employ GRU ( Cho et al . , 2014 ) to replace Transformer as the core structure .
SongNet w/o C Remove the format and rhyme symbols C. SongNet w/o P Remove the intra - position symbolsP. SongNet w/o S Remove the sentence segment symbolsS. SongNet
w/ inverse - P Arrange the intraposition indices in ascending order instead of the descending order .
749 Figure 3 : Parameter tuning of kon the metrics of Rhyme , Integrity , and Micro - Dist-2 .
Model Cases of Generated Results SongNet - SongCi CiPai : Zhe Gu Tian , Format : 7 . 7 . 7 , 7 . 3 , 3 . 7 . 7 , 7 .
â‰–ãšœã¨±äœ³ã”¤â«‘ã±„(qian)È¼á´›æŸá³¿æ˜ã”¤ä†¸ã–•(nuan)È¼ã±¶ãŸŸæ—µáµ°ã––æ¢˜ãªŠ(can)æ¼“æ˜±æ–ã˜©ã²‡ä¶¡ã¯©ã· (man)È¼ã”¤á´Œäª (guan)æ¼“á¶¹á¹”å»›(yuan)È¼ã­ â ³ ã“¦ ã“¤ã´„ã¶©á¸³(ban)È¼ã¨±âƒ¬ã¡»á´‰ã‘¯å‹áµ¥æ¼“â‰³á´¹ã¥æ©ã“Ÿå£„á¸³(ban)È¼ CiPai : Bu Suan Zi , Format : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 .
ã’¯ã˜‡ ãˆ â´—ã“‹æ¼“ã––å‰ˆå—¨âƒƒã¡™(chu)È¼ â › â‰‰æµã¹¡â‰€á¶‹æ”æ¼“äºâµ”ã½®å†° âŒ (tu)È¼á¹” â ƒ ä¨šâŸ¯ãªŠæ¼“ã•’ä¦–æŸæ—§(yu)È¼ä‡«åª·â«‘ã„á¸³ â¬ æ¨æ¼“æ¢˜ â˜§ ä£Šâ‰‚ã›°(zhu)È¼
CiPai : Self - Defined , Format : 3 , 3 , 5 . 3 , 3 , 5 . 7 , 7 . ä»Ÿ â®¨ á´¬æ¼“ã±€ã¬³ â • æ¼“â„ªã˜ˆ â¬ âŸµ â ¨ (tian)È¼åƒ©æ˜›ã´„æ¼“ä‡«ã’–å†²æ¼“å¬€ã‘¡âµµæŸá·˜(xian)È¼ â › áµ„âƒˆäá³¿ã—± ã€€ æ¼“ã˜‡ â¢ å†°â¹°á¸»å†° â˜… (yuan)È¼ CiPai : Self - Defined , Format : 9 . 9 . 9 . 9 .
æ—§ã°‘æ·ƒã¯ˆä®»ä®» ä·… á¹›â«‘(han)È¼å²‰ã¬³å¡¾ã™¤ã“µå†åƒ©ã´„æ“±(xian)È¼ã©‹ä¨á³¿ã™®æ‘¾â°æ‚ˆæ‚‘æ“³(jian)È¼ã”¤âŠºá´Œ âœ© â«ºã¥ ä·” å„Œ â­° (shan)È¼ SongNet - Sonnet how do you hold such a thing like this , \ when my eyes are so not black ?
\
but how can i show myself , so strange , \ that all this black is white ?
where am i to hide this from my eyes , \ from this white mine eyes   all fals , \ where is the good fortune , in me , \ that hath no exc use , no excuse ?
what is that which can mask the true love \ and for whom is this   true love more ?
\ the one , which shall save the poor my eye , \ from the false truth of my judgment ?
what lies , for when you are not that , \ no one in this and that   can see me lies !
Table 5 : Cases of the generated results for SongCi and Sonnet respectively .
For SongCi , the number in Format ( e.g. , 3,5,7 ) denotes the number of tokens in one sentence .
The rhyming words are labeled in red color and italic font following is the Pinyin .
( Since cases are provided to conï¬rm the format consistency , thus we did not conduct translation for the Chinese samples .
Translation for Chinese poetry is also a challenging task . )
Model Cases of Generated Results Given the Formats with Partial Content SongNet - SongCi CiPai : Bu Suan Zi , Format : 5 , 5 . 7 , 5 . 5 , 5 . 7 , 5 .
Format C æ¼¡
_ _
_
_
_
æ¼“ _ _
_
_ â„¯È¼
_ _
_ _
_
_
_
æ¼“ _ _
_
_
á»È¼ _ _
_
_
_
æ¼“ _ _
_ ã†¤È¼ _ _
_ _
_
_
_
æ¼“ _ _
_
_
ä¨È¼ ( 1)æŸã–•åŠ¹âŸ¯å‡¥æ¼“â‹‡ã”®âµ³ã“µ â„¯È¼æ‘¾ä„°ã›²å…±á´ˆ â„… æƒ‹æ¼“ â ™ â¬ á´¹ã”¤ á»È¼â° â¬ âµ³ã“µå†æ¼“â¿® âº– å†°ã“µ ã†¤È¼á¶ˆá¸»æ³ âºƒ â¤â·šã™¤æ¼“ã©¤ã©¤æ–ã”¤ ä¨È¼ ( 2)ã”¤ã™¤ã”¤â‹‡âŠºæ¼“å†°â¹°âƒŸã¯¡ â„¯È¼æ“§ â • ä·¾ ã™§ã›²åŒ¦ã°‘æ¼“ã¶©ã¤á¶¹á¶¹ á»È¼æ“§ â • á´›æŸæ¥«æ¼“á¸»ã“¦ã“µæ¢˜ ã†¤È¼á¹… â¼© ã‚ã™ã•™ã“µäºæ¼“â‚¶åŒ¼ã“Ÿá¶¹ ä¨È¼ Format C æ¼¡_æ—§ _ _
_
æ¼“ _ _
_
_ â„¯È¼
_ _
_ _
_
_
â‚¯ æ¼“ _ _
_
_
á»È¼ _ _
_
_ ã”¤æ¼“ _
_ ã”¤_ã†¤È¼
_
_
â­° å†° _ _
_
æ¼“ _ _
_
_ ä¨È¼ ( 1)ã”¤æ—§ä¦å»åŒ¤æ¼“ã›²ã––æ“§â³¶ â„¯È¼âªªãª¾ã©¤åº†å´â«‘ â‚¯ æ¼“ä•½â¦™äã”¤ á»È¼ã©¢ã“¤ã¿—ã•³ ã”¤æ¼“å†°æ—½ã”¤æŸã†¤È¼á³¿ã¾¸ â­° å†°æ‚ˆä˜»ã”æ¼“â‰‰á¼™æ”âµ± ä¨È¼ ( 2)æ—©æ—§â¸ƒå¹ºã–•æ¼“ã’¯ã²§ ä·¾ ã¯¡ â„¯È¼ã¡»á´‰â«¸æ™¡ãµ¾ä»Ÿ â‚¯ æ¼“á³¿ â › æŸå†° á»È¼ã•’ã“¤ã¿—æ‘¾ ã”¤æ¼“ä™ å±¶ã”¤âª´ã†¤È¼ãš”ä‘“ â­° å†°åŒ¼â‹µâŸ¯æ¼“á´Œã”®ã¥æ©
ä¨È¼ SongNet - Sonnet _ _
_
_
with _ hearts , _ _
_
lacking _
_ dead ; _ _
_ love _ _
_ _
_
_ parts , and _ _
_ _
_
_ buried .
_ many _
_ _
_ tear , hath _
_
_
_
_
_
_
_ eye , _ _
_ _
_ _
_ now appear , _ _
_ _
_ _
_ thee lie !
_ _
_ _
_ buried _
_ live , _ _
_
_ of _ _
gone , _ _
_ parts _ _
_ _
_ give , _ _
_ _
_
_
thine alone : _ _
_ _
_ _
_ view _ thee , _ _
_ _
_ _
_
all _ _
_
me .though all thy love with thy hearts , thou still are lacking of my dead ;   if thy love love is lost to your love and parts ,   and yet mine own heart can be buried .  
so many are ill or in tear , hath not this time that we will make their eye , for that which lies not well hath now appear , no longer nor the world that holds thee lie !  
for if it would be buried in my live ,   or by the earth ofmine was gone ,   then my own parts as my body and mine give , may not be so far beyond thine alone : so far   as thee and this world view find thee , then mine life be far enough from allthee and no me .  
Table 6 : Cases of the generated results given the formats with partial pre - deï¬ned content .
Format token â€œ â€ needs to be translated to real word token .
5 Results and Discussions 5.1 Results Please note that we mainly employ top- ksampling method ( Fan et al . , 2018 ; Radford et al . , 2019 ) to conduct the generation , and we let k= 32 here .
The parameter tuning of kis described in Section 5.3 .
Table 1 and Table 2 depict the experimental results of SongNet as well as the baseline methods S2S and GPT2 on corpus SongCi and Sonnet respectively .
It is obvious that our pre - training and ï¬ne - tuning framework SongNet obtain the best per - formance on most of the automatic metrics .
Especially on the metric of Format accuracy , SongNet can even obtain a 98%+ value which means that our framework can conduct the generation rigidly matching with the pre - deï¬ned formats .
On the metric of PPL , Rhyme accuracy , and sentence integrity , SongNet also performs signiï¬cantly better in a large gap than the baseline methods such as S2S and GPT2 as well as the model variants only with the pre - training or ï¬ne - tuning stage .
Another observation is that some of the results on corpus Sonnet are not as good as the results
750Model Relevance Fluency Style SongNet - SongCi 1.36 1.45 2.00 SongNet - Sonnet 0.58 0.42 0.83 Table 7 : Human evaluation results .
on SongCi .
The main reason is that Sonnet only contains 100 samples in the training set as shown in Table 3 .
Therefore , the model can not capture sufï¬cient useful features especially for the rhyming issue .
5.2 Ablation Analysis We conduct ablation study on corpus SongCi and the experimental results are depicted in Table 4 .
It should note that all the models are purely trained on SongCi corpus without any pre - training stages .
From the results we can conclude that the introduced symbols C , P , andSindeed play crucial roles in improving the overall performance especially on the metrics of format , rhyme , and sentence integrity .
Even though some of the components can not improve the performance simultaneously on all the metrics , the combination of them can obtain the best performance .
5.3 Parameter Tuning Since we employ top- ksampling as our main decoding strategy , thus we design several experiments to conduct the parameter tuning on k.
We let k to be 1 , 5 , 10 , 20 , 50 , 500 respectively .
We also provide the beam - search ( beam=5 ) results for comparing and reference .
The parameter tuning results are depicted in Figure 3 .
From the results we can observe that large kcan increase the diversity of the results signiï¬cantly .
But the Rhyme accuracy and the sentence integrity will drop simultaneously .
Therefore , in the experiments we let k= 32 to obtain a trade - off between the diversity and the general quality .
5.4 Human Evaluation For human evaluation , we just conduct the judging on the results generated by our ï¬nal model SongNet .
From the result we can observe that the results on corpus SongCi is much better than the ones on corpus Sonnet , which is because the corpus scale is different .
And the the small scale also lead to dramatically dropping on all the metrics.5.5 Case Analysis Table 5 depicts several generated cases for SongCi and Sonnet respectively .
For SongCi , the formats ( CiPai ) are all cold - start samples which are not in the training set or even newly deï¬ned .
Our model can still generate high quality results on the aspects offormat , rhyme as well as integrity .
However , for corpus Sonnet , even though the model can generate 14 lines text , the quality is not as good as SongCi due to the insufï¬cient training - set ( only 100 samples ) .
We will address this interesting and challenging few - shot issue in the future .
In addition , we mentioned that our model has the ability of reï¬ning and polishing given the format Cwhich contains some ï¬xed text information .
The examples of the generated results under this setting are shown in Table 6 , which show that our model SongNet can generate satisfying results especially on SongCi .
6 Conclusion We propose to tackle a challenging task called rigid formats controlled text generation .
A pre - training and ï¬ne - tuning framework SongNet is designed to address the problem .
Sets of symbols are tailordesigned to improve the modeling performance for format , rhyme , and sentence integrity .
Extensive experiments conducted on two collected corpora demonstrate that our framework generates significantly better results in terms of both automatic metrics and human evaluations given arbitrary cold start formats .
References Dzmitry Bahdanau , Kyunghyun Cho , and Yoshua Bengio .
2014 .
Neural machine translation by jointly learning to align and translate .
arXiv preprint arXiv:1409.0473 .
Kyunghyun Cho , Bart van Merrienboer , Caglar Gulcehre , Dzmitry Bahdanau , Fethi Bougares , Holger Schwenk , and Yoshua Bengio .
2014 .
Learning phrase representations using rnn encoder â€“ decoder for statistical machine translation .
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1724 â€“ 1734 .
Zihang Dai , Zhilin Yang , Yiming Yang , William W Cohen , Jaime Carbonell , Quoc V Le , and Ruslan Salakhutdinov .
2019 .
Transformer - xl : Attentive language models beyond a ï¬xed - length context .
arXiv preprint arXiv:1901.02860 .
751Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 .
Bert : Pre - training of deep bidirectional transformers for language understanding .
In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , pages 4171â€“4186 .
Angela Fan , Mike Lewis , and Yann Dauphin .
2018 .
Hierarchical neural story generation .
In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 889â€“898 .
Jonas Gehring , Michael Auli , David Grangier , Denis Yarats , and Yann N Dauphin . 2017 .
Convolutional sequence to sequence learning .
In Proceedings of the 34th International Conference on Machine Learning - Volume 70 , pages 1243â€“1252 .
JMLR .
org .
Diederik P Kingma and Jimmy Ba . 2014 .
Adam : A method for stochastic optimization .
arXiv preprint arXiv:1412.6980 .
Philipp Koehn .
2004 .
Pharaoh : a beam search decoder for phrase - based statistical machine translation models .
In Conference of the Association for Machine Translation in the Americas , pages 115 â€“ 124 .
Springer .
Jey Han Lau , Trevor Cohn , Timothy Baldwin , Julian Brooke , and Adam Hammond .
2018 .
Deep - speare : A joint neural model of poetic language , meter and rhyme .
arXiv preprint arXiv:1807.03491 .
Jiwei Li , Michel Galley , Chris Brockett , Jianfeng Gao , and Bill Dolan .
2016 .
A diversity - promoting objective function for neural conversation models .
In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pages 110â€“119 .
Piji Li .
2020 .
An empirical investigation of pre - trained transformer language models for open - domain dialogue generation .
arXiv preprint arXiv:2003.04195 .
Piji Li , Wai Lam , Lidong Bing , and Zihao Wang .
2017 .
Deep recurrent generative decoder for abstractive text summarization .
In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 2091â€“2100 .
Yi Liao , Yasheng Wang , Qun Liu , and Xin Jiang .
2019 .
Gpt - based generation for classical chinese poetry .
arXiv preprint arXiv:1907.00151 .
Alec Radford , Karthik Narasimhan , Tim Salimans , and Ilya Sutskever . 2018 .
Improving language understanding with unsupervised learning .
Technical report , Technical report , OpenAI .
Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 .
Language models are unsupervised multitask learners .
OpenAI Blog , 1(8).Alexander M Rush , Sumit Chopra , and Jason Weston .
2015 .
A neural attention model for abstractive sentence summarization .
In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 379â€“389 .
Abigail See , Peter J Liu , and Christopher D Manning .
2017 .
Get to the point : Summarization with pointergenerator networks .
In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 1073 â€“ 1083 .
Abigail See , Aneesh Pappu , Rohun Saxena , Akhila Yerukola , and Christopher D Manning .
2019 .
Do massively pretrained language models make better storytellers ?
arXiv preprint arXiv:1909.10705 .
Rico Sennrich , Barry Haddow , and Alexandra Birch . 2015 .
Neural machine translation of rare words with subword units .
arXiv preprint arXiv:1508.07909 .
William Shakespeare .
2000 .
Shakespeare â€™s sonnets .
Yale University Press .
Lifeng Shang , Zhengdong Lu , and Hang Li . 2015 .
Neural responding machine for short - text conversation .
InProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Volume 1 : Long Papers ) , pages 1577â€“1586 . Speech@CMU .
1998 .
Carnegie - mellon university pronouncing dictionary for american english .
Version 0.7b .
Available at [ http://www.speech.cs.cmu.edu/cgi-bin/cmudict ] .
Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Åukasz Kaiser , and Illia Polosukhin . 2017 .
Attention is all you need .
In Advances in neural information processing systems , pages 5998â€“6008 .
Oriol Vinyals and Quoc Le . 2015 .
A neural conversational model .
arXiv preprint arXiv:1506.05869 .
Zhilin Yang , Zihang Dai , Yiming Yang , Jaime Carbonell , Ruslan Salakhutdinov , and Quoc V Le . 2019 .
Xlnet :
Generalized autoregressive pretraining for language understanding .
arXiv preprint arXiv:1906.08237 .
Xingxing Zhang and Mirella Lapata .
2014 .
Chinese poetry generation with recurrent neural networks .
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 670â€“680 .
Yukun Zhu , Ryan Kiros , Rich Zemel , Ruslan Salakhutdinov , Raquel Urtasun , Antonio Torralba , and Sanja Fidler .
2015 .
Aligning books and movies : Towards story - like visual explanations by watching movies and reading books .
In Proceedings of the IEEE international conference on computer vision , pages 19 â€“ 27 .
