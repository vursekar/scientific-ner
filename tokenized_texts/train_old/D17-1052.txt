Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 502–510 Copenhagen , Denmark , September 7–11 , 2017 .
c  2017 Association for Computational Linguistics Sentiment Lexicon Construction with Representation Learning Based on Hierarchical Sentiment Supervision Leyi Wang and Rui Xia∗ School of Computer Science & Engineering Nanjing University of Science & Technology , China leyiwang.cn@gmail.com , rxia@njust.edu.cn Abstract Sentiment lexicon is an important tool for identifying the sentiment polarity of words and texts .
How to automatically construct sentiment lexicons has become a research topic in the ﬁeld of sentiment analysis and opinion mining .
Recently there were some attempts to employ representation learning algorithms to construct a sentiment lexicon with sentiment - aware word embedding .
However , these methods were normally trained under documentlevel sentiment supervision .
In this paper , we develop a neural architecture to train a sentiment - aware word embedding by integrating the sentiment supervision at both document and word levels , to enhance the quality of word embedding as well as the sentiment lexicon .
Experiments on the SemEval 2013 - 2016 datasets indicate that the sentiment lexicon generated by our approach achieves the state - of - the - art performance in both supervised and unsupervised sentiment classiﬁcation , in comparison with several strong sentiment lexicon construction methods .
1 Introduction Sentiment lexicon is a set of words ( or phrases ) each of which is assigned with a sentiment polarity score .
Sentiment lexicon plays an important role in many practical sentiment analysis and opinion mining tasks .
There were some manually annotated universal sentiment lexicons such as General Inquireer ( GI ) and HowNet .
However , due to the ubiquitous domain diversity and absence of domain prior knowledge , the automatic construction technique for domain - speciﬁc sentiment lex∗The corresponding author of this paper.icons has become a challenging research topic in the ﬁeld of sentiment analysis and opinion mining ( Wang and Xia , 2016 ) .
The early work employed unsupervised learning for sentiment lexicon construction .
They normally labelled a set of seed words at ﬁrst , and then learned the polarity of each candidate word , based on either word conjunction relations ( e.g. , constellation and transition in texts ) ( Hatzivassiloglou and McKeown , 1997 ) , or the word co - occurrence information ( such as pointwise mutual information , PMI ) ( Turney , 2002 ) , between the candidate word and the seed words .
However , the unsupervised manner showed limited effect in sentiment prediction , and the performance greatly depends on the quality of the seed words .
To fully exploit the sentiment labeling information in texts , a series of supervised learning methods was further proposed to learn the sentiment lexicons .
For example , Mohammad et al .
( 2013 ) proposed to construct sentiment lexicons by calculating PMI between the word and the distantly supervised sentiment labels ( such as emoticons ) in tweets and the word ’s sentiment orientation ( SO ) .
The resulting lexicons obtained the best results in SemEval 2013 .
More advanced representation learning models were also utilized , with the aim to construct the sentiment lexicons with efﬁcient word embeddings ( Tang et al . , 2014a ; Hamilton et al . , 2016 ; V o and Zhang , 2016 ) .
The traditional representation learning framework such as Word2Vec only captures the syntactic information in the texts , but ignores the sentiment relations between words .
Therefore , some researchers attempted to add sentiment supervision into the network structure , in order to train a sentimentaware word embedding .
For example , Tang et al . ( 2014a ) exploited a dedicated neural architecture to integrate document - level sentiment supervision and the syntactic knowledge for representation502
learning .
The sentiment - aware word embedding is then used to construct a sentiment lexicon .
V o and Zhang ( 2016 ) proposed to learn a two - dimensional sentiment representation based on a simple neural network .
The sentiment lexicons generated by their approach obtained better performance to predict the tweet sentiment labels , in comparison with the PMI - based method ( Mohammad et al . , 2013 ) .
Although these supervised learning methods can to some extent exploit the sentiment labeling information in the texts and can learn a sentiment - aware word embedding , the manner of using document - level sentiment supervision suffers from some complex linguistic phenomena such as negation , transition and comparative degree , and hence unable to capture the ﬁne - grained sentiment information in the text .
For example , in the following tweet “ Four more fake people added me .
Is this why people do n’t like Twitter ? :(
” , the document - level sentiment label is negative , but there is a positive word “ like ” in the text .
In representation learning , the embeddings of words are summed up to represent the document , and the word “ like ” will be falsely associated with the negative sentiment label .
Such linguistic phenomena occur frequently in review texts , and makes sentiment - aware word representation learning less effective .
To address this problem , in this paper , we propose a new representation learning framework called HSSWE , to learn sentiment - aware word embeddings based on hierarchical sentiment supervision .
In HSSWE , the learning algorithm is supervised under both document - level sentiment labels and word - level sentiment annotations ( e.g. , labeling “ like ” as a positive word ) .
By leveraging the sentiment supervision at both document and word level , our approach can avoid the sentiment learning ﬂaws caused by coarse - grained document - level supervision by incorporating ﬁnegrained word - level supervision , and improve the quality of sentiment - aware word embedding .
Finally , following Tang et al . ( 2014a ) , a simple classiﬁer was constructed to obtain the domainspeciﬁc sentiment lexicon by using word embeddings as inputs .
The main contributions of this work are as follows : 1 .
To the best of our knowledge , this is the ﬁrstwork that learns the sentiment - aware word representation under supervision at both document and word levels .
2 . Our approach supports several kinds of wordlevel sentiment annotations such as 1 ) predeﬁned sentiment lexicon ; 2 ) PMI - SO lexicon with hard sentiment annotation ; 3 ) PMISO lexicon with soft sentiment annotation .
By using PMI - SO dictionary as word - level sentiment annotation , our approach is totally corpus - based , without any external resource .
3 .
Our approach obtains the state - of - the - art performance in comparison with several strong sentiment lexicon construction methods , on the benchmark SemEval 2013 - 2016 datasets for twitter sentiment classiﬁcation .
2 Related Work In general , sentiment lexicons construction can be classiﬁed into two categories , dictionary - based methods and corpus - based methods .
Dictionary - based methods generally integrate predeﬁned resources , such as WordNet , to construct sentiment lexicons .
Hu and Liu ( 2004 ) exploited WordNet for sentiment lexicon construction .
They ﬁrst labelled two sets of seed words by polarities , then extended the sets by adding the synonyms for each word to the same set and antonyms to the other .
For a given new word , Kim and Hovy ( 2004 ) introduced a Naive Bayes model to predict the polarities with .the synonym set obtained from WordNet as features .
Kamps et al .
( 2004 ) investigated a graph - theoretic model of WordNet ’s synonymy relation and measured the sentiment orientation by distance between each candidate word and the seed words with different polarities .
Heerschop et al .
( 2011 ) proposed a method to propagate the sentiment of seed set words through semantic relations of WordNet .
Corpus - based approaches originate from the latent relation hypothesis : “ Pairs of words that cooccur in similar patterns tend to have similar semantic and sentiment relations ” ( Turney , 2008 ) .
The primary corpus - based method made the use of PMI .
Turney ( 2002 ) built a sentiment lexicon by calculating PMI between the candidate word and seed words .
The difference of the PMI score between positive and negative seed words is ﬁnally used as the sentiment orientation ( SO ) of each candidate word ( Turney , 2002 ) .
Many variants of503
PMI were proposed afterwards , for example , positive pointwise mutual information ( PPMI ) , second order co - occurrence PMI ( SOC - PMI ) , etc .
Hamilton et al .
( 2016 ) proposed to build a sentiment lexicon by a propagation method .
The key of this method is to build a lexical graph by calculating the PPMI between words .
Instead of calculating the PMI between words , Mohammad et al .
( 2013 ) proposed to use emoticons as distant supervision and calculate the PMI between words and the distant class labels , and obtained sound performance for tweet sentiment classiﬁcation .
The latest corpus - based approaches normally utilize the up - to - date machine learning models ( e.g. neural networks ) to ﬁrst learn a sentimentaware distributed representation of words , based on which the sentiment lexicon is then constructed .
There were many word representation learning methods such as NNLM ( Bengio et al . , 2003 ) and Word2Vec ( Mikolov et al . , 2013 ) .
However , they mainly consider the syntactic relation of words in the context but ignore the sentiment information .
Some work were later proposed to deal with this problem by incorporating the sentiment information during representation learning .
For example , Tang et al .
( 2014a ) adapted a variant of skip - gram model , which can learn the sentiment information based on distant supervision .
Furthermore , Tang et al .
( 2014b ) proposed a new neural network approach called SSWE to train sentimentaware word representation .
V o and Zhang ( 2016 ) exploited a simple and fast neural network to train a 2 - dimensional representation .
Each dimension is explicitly associated with a sentiment polarity .
The sentiment - aware word representation in these methods was normally trained based on only document - level sentiment supervision .
In contrast , the learning algorithm in our approach is supervised under both document - level and wordlevel sentiment supervision .
3
Our Approach Our approach is comprised of three base modules : ( 1 ) Word - level sentiment learning and annotation ; ( 2 ) Sentiment - aware word embedding learning ; ( 3 ) Sentiment lexicon construction .
Our approach depends on document - level sentiment labels .
The tweet corpus provides a cheap way to get document - level sentiment annotation , owing to the distant sentiment supervision .
But it should be noted that our approach is feasiblefor any corpus provided with document - level sentiment labels ( not merely tweets ) .
The ﬁrst module of our method aims to learn the pseudo sentiment distribution for each word and use it as word - level sentiment annotations to supervise word embedding learning .
In the second module , we learn the sentimentaware embeddings for each word in corpus , based on hierarchical sentiment supervision .
In the last module , we construct a sentiment lexicon by using the sentiment - aware word embeddings as the basis .
3.1 Learning Word - Level Sentiment Supervision
In addition to use a pre - deﬁned sentiment lexicon for word - level annotations , we also propose to learn the word - level sentiment supervision , based on PMI and SO .
( 1 ) PMI and SO Given a corpus with document - level class labels .
We ﬁrst compute the PMI score between each wordtand two class labels PMI ( t,+ ) = logp(+|t ) p(+ ) , ( 1 ) PMI ( t,− ) = logp(−|t ) p(− ) , ( 2 ) where + and−denote the positive and negative document - level class labels , respectively .
Second , we compute the SO score for each wordt : SO(t )
= PMI ( t,+)−PMI ( t,−).(3 ) We call{t , SO ( t)}as PMI - SO dictionary .
The PMI - SO dictionary was widely used as a corpusbased sentiment lexicon for sentiment classiﬁcation .
By contrast , in our approach , it is the ﬁrst step to learn the sentiment - aware word representation .
Our approach supports two kinds of wordlevel sentiment annotations : 1 ) PMI - SO dictionary with hard sentiment annotation ; 2 ) PMI - SO dictionary with soft sentiment annotation .
The word - level sentiment annotation is represented as [ ˆp(−|t),ˆp(+|t ) ] .
We employ the following two ways to obtain [ ˆp(−|t),ˆp(+|t ) ] .
( 2 ) PMI - SO lexicon with hard sentiment annotation504
Notations Description et
The embedding of word t de The document representation of d bt
The bias of word - level softmax layer bd The bias of document - level softmax layer θt Weight of word - level softmax layer θd Weight of document - level softmax layer p(c|et )
The sentiment distribution of word tpredicted by our model p(c|de )
The sentiment distribution of document d predicted by our model ˆp(c|t ) The word - level sentiment annotation of wordtwith respect to class c ˆp(c|d ) The document - level sentiment annotation of documentdwith respect to class c Table 1 : The parameters used in our neural network .
“ Hard sentiment annotation ” indicates that [ ˆp(−|t),ˆp(+|t)]is a two - dimensional one - hot representation , where the annotation of words is given by the class labels : [ ˆp(−|t),ˆp(+|t ) ]
=   [0,1 ] , ifSO(t)>0 [ 1,0 ] , ifSO(t)<0 random{[1,0]or[0,1]},otherwise .
( 4 ) ( 3 ) PMI - SO lexicon with soft sentiment annotation “ Soft sentiment annotation ” means that the annotation is given by the probability of two sentiment polarities , rather than the class label .
We ﬁrst use the sigmoid function to map the SO score to the range of a probability , and then deﬁne [ ˆp(−|t),ˆp(+|t ) ]
= [ 1−σ(SO(t)),σ(SO(t ) ) ] ( 5 ) as the PMI - SO soft sentiment distribution of the wordt .
3.2 Learning Sentiment - aware Word Representation under Hierarchical Sentiment Supervision
Till now we have obtained both document and word - level sentiment annotations , in the next step , we propose a neural network framework to learn the sentiment - aware word representation by integrating the sentiment supervision at both word and document granularities .
We call it “ hierarchical sentiment supervision ” .
The architecture of ourmodel is shown in Figure 1 .
We denote the corpus asD={d1,d2, ... ,d N}whereNis the size of the corpus .
Suppose dkisk - th document in D , andti represents the i - th word in a document
d.
The parameters used in our neural network are described in Table 1 .
We construct a embedding matrix C∈RV×M , of which each row represents the embedding of a word in the vocabulary , where Vis the size of the vocabulary and Mis the dimension of word embedding .
We randomly initialize each element of matrixCwith a normal distribution .
( 1 ) Word - Level Sentiment Supervision We use the word - level sentiment annotation [ ˆp(−|t),ˆp(+|t)]provided in Section 3.1 to supervise word representation learning at the word level .
For each word in document d , we map it to a continuous representation as e∈Cand feedeinto our model to predict the sentiment distribution of the input word : p(c|e ) = softmax ( θt·e+bt ) .
( 6 ) The cost function is deﬁned as the average cross entropy that measures the difference between the sentiment distribution predicted in our model and the sentiment annotations at the word level : fword=−1 TN / summationdisplay k=1 / summationdisplay t∈dk / summationdisplay c∈{+,−}ˆp(c|t ) logp(c|et ) ( 7 ) whereTis the number of words in corpus .
( 2 ) Document - Level Sentiment Supervision We use the document - level sentiment annotations to supervise word representation learning at the document level .
In order to obtain a continuous representation of a document d , we simply use the average embedding of words in dasde : de=1 |d|/summationdisplay t∈det .
( 8) We feeddeinto our model to predict the sentiment probability : p(c|de ) = softmax ( θd·de+bd ) .
( 9)505
Average Pooling Lookup layerRepresentation Layer … Output Layer PositiveNegative An Element of EmbeddingSoftmax … Input layerOperationDocument -Level Sentiment Supervision Word -Level Sentiment Supervision SoftmaxFigure 1 : The Architecture of our Neural Network .
Given a document d , represented as [ t1,t2, ... ,t n ] .
tiis thei - th word in d. Andetirepresents the embedding of the word ti .
We takede , the average embedding of [ et1,et2, ... ,e tn ] , as the representation of document d.
We get each embedding of words indas input to predict its sentiment polarities .
We also take deas input to predict the sentiment for documentdone time per epoch .
Similarly , the cost function is deﬁned as average cross entropy that measures the difference between the sentiment distribution predicted in our model and the sentiment annotation at the document level : fdoc=−1 NN / summationdisplay k=1 / summationdisplay c∈{+,−}ˆp(c|dk ) logp(c|dek ) ( 10 ) where ˆp(c|dk)is the sentiment annotation of documentdk.ˆp(c|dk )
= 1 denotes the class label of dkis positive , otherwise ˆp(c|dk ) = 0 .
( 3 ) Word and Document - Level Joint Learning In order to learn the sentiment - aware word representation at both word and document levels , we integrate the cost function of two levels in a weighted combination way .
The ﬁnal cost function is deﬁned as follows : f = αfword+ ( 1−α)fdoc ( 11 ) whereαis a tradeoff parameter ( 0≤α≤1 ) .
Theweight offword can be increased by choosing a lager value of α .
We train our neural model with stochastic gradient descent and use AdaGrad ( Duchi et al . , 2011 ) to update the parameters .
3.3 From Sentiment Representation to Sentiment Lexicon
In this part , we follow the method proposed by Tang et al .
( 2014a ) to build a classiﬁer to convert the sentiment - aware word representation learned in Section 3.2 to a sentiment lexicon .
The word representation is the input of the classiﬁer and word sentiment polarity is the output .
Firstly , we utilize the embedding of 125 positive and 109 negative seed words manually labelled by Tang et al .
( 2014a ) as training data1 .
Secondly , a variant - KNN classiﬁer is also applied to extending the seed words on a web dictionary called Urban Dictionary .
Unlike ( Tang et al . , 1http://ir.hit.edu.cn/ dytang / paper/14coling / data.zip506
Dataset # pos # negTotal SemEval2013 - train 3632 1449 5081 SemEval2013 - dev 482 282 764 SemEval2013 - test 1474 559 2033 SemEval2014 - test 982 202 1184 SemEval2015 - test 1038 365 1403 SemEval2016 - test 7059 3231 10290 Table 2 : Statistics of Evaluation Datasets 2014a ) , we did not extend the neutral words .
Thirdly , a traditional logistic regression classiﬁer is trained by using the embeddings of extended sentiment words as the inputs .
The sentiment score of a word is the difference between its positive and negative probabilities .
Finally , the sentiment lexicon can be collected by using the classiﬁer to predict the other words ’ sentiment score .
4 Experiment Study 4.1 Datasets and Settings We utilize the public distant - supervision corpus2 ( Go et al . , 2009 ) to learn our lexicons .
We set M , the dimension of embedding , as 50 .
The learning rate is 0.3 for stochastic gradient descent optimizer .
We tune the hyper - parameter αin the training process .
We evaluate the sentiment lexicons in both supervised and unsupervised sentiment classiﬁcation tasks , on the SemEval 2013 - 2016 datasets .
The statistics of evaluation datasets are shown in Table 2 .
Supervised Sentiment Classiﬁcation Evaluation : To evaluate the effect of the sentiment lexicon in supervised sentiment classiﬁcation , we report the supervised sentiment classiﬁcation performance by using some pre - deﬁned lexicon features .
We follow ( Mohammad et al . , 2013 ) to extract the lexicon features as follows : •Total count of words in the tweet score of which is greater than 0 ; •Total count of words in the tweet score of which is less than 0 ; •The sum of scores for all word great than 0 ; 2http://help.sentiment140.com/for-students•The sum of scores for all word less than 0 ; •The max score greater than 0 ; •The min score less than 0 ; •Non - zero score of the last positive word in the tweet ; •Non - zero score of the last negative word in the tweet .
We report the performance of SVM by using these lexicon features .
The LIBSVM3toolkit is used with a linear kernel and the penalty parameter is set as the default value .
The metric is F1score .
Unsupervised Sentiment Classiﬁcation Evaluation : For unsupervised sentiment classiﬁcation , we sum up the scores of all sentiment words in the document , according to the sentiment lexicon .
If the sum is greater than 0 , the document will be considered as positive , otherwise negative .
The unsupervised learning evaluation metric is accuracy .
4.2 ( External ) Comparison with Public Lexicons
We compare our HSSWE method with four sentiment lexicons generated by the related work proposed in recent years : •Sentiment140 was constructed by Mohammad et al .
( 2013 ) on tweet corpus based on PMI between each word and the emoticons .
•HIT was constructed by Tang et al .
( 2014a ) with a representation learning approach .
•NNwas constructed by V o and Zhang ( 2016 ) with a neural network method .
•ETSL refers to SemEval-2015 English Twitter Sentiment Lexicon4(Rosenthal et al . , 2015 ; Kiritchenko et
al . , 2014 ) , which is done using Best - Worst Scaling .
Note that Tang et al . ( 2014a ) , V o and Zhang ( 2016 ) used incomplete dataset of SemEval2013 in their papers .
For fair comparison , we conduct 3http://www.csie.ntu.edu.tw/ cjlin / libsvm 4http://www.saifmohammad.com/WebDocs/lexiconstoreleas eonsclpage / SemEval2015 - English - Twitter - Lexicon.zip507
Lexicon Semeval2013 Semeval2014 Semeval2015 Semeval2016 Average Sentiment140 0.7317 0.7271 0.6917 0.6809 0.7079 HIT 0.7181 0.6947 0.6797 0.6928 0.6963 NN 0.7225 0.7115 0.6970 0.6887 0.7049 ETSL 0.7104 0.7090 0.6650 0.6862 0.6926 HSSWE 0.7550 0.7424 0.6921 0.7097 0.7248
Table 3 : Supervised Evaluation for External Comparison ( F1Score )
Lexicon Semeval2013
Semeval2014 Semeval2015 Semeval2016 Average Sentiment140 0.7208 0.7416 0.6935 0.6928 0.7122 HIT 0.7566 0.7922 0.7128 0.7282 0.7474 NN 0.6903 0.7280 0.6507 0.6585 0.6819 ETSL 0.7675 0.8226 0.7505 0.7365 0.7693 HSSWE 0.7734 0.8539 0.7669 0.7206 0.7787 Table 4 : Unsupervised Evaluation for External Comparison ( Accuracy ) all the comparison experiments on the complete benchmark datasets .
Supervised Sentiment Classiﬁcation : We ﬁrst report the supervised sentiment classiﬁcation F1 score of ﬁve compared methods on the Semeval 2013 - 2016 datasets in Table 3 .
It can be seen that our HSSWE method gets the best result on all four datasets .
It outperforms Sentiment140 , HIT , NN and ETSL 1.7 , 2.8 , 1.9 , and 3.2 percentages on the average of four datasets .
The improvements are signiﬁcant according to the paired t - test .
Unsupervised Sentiment Classiﬁcation : We then report the unsupervised sentiment classiﬁcation accuracy of ﬁve methods on the Semeval 2013 - 2016 datasets in Table 4 .
In can be seen that HSSWE obtains the best performance on Semeval 2013 - 2015 .
On the Semeval 2016 dataset , it is slightly lower than ETSL .
Across four datasets , the average accuracy of HSSWE is 6.6 , 3.1 , 9.6 and 0.94 higher than Sentiment140 , HIT , NN and ETSL , respectively .
4.3 ( Internal ) Comparison within the Model
In order to further verify the effectiveness of our method and analyze which part of our model contributes the most , we carried out the internal comparison within our model .
We design the following two simpliﬁed versions of our model for comparison : •PMI - SO denotes a PMI - SO based sentiment lexicon with soft sentiment annotation learned in Section 3.1 .
•Doc - Sup denotes the neural network systemwith only document - level sentiment supervision .
It equals to HSSWE when α= 0 .
Actually , HSSWE can be viewed as a “ combination ” of PMI - SO and Doc - Sup .
In Tables 5 and 6 , we report the comparison results on supervised and unsupervised sentiment classiﬁcation respectively .
Supervised Sentiment Classiﬁcation : As is shown in Table 5 , two basic models PMI - SO and Doc - Sup show similar performance .
They have distinct superiority across different datasets .
But both are signiﬁcantly lower than HSSWE .
It shows that by combing the supervision at both document and word levels , it can indeed improve the quality of sentiment - aware word embedding and the subsequent sentiment lexicon .
Unsupervised Sentiment Classiﬁcation : As is shown in Table 6 , the conclusions are similar with that in supervised sentiment classiﬁcation : HSSWE achieves the signiﬁcantly better performance .
4.4 Word - level Sentimnt Annotation :
Hard vs. Soft In Section 3.1 , we introduce two kinds of wordlevel sentiment annotation , i.e. , soft and hard sentiment annotation .
We now compare two methods .
The results are reported in Tables 5 and 6 .
It can be seen that for supervised evaluation , HSSWE ( soft ) and HSSWE ( hard ) yield comparative performance .
HSSWE ( hard ) has slight superiority over HSSWE ( hard ) in Semeval 2013 , 2014 and 2016 , but HSSWE ( hard ) is better on Semeval2015 .
In contrast , for unsupervised evaluation , HSSWE ( soft ) is signiﬁcantly better than508
Lexicon Semeval2013
Semeval2014 Semeval2015 Semeval2016
Average PMI - SO 0.7265 0.7333 0.7008 0.6858 0.7116 Doc - Sup 0.7326 0.7302 0.6814 0.6986 0.7107 HSSWE ( soft ) 0.7550 0.7424 0.6921 0.7097 0.7248 HSSWE ( hard ) 0.7503 0.7383 0.7020 0.7061 0.7242 Table 5 : Supervised Evaluation for Internal Comparison ( F1Score ) , where HSSWE ( hard ) and HSSWE ( soft ) utilize the PMI - SO lexicon with hard sentiment annotation and soft sentiment annotation at the word level , respectively .
Lexicon Semeval2013
Semeval2014 Semeval2015 Semeval2016
Average Doc - Sup 0.7252 0.8294 0.7391 0.6859 0.7449 HSSWE ( soft ) 0.7734 0.8539 0.7669 0.7206 0.7787 HSSWE ( hard ) 0.7418 0.8395 0.7633 0.7011 0.7614 Table 6 : Unsupervised Evaluation for Internal Comparison ( Accuracy ) 0.0 0.2 0.4 0.6 0.8 1.0 alpha0.680.690.700.710.720.730.740.75Macro - F1 Score SemEval2013 SemEval2014 SemEval2015 SemEval2016 Figure 2 : HSSWE ( soft ) with different α HSSWE ( hard ) .
The average improvement is 1.7 percentage .
4.5 Tuning the Parameter α
In this section , we discuss the tradeoff between two parts of supervisions by turning the tradeoff parameterα .
Whenαis 0 , HSSWE only beneﬁts from the document - level sentiment supervision and when αis 1 , HSSWE beneﬁts from only word - level sentiment supervision .
We observe that HSSWE performs better when αis in the range of [ 0.45,0.55 ] .
By integrating two component parts of sentiment supervision , HSSWE has signiﬁcant superiority over that learned from either one .
4.6 Lexicon Analysis In order to gain more insight of our model and observe the effectiveness of the sentiment lexicon , in Table 7 we extract the positive sentimen - Words HSSWE PMI - SO Doc - Sup well 0.5740 0.5430 0.7898 better 0.5837 0.5358 ( F ) 0.8440 best 0.9455 0.6823 0.9639 ﬁt 0.2894 -0.5594 ( F ) 0.6076 unreasonable -0.2441 -0.8421
0.5275
( F ) boreddddd -0.1137 -0.7142 0.4843
( F ) sickkkk -0.3892 -0.7692 0.1323 ( F ) overplayed -0.1390 0.5000 ( F ) 0.8448 ( F ) Table 7 : Sentiment Lexicon Analysis , where score with ( F)means falsely predicted polarity or strength .
t score of some representative words learned by different methods .
The positive scores are supposed to be : best > better > well .
HSSWE captures such comparative sentiment strength but PMI - SO does not .
We further observe that in many cases where the results of PMI - SO and Doc - Sup are inconsistent ( e.g. , Doc - Sup incorrectly predicts “ unreasonable ” , “ boreddddd ” and“sickkk ” as positive words , but PMI - SO predicts them correctly ; PMI - SO incorrectly predicts “ ﬁt ” but Doc - Sup predicts it correctly . ) , HSSWE often yield the correct results .
It shows the advantages of hierarchical sentiment supervision .
HSSWE can also correct the sentiment prediction where both PMI - SO and Doc - Sup are inefﬁcient ( e.g. , “ overplayed ” ) .
5 Conclusion In this paper , we proposed to construct sentiment lexicons based on a sentiment - aware word representation learning approach .
In contrast to traditional methods normally learned based on only the document - level sentiment supervision .
We proposed word representation learning via hierarchical sentiment supervision , i.e. , under the supervi-509
sion at both word and document levels .
The wordlevel supervision can be provided based on either predeﬁned sentiment lexicons or the learned PMISO based sentiment annotation of words .
A wide range of experiments were conducted on several benchmark sentiment classiﬁcation datasets .
The results indicate that our method is quite effective for sentiment - aware word representation , and the sentiment lexicon generated by our approach beats the state - of - the - art sentiment lexicon construction approaches .
Acknowledgements The work was supported by the Natural Science Foundation of China ( No . 61672288 ) , and the Natural Science Foundation of Jiangsu Province for Excellent Young Scholars ( No . BK20160085 ) .
References Yoshua Bengio , R ´ ejean Ducharme , Pascal Vincent , and Christian Jauvin .
2003 .
A neural probabilistic language model .
Journal of Machine Learning Research , 3(Feb):1137–1155 .
John Duchi , Elad Hazan , and Yoram Singer . 2011 .
Adaptive subgradient methods for online learning and stochastic optimization .
Journal of Machine Learning Research , 12(Jul):2121–2159 .
Alec Go , Richa Bhayani , and Lei Huang .
2009 .
Twitter sentiment classiﬁcation using distant supervision .
CS224N Project Report , Stanford , 1(2009):12 .
William L. Hamilton , Kevin Clark , Jure Leskovec , and Dan Jurafsky .
2016 .
Inducing domain - speciﬁc sentiment lexicons from unlabeled corpora .
In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 595–605 .
Vasileios Hatzivassiloglou and Kathleen R McKeown .
1997 .
Predicting the semantic orientation of adjectives .
In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics , pages 174–181 .
Bas Heerschop , Alexander Hogenboom , and Flavius Frasincar .
2011 .
Sentiment lexicon creation from lexical resources .
In International Conference on Business Information Systems , pages 185–196 .
Minqing Hu and Bing Liu .
2004 .
Mining and summarizing customer reviews .
In Proceedings of the Tenth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 168–177 .
Jaap Kamps , Maarten Marx , Robert J Mokken , Maarten De Rijke , et al . 2004 .
Using wordnetto measure semantic orientations of adjectives .
In Proceedings of the Fourth International Conference on Language Resources and Evaluation , volume 4 , pages 1115–1118 .
Soo - Min Kim and Eduard Hovy .
2004 .
Determining the sentiment of opinions .
In Proceedings of the 20th international conference on Computational Linguistics , page 1367 .
Svetlana Kiritchenko , Xiaodan Zhu , and Saif M Mohammad . 2014 .
Sentiment analysis of short informal texts .
Journal of Artiﬁcial Intelligence Research , 50:723–762 .
Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean .
2013 .
Efﬁcient estimation of word representations in vector space .
Proceedings of Workshop at 1st International Conference on Learning Representations ( ICLR2013 ) .
Saif M. Mohammad , Svetlana Kiritchenko , and Xiaodan Zhu . 2013 .
Nrc - canada : Building the state - ofthe - art in sentiment analysis of tweets .
In Proceedings of the seventh international workshop on Semantic Evaluation Exercises ( SemEval-2013 ) , pages 321–327 .
Sara Rosenthal , Preslav Nakov , Svetlana Kiritchenko , Saif Mohammad , Alan Ritter , and Veselin Stoyanov . 2015 .
Semeval-2015 task 10 : Sentiment analysis in twitter .
In SemEval@ NAACL - HLT , pages 451–463 .
Duyu Tang , Furu Wei , Bing Qin , Ming Zhou , and Ting Liu . 2014a .
Building large - scale twitter - speciﬁc sentiment lexicon : A representation learning approach .
In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , pages 172–182 .
Duyu Tang , Furu Wei , Nan Yang , Ming Zhou , Ting Liu , and Bing Qin . 2014b .
Learning sentimentspeciﬁc word embedding for twitter sentiment classiﬁcation .
In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , pages 1555–1565 .
Peter D Turney .
2002 .
Thumbs up or thumbs down ? : semantic orientation applied to unsupervised classiﬁcation of reviews .
In Proceedings of the 40th annual meeting on association for computational linguistics , pages 417–424 .
Peter D Turney . 2008 .
The latent relation mapping engine : Algorithm and experiments .
Journal of Artiﬁcial Intelligence Research , 33:615–655 .
Duy Tin V o and Yue Zhang .
2016 .
Do nt count , predict !
an automatic approach to learning sentiment lexicons for short text .
In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , volume 2 , pages 219–224 .
Ke Wang and Rui Xia . 2016 .
A survey on automatical construction methods of sentiment lexicons .
Acta Automatica Sinica , 42(4):495–511.510
