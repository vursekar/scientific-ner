STIL - Simultaneous Slot Filling , Translation , Intent Classiﬁcation , and Language Identiﬁcation : Initial Results using mBART on MultiATIS++
Jack G. M. FitzGerald Amazon Alexa AI Seattle , WA jgmf@amazon.com
Abstract
Input
从盐湖城到加州奥克兰的航班
Slot-ﬁlling , Translation , Intent classiﬁcation , and Language identiﬁcation , or STIL , is a newly - proposed task for multilingual Natural Language Understanding ( NLU ) .
By performing simultaneous slot ﬁlling and translation into a single output language ( English in this case ) , some portion of downstream system components can be monolingual , reducing development and maintenance cost .
Results are given using the multilingual BART model ( Liu et al , 2020 ) ﬁne - tuned on 7 languages using the MultiATIS++ dataset .
When no translation is performed , mBART ’s performance is comparable to the current state of the art system ( Cross - Lingual BERT by Xu et al ( 2020 ) ) for the languages tested , with better average intent classiﬁcation accuracy ( 96.07 % versus 95.50 % ) but worse average slot F1 ( 89.87 % versus 90.81 % ) .
When simultaneous translation is performed , average intent classiﬁcation accuracy degrades by only 1.7 % relative and average slot F1 degrades by only 1.2 % relative .
1
Introduction
Multilingual Natural Language Understanding ( NLU ) , also called cross - lingual NLU , is a technique by which an NLU - based system can scale to multiple languages .
A single model is trained on more than one language , and it can accept input from more than one language during inference .
In most recent high - performing systems , a model is ﬁrst pre - trained using unlabeled data for all supported languages and then ﬁne tuned for a speciﬁc task using a small set of labeled data ( Conneau and Lample , 2019 ; Pires et al , 2019 ) .
Two typical tasks for goal - based systems , such as virtual assistants and chatbots , are intent classiﬁcation and slot ﬁlling ( Gupta et al , 2006 ) .
Though intent classiﬁcation creates a language agnostic output ( the intent of the user ) , slot ﬁlling does not .
Traditional Output
STIL Output
intent : ﬂight slots : ( 盐湖城 , fromloc.cityname ) , ( 奥克兰 , toloc.cityname ) , . . .
( 加州 , toloc.statename ) .
. .
intent : ﬂight slots : ( salt lake city , fromloc.cityname ) , ( oakland , toloc.cityname ) , . . . . . .
( california , toloc.statename ) lang : zh
Table 1 : Today ’s slot ﬁlling systems do not translate the slot content , as shown in “ Traditional Ouput . ”
With a STIL model , the slot content is translated and language identiﬁcation is performed .
Instead , a slot-ﬁlling model outputs the labels for each of input tokens from the user .
Suppose the slot-ﬁlling model can handle L languages .
Downstream components must therefore handle all L languages for the full system to be multilingual across L languages .
Machine translation could be performed before the slot ﬁlling model at system runtime , though the latency would be fully additive , and some amount of information useful to the slotﬁlling model may be lost .
Similarly , translation could occur after the slot-ﬁlling model at runtime , but slot alignment between the source and target language is a non - trivial task ( Jain et al , 2019 ;
Xu et
al , 2020 ) .
Instead , the goal of this work was to build a single model that can simultaneously translate the input , output slotted text in a single language ( English ) , classify the intent , and classify the input language ( See Table 1 ) .
The STIL task is deﬁned such that the input language tag is not given to the model as input .
Thus , language identiﬁcation is necessary so that the system can communicate back to the user in the correct language .
Contributions of this work include ( 1 ) the introduction of a new task for multilingual NLU , namely simultaneous Slot ﬁlling , Translation , Intent clasProceedingsofthe1stConferenceoftheAsia - PaciﬁcChapteroftheAssociationforComputationalLinguisticsandthe10thInternationalJointConferenceonNaturalLanguageProcessing , pages576–581December4 - 7,2020.c(cid:13)2020AssociationforComputationalLinguistics576  Example Input
Example Output
ﬂ¨uge von salt lake city nach oakland kalifornien
salt < B-fromloc.city name > lake < I-fromloc.city name > city < I-fromloc.city name > oakland < B-toloc.city name > california
< B-toloc.state name >
< intent-ﬂight > < lang - de >
从盐湖城到加州奥克兰 的航班
salt < B-fromloc.city name > lake < I-fromloc.city name > city < I-fromloc.city name > oakland < B-toloc.city name > california
< B-toloc.state name >
< intent-ﬂight > < lang - zh >
Table 2 : Two text - to - text STIL examples .
In all STIL cases , the output is in English .
Each token is followed by its BIO - tagged slot label .
The sequence of tokens and slots are followed by the intent and then the language .
siﬁcation , and Language identiﬁcation ( STIL ) ; ( 2 ) both non - translated and STIL results using the mBART model ( Liu et al , 2020 ) trained using a fully text - to - text data format ; and ( 3 ) public release of source code used in this study , with a goal toward reproducibility and future work on the STIL task1 .
2 Dataset
The Airline Travel Information System ( ATIS ) dataset is a classic benchmark for goal - oriented NLU ( Price , 1990 ; Tur et al , 2010 ) .
It contains utterances focused on airline travel , such as how much is the cheapest ﬂight from Boston to New York tomorrow morning ?
The dataset is annotated with 17 intents , though the distribution is skewed , with 70 % of intents being the ﬂight intent .
Slots are labeled using the Beginning Inside Outside ( BIO ) format .
ATIS was localized to Turkish and Hindi in 2018 , forming MultiATIS ( Upadhyay et al , 2018 ) , and then to Spanish , Portuguese , German , French , Chinese , and Japanese in 2020 , forming MultiATIS++ ( Xu et al , 2020 ) .
In this work , Portuguese was excluded due to a lack of Portuguese pretraining in the publicly available mBART model , and Japanese was excluded due to a current lack of alignment between Japanese and English samples in MultiATIS++ .
Hindi and Turkish data were taken from MultiATIS , and the training data were upsampled by 3x for Hindi and 7x for Turkish .
Prior to any upsampling , there were 4,488 training samples for English , Spanish , German , French , and Chinese .
The test sets contained 893 samples for all languages except Turkish , which had 715 samples .
For English , Spanish , German , French , and Chinese , validation sets of 490 samples were used in all cases .
Given the smaller data quantities for Hindi and Turkish , two training and validation set conﬁgurations were considered .
The ﬁrst conﬁguration
1https://github.com/jgmﬁtz/stil-mbart-multiatisppaacl2020
matched that of Xu et al ( 2020 ) , using training sets of 1,495 for Hindi and 626 for Turkish along with validation sets of 160 for Hindi and 60 for Turkish .
In the second conﬁguration , no validation sets were made for Hindi and Turkish ( though there were still validation sets for the other languages ) , and the training sets of 1,600 Hindi samples and 638 samples from MultiATIS were used .
Two output formats are considered , being ( 1 ) the non - translated , traditional case , in which translation of slot content is not performed , and ( 2 ) the translated , STIL case , in which translation of slot content is performed .
In both cases , the tokens , the labels , the intent , and the detected language are all output from the model as a single ordered text sequence , as shown in Table 2 .
3 Related Work
Previous approaches for intent classiﬁcation and slot ﬁlling have used either ( 1 ) separate models for slot ﬁlling , including support vector machines ( Moschitti et al , 2007 ) , conditional random ﬁelds ( Xu and Sarikaya , 2014 ) , and recurrent neural networks of various types ( Kurata et al , 2016 ) or ( 2 ) joint models that diverge into separate decoders or layers for intent classiﬁcation and slot ﬁlling ( Xu and Sarikaya , 2013 ; Guo et al , 2014 ; Liu and Lane , 2016 ; Hakkani - T¨ur et al , 2016 ) or that share hidden states ( Wang et al , 2018 ) .
In this work , a fully text - to - text approach similar to that of the T5 model was used , such that the model would have maximum information sharing across the four STIL sub - tasks .
Encoder - decoder models , ﬁrst introduced in 2014 ( Sutskever et al , 2014 ) , are a mainstay of neural machine translation .
The original transformer model included both an encoder and a decoder ( Vaswani et al , 2017 ) .
Since then , much of the work on transformers focuses on models with only an encoder pretrained with autoencoding techniques ( e.g. BERT by Devlin et al ( 2018 ) ) or auto - regressive models with only a decoder ( e.g.
577  GPT by Radford ( 2018 ) )
.
In this work , it was assumed that encoder - decoder models , such as BART ( Lewis et al , 2019 ) and T5 ( Raffel et al , 2019 ) , are the best architectural candidates given the translation component of the STIL task , as well as past state of the art advancement by encoder - decoder models on ATIS , cited above .
Rigorous architectural comparisons are left to future work .
4 The Model
4.1 The Pretrained mBART Model
The multilingual BART ( mBART ) model architecture was used ( Liu et al , 2020 ) , as well as the pretrained mBART.cc25 model described in the same paper .
The model consists of 12 encoder layers , 12 decoder layers , a hidden layer size of 1,024 , and 16 attention heads , yielding a parameter count of 680M.
The mBART.cc25 model was trained on 25 languages for 500k steps using a 1.4 TB corpus of scraped website data taken from Common Crawl ( Wenzek et al , 2019 ) .
The model was trained to reconstruct masked tokens and to rearrange scrambled sentences .
SentencePiece tokenization ( Kudo and Richardson , 2018 ) was used for mBART.cc25 with a sub - word vocabulary size of 250k .
4.2 This Work
The same vocabulary as that of the pretrained model was used for this work , and SentencePiece tokenization was performed on the full sequence , including the slot tags , intent tags , and language tags .
For all mBART experiments and datasets , data from all languages were shufﬂed together .
The fairseq library was used for all experimentation ( Ott et al , 2019 ) .
Training was performed on 8 Nvidia V100 GPUs ( 16 GB ) using a batch size of 32 , layer normalization for both the encoder and the decoder ( Xu et al , 2019 ) ; label smoothed cross entropy with ( cid:15 ) = 0.2 ( Szegedy et al , 2016 ) ; the ADAM optimizer with β1 = 0.9 and β2 = 0.999 ( Kingma and Ba , 2014 ) ; an initial learning rate of 3 × 10−5 with polynomial decay over 20,000 updates after 1 epoch of warmup ; attention dropout of 0.1 and dropout of 0.2 elsewhere ; and FP16 type for weights .
Each model was trained for 19 epochs , which took 5 - 6 hours .
method ( Wilson , 1927 ) with 95 % conﬁdence .
5.1 Comparing to Xu et al ( 2020 )
Examining the ﬁrst training conﬁguration ( 1,496 samples for Hindi and 626 for Turkish ) , the nontranslated mBART ’s macro - averaged intent classiﬁcation ( 96.07 % ) outperforms Cross - Lingual BERT by Xu et al ( 2020 ) ( 95.50 % ) , but slot F1 is worse ( 89.87 % for non - translated mBART and 90.81 % for Cross - Lingual BERT ) .
The differences are statistically signiﬁcant in both cases .
5.2 With and Without Translation
When translation is performed ( the STIL task ) , intent classiﬁcation accuracy degrades by 1.7 % relative from 96.07 % to 94.40 % , and slot F1 degrades by 1.2 % relative from 89.87 % to 88.79 % .
The greatest degradation occurred for utterances involving ﬂight number , airfare , and airport name ( in that order ) .
5.3 Additional Hindi and Turkish Training
Data
Adding 105 more Hindi and 12 more Turkish training examples results in improved performance for the translated , STIL mBART model .
Macro - averaged intent classiﬁcation improves from 94.40 % to 95.94 % , and slot F1 improves from 88.79 % to 90.10 % , both of which are statistically signiﬁcant .
By adding these 117 samples , the STIL mBART model matches the performance ( within conﬁdence intervals ) of the non - translated mBART model .
This ﬁnding suggests that the STIL models may require more training data than traditional , non - translated slot ﬁlling models .
Additionally , by adding more Hindi and Turkish data , both the intent accuracy and the slot ﬁlling F1 improves for every individual language of the translated , STIL models , suggesting that some portion of the internal , learned representation is language agnostic .
Finally , the results suggest that there is a trainingsize - dependent performance advantage in using a single output language , as contrasted with the nontranslated mBART model , for which the intent classiﬁcation accuracy and slot F1 does not improve ( with statistical signiﬁcance ) when using the additional Hindi and Turkish training samples .
5 Results and Discussion
5.4 Language Identiﬁcation
Results from the models are given in Table 3 .
Statistical signiﬁcance was evaluated using the Wilson
Language identiﬁcation F1 is above 99.7 % for all languages , with perfect performance in many cases .
578  Intent accuracy
en
es
de
zh
fr
hi
tr
Mac Avg
Cross - Lingual BERT ( Xu et al , 2020 )
97.20
96.77
96.86
95.54
97.24
92.70 tr=1495
92.20 tr=626
95.50
Seq2Seq - Ptr ( Rongali et al , 2020 )
Stack Propagation ( Qin et al , 2019 )
Joint BERT + CRF ( Chen et al , 2019 )
97.42 97.5 97.9
Non - translated mBART , with hi - tr val
96.98
96.98
97.09
96.08
97.65
Translated / STIL mBART , with hi - tr val
95.86
94.62
95.63
93.84
95.97
Non - translated mBART , no hi - tr val
97.09
97.20
97.20
96.30
97.42
Translated / STIL mBART , no hi - tr val
96.98
96.53
96.64
96.42
97.31
Slot F1
Bi - RNN ( Upadhyay et al , 2018 )
Stack Propagation ( Qin et al , 2019 )
Joint BERT ( Chen et al , 2019 )
en
95.2
96.1 96.1
Cross - Lingual BERT ( Xu et al , 2020 )
95.90
87.95
95.00
93.67
90.39
Non - translated mBART , with hi - tr val
95.03
86.76
94.42
92.13
89.31
Translated / STIL mBART , with hi - tr val
93.81
90.38
91.41
85.93
91.24
Non - translated mBART , no hi - tr val
95.00
86.87
94.14
92.22
89.32
Translated / STIL mBART , no hi - tr val
94.66
91.55
92.61
87.73
92.15
95.07 tr=1495 93.84 tr=1495 94.74 tr=1600 94.85 tr=1600
80.6 tr=600 86.73 tr=1495
86.91 tr=1495 83.98 tr=1495 87.42 tr=1600 86.74 tr=1600
92.73 tr=626 91.05 tr=626 94.27 tr=638 92.87 tr=638
78.9 tr=600 86.04 tr=626
84.53 tr=626 84.79 tr=626 84.33 tr=638 85.23 tr=638
96.07
94.40
96.32
95.94
84.90
90.81
89.87
88.79
89.90
90.10
es
de
zh
fr
hi
tr
Mac Avg
Language Identiﬁcation F1
en
Translated / STIL mBART , with hi - tr val Translated / STIL mBART , no hi - tr val
100.00 99.78
es
98.87 99.83
de
zh
100.00 100.00
100.00 100.00
fr
98.95 99.72
hi
tr
Mac Avg
100.00 100.00
99.93 99.86
99.68 99.88
Table 3 : Results are shown for intent accuracy , slot F1 score , and language identiﬁcation F1 score .
For English , Spanish , German , Chinese , and French in all of the models shown above ( including other work ) , training sets were between 4,478 and 4,488 samples , and validation sets were between 490 and 500 samples .
In this work , two training set sizes were used for Hindi and Turkish , denoted by “ tr= ” and “ with hi - tr val[idation set ] ” or “ no hi - tr val[idation set ] ” .
Across all work shown above , the tests sets contained 893 samples for all languages except Turkish , for which the test set was 715 samples .
Perfect performance on Chinese and Hindi is unsurprising given their unique scripts versus the other languages tested .
6 Conclusion
This preliminary work demonstrates that a single NLU model can perform simultaneous slot ﬁlling , translation , intent classiﬁcation , and language identiﬁcation across 7 languages using MultiATIS++ .
Such an NLU model would negate the need for multiple - language support in some portion of downstream system components .
Performance is not irreconcilably worse than traditional slot-ﬁlling models , and performance is statistically equivalent with a small amount of additional training data .
Looking forward , a more challenging dataset is needed to further develop the translation component of the STIL task .
The English MultiATIS++ test set only contains 455 unique entity - slot pairs .
An ideal future dataset would include freeform and varied content , such as text messages , song titles , or open - domain questions .
Until then , work remains to achieve parity with English - only ATIS models .
Acknowledgments
The author would like to thank Saleh Soltan , Gokhan Tur , Saab Mansour , and Batool Haider for reviewing this work and providing valuable feedback .
