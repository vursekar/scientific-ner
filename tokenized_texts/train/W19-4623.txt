ZCU - NLP at MADAR 2019 :
Recognizing Arabic Dialects
Pavel Pˇrib´a ˇn pribanp@kiv.zcu.cz
Stephen Taylor stepheneugenetaylor@gmail.com
Department of Computer Science and Engineering , Faculty of Applied Sciences , University of West Bohemia , Pilsen , Czech Republic http://nlp.kiv.zcu.cz
Abstract
In this paper , we present our systems for the MADAR Shared Task : Arabic Fine - Grained Dialect Identiﬁcation .
The shared task consists of two subtasks .
The goal of Subtask – 1 ( S-1 ) is to detect an Arabic city dialect in a given text and the goal of Subtask–2 ( S-2 ) is to predict the country of origin of a Twitter user by using tweets posted by the user .
In S-1 , our proposed systems are based on language modelling .
We use language models to extract features that are later used as an input for other machine learning algorithms .
We also experiment with recurrent neural networks ( RNN ) , but these experiments showed that simpler machine learning algorithms are more successful .
Our system achieves 0.658 macro F1 - score and our rank is 6th out of 19 teams in S-1 and 7th in S-2 with 0.475 macro F1 - score .
1
Introduction
The Madar shared tasks ( Bouamor et al , 2019 ) are a follow - up to Salameh ’s
( Salameh et al , 2018 ) work with the synthetic corpus of Bouamor ( Bouamor et al , 2014 ) and Salameh ’s work with tweets based on the corpus .
Two corpora are provided , a six - city corpus of travel sentences rendered into the dialects of ﬁve cities and MSA1 , and a 25 - city + MSA corpus using a smaller number of sentences .
In the ﬁrst task , test data is classiﬁed as one of the 25 cities or MSA .
For the second task , the organizers chose training , development and test tweet - sets for download from Twitter .
The tweets are from 21 Arabic countries , and the goal is to determine , for each tweet author , the country of origin .
For S-1 we did not use any external data , only data provided by the shared task organizers .
The organizers provided training and development data2 consisting of sentences in different dialects with a label denoting the corresponding dialect .
The training data contain 41 K sentences and development data contain 5.2 K sentences .
Organizers also provided additional data with Arabic sentences in seven dialects .
S-2 uses a corpus of tweets .
Twitter does not permit the organizers to distribute tweets , only the user ids and tweet ids .
Every participant must arrange with Twitter to download the tweets themselves , and because tweets are subject to deletion over time , it is possible that each participant ’s version of the corpus and test is unique .
2 Related Work
The Arabic dialects have a common written form and uniﬁed literary tradition , so it seems most logical to distinguish dialects on the basis of acoustics , and there is a fair amount of work there , including Hanani et al ( 2013 , 2015 ) ;
Ali et al ( 2016 ) .
— Biadsy et al ( 2009 ) distinguish four Arabic dialects and MSA based on ( audio ) phone sequences ; the phones were obtained by phone recognizers for English , German , Japanese , Hindi , Mandarin , Spanish , and three different MSA phone - recognizer implementations .
The dialects were distinguished by phoneme sequences , and the results of classiﬁcations based on each phonerecognizer were combined using a logistic regression classiﬁer .
They train on 150 hours per dialect of telephone recordings .
They report 61 % accuracy on 5 - second segments , and 84 % accuracy on 120 second segments .
Zaidan and Callison - Burch ( 2011 ) describe building a text corpus , based on reader commen2The participants were not allowed to use these data for
1Modern Standard Arabic
any training purposes .
ProceedingsoftheFourthArabicNaturalLanguageProcessingWorkshop , pages208–213Florence , Italy , August1,2019.c(cid:13)2019AssociationforComputationalLinguistics208  tary on newspaper websites , with signiﬁcant dialect content ; the goal is to provide a corpus to improve machine translation for Arabic dialects .
They used Amazon Mechanical Turk to provide annotation for a portion of the corpus .
Zaidan and Callison - Burch ( 2014 ) describe the same work in greater detail , including dialect classiﬁers they built using the Mechanical Turk data for classes and origin metadata as additional features .
They say these classiﬁers are ‘ approaching human quality . ’
ElFardy and Diab ( 2013 ) classify EGY3 and MSA sentences from the Zaidan and CallisonBurch ( 2011 ) corpus , that is , from text .
Not only is this a binary task , but orthographic hints , including repeated long vowels , emojis and multiple punctuations , give strong clues of the register , and hence whether MSA is being employed .
They do a number of experiments comparing various preprocessing schemes and different training sizes , ranging from 2 - 28 million tokens .
They achieve 80 % – 86 % accuracy for all of their attempts .
Malmasi et al ( 2015 ) do Arabic dialect identiﬁcation from text corpora , including the MultiDialect Parallel Corpus of Arabic ( Bouamor et al , 2014 ) and the Arabic Online Commentary database ( Zaidan and Callison - Burch , 2011 ) .
Hanani et al ( 2015 ) perform recognition of several Palestinian regional accents , evaluating four different acoustic models , achieving 81.5 % accuracy for their best system , an I - vector framework with 64 Gaussian components .
Ali et al ( 2016 ) developed the corpus on which the DSL Arabic shared task is based .
Their own dialect detection efforts depended largely on acoustical cues .
Arabic dialect recognition appeared in the 2016 edition of the VarDial workshop ’s shared task ( Malmasi et al , 2016 ) .
The shared task data was text - only .
The best classiﬁers ( Malmasi et al , 2016 ; Ionescu and Popescu , 2016 ) for the shared task performed far below the best results reported by some of the preceding researchers , in particular Ali et al ( 2016 ) which used some of the same data .
Part of the reason must be that the amount of training data for the workshop is much smaller than that used by some of the other researchers ; the workshop data also did not include the audio recordings on which the transcripts are based .
3Egyptian dialect
The absence of audio was remedied for the 2017 and 2018 VarDial workshops , ( Zampieri et al , 2017 , 2018 )
However , the ﬁve dialects plus MSA targeted by the VarDial shared task comprise a small fraction of Arabic ’s dialectical variation .
Salameh et al ( Salameh et al , 2018 ) use a corpus ( Bouamor et al , 2018 ) which differentiates between twentyﬁve different cities and MSA .
This still does n’t address urban rural divides , but it begins to reﬂect more realistic diversity .
3 Overview
3.1 Language Modelling
In S-1 , both of our systems used for the ofﬁcial submission take as an input language model features .
In our case the objective of a language model in its simplest form is to predict probability p(S ) of sentence S which is composed from strings ( words or character n - grams ) s1 , s2 . . .
sN , where N is a number of strings in the sentence .
The probability estimation of p(S ) can be computed as a product of conditional probabilities p(si|hi ) of its strings s1 , s2 . . .
sN , where hi is a history of a string si .
The probability of string si is conditioned by history hi i.e. n − 1 preceding strings si−n+1 , si−n+2 , . . .
si−1 which can be rewritten as si−1 i−n+1 .
The resulting formula for the p(S ) estimation looks as follows :
p(S )
=
p(si|hi )
=
p(si|si−1
i−n+1 )
( 1 )
N ( cid:89 )
i=1
N ( cid:89 )
i=1
The conditioned probability p(si|hi ) can be estimated with Maximum Likelihood Estimate ( MLE ) which is deﬁned as :
pM LE(si|hi )
=
c(si−n+1 , si−n+2 . . .
si ) c(si−n+1 , si−n+2 . . .
si−1 )
( 2 )
where c(si−n+1 , si−n+2 . . .
si ) is a number of occurrences of string si with history
hi and c(si−n+1 , si−n+2 . . .
si−1 ) is a number of occurrences of history hi .
These counts are taken from a training corpus .
We followed Salameh ( Salameh et al , 2018 ) in using the kenlm language modelling tool ( Heaﬁeld et al , 2013 ) .
kenlm does n’t have an option to use character n - grams instead of words ,
209  so in order to get character - based language models , we prepared input ﬁles with characters separated by spaces .
Instead of encoding space as a special word , we surrounded words with a < w></w > pair .
This enables noticing strings which occur at the beginning or end of a word ( as would a special sequence for space ) but reduces the possible amount of inter - word information which the language model can keep for a given order , the parameter which indicates to kenlm the largest n - gram to index .
We used order 5 for all our kenlm language models .
We prebuilt models for each dialect .
We prepared six directories , each containing word or character models for each dialect in one of the three corpora .
that is ,
We wrote a LangModel class which quacks like a sklearn classiﬁer , it supports fit ( ) , predict ( ) , and predict proba ( ) , but its choices are based on a directory of lanpredict ( ) returns the diguage models .
alect name whose model gives the highest score .
predict proba ( ) provides a list of languagemodel - score features , adjusted to probabilities .
4 Subtask–1 System Description
In this section we describe our models4 .
We submitted results for the S-1 from two systems – Tortuous Classiﬁer and Neural Network Classiﬁer .
4.1 Tortuous Classiﬁer
This submission uses a jumble of features and classiﬁers , most from the sklearn module ( Buitinck et al , 2013 ) .
The ﬁnal classiﬁer is a hard voting classiﬁer with three input streams :
1 .
Soft voting classiﬁer on :
( a ) Multinomial naive Bayes classiﬁer on
( b ) Multinomial naive Bayes classiﬁer on
word 1 - 2grams ,
char 3 - 5grams ,
( c ) Language model scores adjusted to probabilities , for word - based language models of the corpus 26 dialects
( d ) Language model scores adjusted to probabilities , for char - based language models of the corpus 26 dialects
classiﬁer ( e ) Multinomial naive Bayes on language - model - scores for character and language models on the
4The source code is available at https://github .
com / StephenETaylor / Madar-2019
corpus-6 language models and character the corpus-26 language models language models .
for
2 . Support
vector machine ,
svm .
SVC (
gamma=’scale ’ , kernel = ’ poly ’ , degree = 2 ) same features as item 1e .
with
the
3 .
Multinomial naive Bayes classiﬁer using word and char language model features for corpus-6 and corpus-26 features , tﬁd vectorized word 1 - 2grams , and tﬁd vectorized char 3 - 5grams .
The classiﬁer did better on the development data , suggesting that it is over-ﬁtted , but the language model features , which are the most predictive , also did better on the development data .
4.2 Neural Network Classiﬁer
We experimented with several neural networks .
Our model for the S-1 submission uses as input 26 features which correspond to one of our 26 pretrained dialect language models .
Each feature represents the probability of a given sentence for one language model .
The probability scores measure how close each sentence is to the dialect .
We train Multilayer Perceptron ( MLP ) with one hidden ( dense ) layer with 400 units .
The output of the hidden layer is passed to a ﬁnal fullyconnected softmax layer .
The output of the softmax layer is a probability distribution over all 26 classes .
The class with the highest probability is predicted as a ﬁnal output of our model .
As an activation function in the hidden layer of the MLP a Rectiﬁed Linear Unit ( ReLu ) is employed .
We also tried to combine character n - gram features with the language model features .
The input is a sequence of ﬁrst 200 character n - grams of a given text .
Each sequence of character n - grams is used as a separate input followed by a randomly initialized embedding layer and then two layers of Bidirectional LSTM ( BiLSTM)(Graves and Schmidhuber , 2005 ) with 64 units are employed ( see Figure 1 ) .
The output vector of the BiLSTM layers is concatenated with the language model features and this concatenated vector is passed to the MLP layer with 400 units ( the same as described above ) .
All models were implemented by using Keras ( Chollet et al , 2015 ) with TensorFlow backend ( Abadi et al , 2015 )
210  Figure 1 : Neural network model architecture
4.3 Neural Netwok Model Training
We tune all hyperparameters on the development data .
We train our model with Adam ( Kingma and Ba , 2014 ) optimizer with learning rate 0.01 and without any dropout .
The number of epochs is 800 and we do not use mini - batches or dropout regularization technique .
The model with these hyperparameters achieves the best result ( 0.661 macro F1 - score ) on the development data and was used for the ﬁnal submission .
We also experimented with the n - gram inputs .
We tried a different number of character n - grams and we achieve the best result ( 0.555 macro F1score ) on the development data using three inputs - character unigrams , bigrams and trigrams , with learning rate 0.005 , mini - batches of size 256 for 11 epochs and with the Adam optimizer .
5 Subtask–2 System Description
Our tortuous classiﬁer did less well on the tweet data , so we used a simpler classiﬁer .
The features are the kenlm language model scores for the 21 countries , computed for each of the training tweets , then exponentiated and normalized to sum to 1 .
The tweets are classiﬁed using
y_test = KNeighborsClassifier ( n_neighbors=31 ) .fit(X_train , y_train ) .predict(X_test )
The users are predicted based on the plurality prediction for all of their tweets , that is , the country to which the largest number of their tweets were assigned .
There were a signiﬁcant number of tweets unavailable , about 10 % in the training and development sets , and 12 % in the test set .
After the submissions had closed we experimented with eliminating the unavailable and non - Arabic tweets from
Figure 2 : Tortuous Classiﬁer confusion matrix
training and testing and choosing Saudi Arabia ( which is the origin for the plurality of tweets at 36 % ) for users with no remaining tweets .
This improved tweet classiﬁcation accuracy by about 5 % , but actually decreased user classiﬁcation accuracy on the development set .
6 Results
For the Subtask–1 we achieved 0.658 macro F1score on the test data , sixth among nineteen submissions with the Tortuous Classiﬁer .
The Neural Network Classiﬁer achieved a macro F1 - score of 0.648 on the test data .
For the Subtask–2 we submitted a single entry .
It ranked 7th among 9 submissions with 0.475 macro F1 - score .
Figure 2 shows that many of the errors are geographically plausible .
For example , ASWan ALXandria and CAIro are all in Egypt , and each has a sizeable chunk of mistaken identity for the others .
Similarly , DAMascus , ALEppo , AMMan , BEIrut , JERusalem which are all ’ Levantine ’ and only a few hundred miles apart .
7 Conclusion
This paper presents an automatic approach for Arabic dialect detection in the MADAR Shared Task .
Our proposed systems for the Subtask-1 use language model features .
Our experiments showed that simpler machine learning algorithms outperform RNN using language model features .
Subtask–2 turned out to be more challenging because Tweets , which are real - world wild data , are more difﬁcult to process than systematically prepared texts .
211text n - gramsBiLSTMBiLSTMCharacter   EmbedingsBiLSTMBiLSTM200 x 1501 x ( n*128 + 26)Language model featuresDenseLayerConcatenatedVectorSoftmaxALEALGALXAMMASWBAGBASBEIBENCAIDAMDOHFESJEDJERKHAMOSMSAMUSRABRIYSALSANSFXTRITUNPredicted labelsALEALGALXAMMASWBAGBASBEIBENCAIDAMDOHFESJEDJERKHAMOSMSAMUSRABRIYSALSANSFXTRITUNTrue labels1270012341700301008010000310110160110100800171141422210111031494161001101112180000002000902118210628970218300202710100021413411001914134200003100102005212725131130104331092520011121291281201601008230523210810721112923180019301213500212506931113121804200020614111064193372002100211519000030102216011644217231084121000000081010110422311101501845013142112107112000021413630201231111301111640025331411231601301055131721262127511602121200102910100238101110113042147112000010201000038010000100167110645011172201002110001911584071101023131311513151811003283116440101703000020113612100013901031120030223650131181129701152701033112322532710051221320710941101112162131170913431064140020260112303120202000213101460221302300292040224001141141513190103212222101000121213801280306090120150  Acknowledgments
This work has been partly supported by Grant No . SGS-2019 - 018 Processing of heterogeneous data and its specialized applications , and was partly supported from ERDF ” Research and Development of Intelligent Components of Advanced Technologies for the Pilsen Metropolitan Area ( InteCom ) ” .
Access to computing and storage facilities owned by parties and projects contributing to the National Grid Infrastructure MetaCentrum provided under the programme ” Projects of Large Research , Development , and Innovations Infrastructures ” ( CESNET LM2015042 ) , is greatly appreciated .
