IIITT at CASE 2021 Task 1 : Leveraging Pretrained Language Models for Multilingual Protest Detection
Pawan Kalyan Jada1 , Duddukunta Sashidhar Reddy1 , Adeep Hande1 , Ruba Priyadharshini2 , Ratnasingam Sakuntharaj3 , Bharathi Raja Chakravarthi4 1 Indian Institute of Information Technology Tiruchirappalli
2 ULTRA Arts and Science College , India ,
3Eastern University , Sri Lanka
4Insight SFI Research Centre for Data Analytics , National University of Ireland Galway pawankj19c@iiitt.ac.in
Abstract
In a world abounding in constant protests resulting from events like a global pandemic , climate change , religious or political conﬂicts , there has always been a need to detect events / protests before getting ampliﬁed by news media or social media .
This paper demonstrates our work on the sentence classiﬁcation subtask of multilingual protest detection in CASE@ACL - IJCNLP 2021 .
We approached this task by employing various multilingual pre - trained transformer models to classify if any sentence contains information about an event that has transpired or not .
Furthermore , we performed soft voting over the models , achieving the best results among the models , accomplishing a macro F1 - Score of 0.8291 , 0.7578 , and 0.7951 in English , Spanish , and Portuguese , respectively .
The source codes for our systems are published1 .
1
Introduction
The recent surge in social media users has led many people to express their opinions on various global issues .
These opinions travel far and wide within a matter of seconds ( Hossny et al , 2018 ) .
This can inﬂuence many people and may engage public movements ( Won et al , 2017a ) .
Therefore , there is a deﬁnite need to detect these protests and analyse them to know the signiﬁcant areas of disinterest .
Being a free and easy to use platform , social media has become a part of our day to day life .
It incorporates people of different ages , gender , location , religions , background , and so on .
The enormous number of rich and diversiﬁed users results in an enormous amount of information being generated , which is helpful in many ways ( Kapoor et al , 2018 ) .
Some of this even contains private information about the users , which others could misuse .
Cases were also found where certain users
1https://github.com/adeepH/
CASE-2021 - Task-1
were being targeted and harassed by people using this platform , a common scenario in cyberbullying ( Abaido , 2020 ) .
Social media plays a crucial role in amplifying these protests and movements ( Won et al , 2017b ) .
It enables political groups and protesters to organise protest movements and share information .
It acts as a platform for the people who are underrepresented by giving a voice to them .
It also offers new opportunities for people to engage in activism , political resistance , and protest outside the political groups and civic institutions .
Thus , it has a social impact on everyone ( Pulido et al , 2018 ) .
It is to be noted that social media , similar to news media , plays a vital role in its social and political events worldwide ( Holt et al , 2013 ) .
For the above reasons , we can state that social media plays a crucial role in most worldwide events .
The English language is widely regarded as the ﬁrst Lingua Franca .
Statistically , it is one of the most widely spoken languages globally , having ofﬁcial status in over 53 countries ( Crystal , 2008 ) .
Over 400 million people speak English as their primary language and widely spoken in the United States and the United Kingdom .
BlackLivesMatter ( Dave et al , 2020 ) , EarthDay ( Rome , 2010 ) are some of the major protests that have occurred in these countries .
Espa˜nol commonly referred to as Spanish , is spoken by over 360 million people worldwide , with most of its speakers residing in Mexico , Argentina , Spain .
15 - M Movement ( Casero - Ripoll´es and Feenstra , 2012 ) and YoSoy132 ( Garc´ıa and Trer´e , 2014 ) are some of the recent protests where people have been vocal about in the Spanish language .
Portuguese has over 220 million native speakers .
Brazil , Portugal , Angola are some of the major countries where this language is spoken .
Protests like Racism Kills , May 68 ( Ross , 2008 ) are the recent ones that occurred in the Portuguese language .
The recent upheavals of protests are due to soProceedingsofthe4thWorkshoponChallengesandApplicationsofAutomatedExtractionofSocio - politicalEventsfromText(CASE),pages98–104August5–6,2021, © 2021AssociationforComputationalLinguistics98  Language Label Sentence Event Fabius ran against Royal for the presidential nomination in 2007 .
English Event English He planned to start a race war .
Not - event English Metro police intervened and the ﬁre was put out .
Pero
no es ´ ese el mayor problema .
Event Spanish La Argentina retroceder´ıa un paso todos los d´ıas .
Event Spanish Carri´o
no objet´o que se trat´o de un secuestro .
Spanish Not - event Os servidores do Piau´ı est˜ao em greve h´a 17 dias .
Portuguese Not - event ´ E uma nova experiˆencia mobilizat´oria .
Portuguese Event ´ E decidiram ir ` as aulas e passar o dia de saia .
Portuguese Not - event
Table 1 : Examples of the dataset indicating events of the past and not - events .
cial media , youth , exaggeration of certain events .
( Basile and Caselli , 2020 ) .
Any early detection of mass protest detection through social media platforms such as Facebook , Twitter , and Instagram to help minimizing the aftermath of the protests ( Wilson , 2017 ) .
This has motivated Natural Language Processing ( NLP ) researchers to develop NLP systems to generalize on data coming from diverse sources to leverage the NLP systems to more realistic environments ( B¨uy¨uk¨oz et al , 2020 ) .
Hence , there is a need to develop NLP systems that could be generalized to any protest / events ( Peng et al , 2013 ) , which has motivated us to participate in the shared task for multilingual protest detection ( H¨urriyeto˘glu et al , 2019a , 2021 )
The objective of the task is to identify if any sentence talks about any mentions of protests or events in three languages , namely , English , Spanish , and Portuguese .
Hence , we treat this as a sequence classiﬁcation task .
The rest of the paper is organized as follows , Section 2 presents previous work on protest detection and analysis .
Section 3 entails a comprehensive analysis of the dataset used for our cause .
Next , section 4 gives a detailed description of the models used for the multilingual event detection .
Finally , section 5 analyses the results obtained , and Section 6 concludes our work while discussing the potential directions for future work .
2 Related Work
The need to detect events that could lead to protests is of prime interest to sociologists and governments ( Danilova et al , 2016 ) .
There are several active ongoing projects for socio - political event systems such as KEDS ( Kansas Event Data System ) ( Schrodt and Hall , 2006 ) , CAMEO ( Conﬂict and Mediation Event Observation ) ( Gerner et al , 2002 ) , and several other databases for protest detection systems ( Danilova , 2015 ) .
These methods have focused on news data as they have traditionally been the most reliant source of events .
Protest detection has been one of the major issues in the context of social and political ( Ettinger et al , 2017 ) .
Papanikolaou and Papageorgiou ( 2020 ) presented a computational social science methodology to analyse protests in Greece .
H¨urriyeto˘glu et
al ( 2021 ) constructed a corpus of protest events comprising various language sources from various countries .
Several systems were submitted to the CLEF ProtestNews Track that consisted of three shared tasks , primarily aimed at identifying and extracting event information spanning to multiple countries ( H¨urriyeto˘glu et al , 2019b , 2020 ) .
3 Dataset
This dataset comprises 26,208 sentences in three languages , namely English , Spanish , and Portuguese .
The dataset consists of two classes :
• Event : The sentence indicates an event of the
past .
any event .
• Not - event :
The sentence does not talk about
The volume of sequences indicating Not - event is higher in contrast to that of the Event label .
Therefore , the dataset distribution is quite imbalanced .
We can also notice that the number of English samples exceeds that of Spanish and Portuguese ones .
Refer to Table 1 for examples of sentences talking about events and not talking about events displayed in English , Spanish , and Portuguese .
The dataset distribution is displayed in Table 2 .
For our cause , we split the training and validation set in the ratio of 80:20 .
99  Figure 1 : System Architecture based on BERT ( Devlin et al , 2019 )
Language English Spanish Portuguese 901 Not - event 281 Event 1,182 Total
18,602 4,223 22,285
2,291 450 2,741
Table 2 : Classwise distribution of the training set
4.1 BERT
of the weighted probability , thus winning the vote ( Beyeler , 2017
; Hande et al , 2021 ) .
4 Methodology
We used pretrained transformer - based models for identifying if a sentence talks about an event or not .
The models that were used are BERT ( Devlin et al , 2019 ) , RoBERTa ( Liu et al , 2019 ) and DistilBERT ( Sanh et al , 2019 ) .
Even though there are 3 different languages , we used a single model for all three due to memory constraints and reduced training time .
We ﬁne - tuned these models for sequence classiﬁcation .
Soft Voting is done on all these models to produce the respective ﬁnal outputs for the languages .
In soft voting , each classiﬁer predicts that a speciﬁc data point belongs to the particular target class .
A weighted sum of the predictions is done based on the importance of the classiﬁer ( all models have equal weights ) .
The overall prediction is chosen as the target with the greatest sum
Bidirectional Encoder Representations from Transformers ( BERT ) ( Devlin et al , 2019 ) is a pretrained language model which was created with the objective that ﬁne - tuning a pretrained model yields better performance .
BERT ’s pretraining Firstly , Masked phase includes two tasks .
Language Modeling ( MLM ) is where certain words are randomly masked in a sequence .
About 15 % of the words in a sequence is masked .
The model then attempts to predict the masked words .
Secondly , Next Sentence Prediction ( NSP ) , where the model has an additional loss function , NSP loss , indicates if the second sequence follows the ﬁrst one .
Around 50 % of the inputs are a pair , and they randomly chose the other 50 .
Here , we use a bert - base - multilingual - cased ( Pires et al , 2019 ) trained on top of 104 languages in the largest Wikipedia corpus .
This model has 12 layers , 12 Attention heads with over 179 million parameters .
100[CLS]Tok 1Tok 2Tok N ..... E[CLS]E1E2EN ..... CTNT2T1 ............... LSTMLSTMLSTMLSTM ..... Global Average PoolingDropout .......... DenseLayer(128Neurons)DenseLayer(1Neuron)PretrainedLanguageModelNot - eventEvent  P Model mBERT 0.928 DistilmBERT 0.924 0.910 RoBERTa SoftVoting 0.937
Event R 0.917 0.947 0.938 0.939
Not - event
F1 0.922 0.936 0.924 0.938
P 0.641 0.729 0.670 0.720
R 0.675 0.646 0.578 0.713
F1 0.658 0.685 0.621 0.717
Overall Acc M(P ) M(R ) M(F1 ) 0.790 0.810 0.772 0.827
0.796 0.797 0.758 0.826
0.784 0.827 0.790 0.829
0.873 0.893 0.873 0.899
Table 3 : Precision ( P ) , recall ( R ) , and F1 - Score of the models on the validation set ; M(P ) , M(R ) , and M(F1 ) are the Macro averages of precision , recall , and F1 - Score respectively
4.2 DistilmBERT
DistilBERT ( Sanh et al , 2019 ) is the distilled version of BERT .
DistilBERT employs a triple loss language modelling , where it integrates cosine distance loss with knowledge distillation .
DistilBERT has 40 % fewer parameters than BERT but still promises 97 % of the latter ’s performance .
It is also 60 % faster than BERT .
In this system , we used a cased multilingual DistilBERT model as they are three different languages .
For our cause , we ﬁnetune distilbert - base - multilingual - cased , which is distilled from the mBERT checkpoint .
The model has 6 layers , 768 dimensions , and 12 Attention heads , totalizing about 134 million parameters .
4.3 RoBERTa
Robustly Optimized BERT ( RoBERTa ) ( Liu et al , 2019 ) follows the same architecture of BERT while differing in the pretraining strategy .
It is pretrained with MLM as its objective where the model tries to predict the masked words .
RoBERTa model is trained on the vast English Wikipedia and CCNews datasets .
The NSP is not employed as a pretraining strategy , and the tokens are dynamically masked , making the model slightly different to BERT .
During tokenization , RoBERTa follows byte - pair encoding ( BPE ) ( Gall´e , 2019 ) as opposed to WordPiece employed in BERT .
We use robertabase , a pretrained language model consisting of 12 layers , 768 hidden , 12 attention heads , and 125 million parameters .
4.4 System Description
For our system , we ﬁne - tune the pretrained models discussed in Section 4.1 , 4.2 , and 4.3 .
We combine the three datasets as the number of samples for Spanish and Portuguese are quite low .
After combining the models , we split the validation set accordingly , maintaining the split ’s ratio and tabulating the results on the concatenated dataset in Table3 .
The embeddings are extracted from
these models to be fed as input to the LSTM layer , ( Hochreiter and Schmidhuber , 1997 ) as shown in Figure1 .
The resulting output is fed into a global average pooling layer ( Lin et al , 2014 ) and then passed into fully connected layers , followed by a sigmoid activation function to obtain the resulting probability score for the input sentences .
The same parameters are used for all three models .
A dropout layer ( Srivastava et al , 2014 ) is also added in between the fully connected layers for regularization .
Refer Table 4 for the parameters used in the model .
Parameters Number of LSTM units Dropout Rate Batch Size Max Length Optimizer Learning Rate Activation Function Loss Function
Values 128 0.2 16 128 Adam 3e-5 Sigmoid cross - entropy
Table 4 : Parameters used for training the Models
5 Results and Analysis
All pretrained language models are ﬁne - tuned in Google Colab2 for ten epochs .
We use the Tensorﬂow implementation of the models3 on the Huggingface transformers library4 .
We compare the macro F1 - Scores of our ﬁne - tuned models on the validation set , which were created by splitting the given dataset .
The remaining split is the training data .
The validation set contains samples from all three languages .
It has 4,387 Not - event sequences and 963 Event sequences making a combined total of 5,350 .
The results are shown in Table3 .
We ﬁne - tuned BERT , DistilBERT , and RoBERTa models on the training set .
We have combined the
2https://colab.research.google.com/ 3https://huggingface.co/transformers/pretrained models.html 4https://huggingface.co/
101  Language Macro F1 - Score 0.8291 English 0.7578 Spanish 0.7951 Portuguese
Table 5 : Macro F1 - Scores on the Test Set
models .
The soft voting approach has achieved macro F1 - Scores of 0.8291 , 0.7578 , and 0.7951 for English , Spanish , and Portuguese , respectively .
For future work , we intend to explore class weighting techniques and semi - supervised approaches to improve our performance .
three language corpora into a single corpus comprising of all the three languages together .
The main intention towards using a multilingual model is that the representations learnt during one language ’s pretraining would help the other .
We can observe that DistilBERT achieved a better F1 - Score among the models mentioned in the previous sections .
RoBERTa gave the lowest score among these .
The reason could be that the RoBERTa model was not multilingual , unlike the other two ; however , it still managed to get a score very close to the BERT model .
It is imperative that performing soft voting on all three models has managed to increase the score .
One of the reasons for the poor performance of the models is the imbalance in the distribution of the classes .
In the dataset , there are 21,794 Not - event sentences and only 4,954 Event ones .
The models performed very well in the majority class and poorly in the minority class .
Having more Event samples could have certainly helped the model in distinguishing better among the classes .
Based on the performance of soft voting on the validation set , we have used the same for the test set .
The results for the test set are shown in Table5 .
The reason for relatively low scores of Spanish and Portuguese could be due to the inadequate support of the training set ( 2,741 and 1,182 ) instead of English ( 22,825 ) .
We also believe that our approach of combining datasets could have inﬂuenced the performance of the low support datasets .
6 Conclusion
The need to develop automated systems to detect any event is an active protest has constantly been increasing because of the escalation of social media users and several platforms to support them .
In this paper , we have explored several multilingual language models to classify if a given sentence talks about an event that has happened ( Event ) or not ( Not - event ) in three languages .
Our work primarily focuses on ﬁne - tuning language models and feeding them to an architecture we created .
We also observe that the problem of class imbalance has had a signiﬁcant impact on the performance of the
