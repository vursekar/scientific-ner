{"authors": "David Trye; Andreea S Calude; Felipe Bravo-Marquez; Te Taka Keegan", "pub_date": "", "title": "M\u0101ori Loanwords: A Corpus of New Zealand English Tweets", "abstract": "M\u0101ori loanwords are widely used in New Zealand English for various social functions by New Zealanders within and outside of the M\u0101ori community. Motivated by the lack of linguistic resources for studying how M\u0101ori loanwords are used in social media, we present a new corpus of New Zealand English tweets. We collected tweets containing selected M\u0101ori words that are likely to be known by New Zealanders who do not speak M\u0101ori. Since over 30% of these words turned out to be irrelevant (e.g., mana is a popular gaming term, Moana is a character from a Disney movie), we manually annotated a sample of our tweets into relevant and irrelevant categories. This data was used to train machine learning models to automatically filter out irrelevant tweets.", "sections": [{"heading": "Introduction", "text": "One of the most salient features of New Zealand English (NZE) is the widespread use of M\u0101ori words (loanwords), such as aroha (love), kai (food) and Aotearoa (New Zealand). See ex. (1) specifically from Twitter (note the informal, conversational style and the M\u0101ori loanwords emphasised in bold).\n(1) Led the waiata for the manuhiri at the p\u014dwhiri for new staff for induction week. Was told by the kaum\u0101tua I did it with mana and integrity.\nThe use of M\u0101ori words has been studied intensively over the past thirty years, offering a comprehensive insight into the evolution of one of the youngest dialects of English -New Zealand English (Calude et al., 2017;Daly, 2007Daly, , 2016; Davies and Maclagan, 2006;De Bres, 2006;Degani and Onysko, 2010;Kennedy and Yamazaki, 1999;Macalister, 2009Macalister, , 2006aOnysko and Calude, 2013). One aspect which is missing in this body of work is the online discourse presence of the loanwords -almost all studies come from (collaborative) written language (highly edited, revised and scrutinised newspaper language, Davies and Maclagan 2006;Macalister 2009Macalister , 2006aOnysko and Calude 2013, and picture-books, Daly 2007, 2016, or from spoken language collected in the late 1990s (Kennedy and Yamazaki, 1999).\nIn this paper, we build a corpus of New Zealand English tweets containing M\u0101ori loanwords. Building such a corpus has its challenges (as discussed in Section 3.1). Before we discuss these, it is important to highlight the uniqueness of the language contact situation between M\u0101ori and (NZ) English.\nThe language contact situation in New Zealand provides a unique case-study for loanwords because of a number of factors. We list three particularly relevant here. First, the direction of lexical transfer is highly unusual, namely, from an endangered indigenous language (M\u0101ori) into a dominant lingua franca (English). The large-scale lexical transfer of this type has virtually never been documented elsewhere, to the best of our knowledge (see summary of current language contact situations in Stammers and Deuchar 2012, particularly Table 1, p. 634).\nSecondly, because M\u0101ori loanwords are \"New Zealand's and New Zealand's alone\" (Deverson, 1991, p. 18-19), and above speakers' consciousness, their ardent study over the years provides a fruitful comparison of the use of loanwords across genres, contexts and time.\nFinally, the aforementioned body of previous research on the topic is rich and detailed, and still rapidly changing, with loanword use being an increasing trend (Macalister, 2006a;Kennedy and Yamazaki, 1999). However, the jury is still out regarding the reasons for the loanword use (some hypotheses have been put forward), and the pat-terns of use across different genres (it is unclear how language formality influences loanword use).\nWe find that Twitter data complements the growing body of work on M\u0101ori loanwords in NZE, by adding a combination of institutional and individual linguistic exchanges, in a non-editable online platform. Social media language shares properties with both spoken and written language, but is not exactly like either. More specifically, Twitter allows for creative expression and lexical innovation (Grieve et al., 2017).\nOur Twitter corpus was created by following three main steps: collecting tweets over a ten-year period using \"query words\" (Section 3.1), manually labelling thousands of randomly-sampled tweets as \"relevant\" or \"irrelevant\" (Section 3.2), and then training a classifier to obtain automatic predictions for the relevance of each tweet and deploying this model on our target tweets, in a bid to filter out all those which are \"irrelevant\" (Section 3.3). As will be discussed in Section 2, our corpus is not the first of its kind but is the first corpus of New Zealand English tweets and the first collection of online discourse built specifically to analyse the use of M\u0101ori loanwords in NZE. Section 4 outlines some preliminary findings from our corpus and Section 5 lays out plans for future work.", "n_publication_ref": 21, "n_figure_ref": 0}, {"heading": "Related Work", "text": "It is uncontroversial that M\u0101ori loanwords are both productively used in NZE and increasing in popularity (Macalister, 2006a). The corpora analysed previously indicate that loanword use is highly skewed, with some language users leading the way -specifically M\u0101ori women (Calude et al., 2017;Kennedy and Yamazaki, 1999), and with certain topics of discourse drawing significantly higher counts of loanwords than others -specifically those related to M\u0101ori people and M\u0101ori affairs, M\u0101oritanga (Degani, 2010). The type of loanwords being borrowed from M\u0101ori is also changing. During the first wave of borrowing, some two-hundred years ago, many flora and fauna words were being borrowed; today, it is social culture terms that are increasingly adopted, e.g., aroha (love), whaea (woman, teacher), and tangi (M\u0101ori funeral), see Macalister (2006a). However, the data available for loanword analysis is either outdated (Calude et al., 2017;Kennedy and Yamazaki, 1999), or exclusively formal and highly edited (mainly newspaper language, Macalister 2006a; Davies and Maclagan 2006;Degani 2010), so little is known about M\u0101ori loanwords in recent informal NZE interactions -a gap we hope to address here.\nWith the availability of vast amounts of data, building Twitter corpora has been a fruitful endeavour in various languages, including Turkish (\u015e im\u015fek and\u00d6zdemir, 2012; \u00c7 etinoglu, 2016), Greek (Sifianou, 2015), German (Scheffler, 2014;Cieliebak et al., 2017), and (American) English (Huang et al., 2016) (though notably, not New Zealand English, while a modest corpus of te reo M\u0101ori tweets does exist, Keegan et al. 2015). Twitter corpora of mixed languages are tougher to collect because it is not straightforward to detect mixed language data automatically. Geolocations can help to some extent, but they have limitations (most users do not use them to begin with). Recent work on Arabic has leveraged the presence of distinct scripts -the Roman and Arabic alphabet -to create a mixed language corpus (Voss et al., 2014), but this option is not available to us. M\u0101ori has traditionally been a spoken (only) language, and was first written down in the early 1800s by European missionaries in conjunction with M\u0101ori language scholars, using the Roman alphabet (Smyth, 1946). Our task is more similar to studies such as Das andGamb\u00e4ck (2014) and\u00c7 etinoglu (2016), who aim to find a mix of two languages which share the same script (in their case, Hindi and English, and Turkish and German, respectively), but our method for collecting tweets is not user-based; instead we use a set of target query words, as detailed in Section 3.1.", "n_publication_ref": 20, "n_figure_ref": 0}, {"heading": "The Corpus", "text": "In this section, we describe the process of building the M\u0101ori Loanword Twitter Corpus (hereafter, the MLT Corpus) 1 . This process consists of three main steps, as depicted in Figure 1.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "Step 1: Collecting Tweets", "text": "In order to facilitate the collection of relevant data for the MLT Corpus, we compiled a list of 116 target loanwords, which we will call \"query words\". Most of these are individual words but some are short phrasal units (tangata whenua, people of the land; kapa haka, cultural performance). The list is largely derived from Hay (2018) but was modified to exclude function words (such as numerals) and most proper nouns, except five that have native English counterparts: Aotearoa (New Zealand), Kiwi(s) (New Zealander(s)), M\u0101ori (indigenous New Zealander), P\u0101keh\u0101 (European New Zealander), non-M\u0101ori (non-indigenous New Zealander). We also added three further loanwords which we deemed useful for increasing our data, namely haurangi (drunk), wairangi (drugged, confused), and p\u014drangi (crazy).\nUsing the Twitter Search API, we harvested 8 million tweets containing at least one query word (after converting all characters to lowercase). The tweets were collected diachronically over an eleven year period, between 2007-2018. We ensured that tweets were (mostly) written in English by using the lang:en parameter.\nA number of exclusions and further adjustments were made. With the aim of avoiding redundancy and uninformative data, retweets and tweets with URLs were discarded. Tweets in which the query word was used as part of a username or mention (e.g., @happy kiwi) were also discarded. For those query words which contained macrons, we found that users were inconsistent in their macron use. Consequently, we consolidated the data by adjusting our search to include both the macron and the non-macron version (e.g., both M\u0101ori and Maori). We also removed all tweets containing fewer than five tokens (words), due to insufficient context of analysis.\nOwing to relaxed spelling conventions on Twitter (and also the use of hashtags), certain query words comprising multiple lexical items were stripped of spaces in order to harvest all variants of the phrasal units (e.g., kai moana and kaimoana). As kai was itself a query word (in its own right), we excluded tweets containing kai moana when searching for tweets containing kai (and repeated this process with similar items).\nAfter inspecting these tweets, it was clear that a large number of our query words were polysemous (or otherwise unrelated to NZE), and had introduced a significant amount of noise into the data. The four main challenges we encountered are described below.\nFirst, because Twitter contains many different varieties of English, NZE being just one of these, it is not always straightforward to disentangle the dialect of English spoken in New Zealand from other dialects of English. This could be a problem when, for instance, a M\u0101ori word like Moana (sea) is used in American English tweets to denote the Disney movie (or its main character).\nSecondly, M\u0101ori words have cognate forms with other Austronesian languages, such as Hawaiian, Samoan and Tongan, and many speakers of these languages live and work (and tweet) in New Zealand. For instance, the word wahine (woman) has the same written form in M\u0101ori and in Hawaiian. But cognates are not the only problematic words. Homographs with other, genealogically-unrelated languages can also pose problems. For instance, the M\u0101ori word hui (meeting) is sometimes used as a proper noun in Chinese, as can be seen in the following tweet: \"Yo is Tay Peng Hui okay with the tip of his finger?\".\nProper nouns constitute a third problematic aspect in our data. As is typical for many language contact situations where an indigenous language shares the same geographical space as an incoming language, M\u0101ori has contributed many place names and personal names to NZE, such as Timaru, Aoraki, Titirangi, H\u0113mi, Mere and so on. While these proper nouns theoretically count as loanwords, we are less interested in them than in content words because the use of the former does not constitute a choice, whereas the use of the latter does (in many cases). The \"choice\" of whether to use a loanword or whether to use a native English word (or sometimes a native English phrase) is interesting to study because it provides insights into idiolectal lexical preferences (which words different speakers or writers prefer in given contexts) and relative borrowing success rates (Calude et al., 2017;Zenner et al., 2012).\nFinally, given the impromptu and spontaneous nature of Twitter in general, we found that certain M\u0101ori words coincided with misspelled versions of intended native English words, e.g., whare (house) instead of where.\nThe resulting collection of tweets, termed the Original Dataset, was used to create the Raw Corpus, as explained below.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Step 2: Manually Annotating Tweets", "text": "We decided to address the \"noisy\" tweets in our data using supervised machine learning. Two coders manually inspected a random sample of 30 tweets for each query word, by checking the word's context of use, and labelled each tweet as \"relevant\" or \"irrelevant\". For example, a tweet like that in example (1) would be coded as relevant and one like \" awesome!! Congrats to Tangi :)\", would be coded as irrelevant (because the query word tangi is used as a proper noun). Since 39 of the query words consistently yielded irrelevant tweets (at least 90% of the time), these (and the tweets they occurred in) were removed altogether from the data. Our annotators produced a total of 3, 685 labelled tweets for the remaining 77 query words, which comprise the Labelled Corpus (see Tables 1 and 4; note that irrelevant tweets have been removed from the latter for linguistic analysis).\nAssuming our coded samples are representative of the real distribution of relevant/irrelevant tweets that occur with each query word, it makes sense to also discard the 39 \"noisy\" query words from our Original Dataset. In this way, we created the (unlabelled) Raw Corpus, which is a fifth of the size (see Table 4).\nWe computed an inter-rater reliability score for our two coders, based on a random sample of 200 tweets. Using Cohen's Kappa, we calculated this value to be 0.87 (\"strong\"). In light of the strong agreement between the initial coders, no further coders were enlisted for the task.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Step 3: Automatically Extracting Relevant Tweets", "text": "The next step was to train a classifier using the Labelled Corpus as training data, so that the resulting model could be deployed on the Raw Corpus. Our goal is to obtain automatic predictions for the relevance of each tweet in this corpus, according to probabilities given by our model. We created (stratified) test and training sets that maintain the same proportion of relevant and irrelevant tweets associated with each query word in the Labelled Corpus. We chose to include 80% of these tweets in the training set and 20% in the test set (see Table 1   Using the AffectiveTweets package (Bravo-Marquez et al., 2019), our labelled tweets were transformed into feature vectors based on the word n-grams they contain. We then trained various classification models on this transformed data in Weka (Hall et al., 2009). The models we tested were 1) Multinomial Naive Bayes (McCallum et al., 1998) with unigram attributes and 2) L2regularised logistic regression models with different word n-gram features, as implemented in LIB-LINEAR 2 . We selected Multinomial Naive Bayes as the best model because it produced the highest AUC, Kappa and weighted average F-Score (see Table 2 for a summary of results). Overall, logistic regression with unigrams performed the worst, yielding (slightly) lower values for all three measures.\nAfter deploying the Multinomial Naive Bayes model on the Raw Corpus, we found that 1,179,390 tweets were classified as relevant and 448,652 as irrelevant (with probability threshold = 0.5).\nTable 3 shows examples from our corpus of each type of classification. Some tweets were falsely classified as \"irrelevant\" and some were falsely classified as \"relevant\". A short explanation why the irrelevant tweets were coded as such is given in brackets at the end of each tweet.\nWe removed all tweets classified as irrelevant,  thereby producing the Processed Corpus. A summary of all three corpora is given in Table 4.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "Preliminary Findings", "text": "As we are only just beginning to sift through the MLT Corpus, we note two particular sets of preliminary findings. First, even though our corpus was primarily geared up to investigate loanword use, we are finding that, unlike other NZE genres analysed, the Twitter data exhibits use of M\u0101ori which is more in line with code-switching than with loanword use, see ex. (2-3). This is particularly interesting in light of the reported increase in te reo M\u0101ori language tweets (Keegan et al., 2015).\n(2) M\u014drena e hoa! We must really meet IRL when I get back to T\u0101maki Makaurau! You have a fab day too!\n(3) Heh! He porangi toku ngeru -especially at 5 in the morning!! Ata marie e hoa ma. I am well thank you.\nSecondly, we also report the use of hybrid hashtags, that is, hashtags which contain a M\u0101ori part and an English part, for example #mycrazywhanau, #reostories, #Matarikistar, #bringitonmana, #growingupkiwi, #kaitoputinmyfridge. To our knowledge, these hybrid hashtags have never been analysed in the current literature. Hybrid hashtags parallel the phenomenon of hybrid compounds discussed by Degani and Onysko (2010). Degani and Onysko report that hybrid compounds are both productive and semantically novel, showing that the borrowed words take on reconceptualised meanings in their adoptive language (2010, p.231).", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Irrelevant tweets", "text": "Relevant tweets f(x)<0.5 Classified irrelevant Haka ne! And i know even the good guys get blood for body (0.282, foreign language) son didnt get my chop ciggies 2day so stopped talking 2 him. he just walked past and gave me the maori eyebrow lift and a smile. were friends (0.337) Whare has the year gone (0.36, misspelling) Shorts and bare feet in this whare (0.41) chegar na morena e falar can i be your girlfriend can i (0.384, foreign language)   ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Conclusions and Future Work", "text": "This paper introduced the first purpose-built corpus of M\u0101ori loanwords on Twitter, as well as a methodology for automatically filtering out irrelevant data via machine learning. The MLT Corpus opens up a myriad of opportunities for future work.\nSince our corpus is a diachronic one (i.e., all tweets are time-stamped), we are planning to use it for testing hypotheses about language change. This is especially desirable in the context of New Zealand English, which has recently undergone considerable change as it comes into the final stage of dialect formation (Schneider, 2003).\nAnother avenue of future research is to automatically identify other M\u0101ori loanwords that are not part of our initial list of query words. This could be achieved by deploying a language detector tool on every unique word in the corpus (Martins and Silva, 2005). The \"discovered\" words could be used as new query words to further expand our corpus.\nIn addition, we intend to explore the meaning of our M\u0101ori loanwords using distributional semantic models. We will train popular word embeddings algorithms on the MLT Corpus, such as Word2Vec (Mikolov et al., 2013) and FastText (Bojanowski et al., 2017), and identify words that are close to our loanwords in the semantic space. We predict that these neighbouring words will enable us to understand the semantic make-up of our loanwords according to their usage.\nFinally, we hope to extrapolate these findings by deploying our trained classifier on other online discourse sources, such as Reddit posts. This has great potential for enriching our understanding of how M\u0101ori loanwords are used in social media.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Acknowledgements", "text": "The authors would like to thank former Honours student Nicole Chan for a preliminary study on M\u0101ori Loanwords in Twitter. Felipe Bravo-Marquez was funded by Millennium Institute for Foundational Research on Data. Andreea S. Calude acknowledges the support of the NZ Royal Society Marsden Grant. David Trye acknowledges the generous support of the Computing and Mathematical Sciences group at the University of Waikato.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Enriching word vectors with subword information", "journal": "Transactions of the Association for Computational Linguistics", "year": "2017", "authors": "Piotr Bojanowski; Edouard Grave; Armand Joulin; Tomas Mikolov"}, {"title": "AffectiveTweets: a Weka package for analyzing affect in tweets", "journal": "Journal of Machine Learning Research", "year": "2019", "authors": "Felipe Bravo-Marquez; Eibe Frank; Bernhard Pfahringer; Saif M Mohammad"}, {"title": "Modelling loanword success-a sociolinguistic quantitative study of M\u0101ori loanwords in New Zealand English", "journal": "", "year": "2017", "authors": "Andreea Simona Calude; Steven Miller; Mark Pagel"}, {"title": "A Turkish-German codeswitching corpus", "journal": "", "year": "2016", "authors": "\u00c7 Ozlem;  Etinoglu"}, {"title": "A twitter corpus and benchmark resources for German sentiment analysis", "journal": "", "year": "2017-12-11", "authors": "Mark Cieliebak; Jan Milan Deriu; Dominic Egger; Fatih Uzdilli"}, {"title": "K\u016bkupa, koro, and kai: The use of M\u0101ori vocabulary items in New Zealand English children's picture books", "journal": "", "year": "2007", "authors": "Nicola Daly"}, {"title": "Dual language picturebooks in English and M\u0101ori", "journal": "Bookbird: A Journal of International Children's Literature", "year": "2016", "authors": "Nicola Daly"}, {"title": "Identifying languages at the word level in code-mixed Indian social media text", "journal": "", "year": "2014", "authors": "Amitava Das; Bj\u00f6rn Gamb\u00e4ck"}, {"title": "M\u0101ori words-read all about it: Testing the presence of 13 m\u0101ori words in four New Zealand newspapers from", "journal": "Te Reo", "year": "1997", "authors": "Carolyn Davies; Margaret Maclagan"}, {"title": "Maori lexical items in the mainstream television news in New Zealand", "journal": "New Zealand English Journal", "year": "2006", "authors": "Julia De Bres"}, {"title": "The Pakeha myth of one New Zealand/Aotearoa: An exploration in the use of Maori loanwords in New Zealand English. From international to local English-and back again", "journal": "", "year": "2010", "authors": "Marta Degani"}, {"title": "", "journal": "Hybrid compounding in New Zealand English. World Englishes", "year": "2010", "authors": "Marta Degani; Alexander Onysko"}, {"title": "New Zealand English lexis: the Maori dimension", "journal": "English Today", "year": "1991", "authors": "Tony Deverson"}, {"title": "Analyzing lexical emergence in Modern American English online", "journal": "English Language & Linguistics", "year": "2017", "authors": "Jack Grieve; Andrea Nini; Diansheng Guo"}, {"title": "The WEKA data mining software: an update", "journal": "ACM SIGKDD explorations newsletter", "year": "2009", "authors": "Mark Hall; Eibe Frank; Geoffrey Holmes; Bernhard Pfahringer; Peter Reutemann; Ian H Witten"}, {"title": "What does it mean to \"know a word?", "journal": "", "year": "2018", "authors": "Jennifer Hay"}, {"title": "Understanding US regional linguistic variation with twitter data analysis. Computers, Environment and Urban Systems", "journal": "", "year": "2016", "authors": "Yuan Huang; Diansheng Guo; Alice Kasakoff; Jack Grieve"}, {"title": "Using Twitter in an indigenous language: An analysis of Te Reo M\u0101ori tweets", "journal": "AlterNative: An International Journal of Indigenous Peoples", "year": "2015", "authors": "Paora Te Taka Keegan; Stacey Mato;  Ruru"}, {"title": "The influence of Maori on the Nw Zealand English lexicon", "journal": "LANGUAGE AND COMPUTERS", "year": "1999", "authors": "Graeme Kennedy; Shunji Yamazaki"}, {"title": "The Maori lexical presence in New Zealand English: Constructing a corpus for diachronic change", "journal": "Corpora", "year": "2006", "authors": "John Macalister"}, {"title": "the Maori presence in the New Zealand English lexicon, 1850-2000: Evidence from a corpus-based study", "journal": "English World-Wide", "year": "2006", "authors": "John Macalister"}, {"title": "Investigating the changing use of Te Reo", "journal": "NZ Words", "year": "2009", "authors": "John Macalister"}, {"title": "Language identification in web pages", "journal": "ACM", "year": "2005", "authors": "Bruno Martins; J M\u00e1rio;  Silva"}, {"title": "A comparison of event models for naive Bayes text classification", "journal": "Citeseer", "year": "1998", "authors": "Andrew Mccallum; Kamal Nigam"}, {"title": "Distributed representations of words and phrases and their compositionality", "journal": "", "year": "2013", "authors": "Tomas Mikolov; Ilya Sutskever; Kai Chen; Greg S Corrado; Jeff Dean"}, {"title": "Comparing the usage of M\u0101ori loans in spoken and written New Zealand English: A case study of M\u0101ori, P\u0101keh\u0101, and Kiwi. New perspectives on lexical borrowing: Onomasiological, methodological, and phraseological innovations", "journal": "", "year": "2013", "authors": "Alexander Onysko; Andreea Calude"}, {"title": "A German twitter snapshot", "journal": "Citeseer", "year": "2014", "authors": "Tatjana Scheffler"}, {"title": "The dynamics of New Englishes: From identity construction to dialect birth", "journal": "Language", "year": "2003", "authors": "W Edgar;  Schneider"}, {"title": "Conceptualizing politeness in Greek: Evidence from twitter corpora", "journal": "Journal of Pragmatics", "year": "2015", "authors": "Maria Sifianou"}, {"title": "Analysis of the relation between Turkish twitter messages and stock market index", "journal": "IEEE", "year": "2012", "authors": "Mehmet Ulvi; \u015e Im\u015fek; Suat\u00f6zdemir "}, {"title": "Maori Pronunciation and the Evolution of Written Maori", "journal": "Whitcombe & Tombs Limited", "year": "1946", "authors": "Patrick Smyth"}, {"title": "Testing the nonce borrowing hypothesis: Counterevidence from English-origin verbs in Welsh", "journal": "Bilingualism: Language and Cognition", "year": "2012", "authors": "R Jonathan; Margaret Stammers;  Deuchar"}, {"title": "Finding Romanized Arabic dialect in code-mixed tweets", "journal": "", "year": "2014", "authors": "R Clare; Stephen Voss; Jamal Tratz; Douglas M Laoudi;  Briesch"}, {"title": "Cognitive Sociolinguistics meets loanword research: Measuring variation in the success of anglicisms in Dutch", "journal": "Cognitive Linguistics", "year": "2012", "authors": "Eline Zenner; Dirk Speelman; Dirk Geeraerts"}], "figures": [{"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "The corpus-building process.", "figure_data": "Proud to be a kiwi haka ne kuma faLove my crazy whanau Proud to be a kiwi Moana is my fav Princess haka ne kuma fa 2Target Tweetstweet 1 tweet 2 ... tweet mFigure 1:"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Dataset statistics for our labelled tweets. This Table shows the relevant, irrelevant and total number of instances (i.e., tweets) in the independent training and test sets.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Classification results on the test set. The best results for each column are shown in bold. The value of n corresponds to the type of word n-grams included in the feature space.", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "A selection of tweets and their classification types. The first three irrelevant tweets were classified correctly (i.e. true negatives), as were the last three relevant tweets (i.e. true positives). Function f (x) corresponds to the posterior probability of the \"relevant\" class. The entries in brackets for the irrelevant examples correspond to the values of f (x) and the reason why the target word was coded as irrelevant.", "figure_data": "Raw Labelled ProcessedTokens (words)28,804,64049,477 21,810,637Tweets1,628,0422,4951,179,390Tweeters (authors)604,0061,866426,280"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "A description of the MLT Corpus' three components (namely, the Raw Corpus, Labelled Corpus and Processed Corpus), which were harvested using the same 77 query words.", "figure_data": ""}], "doi": ""}