The Strength of the Weakest Supervision : Topic Classification Using Class Labels
When developing topic classifiers for realworld applications , we begin by defining a set of meaningful topic labels . Ideally , an intelligent classifier can understand these labels right away and start classifying documents . Indeed , a human can confidently tell if a news article is about science , politics , sports , or none of the above , after knowing just the class labels . We study the problem of training an initial topic classifier using only class labels . We investigate existing techniques for solving this problem and propose a simple but effective approach . Experiments on a variety of topic classification data sets show that learning from class labels can save significant initial labeling effort , essentially providing a " free " warm start to the topic classifier .
When developing topic classifiers for real - world tasks , such as news categorization , query intent detection , and user - generated content analysis , practitioners often begin by crafting a succinct definition , or a class label , to define each class . Unfortunately , these carefully written class labels are completely ignored by supervised topic classification models . Given a new task , these models typically require a significant amount of labeled documents to reach even a modest initial performance . In contrast , a human can readily understand new topic categories by reading the class definitions and making connections to prior knowledge . Labeling initial examples for every new task can be time - consuming and laborintensive , especially in resource - constrained domains like medicine and law . Therefore it is desirable if a topic classifier can proactively interpret class labels before the training starts , giving itself a " warm start " . An imperfect initial model can always be fine - tuned with more labeled documents . As conceptually shown in Figure 1 , a warm start can reduce the total number of training labels for a classifier to reach certain performance level . In this work , we study algorithms that can initialize a topic classifier using class labels only . Since class labels are the starting point of any topic classification task , they can be viewed as the earliest hence weakest supervision signal . We propose a simple and effective approach that combines word embedding and naive Bayes classification . On six topic classification data sets , we evaluate a suite of existing approaches and the proposed approach . Experimental results show that class labels can train a topic classifier that generalizes as well as a classifier trained on hundreds to thousands of labeled documents .
Text retrieval . Classifying documents by short labels can be viewed as evaluating textual similarity between a document and a label . Baeza - Yates et al ( 2011 ) called this approach " naive text classification " . Treating labels as search queries , we can classify a document into a class if it best matches the label of that class . Well - studied text retrieval methods , such as vector space models and probabilistic models ( Croft et al , 2010 ) , can produce matching scores . To mitigate vocabulary mismatch , such a classifier can be further enhanced by self - training : the classifier assigns pseudo labels to top - ranked documents as done in pseudo relevance feedback ( Rocchio , 1965 ) , and updates itself using those labels . Semi - supervised learning . Our problem setting can be seen as an extreme case of weak supervision : we only use class labels as the ( noisy ) supervision signal , and nothing else . If we view class labels as " labeled documents " , one from each class , and to - be - classified documents as unlabeled documents , then we cast the problem as semisupervised learning ( Zhu , 2006 ) . Self - training is one such technique : a generative classifier is trained using only class labels , and then teaches itself using its own predictions on unlabeled data . If we view class labels as " labeled features " , then we expect the classifier to predict a class when a document contains the class label words . For instance , Druck et al ( 2008 ) proposed generalized expectation criteria that uses feature words ( class labels ) to train a discriminative classifier . Jagarlamudi et al ( 2012 ) and Hingmire and Chakraborti ( 2014 ) proposed Seeded LDA to incorporate labeled words / topics into statistical topic modeling . The inferred document - topic mixture probabilities can be used to classify documents . Zero - shot learning aims to classify visual objects from a new class using only word descriptions of that class ( Socher et al , 2013 ) . It first learns visual features and their correspondence with word descriptions , and then constructs a new classifier by composing learned features . Most research on zero - shot learning focuses on image classification , but the same principle applies to text classification as well ( Pushp and Srivastava , 2017 ) . Our proposed method constructs a new classifier by composing learned word embeddings in a probabilistic manner . Since the new classifier transfers semantic knowledge in word embedding to topic classification tasks , it is broadly related to transfer learning ( Pan and Yang , 2010 ) . The main difference is that in transfer learning the information about the new task is in the form of labeled data , not class definition words .
Let a test document x be a sequence of words ( w 1 , , w j , ) , and a class topic description y be a sequence of words d y = ( w 1 , , w y , ) . All words are in vocabulary V . We propose a generative approach , where the predictive probabil - ity p ( y | x ) ∝ p ( x | y ) p ( y ) . Generative approaches tends to perform well when training data is scarce , which is the case in our setting . We assume there exists weak prior knowledge on which classes are popular and which are rare . We can then construct rough estimatesp ( y ) using simple heuristics as described in ( Schapire et al , 2002 ) . It distributes probability mass q evenly among majority classes , and 1 − q evenly among minority classes . We treat the most frequent class as the majority class , the rest as minority classes , and q = 0.7 in our experiments . By interpreting class topic description as words , we obtainp ( x | y ) = p ( x | d y ) . We assume that the d y expresses a noisy - OR relation of the words it contains ( Oniśko et al , 2001 ) . Up to first - order approximation : p ( x | d y ) = 1 − wy dy ( 1 − p ( x | w y ) ) ≈ wy dy p ( x | w y ) , ( 1 ) where each w y is a word in the class topic description d y . Further , we assume that words in document x are conditionally independent given a label word w y ( naïve Bayes assumption ) : p ( x | w y ) = w j x p ( w j | w y ) . ( 2 ) Combining ( 1 ) and ( 2 ) , the document likelihood iŝ p ( x | y ) = wy dy w j x p ( w j | w y ) . To this end , we need a word association model p ( w 1 | w 2 ) , ∀w 1 , w 2 V . It can be efficiently learned by word embedding algorithms . The skipgram algorithm learns vector representations of words , such that for words w 1 , w 2 , their vectors u w 1 , v w 2 approximate the conditional probability 1 p ( w 1 | w 2 ) = exp u w 1 v w 2 w V exp ( u w v w 2 ) . ( 4 ) Combining ( 3 ) with ( 4 ) , the document likelihood becomeŝ p ( x | y ) = wy dy exp   w j x u w j v wy − C wy   , where C wy = log w V exp u w v wy is independent of document x and only related to label word w y , therefore can be precomputed and stored to save computation . Finally , we construct an generative classifier aŝ p ( y | x ) ∝p ( x | y ) p ( y ) . We call this method word embedding naïve Bayes ( WENB ) .
The proposed method produces pseudo labelŝ p ( y | x j ) for unlabeled documents { x j } m j=1 . When true labels { ( x i , y i ) } n i=1 are available , we can train a new discriminative logistic regression classifier p θ ( y | x ) using both true and pseudo labels ( θ is the model parameter ) : J ( θ ) = n i=1 y Y −1 { y i = y } log p θ ( y | x i ) + λ θ 2 + µ m j=1 y Y −p ( y | x j ) log p θ ( y | x j ) . ( 5 ) To find the balance of pseudo vs. true labels in ( 5 ) , we search the hyperparameter µ on a 5point grid { 10 −2 , 10 −1 , 0.4 , 0.7 , 1 } . We expect pseudo labels to have comparable importance as true labels when n is small ( fine granularity for µ [ 10 −1 , 1 ] ) , and their importance will diminish as n gets large ( µ = 10 −2 ) . µ is automatically selected such that it gives the best 5 - fold crossvalidation accuracy on n true labels .
We compare a variety of methods on six topic classification data sets . The goals are ( 1 ) to study the best classification performance achievable using class labels only , and ( 2 ) to estimate the equivalent amount of true labels needed to achieve the same warm - start performance .
Retrieval - based methods . We use language modeling retrieval function with Dirichlet smoothing ( Zhai and Lafferty , 2001 ) ( µ = 2500 ) to match a document to class labels ( IR ) . The top 10 results are then used as pseudo - labeled documents to retrain three classifiers : IR+Roc : a Rocchio classifier ( α = 1 , β = 0.5 , γ = 0 ) ; IR+NB : a multinomial naive Bayes classifier ( Laplace smoothing , α = 0.01 ) ; IR+LR a logistic regression classifier ( linear kernel , C = 1 ) . Semi - supervised methods . ST - 0 : the initial self - training classifier using class labels as " training documents " ( multinomial naïve Bayes , Laplace smoothing α = 0.01 ) . ST - 1 : ST - 0 retrained on 10 most confident documents predicted by itself . GE : a logistic regression classifier trained using generalized expectation criteria ( Druck et al , 2008 ) . Class labels are used as labeled features . sLDA : a supervised topic model trained using seeded LDA ( Jagarlamudi et al , 2012 ) . Besides k seeded topics ( k is the number of classes ) , we use an extra topic to account for other content in the corpus . Word embedding - based methods . Cosine : a centroid - based classifier , where class definitions and documents are represented as average of word vectors . WENB : The proposed method ( Section 3 ) . WENB+LR : a logistic regression classifier trained only on pseudo labels produced by WENB ( Section 3.1 , n = 0 ) . For general domain tasks , we take raw text from English Wikipedia , English news crawl ( WMT , 2014 ) , and 1 billion word news corpus ( Chelba et al , 2013 ) to train word vectors . For medical domain tasks , we take raw text from MEDLINE abstracts ( NLM , 2018 ) to train word vectors . We find 50 - dimensional skip - gram word vectors perform reasonably well in the experiments .
We consider six topic classification data sets with different document lengths and application domains . Table 1 summarizes basic statistics of these data sets . Table 4 and Three short text data sets are ( 1 ) Wiki Titles : Wikipedia article titles sampled from 15 main categories ( Wikipedia Main Topic ) . ( 2 ) News Titles : The UCI news title data set ( Lichman , 2013 ) . ( 3 ) Y Questions : User - posted questions in Yahoo Answers ( Yahoo Language Data , 2007 ) . Three long text data sets are ( 1 ) 20 News : The well - known 20 newsgroup data set . ( 2 ) Reuters . The Reuters - 21578 data set ( Lewis ) . We take the articles from the 10 largest topics . ( 3 ) Med WSD : The MeSH word sense disambiguation ( WSD ) data set ( Jimeno - Yepes et al , 2011 ) . Each WSD task aims to tell the sense ( meaning ) of an ambiguous term in a MEDLINE abstract . For instance , the term " cold " may refer to Low Temperature , Common Cold , or Chronic Obstructive Lung Disease , depending on its context . These senses are used as the class labels . We use 198 ambiguous words with at least 100 labeled abstracts in the data set , and report the average statistics over 198 independent classification tasks . Although no true labels are used for training , some methods require unlabeled data for retrieval , pseudo - labeling , and re - training . We split unlabeled data into 5 folds , using 4 folds to " train " a classifier and 1 fold for test . We use macroaveraged F 1 as the performance metric because not all data sets have a balanced class distribution .
Label savings . Table 2 shows that overall , class labels can train text classifiers remarkably better than majority guess . This is no small feat considering that the classifier has not seen any labeled documents yet . Such performance gain essentially comes " for free " , as any text classification task has to start by defining classes . In Table 3 , we report the number of true labels needed for a logistic regression model to achieve the same performance as WENB+LR . The most significant savings happen on short documents : class labels are equivalent to hundreds to thousands of labeled documents at the beginning of the training process . Effect of document length . On short documents ( Wiki Titles , News Titles , Y Questions ) , leveraging unlabeled data does not help with most semi - supervised methods due to severe vocabulary mismatch . The proposed methods ( WENB and WENB+LR ) show robust performance , because pretrained word vectors can capture semantic similarity even without any word overlap between a class label and a document . This prior knowledge is essential when documents are short . On long documents ( 20 News , Reuters , Med WSD ) , leveraging unlabeled data helps , since long documents have richer content and are more likely to contain not only label words themselves , but also other topic - specific words . Retrieval - based and semi - supervised methods are able to learn these words by exploiting intra - document word co - occurrences . Performance of other methods . Learning from class labels themselves provides very limited help ( IR and ST - 0 ) . Using class labels as search queries and labeled documents are closely related : IR and ST - 0 perform similarly ; so do IR+NB and ST - 1 . When using class labels as search queries , 2 shows a salient warm - start effect on a balanced binary classification task in 20 News . The weight µ of pseudo labels increases when true labels are few ( initial classifier as an informative prior ) . As expected , µ decreases when true labels become abundant . Figure 3 shows another binary classification task in 20 News where the warm - start effect is limited . Correspondingly , µ quickly diminishes as more true labels are available . With 100 or more true labels , pseudo labels have a negligible weight ( µ = 10 −2 ) . In machine learning terms , these pseudo labels specify an incorrect prior that the model should quickly forget , so that it will not hinder the overall learning process . A closer investigation reveals that the word vector for mideast ( the class label of one topic in Figure 3 ) is not well - trained . This is because in general text corpus , the word mideast is rather infrequent compared to commonly used alternatives , such as middle east . The word vector of mideast is surrounded by other infrequent words or misspellings ( such as hizballah , jubeir , saudis , isreal ) as opposed to more frequent and relevant ones ( such as israel , israeli , saudi , arab ) . Since WENB uses the semantic knowledge in word vectors to infer pseudo labels , the quality of class label word vectors will affect the pseudo label accuracy .
We studied the problem of training topic classifiers using only class labels . Experiments on six data sets show that class labels can save a significant amount of labeled examples in the beginning . Retrieval - based and semi - supervised methods tend to perform better on long documents , while the proposed method performs better on short documents . This study opens up many interesting avenues for future work . First , we introduce a new perspective on text classification : can we build a text classifier by just providing a short description of each class ? This is a more challenging ( but more user - friendly ) setup than standard supervised classification . Second , future work can investigate tasks such as sentiment and emotion classification , which are more challenging than topic classification tasks . Third , the two approaches - leveraging unlabeled data ( retrievalbased and semi - supervised methods ) and leveraging pretrained models ( the proposed method ) could be combined to give robust performance on both short and long documents . Finally , we can invite users into the training loop : in addition to labeling documents , users can also revise the class definitions to improve the classifier .
We thank the anonymous reviewers for their helpful comments . This work was in part supported by the National Library of Medicine under grant number 2R01LM010681 - 05 . Qiaozhu Mei 's work was supported in part by the National Science Foundation under grant numbers 1633370 and 1620319 . Yue Wang would like to thank the support of the Eleanor M. and Frederick G. Kilgour Research Grant Award by the UNC - CH School of Information and Library Science .
