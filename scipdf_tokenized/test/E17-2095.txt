Context - Aware Graph Segmentation for Graph - Based Translation
In this paper , we present an improved graph - based translation model which segments an input graph into node - induced subgraphs by taking source context into consideration . Translations are generated by combining subgraph translations leftto - right using beam search . Experiments on Chinese - English and German - English demonstrate that the context - aware segmentation significantly improves the baseline graph - based model .
The well - known phrase - based statistical translation model ( Koehn et al , 2003 ) extends the basic translation units from single words to continuous phrases to capture local phenomena . However , one of its significant weaknesses is that it can not learn generalizations Galley and Manning , 2010 ) . To allow discontinuous phrases ( any subset of words of an input sentence ) , dependency treelets Xiong et al , 2007 ) can be used , which are connected subgraphs on trees . However , continuous phrases which are not connected on trees and thus excluded could in fact be extremely important to system performance ( Koehn et al , 2003 ; Hanneman and Lavie , 2009 ) . To make use of the merits of both phrase - based models and treelet - based models , Li et al ( 2016 ) proposed a graph - based translation model as in Equation ( 1 ) : p ( t I 1 | g I 1 ) = I i=1 p ( t i | g a i ) × d ( g a i , g a i−1 ) ( 1 ) where t i is a continuous target phrase which is the translation of a node - induced and connected source subgraph g a i . 1 d is a distance - based reordering function which penalizes discontinuous phrases that have relatively long gaps ( Galley and Manning , 2010 ) . The model translates an input graph by segmenting it into subgraphs and generates a complete translation by combining subgraph translations left - to - right . However , the model treats different graph segmentations equally . Therefore , in this paper we propose a contextaware graph segmentation ( Section 2 ) : ( i ) we add contextual information to each translation rule during training ( Section 2.2 ) ; ( ii ) during decoding , when a rule is applied , the input context should match with the rule context ( Section 2.3 ) . Experiments ( Section 3 ) on Chinese - English ( ZH - EN ) and German - English ( DE - EN ) tasks show that our method significantly improves the graphbased model . As observed in our experiments , the context - aware segmentation brings two benefits to our system : ( i ) it helps to select a better subgraph to translate ; and ( ii ) it selects a better target phrase for a subgraph .
Our model extends the graph - based translation model by considering source context during segmenting input graphs , as in Equation ( 2 ) : p ( t I 1 | g I 1 ) = I i=1 p ( t i | g a i , c a i ) × d ( g a i , g a i−1 ) ( 2 ) where c a i denotes the context of the subgraph g a i , which is represented as a set of connections ( i.e. edges ) between g a i and [ g a i+1 , , g a I ] . 2010Nian FIFA Shijiebei Zai Nanfei Chenggong Juxing
The graph used in this paper combines a sequence and a dependency tree as in Li et al ( 2016 ) . Each graph contains two kinds of links : dependency links from dependency trees which model syntactic and semantic relations between words , and bigram links which provide local and sequential information on pairs of continuous words . Figure 1 shows an example graph . Given such graphs , we can make use of both continuous and linguistically informed discontinuous phrases as long as they are connected on graphs . In this paper , we do not distinguish the two kinds of relations , because our preliminary experiments showed no improvement when considering edge types .
During training , given a word - aligned graphstring pair g , t , a , we extract translation rules g a i , c a i , t i , each of which consists of a continuous target phrase t i , a source subgraph g a i aligned to t i , and a source context c a i . We first find initial pairs . s a i , t i is an initial pair , iff it is consistent with the word alignment a ( Och and Ney , 2004 ) . s a j is a set of source words which are aligned to t i . Then , the set of rules satisfies the following : 1 . If s a i , t i is an initial pair ands a i is covered by a subgraph g a i which is connected , then g a i , * , t i is a basic rule . c a i = * means that a basic rule is applied without considering context to make sure that at least one translation is produced for any inputs during decoding . Therefore , basic rules are the same as rules in the conventional graph - based model . Rule ( 3 ) shows an example of a basic rule : 2010Nian FIFA Shijiebei 2010 FIFA World Cup ( 3 ) 2 . Assume g a i , * , t i is a basic rule and s a i+1 , t i+1 is an initial pair where t i+1 is on the right of and adjacent to t i . If there are edges between g a i ands a i+1 , then g a i , c a i , t i is a segmenting rule , where c a i is the set of edges between g a i ands a i+1 by treatings a i+1 as a single node x. Rule ( 4 ) is an example of a segmenting rule : 2010Nian FIFA x 2010 FIFA ( 4 ) where dashed links are contextual connections . During decoding , when the context matches , rule ( 4 ) translates a subgraph over 2010Nian FIFA into a target phrase 2010 FIFA . For example , it can be applied to graph ( 5 ) where Shijiebei Zai Nanfei ( in the dashed rectangle ) is treated as x : 2010Nian FIFA Shijiebei Zai Nanfei ( 5 ) 3 . If there are no edges between g a i ands a i+1 , then c a i is equal to and g a i , , t i is a translation rule , called a selecting rule in this paper . During decoding , the untranslated input could be a set of subgraphs which are disjoint with each other . A selecting rule is used to select one of them . For example , rule ( 6 ) can be applied to ( 7 ) to translate 2010Nian FIFA to 2010 FIFA . In this example , the x in rule ( 6 ) matches with Chenggong Juxing ( in the dashed rectangle ) in ( 7 ) . By comparing these three types of rules , we observe that both segmenting rules and selecting rules are based on basic rules . They extend basic rules by adding contextual information to their source subgraphs so that basic rules are split into different groups according to the context . During decoding , the context will help to select target phrases as well . Algorithm 1 illustrates a simple process for rule extraction . Given a word - aligned graph - string pair , we first extract all initial pairs ( Line 1 ) . Then , we find basic rules from these pairs ( Lines 3 - 4 ) . Basic Algorithm 1 : An algorithm for extracting translation rules from a graph - string pair . Data : Word - aligned graph - string pair g , t , a Result : A set of translation rules R 1 find a set of initial pairs P ; 2 for each p = s a i , t i in P do 3 if s j i is connected then // basic rules
Following Li et al ( 2016 ) , we define our model in the well - known log - linear framework ( Och and Ney , 2002 ) . In our experiments , we use the following standard features : two translation probabilities p ( g , c | t ) and p ( t | g , c ) , two lexical translation probabilities p lex ( g , c | t ) and p lex ( t | g , c ) , a language model p ( t ) , a rule penalty , a word penalty , and a distortion function as defined in Galley and Manning ( 2010 ) . In addition , we add one more feature into our system : a basic - rule penalty to distinguish basic rules from segmenting and selecting rules . Our decoder is very similar to the one in the conventional graph - based model , which generates hypotheses left - to - right using beam search . A hypothesis can be extended on the right by translating an uncovered source subgraph . The translation process ends when all source words have been translated . However , when extending a hypothesis , our decoder considers the context of the translated subgraph , i.e. edges connecting it with the remaining untranslated source words . Figure 2 shows a derivation which translates an input graph in Chinese to an English string . In this example , both rules r 1 and r 2 are segmenting rules .
We conduct experiments on ZH - EN and DE - EN corpora .
The 1 : BLEU scores of all systems . Bold figures mean GBMT ctx is significantly better than GBMT at p ≤ 0.01 . * means a system is significantly better than PBMT at p ≤ 0.01 . + means a system is significantly better than TBMT at p ≤ 0.01 . Following Li et al ( 2016 ) , Chinese and German sentences are parsed into projective dependency trees which are then converted to graphs by adding bigram edges . Word alignment is performed by GIZA++ ( Och and Ney , 2003 ) with the heuristic function grow - diag - final - and . We use SRILM ( Stolcke , 2002 ) to train a 5 - gram language model on the Xinhua portion of the English Gigaword corpus 5th edition with modified Kneser - Ney discounting ( Chen and Goodman , 1996 ) . Batch MIRA ( Cherry and Foster , 2012 ) is used to tune feature weights . We report BLEU ( Papineni et al , 2002 ) scores averaged on three runs of MIRA ( Clark et al , 2011 ) . We compare our system GBMT ctx with several other systems . A system PBMT is built using the phrase - based model in Moses ( Koehn et al , 2007 ) . GBMT is the graph - based translation system described in Li et al ( 2016 ) . To examine the influence of bigram links , GBMT is also used to translate dependency trees where treelets Xiong et al , 2007 ) are the basic translation units . Accordingly , we name the system TBMT . All systems are implemented in Moses .
Table 1 shows BLEU scores of all systems . We found that GBMT ctx is better than PBMT across all test sets . Specifically , the improvements are +2.0/+0.7 BLEU on average on ZH - EN and DE - EN , respectively . This improvement is reasonable as our system allows discontinuous phrases which can reduce data sparsity and handle longdistance relations ( Galley and Manning , 2010 ) . In addition , the system TBMT does not show consistent improvements over PBMT while both GBMT and GBMT ctx achieve better BLEU scores than TBMT on both ZH - EN ( +1.8 BLEU , in terms of The number of rules in GBMT ctx according to their type GBMT ctx ) and DE - EN ( +0.6 BLEU , in terms of GBMT ctx ) . This suggests that continuous phrases connected by bigram links are essential to system performance since they help to improve phrase coverage ( Hanneman and Lavie , 2009 ) . We also found that GBMT ctx is significantly better than GBMT on both ZH - EN ( +1.0 BLEU ) and , which indicates that explicitly modeling a segmentation using context is helpful . The main reason for the improvement is that context helps to select proper subgraphs and target phrases . Figure 3 shows example translations . We found that in Figure 3a , after translating a parenthesis , GBMT ctx correctly selects a subgraph Gang Ao Tai and generates a target phrase hong kong , macao and taiwan . In Figure 3b , both GBMT and GBMT ctx choose to translate the subgraph WoMen Ye ZhiLi . However , given the context of the subgraph , GBMT ctx selects a correct target phrase we are also committed to for it .
Recall that , compared with GBMT , GBMT ctx contains three types of rules : basic rules , segmenting rules , and selecting rules . While basic rules exist in both systems , segmenting and selecting rules make GBMT ctx context - aware . Table 2 shows the number of rules in GBMT ctx according to their types . We found that on both language pairs 35 % - 36 % of rules are basic rules . While the proportion of segmenting rules is ∼53 % , selecting rules only account for 11 % - 12 % . This is because segmenting rules contain richer contextual information than selecting rules . Table 3 shows BLEU scores of GBMT ctx when different types of rules are used . Note that when only basic rules are allowed , our system degrades to the conventional GBMT system . The results in Table 3 suggest that both segmenting and selecting rules consistently improve GBMT on both language pairs . However , segmenting rules are more useful than selecting rules . This is reasonable since ( hong kong macao taiwan ) hong kong spring festival retail business rise 10 % ( Gang Ao Tai ) XiangGang XinChun LingShou ShengYi ShangSheng YiCheng Ref : GBMT : GBMTctx : ( hong kong , macao and taiwan ) hong kong 's retail sales up 10 % during spring festival ( the spring festival ) hong kong retail business in hong kong , macao and taiwan rose by 10 % ( hong kong , macao and taiwan ) hong kong spring retail business will increase by 10 % ( a ) subgraph selection we also dedicate protect and improve living emvironment .
ZhiLi BaoHu He GaiShan JuZhu HuanJing . Ref : GBMT : GBMTctx : we are also committed to protect and improve our living environment . we have worked hard to protect and improve the living environment . we are also committed to protect and improve the living environment . ( b ) target - phrase selection Bold figures mean a system is significantly better than the one only using basic rules at p ≤ 0.01 . the number of segmenting rules is much larger than the number of selecting rules . We further observed that , while our system achieves the best performance when all rules are used on ZH - EN , the combination of basic rules and segmenting rules on DE - EN results in the best system . This is probably because reordering ( including long - distance reordering ) is performed less often in DE - EN than in ZH - EN ( Li et al , 2016 ) which makes selecting rules less preferable on DE - EN .
In this paper , we present a graph - based model which takes subgraphs as the basic translation units and considers source context during segmenting graphs into subgraphs . Experiments on Chinese - English and German - English show that our model is significantly better than the conventional graphbased model which equally treats different graph segmentations . In this paper , source context is used as hard constraints during decoding . In future , we would like to try soft constraints . In addition , it would also be interesting to extend this model using a synchronous graph grammar .
This research has received funding from the European Union 's Horizon 2020 research and innovation programme under grant agreement n o 645452 ( QT21 ) . The ADAPT Centre for Digital Content Technology is funded under the SFI Research Centres Programme ( Grant 13 / RC/2106 ) and is cofunded under the European Regional Development Fund . The authors thank all anonymous reviewers for their insightful comments and suggestions .
