ZYJ123@DravidianLangTech - EACL2021 : Offensive Language Identification based on XLM - RoBERTa with DPCNN
The development of online media platforms has given users more opportunities to post and comment freely , but the negative impact of offensive language has become increasingly apparent .
It is very necessary for the automatic identification system of offensive language .
This paper describes our work on the task of Offensive Language Identification in Dravidian language - EACL 2021 .
To complete this task , we propose a system based on the multilingual model XLM - Roberta and DPCNN .
The test results on the official test data set confirm the effectiveness of our system .
The weighted average F1 - score of Kannada , Malayalam , and Tamil language are 0.69 , 0.92 , and 0.76 respectively , ranked 6th , 6th , and 3rd .
With the development of the information society , people have become accustomed to uploading content on social media platforms in the form of text , pictures , or videos .
At the same time , they also comment on the content uploaded by other users and interact with each other , thus increasing the activity of social media platforms Mahesan , 2019 , 2020a , b ) .
Inevitably , however , some users will post offensive posts or comments .
The use of offensive discourse is a kind of impolite phenomenon which has negative effects on the civilization of the network community ( Chakravarthi , 2020 ) .
It usually has the characteristics of causing conflicts and the purpose of publishing intentionally .
The publisher of offensive language may use reproach , sarcasm , swear and other language means to achieve intentional offense , and express a variety of intentions , such as disturbing , provoking , and expressing negative emotions ( Chakravarthi and Muralidaran , 2021 ; Suryawanshi and Chakravarthi , 2021 ) .
Most people will take measures to respond to offensive words .
The way to respond to the direct conflict of offensive words is mainly rhetorical questions , swear , sarcasm and threat , so as to express dissatisfaction , deny and satirize the other party and provoke the other party .
This will further cause conflicts and destroy the harmony of the network environment . 
Many social media platforms use a content review process , in which human reviewers check users ' comments for offensive language and other infractions , and which comments have been removed from the platform because of the violation ( Mandl et al , 2020 ) .
It is up to the moderator to decide which comments will be removed from the platform due to violations and which ones will be kept .
As the number of network users increases and user activity increases , the manual approach is undoubtedly inefficient .
Therefore , the automatic detection and identification of offensive content are very necessary .
However , offensive words often depend on the emotions and psychology of the listener , and some seemingly innocuous words can be potentially offensive , and words that often seem offensive are watered down by the emotions of the listener .
This kind of language phenomenon is not uncommon in real life , either unintentionally or deliberately used to achieve the speaker 's expected purpose , which is a challenging work for the current detection system . 
Our team takes part in the shared task of Offensive Language Identification in Dravidian Languages - EACL 2021 ( Chakravarthi et al , , 2020aHande et al , 2020 ) .
This is a classification task at the comment / post level .
The goal of this task is to identify offensive language content of the code - mixed dataset of comments / posts in Dravidian Languages ( ( Tamil - English , Malayalam - English , and Kannada - English ) ) collected from social media .
Tamil language is the oldest language in Indian languages , Malayalam and Kannada evolved from Tamil language .
For a comment on Youtube , the system must classify it into not - offensive , offensive - untargeted , offensive - targeted - individual , offensive - targeted - group , offensive - targeted - other , or not - in - indented - language . 
In our approach , the multilingual model XLM - RoBERTa and DPCNN are combined to carry out the classification task .
This method can combine the advantages of the two models to achieve a better classification effect .
The rest of the paper is divided into the following parts .
In the second part , we introduce the relevant work in this field , which involves offensive language detection and text classification methods .
In the third part , we introduce the model structure and the composition of our training data .
The fourth part introduces our experimental setup and results .
The fifth part is the conclusion .
Due to the harm of offensive language to the network environment , the identification of offensive language has been carried out for a long time . 
Research so far has focused on automating the decision - making process in the form of supervised machine learning for classification tasks ( Sun et al , 2019 ) .
As far back as 2012 , Chen et al ( 2012 ) proposed a lexical syntactic feature ( LSF ) framework to detect offensive content in social media , distinguished the roles of derogatory / profane and obscenity in identifying offensive content , and introduced handwritten syntax rules to identify abusive harassment .
In contrast to the start - to - end training model , Howard and Ruder ( 2018 ) proposed an effective transfer learning method , Universal Language Model Tuning ( ULMFIT ) , which can be applied to any task in natural language processing , and has shown significant results on six text classification tasks .
Subsequently , Abdellatif and Elgammal ( 2020 ) used the ULMFiT transfer learning method to train forward and backward models on Arabic datasets and ensemble the results to perform an offensive language detection task . 
Although English is currently one of the most commonly spoken languages in the world , work is ongoing to identify the offensive language in other languages that are less widely spoken .
Pitenis et al ( 2020 ) tested the performance of several traditional machine learning models and deep learning models on an offensive language dataset of Greek , and the best results were achieved with the attention model of LSTM and GRU .
Ozdemir and Yeniterzi ( 2020 ) ensembled CNN - LSTM , BILSTM - Attention , and BERT three models , combined with pre - trained word embedding on Twitter to complete the identification task of offensive Turkish language , and achieved a good result . 
A key challenge in automatically detecting hate speech on social media is to separate hate speech from other offensive languages .
Davidson et al ( 2017 ) used the crowd - sourced hate speech lexicon to collect tweets containing hate speech keywords .
They trained a multi - class classifier to reliably distinguish hate speech from other offensive languages , and found that racist and homophobic tweets were more likely to be classified as hate speech , but sexist tweets were generally classified as offensive .
Razavi et al ( 2010 ) proposed to extract features at different conceptual levels and apply multilevel classification for offensive language detection .
The system leverages a variety of statistical models and rule - based patterns , combined with an auxiliary weighted pattern library , to improve accuracy by matching text with its graded entries .
Pitsilis et
al ( 2018 ) proposed the ensemble of a recursive neural network ( RNN ) classifier , which combines various characteristics related to user - related information , such as the user 's sexist or racist tendencies , and was then fed to the classifier as input along with a word frequency vector derived from the text content . 
When there is a large amount of labeled data , increasing the size and parameters of the model will definitely improve the performance of the model .
However , when the amount of training is relatively small , the large - scale model may not be able to achieve good results , so solving the problem of model training under the condition of a small amount of target data has become a research hotspot .
Sun et al ( 2019 ) proposed a Hierarchical Attention Prototype Network ( HAPN ) for fewshot text classification , which designed multiple cross - concerns of a feature layer , word layer , and instance layer for the model to enhance the expressive power of semantic space .
The model was validated on two standard reference text classification datasets , Fewrel and CSID .
Prettenhofer and Stein ( 2010 ) built on structural correspondence learning , using untagged documents and simple word translation to induce task - specific , cross - language word correspondence .
English was used as the source language and German , French , and Japanese were used as the target language to conduct the experiment in the field of cross - language sentiment classification .
Using English data , Ranasinghe and Zampieri ( 2020 ) trained the model by applying cross - language contextual word embedding and transfer learning methods , and then predicted the effect of cross - language contextual embedding and transfer learning on this task in less resourceintensive languages such as Bengali , Hindi , and Spanish .
We count the number of each type of tag in the training set and the validation set , and obtain the data distribution of Not - offensive , offensive - untargeted , offensive - targeted - individual , offensive - targeted - group , offensive - targeted - other , and Not - in - indented - language in Tamil , Malayalam , and Kannada .
as shown in Table 1 .
Compared with the original BERT model , XLM - RoBERTa increases the number of languages and the number of training data sets .
Specifically , a preprocessed CommonCrawl dataset of more than 2 TB based on 100 languages is used to train crosslanguage representations in a self - supervised manner .
This includes generating new unlabeled corpora for low - resource languages and expanding the amount of training data available for these languages by two orders of magnitude .
In the finetuning period , the multi - language tagging data is used based on the ability of the multi - language model to improve the performance of the downstream tasks .
This enables XLM - RoBERTa to achieve state - of - the - art results in cross - language benchmarks while exceeding the performance of the single - language BERT model for each language .
Tune the parameters of the model to address cases where extending the model to more languages using cross - language migration limits the ability of the model to understand each language .
The XLM - RoBERTa parameter changes include up - sampling of low - resource languages during training and vocabulary building , generating a larger shared vocabulary , and increasing the overall model to 550 million parameters .
In this task , we combined XLM - RoBERTa with DPCNN ( Johnson and Zhang , 2017 ) to make the whole model more suitable for the downstream classification task .
DPCNN ( Deep Pyramid Convolutional Neural Networks ) is a kind of deep word level CNN structure , the calculation amount of each layer of the structure decreases exponentially .
DPCNN simply stacks the convolution module and negative sampling layer .
The computation volume of the whole model is limited to less than two times the number of convolution blocks .
At the same time , the pyramid structure also enables the model to discover long - term dependencies in the text .
In a common classification task , the last hidden state of the first token of the sequence ( CLS token ) , namely the original output of XLM - Roberta ( Pooler output ) , is further processed through the linear layer and the tanh activation function for classification purposes .
To obtain richer semantic information features of the model and improve the performance of the model , we first processed the output of the last three layers of XLM - RoBERTa through DPCNN , and then concatenate it with the original output of XLM - RoBERTa ( Pooler output ) to get a new and more effective feature vector , and then input this feature vector into the classifier for classification .
As shown in Figure 1 .
In this experiment , the pre - training model I used was XLM - RoBERTa - base .
After adding the DPCNN module , we began to set the experimental parameters .
We set the learning rate as 2e - 5 , the maximum sequence length is 256 , and the gradient steps are set to 4 .
The batch size is set to 32 , as shown in table 2 .
In the training process , we used five - fold stratified cross - validation to make the proportion of data of each category in each subsample the same as that in the original data and finally obtained the optimal result through the voting ( Onan et al , 2016 ) system , as shown in Figure 2 .
After the evaluation by the organizer , we obtained the weighted average F1 - score in the three languages , as shown in table 3 .
Our team 's F1 - score is 0.69 , ranked 6th place for the Kannada language .
For the Malayalam language , our team 's F1 - score is 0.92 ranked 6th place , and for the Tamil language , our team 's F1 - score is 0.76 ranked 3rd place .
In this paper , we describe our system in the task of offensive language identification for Tamil , Malayalam , and Kannada language .
In this model , the XLM - RoBERTa pre - training model is used to extract semantic information features of the text , and DPCNN is used to further process the output features .
At the same time , the hierarchical crossvalidation method is used to improve the training effect .
The final results show that our model achieves satisfactory performance .
In future work , we will try to adjust the structure of the new model , so as to improve its effect more significantly .
